{"cells":[{"metadata":{"_uuid":"785d4912b4289c6d0036241ffe9212cc44534c42"},"cell_type":"markdown","source":"# Chicago Divvy Bicycle Sharing Data\n\n#### Link Kaggle\nhttps://www.kaggle.com/yingwurenjian/chicago-divvy-bicycle-sharing-data\n\n#### Descrição das features:\n<br><b>trip_id</b>ID attached to each trip taken\n<br><b>year</b> Year\n<br><b>month</b> Month\n<br><b>week</b> Week No.\n<br><b>day</b> Day\n<br><b>hour</b> Hour\n<br><b>usertype</b> \"Customer\" is a rider who purchased a 24-Hour Pass; \"Subscriber\" is a rider who purchased an Annual Membership\n<br><b>gender</b>\n<br><b>starttimeday</b> and time trip started, in CST\n<br><b>stoptimeday</b> and time trip ended, in CST\n<br><b>tripdurationtime</b> of trip in minutes\n<br><b>temperature</b>\n<br><b>events</b>\n<br><b>from_station_idID</b> of station where trip originated\n<br><b>from_station_namename</b> of station where trip terminated\n<br><b>latitude_startstation</b> latitude\n<br><b>longitude_startstation</b> longitude\n<br><b>dpcapacity_startnumber</b> of total docks at each station\n<br><b>to_station_id</b>\n<br><b>to_station_name</b>\n<br><b>latitude_end</b>\n<br><b>longitude_end</b>\n<br><b>dpcapacity_endnumber</b> of total docks at each station"},{"metadata":{"_uuid":"8c99fb7c8163872faac6327b06716781b05a7a52"},"cell_type":"markdown","source":"### Bibliotecas"},{"metadata":{"trusted":false,"_uuid":"7d8d627337317423aa3b89791ebb16e332007e06"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n#from sklearn.learning_curve import validation_curve\n#from sklearn.learning_curve import learning_curve\n#from sklearn.cross_validation import train_test_split\n#from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n#from sklearn.cross_validation  import cross_val_score\nfrom sklearn.model_selection  import validation_curve\nfrom sklearn.model_selection  import learning_curve\nfrom sklearn.model_selection  import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error, r2_score\nfrom sklearn.model_selection   import cross_val_score\n\nfrom sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"13a427d9f27f97fa405d26786bd56bf2bef89485"},"cell_type":"code","source":"#################### Define Helper Functions\ndef bs_create_polynomial_terms(l_train, l_test, degree):\n    from sklearn.preprocessing import PolynomialFeatures\n    poly = PolynomialFeatures(degree=degree)\n    # details http://scikit-learn.org/stable/modules/linear_model.html\n    l_train_poly = poly.fit_transform(l_train) \n    l_test_poly = poly.fit_transform(l_test)\n    return l_train_poly, l_test_poly\n    \ndef bs_scale_mean_std(l_train, l_test):\n    # read about data scaling here: \n    # http://quant.stackexchange.com/questions/4434/gradient-tree-boosting-do-input-attributes-need-to-be-scaled\n    sc = StandardScaler()\n    l_train_scaled = pd.DataFrame(sc.fit_transform(l_train))\n    l_test_scaled = pd.DataFrame(sc.transform(l_test)) # careful, transform() only.\n    return l_train_scaled, l_test_scaled\n\ndef bs_fit_and_save(clf, l_train, l_target, l_test, filename):\n    # more about it here: http://scikit-learn.org/stable/modules/svm.html#regression\n    clf.fit (l_train, l_target)\n    # The mean square error\n    predict_train = clf.predict(l_train)\n    print(\"Residual sum of squares: %.2f\" % np.mean((predict_train - l_target) ** 2))\n    # Explained variance score: 1 is perfect prediction\n    print('Variance score: %.2f' % clf.score(l_train, l_target))\n    return clf\n\ndef bs_accuracy(test, pred):   \n    print('Acurácia norm. = {:.2f}'.format(accuracy_score(test, pred)))\n    print('Acurácia = {:.0f}'.format(accuracy_score(test, pred, normalize=False)))\n\ndef plot_chart_predict(x__plot, model, x_test, y_test, bot, top, desc):\n    y_pred = model.predict(x_test)\n    v_title = \"Predição de viagens - Modelo: \" + desc\n\n    \n    plt.rcParams[\"figure.figsize\"] = (15,9)\n    plt.plot(x__plot['date2'][bot:top], np.exp(np.log(y_test[bot:top])),  color='black', label=\"Dia Real\")\n    plt.plot(x__plot['date2'][bot:top], np.exp(y_pred[bot:top]),10, color='blue', linewidth=3,  label=\"Predição\")\n    plt.legend(loc='upper right')\n    plt.title(v_title, fontsize=16, fontweight='bold')\n    plt.xlabel(\"Dia\")\n    plt.ylabel(\"Media Viagens\")\n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9c01ed8956b539329da56fd478fe2534fa110e6"},"cell_type":"markdown","source":"### Carregar dataset"},{"metadata":{"trusted":false,"_uuid":"3ca9afa4678716539e41cc61421286d88fe9df3b"},"cell_type":"code","source":"#Carregar dataset\n#path = \"data.csv\"\npath = \"../input/data.csv\"\ndf = pd.read_csv(path)\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"21e41fc00ea08598ad7929ef64a6b5991e14295a"},"cell_type":"code","source":"#feriados ###############\nholidays = [\n'2014-01-01','2014-12-25',\n'2014-11-11','2014-07-04',\n'2014-01-20','2014-02-17',\n'2014-03-02','2014-05-26',\n'2014-09-01','2014-10-13',\n'2014-11-27','2015-01-01',\n'2015-12-25','2015-11-11',\n'2015-07-04','2015-01-19',\n'2015-02-16','2015-03-02',\n'2015-05-25','2015-09-07',\n'2015-10-12','2015-11-26',\n'2016-01-01','2016-12-25',\n'2016-11-11','2016-07-04',\n'2016-01-18','2016-02-15',\n'2016-03-04','2016-05-30',\n'2016-09-05','2016-10-10',\n'2016-11-24','2017-01-01',\n'2017-12-25','2017-11-11',\n'2017-07-04','2017-01-16',\n'2017-02-20','2017-03-06',\n'2017-05-29','2017-09-04',\n'2017-10-09','2017-11-23'\n]\n\ndf_holidays = pd.DataFrame(holidays)\ndf_holidays['date'] = pd.to_datetime(df_holidays[0]).dt.date\ndf_holidays['holiday'] = 1\ndf_holidays = df_holidays.drop([0], axis=1)\n\n\n#Corringindo campo day com 0\ndf.day =  df.starttime.astype(str).str.slice(8,10).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"27050adf1c0f72c7eceab03d7e47b06a5823b28e"},"cell_type":"code","source":"#Novas features\ndf.starttime = pd.to_datetime(df.starttime)\ndf.stoptime  = pd.to_datetime(df.stoptime)\ndf['date']   = df.starttime.dt.date\n\n#Definição fim de semana\ndf['weekend'] = np.where(df.starttime.dt.weekday > 4 , 1, 0)\n\n#Inicializando novas features\ndf['season'] = ''\n\n#Definição estações Hemisfério NORTE  ##########################\nfor x in range(df.year.min().astype(int), df.year.max().astype(int)+1):\n    #Primavera: 21-03 até 20-06\n    df.loc[(df.starttime > str(x)+'-03-21 00:00:00') & (df.starttime < str(x)+'-06-20 23:59:59'),  'season'] = 'primavera'\n    #Verão:     21-06 até 20-09\n    df.loc[(df.starttime > str(x)+'-06-21 00:00:00') & (df.starttime < str(x)+'-09-20 23:59:59'),  'season'] = 'verão'\n    #Outono:    21-09 até 20-12\n    df.loc[(df.starttime > str(x)+'-09-21 00:00:00') & (df.starttime < str(x)+'-12-20 23:59:59'),  'season'] = 'outono'\n    #Inverno:   21-12 até 20-03\n    df.loc[(df.starttime > str(x)+'-12-21 00:00:00') & (df.starttime < str(x+1)+'-03-20 23:59:59'),'season'] = 'inverno'\n    \n    \n    \n#Junção dos dados com feriados #################################\ndf_holidays.head()\ndf_join = df.set_index('date').join(df_holidays.set_index('date'))\ndf_join['isholiday']  = np.where(df_join.holiday==1, 1, 0)\ndf_join['regularday'] = np.where(df_join.isholiday+df_join.weekend == 0, 1, 0)\n\n#clear DF ##################################\ndf.iloc[0:0]\ndel df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bcb489ae1a04bfe8f45adb78b5c66516637a7447"},"cell_type":"code","source":"#Label Encoder ##############################\n# Replace all male and female genders with '0's and '1's respectively\ndf_join.loc[df_join[\"gender\"] == \"Male\", \"gender\"] = 0\ndf_join.loc[df_join[\"gender\"] == \"Female\", \"gender\"] = 1\n\n# tipo usuario\nlb_usertype = LabelEncoder()\ndf_join[\"usertype_code\"] = lb_usertype.fit_transform(df_join[\"usertype\"])\ndf_join[[\"usertype\", \"usertype_code\"]].head(11)\n\n#estação\nlb_to_station_name = LabelEncoder()\ndf_join[\"to_station_name_code\"] = lb_usertype.fit_transform(df_join[\"to_station_name\"])\ndf_join[[\"to_station_name\", \"to_station_name_code\"]].head(11)\n\n\n#estação\n#lb_season = LabelEncoder()\n#df_join[\"season_code\"] = lb_season.fit_transform(df_join[\"season\"])\n#df_join[[\"season\", \"season_code\"]].head(11)\n\n#lb_date_id = LabelEncoder()\n#df_join[\"lb_date_id_code\"] = lb_season.fit_transform(df_join[\"date_id\"])\n#df_join[[\"date_id\", \"lb_date_id_code\"]].head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"907dde90c1151694d4193f7efd3c31d2cde9b1b7"},"cell_type":"code","source":"#convert lines into columns\ndf_join = pd.get_dummies(df_join, columns=[\"season\"])\ndf_join_del = df_join[df_join['season_'] == 1]\ndf_join = df_join.drop(df_join_del.index, axis=0)\n\n# convert string to int\ndf_join[['year', 'month', 'day', 'hour']] = df_join[['year', 'month', 'day', 'hour']].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"88f28028fa4b6ed44fba62a131f2071618d6f17e"},"cell_type":"code","source":"#Agregar informação para modelo\ncol = [\n'year',\n 'month',\n    'day',\n'weekend',\n'season_inverno',\n'season_outono',\n'season_primavera',\n'season_verão',\n'isholiday',\n'regularday'\n]\n\ndf_join['trip_count'] = 1\n\n#Agregação\ndf_join_agg1 =  df_join.groupby(col).aggregate({                                         \n                                         'trip_count'      : 'sum'\n                                        }).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"06a472d1aaa796bdfd2e5f43f973f0da027dcbd5"},"cell_type":"code","source":"#split datasets to train/test and validation\ndf_join_agg_2017 = df_join_agg1[df_join_agg1.year == 2017]\ndf_join_agg_2016 = df_join_agg1[df_join_agg1.year != 2017]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a37849d79588e69ac8de938771767f8ea23b6261"},"cell_type":"code","source":"y = df_join_agg_2016.trip_count\n\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(df_join_agg_2016, y, test_size=0.25)\n\nX_train = X_train.drop(labels=[\"trip_count\"], axis=1)\nX_test = X_test.drop(labels=[\"trip_count\"], axis=1)\n\n#valida\ny_valida = df_join_agg_2017.trip_count\nX_valida = df_join_agg_2017.drop(labels=[\"trip_count\"], axis=1)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n\n\nx_plot = X_test.copy()\nx_plot['date2'] = x_plot['year'].astype(str) +  x_plot['day'].astype(str) +  x_plot['month'].astype(str) \nx_plot2 = X_valida.copy()\nx_plot2['date2'] = x_plot2['year'].astype(str) +  x_plot2['day'].astype(str) +  x_plot2['month'].astype(str) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d1043bcba2a8693e6d6f61fcec6cdd42ba354642"},"cell_type":"code","source":"X_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d1db3a95a57eeac5141070835d5b4b06dd8c2415"},"cell_type":"code","source":"plt.matshow(X_train.corr())\n# fit a model\n#y_train = np.log(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"da9ca5affe127bf2b7288cd32d4d1bbf0897a8aa"},"cell_type":"code","source":"lm         = linear_model.LinearRegression()\nlm.fit(X_train, np.log(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"93d59ae01ae5d503d2d6c2a438e2b6de5ce0f368"},"cell_type":"code","source":"## The line / model\ny_train   = np.log(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"51e25e1e7c455edab9be1adc5268fb5de2e3b7d8"},"cell_type":"code","source":"y_pred  = lm.predict(X_test)\n# The mean squared error\nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))\n\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predição\")\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predição de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a85166964a69d87cdc03177864838903a89143e0"},"cell_type":"code","source":"\nplot_chart_predict(x_plot2, bot=1,top=30,model=lm,x_test=X_valida,y_test=y_valida,desc=\"Baseline\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ba27cac17f33216ab0879e4edd66c8c1735441b8"},"cell_type":"code","source":"################## Simple Linear Regression\n# Since its a regression problem we will first develop simple linear regression\n\n# Create linear regression object\nclf1 = linear_model.LinearRegression()\n\n# get fitted regresser\nclf1 = bs_fit_and_save(clf1, X_train, y_train, X_test, \"output_SLR\")\ny_pred  = clf1.predict(X_test)\n\n\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predição\")\n\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predição de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"556d67b93f8d6601af0537352c3a4cfd6ce76f70"},"cell_type":"code","source":"plot_chart_predict(x_plot2, bot=1,top=30,model=clf1,x_test=X_valida,y_test=y_valida,desc=\"Baseline2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5734e4a7b7bddd5ea2a9cad585ab24d514f09966"},"cell_type":"code","source":"################## Simple Linear Regression with Ridge Regression\n\n# Now we will perform Ridge Regression\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(X_train, X_test)\n\n# first we will perform cross-validation to find the best alpha value\nclf2 = linear_model.RidgeCV(alphas=[0.0001, 0.001, 0.1, 1.0, 10.0, 100.0, 1000.0])\n\nclf2 = bs_fit_and_save(clf2, train_scaled, y_train, test_scaled, \"output_Ridge\")\n\n# The coefficients\nprint('Coefficients: \\n', clf2.coef_)\nprint('Alpha: \\n', clf2.alpha_) \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"647d04276bb102152f285bd48d9029a73b218080"},"cell_type":"code","source":"################## Simple Linear Regression with Lasso Regression\n\n# Unlike simple linear regression, lasso regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(X_train, X_test)\n\n# first we will perform cross-validation to find the best alpha value\nclf3 = linear_model.LassoCV(alphas=[0.001, 0.1, 1.0, 10.0, 100.0, 1000.0])\n\n# get fitted regresser\nclf3 = bs_fit_and_save(clf3, train_scaled, y_train, test_scaled, \"output_Lasso\")\n\n# The coefficients\nprint('Alpha: \\n', clf3.alpha_)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"16c64bd98bcf9f965585d383d809ead77583b617"},"cell_type":"code","source":"################## Simple Linear Regression with Polynomial terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Create linear regression object\nclf4 = linear_model.LinearRegression()\n\n# get fitted regresser\nclf4 = bs_fit_and_save(clf4, train_poly, y_train, test_poly, \"output_poly_d2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7273e496b8ed0a0d0b2b15c6382bc2d19f7b4ea7"},"cell_type":"code","source":"################## Ridge Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\nclf5 = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0, 1000.0])\n\n# get fitted regresser\nclf5 = bs_fit_and_save(clf5, train_scaled, y_train, test_scaled, \"output_Ridge_poly_2\")\n\n\n\ny_pred  = clf5.predict(test_scaled)\n\n\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predição\")\n\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predição de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"970dda0e16802ddbf8eef228350e4abc46d83600"},"cell_type":"code","source":"################## Lasso Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Lasso regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\nclf6 = linear_model.LassoCV(alphas=[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0])\n\n# get fitted regresser\nclf6 = bs_fit_and_save(clf6, train_scaled, y_train, test_scaled, \"output_lasso_poly_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"afd24404e1e4cfb3479c59ba1467ff677c315c8a"},"cell_type":"code","source":"################## Support Vector Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# SVR requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\n# ideally these parameters should be determined using cross-validation\nclf7 = svm.SVR(kernel='rbf', C=100, gamma=0.01) \n\n# get fitted regresser\nclf7 = bs_fit_and_save(clf7, train_scaled, y_train, test_scaled, \"output_svm_poly_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2f1c8ce9358b6051362f53bcd8ef7c7fefe0d0fe"},"cell_type":"code","source":"################## Gradient Boosting Regression with Polynomial Terms\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 2)\n\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n# Create linear regression object\nclf8 = GradientBoostingRegressor(n_estimators=350, learning_rate=0.1, \n                                max_depth=3, loss='ls')\n\n# get fitted regresser\nclf8 = bs_fit_and_save(clf8, train_scaled, y_train, test_scaled, \"output_gbm_poly_2\")\n\n\ny_pred  = clf8.predict(test_scaled)\nplt.scatter(x_plot['date2'], np.log(y_test),  color='black', label=\"Dia Real\")\nplt.plot(x_plot['date2'], y_pred, color='blue', linewidth=3,  label=\"Predição\")\nplt.rcParams[\"figure.figsize\"] = (15,9)\nplt.legend(loc='upper right')\nplt.title(\"Predição de viagens\", fontsize=16, fontweight='bold')\nplt.xlabel(\"Dia\")\nplt.ylabel(\"Media Viagens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4c136fa3cad1147db686d2f1852da643690a8ecb"},"cell_type":"code","source":"#Validation ###################################################\n# create polynomial terms\ntrain_poly, valid_poly = bs_create_polynomial_terms(X_train, X_valida, 2)\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, valid_scaled = bs_scale_mean_std(train_poly, valid_poly)\n\n\nplot_chart_predict(x_plot2, bot=120,top=130,model=clf8,x_test=valid_scaled,y_test=y_valida,desc=\"Gradient Boosting - Polynomial\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e01cfd96d2f0e655367a221ab71488a892f3ab11"},"cell_type":"code","source":"################## GBR with parameter estimation with cross-validation\n\n# create polynomial terms\ntrain_poly, test_poly = bs_create_polynomial_terms(X_train, X_test, 3)\n\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain_scaled, test_scaled = bs_scale_mean_std(train_poly, test_poly)\n\n\n# create polynomial terms\ntrain2_poly, valid_poly = bs_create_polynomial_terms(X_train, X_valida, 3)\n\n# Unlike simple linear regression, ridge regularization requires scaled data\ntrain2_scaled, valid_poly = bs_scale_mean_std(train2_poly, valid_poly)\n\n\n# Create linear regression object\nt_clf = GradientBoostingRegressor(n_estimators=500, learning_rate=0.1, \n                                max_depth=3, loss='ls')\n                                \n#from sklearn.grid_search import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\nparam_range_n_estimators = [500, 1000, 2000]\nparam_range_max_depth = [1, 3, 5]\n\nparam_grid = [{'n_estimators': param_range_n_estimators,\n              'max_depth': param_range_max_depth}]\n\n# we will not define optional 'scoring' parameter. It will use lsr for scoring\n# read here for detail of scoring for classification and regression grid search\n# http://scikit-learn.org/stable/modules/grid_search.html\n# https://github.com/scikit-learn/scikit-learn/blob/51a765a/sklearn/metrics/regression.py#L370\nclf10 = GridSearchCV(estimator=t_clf, param_grid=param_grid, cv=5, n_jobs=4)\n                 \n# get fitted regresser\nclf10 = bs_fit_and_save(clf10, train_scaled, y_train, test_scaled, \"output_gbm_cv_poly_3\") # this will take some time","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"796530dd3c46552b5f200f4dcca9d701374d7eab"},"cell_type":"code","source":"plot_chart_predict(x__plot=x_plot2, bot=213,top=219,model=clf10,x_test=valid_poly,y_test=y_valida,desc=\"Gradient Boosting - Cross Valid\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}