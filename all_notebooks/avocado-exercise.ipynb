{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"avocado_data = pd.read_csv(\"/kaggle/input/avocado-prices/avocado.csv\")\navocado_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deleting columns, namely Unnamed and Date"},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado_data = avocado_data.drop([\"Unnamed: 0\", \"Date\"], axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado_data = avocado_data.rename(columns={\"4046\": \"small\", \"4225\": \"big\", \"4770\": \"very big\"})\navocado_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado_data = avocado_data.replace(0.0, np.nan)\nmissing_values_count = avocado_data.isnull().sum() \nprint(\"Length of data: \", len(avocado_data))\nmissing_values_count ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['small', 'big', 'very big', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags'] \n\nmedians = []\n\nfor c in columns:\n    medians.append(avocado_data[c].median())\n    \nmedians","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor c in columns:\n    avocado_data[c] = avocado_data[c].fillna(medians[i])\n    i += 1\n    \navocado_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filled all Nan data with the median of columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"avocado_data = avocado_data.replace(0.0, np.nan)\nmissing_values_count = avocado_data.isnull().sum() \nprint(\"Length of data: \", len(avocado_data))\nmissing_values_count ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting average price"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.distplot(avocado_data['AveragePrice']); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nf,ax=plt.subplots(figsize=(10,9))\nsns.heatmap(avocado_data.corr(),annot=True,fmt='.2f',ax=ax,vmin=-1, vmax=1, center= 0, cmap= 'coolwarm',linewidths=3, linecolor='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.scatter(avocado_data, x='AveragePrice', y='Total Volume',\n                 color='type') # Added color to previous basic \nfig.update_layout(title='Average Price Vs Volume with Avocado Type ',xaxis_title=\"Price\",yaxis_title=\"Volume\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = ['type','region']\n\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\navocado_data[label_cols] = avocado_data[label_cols].apply(lambda x : label.fit_transform(x)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = avocado_data.drop(['AveragePrice'],axis=1)\ny = avocado_data[\"AveragePrice\"]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import make_column_transformer \nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nscaler = StandardScaler()\nohe = OneHotEncoder() \n\nscale_cols = avocado_data.drop(['AveragePrice','type','year','region'], axis=1).columns\ncol_trans = avocado_data[label_cols].columns\n\n# X_train, X_test, y_train, y_test\nscaled_columns  = scaler.fit_transform(X_train[scale_cols]) \nencoded_columns = ohe.fit_transform(X_train[col_trans])  \nX_train = np.concatenate([scaled_columns, pd.DataFrame(encoded_columns.toarray())\n], axis=1)  \n\nscaled_columns  = scaler.fit_transform(X_test[scale_cols]) \nencoded_columns = ohe.fit_transform(X_test[col_trans])  \nX_test = np.concatenate([scaled_columns, pd.DataFrame(encoded_columns.toarray())\n], axis=1)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf \n\navocado_model = tf.keras.Sequential([  \n    tf.keras.layers.Dense(32, activation='relu', input_shape = X_train.shape[1:]),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.2),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.2),\n    tf.keras.layers.Dense(1),\n]) \n\navocado_model.compile(loss='mse', optimizer='sgd')\navocado_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 30\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True) \n\nhistory = avocado_model.fit(\n    X_train, y_train,\n    validation_split=0.15, \n    epochs=num_epochs, \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting results"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \n\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_' + string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n   \nplot_graphs(history, \"loss\")  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Evaluate on test data\")\nresults = avocado_model.evaluate(X_test, y_test)\nprint(\"test loss, test acc:\", results) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = avocado_model.predict(X_test[:5])\nprint(\"prediction: \", prediction.tolist()) \nprint(\"test: \",  y_test[:5].tolist())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}