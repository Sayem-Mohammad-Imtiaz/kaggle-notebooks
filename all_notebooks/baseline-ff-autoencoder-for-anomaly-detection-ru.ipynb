{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Воркшоп по поиску аномалий в технических системах: Обнаружение аномалий в работе насоса"},{"metadata":{},"cell_type":"markdown","source":"## Общие материалы для погружения в тему:\nБольшинство ссылок взято из моего [cheatsheet](https://github.com/YKatser/DS-links)'а по data science. Там еще много отобранного материала, правда совсем немного для начального уровня.\n\nКурсы:\n1. [Курс Введение в машинное обучение (примерно 56 часов для прохождения)](https://www.coursera.org/learn/vvedenie-mashinnoe-obuchenie)\n```\nВы изучите основные типы задач, решаемых с помощью машинного обучения — в основном речь пойдёт о классификации, регрессии и кластеризации. Узнаете об основных методах машинного обучения и их особенностях, научитесь оценивать качество моделей — и решать, подходит ли модель для решения конкретной задачи. Наконец, познакомитесь с современными библиотеками, в которых реализованы обсуждаемые модели и методы оценки их качества. Для работы мы будем использовать реальные данные из реальных задач.\n```\n2. [Курс Машинное обучение и анализ данных (примерно 224 часа для прохождения)](https://www.coursera.org/specializations/machine-learning-data-analysis) \n```\nМы покажем, как проходит полный цикл анализа, от сбора данных до выбора оптимального решения и оценки его качества. Вы научитесь пользоваться современными аналитическими инструментами и адаптировать их под особенности конкретных задач.\n```\n3. [Курс \"Машинное обучение\" на ФКН ВШЭ](https://github.com/esokolov/ml-course-hse)\n```\nКонспекты лекций, материалы семинаров и домашние задания (теоретические, практические, соревнования) по курсу \"Машинное обучение\", проводимому на бакалаврской программе \"Прикладная математика и информатика\" Факультета компьютерных наук Высшей школы экономики.\n```\n4. [Курс от mlcourse.ai](https://github.com/Yorko/mlcourse.ai)\n```\nmlcourse.ai is an open Machine Learning course by OpenDataScience. The course is designed to perfectly balance theory and practice.\n```\n\nДругие материалы:\n1. [Machine Learning with scikit-learn (interactive slides)](http://amueller.github.io/sklearn_tutorial/#/1)\n```\nОтличное введение в sklearn - одну из самых популярных библиотек для решения задач машинного обучения.\n```\n2. [Machine Learning and Data Science Applications in Industry](https://github.com/ashishpatel26/Real-time-ML-Project#manufacturing)\n```\nБольшое число инструментов и ноутбуков с решением задач в различых отраслях.\n```\n3. [Awesome Machine Learning (github)](https://github.com/josephmisiti/awesome-machine-learning#python-general-purpose)\n```\nБольшое число библиотек для работы в data science.\n```\n4. [Time Series Analysis (TSA) in Python - Linear Models to GARCH](http://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016)"},{"metadata":{},"cell_type":"markdown","source":"## Описание установки"},{"metadata":{},"cell_type":"markdown","source":"Демонстрационный стенд промышленного интернета вещей (далее - Стенд) предназначен для:\n\n- Демонстрации возможностей и преимуществ, связанных с внедрением технологий промышленного интернета вещей;\n- Апробации, верификации и валидации новых технологий, связанных с промышленным интернетом вещей, в лабораторных условиях в целях определения набора научных теорий, алгоритмов и практических инструментов для применения данных технологий в актуальных промышленных задачах;\n- Проведения образовательных и исследовательских работ по тематике промышленного интернета вещей.\n\nПростой и интуитивно понятный пользовательский интерфейс программы позволяет работать с системами в соответствии с инструкциями, представленными в руководстве пользователя по отдельности.\n\nСтенд представляет собой водяной насос с замкнутым контуром, системой электропитания, системами управления, сбора данных и мониторинга, построенных с применением технологий промышленного интернета вещей.\nСтенд состоит из следующих систем:\n\n1. Система циркуляции воды.\n2. Система управления системой циркуляции воды (далее - Система управления).\n3. Система мониторинга состояния системы циркуляции воды (далее - Система мониторинга).\n4. Система демонстрации технологии TSN.\n5. Система хранения, обработки и визуализации данных.\n\nСистема циркуляции воды предназначена для имитации системы водоснабжения в лабораторных условиях и обеспечивает циркуляцию воды по водяным трубам путем использования водяного насоса.\nСистема циркуляции воды обеспечивает имитацию следующих неполадок:\n\n- Введение дисбаланса на соединительном вале мотора и водяного насоса;\n- Изменение пропускной способности клапана на входе насоса;\n- Изменение пропускной способности клапана на выходе насоса.\n\nСистема состоит из следующих компонентов: \n- Водяной насос\n- Электрический мотор\n- Инвертор\n- Электроклапан (1)\n- Электроклапан (2)\n- Механический рычаг для нарушения соосности\n- Датчики вибрации\n- Водяной бак с трубами\n- Датчик давления\n- Расходомер\n- Термопара"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/skoltech-anomaly-benchmark-skab-teaser/look.png\", width=1000, height=500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Лицевая панель систем циркуляции воды, управления и мониторинга, где:\n1,2 – электроклапаны;\n3 - бак с водой;\n4 – насос;\n5 – кнопка экстренного останова; 6 – мотор;\n7 – инвертор;\n8 – cRIO;\n9 – механический рычаг."},{"metadata":{},"cell_type":"markdown","source":"## Работа с данными"},{"metadata":{},"cell_type":"markdown","source":"В выборке присутствуют 4 аномалии:\n\n- РАСЦЕНТРОВКА ВАЛОВ НАСОСА И ДВИГАТЕЛЯ (резко)  \nРезкое появление дефекта: 18:39:22  \nРезкое отключение дефекта: 18:42:32\n\n- РАСЦЕНТРОВКА ВАЛОВ НАСОСА И ДВИГАТЕЛЯ (медленно)  \nМедленное появление дефекта: 18:44:36-18:45:49  \nРезкое отключение дефекта: 18:46:51\n\n- ПЕРЕКРЫТИЕ (УМЕНЬШЕНИЕ) ПРОХОДНОГО СЕЧЕНИЯ-1 (верх)  \nМедленное появление дефекта: 19:06:57-19:07:37  \nМедленное отключение дефекта: 19:10:45-19:11:31\n\n- ПЕРЕКРЫТИЕ (УМЕНЬШЕНИЕ) ПРОХОДНОГО СЕЧЕНИЯ-2 (низ)  \nМедленное появление дефекта: 19:14:40-19:16:24  \nМедленное отключение дефекта: 19:19:15-19:21:16"},{"metadata":{},"cell_type":"markdown","source":"## Постановка задачи"},{"metadata":{},"cell_type":"markdown","source":"- **ДС задача с точки зрения бизнеса:** Необходимо обнаруживать возникающие аномалии как можно раньше с момента их появления.\n\nМетрика:\nСреднее время запаздывания обнаружения\n\n$\\text{ADD} = \\frac{1}{|Y|}\\sum_{y \\in Y} ( \\tau_y - \\theta_y )$,\n\nгде $|Y|$ - суммарное количество точек изменения состояния,  \n$\\tau_y$ - время обнаружения  \n$\\theta_y$ - время реального изменения состояния\n\n- **ДС задача с точки зрения математики:** Необходимо построить модель, которая наиболее точно описывает нормальный режим работы установки.\n\nМетрика:\nСредняя абсолютная ошибка\n\n$\\text{MAE} = \\frac{1}{N} \\sum^{N}_{i=1}|x_i - \\hat{x}_i|$,\n\nгде $N$ - общее число значений,  \n$x_i$ - правдивое значение в момент времени $i$,  \n$\\hat{x}_i$ - предсказанное значение в момент времени $i$."},{"metadata":{},"cell_type":"markdown","source":"### Импорт необходимых библиотек"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Загрузка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Считывание данных из исходного csv файла\nraw_data = pd.read_csv('../input/skoltech-anomaly-benchmark-skab-teaser/SkAB teaser.csv', \n                   sep=';', \n                   index_col='datetime', \n                   parse_dates=True).drop('index',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отображение 10 первых строк таблицы\nraw_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Необходимо развернуть таблицу, чтобы каждый сигнал являлся колонкой таблицы."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разворачиваем таблицу, приведение к нормальному виду\nraw_data = raw_data.pivot_table(values='value', index=raw_data.index, columns='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отображение 5 первых строк таблицы\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отрисовка графика\nraw_data.plot(figsize=(12,6), marker='o', markersize=3);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обрежем начало данных, чтобы исключить переходный период (разогрев)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обрезка данных\nraw_data = raw_data['2019-07-08 17:52:29':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отрисовка графика\nraw_data.plot(figsize=(12,6), marker='o', markersize=3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохранение предобработанных данных\n# raw_data.to_csv('raw_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Принт размерности данных\nprint(f'Размерность данных следующая: {raw_data.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Значения признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отрисовка графиков всех сигналов\nfor name in raw_data.columns:\n    raw_data[name].plot(figsize=(12,3), marker='o', markersize=2)\n    plt.xlabel('Время')\n    plt.ylabel('Значение параметра')\n    plt.title(f'График сигнала: {name}')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Дополнительная обработка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# todo\ndef preprocessing(raw_data):\n    data = raw_data.copy()\n    \n    # your code\n    \n    return data\n\ndata = preprocessing(raw_data=raw_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Разбиение на обучающую, валидационную и тестовую выборки"},{"metadata":{},"cell_type":"markdown","source":"- Обучающая выборка (training sample) — выборка, по которой производится настройка (оптимизация параметров) модели зависимости.\n- Валидационная выборка (validation sample) — выборка, по которой осуществляется выбор наилучшей модели из множества моделей, построенных по обучающей выборке.\n- Тестовая (или контрольная) выборка (test sample) — выборка, по которой оценивается качество решения задачи.\n\nОписания и варианты определений обучающей, валидационной и тестовой выборок представлены в [статье 1](http://www.machinelearning.ru/wiki/index.php?title=Выборка), [статье 2](https://medium.com/@tekaround/train-validation-test-set-in-machine-learning-how-to-understand-6cdd98d4a764) и др.\n\n[Статья](https://hunch.net/?p=22) о переобучении в машинном обучении."},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"# Демонстрация разбиения на обучающую, валидационную и тестовую выборки\ndata.plot(figsize=(12,6))\nplt.axvspan(data.index[0], \n            '2019-07-08 18:25', \n            color='green', \n            alpha=0.1, \n            label='Обучающая выборка')\nplt.axvspan('2019-07-08 18:25', \n            '2019-07-08 18:35', \n            color='yellow', \n            alpha=0.1, \n            label='Валидационная выборка')\nplt.axvspan('2019-07-08 18:35', \n            data.index[-1], \n            color='red', \n            alpha=0.1, \n            label='Тестовая выборка')\nplt.legend(bbox_to_anchor =(0.8, -0.2), ncol = 3)\nplt.xlabel('Время')\nplt.ylabel('Значение параметров')\nplt.title('Обучающая, валидационная и тестовая выборки');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Масштабирование (нормализация) данных"},{"metadata":{},"cell_type":"markdown","source":"Для большинства алгоритмов машинного обучения необходимо, чтобы все признаки были в одном масштабе."},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"# Инициализация скэйлера\nStSc = StandardScaler()\n# Обучение скэйлера на тренировочной выборке\nStSc.fit(data[:'2019-07-08 18:25'])\n\n# Применение скэйлера на всех данных\n# Преобразование тренировочной выборки\ntrain_sc = StSc.transform(data[:'2019-07-08 18:25'])\n# Преобразование валидационной выборки\nval_sc = StSc.transform(data['2019-07-08 18:25':'2019-07-08 18:35'])\n# Преобразование всей выборки\ndata_sc = StSc.transform(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обучение модели"},{"metadata":{},"cell_type":"markdown","source":"- Ссылка на курс Keras с бэкэндом TensorFlow: https://youtu.be/qFJeN9V1ZsI"},{"metadata":{},"cell_type":"markdown","source":"### Импорт необходимых библиотек"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n# from tensorflow.keras.callbacks import TensorBoard\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom itertools import product","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Функция для воспроизводимости результатов"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"def Random(seed_value):\n    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n    import os\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n\n    # 2. Set `python` built-in pseudo-random generator at a fixed value\n    import random\n    random.seed(seed_value)\n\n    # 3. Set `numpy` pseudo-random generator at a fixed value\n    import numpy as np\n    np.random.seed(seed_value)\n\n    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n    import tensorflow as tf\n    tf.random.set_seed(seed_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Описание Автоэнкодера"},{"metadata":{},"cell_type":"markdown","source":"![ae](https://miro.medium.com/max/700/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)"},{"metadata":{},"cell_type":"markdown","source":"Автоэнкодер (автокодировщик) - нейронная сеть, которая копирует входные данные на выход. Автоэнкодеры сжимают входные данные для представления их в скрытое пространство меньшей размерности (бутылочное горлышко), а затем восстанавливают из этого представления выходные данные. Цель — получить на выходном слое отклик, наиболее близкий к входному.\n\nОтличительная особенность автоэнкодеров — количество нейронов на входе и на выходе совпадает."},{"metadata":{},"cell_type":"markdown","source":"## Полезные ссылки\n\n- Об автоэнкодере:\nhttps://www.youtube.com/watch?v=H1AllrJ-_30\n\n- Лекция К. Воронцова по искусственным нейронным сетям:\nhttp://www.machinelearning.ru/wiki/images/3/38/Voron-ML-NeuralNets1-2018-slides.pdf\n\n- Презентация к лекции:\nhttp://www.machinelearning.ru/wiki/images/c/cc/Voron-ML-NeuralNets.pdf\n\n- Автоэнкодеры для поиска аномалий:\nhttps://saketsathe.net/downloads/autoencode.pdf\n\n- О слое batch normalization:\nhttps://arxiv.org/pdf/1502.03167v2.pdf"},{"metadata":{},"cell_type":"markdown","source":"### Архитектура для обучения автоэнкодера"},{"metadata":{"jupyter":{"outputs_hidden":true},"scrolled":true,"trusted":true},"cell_type":"code","source":"# Функция для обучения конкретной архитектуры модели\ndef arch(param, data):\n    \"\"\"\n    Обучение конкретной архитектуры\n\n    Parameters\n    ----------\n    param : list\n    \n    data : np.array\n    \"\"\"\n    Random(0)\n    input_dots = Input((8,))\n\n    x = Dense(param[0])(input_dots)\n    x = BatchNormalization()(x)\n    x = Activation('elu')(x)\n\n    x = Dense(param[1])(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    bottleneck = Dense(param[2], activation='linear')(x)\n\n    x = Dense(param[1])(bottleneck)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Dense(param[0])(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    out = Dense(8, activation='linear')(x)\n\n    model = Model(input_dots, out)\n    model.compile(optimizer=Adam(param[3]), loss='mae', metrics=[\"mse\"])\n    \n#     early_stopping = EarlyStopping(patience=3, verbose=0)\n    model.fit(data, data,\n                validation_split=0.2,\n                epochs=10,\n                batch_size=param[4],\n                verbose=0,\n                shuffle=True,\n#                 callbacks=[early_stopping]\n               )\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Обучим случайную модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = arch(param=(6, 5, 4, 0.0001, 30), data=train_sc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(val_sc.shape[1]):\n    plt.figure(figsize=(12,3))\n    plt.plot(StSc.inverse_transform(val_sc)[:, i])\n    plt.plot(StSc.inverse_transform(model.predict(val_sc))[:, i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Средняя абсолютная ошибка:\n\n$\\text{mae} = \\frac{1}{N} \\sum^{N}_{i=1}|x_i - \\hat{x}_i|$,  \nгде $N$ - общее число значений, $x_i$ - правдивое значение в момент времени $i$, $\\hat{x}_i$ - предсказанное значение в момент времени $i$."},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(val_sc, model.predict(val_sc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Параметры, которые будем подбирать"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выбор сетки параметров для обучения и тестирования\nn1=[6, 5]\nn2=[4, 3]\nn3=[2, 1]\nlr=[0.05, 0.01]\nbatch_size=[32, 64]\n\nparameters = product(n1, n2, n3, lr, batch_size)\nparameters_list = list(parameters)\nprint(f'Total number of parameter combinations: {len(parameters_list)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Таблица с сеткой параметров\npd.DataFrame(parameters_list, columns=['neurons 1st layer',\n                                      'neurons 2nd layer',\n                                      'neurons 3rd layer',\n                                      'learning rate',\n                                      'batch size']).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Результаты подбора модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"# \"Перебор моделей\"\nerrors = []\nfor params in tqdm(parameters_list):\n    \n    model = arch(params, train_sc)\n    train_pred = model.predict(train_sc, batch_size=params[4])\n    val_pred = model.predict(val_sc, batch_size=params[4])\n    \n    train_error = mean_absolute_error(train_sc, train_pred)\n    val_error = mean_absolute_error(val_sc, val_pred)\n    \n    errors.append(list(params)+[train_error, val_error])\n\n# Сортировка ошибки\ndf_errors = pd.DataFrame(errors,\n                         columns=['neurons 1st layer', \n                                  'neurons 2nd layer', \n                                  'neurons 3rd layer', \n                                  'learning rate', \n                                  'batch size', \n                                  'mae train', \n                                  'mae val'])\ndf_errors.sort_values('mae val').head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Обучение лучшей модели на тренировочной и валидационной выборке"},{"metadata":{"jupyter":{"outputs_hidden":true},"scrolled":true,"trusted":true},"cell_type":"code","source":"best_params = parameters_list[df_errors.sort_values('mae val').index[0]]\n\nmodel = arch(best_params, train_sc) # train+val стоит использовать, если распределения выборок совпадают\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"# #прогноз и ошибка лучшей модели на обучающей выборке\n# train_pred = model.predict(train_df_sc, batch_size=30)\n# print('train mae: ', mean_absolute_error(train_df_sc,train_pred))\n\n# #прогноз и ошибка лучшей модели на тестовой выборке\n# test_pred = model.predict(test_df_sc, batch_size=30)\n# print('test mae: ', mean_absolute_error(test_df_sc,test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(val_sc.shape[1]):\n    plt.figure(figsize=(12,3))\n    plt.plot(StSc.inverse_transform(val_sc)[:, i])\n    plt.plot(StSc.inverse_transform(model.predict(val_sc))[:, i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Индекс технического состояния (ИТС)"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"test_residuals = data_sc - model.predict(data_sc)\n\npd.DataFrame(test_residuals, columns=data.columns, index = data.index).plot(figsize=(12,6))\nplt.xlabel('Время')\nplt.ylabel('Значение разностей параметров')\nplt.title('График разностей сигналов')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"train_residuals = train_sc - model.predict(train_sc)\nval_residuals = val_sc - model.predict(val_sc)\n\nUCL = pd.DataFrame(val_residuals).abs().sum(axis=1).quantile(0.99)","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"# ИТС\npd.DataFrame(test_residuals, index=data.index).abs().sum(axis=1).plot(marker='o', \n                                                                      markersize=2, \n                                                                      alpha=0.2, \n                                                                      figsize=(12,6), \n                                                                      label='ИТС')\n# ИТС с медианным фильтром с окном в 3 точки\npd.DataFrame(test_residuals, index=data.index).abs().sum(axis=1).rolling(3).median().plot(marker='o', \n                                                                                          markersize=2, \n                                                                                          alpha=0.7, \n                                                                                          figsize=(12,6),\n                                                                                          label='Сглаженный ИТС')\n\nplt.axvspan(data.index[0], \n            '2019-07-08 18:25', \n            color='green', \n            alpha=0.1, \n            label='Обучающая выборка')\nplt.axvspan('2019-07-08 18:25', \n            '2019-07-08 18:35', \n            color='yellow', \n            alpha=0.1, \n            label='Валидационная выборка')\nplt.axvspan('2019-07-08 18:35', \n            data.index[-1], \n            color='red', \n            alpha=0.1, \n            label='Тестовая выборка')\n\nplt.axhline(UCL, color='r', label='Верхняя допустимая граница')\nplt.ylim([0, 4*UCL])\nplt.xlabel('Время')\nplt.ylabel('Значение ИТС')\nplt.legend(bbox_to_anchor =(0.8, -0.2), ncol = 3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,6))\nax.axvspan(\n    data.index[data.index=='2019-07-08 18:39:22'][0],\n    data.index[data.index=='2019-07-08 18:42:32'][0],\n    alpha=0.2, \n    color='red')\nax.axvspan(\n    data.index[data.index=='2019-07-08 18:44:36'][0],\n    data.index[data.index=='2019-07-08 18:46:51'][0],\n    alpha=0.2, \n    color='red')\nax.axvspan(\n    data.index[data.index=='2019-07-08 19:06:57'][0],\n    data.index[data.index=='2019-07-08 19:11:31'][0],\n    alpha=0.2, \n    color='red')\nax.axvspan(\n    data.index[data.index=='2019-07-08 19:14:40'][0],\n    data.index[data.index=='2019-07-08 19:21:16'][0],\n    alpha=0.2, \n    color='red', label='Аномальные интервалы')\nax.plot(data.index, pd.DataFrame(test_residuals).abs().sum(axis=1), marker='o', markersize=2, alpha=0.2, label='ИТС')\nax.plot(data.index, pd.DataFrame(test_residuals).abs().sum(axis=1).rolling(3).median(), marker='o', markersize=2, alpha=0.7, label='Сглаженный ИТС')\nax.axhline(UCL, color='r', label='Верхняя допустимая граница')\nax.set_ylim([0, 4*UCL])\nax.set_xlabel('Время')\nax.set_ylabel('Значение ИТС')\nplt.legend(bbox_to_anchor =(0.8, -0.1), ncol = 3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Среднее время запаздывания обнаружения\n\n$\\text{ADD} = \\frac{1}{|Y|}\\sum_{y \\in Y} ( \\tau_y - \\theta_y )$,\n\nгде $|Y|$ - суммарное количество точек изменения состояния,  \n$\\tau_y$ - время обнаружения  \n$\\theta_y$ - время реального изменения состояния"},{"metadata":{},"cell_type":"markdown","source":"### Вклад компонент в моменты аномалий (важность признаков)"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"def feature_importance(residuals, analysis_type=\"collective\", date_from=None, date_till=None, weigh=True):\n    \"\"\"\n    Оценка вклада компонент в каждый момент времени/на интервале\n\n    Parameters\n    ----------\n    residuals : pandas.DataFrame()\n        Данные о разностях (невязках) модели между предсказанным и реальным значениями в формате DataFrame,\n        где индексы - время, столбцы - названия признаков.\n\n    analysis_type : str, \"single\"/\"collective\", \"single\" by default\n        Поточечный: для каждого момента времени оценить вклад компонент\n        интервальный: для интервала оценить вклад компонент, результат в каждым момент времени нормируется\n\n    date_from : str в формате 'yyyy-mm-dd HH:MM:SS', None by default\n        Дата и время, начиная с которого оценить вклад\n\n    date_till : str в формате 'yyyy-mm-dd HH:MM:SS', None by default\n        Дата и время, заканчивая которым оценить вклад\n\n    weigh : boolean, True by default\n        Взвешивать ли вклад в каждый момент времени на значение отклонения в данный момент времени.\n        Только для analysis_type == \"collective\".\n\n    Returns\n    -------\n    data : pandas.DataFrame().\n        На выходе получаем DataFrame, где приведены результаты (вклад) либо для каждого момента времени,\n        либо суммарный результат на интервале в ПРОЦЕНТАХ.\n    \"\"\"\n    if date_from is None:\n        start = 0\n    if date_till is None:\n        end = -1\n    data = residuals[date_from:date_till].abs().copy()\n\n    if (analysis_type == \"collective\") & (weigh == False):\n        data = data.div(data.sum(axis=1), axis=0) * 100\n        return pd.DataFrame(data.mean(), columns=['Важность признаков, %']).T\n    elif (analysis_type == \"collective\") & (weigh == True):\n        data = data.mean().div(data.mean().sum(), axis=0) * 100\n        return pd.DataFrame(data, columns=['Важность признаков, %']).T\n    elif analysis_type == \"single\":\n        return data.div(data.sum(axis=1), axis=0) * 100","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"for dates in [['2019-07-08 18:39:22','2019-07-08 18:42:32'],\n              ['2019-07-08 18:44:36','2019-07-08 18:46:51'],\n              ['2019-07-08 19:06:57','2019-07-08 19:11:31'],\n              ['2019-07-08 19:14:40','2019-07-08 19:21:16']]:\n    print(f'Инцидент с {dates[0]} по {dates[1]}')\n    display(feature_importance(pd.DataFrame(test_residuals, index=data.index, columns=data.columns), date_from=dates[0], date_till=dates[1]))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Спасибо за внимание"},{"metadata":{},"cell_type":"markdown","source":"## Задания\n\n### Вариант 1\nУлучшить качество модели (получить более низкую среднюю абсолютную ошибку на валидационной выборке).\n\n### Вариант 2\nРеализовать и посчитать метрику ADD для обнаруженных аномалий.\n\n\n<!-- Решить задачу для других данных - Tennessee Eastman Process (TEP) -->"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}