{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 4.5 Creating features and data exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In Section 4.2 we created a feature set from the customer and contract files, and we also created our churn label.   Now we will load this file and explore variables that may be potential features, such as some demographic, payment methods and basic contract details. "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/applied-ml-microcourse-telco-churn'\ndata = pd.read_csv('{}/customer_contract_churn.csv'.format(path))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inital Exploration\n\nLet us first have a look at the data, and explore some of the variables.  We will start by counting the values of key categorical variables.  It can be handy to use loops to iteratively run a group by and count over each variable.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PaperlessBilling', 'PaymentMethod', 'Contract']\nfor column in columns:\n    display(data.groupby(column)['customerID'].count().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data looks to be very clean with no missing values and the number of unique values is quite low.  The only numeric variable of interest is the MonthlyCharges column, so lets have a look at that.  The pandas function describe() will calculate several descriptive statistics over our data, giving us the mean, standard deviation, min and max, and the median (50%) and interquartile range (25%, 75%).  These values show that this variable is bound between 18.25 and 118.75, with a mean of 64.76, so does not seem to have any outliers or missing values.  \n\nIt is also good practice with numeric variables in particular to plot the distribution.  We can use this hist() function from matplotlib.pyplot.  In this case, we see two clear peaks in the data: one large peak at MonthlyCharges of around 10 or less, and another at value of 80 or so.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data['MonthlyCharges'].describe().to_frame())\n\nimport matplotlib.pyplot as plt\nplot = plt.hist(data['MonthlyCharges'], bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create some additional features from this data."},{"metadata":{},"cell_type":"markdown","source":"### Tenure\n\nWe know the start date of each customer, but we cannot use dates as features in machine learning models since they are not numeric without specific transformations.  One way we can use this information is to calculate the tenure of the customer, which is the time that has passed since their contract started.  However, you need to be careful here since the end date will be different depending on the churn class.  If the customer has churned, we want to predict their churn event so the tenure should be at or before their churn date.  For simplicity, we will just set it to be the churn date.  For customers who are currently active, we set the end date to be the date we run this analysis.  In this case, it is the 1st of January 2020.\n\nDo this in python, we need to first insert the current date into our EndDate column, and make sure the date columns are formatted as pandas dates."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['EndDate'].isna(), 'EndDate'] = '2020-01-01'\ndata['EndDate'] = pd.to_datetime(data['EndDate'])\ndata['StartDate'] = pd.to_datetime(data['StartDate'])\ndata['Tenure'] = (data['EndDate'] - data['StartDate']) / np.timedelta64(1, 'M')\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Services data\n\nNow we will introduce some further data.  Often there are multiple services that can be bundled with a contract.  After some investigation, we find that there is another file which contains the list of services for each contract.  We will load this file and have a look."},{"metadata":{"trusted":true},"cell_type":"code","source":"services = pd.read_csv('{}/services.csv'.format(path))\ndisplay(services.shape)\nservices.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This file looks to have a deep structure since it has 63,387 rows, likely one row per contractID and service.  We should explore the count of contractIDs for each service value and service"},{"metadata":{"trusted":true},"cell_type":"code","source":"services.groupby(['Service', 'ServiceValue'])['contractID'].count().to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To turn this data into features, we will have to group the data to the contractID level (i.e. one row per contract), and convert each value to a column.   We can do this using the pandas pivot() function, then merge the results into our growing feature set."},{"metadata":{"trusted":true},"cell_type":"code","source":"services_pivot = services.pivot(index='contractID', columns='Service', values='ServiceValue').reset_index()\ndata = data.merge(services_pivot, on='contractID')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Charges\n\nWe have also come across some data related to historic charges for each contract. This data set looks to be recorded per month, without the day being specified (all the days given are the first). Let's load this data and have a look."},{"metadata":{"trusted":true},"cell_type":"code","source":"charges = pd.read_csv('{}/charges.csv'.format(path))\ncharges.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets also plot the charge variable.  Compare this plot to the earlier one for the MonthlyCharges variable.  You will notice that the values are slightly higher here.  E.g. the second peak in the distribution is at around 100 or so, previously it was around 80.  This indicates that customers may be charged additional amounts each month from their contracted rates.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = plt.hist(charges['charge'], bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transactional data sets can often contain interesting patterns. For instance, a customer may get a large and unexpected bill one month for additional charges. This may prompt a churn event.  For more complex features, we could look at the variation in the charge amount over time.  To keep things simple for now, we will just calculate the average charge paid by the customer per month, and join this feature to our growing feature set."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_charges = charges.groupby('contractID')['charge'].mean().to_frame().reset_index()\ntotal_charges.rename(columns={'charge': 'MeanMonthlyCharge'}, inplace=True)\ndata = data.merge(total_charges, on='contractID')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Phone data usage\n\nGiven that most of the customers have phone services, one potentially useful data source would be their phone service data usage.   We have managed to source a data set containing the total phone service data usage for each contract per month. "},{"metadata":{"trusted":true},"cell_type":"code","source":"usage = pd.read_csv('{}/phone_usage.csv'.format(path))\nusage.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As with the charges data, there are many ways to create features from this monthly usage data.  For now, we will just calculate the mean data usage used by the customer, and join this feature to our feature set."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_usage = usage.groupby('contractID')['MonthlyUsage'].mean().to_frame().reset_index()\ntotal_usage.rename(columns={'MonthlyUsage': 'MeanMonthlyUsage'}, inplace=True)\ndata = data.merge(total_usage, on='contractID')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have now created a good set of features for our task.  You can also use the info() method on pandas dataframes to see a summary of all the columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now remove the columns that we no longer need.  We have saved the data set to a file called 'features.csv'"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['contractID', 'StartDate', 'EndDate'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}