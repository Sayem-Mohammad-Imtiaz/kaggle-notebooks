{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory Data Analysis (EDA)**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/svm-classification/UniversalBank.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop columns which are not necessary\ndata.drop([\"ID\",\"ZIP Code\"],axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 5000 rows and 12 columns in the data set now. 14 columns were reduced to 12 as columns \"ID\" and \"ZIP Code\" were removed as they were unnecessary for Credit Card approval."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no missing value in the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe() # Summary Stats of the Data Set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Mean, Standard Deviation and other statistics of each feature are displayed.\nIt can be observed that the minimum value of the Experience feature set is -3 which may be incorrect as Experience can't be expressed as a negative value. Hence, all negative experience values need to be changed to 0 (which means no experience)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Experience'] < 0] = 0\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA VISUALIZATION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the Heatmap of the Dataset\nplt.rcParams['figure.figsize'] = (15, 15)\nplt.style.use('ggplot')\nsns.heatmap(data.corr() ,annot = True)\nplt.title('Heatmap', fontsize = 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above heatmap, it can be seen that 'Age' and 'Experience' have very high correlation between them. The correlation between Income and CCAvg is also quite high.\nFor CreditCard, features 'Age', 'Experience','Family', 'CD Amount' are useful as they are more correlated compared to other features."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['Experience'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***MODELLING***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,mean_squared_error,accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# Split the data into X and y\nX = data.iloc[:,:-1]\ny = data[\"CreditCard\"]\n\n# Split the data into trainx, testx, trainy, testy \ntrainx, testx, trainy, testy = train_test_split(X, y, test_size=0.20)\n\n## Print the shape of X_train, X_test, y_train, y_test\nprint(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nX = trainx\ny = trainy\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score \nmodel = LogisticRegression()\nmodel.fit(X , y)\npredicted_classes = model.predict(X)\naccuracy = accuracy_score(y,predicted_classes)\nparameters = model.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy)\nprint(parameters)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(testx , testy)\npredicted_classes_test = model.predict(testx)\naccuracy = accuracy_score(testy,predicted_classes_test)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nNB = GaussianNB()\n\nNB.fit(X , y)\n\nNB_train_pred = NB.predict(X)\nprint(accuracy_score(y,NB_train_pred))\n\nNB_test_pred = NB.predict(testx)\nprint(accuracy_score(testy,NB_test_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}