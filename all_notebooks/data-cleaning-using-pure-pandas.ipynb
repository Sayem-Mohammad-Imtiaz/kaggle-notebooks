{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-25T16:47:12.492195Z","iopub.execute_input":"2021-07-25T16:47:12.492604Z","iopub.status.idle":"2021-07-25T16:47:12.502737Z","shell.execute_reply.started":"2021-07-25T16:47:12.49258Z","shell.execute_reply":"2021-07-25T16:47:12.501874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> Import the libraries </center>","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.504673Z","iopub.execute_input":"2021-07-25T16:47:12.504987Z","iopub.status.idle":"2021-07-25T16:47:12.512598Z","shell.execute_reply.started":"2021-07-25T16:47:12.504947Z","shell.execute_reply":"2021-07-25T16:47:12.511416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/-datacleaningforbeginnerusingpandas/Data-cleaning-for-beginners-using-pandas.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.514498Z","iopub.execute_input":"2021-07-25T16:47:12.514851Z","iopub.status.idle":"2021-07-25T16:47:12.52974Z","shell.execute_reply.started":"2021-07-25T16:47:12.514827Z","shell.execute_reply":"2021-07-25T16:47:12.528743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(6)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.530915Z","iopub.execute_input":"2021-07-25T16:47:12.531199Z","iopub.status.idle":"2021-07-25T16:47:12.544147Z","shell.execute_reply.started":"2021-07-25T16:47:12.531169Z","shell.execute_reply":"2021-07-25T16:47:12.543633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# <center> Let's begin our process! using pandas  </center>","metadata":{}},{"cell_type":"code","source":"################# Check the null values ################\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.545039Z","iopub.execute_input":"2021-07-25T16:47:12.545241Z","iopub.status.idle":"2021-07-25T16:47:12.561513Z","shell.execute_reply.started":"2021-07-25T16:47:12.54522Z","shell.execute_reply":"2021-07-25T16:47:12.560869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################ We can also plot using heat map ############\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,6))\n\nsns.heatmap(df.isnull(),cbar=False,cmap='Set1',yticklabels=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.57219Z","iopub.execute_input":"2021-07-25T16:47:12.572415Z","iopub.status.idle":"2021-07-25T16:47:12.670296Z","shell.execute_reply.started":"2021-07-25T16:47:12.572392Z","shell.execute_reply":"2021-07-25T16:47:12.669674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## fillna() method [click-here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)","metadata":{}},{"cell_type":"code","source":"###################### First check the age column ################################\n\ndf['Age'] = df['Age'].fillna(df['Age'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.671489Z","iopub.execute_input":"2021-07-25T16:47:12.671882Z","iopub.status.idle":"2021-07-25T16:47:12.675922Z","shell.execute_reply.started":"2021-07-25T16:47:12.671852Z","shell.execute_reply":"2021-07-25T16:47:12.675222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## lambda function/method [click-here](https://www.w3schools.com/python/python_lambda.asp)   \n## apply method [click-here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)\n## replace method [click-here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)","metadata":{}},{"cell_type":"code","source":"################ Now clean the Salary columns little bit tricky ! ############################\n\n################# check the first loc of the salary how it's look like #########################\ndf['Salary'].iloc[0]\n\n##################### how use replace method remove the unnecessary char ##########################\n\ndf['Salary'] = df['Salary'].apply(lambda x:x.replace(\"$\",''))\ndf['Salary'] = df['Salary'].apply(lambda x:x.replace(\"k\",''))\n\n############ Now use split method to split this into two values #############\n\n####### use custom function and create what ever u want ðŸ’¥ ##############\n\n\ndef average_of_this_two(args):\n    try :\n        return float(args)\n    except:\n        values = args.split('-')\n        \n        if len(values) == 2:\n            \n            return float(int(values[0]) + int(values[1]) ) /2\n        \n\n        \n        \ndf['Salary'] = df[\"Salary\"].apply(average_of_this_two)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.677785Z","iopub.execute_input":"2021-07-25T16:47:12.678315Z","iopub.status.idle":"2021-07-25T16:47:12.6965Z","shell.execute_reply.started":"2021-07-25T16:47:12.678284Z","shell.execute_reply":"2021-07-25T16:47:12.695944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n################### Now check the Rating columns #########################\ndf['Rating'].isnull().sum()\n######## Here we can 1 null values and -1 values like outliers ############\n###### Fill those values using np.nan using replace method ###########\n\ndf['Rating'] = df[\"Rating\"].replace(-1,np.nan)\n\n#### Now replace the those nan values using mean() method ###\n\ndf['Rating'] = df[\"Rating\"].fillna(df['Rating'].mean())\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.697569Z","iopub.execute_input":"2021-07-25T16:47:12.698003Z","iopub.status.idle":"2021-07-25T16:47:12.716473Z","shell.execute_reply.started":"2021-07-25T16:47:12.697953Z","shell.execute_reply":"2021-07-25T16:47:12.715895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ Now check the Location column ########################\n\ndf['Location'] = df[\"Location\"].apply(lambda x:x.split(',')[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.743631Z","iopub.execute_input":"2021-07-25T16:47:12.743874Z","iopub.status.idle":"2021-07-25T16:47:12.748302Z","shell.execute_reply.started":"2021-07-25T16:47:12.743852Z","shell.execute_reply":"2021-07-25T16:47:12.7472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################ Now remove the outliers(-1) values in established column #####################\n\n######## Step one : --->> \n\ndf[\"Established\"] = df[\"Established\"].replace(-1,np.nan)\n\n\n######## Setp two ----->>\n\ndf[\"Established\"].dropna()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.749554Z","iopub.execute_input":"2021-07-25T16:47:12.749941Z","iopub.status.idle":"2021-07-25T16:47:12.765604Z","shell.execute_reply.started":"2021-07-25T16:47:12.749909Z","shell.execute_reply":"2021-07-25T16:47:12.764845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####### let's check the Final column i.e Easy apply for the application ###########\n\n\n\ndf['Easy Apply']  =  df[\"Easy Apply\"].replace(\"-1\",\"FALSE\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.767465Z","iopub.execute_input":"2021-07-25T16:47:12.767815Z","iopub.status.idle":"2021-07-25T16:47:12.780117Z","shell.execute_reply.started":"2021-07-25T16:47:12.767778Z","shell.execute_reply":"2021-07-25T16:47:12.779653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:47:12.780874Z","iopub.execute_input":"2021-07-25T16:47:12.781094Z","iopub.status.idle":"2021-07-25T16:47:12.801132Z","shell.execute_reply.started":"2021-07-25T16:47:12.781071Z","shell.execute_reply":"2021-07-25T16:47:12.800374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Any other suggestion are accepted ðŸ—¨ðŸ’¬ðŸ’¬ðŸ’¬ ########### \n## I hope this data cleaning process is very useful to you !! #########\n## Have great day a head ðŸ’¥ All the best âœ…  \n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}