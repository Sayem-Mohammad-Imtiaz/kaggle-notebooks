{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Data manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n\n# Data Visualization\nimport matplotlib.pyplot as plt \nfrom mpl_toolkits import mplot3d \nimport matplotlib.ticker as mticker\n\n# Data Classification\nfrom sklearn.naive_bayes import MultinomialNB \nfrom sklearn.model_selection import train_test_split  \nfrom sklearn.preprocessing import StandardScaler, Normalizer\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"execution":{"iopub.status.busy":"2021-07-22T19:38:28.256701Z","iopub.execute_input":"2021-07-22T19:38:28.257047Z","iopub.status.idle":"2021-07-22T19:38:28.263083Z","shell.execute_reply.started":"2021-07-22T19:38:28.25701Z","shell.execute_reply":"2021-07-22T19:38:28.261943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ---- Getting a grasp on the data ----","metadata":{"editable":false}},{"cell_type":"code","source":"# Loading the data \ndf = pd.read_csv('../input/clothessizeprediction/final_test.csv')\n\n# Cleaning data \ndf.dropna(inplace=True)\nprint(df.isna().sum())\n\n# Removing age outliers\ndf = df[df['age'] > 9]\ndf = df[df['age'] < 90]\n\n# Summary of the data\nprint(df.describe())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"execution":{"iopub.status.busy":"2021-07-22T19:38:32.487825Z","iopub.execute_input":"2021-07-22T19:38:32.488388Z","iopub.status.idle":"2021-07-22T19:38:32.716897Z","shell.execute_reply.started":"2021-07-22T19:38:32.488352Z","shell.execute_reply":"2021-07-22T19:38:32.715738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This will be the base for which the rest of the analysis is done. There is a couple of thing to notice right off the bat:\n- The data is skewed right\n- We will need to need to handle outliers","metadata":{"editable":false}},{"cell_type":"code","source":"# Overview of data\nsns.pairplot(data=df, hue='size', height=7)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-22T19:24:37.282601Z","iopub.execute_input":"2021-07-22T19:24:37.282996Z","iopub.status.idle":"2021-07-22T19:25:49.616686Z","shell.execute_reply.started":"2021-07-22T19:24:37.282955Z","shell.execute_reply":"2021-07-22T19:25:49.615539Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3-D Visualization","metadata":{"editable":false}},{"cell_type":"code","source":"# getting the unique sizes present in the dataset and turning the string labels into int labels \nSizeChart = [];\nfor label in df['size']:\n    if label == 'XXS':\n        SizeChart.append(1)\n    if label == 'S':\n        SizeChart.append(2)\n    if label == 'M':\n        SizeChart.append(3)\n    if label == 'L':\n        SizeChart.append(4)\n    if label == 'XL':\n        SizeChart.append(5)\n    if label == \"XXL\":\n        SizeChart.append(6)\n    if label == \"XXXL\":\n        SizeChart.append(7)\n        \ndf['SizeLabels'] = SizeChart\nSizeTicks = ['XXS','S', 'M', 'L', 'XL', 'XXL', 'XXXL']\n\n\n# Declaring a plot\nfig = plt.figure(figsize=(8,10))\nax = fig.add_subplot(projection='3d')\n\n# 3d Scatter plot of age, height, weight\nax.scatter(xs=df['SizeLabels'], ys=df['weight'], zs=df['age'], c=df['height'], s=10)\nax.set_facecolor('white')\nax.set_zlabel(\"Age\")\nax.set_ylabel(\"Weight\")\nax.set_xlabel('Size')\nax.set_title('Size Distrubtion')\nax.view_init(15, 300)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:25:49.618454Z","iopub.execute_input":"2021-07-22T19:25:49.618784Z","iopub.status.idle":"2021-07-22T19:25:53.68455Z","shell.execute_reply.started":"2021-07-22T19:25:49.618751Z","shell.execute_reply":"2021-07-22T19:25:53.683413Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Height was used as the hue for this graph!\n\n**Key take aways for me**\n- Weight seems to have the largest effect on size difference\n- Age has little effect on size in most cases\n- height and weight seem to be strongly correlated","metadata":{"editable":false}},{"cell_type":"code","source":"# dropping the size column with strings for ease of Visualizarion\nplt_df = df.drop('size',axis=1)\nplt_colnames = ['Weight (kg)', 'Age (Years)','Height (cm)','Size Labels']\nplt_df.columns = plt_colnames\n\n\n# Plot of all 4 meterics to understand the data\nfig, ax = plt.subplots(2,2, figsize=(15,18))\n\nit = 0\n\nfor x in range(2):\n    for y in range(2):\n        # Defaulting the bin value to 20\n        num_bin = 40\n        \n        # Setting up the iteration loop so that it is always +1\n        colname = plt_colnames[it]\n        \n        # grabbing the min and max values\n        min_val = plt_df[colname].min()\n        max_val = plt_df[colname].max()\n        val_width = max_val - min_val\n        \n        # Changing the number of bins for the size plot\n        if it == 3:\n        \n            sns.countplot(x=colname,\n                          data=plt_df,\n                          ax = ax[x,y])\n            ax[x,y].set(title=colname)\n            pass    \n                          \n        # setting the bin width to the number of bins present in the data\n        bin_width = val_width/num_bin\n        \n    \n        # plotting the graph\n        if it < 3:\n            if it  == 2:\n                num_bin = 10\n            sns.histplot(plt_df[colname],\n                         bins = num_bin,\n                         binrange=(min_val, max_val),\n                         ax = ax[x,y])\n            \n            ax[x,y].set(title=colname)\n        \n        # counter\n        it+=1","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:25:53.686496Z","iopub.execute_input":"2021-07-22T19:25:53.686906Z","iopub.status.idle":"2021-07-22T19:25:54.925536Z","shell.execute_reply.started":"2021-07-22T19:25:53.686864Z","shell.execute_reply":"2021-07-22T19:25:54.92444Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Key take aways for me**\n- Shows the skewness of the data pretty well, strong right skew on age and weight\n- Size \"6\" or XXL has a extremely low repesentation in this dataset and can be removed (though you can keep it in!)\n- This shows a justification for some pre-processing in order to have a more repersentive model","metadata":{"editable":false}},{"cell_type":"markdown","source":"# --- Data Prep aka the fun stuff! ---","metadata":{"editable":false}},{"cell_type":"code","source":"# Prepping Dataframe\npre_df = df.drop(\"size\", axis=1)\n# Looking at skew measurement\nfor columns in pre_df:\n    print( \"Before: \" +pre_df[columns].skew().astype(str)) ","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:25:54.926932Z","iopub.execute_input":"2021-07-22T19:25:54.927268Z","iopub.status.idle":"2021-07-22T19:25:54.941931Z","shell.execute_reply.started":"2021-07-22T19:25:54.927239Z","shell.execute_reply":"2021-07-22T19:25:54.940868Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A strong measurement of skew is noted to be > 1 || < -1 \n\nTo address this I go for a **log transform** which is the a strong corrector of right skew\n\n[See here for more information on transforms](http://towardsdatascience.com/top-3-methods-for-handling-skewed-data-1334e0debf45)\n","metadata":{"editable":false}},{"cell_type":"code","source":"# addressing this through log transfrom\nfor columns in pre_df:\n    # only applying the transform to the first two columns\n    if columns == \"SizeLabels\" or columns == \"height\":\n        pass\n    else:\n        pre_df[columns] = np.log(pre_df[columns])\n        print( \"After: \"+pre_df[columns].skew().astype(str))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:25:54.943224Z","iopub.execute_input":"2021-07-22T19:25:54.943573Z","iopub.status.idle":"2021-07-22T19:25:54.961279Z","shell.execute_reply.started":"2021-07-22T19:25:54.943541Z","shell.execute_reply":"2021-07-22T19:25:54.960286Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is more managable degree of skew if we want to address outliers.\n\n**Key Take Away**\n- The less skewed your data, the more accurate outlier corrects will become","metadata":{"editable":false}},{"cell_type":"code","source":"# Addressing outliers through std method (95%)\nfor column in pre_df:\n    if column == \"SizeLabels\":\n        pass\n    else: \n        pre_df = pre_df[pre_df[column] < ( pre_df[column].mean() + (3*pre_df[column].std()))]\n        pre_df = pre_df[pre_df[column] > ( pre_df[column].mean() - 3*pre_df[column].std())]   \n        # Checking\n        print(pre_df[pre_df[column] > ( pre_df[column].mean() + 3*pre_df[column].std())])\n        print(pre_df[pre_df[column] < ( pre_df[column].mean() - 3*pre_df[column].std())])\n        \nprint(\"\\n\", pre_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:28:11.234032Z","iopub.execute_input":"2021-07-22T19:28:11.234586Z","iopub.status.idle":"2021-07-22T19:28:11.287263Z","shell.execute_reply.started":"2021-07-22T19:28:11.234536Z","shell.execute_reply":"2021-07-22T19:28:11.286459Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have reduced my dataset to only repersent 95% of the overall population so any my models accuracy on the whole data set is its score * 95% for the population as a whole!\n\n**Key take away**\n- When you reduce the size of the data set you should also reduce the accuracy score of model accordingly","metadata":{"editable":false}},{"cell_type":"code","source":"# Preping the data\nFeatures = pre_df.drop('SizeLabels', axis = 1)\n\n# seperating out the labels\nlabels = pre_df['SizeLabels']\n\n# Generating test set and training set (trainf)\ntrainingFeatures, testingFeatures, trainingLabels, testingLabels = train_test_split(Features, labels, test_size = .2, random_state=42)\n\n# now we gonna set up a scale for the values!\nscaler = StandardScaler()\n\n# Scaling the features after splitting them\ntrainingFeatures = scaler.fit_transform(trainingFeatures)\ntestingFeatures = scaler.transform(testingFeatures)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:28:16.334851Z","iopub.execute_input":"2021-07-22T19:28:16.335204Z","iopub.status.idle":"2021-07-22T19:28:16.364081Z","shell.execute_reply.started":"2021-07-22T19:28:16.335174Z","shell.execute_reply":"2021-07-22T19:28:16.363188Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Time!","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Neighboors","metadata":{"editable":false}},{"cell_type":"code","source":"# KNeighboors Classifer\nfrom sklearn.neighbors import KNeighborsClassifier \n# These are used to keep track of the best score obtained by the model\nBestN = 0\nprev = 0\naccuracy = []\n\nfor x in range(80,150,5):\n    # Declare a model\n    model = KNeighborsClassifier(n_neighbors=x, metric='manhattan', weights='uniform') \n\n    # Fit the model\n    model.fit(trainingFeatures, trainingLabels)\n\n    # Trying to predict the model\n    score = model.score(testingFeatures,testingLabels) * 100\n    # Iteritive testing for nieghbors score\n    if score > prev:\n        prev = score\n        BestN = x\n    # Creating meterics to identify optimal neighbors\n    accuracy.append(score)\n\n# For model comparision\nclusterScore = (np.mean(accuracy))\n\n# Printing best score\nprint(BestN, \" is the best number of neighbors with a score of: \", prev)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:31:23.698219Z","iopub.execute_input":"2021-07-22T19:31:23.698624Z","iopub.status.idle":"2021-07-22T19:31:58.020061Z","shell.execute_reply.started":"2021-07-22T19:31:23.698588Z","shell.execute_reply":"2021-07-22T19:31:58.019146Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Graphing the preformace of difference number of clusters","metadata":{"editable":false}},{"cell_type":"code","source":"# Graphing model preformace\nfig = plt.figure(figsize=(8,10))\nax = fig.add_subplot()\nax.plot(range(80,150,5),accuracy)\nax.set_title('Model Accuracy')\nax.set_xlabel('Number of clusters')\nax.set_xticks(range(80,150,5))\nax.set_ylabel('Accuracy (%)')","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:32:07.218163Z","iopub.execute_input":"2021-07-22T19:32:07.218545Z","iopub.status.idle":"2021-07-22T19:32:07.448625Z","shell.execute_reply.started":"2021-07-22T19:32:07.218513Z","shell.execute_reply":"2021-07-22T19:32:07.44761Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Multiple Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\n# Declare Model\nmodel = LinearRegression()\n\n# Fit Model\nmodel.fit(trainingFeatures, trainingLabels)\n\n# Scoring the model --- 69%\nregressionScore = (model.score(testingFeatures,testingLabels)) * 100\n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:26:27.444137Z","iopub.execute_input":"2021-07-22T19:26:27.444604Z","iopub.status.idle":"2021-07-22T19:26:27.4746Z","shell.execute_reply.started":"2021-07-22T19:26:27.444556Z","shell.execute_reply":"2021-07-22T19:26:27.473436Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Breakdown\n\n**My conclusions**\n- When looking at the two models its clear that there just isn't enough parameters\n- Regression handles predicting better than clustering with this dataset\n- More context to the data would help us better understand how good our model preforms\n- A ~65% chance to guess the cloth size of an individual with 7 options is a huge improvement on just guessing!\n","metadata":{"editable":false}},{"cell_type":"code","source":"# Graph comparing the model effectness (95% reflection on the graph!)\nY = [clusterScore*.95, regressionScore*.95]\nX = [\"Neighbors\" , \"Regression\"]\nsns.barplot(y=Y, x=X)\nplt.show()\nprint(\"Neighbors method averaged a score of: \" + clusterScore.astype(str) + \"\\n\\n\")\nprint(\"Regression method average a score of: \" + regressionScore.astype(str))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T19:37:23.059576Z","iopub.execute_input":"2021-07-22T19:37:23.059943Z","iopub.status.idle":"2021-07-22T19:37:23.165543Z","shell.execute_reply.started":"2021-07-22T19:37:23.059904Z","shell.execute_reply":"2021-07-22T19:37:23.164546Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}