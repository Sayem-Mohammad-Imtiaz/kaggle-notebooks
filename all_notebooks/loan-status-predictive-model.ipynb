{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem Statement"},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. Develop a statistical model for predicting bad loans\n#2. Use the model to identify the most important drivers of bad loans\n#3. With these new insights, make recommendations to avoid funding bad loans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Required Packages and Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import libraries for logistic regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n#import libraries for model evaluation\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\n\n# importing libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import libraries for logistic regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n#import libraries for model evaluation\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import average_precision_score\n\n#import libraries for KNN\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#import library for ignoring warnings in the output\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#import libraries for KNN\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#import library for ignoring warnings in the output\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining working directory\n#os.chdir('C:\\\\Users\\\\pallavvi\\\\Desktop\\\\ProjMat\\\\Data Science\\\\Data_Science_Course\\\\Piyush\\\\Projects\\\\Upload_Online\\\\Loan_status_prediction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing dataset\ntarget_csv = \"../input/Loan_Training_data.csv\"\nloan_df = pd.read_csv(target_csv,sep=',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Wrangling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first five observations\nloan_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data info\nloan_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#listing all the variables/fields\nloan_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shape of the data(number of rows and number of columns)\nloan_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding how many features are categories/numerical in data set\nprint(len(loan_df._get_numeric_data().columns))                  #numerical variables\nlen(loan_df.columns)-len(loan_df._get_numeric_data().columns)    #categorical variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding How many columns have got some missing values\nprint(loan_df.isnull().any().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding How many rows have got some missing values\nprint(loan_df.isnull().any(axis=1).sum())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Finding How many column are having all missing values\nprint(loan_df.isnull().all().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding How many rows are having all missing values\nprint(loan_df.isnull().all(axis=1).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop duplicate rows- if any\nloan_df = loan_df.drop_duplicates(keep='first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping unimportant variables\n#drop_cols = ['Education']\n#loan_df = loan_df.drop(drop_cols,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding How many/what percentage of applications got approved /rejected? This is basically to check class imbalance.\n\nprint(pd.value_counts(loan_df['Loan_Status'].values, sort=False))                                #Gives count\nround(100*((pd.value_counts(loan_df['Loan_Status'].values, sort=False))/len(loan_df.index)),2)   #Gives %","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identifying if there are outliers in any feature using describe()\n#summary statistics (gives mean , median, std, min, max for continuous numerical data only)\n\nloan_df.describe()\n\n#Explanation:\n#1. if 25%,50%,75% values are far away from mean value that means there are outliers in that feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identifying if there are outliers in any feature using quantile()\nQ1 = loan_df.quantile(0.25)\nQ3 = loan_df.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)\n\nlower_limit  = Q1-1.5*IQR\nprint(lower_limit)\n\nupper_limit = Q3+1.5*IQR\nprint(upper_limit)\n\nprint(((loan_df['ApplicantIncome'] > 10171.250) | (loan_df['ApplicantIncome'] < 1498.750)).sum())      #gives count\nprint(((loan_df['CoapplicantIncome'] > 5743.125) | (loan_df['CoapplicantIncome'] < 3445.875)).sum())\nprint(((loan_df['LoanAmount'] > 270.000) | (loan_df['LoanAmount'] < 2.000)).sum())\nprint(((loan_df['Loan_Amount_Term'] > 360.000) | (loan_df['Loan_Amount_Term'] < 360.000)).sum())\nprint(((loan_df['Credit_History'] > 1) | (loan_df['Credit_History'] < 1)).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding the % of nulls in each column\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing nulls from Loan Amount, Credit History, Loan amount term \nloan_df = loan_df[~np.isnan(loan_df['LoanAmount'])]\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\nloan_df = loan_df[~np.isnan(loan_df['Credit_History'])]\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\nloan_df = loan_df[~np.isnan(loan_df['Loan_Amount_Term'])]\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\n#alternate way to remove NA's from columns\n#loan_df.dropna(subset = [\"Married\", \"Gender\",\"Self_Employed\",\"Loan_Amount_Term\",\"Dependents\",\"LoanAmount\",\"Credit_History\"] , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing nulls from self_employed, Gender, Dependents, Married(categorical variables)\nprint(loan_df['Self_Employed'].value_counts())\nloan_df.loc[pd.isnull(loan_df['Self_Employed']), ['Self_Employed']] = 'No'\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\nprint(loan_df['Gender'].value_counts())\nloan_df.loc[pd.isnull(loan_df['Gender']), ['Gender']] = 'Male'\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\nprint(loan_df['Dependents'].value_counts())\nloan_df.loc[pd.isnull(loan_df['Dependents']), ['Dependents']] = '0'\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\nprint(loan_df['Married'].value_counts())\nloan_df.loc[pd.isnull(loan_df['Married']), ['Married']] = 'Yes'\nround(100*(loan_df.isnull().sum()/len(loan_df.index)), 2)\n\n#alternate way to find the count per feature\n#loan_df.groupby([\"Dependents\"]).size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gives unique values of a feature/column\nset(loan_df['Married'])\n\n#alternate way to find the unique values\n#loan_df.Married.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the fraction of rows cost\nprint('data left(%):',(len(loan_df.index)/614)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating the combined income and inserting a new column to loan_df\nloan_df['comb_income'] = pd.DataFrame(loan_df['ApplicantIncome']+loan_df['CoapplicantIncome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping columns applicant and coapplicant income \ndrop_cols = ['ApplicantIncome','CoapplicantIncome']\nloan_df = loan_df.drop(drop_cols,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sorting with respect to a variable in descending order\nloan_df = loan_df.sort_values(by = 'comb_income',ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting the categorical target variable into dummies (0,1's)\nloan_df['Status'] = pd.get_dummies(loan_df['Loan_Status'], drop_first=True)\nloan_df.drop(['Loan_Status'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if there is a space in columnnames then replace it\nloan_df.columns = loan_df.columns.str.replace(' ','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''The functions takes column name as an argument and returns the top and bottom observation in that dataframe'''\ndef min_max_values(col):\n    \n    top = loan_df[col].idxmax()\n    top_obs = pd.DataFrame(loan_df.loc[top])\n    \n    bottom = loan_df[col].idxmin()\n    bottom_obs = pd.DataFrame(loan_df.loc[bottom])\n    \n    min_max_obs = pd.concat([top_obs, bottom_obs], axis=1)\n    \n    return min_max_obs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applicable only for numerical variable\nmin_max_values('comb_income')\nmin_max_values('LoanAmount')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of Numerical / Quantitative Variables(Univariate Analysis)"},{"metadata":{},"cell_type":"markdown","source":"# Histogram, Distplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#histogram of continuous numerical variables\nplt.hist(loan_df['comb_income'],color='Magenta')\n\n#observation:\n#1. majority of people have combined income between a range of approx.1000 to 10000\n#2. data spread is very high on right hand side\n#3. people with income 40000 to 80000 are far away from the other set of people \n#4. data on tail side can be removed for analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability Distribution Function\nsns.distplot(loan_df['comb_income'],color='green')\n\n#observation:\n#1. In histogram we get the count/actual value for every data on x axis, But here we get % instead of actual value\n#2. Area under the curve here is equal to '1'\n#3. % value always lie between '0' and '1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#histogram of continuous numerical variables\nplt.hist(loan_df['LoanAmount'],color='Magenta')\n\n#observation:\n#1. majority of people applied for loan amount between a range of approx.90 to 130\n#2. data spread is high on right hand side\n#3. people having loan_amount applied=500-700 are far away from the other set of people \n#4. data on tail side can be removed for analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability Distribution Function\nsns.distplot(loan_df['LoanAmount'],color='green')\n\n#observation:\n#1. In histogram we get the count/actual value for every data on x axis, But here we get % instead of actual value\n#2. Area under the curve here is equal to '1'\n#3. % value always lie between '0' and '1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#histogram of continuous numerical variables\nplt.hist(loan_df['Loan_Amount_Term'],color='Magenta')\n\n#observation:\n#1. the data is highly distributed \n#2. maximum people have term amount between 350 to 390 approx.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability Distribution Function\nsns.distplot(loan_df['Loan_Amount_Term'],color='green')\n\n#observation:\n#1. In histogram we get the count/actual value for every data on x axis, But here we get % instead of actual value\n#2. Area under the curve here is equal to '1'\n#3. % value always lie between '0' and '1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#histogram of continuous numerical variables\nplt.hist(loan_df['Credit_History'],color='Magenta')\n\n#observation:\n#1. can be better represented by categopry\n#2. maximum people have credit history between 0.9 to 1.0 approx.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability Distribution Function\nsns.distplot(loan_df['Credit_History'],color='green')\n\n#observation:\n#1. In histogram we get the count/actual value for every data on x axis, But here we get % instead of actual value\n#2. Area under the curve here is equal to '1'\n#3. % value always lie between '0' and '1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select all numerical variables and analyzing them\nloan_num = loan_df.select_dtypes(include=['float64','int64'])\nloan_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_num.hist(color='orange',histtype='bar',stacked=True,fill=True,figsize=(10,10))\n\n#observation:\n#1. Credit history can be better represented by making it as 'Category'\n#2. For Loan amount Term a) the data is highly distributed \n#                        b) maximum people have term amount between 350 to 390 approx.\n#3. For Loan Amount a) majority of people applied for loan amount between a range of approx.90 to 130\n#                   b) data spread is high on right hand side\n#                   c) people having loan_amount applied=500 are far away from the other set of people \n#                   d) data on tail side can be removed for analysis\n#4. For Comb Income a) majority of people have combined income between a range of approx.1000 to 10000\n#                   b) data spread is very high on right hand side\n#                   c) people with income approx.38000 are far away from the other set of people \n#                   d) data on tail side can be removed for analysis","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation, Pairplot, Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with the variable of interest\ncomb_income_corr = loan_num.corr()['comb_income'][:-1]  #[:-1] is for not taking the correlation with variable itself\ncomb_income_corr\n\n#observation:\n#1. LoanAmount is directly proportional to combined income, and other numerical variables are inversely proportional\n#2. LoanAmount has +ve relation and other two have -ve relation\n#3. loan amount has medium relation with comb_income, so as the combined income increases the loan amount will also increase\n#4. There is no relation between comb_income and (loan_amoun_term and credit history), since correlation value is < 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation plots using 'pairplots'\nfor i in range(0,len(loan_num.columns),3):\n    sns.pairplot(loan_num,y_vars=['comb_income'],\n                 x_vars=loan_num.columns[i:i+3],\n                 kind='reg',\n                 plot_kws={'line_kws':{'color':'red'}},\n                 height=3\n                )\n\n#observation:\n#1. If the dots are downward sloping then negative relation, upward sloping positive relation\n#2. comb_income and loan_amount has medium positive relationship as the variance is medium\n#3. Useful for detecting the outliers/extreme values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(loan_df, \n             hue='Status', \n             palette='husl', \n             height=3, \n             markers=[\"o\", \"s\"], \n             diag_kind=\"kde\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting significant correlation in one map ('heatmap')\ncorr = loan_num.corr()\nsns.heatmap(corr[(corr >= 0.5)], \n            cmap='viridis', \n            annot=True, \n            vmax=1.0, \n            vmin=1.0, \n            linewidths=0.1, \n            annot_kws={\"size\":8}, \n            square=True\n           )\n\n#observation:\n#1. there is no relation between the loan_amount, loan_amount term anmd credit history\n#2. squares which have no color indicates that no relationship\n#3. there is a high relation between loan amount and comb_income","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of Numerical variables(Bivariate Analysis)"},{"metadata":{},"cell_type":"markdown","source":"# Regplot, Lmplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#regression Plot\nsns.regplot(loan_df['LoanAmount'],loan_df['comb_income'],scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"blue\"})\n\n#observation:\n#1. there is strong positive relationship between loan_amount and comb_income","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regression Plot\nsns.regplot(loan_df['Loan_Amount_Term'],loan_df['comb_income'],scatter_kws={\"color\": \"green\"}, line_kws={\"color\": \"blue\"})\n\n#observation:\n#1. there is no relationship between loan_amount_term and comb_income","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regression Plot\nsns.regplot(loan_df['Credit_History'],loan_df['comb_income'],scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"blue\"})\n\n#observation:\n#1. there is no relation between credit history and com_income","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear plot\nsns.lmplot(x=\"comb_income\" , y = \"LoanAmount\" , hue = \"Status\" , markers=[\"o\", \"D\"], data = loan_df, palette='Set1')\n\n#observation:\n#1. As the comb_income increase loan amount also increases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear plot\nsns.lmplot(x=\"comb_income\" , y = \"LoanAmount\" ,hue='Status', col = \"Status\", data=loan_df)\n\n#observation:\n#1. base on status impact of comb_income on loan amount is visualized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear plot\nsns.lmplot(x=\"comb_income\" , y = \"LoanAmount\" ,row='Status', col = \"Credit_History\", data=loan_df)\n\n#observation:\n#1. condition of two variables status and credit history on comb_income affecting loan_amount\n#2. credit history plays a role in approval and rejection of loan application","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# JointPlot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#joint plot with kind=reg\nsns.jointplot(x='LoanAmount', y='comb_income', data=loan_df, kind='reg', color='yellow',joint_kws={'line_kws':{'color':'cyan'}})\n\n#Observation:\n#1. Curve on the top shows distribution of Loan Amount\n#2. Curve on the right shows distribution of comb_income\n#3. Plot shows as loan amount increases com_income requriement also increase i.e loan_amount is directly proportional to comb_income","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#joint plot with kind=scatter\nsns.jointplot(x='LoanAmount', y='comb_income', data=loan_df, kind='scatter', joint_kws={'color':'red'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Joint Plot with kind=kde\nsns.jointplot(x='LoanAmount', y='comb_income', data=loan_df, kind='kde', color='green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Joint Plot with kind=resid\nsns.jointplot(x='LoanAmount', y='comb_income', data=loan_df, kind='resid', color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of Categorical / Qualitative Variables(Univariate Analysis)"},{"metadata":{},"cell_type":"markdown","source":"# Countplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Gender').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(loan_df.Gender)\n\n#observation:\n#1. Number of male applicants are much greater than female applicants","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Married').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(data=loan_df,x= 'Married', hue='Status')\n\n#observation:\n#1. Married applicants are getting the loan approved compared to unmarried ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Education').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(data=loan_df,x= 'Education', hue='Status')\n\n#observation:\n#1. graduate applicants are getting loans approved compared to undergraduates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Dependents').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(data=loan_df,x= 'Dependents', hue='Status')\n\n#observation:\n#1. applicants with 0 dependents got the loan approved\n#2. applicants with 3+ have very less number whose loan got approved\n#3. applicants with 1 and 2 dependents are average compared to other two","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Self_Employed').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(data=loan_df,x= 'Self_Employed', hue='Status')\n\n#observation:\n#1. those who are not self employed, their loans approved as compared to who are self employed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Property_Area').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(data=loan_df,x= 'Property_Area', hue='Status')\n\n#observation:\n#1. numnber of Applicants having property area in semiurban > urban > rural\n#2. applicants having semiurban property area have loans approved","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count by category- cross tabulation  (simply gives count of each categopry)\ngender_dist = loan_df.groupby('Status').size()\ngender_dist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical variables\n#count plot\nsns.countplot(loan_df.Status)\n\n#observation:\n#1. Loan is approved for more number of applicants(almost double than rejected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Analysis (Category,Numerical)"},{"metadata":{},"cell_type":"markdown","source":"# Boxplot, Swarmplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Swarmplot\nsns.swarmplot(x='Property_Area', y ='comb_income', hue ='Status', data=loan_df, split=True)\n\n#Observation:\n#1. We have few outliers in Urban and semiurban area\n#2. Applicants whose property area is urban are more likely to get loan approved\n#3. there is no effect on comb_income for property area","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Swarmplot\nsns.swarmplot(x='Property_Area', y ='comb_income', hue ='Credit_History', data=loan_df, split=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_gender = sns.boxplot(x='Gender', y='comb_income', data=loan_df, palette='Set1', linewidth=0.8, width=0.4, whis=5)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_gender = sns.boxplot(x='Gender', y='comb_income', data=loan_df, ax=ax)\n\n#observation:\n#1. there is more variation of combined income in female category compared to male\n#2. Males having comb_income of approx. >12000 are outliers\n#3. Females having comb_income of approx. >9500 are outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gives total count, unique values of,top category,and no of records of top category\nloan_df['Gender'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_married = sns.boxplot(x='Married', y='comb_income', data=loan_df, palette='Set1', ax=ax)\n\n#observation:\n#1. there is more variation of combined income in married category compared to not married\n#2. Males having comb_income of approx. >12000 are outliers\n#3. Females having comb_income of approx. >10000 are outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_dependents = sns.boxplot(x='Dependents', y='comb_income', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_dependents = sns.boxplot(x='Dependents', y='comb_income', data=loan_df, palette='Set2', ax=ax)\n\n#observation:\n#1. there is more variation of combined income 3+ dependents\n#2. For 1 dependent, data is equally centered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_self_employed = sns.boxplot(x='Self_Employed', y='comb_income', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_self_employed = sns.boxplot(x='Self_Employed', y='comb_income', data=loan_df, palette='Set3', ax=ax)\n\n#observation:\n#1. Combined income of people who are not self_employed is higher than self_employed people\n#2. variation of combined income is high in not self_employed category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_prop_area = sns.boxplot(x='Property_Area', y='comb_income', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_prop_area = sns.boxplot(x='Property_Area', y='comb_income', data=loan_df, palette='Set2', ax=ax)\n\n#observation:\n#1. Urban property area has more variation in comb_income and has more outliers than rural/semiurban \n#2. Rural and semiurban has approximately equal variance in comb_income","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_com_inc = sns.boxplot(x='Status', y='comb_income', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_com_inc = sns.boxplot(x='Status', y='comb_income', data=loan_df, palette='Set3', ax=ax)\n\n#observation:\n#1. Variation is almost equal in combined income for approved and rejected loans\n#2. Outliers are high in comb_income for approved loans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_Loan_Amt = sns.boxplot(x='Status', y='LoanAmount', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_Loan_Amt = sns.boxplot(x='Status', y='LoanAmount', data=loan_df, palette='Set1', ax=ax)\n\n#observation:\n#1. Loan Amount varies according to status and the variation is more in rejected loans\n#2. Outliers are more in approved loans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_Loan_amt_hue = sns.boxplot(x='Status', y='LoanAmount', hue='Self_Employed', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_Loan_amt_hue = sns.boxplot(x='Status', y='LoanAmount', hue='Self_Employed', data=loan_df, palette='Set3', ax=ax)\n\n#observation:\n#1. Loan amount varies at some extent for self employed and not self employed people\n#2. Doesnt really has any effect of   self employed and not self employed on loan approval or rejection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot for categorical variables\n#box_comb_inc_hue = sns.boxplot(x='Status', y='comb_income', hue='Self_Employed', data=loan_df, palette='Set2', linewidth=1.5, width=0.8)\nfig_size = (7, 7)\nfig, ax = plt.subplots(figsize=fig_size)\nbox_comb_inc_hue = sns.boxplot(x='Status', y='comb_income', hue='Self_Employed', data=loan_df, palette='Set1', ax=ax)\n\n#observation:\n#1. comb_income varies alot of self employed and non self employed people\n#2. no such effect of  self employed and not self employed on loan status ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Barplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='comb_income', y='Status', data=loan_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='LoanAmount', y='Status', hue='Gender', data=loan_df, color='violet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='comb_income', y='Status', hue='Gender' ,  data=loan_df, color='purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='comb_income', y='Self_Employed', hue='Gender' , data=loan_df, color='yellow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='comb_income', y='Self_Employed', hue='Married' , data=loan_df, color='green')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='LoanAmount', y='Gender', hue='Married' , data=loan_df, color='brown', palette='Blues_d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='LoanAmount', y='Gender', hue='Status' , data=loan_df, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n       'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', \n       'Property_Area', 'Status']\n\nx = loan_df.drop(cols,axis=1)\ny = loan_df['Status']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=20)\n\nlogmodel = LogisticRegression()\nlogmodel.fit(x_train, y_train)\n\ny_pred = logmodel.predict(x_test)\ny_pred_prob = logmodel.predict_proba(x_test)\ny_pred1 = logmodel.predict(x_train)\n\nprint(logmodel.intercept_ )\nprint(logmodel.coef_ )\n\nprint(classification_report(y_test , y_pred))\nprint(classification_report(y_train , y_pred1))\n\nprint(confusion_matrix(y_test,y_pred))\nprint(confusion_matrix(y_train,y_pred1))\n\nprint(\"test accuracy:\",accuracy_score(y_test,y_pred )*100)\nprint(\"train accuracy:\",accuracy_score(y_train,y_pred1)*100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#new_loan= loan_df\n#new_loan[\"Prediction\"] = logmodel.predict(x)\n\n#new_loan.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#new_loan.to_csv('out.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking if the test data before and after data cleansing is consistent\ny_test.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking if the train data before and after data cleansing is consistent\ny_train.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df.Status.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# probability cut off "},{"metadata":{"trusted":true},"cell_type":"code","source":"Sensitivity = []\nSpecificity = []\nAccuracy = []\nprob_range = np.linspace(0.6,0.8,50)\nfor pc in prob_range:\n   y_pred_res = [1 if np.any(prob>=pc) else 0 for prob in y_pred_prob ]\n   conf_mat = confusion_matrix(y_test,y_pred_res)\n   Accuracy.append(accuracy_score(y_test,y_pred_res))\n   Sensitivity.append(conf_mat[1,1]/(conf_mat[1,1] + conf_mat[1,0]))\n   Specificity.append(conf_mat[0,0]/(conf_mat[0,0] + conf_mat[0,1]))\n\nplt.plot(prob_range,Accuracy)\nplt.plot(prob_range,Sensitivity)\nplt.plot(prob_range,Specificity)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the probability of being y=1 >= 0.78\ny_pred = (logmodel.predict_proba(x_test)[:,1] >= 0.78).astype(bool)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ROC curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n       'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', \n       'Property_Area', 'Status']\n\nx = loan_df.drop(cols,axis=1)\ny = loan_df['Status']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=20)\n\n#instantiate the classifier\nlogmodel = LogisticRegression()\n\n#fit a model\nlogmodel.fit(x_train, y_train)\n\n#predict probabilities and keep probabilities for the positive outcome only\nprobs = logmodel.predict_proba(x_test)[:,1]\n\nauc = roc_auc_score(y_test, probs)\nprint('AUC: %.3f' % auc)\n\n#calculating the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test, probs)\n\n#plot NO skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n\n# show the plot\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Precision Recall curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n       'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', \n       'Property_Area', 'Status']\n\nx = loan_df.drop(cols,axis=1)\ny = loan_df['Status']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=20)\n\n#instantiate the classifier\nlogmodel = LogisticRegression()\n\n#fit a model\nlogmodel.fit(x_train, y_train)\n\n#predict probabilities and keep probabilities for the positive outcome only\nprobs = logmodel.predict_proba(x_test)[:,1]\n\n#predict class values\ny_pred = logmodel.predict(x_test)\n\n# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, probs)\n\n# calculate F1 score\nf1 = f1_score(y_test, y_pred)\n\n# calculate precision-recall AUC\n#auc = auc(recall, precision)\n\n# calculate average precision score\nap = average_precision_score(y_test, probs)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n\n# plot the precision-recall curve for the model\nplt.plot(recall, precision, marker='.')\n\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#help(roc_auc_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN Starts Here"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n       'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', \n       'Property_Area', 'Status',]\n\nx = loan_df.drop(cols,axis=1)\ny = loan_df['Status']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=20)\n\nneighbors = np.arange(1, 17)\ntrain_accuracy = np.empty(len(neighbors))   # creates an empty array of size 9\ntest_accuracy = np.empty(len(neighbors))\n\nfor i, k in enumerate(neighbors):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train,y_train) \n    train_accuracy[i] = knn.score(x_train,y_train)\n    test_accuracy[i] = knn.score(x_test, y_test)\n\nplt.title('k-NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()\n\n\n#took the appropriate value of k\nknn = KNeighborsClassifier(n_neighbors=16)\nknn.fit(x_train,y_train)\ny_pred = knn.predict(x_test)\nprint(y_pred)\nscore = knn.score(x_test, y_test)\nscore1 = knn.score(x_train, y_train)\nprint(\"test score:\",score, \"train score:\",score1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test , y_pred))\n\npd.crosstab(y_test , y_pred , rownames=[\"True\"], colnames=[\"Predicted\"] ,margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test , y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"\n# ROC (Reciever Operating Charecteristic) curve\nIt is a plot of the true positive rate against the false positive rate for the different possible cutpoints of a diagnostic test.\nAn ROC curve demonstrates several things:\n1) It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n2) The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n3)The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.\n4) The area under the curve is a measure of test accuracy '''"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = knn.predict_proba(x_test)[:,1]\n\nfrom sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=16) ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Hyperparameter tuning\nThe value of k (i.e 7) we selected above was selected by observing the curve of accuracy vs number of neighbors. This is a primitive way of hyperparameter tuning.\nThere is a better way of doing it which involves:\n1) Trying a bunch of different hyperparameter values\n2) Fitting all of them separately\n3) Checking how well each performs\n4) Choosing the best performing one\n5) Using cross-validation every time\nScikit-learn provides a simple way of achieving this using GridSearchCV i.e Grid Search cross-validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"#import GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\n#In case of classifier like knn the parameter to be tuned is n_neighbors\nparam_grid = {'n_neighbors': np.arange(1,150)}\n\nknn = KNeighborsClassifier()\nknn_cv= GridSearchCV(knn,param_grid)\nknn_cv.fit(x,y)\n\nprint(\"KNN Best Score : \" , knn_cv.best_score_)\n\nprint(\"KNN Best K Fit : \" , knn_cv.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"knnf = KNeighborsClassifier()\n\nknnf.fit(x,y)\n\ny_pred = knnf.predict(x)\n\ny_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_df[\"Prediction\"] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.pivot_table (  data  = loan_df , index=\"Status\" ,  aggfunc='count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This concludes that logistic regression model best suits this loan status prediction problem.\n\n#for any queries reach me @pallavivibhute31@gmail.com.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}