{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn import preprocessing, model_selection\n\ndf = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\",parse_dates=True)\n\ndf.drop([\"id\",\"date\"],axis=1,inplace=True)\ndisplay(df.head(3))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n#Dataset is clean of null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking correlations\nfig,ax = plt.subplots(figsize=(25, 15))\nsns.heatmap(df.corr(),annot=True,ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing X,y\ny =df[\"price\"]\nX = df.drop(\"price\",axis=1)\nfeatures = list(X.columns)\n\ndisplay(X.shape,y.shape)\ndisplay(X.head(3))\ndisplay(y.head(3))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optional but makes gradient descent faster\n\n#X = preprocessing.scale(X)\n#y = preprocessing.scale(y)\n\n#train test split\n\nX_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.2,random_state=11)\n#lr is our linear regression classifier\n\nlr = LinearRegression(fit_intercept=True, n_jobs=1, normalize=False)\n\nlr.fit(X_train , y_train)\nAccuracy = lr.score(X_test,y_test)\nprint(str(Accuracy*100) +\" %\" )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({\"Theta values\":lr.coef_},index = features )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = lr.predict(X_test)\n\nsns.scatterplot(y_predict,y_test)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(y_predict-y_test,bins=60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import metrics\nRMSE = metrics.mean_squared_error(y_predict,y_test,squared=False)\nMSE = RMSE**2\nMAE = metrics.mean_absolute_error(y_predict,y_test)\nprint( \"Accuracy: \" + str(accuracy*100) +\" %\" )\nprint(\"MSE : \"+str(MSE))\nprint(\"RMSE : \"+str(RMSE))\nprint(\"MAE : \"+str(MAE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ELASTIC NET r=1 essentialy ridge\n\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn import metrics\n\nelastic_reg = ElasticNet(alpha=0.1,l1_ratio=1,random_state=11)\nelastic_reg.fit(X_train,y_train)\nAccuracy = elastic_reg.score(X_test,y_test)\n\n\n\n\nprint( \"Accuracy: \" + str(Accuracy*100) +\" %\" )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#polynomial conversion + plain linear regression - ----- Most accurate\n\nfrom sklearn import preprocessing\npoly_features = preprocessing.PolynomialFeatures(degree=2)\nX_poly = poly_features.fit_transform(X)\n\n#resplitting data after polynomial conversion\nX_train,X_test,y_train,y_test = model_selection.train_test_split(X_poly,y,test_size=0.2,random_state=11)\n\nlr = LinearRegression(fit_intercept=True, n_jobs=1, normalize=False)\n\nlr.fit(X_train , y_train)\nAccuracy = lr.score(X_test,y_test)\n\nprint( \"Accuracy: \" + str(Accuracy*100) +\" %\" )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#polynomial conversion + Elasticnet (Regularized linear regression)\n\nfrom sklearn import preprocessing\npoly_features = preprocessing.PolynomialFeatures(degree=2)\nX_poly = poly_features.fit_transform(X)\n\n#resplitting data after polynomial conversion\nX_train,X_test,y_train,y_test = model_selection.train_test_split(X_poly,y,test_size=0.2,random_state=11)\n\nelastic_reg = ElasticNet(alpha=0.1,l1_ratio=0.5,random_state=11,max_iter=2000)\nelastic_reg.fit(X_train,y_train)\nAccuracy=elastic_reg.score(X_test,y_test)\n\n\nprint( \"Accuracy: \" + str(Accuracy*100) +\" %\" )\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}