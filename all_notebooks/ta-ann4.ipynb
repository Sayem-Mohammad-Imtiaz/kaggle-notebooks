{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport librosa\nimport glob \nfrom IPython.display import Audio\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom keras.layers import Dense , Dropout ,Input , LSTM\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD\nfrom keras.utils import plot_model\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls '../input/xenocanto-avian-vocalizations-canv-usa'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root = '../input/xenocanto-avian-vocalizations-canv-usa/'\nmeta = pd.read_csv(root + 'xeno-canto_ca-nv_index.csv')\nmeta.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta['species'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta = meta[meta['species'].isin(['californica','nuttallii','occidentalis'])]\nmeta.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(meta['species'])\nmeta['species'] = le.transform(meta['species'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_id = list(meta['file_name'].values)\nlabels = list(meta['species'].values)\n\nprint(f\"shape sound id : {len(sound_id)}\")\nprint(f\"shape labels : {len(labels)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = to_categorical(labels)\nprint(f\"shape labels : {labels.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\nroot = '../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto-ca-nv/'\nIPython.display.Audio(root + sound_id[50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# more feature extractor : https://librosa.org/doc/main/feature.html\n\ndef extract_mfcc(file_name):\n    #This function extracts mfcc features and obtain the mean of each dimension\n    #Input : path sound\n    #Output: mfcc_features'''\n    root = '../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto-ca-nv/'\n    path =  root + file_name \n    y, sr = librosa.load(path)\n    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr,n_mfcc=36).T,axis=0)\n    \n    return mfccs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_CENS(file_name):\n    #This function extracts CENS features and obtain the mean of each dimension\n    #Input : path sound\n    #Output: CENS_features'''\n    root = '../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto-ca-nv/'\n    path =  root + file_name \n    y, sr = librosa.load(path)\n    cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=36).T,axis=0)\n    \n    return cens","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"sound_features_mfcc = []\nsound_features_cens = []\nfor path in sound_id:\n    sound_features_mfcc.append(extract_mfcc(path))\n    sound_features_cens.append(extract_CENS(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_features_mfcc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(sound_features_mfcc))\nprint(sound_features_mfcc[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_features_cens[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(sound_features_cens))\nprint(sound_features_cens[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_features = []\n\nfor i in range(len(sound_id)):\n    mfcc = sound_features_mfcc[i]\n    feature = np.array([mfcc]).reshape(36,1)\n    sound_features.append(feature)\n    \nsound_features = np.asarray(sound_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LSTM input -> (Samples,timesteps,Features)\n# we split sound to 36 timesteps and each timesteps represents by 2 features.\ninput_layer = Input(shape=(36,1), name =\"input\")\nlstm_layer = LSTM(128, return_sequences=False)(input_layer)\nhidden_layer1 = Dense(32 ,activation='relu' , name=\"layer1\")(lstm_layer)\nhidden_layer2 = Dense(16 ,activation='relu' , name=\"layer2\")(hidden_layer1)\ndroupout_layer = Dropout(0.5)(hidden_layer2)\nhidden_layer3 = Dense(8 ,activation='tanh' , name=\"layer3\")(droupout_layer)\noutput_layer = Dense(3 ,activation='softmax' , name=\"output\")(droupout_layer)\n\nmodel = Model(inputs=input_layer, outputs=output_layer , name = \"model\")\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGD(lr=0.0001, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(sound_features,labels ,epochs=50,batch_size = 32 ,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_features = []\n\nfor i in range(len(sound_id)):\n    mfcc = sound_features_mfcc[i]\n    cens = sound_features_cens[i]\n    feature = np.array([mfcc,cens]).reshape(36,2)\n    sound_features.append(feature)\n    \nsound_features = np.asarray(sound_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sound_features[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LSTM input -> (Samples,timesteps,Features)\n# we split sound to 36 timesteps and each timesteps represents by 2 features.\ninput_layer = Input(shape=(36,2), name =\"input\")\nlstm_layer = LSTM(128, return_sequences=False)(input_layer)\nhidden_layer1 = Dense(32 ,activation='relu' , name=\"layer1\")(lstm_layer)\nhidden_layer2 = Dense(16 ,activation='relu' , name=\"layer2\")(hidden_layer1)\ndroupout_layer = Dropout(0.5)(hidden_layer2)\nhidden_layer3 = Dense(8 ,activation='tanh' , name=\"layer3\")(droupout_layer)\noutput_layer = Dense(3 ,activation='softmax' , name=\"output\")(droupout_layer)\n\nmodel = Model(inputs=input_layer, outputs=output_layer , name = \"model\")\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGD(lr=0.0001, momentum=0.9)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(sound_features,labels ,epochs=50,batch_size = 32 ,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}