{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport seaborn as sns\nfrom scipy import stats\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Nina Petreska 161092\nimport matplotlib.pyplot as plt #Libraries for visualization\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom scipy import stats #Library for statistical analysis \nfrom sklearn import datasets #Libraries for machine learning\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n%matplotlib notebook\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Избрано е податочното множество покемон кое има 13 атрибути, од кој за таргет јас го земам Legendary"},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemons = pd.read_csv('/kaggle/input/pokemon/Pokemon.csv')\n\nX = pokemons.drop('Legendary', axis=1)\nX = X.drop('Name', axis = 1)\nX = X.drop('#', axis=1)\n\ntarget_names = np.unique(pokemons['Legendary'])\nfeature_names = list(X.columns.values)\n\npokemons['Legendary'] = pokemons['Legendary'].map({False : 0, True : 1})\nprint(np.unique(pokemons['Type 1']))\n\n#Tekstualnite podatoci se zamenivaat so integers\npokemons['Type 1'] = pokemons['Type 1'].map({'Bug' : 0, 'Dark' : 1,'Dragon' : 2,'Electric': 3, 'Fairy' : 4, 'Fighting':5, 'Fire':6, 'Flying':7,'Ghost':8 ,'Grass':9 ,'Ground':10, 'Ice':11, 'Normal':12, 'Poison':13, 'Psychic':14, 'Rock':15 ,'Steel':16,'Water':17,float('nan'):18 })\npokemons['Type 2'] = pokemons['Type 2'].map({'Bug' : 0, 'Dark' : 1,'Dragon' : 2,'Electric': 3, 'Fairy' : 4, 'Fighting':5, 'Fire':6, 'Flying':7,'Ghost':8 ,'Grass':9 ,'Ground':10, 'Ice':11, 'Normal':12, 'Poison':13, 'Psychic':14, 'Rock':15 ,'Steel':16,'Water':17,float('nan'):18 })\nprint(pokemons) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = pokemons.drop('Name', axis = 1)\np = p.drop('#',axis = 1)\n\n#Ke probam bez ovie\npp = p.drop(['Type 1','Type 2','HP','Attack','Defense','Generation'],axis = 1)\n\n#I ke probam bez types i bez generation, bidejki mislam deka tie se ramnomerno raspredelneni skoro\np_p = p.drop(['Type 1','Type 2','Generation'],axis=1)\n\n#bez total isto kako tretoto\np4 = p.drop(['Type 1','Type 2','Generation','Total'],axis=1)\n\n#izmenetiot fajl go zacuvuvam vo nov\np.to_csv(\"Pokemons_Nina.csv\", sep=',', index=False)\npp.to_csv(\"P.csv\", sep=',', index=False)\np_p.to_csv(\"poke.csv\",sep= ',',index=False)\np4.to_csv('p4.csv',sep = ',', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = np.loadtxt(open(\"Pokemons_Nina.csv\", \"rb\"), delimiter=\",\", max_rows=1, dtype = str)\npokemon = np.loadtxt(open(\"Pokemons_Nina.csv\", \"rb\"), delimiter=\",\", skiprows=1, dtype = str)\ny = pokemon[:,-1].astype(np.int)\nX = pokemon[:,:-1].astype(np.float)\n\nnumber_of_features = X.shape[1]\nnumber_of_classes = len(np.unique(y))\n\nprint(\"Number and names of classes:\", len(np.unique(y)), target_names) \nprint(\"Number and names of features:\", len(np.unique(feature_names)), feature_names) \nprint(\"Number of data points:\", X.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(column_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['crimson', 'turquoise']\nprint(feature_names)\n#X[feature_names[0]]\nprint(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 16))\nfig.subplots(nrows=5, ncols=2)\nfor feat_i in range(number_of_features): #For each feature, we have a new subplot\n    ax = plt.subplot(5,2, feat_i+1)\n    f = feature_names[feat_i]\n    plt.title(feature_names[feat_i])\n    sns.distplot(X[:,feat_i])\n    for class_i in range(number_of_classes): #After that we draw the within-class histograms of the same feature\n        sns.distplot(X[y == class_i,feat_i], color=colors[class_i], label=target_names[class_i])\n    plt.legend()\nplt.show()\n\n#Jas ke gi koristam Total, Sp.Atk, Sp.Def , Speed bidejkispored vzuelnite pretstavi izgledaat kako pobitni","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 40))\nplt.title(\"Scatterplots of the Pokemon dataset features\")\nfig.subplots(nrows=10, ncols=10)\nfor feat_i in range(number_of_features): #We go over all pairs of features (4x4 in this case)\n    for feat_j in range(number_of_features):  \n        ax = plt.subplot(10,10,10*feat_i + feat_j+1)\n        # Plot the points\n        for color, i, target_name in zip(colors, [0, 1], target_names):\n            plt.scatter(X[y == i, feat_i], X[y == i, feat_j], alpha=.8, color=color, label=target_name) #We again extract the feature class specific data using the same method as before and then just use the scatter function\n        plt.xticks(())\n        plt.yticks(())\n        plt.title(\"Feature \"+str(feat_i)+\" x Feature \"+str(feat_j))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_matrix = np.zeros((number_of_features,number_of_features))\nfor i in range(number_of_features): #We need a 10x10 matrix to represent the correlation matrix, where we set the value of Cij to be the correlation between the i'th and the j'th metric\n    measure = X[:,i]\n    for j in range(number_of_features):\n        measure2 = X[:,j]\n        corr, _ = stats.pearsonr(measure, measure2)\n        correlation_matrix[i][j] = corr\nplt.figure()\nplt.imshow(correlation_matrix, cmap = \"inferno\") #We can draw the matrix using imshow\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=2) \nX_PCA = pca.fit(X).transform(X) \n\nplt.figure() \nfor color, i, target_name in zip(colors, [0, 1, 2], target_names):\n    plt.scatter(X_PCA[y == i, 0], X_PCA[y == i, 1], color=color, alpha=.8, lw=2,\n                label=target_name)\nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('PCA of Pokemon dataset')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dimensionality reduction techniques reduce the number of dimensions (i.e. variables) in a dataset while retaining as much information as possible"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bidejki imam samo 2 klasi, nema moznost za 2D vizuelizacija\n#Ovaa funkcija za binaren problem e 1D :(\nlda = LDA(n_components=2)\nlda = lda.fit(X, y) \nX_LDA = lda.transform(X)\n#print(X_LDA[0:10])\nplt.figure() \n\nfor color, i, target_name in zip(colors, [0, 1], target_names):\n    plt.scatter(X_LDA[y == i,0], X_LDA[y == i,0], alpha=.8, color=color, label=target_name)\nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('LDA of Pokemon dataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) #We split the original dataset (we use a fixed random state such as 42 so we always split the data the same way)\nX_PCA_train, X_PCA_test, y_PCA_train, y_PCA_test = train_test_split(X_PCA, y, test_size=0.30, random_state=42) #We split the PCA dimensionaly reducted dataset\nX_LDA_train, X_LDA_test, y_LDA_train, y_LDA_test = train_test_split(X_LDA, y, test_size=0.30, random_state=42) #We split the LDA dimensionaly reducted dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize the model, fit the training data and predict the test data\nlda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\nlda.fit(X_LDA_train, y_LDA_train)\ny_pred = lda.predict(X_LDA_test)\nprint(\"LDA accuracy for the LDA dimensionaly reducted Pokemon dataset\", np.round(np.sum(y_LDA_test == y_pred)/len(y_LDA_test),3))\n\n#Visualize the test set and the errors which have occured\nplt.figure()\nfor color, i, target_name in zip(colors, [0, 1, 2], target_names):\n    plt.scatter(X_LDA_test[y_LDA_test == i, 0], X_LDA_test[y_LDA_test == i, 0], alpha=.8, color=color,\n                label=target_name)\nplt.title('LDA classification: LDA of Pokemon dataset')\n\nincorrect = y_pred!=y_LDA_test\nfor i in range(len(incorrect)):\n    if(incorrect[i]==True):\n        plt.scatter(X_LDA_test[i][0], X_LDA_test[i][0], alpha=.5, color=\"black\")\nplt.legend(loc='best', shadow=False, scatterpoints=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb = GaussianNB() \ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\naccuracy = np.round(np.sum(y_test == y_pred)/len(y_test),3)\nprint(\"Naive Bayes accuracy for the original Pokemon dataset\", accuracy)\nprint(\"Precision_score\",precision_score(y_test, y_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y_test, y_pred, average='macro'))\nprint(\"F1_score\",f1_score(y_test, y_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probuvam poveke opcii koi koloni da gi koristam\ncolumn_names_2 = np.loadtxt(open(\"P.csv\", \"rb\"), delimiter=\",\", max_rows=1, dtype = str)\npokemon_2 = np.loadtxt(open(\"P.csv\", \"rb\"), delimiter=\",\", skiprows=1, dtype = str)\ny2 = pokemon_2[:,-1].astype(np.int)\nX2 = pokemon_2[:,:-1].astype(np.float)\n\nnumber_of_features_2 = X2.shape[1]\nnumber_of_classes_2 = len(np.unique(y2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.30, random_state=42)\n\ngnb = GaussianNB() \ngnb.fit(X2_train, y2_train)\ny2_pred = gnb.predict(X2_test)\naccuracy = np.round(np.sum(y2_test == y2_pred)/len(y2_test),3)\nprint(\"Naive Bayes accuracy for the smaller Pokemon dataset\", accuracy)\n#Iako gi odbrav tie koi najmnogu bea razdaleceni, sepak se mnogu malku atributi i dobiv polosi rezultati osven vo recall\nprint(\"Precision_score\",precision_score(y2_test, y2_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y2_test, y2_pred, average='macro'))\nprint(\"F1_score\",f1_score(y2_test, y2_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names_3 = np.loadtxt(open(\"poke.csv\", \"rb\"), delimiter=\",\", max_rows=1, dtype = str)\npokemon_3 = np.loadtxt(open(\"poke.csv\", \"rb\"), delimiter=\",\", skiprows=1, dtype = str)\ny3 = pokemon_3[:,-1].astype(np.int)\nX3 = pokemon_3[:,:-1].astype(np.float)\n\nnumber_of_features_3 = X3.shape[1]\nnumber_of_classes_3 = len(np.unique(y3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.30, random_state=42)\n\ngnb = GaussianNB() \ngnb.fit(X3_train, y3_train)\ny3_pred = gnb.predict(X3_test)\naccuracy = np.round(np.sum(y3_test == y3_pred)/len(y3_test),3)\nprint(\"Naive Bayes accuracy for the smaller Pokemon dataset\", accuracy)\n#VO tretiot obid, vo koj gi trgnav tie koi mi izgledaa ramnomerno raspredeleni so Naive Bayes dobiv podobri rezultati\n#Ponatamu ke prodolzam da rabotam so ovie podatoci","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(target_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bidejki imam samo 2 klasi, nema moznost za 2D vizuelizacija\n#Ovaa funkcija za binaren problem e 1D :(\nlda3 = LDA(n_components=2)\nlda3 = lda3.fit(X3, y3) \nX3_LDA = lda3.transform(X3)\nplt.figure() \n\nfor color, i, target_name in zip(colors, [0, 1], target_names):\n    plt.scatter(X3_LDA[y == i,0], X3_LDA[y == i,0], alpha=.8, color=color, label=target_name)\nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('LDA of Pokemon3 dataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca3 = PCA(n_components=2) \nX3_PCA = pca3.fit(X3).transform(X3)  \n\nplt.figure()\nfor color, i, target_name in zip(colors, [0, 1], target_names):\n    plt.scatter(X3_PCA[y == i, 0], X3_PCA[y == i, 1], color=color, alpha=.8, lw=2,\n                label=target_name)\nplt.legend(loc='best', shadow=False, scatterpoints=1)\nplt.title('PCA of Pokemon dataset')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X3_train, X3_test, y_train, y3_test = train_test_split(X3, y3, test_size=0.30, random_state=42) #We split the original dataset (we use a fixed random state such as 42 so we always split the data the same way)\nX3_PCA_train, X3_PCA_test, y3_PCA_train, y3_PCA_test = train_test_split(X3_PCA, y3, test_size=0.30, random_state=42) #We split the PCA dimensionaly reducted dataset\nX3_LDA_train, X3_LDA_test, y3_LDA_train, y3_LDA_test = train_test_split(X3_LDA, y3, test_size=0.30, random_state=42) #We split the LDA dimensionaly reducted dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LDA model\nlda = LinearDiscriminantAnalysis()\nlda.fit(X3_train, y3_train) \ny3_pred = lda.predict(X3_test) \naccuracy = np.round(np.sum(y3_test == y3_pred)/len(y3_test),3)\nprint(\"LDA accuracy for the Pokemon3 dataset\", accuracy) \nprint(\"Precision_score\",precision_score(y3_test, y3_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y3_test, y3_pred, average='macro'))\nprint(\"F1_score\",f1_score(y3_test, y3_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#QDA Model\nclf = QDA()\nclf.fit(X3_train, y3_train)\ny3_pred = clf.predict(X3_test) \naccuracy = np.round(np.sum(y3_test == y3_pred)/len(y3_test),3)\nprint(\"QDA accuracy for the Pokemon3 dataset\", accuracy) \nprint(\"Precision_score\",precision_score(y3_test, y3_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y3_test, y3_pred, average='macro'))\nprint(\"F1_score\",f1_score(y3_test, y3_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayes\ngnb = GaussianNB() \ngnb.fit(X3_train, y3_train)\ny3_pred = gnb.predict(X3_test)\naccuracy = np.round(np.sum(y3_test == y3_pred)/len(y3_test),3)\nprint(\"Naive Bayes accuracy for the smaller Pokemon dataset\", accuracy)\nprint(\"Precision_score\",precision_score(y3_test, y3_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y3_test, y3_pred, average='macro'))\nprint(\"F1_score\",f1_score(y3_test, y3_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"poke.csv\")\nprint(df)\nc = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(c[c >= 0.7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(c[c >= 0.7].stack().reset_index(name='cor').query(\"abs(cor) < 1.0\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bidejki total e koreliran so site, ke probam i bez nego\n\n#Otkako gi trgnav kolinearnite koloni, dobiv najdobar rezultat so QDA modelot\n#Bidejki speak dosta se razlikuvaat legendarnite pokemons od obicnite, ne e mnogu tesko da se razgranicat\n#so Site modeli dobiv dosta dobri rezultati","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names_4 = np.loadtxt(open(\"p4.csv\", \"rb\"), delimiter=\",\", max_rows=1, dtype = str)\npokemon_4 = np.loadtxt(open(\"p4.csv\", \"rb\"), delimiter=\",\", skiprows=1, dtype = str)\ny4 = pokemon_4[:,-1].astype(np.int)\nX4 = pokemon_4[:,:-1].astype(np.float)\n\nnumber_of_features_4 = X3.shape[1]\nnumber_of_classes_4 = len(np.unique(y4))\n\npca4 = PCA(n_components=2) \nX4_PCA = pca4.fit(X4).transform(X4) \n\nlda4 = LDA(n_components=2)\nlda4 = lda4.fit(X4, y4) \nX4_LDA = lda4.transform(X4)\n\nX4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.30, random_state=42) #We split the original dataset (we use a fixed random state such as 42 so we always split the data the same way)\nX4_PCA_train, X4_PCA_test, y4_PCA_train, y4_PCA_test = train_test_split(X4_PCA, y4, test_size=0.30, random_state=42) #We split the PCA dimensionaly reducted dataset\nX4_LDA_train, X4_LDA_test, y4_LDA_train, y4_LDA_test = train_test_split(X4_LDA, y4, test_size=0.30, random_state=42) #We split the LDA dimensionaly reducted dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LDA model\nlda = LinearDiscriminantAnalysis()\nlda.fit(X4_train, y4_train) \ny4_pred = lda.predict(X4_test) \naccuracy = np.round(np.sum(y4_test == y4_pred)/len(y4_test),3)\nprint(\"LDA accuracy for the Pokemon3 dataset\", accuracy) \nprint(\"Precision_score\",precision_score(y4_test, y4_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y4_test, y4_pred, average='macro'))\nprint(\"F1_score\",f1_score(y4_test, y4_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#QDA Model\nclf = QDA()\nclf.fit(X4_train, y4_train)\ny4_pred = clf.predict(X4_test) \naccuracy = np.round(np.sum(y4_test == y4_pred)/len(y4_test),3)\nprint(\"QDA accuracy for the Pokemon3 dataset\", accuracy) \nprint(\"Precision_score\",precision_score(y4_test, y4_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y4_test, y4_pred, average='macro'))\nprint(\"F1_score\",f1_score(y4_test, y4_pred, average='macro'))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayes\ngnb = GaussianNB() \ngnb.fit(X4_train, y4_train)\ny4_pred = gnb.predict(X4_test)\naccuracy = np.round(np.sum(y4_test == y4_pred)/len(y4_test),3)\nprint(\"Naive Bayes accuracy for the smaller Pokemon dataset\", accuracy)\nprint(\"Precision_score\",precision_score(y4_test, y4_pred, average='macro'))\nprint(\"Recall_score\",recall_score(y4_test, y4_pred, average='macro'))\nprint(\"F1_score\",f1_score(y4_test, y4_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Otkako gi trgnav kolinearnite koloni, dobiv najdobar rezultat so QDA modelot\n#Bidejki speak dosta se razlikuvaat legendarnite pokemons od obicnite, ne e mnogu tesko da se razgranicat\n#so Site modeli dobiv dosta dobri rezultati","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}