{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nsns.set(color_codes=True)\npal = sns.color_palette(\"Set2\", 10)\nsns.set_palette(pal)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/hackerearth-how-not-to-lose-a-customer-in-10-days/train.csv')\ntest = pd.read_csv('../input/hackerearth-how-not-to-lose-a-customer-in-10-days/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA/ DATA PREP","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in train.columns:\n    if col not in ['customer_id','Name',  'security_no','referral_id','last_visit_time','joining_date','avg_frequency_login_days'] and train[str(col)].dtype != 'float64':\n        x = train.groupby(str(col))[str(col)].count().sort_values(ascending=False)\n        df = pd.DataFrame({str(col):x.index,'count':x.values})\n        \n        print(df.to_string(index=False))\n        print(\".............................\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in test.columns:\n    if col not in ['customer_id','Name',  'security_no','referral_id','last_visit_time','joining_date','avg_frequency_login_days'] and train[str(col)].dtype != 'float64':\n        x = test.groupby(str(col))[str(col)].count().sort_values(ascending=False)\n        df = pd.DataFrame({str(col):x.index,'count':x.values})\n        \n        print(df.to_string(index=False))\n        print(\".............................\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Garbge Values","metadata":{}},{"cell_type":"code","source":"## Dropping rows with -1 churn risk\n\nl=[]\nfor i in range(train.shape[0]):\n    if(train['churn_risk_score'][i]==-1):\n        l.append(i)\n        \ntrain = train.drop(l,axis=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ab = train[train['avg_frequency_login_days']!='Error']\nab['avg_frequency_login_days'] = ab['avg_frequency_login_days'].astype('float64')\nposmean = ab[ab['avg_frequency_login_days']>0]['avg_frequency_login_days'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(ab, x=\"avg_frequency_login_days\", kind=\"kde\",hue='churn_risk_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Handling avg_frequency_login_days error value and negative values\n\nl = []\nfor i in train['avg_frequency_login_days']:\n    if i =='Error' or '-' in str(i):\n        l.append(posmean)\n    else:\n        l.append(i)\n        \ntrain['avg_frequency_login_days'] = l\ntrain['avg_frequency_login_days'] = train['avg_frequency_login_days'].astype('float64')\n\n\nl = []\nfor i in test['avg_frequency_login_days']:\n    if i =='Error' or '-' in str(i):\n        l.append(posmean)\n    else:\n        l.append(i)\n        \ntest['avg_frequency_login_days'] = l\ntest['avg_frequency_login_days'] = test['avg_frequency_login_days'].astype('float64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(train, x=\"avg_frequency_login_days\", kind=\"kde\",hue='churn_risk_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## With whole Data\n\nsns.displot(train, x=\"days_since_last_login\", kind=\"kde\",hue='churn_risk_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Without Garbage Value\n\n\ndsllp = train[train['days_since_last_login']>0]\nsns.displot(dsllp, x=\"days_since_last_login\", kind=\"kde\",hue='churn_risk_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mu = np.mean(dsllp['days_since_last_login'])\nsigma = np.std(dsllp['days_since_last_login'])\nnp.random.seed(13)\ns = np.random.normal(mu, sigma, 100000).astype('int64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling days_since_last_login -999 values, we will NORMALLY distribute over all values","metadata":{}},{"cell_type":"code","source":"## Handling days_since_last_login -999\n\n\nimport random\nnp.random.seed(13)\nl = []\nfor i in train['days_since_last_login']:\n    if i == -999:\n        num =0\n        f = True\n        while f:\n            num =random.choice(s)\n            if num>0 and num<=26:\n                l.append(num)\n                f=False\n    else:\n        l.append(i)\n        \ntrain['days_since_last_login'] = l\n\n\n\nl = []\nfor i in test['days_since_last_login']:\n    if i == -999:\n        num =0\n        f = True\n        while f:\n            num =random.choice(s)\n            if num>0 and num<=26:\n                l.append(num)\n                f=False\n    else:\n        l.append(i)\n        \ntest['days_since_last_login'] = l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After Handling Garbage Values\n\nsns.displot(train, x=\"days_since_last_login\", kind=\"kde\",hue='churn_risk_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WE HAVE SUCCESSFULLY SYNTHESISED THE -999 DATA","metadata":{}},{"cell_type":"markdown","source":"## Handling Missing values","metadata":{}},{"cell_type":"code","source":"## For Points in Wallet\n\n### Before Handling missing values\n\nsns.displot(train, x=\"points_in_wallet\", kind=\"kde\",hue='churn_risk_score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Less churn risk score tend to have more points","metadata":{}},{"cell_type":"code","source":"## Checking various distributions for selecting Imputation method\n\nprint('-------------------------------')\nfor i in range(0,1400,100):\n    print('From '+str(i)+' to '+str(i+100))\n    print('Total no. of observations:', train[(train['points_in_wallet']>i)&(train['points_in_wallet']<i+100)].shape[0])\n    a = train[(train['points_in_wallet']>i)&(train['points_in_wallet']<i+100)].groupby('churn_risk_score').churn_risk_score.count()\n    b = pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\n    print(b.to_string(index=False))\n    \n    print('-------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('For Missing Values')\nprint('Total no. of observations:', train[(train['points_in_wallet'].isnull())|(train['points_in_wallet']<0)].shape[0])\na = train[(train['points_in_wallet'].isnull())|(train['points_in_wallet']<0)].groupby('churn_risk_score').churn_risk_score.count()\nb =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\nprint(b.to_string(index=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Missing values match with data that is less than 0, Its Possible that missing values must be 0 points ","metadata":{}},{"cell_type":"code","source":"## imputing 0 \n\nl = []\nnp.random.seed(13)\nr= np.random.uniform(500,1000,100000)\ns = set(train['points_in_wallet'])\nfor i in train['points_in_wallet']:\n    if (i not in s) or (i<0) :\n        l.append(random.choice(r))\n    else:\n        l.append(i)\ntrain['points_in_wallet'] = l\n\n\nl = []\ns = set(test['points_in_wallet'])\nfor i in test['points_in_wallet']:\n    if (i not in s) or i<0 :\n        l.append(random.choice(r))\n    else:\n        l.append(i)\ntest['points_in_wallet'] = l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## After Handling Missing Values\n\nsns.displot(train, x=\"points_in_wallet\", kind=\"kde\",hue='churn_risk_score')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Handling Region Category\ns = ['Town','City','Village']\nfor i in s: \n    a = train[train['region_category']==i].groupby('churn_risk_score').churn_risk_score.count()\n    b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\n    print('For ', i)\n    print('Total no. of observations : ', train[train['region_category']==i].shape[0])\n    print(b.to_string(index=False))\n    print('-------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = train[train['region_category'].isnull()].groupby('churn_risk_score').churn_risk_score.count()\nb =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\nprint('For missing values')\nprint(b.to_string(index=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It matches with town and city data, therefore we will go with most frequent that is Town","metadata":{}},{"cell_type":"code","source":"## Imputing Town\n\nl = []\nfor i in train['region_category']:\n    if i in [np.nan]:\n        l.append('Town')\n    else:\n        l.append(i)\n\ntrain['region_category'] = l\n\n\nl = []\nfor i in test['region_category']:\n    if i in [np.nan]:\n        l.append('Town')\n    else:\n        l.append(i)\n\ntest['region_category'] = l\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = set(train['preferred_offer_types'])\nfor i in s: \n    if i not in [np.nan]:\n        a = train[train['preferred_offer_types']==i].groupby('churn_risk_score').churn_risk_score.count()\n        b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\n        print('For ', i)\n        print('Total no. of observations : ', train[train['preferred_offer_types']==i].shape[0])\n        print(b.to_string(index=False))\n        print('-------------------------------')\n    else:\n        a = train[train['preferred_offer_types'].isnull()].groupby('churn_risk_score').churn_risk_score.count()\n        b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\n        print('For ', i)\n        print('Total no. of observations : ', train[train['preferred_offer_types'].isnull()].shape[0])\n        print(b.to_string(index=False))\n        print('-------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Missing Data more similar to Without offer and it makes sense also!!","metadata":{}},{"cell_type":"code","source":"## Imputing Without Offers\n\nl = []\nfor i in train['preferred_offer_types']:\n    if i in [np.nan]:\n        l.append('Without Offers')\n    else:\n        l.append(i)\n\ntrain['preferred_offer_types'] = l\n\n\nl = []\nfor i in test['preferred_offer_types']:\n    if i in [np.nan]:\n        l.append('Without Offers')\n    else:\n        l.append(i)\n\ntest['preferred_offer_types'] = l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = train[train['preferred_offer_types']=='Without Offers'].groupby('churn_risk_score').churn_risk_score.count()\nb =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\nprint('For ', i)\nprint('Total no. of observations : ', train[train['preferred_offer_types']=='Without Offers'].shape[0])\nprint(b.to_string(index=False))\nprint('-------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Perfectly Synthesised Missing Values","metadata":{}},{"cell_type":"markdown","source":"## There are some values with '?' also, Lets Handle them","metadata":{}},{"cell_type":"code","source":"for col in train.columns:\n    if '?' in set(train[str(col)]):\n        print(col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = set(train['joined_through_referral'])\nfor i in s: \n    a = train[train['joined_through_referral']==i].groupby('churn_risk_score').churn_risk_score.count()\n    b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\n    print('For ', i)\n    print('Total no. of observations : ', train[train['joined_through_referral']==i].shape[0])\n    print(b.to_string(index=False))\n    print('-------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Missing Data is simillar to Yes and No both, but more like Yes, So not deisturbing the balance Lets impute YES in probability of 0.66 randomly","metadata":{}},{"cell_type":"code","source":"# Imputing Yes\n\nl = []\nnp.random.seed(13)\nr = ['Yes','Yes','No']\nfor i in train['joined_through_referral']:\n    if i in ['?']:\n        l.append(random.choice(r))\n    else:\n        l.append(i)\n\ntrain['joined_through_referral'] = l\n\n\nl = []\nfor i in test['joined_through_referral']:\n    if i in ['?']:\n        l.append(random.choice(r))\n    else:\n        l.append(i)\n\ntest['joined_through_referral'] = l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For medium of operation\n\ns = set(train['medium_of_operation'])\nfor i in s: \n    a = train[train['medium_of_operation']==i].groupby('churn_risk_score').churn_risk_score.count()\n    b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100/a.values.sum()})\n    print('For ', i)\n    print('Total no. of observations : ', train[train['medium_of_operation']==i].shape[0])\n    print(b.to_string(index=False))\n    print('-------------------------------')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data doesnot match any feature specifically, so we can assume this must be an other device like Tablet/Ipad or Laptop etc.","metadata":{}},{"cell_type":"code","source":"l = []\nfor i in train['medium_of_operation']:\n    if i in ['?']:\n        l.append('Laptop')\n    else:\n        l.append(i)\n\ntrain['medium_of_operation'] = l\n\nl = []\nfor i in test['medium_of_operation']:\n    if i in ['?']:\n        l.append('Laptop')\n    else:\n        l.append(i)\n\ntest['medium_of_operation'] = l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling Date column","metadata":{}},{"cell_type":"code","source":"train['joining_date'] =  pd.to_datetime(train['joining_date'], format='%Y-%m-%d')\ntest['joining_date'] =  pd.to_datetime(test['joining_date'], format='%Y-%m-%d')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"days = []\nmonths = []\nyears = []\nfor i in train['joining_date']:\n    days.append(i.day)\n    months.append(i.month)\n    years.append(i.year)\n\ntrain['Day'] = days\ntrain['Month'] = months\ntrain['Year'] = years\n\n\n\ndays = []\nmonths = []\nyears = []\nfor i in test['joining_date']:\n    days.append(i.day)\n    months.append(i.month)\n    years.append(i.year)\n\ntest['Day'] = days\ntest['Month'] = months\ntest['Year'] = years","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Prep done, now we will continue with Model Building","metadata":{}},{"cell_type":"code","source":"X = train.drop(['customer_id','Name','security_no','churn_risk_score','joining_date','referral_id','last_visit_time'],axis=1)\ny = train['churn_risk_score']\nX_test = test.drop(['customer_id','Name','security_no','joining_date','referral_id','last_visit_time'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols1 = [col for col in X.columns if X[str(col)].dtype=='object']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## region_category\nd1 ={'Village':0, 'Town':1, 'City':2}\nl1=[]\nl2=[]\nfor i in X['region_category']:\n    l1.append(d1[i])\nX['region_category']= l1\n\nfor i in X_test['region_category']:\n    l2.append(d1[i])\nX_test['region_category'] = l2\n\n\n\n## membership_category\nd1 ={'No Membership':0, 'Basic Membership':1, 'Premium Membership':2, 'Silver Membership':3,'Gold Membership':4,'Platinum Membership':5  }\nl1=[]\nl2=[]\nfor i in X['membership_category']:\n    l1.append(d1[i])\nX['membership_category']= l1\n\nfor i in X_test['membership_category']:\n    l2.append(d1[i])\nX_test['membership_category']= l2\n\n\n\n##internet_options\nd1 ={'Without Offers':0, 'Credit/Debit Card Offers':1, 'Gift Vouchers/Coupons':2}\nl1=[]\nl2=[]\nfor i in X['preferred_offer_types']:\n    l1.append(d1[i])\nX['preferred_offer_types']= l1\n\nfor i in X_test['preferred_offer_types']:\n    l2.append(d1[i])\nX_test['preferred_offer_types'] = l2\n\n\n\n##internet_options\nd1 ={'Mobile_Data':0, 'Wi-Fi':1, 'Fiber_Optic':2}\nl1=[]\nl2=[]\nfor i in X['internet_option']:\n    l1.append(d1[i])\nX['internet_option']= l1\n\nfor i in X_test['internet_option']:\n    l2.append(d1[i])\nX_test['internet_option'] = l2\n\n\n\n\n##complaint_status\nd1 ={'Unsolved':0, 'Not Applicable':1, 'No Information Available':2, 'Solved in Follow-up':3, 'Solved':4}\nl1=[]\nl2=[]\nfor i in X['complaint_status']:\n    l1.append(d1[i])\nX['complaint_status']= l1\n\nfor i in X_test['complaint_status']:\n    l2.append(d1[i])\nX_test['complaint_status'] = l2\n\n\n\n##feedback\nd1 ={'Reasonable Price':1, 'Quality Customer Care':1, 'Too many ads':0, 'User Friendly Website':1, 'Poor Customer Service':0, 'No reason specified':0, 'Products always in Stock':1, 'Poor Website':0, 'Poor Product Quality':0 }\nl1=[]\nl2=[]\nfor i in X['feedback']:\n    l1.append(d1[i])\nX['feedback']= l1\n\nfor i in X_test['feedback']:\n    l2.append(d1[i])\nX_test['feedback'] = l2\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = [col for col in X.columns if X[str(col)].dtype=='object']\nnum_cols = [col for col in X.columns if X[str(col)].dtype!='object']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols_n = []\ni = 0\nfor col in X.columns:\n    if(X[str(col)].dtype=='object'):\n        cat_cols_n.append(i)\n    i = i+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nfor col in cat_cols:\n    X[str(col)] = le.fit_transform(X[str(col)])\n    X_test[str(col)] = le.transform(X_test[str(col)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(X.corr(),annot=True,vmin=-1,vmax=1,cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\nplt.figure(figsize=(10,10))\nimp = mutual_info_classif(X,y)\nfeat_imp = pd.Series(imp,X.columns)\nfeat_imp.plot(kind='barh', color='pink')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline Model","metadata":{}},{"cell_type":"code","source":"lg = LGBMClassifier()\nlg.fit(X_train,y_train)\ny_pred_l = lg.predict(X_dev)\nf1_score(y_dev,y_pred_l,average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred_r = rf.predict(X_dev)\nf1_score(y_dev,y_pred_r,average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xg = XGBClassifier(objective = 'multi:softprob')\nxg.fit(X_train,y_train)\ny_pred_x = xg.predict(X_dev)\nf1_score(y_dev,y_pred_x,average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection (Forward Selection)","metadata":{}},{"cell_type":"code","source":"from mlxtend.feature_selection import SequentialFeatureSelector\nffs =SequentialFeatureSelector(lg,k_features='best',forward=True, n_jobs=-1)\nffs.fit(X_train,y_train)\nfeatures = list(ffs.k_feature_names_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.feature_selection import SequentialFeatureSelector\nffs =SequentialFeatureSelector(rf,k_features='best',forward=True, n_jobs=-1)\nffs.fit(X_train,y_train)\nfeatures2 = list(ffs.k_feature_names_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(features2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lg.fit(X_train[features],y_train)\ny_pred_l = lg.predict(X_dev[features])\nf1_score(y_dev,y_pred_l,average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.fit(X_train[features2],y_train)\ny_pred_r = rf.predict(X_dev[features2])\nf1_score(y_dev,y_pred_r,average='macro')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':lg.predict(X_test[features])})\ndf.to_csv('submit.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':xg.predict(X_test)})\ndf2.to_csv('submit2.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':rf.predict(X_test[features2])})\ndf3.to_csv('submit3.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4 = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':(df['churn_risk_score']+df3['churn_risk_score'])//2})\ndf4.to_csv('submit4.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Will Keep updating, Stay tuned ","metadata":{}}]}