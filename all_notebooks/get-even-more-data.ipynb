{"cells":[{"metadata":{},"cell_type":"markdown","source":"This dataset has 3000 of the most common English words, along with their syllables. These words are parsed from the Merrian Webster Dictionary. However, if perhaps 3000 words were not enough, you could use the parsing code that I made, with a list of words you want to be parsed to make your own csv file. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Start by having access to a list of all the words that you want to find the syllables from\n# Here, I will manually make the list to demostrate quickly, but in reality you would probably read out of a txt file\n\n#Start by importing the neccessary modules\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\n#Now, get the list of words and make sure to turn it to a numpy array\nwords = np.array([\"happy\", \"angry\", \"sad\", \"emotional\"])\n\n#This is the main function to get the syllable\ndef get_syllable(word):\n    URL = 'https://www.merriam-webster.com/dictionary/{}'.format(word)\n    #Sometimes, trying to find a word such as 'Christian' may lead to a redirect error, so do this just in case\n    try:\n        page = requests.get(URL)\n    except:\n        return \"Error finding word\"\n    soup = BeautifulSoup(page.text, 'html.parser')\n    syllable = soup.find('span', {'class':'word-syllables'})\n    #If the word is too short for a syllable, you can just return 'No syllable'\n    if syllable == None:\n        return 'No syllable'\n    syllable = str(syllable).split('</span>')[0].split('s\">')[1]\n    syllable = \"-\".join(syllable.split('Â·'))\n    return syllable\n\nformed_words = np.array([get_syllable(word) for word in words])\n\n#Now, we will make the pandas DataFrame and export it as a csv to be used for later\ndf = pd.DataFrame({\n    \"word\":words,\n    \"syllable\":all_sep\n})\ndf.to_csv('syllable_word.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that parsing generally takes a long time. For me, it took around half an hour to parse 3000 words. Of course, this may vary depending on what device you are using. Also, Merriam Webster in my knowledge allows you to parse words without banning you from the website. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}