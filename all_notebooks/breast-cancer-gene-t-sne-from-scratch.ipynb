{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"width:100%;height:200px\">\n    <img src=\"https://storage.googleapis.com/kaggle-datasets-images/491250/914079/dbf2b107119670d835aa22ca4014fa47/dataset-cover.png?t=2020-01-28-11-41-41\"/>\n</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\n\nsns.set(rc={'figure.figsize':(11.7,8.27)})\npalette = sns.color_palette(\"bright\", 6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:black; background:yellow; border:0.5px dotted black;\" role=\"tab\" aria-controls=\"home\"><center>Prepare Data</center></h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/breast-cancer-gene-expression-cumida/'\n\ndf = pd.read_csv(path + 'Breast_GSE45827.csv', index_col='samples')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = df['type']\nfeatures = df.drop(columns=['type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_to_category = {k:v for k,v in enumerate(np.unique(labels.values))}\ncategory_to_idx = {v:k for k,v in enumerate(list(idx_to_category.values()))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = labels.replace(category_to_idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:black; background:yellow; border:0.5px dotted black;\" role=\"tab\" aria-controls=\"home\"><center>Sklearn t-SNE</center></h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne = TSNE()\nX_embedded = tsne.fit_transform(features.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=labels.values, legend='full', palette=palette)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:black; background:yellow; border:0.5px dotted black;\" role=\"tab\" aria-controls=\"home\"><center>Implementation from Scratch</center></h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Hbeta(D=np.array([]), beta=1.0):\n    \"\"\"\n        Compute the perplexity and the P-row for a specific value of the\n        precision of a Gaussian distribution.\n    \"\"\"\n\n    # Compute P-row and corresponding perplexity\n    P = np.exp(-D.copy() * beta)\n    sumP = sum(P)\n    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n    P = P / sumP\n    return H, P","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n    \"\"\"\n        Performs a binary search to get P-values in such a way that each\n        conditional Gaussian has the same perplexity.\n    \"\"\"\n\n    # Initialize some variables\n    print(\"Computing pairwise distances...\")\n    (n, d) = X.shape\n    sum_X = np.sum(np.square(X), 1)\n    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n    P = np.zeros((n, n))\n    beta = np.ones((n, 1))\n    logU = np.log(perplexity)\n\n    # Loop over all datapoints\n    for i in range(n):\n\n        # Print progress\n        if i % 500 == 0:\n            print(\"Computing P-values for point %d of %d...\" % (i, n))\n\n        # Compute the Gaussian kernel and entropy for the current precision\n        betamin = -np.inf\n        betamax = np.inf\n        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n        (H, thisP) = Hbeta(Di, beta[i])\n\n        # Evaluate whether the perplexity is within tolerance\n        Hdiff = H - logU\n        tries = 0\n        while np.abs(Hdiff) > tol and tries < 50:\n\n            # If not, increase or decrease precision\n            if Hdiff > 0:\n                betamin = beta[i].copy()\n                if betamax == np.inf or betamax == -np.inf:\n                    beta[i] = beta[i] * 2.\n                else:\n                    beta[i] = (beta[i] + betamax) / 2.\n            else:\n                betamax = beta[i].copy()\n                if betamin == np.inf or betamin == -np.inf:\n                    beta[i] = beta[i] / 2.\n                else:\n                    beta[i] = (beta[i] + betamin) / 2.\n\n            # Recompute the values\n            (H, thisP) = Hbeta(Di, beta[i])\n            Hdiff = H - logU\n            tries += 1\n\n        # Set the final row of P\n        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n\n    # Return final P-matrix\n    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n    return P","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pca(X=np.array([]), no_dims=50):\n    \"\"\"\n        Runs PCA on the NxD array X in order to reduce its dimensionality to\n        no_dims dimensions.\n    \"\"\"\n\n    print(\"Preprocessing the data using PCA...\")\n    (n, d) = X.shape\n    X = X - np.tile(np.mean(X, 0), (n, 1))\n    (l, M) = np.linalg.eig(np.dot(X.T, X))\n    Y = np.dot(X, M[:, 0:no_dims])\n    return Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n    \"\"\"\n        Runs t-SNE on the dataset in the NxD array X to reduce its\n        dimensionality to no_dims dimensions. The syntaxis of the function is\n        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n    \"\"\"\n\n    # Check inputs\n    if isinstance(no_dims, float):\n        print(\"Error: array X should have type float.\")\n        return -1\n    if round(no_dims) != no_dims:\n        print(\"Error: number of dimensions should be an integer.\")\n        return -1\n\n    # Initialize variables\n    X = pca(X, initial_dims).real\n    (n, d) = X.shape\n    max_iter = 200\n    initial_momentum = 0.5\n    final_momentum = 0.8\n    eta = 500\n    min_gain = 0.01\n    Y = np.random.randn(n, no_dims)\n    dY = np.zeros((n, no_dims))\n    iY = np.zeros((n, no_dims))\n    gains = np.ones((n, no_dims))\n\n    # Compute P-values\n    P = x2p(X, 1e-5, perplexity)\n    P = P + np.transpose(P)\n    P = P / np.sum(P)\n    P = P * 4.\n    P = np.maximum(P, 1e-12)\n\n    # Run iterations\n    for iter in range(max_iter):\n\n        # Compute pairwise affinities\n        sum_Y = np.sum(np.square(Y), 1)\n        num = -2. * np.dot(Y, Y.T)\n        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n        num[range(n), range(n)] = 0.\n        Q = num / np.sum(num)\n        Q = np.maximum(Q, 1e-12)\n\n        # Compute gradient\n        PQ = P - Q\n        for i in range(n):\n            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n\n        # Perform the update\n        if iter < 20:\n            momentum = initial_momentum\n        else:\n            momentum = final_momentum\n        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n        gains[gains < min_gain] = min_gain\n        iY = momentum * iY - eta * (gains * dY)\n        Y = Y + iY\n        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n\n        # Compute current value of cost function\n        if (iter + 1) % 10 == 0:\n            C = np.sum(P * np.log(P / Q))\n            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n\n        # Stop lying about P-values\n        if iter == 100:\n            P = P / 4.\n\n    # Return solution\n    return Y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:black; background:yellow; border:0.5px dotted black;\" role=\"tab\" aria-controls=\"home\"><center>Training</center></h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use < 2000 feature columns, otherwise we don't have enough RAM to process it\nX_embedded = tsne(features.values[:,:1000], 2, 50, 20.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=labels.values, legend='full', palette=palette)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}