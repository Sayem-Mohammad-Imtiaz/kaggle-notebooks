{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\n# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.pandas.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filename = \"../input/sms-spam-collection-dataset/spam.csv\"\ndf = pd.read_csv(filename, encoding = 'latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\ndf.columns = ['category', 'text']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Shape of the dataset, and breakdown of the classes\nprint(\"Input data has {} rows and {} columns\".format(len(df), len(df.columns)))\nprint(\"Out of {} rows, {} are spam, {} are ham\".format(len(df),len(df[df['category']=='spam']),len(df[df['category']=='ham'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing values in the dataset\nprint(\"Number of null in label: {}\".format(df['category'].isnull().sum()))\nprint(\"Number of null in text: {}\".format(df['text'].isnull().sum()))\nsns.countplot(x='category', data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing Word Clouds"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ham = df[df['category']=='ham']\ndf_spam = df[df['category']=='spam']\n#convert to list\nham_list=df_ham['text'].tolist()\nspam_list= df_spam['text'].tolist()\nfiltered_spam = (\"\").join(spam_list) #convert the list into a string of spam\nfiltered_spam = filtered_spam.lower()\nfiltered_ham = (\"\").join(ham_list) #convert the list into a string of ham\nfiltered_ham = filtered_ham.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\nwordcloud = WordCloud(max_font_size = 160, margin=0, background_color = \"white\", colormap=\"Reds\").generate(filtered_spam)\nplt.figure(figsize=[10,10])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.title(\"Spam Messages Word Cloud\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(max_font_size = 160, margin=0, background_color = \"white\", colormap=\"Greens\").generate(filtered_ham)\nplt.figure(figsize=[10,10])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.title(\"Ham Messages Word Cloud\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing the data\n## Cleaning the text"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    return re.sub('[^a-zA-Z]', ' ', text).lower()\ndf['cleaned_text'] = df['text'].apply(lambda x: clean_text(x))\ndf['label'] = df['category'].map({'ham':0, 'spam':1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding additional features - length of, and percentage of punctuations in the text"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_punct(text):\n    count = sum([1 for char in text if char in string.punctuation])\n    return round(count/(len(text) - text.count(\" \")), 3)*100\ndf['text_len'] = df['text'].apply(lambda x: len(x) - x.count(\" \"))\ndf['punct'] = df['text'].apply(lambda x: count_punct(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_text(text):\n    tokenized_text = text.split()\n    return tokenized_text\ndf['tokens'] = df['cleaned_text'].apply(lambda x: tokenize_text(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lemmatization and Removing Stopwords"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nall_stopwords = stopwords.words('english')\nall_stopwords.remove('not')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lemmatize_text(token_list):\n    return \" \".join([lemmatizer.lemmatize(token) for token in token_list if not token in set(all_stopwords)])\n\nlemmatizer = nltk.stem.WordNetLemmatizer()\ndf['lemmatized_text'] = df['tokens'].apply(lambda x: lemmatize_text(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction from Text\n## Bag-Of-Words Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['lemmatized_text', 'text_len', 'punct']]\ny = df['label']\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(max_df = 0.5, min_df = 2) # ignore terms that occur in more than 50% documents and the ones that occur in less than 2\ntfidf_train = tfidf.fit_transform(X_train['lemmatized_text'])\ntfidf_test = tfidf.transform(X_test['lemmatized_text'])\n\nX_train_vect = pd.concat([X_train[['text_len', 'punct']].reset_index(drop=True), \n           pd.DataFrame(tfidf_train.toarray())], axis=1)\nX_test_vect = pd.concat([X_test[['text_len', 'punct']].reset_index(drop=True), \n           pd.DataFrame(tfidf_test.toarray())], axis=1)\n\nX_train_vect.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training different Classification models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train_vect, y_train)\nnaive_bayes_pred = classifier.predict(X_test_vect)\n\n# Classification Report\nprint(classification_report(y_test, naive_bayes_pred))\n\n# Confusion Matrix\nclass_label = [\"ham\", \"spam\"]\ndf_cm = pd.DataFrame(confusion_matrix(y_test, naive_bayes_pred), index=class_label, columns=class_label)\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=150)\nclassifier.fit(X_train_vect, y_train)\nrandom_forest_pred = classifier.predict(X_test_vect)\n\n# Classification report\nprint(classification_report(y_test, random_forest_pred))\n\n# Confusion Matrix\nclass_label = [\"ham\", \"spam\"]\ndf_cm = pd.DataFrame(confusion_matrix(y_test, random_forest_pred), index=class_label, columns=class_label)\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\nclassifier.fit(X_train_vect, y_train)\nlog_reg_pred = classifier.predict(X_test_vect)\n# Classification report\nprint(classification_report(y_test, log_reg_pred))\n\n# Confusion Matrix\nclass_label = [\"ham\", \"spam\"]\ndf_cm = pd.DataFrame(confusion_matrix(y_test, log_reg_pred), index=class_label, columns=class_label)\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train_vect, y_train)\nsvm_pred = classifier.predict(X_test_vect)\n# Classification report\nprint(classification_report(y_test, svm_pred))\n\n# Confusion Matrix\nclass_label = [\"ham\", \"spam\"]\ndf_cm = pd.DataFrame(confusion_matrix(y_test, svm_pred), index=class_label, columns=class_label)\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5)\nclassifier.fit(X_train_vect, y_train)\nknn_pred = classifier.predict(X_test_vect)\n\n# Classification report\nprint(classification_report(y_test, knn_pred))\n\n# Confusion Matrix\nclass_label = [\"ham\", \"spam\"]\ndf_cm = pd.DataFrame(confusion_matrix(y_test, knn_pred), index=class_label, columns=class_label)\nsns.heatmap(df_cm, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The best performing algorithms so far seem to be Linear SVM, Random Forest and Logistic Regression Classifiers.\nAt this point, it might be worth to perform k-fold cross validation on each of these to estimate their skill on unseen data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nmodels = [LogisticRegression(), RandomForestClassifier(n_estimators = 150), SVC(kernel = 'linear')]\nnames = [\"Logistic Regression\", \"Random Forest\", \"SVM\"]\nfor model, name in zip(models, names):\n    print(name)\n    for score in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n        print(f\" {score} - {cross_val_score(model, X_train_vect, y_train, scoring=score, cv=10).mean()} \")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}