{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras import Model\nfrom keras.applications.mobilenet import MobileNet, preprocess_input\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\nfrom keras.layers import Conv2D, Reshape\nfrom keras.utils import Sequence\nfrom keras.backend import epsilon\nimport tensorflow as tf\n\nfrom PIL import Image\n\nimport os\nimport random\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport numpy as np\nimport cv2\n\nnp.random.seed(1)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading the training data from train.csv file","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/racoon-detection/train_labels_.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = train.sample()\n\nimg = cv2.imread(f'../input/racoon-detection/Racoon Images/images/{row.filename.values[0]}')\nxmin = row.xmin.values[0]\nymin = row.ymin.values[0]\nxmax = row.xmax.values[0]\nymax = row.ymax.values[0]\n\nimg = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color=(255, 0, 0), thickness=4)\nplt.imshow(img)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Create a list variable known as 'path' which has all the path for all the training images\n* Create an array 'coords' which has the resized coordinates of the bounding box for the training images","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coords = train[[\"width\",\"height\",\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n\ncoords[\"xmin\"] = coords[\"xmin\"] * IMAGE_SIZE / coords[\"width\"]\ncoords[\"xmax\"] = coords[\"xmax\"] * IMAGE_SIZE / coords[\"width\"]\ncoords[\"ymin\"] = coords[\"ymin\"] * IMAGE_SIZE / coords[\"height\"]\ncoords[\"ymax\"] = coords[\"ymax\"] * IMAGE_SIZE / coords[\"height\"]\n\ncoords.drop([\"width\",\"height\"], axis=1, inplace=True)\ncoords.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = train[\"filename\"]\nlen(paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = \"../input/racoon-detection/Racoon Images/images/\"\n\nbatch_images = np.zeros((len(paths), IMAGE_SIZE, IMAGE_SIZE,3), dtype=np.float32)\n\nfor i, f in enumerate(paths):\n    img = Image.open(images + f)\n    img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n    img = img.convert('RGB')\n    batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building\n* Building the model using transfer learning","metadata":{}},{"cell_type":"code","source":"model = MobileNet(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layers in model.layers:\n    layers.trainable = False\n\nx = model.layers[-1].output\nx = Conv2D(4, kernel_size=4, name=\"coords\")(x)\nx = Reshape((4,))(x)\n\nmodel = Model(inputs=model.inputs, outputs=x)\nmodel.summary()","metadata":{"scrolled":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define a custom loss function IoU which calculates Intersection Over Union","metadata":{}},{"cell_type":"code","source":"def loss(gt, pred):\n    intersections = 0\n    unions = 0\n    diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n    diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n    intersection = diff_width * diff_height\n    \n    # Compute union\n    area_gt = gt[:,2] * gt[:,3]\n    area_pred = pred[:,2] * pred[:,3]\n    union = area_gt + area_pred - intersection\n\n    # Compute intersection and union over multiple boxes\n    for j, _ in enumerate(union):\n        if union[j] > 0 and intersection[j] > 0 and union[j] >= intersection[j]:\n            intersections += intersection[j]\n            unions += union[j]\n\n    # Compute IOU. Use 1e-8 to prevent division by zero\n    iou = np.round(intersections / (unions + 1e-8), 4)\n    iou = iou.astype(np.float32)\n    return iou\n\n\ndef IoU(y_true, y_pred):\n    iou = tf.py_function(loss, [y_true, y_pred], tf.float32)\n    return iou","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compiling the model","metadata":{}},{"cell_type":"code","source":"gt = coords\n\nPATIENCE=10\n\nmodel.compile(optimizer=\"Adam\",\n              loss=\"mse\",\n              metrics=[IoU])\n\nstop = EarlyStopping(monitor='val_iou', patience=PATIENCE, mode=\"max\")\n\nreduce_lr = ReduceLROnPlateau(monitor='val_iou', factor=0.2, patience=PATIENCE,\n                              min_lr=1e-7, verbose=1, mode=\"max\")\n\nmodel.fit(batch_images, gt,\n          epochs=100,\n          callbacks=[stop, reduce_lr],\n          verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pick a test image from the given data","metadata":{}},{"cell_type":"code","source":"test_img = random.choice(paths)\nfilename = images + test_img\nunscaled = cv2.imread(filename)\nunscaled = cv2.cvtColor(unscaled, cv2.COLOR_BGR2RGB)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing of Test Image\nResizing the image to 128 * 128 and preprocess the image for the MobileNet model","metadata":{}},{"cell_type":"code","source":"image_height, image_width, _ = unscaled.shape\nimage = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\nfeat_scaled = preprocess_input(np.array(image, dtype=np.float32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Predict the coordinates of the bounding box for the given test image","metadata":{}},{"cell_type":"code","source":"region = model.predict(x=np.array([feat_scaled]))[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Scaling the BBox","metadata":{}},{"cell_type":"code","source":"x0 = int(region[0] * image_width / IMAGE_SIZE) \ny0 = int(region[1] * image_height / IMAGE_SIZE)\n\nx1 = int((region[2]) * image_width / IMAGE_SIZE)\ny1 = int((region[3]) * image_height / IMAGE_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting the predicted bounding box","metadata":{}},{"cell_type":"code","source":"unscaled = cv2.rectangle(unscaled, (x0, y0), (x1, y1), color=(255, 0, 0), thickness=2)\n\n# Display the image\nplt.imshow(unscaled)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}