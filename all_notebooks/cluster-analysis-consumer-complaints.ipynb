{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# necessary libraries \nimport numpy as np \nimport pandas as pd \nimport datetime as dt\n\n# for ploting and exploratory data analysis \nimport seaborn as sns \nimport matplotlib.pyplot as plt ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Reading the data__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"//kaggle//input//us-consumer-finance-complaints//consumer_complaints.csv\", low_memory=False)  \ndata.head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Preprocessing</h2>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Check for number of records__ ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Check for unique entries across data__","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for col in data.columns: \n    print(col,\":\",data[col].nunique(dropna=True)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The column <em>\"Complaint ID\"</em> has all unique entries, we can use __Complaint ID__ as index","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.set_index(\"complaint_id\") \ndata.head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Data Imputation__ ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# this function returns percentage of data missing from each column\ndef missing_summary(data): \n    total_rows = data.shape[0] \n    missing_rows = data.isnull().sum() \n    missing_summary = dict() \n    for i in range(0, missing_rows.shape[0]):\n        missing_summary[missing_rows.index[i]] = round(missing_rows[i] / total_rows, 4) * 100\n    return missing_summary \n\nmissing_data = missing_summary(data) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Summary Table for Missing Data__ <br> \n<ul>Percentage of missing values help in making decisions like removing or replacing the data. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data = pd.DataFrame.from_dict(missing_data, orient=\"index\", columns=[\"Percentage Missing\"]).reset_index()\nmissing_data.sort_values(by=\"Percentage Missing\", ascending=False)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Top column with missing data is__ <em>Tags</em>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tags.value_counts()\nplt.figure(figsize=(11, 6))\nsns.countplot(data.tags) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Background information__ \n<ul><li>Data that supports easier searching and sorting of complaints submitted by or on behalf of consumers</li>\n    <li> The services for Older Americans and Servicemen differ from typical customer</li> \n    <li>The tags can't be removed from the data as it gives vital information about customer and the type of service they receive.</li>\n</ul>\n&nbsp;<a>https://www.consumerfinance.gov/practitioner-resources/resources-for-older-adults/</a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Plan of Action__ \n<ul><li>Replace missing values with category \"Others\"</li>\n    <li>Each label to be encoded post visualization</li></ul> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"tags\"] = data.tags.replace(to_replace=np.nan, value=\"Others\") \ndata.tags[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tags.value_counts()\nplt.figure(figsize=(11, 6))\nsns.countplot(data.tags) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h4>Consumer consent provided?</h4>\n<br>\n<strong>Background information</strong> \n<ul><li>Whether a consumer opted in to publish their complaint narrative</li> \n    <li>This column has no bearing on the analysis, mostly concerned with privacy</li>\n    </ul>\n    <strong> Plan of Action</strong> \n    <ul><li>This column is to be removed</li></ul>\n    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"consumer_consent_provided\"].unique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"consumer_consent_provided\", axis=1, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Consumer complaint narrative__\n<ol><li> This is a transcript or summary of the complaint by the consumer, provides detailed description for complex cases</li> \n<li> Although this text can be processsed and top consumer grievances can be extrapolated, the same information overview can be gathered from data within other fields like <em>\"Issue\" and \"Sub-Issue\"</em></li>\n    <li>The objective is to perform Cluster analysis, extracting features from consumer narrative when 83% of data is missing is not ideal </li></ol>  \n<strong>Plan of Action</strong> \n<ul>This column is to be removed</ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"consumer_complaint_narrative\"].unique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"consumer_complaint_narrative\", axis=1, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h4> Company public response</h4>\n<br>\n<strong>Background information</strong> \n<ul><li>A company response comprises of one of ten standard responses</li> \n    <li>Company response for 78% of the cases is missing, implies that a bank doesn't issue a response for majority of the complaints</li>\n    </ul>\n    <strong> Plan of Action</strong> \n    <ul><li>Replace missing values with <em>\"No Response\"</em></li>\n    <li>Encode each category to check if the <em>Company response</em> has any bearing on complaints being disputed by the consumer</li></ul>\n    Note: No Response is different from cases where <em>\"Company chooses not to provide a public response\"</em> which is an official position of said company. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"company_public_response\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total number of complaints where a company chose to respond\ndata[\"company_public_response\"].value_counts().sum() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h5>The following is a visual break up to complaints where a company issued a response</h5>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sizes = data[\"company_public_response\"].value_counts()\nlabels = ['Responded to consumer and CFPB', 'No public response', 'Company acted within law', 'Misunderstanding',\n          'Disputes the facts', 'Actions of third party', 'Isolated error', \"Can't verify the facts\", \n          'Room for improvement in service', 'Discontinued policy']\n\ncmap = plt.get_cmap(\"tab20c\") \ncolors = cmap(np.arange(10) * 2)\nfig1, ax1 = plt.subplots()\nfig1.set_size_inches(10,10)\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, colors=colors, labeldistance=1.05,  \n        textprops={'fontsize': 14})\nax1.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing null values in Company public response with \"No response\" \ndata[\"company_public_response\"].fillna(\"No response\", inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if any null entries left\nprint(\"Missing entries in column -\", data[\"company_public_response\"].isnull().sum())  \nprint(\"Company public response\") \ndata[\"company_public_response\"].value_counts() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"consumer_disputed?\"].isnull()][\"company_public_response\"].value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.state.isnull()] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h4> Location: State and Zipcode</h4>\n<br>\n<strong>Background information</strong> \n<ul><li>One percent of the total complaints do not have the location information</li><li>Location includes all 50 states and military, commonwealths, and territories in United States of America</li><a>https://www.50states.com/abbreviations.htm</a> </ul>\n    <strong> Plan of Action</strong> \n    <ul><li>Further analysis is needed wheather location of consumer plays a role in resolving a complaint</li>\n    <li><strong><em>If we can prove complaints are treated equally regardless of their Location, then Location information is not needed for analysis</li>\n        <li>Remove less than one percent of data with missing location</li></ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for number of missing rows\ndata.state.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Statewise_Product_complaints = data.groupby(\"state\")[[\"product\"]].agg('count') \nStatewise_Product_complaints = Statewise_Product_complaints.sort_values(\"product\", ascending=False)\n\n# ploting statewise product usage\nplt.figure(figsize=(19,19))\nsns.barplot(x=\"product\", y=Statewise_Product_complaints.index, data=Statewise_Product_complaints, palette=\"Blues_d\") \nplt.title(\"Statewise Complaints\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Products_Across_State = pd.crosstab(data[\"state\"], data['product'], normalize=\"index\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Products_Across_State = Products_Across_State.T\nProducts_Across_State.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nyticks = Products_Across_State.index\nkeptticks = yticks[::int(len(yticks)/10)]\nyticks = ['' for y in yticks]\nyticks[::int(len(yticks)/10)] = keptticks\n\nxticks = Products_Across_State.columns\nkeptticks = xticks[::int(len(xticks)/10)]\nxticks = ['' for y in xticks]\nxticks[::int(len(xticks)/10)] = keptticks\n\nsns.heatmap(Products_Across_State, yticklabels=yticks, xticklabels=xticks, square=True, \n            cbar_kws={'fraction' : 0.01}, cmap='OrRd', linewidth=1.5)\n\n# This sets the yticks \"upright\" with 0, as opposed to sideways with 90.\nplt.yticks(rotation=0) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<ul>\n    <li>The heatmap of proportion of <em>financial Products</em> across all states is similar except for Mortgage </li>\n    <li>Further proof can be realized by Chi squared testm to find out if all the groups are similar or not</li>\n</ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import chi2_contingency \n\nchi_stat, p_value, dof, e_table = chi2_contingency(Products_Across_State)  \nprint(\"Chi Statistic = \", round(chi_stat, 3))  \nprint(\"P-value =\", p_value) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<ul>\n   <li>P-values suggests that we must reject the null hypothesis that is usage of products across different states may not be the same/li>\n<li><strong>Given the similar proportions, we would expect the test to find that the groups are similar and that the variables are independent (fail to reject the null hypothesis, or H0).</strong></li>\n    <li><em>All financial products are used similarly across all states</em></li>\n    </ul>\n    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"e_table[:1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<ul>\n<li>If all products are used irrespective of states, logically it follows that <strong>issues arising from these products are also similar across states</strong></li>\n</ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.issue.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Statewise_Issues = pd.crosstab(data[\"state\"], data[\"issue\"]) \nStatewise_Issues","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chi_stat, p_value, dof, e_table = chi2_contingency(Statewise_Issues)  \nprint(\"Chi Statistic = \", chi_stat) \nprint(\"P-value =\", p_value) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<ul><li>Contrary to our intitial assumption, location is not an independent factor when considering the Issue of the complaint</li></ul>\n<h5>Verdict</h5> \nThe State column is vital for data analysis, it cannot be removed","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h4> Location: Zipcode</h4>\n<br>\n<strong>Background information</strong> \n<ul><li>The granularity of location can be analyzed on basis of State, localiztion to specific zipcode can be eliminated for simplification in analysis</li> </ul>\n    <strong> Plan of Action</strong> \n    <ul><li>Zipcodes are to be removed</li></ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"zipcode\", axis=1, inplace=True) \ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting string to datetime \ndata[\"date_received\"] = pd.to_datetime(data[\"date_received\"]) \ndata[\"date_sent_to_company\"] = pd.to_datetime(data[\"date_sent_to_company\"])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Forwarding_time\"] = data[\"date_sent_to_company\"] - data[\"date_received\"]  \ndata.head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4> Dates - Recieved and Sent to the company</h4>\n<br>\n<strong>Background information</strong> \n<ul><li>These dates indicate the date at which the complaint has been forwarded to CFPB and not the date at which complaint has been filed with the Bank or the organization. </li> \n    <li>The Timely Response? column indicates wheather company has reponded or not, the date at which a third party is made aware of the complaint has no bearing on the complaint itself. </li>\n<li>Further more our derived column Forwarding time shows that these dates have no effect on resolution or timely response variables</li></ul>\n    <strong> Plan of Action</strong> \n    <ul><li>All dates are to be removed</li></ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"date_received\", \"date_sent_to_company\", \"Forwarding_time\"], axis=1, inplace=True)\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Sub-Product and Sub-Issue</h4>\n<br>\n<strong>Background information</strong> \n<ul><li>The specificity of product and issue is available for less than 40 percent of the data </li> \n    <li>Simplification of these categories can be achieved by grouping, which is already done with Product and Issue</li></ul>\n    <strong> Plan of Action</strong> \n    <ul><li>Both columns are to be removed</li></ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"sub_product\", \"sub_issue\"], axis=1, inplace=True)\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Consumer Disputed? </h4>\n<br>\n<strong>Background information</strong> \n<ul><li>6 percent of the data is missing</li> </ul>\n\n<strong> Plan of Action</strong>\n<ul><li>Imputation can be done by filling the most common responses</li></ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"common_response = data[\"consumer_disputed?\"].mode()\ncommon_response = \"No\"\n# replacing with most common consumer response\ndata[\"consumer_disputed?\"].fillna(common_response, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Timely Response per Product</h4>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(21, 6)) \nchart = sns.countplot(data[data[\"timely_response\"] == \"Yes\"][\"product\"], palette='Set1')    \nchart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right', fontweight='light', fontsize='x-large')\nplt.title(\"Timely Response? Yes\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(21, 6)) \nchart = sns.countplot(data[data[\"timely_response\"] == \"No\"][\"product\"], palette='Set1')    \nchart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right', fontweight='light', fontsize='x-large')\nplt.title(\"Timely Response? No\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Submitted Via </h4>\n<br>\n<strong>Background information</strong> \n<ul><li>Indicates the medium through which consumer contacted CPFB, has no bearing on analysis</li> </ul>\n\n<strong> Plan of Action</strong>\n<ul><li>Column to be removed</li></ul>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submitted = data[\"submitted_via\"].value_counts() \nitr = 0\nfor i in submitted:\n    print(submitted.index[itr], round(i / data.shape[0], 4))  \n    itr += 1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"not_timely = data[data[\"timely_response\"] == \"No\"] \nsubmitted = not_timely[\"submitted_via\"].value_counts() \nitr = 0\nfor i in submitted:\n    print(submitted.index[itr], round(i/data.shape[0], 4))  \n    itr += 1                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timely = data[data[\"timely_response\"] == \"Yes\"] \nsubmitted = timely[\"submitted_via\"].value_counts() \nitr = 0\nfor i in submitted:\n    print(submitted.index[itr], round(i/data.shape[0], 4))  \n    itr += 1  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"submitted_via\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# revaluating missing data\nmissing_data = missing_summary(data)  \nmissing_data = pd.DataFrame.from_dict(missing_data, orient=\"index\", columns=[\"Percentage Missing\"]).reset_index()\nmissing_data.sort_values(by=\"Percentage Missing\", ascending=False)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(inplace=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# revaluating missing data\nmissing_data = missing_summary(data)  \nmissing_data = pd.DataFrame.from_dict(missing_data, orient=\"index\", columns=[\"Percentage Missing\"]).reset_index()\nmissing_data.sort_values(by=\"Percentage Missing\", ascending=False)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding the data for clustering\ncols = data.columns\nfor col in cols:\n    data[col]=data[col].astype('category')\n\nencoded_data = pd.get_dummies(data[cols], columns=cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Creating a random sample of the encoded dataset</h4> \n<p> For reduced computation and easier clustering <br>Typical sampling problems class imbalance and representative sample are addressed by converting each category into encoded features</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Kmeans Algorithm</h4> \n<em>The Elbow Method to find the number of Optimal Clusters</em>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nwcss = []\nscore = [] \n\nfor i in range(2, 11):\n    km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    cluster_labels = km.fit_predict(encoded_data)\n    wcss.append(km.inertia_)\n    sil_scr = silhouette_score(encoded_data, cluster_labels)\n    score.append(sil_scr)\n    \nplt.plot(range(2, 11), wcss)\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}