{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://image.slidesharecdn.com/artimitateslifeargumenttoturnin-140310190421-phpapp01/95/art-imitates-life-3-638.jpg?cb=1394478444)"},{"metadata":{},"cell_type":"markdown","source":"# Introduction \n\n\" I don't think about art when I'm working. I try to think about life.\nI don’t listen to what art critics say. I don’t know anybody who needs a critic to find out what art is.\" -Jean Michel Basquiat\n\n* Art is often considered the process or product of deliberately arranging elements in a way that appeals to the senses or emotions. It encompasses a diverse range of human activities, creations and ways of expression, including music, literature, film, sculpture and paintings. The meaning of art is explored in a branch of philosophy known as aesthetics\n* The visual arts are art forms such as painting, drawing, printmaking, sculpture, ceramics, photography, video, filmmaking, design, crafts, and architecture. Many artistic disciplines such as performing arts, conceptual art, textile arts also involve aspects of visual arts as well as arts of other types"},{"metadata":{},"cell_type":"markdown","source":"# Problem Statement\n\n* With a collection of artworks of 50 of the most influential artists of all time, the aim is to create a **convolutional neural network** to recognise the artists looking at the colors used and the geometric patterns inside the pictures.\n* This could help detect forgeries in the art world with by being more accurate than even trained art critics at detecting the forgeries"},{"metadata":{},"cell_type":"markdown","source":"# Objective: \nDevelop an algorithm which will identify the artist when provided with a painting, with state of the art precision."},{"metadata":{},"cell_type":"markdown","source":"# Metric of Success\nAccuracy Score of 85%"},{"metadata":{},"cell_type":"markdown","source":"# Understanding the Context\n\nThis dataset contains three files:\n\n* artists.csv: dataset of information for each artist\n* images.zip: collection of images (full size), divided in folders and sequentially numbered\n* resized.zip: same collection but images have been resized and extracted from folder structure\n"},{"metadata":{},"cell_type":"markdown","source":"# Experimental Design\n\nCRISP-DM, which stands for Cross-Industry Standard Process for Data Mining, is an industry-proven way to guide your data mining efforts. This is the methodology that will be used to deploy this classification experiment . The steps are as seen below:\n* Business understanding - assessing the situation (fact finding)\n* Data understanding - acquire the data,understand the strengths and weaknesses.\n* Data Preparation - cleaning the data and performing feature engineering\n* Data modelling -identify the modelling technique\n* Evaluation - gauging whether the standard to which the model meets the set business objectives\n* Deployment - summarizing the stationung approach inclusing the necessary steps that are taken and how they were performed"},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries and Loading the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.filterwarnings('ignore')      \n# Used to ignore the warnings displayed by python\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nsesion 2\n3 months ago\nkernel55e6634486\n84.5s\n0 B\n+2\n0\n￼\n￼\nt_random_seed(1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3e1d6335355d0c30e566597c839a5b3ece5d94a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"artists = pd.read_csv('../input/artists.csv')\nartists ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here's a short description of each column: \n\n| Features      |       Description|\n|---|---|\n|Name | shows the artist's name|\n|Years | artist's years on earth|\n|Genre | the artist's style of art|\n|Nationality | the artist's country of origin|\n|Bio | details about the artist |\n|Wikipidea | a link to the artist's wikipedia page|\n|Paintings | number of paintings the artist has |\n\n\n* Some columns like id, bio and wikipedia are irrelevant and we will therefore drop them later on ."},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape of the dataset \nprint('Our dataset has', artists.shape[0], 'rows and', artists.shape[1], 'columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirming the datatypes\nartists.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the columns are objects except id and paintings, whose datatypes are integers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# statistical summary of the datasets\nartists.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for duplicates\nartists.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for null values\n\nartists.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It seems like our dataset is free of duplicates and null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting infromation on the dataset\nartists.info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From here we can see the name of each artist available on the dataset, together with their nationality  and the genre of their paintings,bios and wikipedia links.\n* Because there are some artists that are well known but aren't on the dataset I will append them on to the csv as well as add a file of their images."},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the unique features\nartists.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Before perfroming any feature engineering we will do away with the irrelevant columns so that we can add more columns that will help give us better information on the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the irrelevant columns\nartists.drop(columns=['id','bio','wikipedia'],inplace =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Processing and Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"* We selected the artists who had more than 200 paintings and created a new dataframe called artists_top.\n* This is done to have enough samples to test and improve the model in future.\n* With this dataset we will create a new column titled class_weight where we will assign weights that will be inversely correlated to the number of paintings an artist has(the more paintings an artist has the lower the the class weight)\n* This means that underrepresented artists get a higher weight to even out the data"},{"metadata":{"_uuid":"6b074e12d27e326be77c2e045b0f0c1f9ae26822","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Sort artists by number of paintings\nartists = artists.sort_values(by=['paintings'], ascending=False)\n\n# Create a dataframe with artists having more than 200 paintings\nartists_top = artists[artists['paintings'] >= 200].reset_index()\nartists_top = artists_top[['name', 'paintings']]\n#artists_top['class_weight'] = max(artists_top.paintings)/artists_top.paintings\nartists_top['class_weight'] = artists_top.paintings.sum() / (artists_top.shape[0] * artists_top.paintings)\nartists_top","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Set class weights - assign higher weights to underrepresented classes\nclass_weights = artists_top['class_weight'].to_dict()\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56cb379b335dd98d09038a6a2a0a4c674cf85435","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Explore images of top artists\nimages_dir = '../input/images/images'\nartists_dirs = os.listdir(images_dir)\nartists_top_name = artists_top['name'].str.replace(' ', '_').values\n\n# See if all directories exist\nfor name in artists_top_name:\n    if os.path.exists(os.path.join(images_dir, name)):\n        print(\"Found -->\", os.path.join(images_dir, name))\n    else:\n        print(\"Did not find -->\", os.path.join(images_dir, name))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1572ec7821c7520ff56c95a9fddb29e7b3211d72","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# There is some problem recognizing 'Albrecht_Dürer' (don't know why, worth exploring)\n# So I'll update this string as directory name to df's\nupdated_name = \"Albrecht_Du╠êrer\".replace(\"_\", \" \")\nartists_top.iloc[4, 0] = updated_name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have updated the name of the artist. Let's see how it goes..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore images of top artists\nimages_dir = '../input/images/images'\nartists_dirs = os.listdir(images_dir)\nartists_top_name = artists_top['name'].str.replace(' ', '_').values\n\n# See if all directories exist\nfor name in artists_top_name:\n    if os.path.exists(os.path.join(images_dir, name)):\n        print(\"Found -->\", os.path.join(images_dir, name))\n    else:\n        print(\"Did not find -->\", os.path.join(images_dir, name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It worked!**"},{"metadata":{},"cell_type":"markdown","source":"# Print few random paintings"},{"metadata":{"_uuid":"6e9a979dcc6c7d65e76bb9ad7cbe0af46210835c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Print few random paintings\nn = 5\nfig, axes = plt.subplots(1, n, figsize=(20,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top_name)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n    image = plt.imread(random_image_file)\n    axes[i].imshow(image)\n    axes[i].set_title(\"Artist: \" + random_artist.replace('_', ' '))\n    axes[i].axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"698097f73386d42c88605975b1c0624c5b810828"},"cell_type":"markdown","source":"# **Data Augmentation**"},{"metadata":{},"cell_type":"markdown","source":"- This helps us to significantly increases the diversity of data available for training models, without actually collecting new data.\n- In the dataset we see that we only have 27 images per artist so we need to augment the data to increase the diversity thus increasing the accuracy of the model"},{"metadata":{"_uuid":"c0dc10a5ef7bf1c7b4d4d219f0b5e5fe168c1200","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"sion 2\n3 months ago\nkernel55e6634486\n84.5s\n0 B\n+2\n0\n￼\n￼\n# Augment data\nbatch_size = 16\ntrain_input_shape = (224, 224, 3)\nn_classes = artists_top.shape[0]\n\ntrain_datagen = ImageDataGenerator(validation_split=0.2,\n                                   rescale=1./255.,\n                                   #rotation_range=45,\n                                   #width_shift_range=0.5,\n                                   #height_shift_range=0.5,\n                                   shear_range=5,\n                                   #zoom_range=0.7,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                  )\n\ntrain_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"training\",\n                                                    shuffle=True,\n                                                    classes=artists_top_name.tolist()\n                                                   )\n\nvalid_generator = train_datagen.flow_from_directory(directory=images_dir,\n                                                    class_mode='categorical',\n                                                    target_size=train_input_shape[0:2],\n                                                    batch_size=batch_size,\n                                                    subset=\"validation\",\n                                                    shuffle=True,\n                                                    classes=artists_top_name.tolist()\n                                                   )\n\nSTEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\nprint(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Print a random paintings and it's random augmented version"},{"metadata":{"_uuid":"215b02db59c36acee06eb148ab061cb30b1d4a04","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Print a random paintings and it's random augmented version\nfig, axes = plt.subplots(1, 2, figsize=(20,10))\n\nrandom_artist = random.choice(artists_top_name)\nrandom_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\nrandom_image_file = os.path.join(images_dir, random_artist, random_image)\n\n# Original image\nimage = plt.imread(random_image_file)\naxes[0].imshow(image)\naxes[0].set_title(\"An original Image of \" + random_artist.replace('_', ' '))\naxes[0].axis('off')\n\n# Transformed image\naug_image = train_datagen.random_transform(image)\naxes[1].imshow(aug_image)\naxes[1].set_title(\"A transformed Image of \" + random_artist.replace('_', ' '))\naxes[1].axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c14ac6b596ba8035bfb6aa23080f9e792ab16a7"},"cell_type":"markdown","source":"## Build Model"},{"metadata":{"_uuid":"217cffe30d19bbcd8ad2db5f088efeca507b9105","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Load pre-trained model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n\nfor layer in base_model.layers:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7418f1308e35730185e027cdba1aa76ca825a922","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Add layers at the end\nX = base_model.output\nX = Flatten()(X)\n\nX = Dense(512, kernel_initializer='he_uniform')(X)\n#X = Dropout(0.5)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\nX = Dense(16, kernel_initializer='he_uniform')(X)\n#X = Dropout(0.5)(X)\nX = BatchNormalization()(X)\nX = Activation('relu')(X)\n\noutput = Dense(n_classes, activation='softmax')(X)\n\nmodel = Model(inputs=base_model.input, outputs=output)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53800d997e58514ae857fb0286c5ea89eed90eef","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"optimizer = Adam(lr=0.0001)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78ed50a86faf5e1621dd6f8273dbfb6803c74a44","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"n_epoch = 10\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n                           mode='auto', restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              verbose=1, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51535a7919f1972b1ea8eb45019380e8cd31074d","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Train the model - all layers\nhistory1 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr],\n                              use_multiprocessing=True,\n                              workers=16,\n                              class_weight=class_weights\n                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Freeze core ResNet layers and train again \nfor layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[:50]:\n    layer.trainable = True\n\noptimizer = Adam(lr=0.0001)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizer, \n              metrics=['accuracy'])\n\nn_epoch = 50\nhistory2 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator, validation_steps=STEP_SIZE_VALID,\n                              epochs=n_epoch,\n                              shuffle=True,\n                              verbose=1,\n                              callbacks=[reduce_lr, early_stop],\n                              use_multiprocessing=True,\n                              workers=16,\n                              class_weight=class_weights\n                             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training graph"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Merge history1 and history2\nhistory = {}\nhistory['loss'] = history1.history['loss'] + history2.history['loss']\nhistory['acc'] = history1.history['acc'] + history2.history['acc']\nhistory['val_loss'] = history1.history['val_loss'] + history2.history['val_loss']\nhistory['val_acc'] = history1.history['val_acc'] + history2.history['val_acc']\nhistory['lr'] = history1.history['lr'] + history2.history['lr']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Plot the training graph\ndef plot_training(history):\n    acc = history['acc']\n    val_acc = history['val_acc']\n    loss = history['loss']\n    val_loss = history['val_loss']\n    epochs = range(len(acc))\n\n    fig, axes = plt.subplots(1, 2, figsize=(15,5))\n    \n    axes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\n    axes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\n    axes[0].set_title('Training and Validation Accuracy')\n    axes[0].legend(loc='best')\n\n    axes[1].plot(epochs, loss, 'r-', label='Training Loss')\n    axes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\n    axes[1].set_title('Training and Validation Loss')\n    axes[1].legend(loc='best')\n    \n    plt.show()\n    \nplot_training(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate performance"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Prediction accuracy on train data\nscore = model.evaluate_generator(train_generator, verbose=1)\nprint(\"Prediction accuracy on train data =\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Prediction accuracy on CV data\nscore = model.evaluate_generator(valid_generator, verbose=1)\nprint(\"Prediction accuracy on CV data =\", score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion Matrix. \nThis looks at the style of the artists which the model thinks are almost similar. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Classification report and confusion matrix\nfrom sklearn.metrics import *\nimport seaborn as sns\n\ntick_labels = artists_top_name.tolist()\n\ndef showClassficationReport_Generator(model, valid_generator, STEP_SIZE_VALID):\n    # Loop on each generator batch and predict\n    y_pred, y_true = [], []\n    for i in range(STEP_SIZE_VALID):\n        (X,y) = next(valid_generator)\n        y_pred.append(model.predict(X))\n        y_true.append(y)\n    \n    # Create a flat list for y_true and y_pred\n    y_pred = [subresult for result in y_pred for subresult in result]\n    y_true = [subresult for result in y_true for subresult in result]\n    \n    # Update Truth vector based on argmax\n    y_true = np.argmax(y_true, axis=1)\n    y_true = np.asarray(y_true).ravel()\n    \n    # Update Prediction vector based on argmax\n    y_pred = np.argmax(y_pred, axis=1)\n    y_pred = np.asarray(y_pred).ravel()\n    \n    # Confusion Matrix\n    fig, ax = plt.subplots(figsize=(10,10))\n    conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(n_classes))\n    conf_matrix = conf_matrix/np.sum(conf_matrix, axis=1)\n    sns.heatmap(conf_matrix, annot=True, fmt=\".2f\", square=True, cbar=False, \n                cmap=plt.cm.jet, xticklabels=tick_labels, yticklabels=tick_labels,\n                ax=ax)\n    ax.set_ylabel('Actual')\n    ax.set_xlabel('Predicted')\n    ax.set_title('Confusion Matrix')\n    plt.show()\n    \n    print('Classification Report:')\n    print(classification_report(y_true, y_pred, labels=np.arange(n_classes), target_names=artists_top_name.tolist()))\n\nshowClassficationReport_Generator(model, valid_generator, STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate performance by predicting on random images from dataset"},{"metadata":{"_uuid":"fcd185d451d3b9f2484b58ace18a5466524c2ab4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Prediction\nfrom keras.preprocessing import *\n\nn = 5\nfig, axes = plt.subplots(1, n, figsize=(25,10))\n\nfor i in range(n):\n    random_artist = random.choice(artists_top_name)\n    random_image = random.choice(os.listdir(os.path.join(images_dir, random_artist)))\n    random_image_file = os.path.join(images_dir, random_artist, random_image)\n\n    # Original image\n\n    test_image = image.load_img(random_image_file, target_size=(train_input_shape[0:2]))\n\n    # Predict artist\n    test_image = image.img_to_array(test_image)\n    test_image /= 255.\n    test_image = np.expand_dims(test_image, axis=0)\n\n    prediction = model.predict(test_image)\n    prediction_probability = np.amax(prediction)\n    prediction_idx = np.argmax(prediction)\n\n    labels = train_generator.class_indices\n    labels = dict((v,k) for k,v in labels.items())\n\n    #print(\"Actual artist =\", random_artist.replace('_', ' '))\n    #print(\"Predicted artist =\", labels[prediction_idx].replace('_', ' '))\n    #print(\"Prediction probability =\", prediction_probability*100, \"%\")\n\n    title = \"Actual artist = {}\\nPredicted artist = {}\\nPrediction probability = {:.2f} %\" \\\n                .format(random_artist.replace('_', ' '), labels[prediction_idx].replace('_', ' '),\n                        prediction_probability*100)\n\n    # Print image\n    axes[i].imshow(plt.imread(random_image_file))\n    axes[i].set_title(title)\n    axes[i].axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The portion below is just for fun :) We will replace the variable `url` with an image of one of the 11 artists above then run this cell."},{"metadata":{"_uuid":"c4f0217bee7b62f835645372f4107c803d7ede2b","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# Predict from web - this is an image of Titian.\n# Replace 'url' with any image of one of the 11 artists above and run this cell.\nurl = 'https://www.gpsmycity.com/img/gd/2081.jpg'\n\nimport imageio\nimport cv2\n\nweb_image = imageio.imread(url)\nweb_image = cv2.resize(web_image, dsize=train_input_shape[0:2], )\nweb_image = image.img_to_array(web_image)\nweb_image /= 255.\nweb_image = np.expand_dims(web_image, axis=0)\n\n\nprediction = model.predict(web_image)\nprediction_probability = np.amax(prediction)\nprediction_idx = np.argmax(prediction)\n\nprint(\"Predicted artist =\", labels[prediction_idx].replace('_', ' '))\nprint(\"Prediction probability =\", prediction_probability*100, \"%\")\n\nplt.imshow(imageio.imread(url))\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}