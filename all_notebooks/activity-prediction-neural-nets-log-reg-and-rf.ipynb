{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.1"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"23a32ec021f8fea64e1c39f2122dd1ce2cf927ef","trusted":false,"_cell_guid":"28b20c99-7b2b-4d5c-a778-6ee5fd2a1e0f","_execution_state":"idle"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport matplotlib.pyplot as plt\n\n# Any results you write to the current directory are saved as output.","outputs":[],"cell_type":"code","execution_count":23},{"metadata":{"_uuid":"fe8a87060f1499a5ba53aca22b5dfebb0b603a8d","collapsed":false,"_execution_state":"idle"},"source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\ntrain_df.columns","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"ab01b61331e1653149ba1f3aa30f03da0c43cb4a","collapsed":false,"_execution_state":"idle"},"source":"unique_activities = train_df.Activity.unique()\nprint(\"NUmber of unique activities: {}\".format(len(unique_activities)))\nreplacer = {}\nfor i, activity in enumerate(unique_activities):\n    replacer[activity] = i\ntrain_df.Activity = train_df.Activity.replace(replacer)\ntest_df.Activity = test_df.Activity.replace(replacer)\ntrain_df.head(10)","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"c525c41c722e4818ffc7df83cd89cc79b936f128","collapsed":false,"_execution_state":"idle"},"source":"train_df = train_df.drop(\"subject\", axis=1)\ntest_df = test_df.drop(\"subject\", axis=1)","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"92049d38b19738e79d796e14d8ac99c3083ece93","collapsed":false,"_execution_state":"idle"},"source":"def get_all_data():\n    train_values = train_df.values\n    test_values = test_df.values\n    np.random.shuffle(train_values)\n    np.random.shuffle(test_values)\n    X_train = train_values[:, :-1]\n    X_test = test_values[:, :-1]\n    y_train = train_values[:, -1]\n    y_test = test_values[:, -1]\n    return X_train, X_test, y_train, y_test","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"d6ed876c6b08edbe9da5b2e743f7b726f434c3ae","collapsed":false,"_execution_state":"idle"},"source":"from sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = get_all_data()\nmodel = LogisticRegression(C=10)\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"a76fe068ff2434aa72e4807bc968dc8998e4cb28","collapsed":false,"_execution_state":"idle"},"source":"# Try some transformations\nfrom sklearn.decomposition import PCA\n\nX_train, X_test, y_train, y_test = get_all_data()\npca = PCA(n_components=200)\npca.fit(X_train)\nX_train = pca.transform(X_train)\nX_test = pca.transform(X_test)\n\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)\n# Worse performance, but trains faster","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"782d70157322ec52fdcc946d6a63d4e0bb638bb3","collapsed":false,"_execution_state":"idle"},"source":"# Scale features to be between -1 and 1\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train, X_test, y_train, y_test = get_all_data()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)\n# Better performance","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"4d287d6927a4a371923f7319bd36b2354f0b4178","collapsed":false,"_execution_state":"idle"},"source":"# Neural network\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils.np_utils import to_categorical\n\nX_train, X_test, y_train, y_test = get_all_data()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nn_input = X_train.shape[1] # number of features\nn_output = 6 # number of possible labels\nn_samples = X_train.shape[0] # number of training samples\nn_hidden_units = 40\n\nY_train = to_categorical(y_train)\nY_test = to_categorical(y_test)\nprint(Y_train.shape)\nprint(Y_test.shape)\n\ndef create_model():\n    model = Sequential()\n    model.add(Dense(n_hidden_units,\n                    input_dim=n_input,\n                    activation=\"relu\"))\n    model.add(Dense(n_hidden_units,\n                    input_dim=n_input,\n                    activation=\"relu\"))\n    model.add(Dense(n_output, activation=\"softmax\"))\n\n    # Compile model\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    return model\n\n\n","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"787d5c459d4dd2a5ff03bee0fe1b13d232a65a8d","collapsed":false,"_execution_state":"idle"},"source":"estimator = KerasClassifier(build_fn=create_model, epochs=20, batch_size=10, verbose=False)\nestimator.fit(X_train, Y_train)\nprint(\"Score: {}\".format(estimator.score(X_test, Y_test)))","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"d0e7ef4a6a50dbc773d3f86bd724083feacb9208","collapsed":false,"_execution_state":"idle"},"source":"from sklearn.ensemble import RandomForestClassifier\n\nX_train, X_test, y_train, y_test = get_all_data()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nmodel = RandomForestClassifier(n_estimators=500)\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"89698deeb64515cc5a0a6ce62d93e03a1ab626cd","collapsed":false,"_execution_state":"idle"},"source":"","outputs":[],"execution_count":null,"cell_type":"code"}]}