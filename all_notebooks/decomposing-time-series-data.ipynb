{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Decomposing Time Series Data into Trend and Seasonality","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-20T12:03:38.16227Z","iopub.execute_input":"2021-05-20T12:03:38.16288Z","iopub.status.idle":"2021-05-20T12:03:38.184351Z","shell.execute_reply.started":"2021-05-20T12:03:38.162791Z","shell.execute_reply":"2021-05-20T12:03:38.182927Z"}}},{"cell_type":"markdown","source":"Time series decomposition involves thinking of a series as a combination of level, trend, seasonality, and noise components.\n\nDecomposition provides a useful abstract model for thinking about time series generally and for better understanding problems during time series analysis and forecasting.\n\nIn this notebook we will learn about the different **time series components** and learn how to automatically **split a time series into it's components using Python.**\n\nIt's always useful to break down time series into it's components before applying forecasting models. The two components are:\n\n1). **Systematic Component**s: As the name suggests, it means that the time-series has a system or in other words has recurrence that can be modeled.\n\n2). **Non-Systematic Components**: Components of the time series that can not be modeled.\n\nWe are going to have a look at these components and how to model them as we move ahead!\n\n**Do upvote the notebook if you liked it!**","metadata":{}},{"cell_type":"markdown","source":"## Importing the libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use(\"fivethirtyeight\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.149445Z","iopub.execute_input":"2021-05-20T13:48:34.150116Z","iopub.status.idle":"2021-05-20T13:48:34.169052Z","shell.execute_reply.started":"2021-05-20T13:48:34.149993Z","shell.execute_reply":"2021-05-20T13:48:34.167994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/time-series-forecasting-with-yahoo-stock-price/yahoo_stock.csv', parse_dates = ['Date'], index_col = 'Date')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.191102Z","iopub.execute_input":"2021-05-20T13:48:34.19146Z","iopub.status.idle":"2021-05-20T13:48:34.226607Z","shell.execute_reply.started":"2021-05-20T13:48:34.19143Z","shell.execute_reply":"2021-05-20T13:48:34.225621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.227919Z","iopub.execute_input":"2021-05-20T13:48:34.228199Z","iopub.status.idle":"2021-05-20T13:48:34.25487Z","shell.execute_reply.started":"2021-05-20T13:48:34.22817Z","shell.execute_reply":"2021-05-20T13:48:34.253895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are six columns given:**\n\n**High** -> Highest Price of the stock for that particular date.\n\n**Low** -> Lowest Price of the stock for that particular date.\n\n**Open** -> Opening Price of the stock.\n\n**Close** -> Closing Price of the stock.\n\n**Volume** -> Total amount of Trading Activity.\n\n**AdjClos**e -> Adjusted values factor in corporate actions such as dividends, stock splits, and new share issuance.","metadata":{}},{"cell_type":"code","source":"print(df.index.min())\nprint(df.index.max())","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.290043Z","iopub.execute_input":"2021-05-20T13:48:34.290453Z","iopub.status.idle":"2021-05-20T13:48:34.299395Z","shell.execute_reply.started":"2021-05-20T13:48:34.290417Z","shell.execute_reply":"2021-05-20T13:48:34.297319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.40183Z","iopub.execute_input":"2021-05-20T13:48:34.402193Z","iopub.status.idle":"2021-05-20T13:48:34.407465Z","shell.execute_reply.started":"2021-05-20T13:48:34.402162Z","shell.execute_reply":"2021-05-20T13:48:34.406689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Stock Price for 1825 days are given in this dataset, starting from 23rd November 2015 to 20th November 2020.","metadata":{}},{"cell_type":"code","source":"df[['High', 'Low']].plot(figsize = (15, 5), alpha = 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.408728Z","iopub.execute_input":"2021-05-20T13:48:34.409147Z","iopub.status.idle":"2021-05-20T13:48:34.793103Z","shell.execute_reply.started":"2021-05-20T13:48:34.409117Z","shell.execute_reply":"2021-05-20T13:48:34.792223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['Open', 'Close']].plot(figsize = (15, 5), alpha = 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:34.794896Z","iopub.execute_input":"2021-05-20T13:48:34.795408Z","iopub.status.idle":"2021-05-20T13:48:35.079775Z","shell.execute_reply.started":"2021-05-20T13:48:34.795373Z","shell.execute_reply":"2021-05-20T13:48:35.078947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe that there are no huge variations in the opening-closing price and the high-low prices. \n\n* There were huge dips in the stock prices 2 times, once close to 2019(due to Brexit) and once in March 2020(owing to Pandemic). \n\n* There was an overall increase in the stock price from 2017 to 2018.\n\n* The stock prices started to increase from the latter half for the year 2020\n\n* The stock price went drastically down from starting of 2018 to 2019","metadata":{}},{"cell_type":"markdown","source":"## Decomposition","metadata":{}},{"cell_type":"markdown","source":"A given time series is thought to consist of **three systematic components including level, trend, seasonality,** and one non-systematic component called **noise.**\n\nThese components are defined as follows:\n\n* **Level:** The average value in the series.\n\n* **Trend**: The increasing or decreasing value in the series.\n\n* **Seasonality:** The repeating short-term cycle in the series.\n\n* **Noise:** The random variation in the series.\n\nAll series have a level and noise. The trend and seasonality components are optional. It is helpful to think of the components as combining either **additively or multiplicatively.**\n\nAn **additive model** suggests that the components are added together as follows:\n\n> **y(t) = Level + Trend + Seasonality + Noise**\n\nAn additive model is linear where changes over time are consistently made by the same amount. A linear seasonality has the same frequency (width of cycles) and amplitude (height of cycles).\n\nA **multiplicative model** suggests that the components are multiplied together as follows:\n\n> **y(t) = Level * Trend * Seasonality * Noise**\n\nA multiplicative model is nonlinear, such as quadratic or exponential. Changes increase or decrease over time. A non-linear seasonality has an increasing or decreasing frequency and/or amplitude over time.\n\nDecomposition provides a structured way of thinking about a time series forecasting problem, both generally in terms of modeling complexity and specifically in terms of how to best capture each of these components in a given model.\n\nEach of these components are something you may need to think about and address during data preparation, model selection, and model tuning. You may address it explicitly in terms of modeling the trend and subtracting it from your data, or implicitly by providing enough history for an algorithm to model a trend if it may exist.\n\nIn order to implement the naive or classical decomposition method, we use the seasonal_decompose() method provided by the statsmodels library. It requires you to specify whether the model is Additive or Multiplicative. ","metadata":{}},{"cell_type":"markdown","source":"## Decompoistion Implementation","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndef decompose(df, column_name):\n    \"\"\"\n    A function that returns the trend, seasonality and residual captured by applying both multiplicative and\n    additive model.\n    df -> DataFrame\n    column_name -> column_name for which trend, seasonality is to be captured\n    \"\"\"\n    result_mul = seasonal_decompose(df[column_name], model='multiplicative', extrapolate_trend = 'freq')\n    result_add = seasonal_decompose(df[column_name], model = 'additive', extrapolate_trend='freq')\n\n    plt.rcParams.update({'figure.figsize': (20, 10)})\n    result_mul.plot().suptitle('Multiplicative Decompose', fontsize=30)\n    result_add.plot().suptitle('Additive Decompose', fontsize=30)\n    plt.show()\n    \n    return result_mul, result_add","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:35.081301Z","iopub.execute_input":"2021-05-20T13:48:35.081907Z","iopub.status.idle":"2021-05-20T13:48:36.016002Z","shell.execute_reply.started":"2021-05-20T13:48:35.081869Z","shell.execute_reply":"2021-05-20T13:48:36.015182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **seasonal_decompose() function returns a result object**. The result object contains arrays to access four pieces of data from the decomposition: Observed Series, Trend, Seasonality, and residual. We have plotted both Multiplicative as well as Additive model, so that we can decide which one of the two should be used.","metadata":{}},{"cell_type":"markdown","source":"## Open","metadata":{}},{"cell_type":"code","source":"result_mul, result_add = decompose(df, 'Open')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:36.017222Z","iopub.execute_input":"2021-05-20T13:48:36.017732Z","iopub.status.idle":"2021-05-20T13:48:38.229748Z","shell.execute_reply.started":"2021-05-20T13:48:36.017699Z","shell.execute_reply":"2021-05-20T13:48:38.228877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The residuals plotted should not be following any kind of pattern, it should be spread randomly. \n\nWe can see that the trend and seasonality information extracted from the series does seem reasonable. The residuals are also interesting, showing periods of high variability during the rapid falls and rise in the series.\n\nThe trend can be clearly observed in the plots above. We had also said that decomposing using additive model will represent the series as a sum of seasonality, trend and residual. Let's check that out:","metadata":{}},{"cell_type":"code","source":"df_reconstructed = pd.concat([result_add.seasonal, result_add.trend, result_add.resid, result_add.observed], axis = 1)\ndf_reconstructed.columns = ['seas', 'trend', 'resid', 'actual_values']\ndf_reconstructed","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:38.230992Z","iopub.execute_input":"2021-05-20T13:48:38.23152Z","iopub.status.idle":"2021-05-20T13:48:38.25011Z","shell.execute_reply.started":"2021-05-20T13:48:38.231484Z","shell.execute_reply":"2021-05-20T13:48:38.249059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Indeed, the sum of the columns seas, trend and resid is equal to the actual values.**\n\nLet's try it out for other columns too.","metadata":{}},{"cell_type":"markdown","source":"## Close","metadata":{}},{"cell_type":"code","source":"result_mul, result_add = decompose(df, 'Close')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:38.251531Z","iopub.execute_input":"2021-05-20T13:48:38.251884Z","iopub.status.idle":"2021-05-20T13:48:40.345354Z","shell.execute_reply.started":"2021-05-20T13:48:38.251852Z","shell.execute_reply":"2021-05-20T13:48:40.341665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reconstructed = pd.concat([result_add.seasonal, result_add.trend, result_add.resid, result_add.observed], axis = 1)\ndf_reconstructed.columns = ['seas', 'trend', 'resid', 'actual_values']\ndf_reconstructed","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:40.34708Z","iopub.execute_input":"2021-05-20T13:48:40.347554Z","iopub.status.idle":"2021-05-20T13:48:40.368485Z","shell.execute_reply.started":"2021-05-20T13:48:40.347504Z","shell.execute_reply":"2021-05-20T13:48:40.367328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## High","metadata":{}},{"cell_type":"code","source":"result_mul, result_add = decompose(df, 'High')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:40.372157Z","iopub.execute_input":"2021-05-20T13:48:40.372931Z","iopub.status.idle":"2021-05-20T13:48:42.474236Z","shell.execute_reply.started":"2021-05-20T13:48:40.372884Z","shell.execute_reply":"2021-05-20T13:48:42.473101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reconstructed = pd.concat([result_add.seasonal, result_add.trend, result_add.resid, result_add.observed], axis = 1)\ndf_reconstructed.columns = ['seas', 'trend', 'resid', 'actual_values']\ndf_reconstructed","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:42.475951Z","iopub.execute_input":"2021-05-20T13:48:42.476269Z","iopub.status.idle":"2021-05-20T13:48:42.500053Z","shell.execute_reply.started":"2021-05-20T13:48:42.476236Z","shell.execute_reply":"2021-05-20T13:48:42.499041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Low","metadata":{}},{"cell_type":"code","source":"result_mul, result_add = decompose(df, 'Low')","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:42.501414Z","iopub.execute_input":"2021-05-20T13:48:42.501756Z","iopub.status.idle":"2021-05-20T13:48:44.751747Z","shell.execute_reply.started":"2021-05-20T13:48:42.501725Z","shell.execute_reply":"2021-05-20T13:48:44.750609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reconstructed = pd.concat([result_add.seasonal, result_add.trend, result_add.resid, result_add.observed], axis = 1)\ndf_reconstructed.columns = ['seas', 'trend', 'resid', 'actual_values']\ndf_reconstructed","metadata":{"execution":{"iopub.status.busy":"2021-05-20T13:48:44.753437Z","iopub.execute_input":"2021-05-20T13:48:44.753942Z","iopub.status.idle":"2021-05-20T13:48:44.77712Z","shell.execute_reply.started":"2021-05-20T13:48:44.753892Z","shell.execute_reply":"2021-05-20T13:48:44.775986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In this way, we are able to capture the trend, seasonality and residuals. By looking at these parameters, we can use trend or seasonality as features or use it to study the time-series dataset.**\n\n**Hope you enjoyed the notebook and most importantly learnt something new.**\n\n**Do upvote the notebook if you liked it!**","metadata":{}}]}