{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div style=\"background-color:#05806c;display:block;padding:10px;\"><h1 style=\"color:#ffffff;\">Text Mining using Gensim Library</h1></div>\n\n## Overview\nText mining is also known as Text Analytics. It is a branch of **Artificial Intelligence(AI)** that uses **Natural Language Processing(NLP)** to transform unstructured text data into normalized and structured data that can be used for Machine Learning model. \n\nTextual data also has huge business values such as companies can use the data to help profile customers and understand their needs.\n\n## NLP Pipeline\n\nNatural Language Processing(NLP) pipeline is a set of text preprocessing and feature extraction steps that are performed in a sequential manner. The length of the pipeline varies from one usecase to another usecase and also the kind of text data we are dealing with. \n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\npd.set_option('display.max_colwidth', -1)\n\n# dataset\nfrom sklearn.datasets import fetch_20newsgroups\n\n# Gensim packages\nfrom gensim.parsing import strip_tags, strip_numeric, strip_multiple_whitespaces, stem_text, strip_punctuation, remove_stopwords\nfrom gensim.parsing import preprocess_string\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Loading Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading dataset\nnews_group = fetch_20newsgroups(subset='train')\n\nnews_group_data = news_group.data\nnews_group_target_names = news_group.target_names\nnews_group_target = news_group.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataframe from the loaded data\nnews_df = pd.DataFrame({'news': news_group_data, \n                        'class': news_group_target})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random sampling \n\nWe will take some of the records randomly as sample from the loaded dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"news_extracts = news_df.sample(2000)\n\nnews_extracts.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_extracts.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Data Cleaning Pipeline\n\nThis is going to be the first step of Text analysis. We will be applying various cleaning algorithms to remove unwanted elements from the text data. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom filter method\ntransform_to_lower = lambda s: s.lower()\n\nremove_single_char = lambda s: re.sub(r'\\s+\\w{1}\\s+', '', s)\n\n# Filters to be executed in pipeline\nCLEAN_FILTERS = [strip_tags,\n                strip_numeric,\n                strip_punctuation, \n                strip_multiple_whitespaces, \n                transform_to_lower,\n                remove_stopwords,\n                remove_single_char]\n\n# Method does the filtering of all the unrelevant text elements\ndef cleaning_pipe(document):\n    # Invoking gensim.parsing.preprocess_string method with set of filters\n    processed_words = preprocess_string(document, CLEAN_FILTERS)\n    \n    return processed_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply the cleaning pipe on the news data\n\nnews_extracts['clean_text'] = news_extracts['news'].apply(cleaning_pipe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_extracts['clean_text'][0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 2. Stemming & Lemmatization\n\n**Stemming**-Stemming is a technique of finding root word of the given word. For example, if a word is 'running' then the stem word of that word is 'run'.\n\n**Lemmatization**-Lemmatization refers to find the axle word by doing vocabulary and morphological analysis of the words.\n\n### Stemming Approaches\n\n#### #1 gensim.parsing.stem()\nThere is an inbuilt method called **stem()** in **parsing** package of gensim. It does the stemming(PorterStemming) on the given text. \n\n#### #2 PorterStemmer \nThe basic approach on stemming is using `PorterStemmer` object. Gensim has a porter stemmer class in `gensim.parsing.porter` package. The class has different functions to accept input as word, sentence and list of sentences. \n\n#### #3 Chain along pipes & filters\nAnother approach is chain the stem_text method in the cleaning pipeline filter and pass it as a parameter to `preprocess_string()` function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import stemmer from gensim\nfrom gensim import parsing\nfrom gensim.parsing.porter import PorterStemmer\nfrom gensim.summarization import textcleaner\n\n# Initialize PorterStemmer\nporter = PorterStemmer()\n\ndef basic_stemming(text):\n    return parsing.stem_text(text)\n\n# Stem the incoming word\ndef get_stemword(stemmer, word):    \n    return stemmer.stem(word)\n# stem all the words in the passed sentence\ndef get_stem_sentence(stemmer, sentence):\n    return stemmer.stem_sentence(sentence)\n\n# stem all the sentences given as a document\ndef get_stem_documents(stemmer, document):\n    return stemmer.stem_documents(document)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Suppose that the following paragraph needs to be processed to find the stem words for Nouns, Verbs, Adjactives and so on. Then it can be first broken into sentences and then passed to `stem_stencences()` method. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"document = \"\"\"A computer is a machine that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming. \nModern computers have the ability to follow generalized sets of operations, called programs. \nThese programs enable computers to perform an extremely wide range of tasks. \nA complete computer including the hardware, the operating system (main software), and peripheral equipment required and used for full operation can be referred to as a computer system. \nThis term may as well be used for a group of computers that are connected and work together, in particular a computer network or computer cluster.\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stem the given paragraph text \nstemmed_text = basic_stemming(document)\n\nprint(stemmed_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Break the paragraph into sentences\nsentences = textcleaner.get_sentences(document)\n\n# Sentences will be parsed by stem method\nstem_doc = get_stem_documents(porter, sentences)\n\nprint(stem_doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}