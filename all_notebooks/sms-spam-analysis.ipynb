{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-10T18:46:15.470958Z","iopub.execute_input":"2021-06-10T18:46:15.471362Z","iopub.status.idle":"2021-06-10T18:46:15.480914Z","shell.execute_reply.started":"2021-06-10T18:46:15.471324Z","shell.execute_reply":"2021-06-10T18:46:15.479798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport chardet\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:15.485662Z","iopub.execute_input":"2021-06-10T18:46:15.486001Z","iopub.status.idle":"2021-06-10T18:46:15.49693Z","shell.execute_reply.started":"2021-06-10T18:46:15.485968Z","shell.execute_reply":"2021-06-10T18:46:15.496114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the encoding style of the input csv file.By mentioning the encoding style in read_csv(), we can avoid the chances of getting an error due to encoding style mismatch \nwith open('../input/sms-spam-collection-dataset/spam.csv', 'rb') as rawdata:\n    encode_style =  chardet.detect(rawdata.read(100000))\nprint(encode_style)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:15.498343Z","iopub.execute_input":"2021-06-10T18:46:15.49879Z","iopub.status.idle":"2021-06-10T18:46:16.455145Z","shell.execute_reply.started":"2021-06-10T18:46:15.498755Z","shell.execute_reply":"2021-06-10T18:46:16.454058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',encoding='Windows-1252')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.456876Z","iopub.execute_input":"2021-06-10T18:46:16.457188Z","iopub.status.idle":"2021-06-10T18:46:16.475524Z","shell.execute_reply.started":"2021-06-10T18:46:16.457154Z","shell.execute_reply":"2021-06-10T18:46:16.474307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the data information \n# the last 3 column (Unnamed: 2, Unnamed: 3, Unnamed: 4) has maximum null values.To confirm the same, we will do another check using isnull()\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.477574Z","iopub.execute_input":"2021-06-10T18:46:16.478185Z","iopub.status.idle":"2021-06-10T18:46:16.493557Z","shell.execute_reply.started":"2021-06-10T18:46:16.478134Z","shell.execute_reply":"2021-06-10T18:46:16.492523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# there is no missing values in first two column but maximum values are missing in the last 3 columns. So, we will drop these last 3 columns \ndata.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.495Z","iopub.execute_input":"2021-06-10T18:46:16.495363Z","iopub.status.idle":"2021-06-10T18:46:16.508723Z","shell.execute_reply.started":"2021-06-10T18:46:16.495327Z","shell.execute_reply":"2021-06-10T18:46:16.507597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the last 3 columns\ndata.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.510311Z","iopub.execute_input":"2021-06-10T18:46:16.510658Z","iopub.status.idle":"2021-06-10T18:46:16.524043Z","shell.execute_reply.started":"2021-06-10T18:46:16.510623Z","shell.execute_reply":"2021-06-10T18:46:16.522943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To increase the readbility , lets change the column name of first two column (v1 and v2)\ndata.columns = ['Label','Message']","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.525307Z","iopub.execute_input":"2021-06-10T18:46:16.525739Z","iopub.status.idle":"2021-06-10T18:46:16.537459Z","shell.execute_reply.started":"2021-06-10T18:46:16.525709Z","shell.execute_reply":"2021-06-10T18:46:16.536192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the data \ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.538662Z","iopub.execute_input":"2021-06-10T18:46:16.539044Z","iopub.status.idle":"2021-06-10T18:46:16.562126Z","shell.execute_reply.started":"2021-06-10T18:46:16.539014Z","shell.execute_reply":"2021-06-10T18:46:16.561307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To understand the details information of these two column. \ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.564856Z","iopub.execute_input":"2021-06-10T18:46:16.565368Z","iopub.status.idle":"2021-06-10T18:46:16.593679Z","shell.execute_reply.started":"2021-06-10T18:46:16.565336Z","shell.execute_reply":"2021-06-10T18:46:16.592512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a new column to understand the charactertistics of two type message label \ndata['Message_length'] = data['Message'].apply(len)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.595628Z","iopub.execute_input":"2021-06-10T18:46:16.595908Z","iopub.status.idle":"2021-06-10T18:46:16.604207Z","shell.execute_reply.started":"2021-06-10T18:46:16.59588Z","shell.execute_reply":"2021-06-10T18:46:16.602888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the distribution of message size\ndata.groupby('Label')['Message_length'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.605561Z","iopub.execute_input":"2021-06-10T18:46:16.605889Z","iopub.status.idle":"2021-06-10T18:46:16.642708Z","shell.execute_reply.started":"2021-06-10T18:46:16.60586Z","shell.execute_reply":"2021-06-10T18:46:16.641676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The mean length of spam messages are larger than the mean length of the ham messages. Usually, the length of the spam messages are larger in length of the non-spam messages. To verify it again, we will check the distribution plot ","metadata":{}},{"cell_type":"code","source":"dist_message = data['Message_length'].hist(bins=100,by=data['Label'],figsize=(10,6))\ndist_message[0].set_xlabel(\"Message Length\")\ndist_message[0].set_ylabel(\"Freequency\")\ndist_message[1].set_xlabel(\"Message Length\")\ndist_message[1].set_ylabel(\"Freequency\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:16.644379Z","iopub.execute_input":"2021-06-10T18:46:16.644816Z","iopub.status.idle":"2021-06-10T18:46:17.474804Z","shell.execute_reply.started":"2021-06-10T18:46:16.64477Z","shell.execute_reply":"2021-06-10T18:46:17.473559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using this basic EDA we can understand that the spam messages are larger in length. In message label = ham distrbution, we can see that there is a message whose length is much higher than the other messages in ham group. Now, it is difficult to get the actual length of this long message from this plot. \nFrom the output of our previous data.groupby('Label')['Message_length'].describe(), we \ncan see that the max length is 910. \nNow, we can also check which message is this in ham group. ","metadata":{}},{"cell_type":"code","source":"# To find out the message which has a length of 910 \ndata[data['Message_length'] == 910]['Message'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:17.478536Z","iopub.execute_input":"2021-06-10T18:46:17.479037Z","iopub.status.idle":"2021-06-10T18:46:17.486265Z","shell.execute_reply.started":"2021-06-10T18:46:17.478982Z","shell.execute_reply":"2021-06-10T18:46:17.485452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data pre-processing","metadata":{}},{"cell_type":"markdown","source":"we need to clean the messages before processing further","metadata":{}},{"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:17.487611Z","iopub.execute_input":"2021-06-10T18:46:17.488126Z","iopub.status.idle":"2021-06-10T18:46:17.50326Z","shell.execute_reply.started":"2021-06-10T18:46:17.488092Z","shell.execute_reply":"2021-06-10T18:46:17.502249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To convert the normal text strings in a list of tokens(these tokens will be needed in next step) we will use the following function:","metadata":{}},{"cell_type":"code","source":" \n\ndef text_clean(message):\n    \n    # first, remove all punctuation\n    nopunc = [letter for letter in message if letter not in string.punctuation]\n    punc_filtered = \"\".join(nopunc)\n    # second, remove all stopwords\n    return [words for words in punc_filtered.split(\" \") if words.lower() not in stopwords.words('english')]\n    # return the words as list ","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:17.504622Z","iopub.execute_input":"2021-06-10T18:46:17.505045Z","iopub.status.idle":"2021-06-10T18:46:17.518675Z","shell.execute_reply.started":"2021-06-10T18:46:17.505012Z","shell.execute_reply":"2021-06-10T18:46:17.517201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As an example,we can see how this text_clean() works on messages :\n","metadata":{}},{"cell_type":"code","source":"data['Message'].apply(text_clean)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:17.520251Z","iopub.execute_input":"2021-06-10T18:46:17.520638Z","iopub.status.idle":"2021-06-10T18:46:27.949991Z","shell.execute_reply.started":"2021-06-10T18:46:17.520605Z","shell.execute_reply":"2021-06-10T18:46:27.949028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The original dataframe is:\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:27.951267Z","iopub.execute_input":"2021-06-10T18:46:27.951612Z","iopub.status.idle":"2021-06-10T18:46:27.962243Z","shell.execute_reply.started":"2021-06-10T18:46:27.951558Z","shell.execute_reply":"2021-06-10T18:46:27.961263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before performing Vectorization, we will divide the dataset into training and test set to avoid Data leakage. Once these partitions are done, we will convert each of these sets(training and test set) into vectors\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:27.96362Z","iopub.execute_input":"2021-06-10T18:46:27.963924Z","iopub.status.idle":"2021-06-10T18:46:27.974992Z","shell.execute_reply.started":"2021-06-10T18:46:27.963895Z","shell.execute_reply":"2021-06-10T18:46:27.973783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we are using only the 'Message' column to perform the classfication and we are taking 70% of dataset as training data and the remainder 30% as test set.","metadata":{}},{"cell_type":"code","source":"x_Train,x_Test,y_Train,y_Test = train_test_split(data['Message'],data['Label'],test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:27.976579Z","iopub.execute_input":"2021-06-10T18:46:27.97692Z","iopub.status.idle":"2021-06-10T18:46:27.990976Z","shell.execute_reply.started":"2021-06-10T18:46:27.976876Z","shell.execute_reply":"2021-06-10T18:46:27.990125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vectorization","metadata":{}},{"cell_type":"markdown","source":"To convert the messages into a vector with which SciKit Learn's model can work, we will use the \nbag-of-words model:","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:27.992173Z","iopub.execute_input":"2021-06-10T18:46:27.992608Z","iopub.status.idle":"2021-06-10T18:46:28.003586Z","shell.execute_reply.started":"2021-06-10T18:46:27.992563Z","shell.execute_reply":"2021-06-10T18:46:28.002257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we will use our defined text_clean() as the analyzer:","metadata":{}},{"cell_type":"code","source":"train_bow = CountVectorizer(analyzer=text_clean).fit(x_Train)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:28.005255Z","iopub.execute_input":"2021-06-10T18:46:28.005738Z","iopub.status.idle":"2021-06-10T18:46:35.488813Z","shell.execute_reply.started":"2021-06-10T18:46:28.005688Z","shell.execute_reply":"2021-06-10T18:46:35.487852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total number of vocab words\nprint(len(train_bow.vocabulary_))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:35.490541Z","iopub.execute_input":"2021-06-10T18:46:35.490943Z","iopub.status.idle":"2021-06-10T18:46:35.49672Z","shell.execute_reply.started":"2021-06-10T18:46:35.490898Z","shell.execute_reply":"2021-06-10T18:46:35.495472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to see the entire vocabulary\n#train_bow.vocabulary_   # execute this command to see the entire vocabulary and the index position of each word","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:35.497977Z","iopub.execute_input":"2021-06-10T18:46:35.498272Z","iopub.status.idle":"2021-06-10T18:46:35.512279Z","shell.execute_reply.started":"2021-06-10T18:46:35.498242Z","shell.execute_reply":"2021-06-10T18:46:35.511547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can take one message as a sampel and can see how bag or words model works:\n\nSamp_message = data['Message'][3]\n# the samepl message is U dun say so early hor... U c already then say...\nbow_samp = train_bow.transform([Samp_message])\nprint(bow_samp)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:35.51323Z","iopub.execute_input":"2021-06-10T18:46:35.5135Z","iopub.status.idle":"2021-06-10T18:46:35.529946Z","shell.execute_reply.started":"2021-06-10T18:46:35.513474Z","shell.execute_reply":"2021-06-10T18:46:35.529097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this output, we can understand that there are seven unique words(after removing common stop words)in the sampel message( which is actually the 4th message of dataframe).\nTwo of them appear twice, the rest only once. We can check  and confirm that which word is appearing twice ","metadata":{}},{"cell_type":"code","source":"print(train_bow.get_feature_names()[3190])\nprint(train_bow.get_feature_names()[7659])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:35.530994Z","iopub.execute_input":"2021-06-10T18:46:35.531425Z","iopub.status.idle":"2021-06-10T18:46:35.555624Z","shell.execute_reply.started":"2021-06-10T18:46:35.531393Z","shell.execute_reply":"2021-06-10T18:46:35.554704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As exepcted, U and Say are the two word that are apperaing twice ","metadata":{}},{"cell_type":"markdown","source":"Now to transform the entire training data set messages:\n","metadata":{}},{"cell_type":"code","source":"train_matrix = train_bow.transform(x_Train)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:35.556949Z","iopub.execute_input":"2021-06-10T18:46:35.557431Z","iopub.status.idle":"2021-06-10T18:46:43.059538Z","shell.execute_reply.started":"2021-06-10T18:46:35.55739Z","shell.execute_reply":"2021-06-10T18:46:43.058593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a result, we will get a sparse matrix.To get the shape of ths matrix and to check the number of non zero entries in the matrix:\n","metadata":{}},{"cell_type":"code","source":"print('Shape of Sparse Matrix: ', train_matrix.shape)\nprint('Amount of Non-Zero occurences: ', train_matrix.nnz)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:43.064637Z","iopub.execute_input":"2021-06-10T18:46:43.064935Z","iopub.status.idle":"2021-06-10T18:46:43.070181Z","shell.execute_reply.started":"2021-06-10T18:46:43.064906Z","shell.execute_reply":"2021-06-10T18:46:43.06915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To assign a weight to each word of the vocabulary, we will use TF-IDF. The words which has higher freequency will be assigned less weighatge and the words which are rare and has lower freequency will be assigned higher weighatge. ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:43.071878Z","iopub.execute_input":"2021-06-10T18:46:43.072174Z","iopub.status.idle":"2021-06-10T18:46:43.084052Z","shell.execute_reply.started":"2021-06-10T18:46:43.072135Z","shell.execute_reply":"2021-06-10T18:46:43.083052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_idf_train = TfidfTransformer().fit(train_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:43.085244Z","iopub.execute_input":"2021-06-10T18:46:43.085546Z","iopub.status.idle":"2021-06-10T18:46:43.101143Z","shell.execute_reply.started":"2021-06-10T18:46:43.085518Z","shell.execute_reply":"2021-06-10T18:46:43.100221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages_tf_idf_train = tf_idf_train.transform(train_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:43.102318Z","iopub.execute_input":"2021-06-10T18:46:43.102594Z","iopub.status.idle":"2021-06-10T18:46:43.116485Z","shell.execute_reply.started":"2021-06-10T18:46:43.102566Z","shell.execute_reply":"2021-06-10T18:46:43.115464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To confirm that the word with higher freequency has given a lower weightage than the word with lower freequency, we will consider two word from the entire document- 'want' and 'come'(more freequent)","metadata":{}},{"cell_type":"code","source":"print(tf_idf_train.idf_[train_bow.vocabulary_['want']])\nprint(tf_idf_train.idf_[train_bow.vocabulary_['come']])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:43.118276Z","iopub.execute_input":"2021-06-10T18:46:43.118716Z","iopub.status.idle":"2021-06-10T18:46:43.130502Z","shell.execute_reply.started":"2021-06-10T18:46:43.11867Z","shell.execute_reply":"2021-06-10T18:46:43.129765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"as the word 'come' is more frequent than 'want' in the entire dataframe, it receives lower weightage ","metadata":{}},{"cell_type":"markdown","source":"Now, we will convert the test set. \n","metadata":{}},{"cell_type":"code","source":"test_matrix = train_bow.transform(x_Test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:43.131375Z","iopub.execute_input":"2021-06-10T18:46:43.131626Z","iopub.status.idle":"2021-06-10T18:46:46.265778Z","shell.execute_reply.started":"2021-06-10T18:46:43.131601Z","shell.execute_reply":"2021-06-10T18:46:46.264649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_idf_test = TfidfTransformer().fit(test_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.26713Z","iopub.execute_input":"2021-06-10T18:46:46.267502Z","iopub.status.idle":"2021-06-10T18:46:46.273961Z","shell.execute_reply.started":"2021-06-10T18:46:46.267465Z","shell.execute_reply":"2021-06-10T18:46:46.272895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages_tf_idf_test = tf_idf_test.transform(test_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.275184Z","iopub.execute_input":"2021-06-10T18:46:46.275585Z","iopub.status.idle":"2021-06-10T18:46:46.291263Z","shell.execute_reply.started":"2021-06-10T18:46:46.275553Z","shell.execute_reply":"2021-06-10T18:46:46.290056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we will use two scikit-learn models. Naive Bayes and KNN and will compare their accuracy.","metadata":{}},{"cell_type":"markdown","source":"# Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.292489Z","iopub.execute_input":"2021-06-10T18:46:46.292785Z","iopub.status.idle":"2021-06-10T18:46:46.307806Z","shell.execute_reply.started":"2021-06-10T18:46:46.292755Z","shell.execute_reply":"2021-06-10T18:46:46.30668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we will create an instance of Naive Bayes and will fit it using our training data. ","metadata":{}},{"cell_type":"code","source":"nb = MultinomialNB()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.309482Z","iopub.execute_input":"2021-06-10T18:46:46.310189Z","iopub.status.idle":"2021-06-10T18:46:46.322231Z","shell.execute_reply.started":"2021-06-10T18:46:46.310129Z","shell.execute_reply":"2021-06-10T18:46:46.321428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb.fit(messages_tf_idf_train,y_Train)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.323673Z","iopub.execute_input":"2021-06-10T18:46:46.324063Z","iopub.status.idle":"2021-06-10T18:46:46.352501Z","shell.execute_reply.started":"2021-06-10T18:46:46.324021Z","shell.execute_reply":"2021-06-10T18:46:46.351781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = nb.predict(messages_tf_idf_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.353769Z","iopub.execute_input":"2021-06-10T18:46:46.354039Z","iopub.status.idle":"2021-06-10T18:46:46.364008Z","shell.execute_reply.started":"2021-06-10T18:46:46.354013Z","shell.execute_reply":"2021-06-10T18:46:46.363248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To check the performance of the model, we will use classification report and accuracy score from scikit learn module","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.365282Z","iopub.execute_input":"2021-06-10T18:46:46.365798Z","iopub.status.idle":"2021-06-10T18:46:46.380709Z","shell.execute_reply.started":"2021-06-10T18:46:46.365767Z","shell.execute_reply":"2021-06-10T18:46:46.37982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Classification report is: \")\nprint(classification_report(y_Test,y_pred))\nprint(\"Accuracy Score is: \")\nprint(accuracy_score(y_Test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.382026Z","iopub.execute_input":"2021-06-10T18:46:46.382581Z","iopub.status.idle":"2021-06-10T18:46:46.466486Z","shell.execute_reply.started":"2021-06-10T18:46:46.382537Z","shell.execute_reply":"2021-06-10T18:46:46.465322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN:","metadata":{}},{"cell_type":"markdown","source":"We can use GridSearchCV to identify the best value of k for KNN model. But instead of using GridSearchCv, we can guess the best value of K in the following way: ","metadata":{}},{"cell_type":"markdown","source":"we are assuming that the best value of K lies in between 1 to 40. we are creating an instance of KNN here and trying to mesaure the prediction error made by that instance of KNN.","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.467804Z","iopub.execute_input":"2021-06-10T18:46:46.468121Z","iopub.status.idle":"2021-06-10T18:46:46.472545Z","shell.execute_reply.started":"2021-06-10T18:46:46.468089Z","shell.execute_reply":"2021-06-10T18:46:46.471495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nerror_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(messages_tf_idf_train,y_Train)\n    y_pred_elbow = knn.predict(messages_tf_idf_test)\n    error = np.mean((y_Test != y_pred_elbow))\n    error_rate.append(error)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:46.474007Z","iopub.execute_input":"2021-06-10T18:46:46.47477Z","iopub.status.idle":"2021-06-10T18:46:56.138899Z","shell.execute_reply.started":"2021-06-10T18:46:46.474733Z","shell.execute_reply":"2021-06-10T18:46:56.137796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,linestyle='--',marker='o',markersize=8,markerfacecolor='red')\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:56.140127Z","iopub.execute_input":"2021-06-10T18:46:56.140459Z","iopub.status.idle":"2021-06-10T18:46:56.308309Z","shell.execute_reply.started":"2021-06-10T18:46:56.140426Z","shell.execute_reply":"2021-06-10T18:46:56.307352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can understand that the error rate is increaseing after K=5. The minimum error that we can get in this task is for k=3 or k=5. \nThe error rate for k=4 will be higher than k=3 or k=5. \nWe will check the performance for these two k value.","metadata":{}},{"cell_type":"code","source":"knn_3 = KNeighborsClassifier(n_neighbors=3)\nknn_3.fit(messages_tf_idf_train,y_Train)\ny_pred = knn_3.predict(messages_tf_idf_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:56.309564Z","iopub.execute_input":"2021-06-10T18:46:56.309872Z","iopub.status.idle":"2021-06-10T18:46:56.538063Z","shell.execute_reply.started":"2021-06-10T18:46:56.309842Z","shell.execute_reply":"2021-06-10T18:46:56.537065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Classification report is: \")\nprint(classification_report(y_Test,y_pred))\nprint(\"Accuracy Score is: \")\nprint(accuracy_score(y_Test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:46:56.539408Z","iopub.execute_input":"2021-06-10T18:46:56.539709Z","iopub.status.idle":"2021-06-10T18:46:56.626296Z","shell.execute_reply.started":"2021-06-10T18:46:56.539679Z","shell.execute_reply":"2021-06-10T18:46:56.625249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For K= 5","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:47:11.962413Z","iopub.execute_input":"2021-06-10T18:47:11.962797Z","iopub.status.idle":"2021-06-10T18:47:11.967188Z","shell.execute_reply.started":"2021-06-10T18:47:11.96276Z","shell.execute_reply":"2021-06-10T18:47:11.966158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_5 = KNeighborsClassifier(n_neighbors=5)\nknn_5.fit(messages_tf_idf_train,y_Train)\ny_pred = knn_5.predict(messages_tf_idf_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:47:16.37977Z","iopub.execute_input":"2021-06-10T18:47:16.380132Z","iopub.status.idle":"2021-06-10T18:47:16.637423Z","shell.execute_reply.started":"2021-06-10T18:47:16.380097Z","shell.execute_reply":"2021-06-10T18:47:16.636281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Classification report is: \")\nprint(classification_report(y_Test,y_pred))\nprint(\"Accuracy Score is: \")\nprint(accuracy_score(y_Test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:47:21.657719Z","iopub.execute_input":"2021-06-10T18:47:21.658068Z","iopub.status.idle":"2021-06-10T18:47:21.745078Z","shell.execute_reply.started":"2021-06-10T18:47:21.658038Z","shell.execute_reply":"2021-06-10T18:47:21.744098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"For K=4,","metadata":{}},{"cell_type":"code","source":"knn_4 = KNeighborsClassifier(n_neighbors=4)\nknn_4.fit(messages_tf_idf_train,y_Train)\ny_pred = knn_4.predict(messages_tf_idf_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:47:25.103171Z","iopub.execute_input":"2021-06-10T18:47:25.103539Z","iopub.status.idle":"2021-06-10T18:47:25.355367Z","shell.execute_reply.started":"2021-06-10T18:47:25.103508Z","shell.execute_reply":"2021-06-10T18:47:25.354334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Classification report is: \")\nprint(classification_report(y_Test,y_pred))\nprint(\"Accuracy Score is: \")\nprint(accuracy_score(y_Test,y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T18:47:30.65598Z","iopub.execute_input":"2021-06-10T18:47:30.656339Z","iopub.status.idle":"2021-06-10T18:47:30.74587Z","shell.execute_reply.started":"2021-06-10T18:47:30.656306Z","shell.execute_reply":"2021-06-10T18:47:30.744761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy score of K=4 is lower than the K=3 or K=5 ( as it is visible already in the error-rate vs K plot). Between K=3 and K=5, K=3 will be a good choice interms of accuracy, precision and recall. ","metadata":{}},{"cell_type":"markdown","source":"Thank you!","metadata":{}}]}