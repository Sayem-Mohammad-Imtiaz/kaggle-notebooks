{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport m3utils\nimport holidays\nfrom sklearn.ensemble import RandomForestRegressor\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True) # falls plotly mal nichts anzeigt, diese Zelle wieder ausführen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering für Zeitreihen\nDieses Notebook zeigt die Beispiele zum Feature Engineering für Zeitreihen. Wir nutzen dafür zuerst wieder die COVID-19-Daten.","metadata":{}},{"cell_type":"code","source":"df = m3utils.load_covid_19_data()\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef train_predict(features):\n    df = features.copy()\n    df['Country/Region'] = df['Country/Region'].cat.codes\n    df['date'] = m3utils.date_to_days(df['date'])\n    \n    result = m3utils.train_predict(df, 7, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', RandomForestRegressor(), ['date'])\n    \n    result['date'] = m3utils.days_to_date(result['date'])\n    result['Country/Region'] = features['Country/Region'].cat.categories[result['Country/Region'].astype('int')]\n    return result\n\nm3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features mit Zeitbezug\n\n## Features mit Komponenten aus Datum und Zeit\n\nKomponenten aus dem Datumswert oder Zeitwert einer Series lassen sich über den Accessor `pandas.Series.dt` ([API-Docs](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.date.html)) extrahieren.\n\nWild alle verfügbaren Komponenten zu extrahieren und in das ML-Modell zu packen ist aber nicht empfehlenswert. Datum und Zeit identifizieren in Kombination mit anderen Attributen oft wenige Werte und können deshalb von den ML-Modellen zum Overfitting genutzt werden. Die extrahierten Komponenten sollten deshalb immer domänenspezifisch geprüft werden: Was soll das Modell potentiell lernen?\n\nIm COVID-19-Beispiel wäre z.B. vorstellbar, das in Abhängigkeit der Jahreszeit ein unterschiedliches Infektionsrisiko. Wir könnten dafür z.B. den Monat und das Quartal in das Modell geben (eigentlich wissen wir aber in diesem konkreten Beispiel, dass wir mit ca. 15 Monaten dafür zu wenig Daten haben).","metadata":{}},{"cell_type":"code","source":"df['month'] = df['date'].dt.month\ndf['quarter'] = df['date'].dt.quarter\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features aus Ereignissen/Zeitpunkten erzeugen\n\n### Exogene Ereignisse: Feiertage\n\nEin gutes Beispiel für exogene Ereignisse sind Feiertage. Dafür gibt es z.B. das Paket [Python-Holidays](https://github.com/dr-prodigy/python-holidays), das für sehr viele Länder die Feiertage berechnen kann. Wenn sich viele Menschen zu Feiertagen treffen, könnte das ein gutes Feature sein.","metadata":{}},{"cell_type":"code","source":"countries = m3utils.EU_UK_data()\ncountries = countries.loc[countries['Country/Region'].isin(df['Country/Region'].unique())]\n\nholidays_df = pd.DataFrame()\nfor i, row in countries.iterrows():\n    country_holidays = holidays.CountryHoliday(row['Country_Code'], years=[2020,2021])\n    holidays_df = holidays_df.append(\n        pd.DataFrame({'date': country_holidays.keys(),\n                      'holiday': country_holidays.values(),\n                      'Country/Region': row['Country/Region']})\n    )\nholidays_df['date'] = pd.to_datetime(holidays_df['date'])\nholidays_df['Country/Region'] = holidays_df['Country/Region'].astype(df.dtypes['Country/Region'])\nholidays_df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ereignisse als boolschen Wert kodieren","metadata":{}},{"cell_type":"code","source":"df = df.drop(columns='holiday', errors='ignore').merge(holidays_df, on=['Country/Region', 'date'], how='left')\ndf['holiday'] = df['holiday'].notnull().astype('int')\ndf.loc[df['date'].isin(['2020-12-24', '2020-12-25'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ereignisse als Zeitspanne kodieren","metadata":{}},{"cell_type":"code","source":"df = df.drop(columns='holiday', errors='ignore').merge(holidays_df, on=['Country/Region', 'date'], how='left')\n# Namen des Feiertags df['holiday'] durch das Datum des Feiertags ersetzen\ndf.loc[df['holiday'].notnull(), 'holiday'] = df.loc[df['holiday'].notnull(), 'date']\n# das Feiertagsdatum nach vorne auffüllen, df['holiday'] enthält jetzt das Datum des letzten Feiertags\ndf['holiday'] = df.groupby(['Country/Region'])['holiday'].ffill()\n# je Land und Feiertagsdatum kumuliert zählen\ndf['holiday'] = df.groupby(['Country/Region', 'holiday'])['holiday'].cumcount()\ndf.loc[(df['Country/Region']=='Germany') & (df['date'] >= '2020-12-23')].head(11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrische Features\n\n## Basis-Features zur Beschreibung der Zeitreihe: Lags und Statistiken auf Zeitfenstern\n\nLags lassen sich mit der Methode [pd.Series.shift ](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.shift.html) erzeugen.","metadata":{}},{"cell_type":"code","source":"max_lag = 7\nlags = list(range(max_lag, 0, -1)) # oder eine eigene Liste [1, 2, 7, 14]\nfor lag in lags:\n    df['value_daily_lag'+str(lag)] = df.groupby('Country/Region')['value_daily'].shift(lag)\ndf.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rollende Statistiken lassen sich mit den Methoden [pd.Series.rolling](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.rolling.html), [pd.Series.expanding](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.expanding.html) und [pd.Series.ewm](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ewm.html) erzeugen.\n\nZum Beispiel könnten wir eine Schätzung des Pool der ansteckenden Infizierten berechnen, in dem wir annehmen, dass die Infizierten ca. 14 Tage ansteckend bleiben.","metadata":{}},{"cell_type":"code","source":"df['contagious_pool'] = df.groupby('Country/Region')['value_daily'].rolling(window=14).sum().reset_index(level=0, drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die gleitende Summe ist aber am Ende nichts anderes, als ein gleitender Mittelwert. Das ist ein Beispiel dafür, dass wir beim Feature Engineering aufpassen müssen, wie unsere Features zusammenhängen und welche ggf. redundant sind.","metadata":{}},{"cell_type":"code","source":"df['contagious_pool'] = df['contagious_pool']/14","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df,\n        x='date', y=['value_daily', 'contagious_pool', 'value_trend'],\n        title='Tägliche Infektionen und Anzahl der ansteckenden Infizierten',\n        facet_row='Country/Region',\n        labels=dict(date='Datum', value=''))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1])) # 'Italy' anstatt 'Country/Region=Italy' für die Beschriftung der Subplots\nfig.update_yaxes(matches=None) # individuelle y-Achsen-Skala je Diagramm\nfig.show()\ndf.drop(columns='contagious_pool', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interaktionen\n\nEine typische Interaktion zwischen zwei Variablen ist die Kombination mit Multiplikation oder Division. Viele ML-Modelle profitieren davon, da sie solche Kombinationen selbst nicht oder nur sehr aufwändig ermitteln können.\n\nDie Reproduktionszahl (R-Wert) aus den Nachrichten ist eine solche Kombination, die sich aus dem Mittelwert der letzten 7-Tage geteilt durch den Mittelwert der letzten 7-Tage vor 4 Tagen berechnet. ","metadata":{}},{"cell_type":"code","source":"df['R-number'] = df['value_trend']/(df.groupby('Country/Region')['value_trend'].shift(4)+0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(df.loc[df['date']>'2020-05-01'],\n        x='date', y=['R-number'],\n        title='Reproduktionszahl R',\n        facet_row='Country/Region',\n        labels=dict(date='Datum', value=''))\nfig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[1])) # 'Italy' anstatt 'Country/Region=Italy' für die Beschriftung der Subplots\nfig.update_yaxes(matches=None) # individuelle y-Achsen-Skala je Diagramm\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Externe Daten\n\nWir fügen einen weiteren Datensatz hinzu:\n\nCovid-19 hat bisher viel Einfluss auf das tägliche Leben, insbesondere auch auf unsere Aufenthaltsorte (Aufrufe zur Kontaktvermeidung, politische Vorgaben...). Da direkter/indirekter Kontakt für eine Infektion nötig ist, liegt es nahe Daten, die unsere Aufenthaltsorte abbilden, miteinzubeziehen. Hierfür verwenden wir Google-Bewegungsdaten (https://www.google.com/covid19/mobility/index.html?hl=de). Sie enthalten Bewegungstrends  (Referenz ist Medianwert der fünf Wochen vom 3. Januar bis 6. Februar 2020) für folgende Ortskategorien:\n- `retail_and_recreation`\n- `grocery_and_pharmacy`\n- `parks`\n- `transit_stations`\n- `workplaces`\n- `residential`\n\nIn den Daten selbst sind indirekt weitere Infomationen codiert (an arbeitsfreien Tagen werden die Zahlen für workplaces absinken; bei schönem Wetter werden die Zahlen für Parks steigen...).","metadata":{}},{"cell_type":"code","source":"df2 = pd.read_csv('https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv', dtype={'country_region': 'category', 'metro_area': 'str', 'iso_3166_2_code': 'str'})\ndf2 = df2.loc[(df2['country_region'].isin(df['Country/Region'].unique())) & (df2['sub_region_1'].isnull())]\ndf2['date'] = pd.to_datetime(df2['date'])\ndf2.drop(columns=['country_region_code', 'place_id', 'sub_region_1', 'sub_region_2', 'metro_area', 'iso_3166_2_code', 'census_fips_code'], inplace=True, errors='ignore')\ndf2 = df2.fillna({col: 0 for col in df.columns[df.dtypes.eq(float)]}) # fehlende Werte mit 0 ersetzen\ndf2.rename(columns={\"country_region\": \"Country/Region\"}, inplace=True) # Spaltennamen angleichen\ndf2.columns = df2.columns.str.replace(r'_percent_change_from_baseline$', '', regex=True) # langes Suffix entfernen\ndf2['Country/Region'] = df2['Country/Region'].astype(df['Country/Region'].dtype) # Datentyp mit df angleichen für merge\ndf2.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Übung\n\n## Aufgabe 1 - Feature Engineering für die COVID-19 Daten\n\nVerbinde die Bewegungsdaten aus `df2` mit den anderen Daten aus `df`.","metadata":{}},{"cell_type":"code","source":"# Hier dein Code für den Join","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In echten Projekten solltest Du beim Feature Engineering viel visualisieren. Das lassen wir heute weg, um Zeit zu sparen :-)","metadata":{}},{"cell_type":"markdown","source":"Willst Du vielleicht noch andere Features erstellen? Willst Du die Bewegungsdaten so verwenden, wie sie sind, oder vielleicht auch noch andere Features auf ihnen erstellen?","metadata":{}},{"cell_type":"code","source":"# Schritt 2: Zusätzliche Features?","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trainiere ein Modell mit Deinen aktuellen Features und schau, ob die Features etwas gebracht haben. Sonst wieder zu Schritt 1.","metadata":{}},{"cell_type":"code","source":"# Schritt 3: ggf. Vorhersage-Code noch anpassen\nm3utils.crossvalidate(df, 'Country/Region', 'date', 'value_daily', 'value_daily_predicted', train_predict, pd.to_datetime('2020-09-01'), 5, 28, m3utils.wmape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Aufgabe 2 - Feature Engineering mit den M5-Daten [optional]\n\nFalls Du keine Lust mehr auf COVID-Daten hast, kannst Du auch gerne die M5-Daten kneten...\n\nNeben den Verkaufszahlen ist eine Datei mit Preisen und ein Kalender hinterlegt. Der Kalender enthält einige Feiertage und Tage, an denen Lebensmittelmarken (SNAP) angenommen werden. Schau dir auch diese Daten dafür an.","metadata":{}},{"cell_type":"code","source":"df_sales = pd.read_parquet('../input/m5-forecasting-parquet-and-aggregations/daily_sales_items_top105.parquet')\nid_columns = [c for c in df_sales.columns.values if 'id' in c]\nfor c in id_columns:\n    df_sales[c] = df_sales[c].astype('category')\ndf_sales.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_prices = pd.read_parquet('../input/m5-forecasting-parquet-and-aggregations/sell_prices.parquet')\nid_columns = [c for c in df_prices.columns.values if 'id' in c]\nfor c in id_columns:\n    df_prices[c] = df_prices[c].astype('category')\ndf_prices.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_calendar = pd.read_csv('../input/m5-forecasting-parquet-and-aggregations/calendar.csv')\ndf_calendar.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ein paar Inspirationen:\n- Wochentag\n- Anzahl Tage im Monat\n- Feiertage\n- Jährliche/wöchentliche Saisonalität\n- Anzahl an Produkten in der Kategorie\n- Trend in den Verkaufszahlen\n- Trend in der Preisentwicklung\n- Innerhalb der letzten 2 Wochen gab es ein Marketing-Event in der Gegend\n- Verhältnis zwischen Preis und Verkaufszahl\n- Regionale Unterschiede (z.B. maximaler Preis)\n- Verschiedenen statistisch Werte","metadata":{}}]}