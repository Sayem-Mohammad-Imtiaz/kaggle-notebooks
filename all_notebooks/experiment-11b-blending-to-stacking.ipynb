{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Blending to Stacking...\n\nBased on Abhishek Thakhur's [notebook \"blending blending blending\"](https://www.kaggle.com/abhishek/blending-blending-blending)\n\n## Record of Submissions\n\n| Date            | Mean RMSE | Std Dev  | Public Score | Rank | Comment                                                 |\n|-----------------|-----------|----------|--------------|------|---------------------------------------------------------|\n| 27 Aug at 11:33 | 0.716401  | 0.000905 | 0.71747      | 218  | Passive: Based on Abhishek's blending-blending-blending |\n| 27 Aug at 14:19 | 0.716391  | 0.000906 | 0.71744      | 163  | Added untuned `CatBoostRegressor` |\n| 27 Aug at 16:25 | 0.716396  | 0.000899 | 0.71745      | 173  | Added untuned `LightGBMRegressor`; competition heats up |\n| 28 Aug at 10:59 | 0.716268  | 0.000985 | 0.71731      | 147  | First run of stacker; top score is 0.71697 |\n| 28 Aug at 21:07 | 0.715997  | 0.000933 | 0.71722      | 48  | Added Level 1 data from [notestack](https://www.kaggle.com/shilpabadge/note-stacking) and [cd6-stacking](https://www.kaggle.com/jhsoft/competition-day-6-stacking10) notebooks |\n| 28 Aug at 21:44 | 0.715138  | 0.000925 | 0.71823      | 48  | Added Google AutoML preds again. Score worse. |\n| 29 Aug at 18:14 | 0.715990  | 0.000928 | 0.71721      | 52  | `CatBoostRegressor` handling cat data natively |\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T09:30:26.281929Z","iopub.execute_input":"2021-08-27T09:30:26.282444Z","iopub.status.idle":"2021-08-27T09:30:26.298778Z","shell.execute_reply.started":"2021-08-27T09:30:26.282344Z","shell.execute_reply":"2021-08-27T09:30:26.297294Z"}}},{"cell_type":"code","source":"from pathlib import Path\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nfrom lightgbm import LGBMRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-31T15:51:21.051848Z","iopub.execute_input":"2021-08-31T15:51:21.052346Z","iopub.status.idle":"2021-08-31T15:51:22.369664Z","shell.execute_reply.started":"2021-08-31T15:51:21.052224Z","shell.execute_reply":"2021-08-31T15:51:22.368501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Data Loading and Saving","metadata":{}},{"cell_type":"code","source":"FOLDS_DATA_DIR = Path('../input/30days-folds')\nTEST_DATA_DIR = Path('../input/30-days-of-ml')\nL1_DATA = Path(\"../input/l1-data\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:51:25.325509Z","iopub.execute_input":"2021-08-31T15:51:25.326193Z","iopub.status.idle":"2021-08-31T15:51:25.332146Z","shell.execute_reply.started":"2021-08-31T15:51:25.326135Z","shell.execute_reply":"2021-08-31T15:51:25.330708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    df = pd.read_csv(FOLDS_DATA_DIR / \"train_folds.csv\")\n    df_test = pd.read_csv(TEST_DATA_DIR / \"test.csv\")\n    sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\n\n    useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n    object_cols = [col for col in useful_features if 'cat' in col]\n    df_test = df_test[useful_features]\n    \n    return df, df_test, sample_submission, useful_features, object_cols","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:51:30.481791Z","iopub.execute_input":"2021-08-31T15:51:30.482324Z","iopub.status.idle":"2021-08-31T15:51:30.488844Z","shell.execute_reply.started":"2021-08-31T15:51:30.482289Z","shell.execute_reply":"2021-08-31T15:51:30.487539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_data(final_valid_predictions, final_test_predictions, sample_submission, level, pred_number):\n    final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n    final_valid_predictions.columns = [\"id\", f\"pred_{ pred_number }\"]\n    final_valid_predictions.to_csv(f\"level{ level }_train_pred_{ pred_number }.csv\", index=False)\n\n    sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n    sample_submission.columns = [\"id\", f\"pred_{ pred_number }\"]\n    sample_submission.to_csv(f\"level{ level }_test_pred_{ pred_number }.csv\", index=False)\n    \n    print(\"\\nSaved prediction files to output directory.\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:51:32.576518Z","iopub.execute_input":"2021-08-31T15:51:32.577083Z","iopub.status.idle":"2021-08-31T15:51:32.583486Z","shell.execute_reply.started":"2021-08-31T15:51:32.577048Z","shell.execute_reply":"2021-08-31T15:51:32.582566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Models Included in the Blend","metadata":{}},{"cell_type":"markdown","source":"## XGBRegressor Model #1\n\n- Mean RMSE score: 0.716423430212675 \n- Standard Deviation: 0.0008883537054028858","metadata":{}},{"cell_type":"code","source":"df, df_test, sample_submission, useful_features, object_cols = load_data()\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03628302216953097,\n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'subsample': 0.7875490025178415,\n        'colsample_bytree': 0.11807135201147481,\n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        n_jobs=4,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=0, pred_number=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T15:51:40.17183Z","iopub.execute_input":"2021-08-31T15:51:40.172358Z","iopub.status.idle":"2021-08-31T16:31:31.035723Z","shell.execute_reply.started":"2021-08-31T15:51:40.172312Z","shell.execute_reply":"2021-08-31T16:31:31.034638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBRegressor #2\n\n- Mean RMSE score: 0.716751801740166  \n- Standard Deviation: 0.0009449448387318704","metadata":{}},{"cell_type":"code","source":"df, df_test, sample_submission, useful_features, object_cols = load_data()\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {\n        'learning_rate': 0.07853392035787837,\n        'reg_lambda': 1.7549293092194938e-05,\n        'reg_alpha': 14.68267919457715, \n        'subsample': 0.8031450486786944, \n        'colsample_bytree': 0.170759104940733, \n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        random_state=fold,\n        n_jobs=4,\n        n_estimators=5000,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=0, pred_number=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:35:25.263176Z","iopub.execute_input":"2021-08-31T16:35:25.263625Z","iopub.status.idle":"2021-08-31T16:54:39.430289Z","shell.execute_reply.started":"2021-08-31T16:35:25.263589Z","shell.execute_reply":"2021-08-31T16:54:39.429224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CatBoostRegressor\n\nLoss indicator improved after allowing `CatBoostRegressor` to run on CPU and to handle categorical features natively, rather than receiving them with ordinal encoding.\n\n- Mean RMSE score: ~0.7357652266177294~ 0.72463705597803   \n- Standard Deviation: ~0.0005995252889098014~ 0.0006605264189716528","metadata":{}},{"cell_type":"code","source":"df, df_test, sample_submission, useful_features, object_cols = load_data()\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    params = dict(\n        # Abhishek reported (rightly) that running on CPU is more accurate\n        #task_type = \"GPU\",\n        #devices = '0',\n        cat_features = object_cols,\n        iterations=6800,\n        learning_rate=0.07853392035787837,\n        loss_function=\"RMSE\",\n        verbose=1000,\n        thread_count=4,\n        depth=1,\n        l2_leaf_reg=3.28,\n        random_state=fold,\n    )\n    \n    model = CatBoostRegressor( **params )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)])\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=0, pred_number=3)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T16:56:17.870122Z","iopub.execute_input":"2021-08-31T16:56:17.870549Z","iopub.status.idle":"2021-08-31T17:08:13.499636Z","shell.execute_reply.started":"2021-08-31T16:56:17.870508Z","shell.execute_reply":"2021-08-31T17:08:13.498455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBMRegressor\n\n- Mean RMSE score: nnn   \n- Standard Deviation: nnn","metadata":{}},{"cell_type":"code","source":"df, df_test, sample_submission, useful_features, object_cols = load_data()\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    # baseline model of https://www.kaggle.com/xaviernuelgavald/xgboost-and-lgbm-comparison\n    params = dict(\n        n_estimators = 3000,\n        learning_rate = 0.05,\n        num_leaves = 256,\n        max_depth = 7,\n        min_data_in_leaf = 40,\n        # Abhishek reported that running on CPU is more accurate\n        #device='gpu',\n        random_state=fold,\n        verbose = -1,\n    )\n    \n    model = LGBMRegressor(**params)  \n    model.fit(xtrain, ytrain,\n              early_stopping_rounds=300,\n              eval_set=[(xvalid, yvalid)],\n              verbose=False,\n             )\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=0, pred_number=4)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:08:13.501259Z","iopub.execute_input":"2021-08-31T17:08:13.501584Z","iopub.status.idle":"2021-08-31T17:10:32.444891Z","shell.execute_reply.started":"2021-08-31T17:08:13.50155Z","shell.execute_reply":"2021-08-31T17:10:32.443721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Blending Stage: Level 0 Submission\n","metadata":{}},{"cell_type":"code","source":"# Load level 0 predictions\n\ndf = pd.read_csv(FOLDS_DATA_DIR / \"train_folds.csv\")\ndf_test = pd.read_csv(TEST_DATA_DIR / \"test.csv\")\nsample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\n\nfor fn in range(1, 5):\n    tmp_df = pd.read_csv( f\"level0_train_pred_{ fn }.csv\" )\n    df = df.merge(tmp_df, on=\"id\", how=\"left\")\n    \n    tmp_test_df = pd.read_csv( f\"level0_test_pred_{ fn }.csv\" )\n    df_test = df_test.merge(tmp_test_df, on=\"id\", how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:10:32.44709Z","iopub.execute_input":"2021-08-31T17:10:32.447448Z","iopub.status.idle":"2021-08-31T17:10:36.604564Z","shell.execute_reply.started":"2021-08-31T17:10:32.447412Z","shell.execute_reply":"2021-08-31T17:10:36.603388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\"]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:10:36.606201Z","iopub.execute_input":"2021-08-31T17:10:36.606563Z","iopub.status.idle":"2021-08-31T17:10:37.61728Z","shell.execute_reply.started":"2021-08-31T17:10:36.606523Z","shell.execute_reply":"2021-08-31T17:10:37.616176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission_level_0.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:10:37.619138Z","iopub.execute_input":"2021-08-31T17:10:37.619899Z","iopub.status.idle":"2021-08-31T17:10:38.394254Z","shell.execute_reply.started":"2021-08-31T17:10:37.61985Z","shell.execute_reply":"2021-08-31T17:10:38.393379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Stacking Stage: Level 1 Predictions\n","metadata":{}},{"cell_type":"code","source":"# Reload level 0 predictions\n\ndf = pd.read_csv(FOLDS_DATA_DIR / \"train_folds.csv\")\ndf_test = pd.read_csv(TEST_DATA_DIR / \"test.csv\")\n\nfor fn in range(1, 5):\n    tmp_df = pd.read_csv( f\"level0_train_pred_{ fn }.csv\" )\n    df = df.merge(tmp_df, on=\"id\", how=\"left\")\n    \n    tmp_test_df = pd.read_csv( f\"level0_test_pred_{ fn }.csv\" )\n    df_test = df_test.merge(tmp_test_df, on=\"id\", how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:11:21.372728Z","iopub.execute_input":"2021-08-31T17:11:21.373088Z","iopub.status.idle":"2021-08-31T17:11:25.258446Z","shell.execute_reply.started":"2021-08-31T17:11:21.373058Z","shell.execute_reply":"2021-08-31T17:11:25.257365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## L1 Stacking: XGBRegressor","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n\n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 7000,\n        'learning_rate': 0.03,\n        'max_depth': 2\n    }\n    \n    model = XGBRegressor(\n        n_jobs=4,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=1, pred_number=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:11:25.259951Z","iopub.execute_input":"2021-08-31T17:11:25.260286Z","iopub.status.idle":"2021-08-31T17:13:57.123397Z","shell.execute_reply.started":"2021-08-31T17:11:25.26023Z","shell.execute_reply":"2021-08-31T17:13:57.122327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## L1 Stacking: RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, max_depth=3)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=1, pred_number=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:13:57.125531Z","iopub.execute_input":"2021-08-31T17:13:57.125945Z","iopub.status.idle":"2021-08-31T17:19:27.07422Z","shell.execute_reply.started":"2021-08-31T17:13:57.125901Z","shell.execute_reply":"2021-08-31T17:19:27.073257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## L1 Stacking: GradientBoostingRegressor","metadata":{}},{"cell_type":"code","source":"sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = GradientBoostingRegressor(n_estimators=500, max_depth=3)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=1, pred_number=3)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:19:27.075842Z","iopub.execute_input":"2021-08-31T17:19:27.076129Z","iopub.status.idle":"2021-08-31T17:42:34.21435Z","shell.execute_reply.started":"2021-08-31T17:19:27.076101Z","shell.execute_reply":"2021-08-31T17:42:34.213374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# L1 Stacking: LinearRegression Submission\n\nAt this stage, some public domain datasets are added to the mix from other notebooks with thanks to @shilpabadge and @jhsoft.\n\n- https://www.kaggle.com/shilpabadge/note-stacking\n- and from https://www.kaggle.com/jhsoft/competition-day-6-stacking10/notebook","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(FOLDS_DATA_DIR / \"train_folds.csv\")\ndf_test = pd.read_csv(TEST_DATA_DIR / \"test.csv\")\nsample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\n\ndf1 = pd.read_csv(\"level1_train_pred_1.csv\")  # output from above blends\ndf2 = pd.read_csv(\"level1_train_pred_2.csv\")  #\ndf3 = pd.read_csv(\"level1_train_pred_3.csv\")  #\ndf4 = pd.read_csv(L1_DATA / \"level1_train_pred_4.csv\")\ndf5 = pd.read_csv(L1_DATA / \"level1_train_pred_5.csv\")\ndf6 = pd.read_csv(L1_DATA / \"level1_train_pred_6.csv\")\ndf7 = pd.read_csv(L1_DATA / \"level1_train_pred_7.csv\")\ndf8 = pd.read_csv(L1_DATA / \"level1_train_pred_8.csv\")\ndf9 = pd.read_csv(L1_DATA / \"level1_train_pred_9.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\ndf = df.merge(df4, on=\"id\", how=\"left\")\ndf = df.merge(df5, on=\"id\", how=\"left\")\ndf = df.merge(df6, on=\"id\", how=\"left\")\ndf = df.merge(df7, on=\"id\", how=\"left\")\ndf = df.merge(df8, on=\"id\", how=\"left\")\ndf = df.merge(df9, on=\"id\", how=\"left\")\n\ndf_test1 = pd.read_csv(\"level1_test_pred_1.csv\")  # output from above blends\ndf_test2 = pd.read_csv(\"level1_test_pred_2.csv\")  # \ndf_test3 = pd.read_csv(\"level1_test_pred_3.csv\")  # \ndf_test4 = pd.read_csv(L1_DATA / \"level1_test_pred_4.csv\")\ndf_test5 = pd.read_csv(L1_DATA / \"level1_test_pred_5.csv\")\ndf_test6 = pd.read_csv(L1_DATA / \"level1_test_pred_6.csv\")\ndf_test7 = pd.read_csv(L1_DATA / \"level1_test_pred_7.csv\")\ndf_test8 = pd.read_csv(L1_DATA / \"level1_test_pred_8.csv\")\ndf_test9 = pd.read_csv(L1_DATA / \"level1_test_pred_9.csv\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test5, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test6, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test7, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test8, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test9, on=\"id\", how=\"left\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:43:27.540141Z","iopub.execute_input":"2021-08-31T17:43:27.540588Z","iopub.status.idle":"2021-08-31T17:43:32.917252Z","shell.execute_reply.started":"2021-08-31T17:43:27.540547Z","shell.execute_reply":"2021-08-31T17:43:32.916012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [c for c in df.columns if c.startswith('pred_')]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:43:46.122471Z","iopub.execute_input":"2021-08-31T17:43:46.122858Z","iopub.status.idle":"2021-08-31T17:43:47.330527Z","shell.execute_reply.started":"2021-08-31T17:43:46.122822Z","shell.execute_reply":"2021-08-31T17:43:47.329493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission_level_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T17:43:47.370049Z","iopub.execute_input":"2021-08-31T17:43:47.370602Z","iopub.status.idle":"2021-08-31T17:43:48.130385Z","shell.execute_reply.started":"2021-08-31T17:43:47.370534Z","shell.execute_reply":"2021-08-31T17:43:48.129329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Stacking Stage: Level 2 Predictions\n\nThis is an experiment to generate yet another blend, possibly risking over-fitting... every effort made below here went crazy.\n","metadata":{}},{"cell_type":"code","source":"# Load level 1 predictions\n\ndf = pd.read_csv(FOLDS_DATA_DIR / \"train_folds.csv\")\ndf_test = pd.read_csv(TEST_DATA_DIR / \"test.csv\")\n\nfor fn in range(1, 4):\n    tmp_df = pd.read_csv( f\"level1_train_pred_{ fn }.csv\" )\n    df = df.merge(tmp_df, on=\"id\", how=\"left\")\n    \n    tmp_test_df = pd.read_csv( f\"level1_test_pred_{ fn }.csv\" )\n    df_test = df_test.merge(tmp_test_df, on=\"id\", how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:01:27.271543Z","iopub.execute_input":"2021-08-31T18:01:27.271966Z","iopub.status.idle":"2021-08-31T18:01:30.92783Z","shell.execute_reply.started":"2021-08-31T18:01:27.271929Z","shell.execute_reply":"2021-08-31T18:01:30.926881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n\n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 7000,\n        'learning_rate': 0.03,\n        'max_depth': 2\n    }\n    \n    model = XGBRegressor(\n        n_jobs=4,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=2, pred_number=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:01:30.929275Z","iopub.execute_input":"2021-08-31T18:01:30.929574Z","iopub.status.idle":"2021-08-31T18:03:33.253025Z","shell.execute_reply.started":"2021-08-31T18:01:30.929547Z","shell.execute_reply":"2021-08-31T18:03:33.251741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = RandomForestRegressor(n_estimators=500, n_jobs=-1, max_depth=3)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=2, pred_number=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:03:33.255575Z","iopub.execute_input":"2021-08-31T18:03:33.256005Z","iopub.status.idle":"2021-08-31T18:06:33.970515Z","shell.execute_reply.started":"2021-08-31T18:03:33.255959Z","shell.execute_reply":"2021-08-31T18:06:33.969191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\nuseful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = GradientBoostingRegressor(n_estimators=500, max_depth=3)\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nsave_data(final_valid_predictions, final_test_predictions, sample_submission, level=2, pred_number=3)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:06:33.972429Z","iopub.execute_input":"2021-08-31T18:06:33.972854Z","iopub.status.idle":"2021-08-31T18:18:14.517812Z","shell.execute_reply.started":"2021-08-31T18:06:33.97281Z","shell.execute_reply":"2021-08-31T18:18:14.516391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(FOLDS_DATA_DIR / \"train_folds.csv\")\ndf_test = pd.read_csv(TEST_DATA_DIR / \"test.csv\")\nsample_submission = pd.read_csv(TEST_DATA_DIR / \"sample_submission.csv\")\n\ndf1 = pd.read_csv(\"level2_train_pred_1.csv\")  # output from above blends\ndf2 = pd.read_csv(\"level2_train_pred_2.csv\")  #\n#df3 = pd.read_csv(\"level2_train_pred_3.csv\")  #\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\n#df = df.merge(df3, on=\"id\", how=\"left\")\n\ndf_test1 = pd.read_csv(\"level2_test_pred_1.csv\")  # output from above blends\ndf_test2 = pd.read_csv(\"level2_test_pred_2.csv\")  # \n#df_test3 = pd.read_csv(\"level2_test_pred_3.csv\")  # \n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n#df_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:21:13.718185Z","iopub.execute_input":"2021-08-31T18:21:13.718626Z","iopub.status.idle":"2021-08-31T18:21:16.943472Z","shell.execute_reply.started":"2021-08-31T18:21:13.71858Z","shell.execute_reply":"2021-08-31T18:21:16.942482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [c for c in df.columns if c.startswith('pred_')]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:21:16.945428Z","iopub.execute_input":"2021-08-31T18:21:16.945848Z","iopub.status.idle":"2021-08-31T18:21:17.815928Z","shell.execute_reply.started":"2021-08-31T18:21:16.945804Z","shell.execute_reply":"2021-08-31T18:21:17.814829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission_level_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-31T18:21:22.705948Z","iopub.execute_input":"2021-08-31T18:21:22.706321Z","iopub.status.idle":"2021-08-31T18:21:23.44485Z","shell.execute_reply.started":"2021-08-31T18:21:22.706288Z","shell.execute_reply":"2021-08-31T18:21:23.443538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}