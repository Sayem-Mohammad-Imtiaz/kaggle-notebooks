{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PROYECTO 2 A.I"},{"metadata":{},"cell_type":"markdown","source":"#### INTEGRANTES :"},{"metadata":{},"cell_type":"markdown","source":"#### José Bustos, Felipe Gutiérrez, Freddy Hidalgo"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np # importamos numpy\nimport pandas as pd # importamos pandas\nimport tensorflow as tf # importamos tensorflow\nfrom sklearn import tree # importamos sklearn el modulo de tree\nfrom sklearn.model_selection import train_test_split #importamos sklearn el modulo de train_test_split\nimport matplotlib.pyplot as plt # importamos matplotlib\nfrom sklearn import preprocessing as pre # importamos sklearn el modulo de preprocessing \nfrom sklearn.svm import SVC # importamos sklearn el modulo de SVC\nfrom sklearn.metrics import classification_report, confusion_matrix # importamos sklearn el modulo de classification_report, confusion_matrix\nfrom sklearn.neural_network import MLPClassifier # importamos sklearn el modulo de MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Procesamiento de Datos"},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset = pd.read_csv('train.csv', delimiter=',') # leemos el dataset\ndataset.head() # mostramos el dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset.info() #informacion del dataset, buscamos si hay elementos nulos (no hay en nuestro caso)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset.price_range.value_counts().plot(kind = 'bar', color = ['b', 'r','g','y']) # vemos la distribucion de datos en los rangos de precio 1,2 y 3\nplt.title('Distribucion de precios') # titulo del grafico\nplt.show() # mostramos el grafico","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_precio = dataset['price_range'].values # cargamos los datos del rango de precios(price_range) en la variable y_precio\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset_num = dataset.drop(['price_range'], axis = 1) # eliminamos los datos de price_range del dataset y alamcenamos este nuevo dataset en dataset_num\ndataset_num.head() # mostramos el dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(dataset_num, y_precio, test_size = .8, random_state = 8) # dividimos los datos del dataset en 4 variables las cuales iran al los datos de validacion y a los de entrenamiento","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"celularbkanazo = np.array([[1034,1,2.7,1,6,0,37,0.7,120,7,20,707,1199,3625,17,1,12,0,1,1]]) # hacemos un posible modelo de celular para estudiar el modelo\ncelularbkanazo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este segmento es para ver la distribucion de los datos (cuantos datos fueron destinados a validacion y a train)"},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_bar(y_precio, loc='left', relative=True):\n    width = 0.35\n    if loc == 'left':\n        n = -0.5\n    elif loc == 'right':\n        n = 0.5\n \n    # calcula la cantidad por clase y tipo de dato\n    unique, counts = np.unique(y_precio, return_counts=True) # busca los valores unicos del rango de valores\n    sorted_index = np.argsort(unique)  # calculamos los indices que ordenarian una matriz de los valores unicos\n    unique = unique[sorted_index] # calculamos los valores unicos de los indices\n \n    if relative:\n        # para graficar como porcentaje\n        counts = 100*counts[sorted_index]/len(y_precio)\n        ylabel_text = '% cantidad'\n    else:\n        # para graficos de la cantidad\n        counts = counts[sorted_index]\n        ylabel_text = 'cantidad'\n \n    xtemp = np.arange(len(unique)) # creamos un vector del largo de los valores unicos\n \n    plt.bar(xtemp + n*width, counts, align='center', alpha=.7, width=width) # diagrama de barras\n    plt.xticks(xtemp, unique) # coordenadas de las barras\n    plt.xlabel('rango de precios') # leyenda del eje x\n    plt.ylabel(ylabel_text) # leyenda del eje y\n \nplt.suptitle('distribucion de precios en train y validation')  # titulo\nplot_bar(y_train, loc='left') #grafico de barras\nplot_bar(y_validation, loc='right') #grafico de barras\n#leyendas\nplt.legend([\n    'train ({0} datos)'.format(len(y_train)),\n    'validation ({0} datos)'.format(len(y_validation))             \n]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DECISION TREE"},{"metadata":{"trusted":false},"cell_type":"code","source":"tree_mobile = tree.DecisionTreeClassifier() # definimos el modelo del tipo DecisionTreeClassifier\ntree_mobile = tree_mobile.fit(x_train, y_train) # le pasamos los datos de x_train y y_train para entrenar el modelo","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tree_mobile_accuracy = tree_mobile.score(x_validation, y_validation) # calculamos la presicion del modelo\nprint('Accuracy: ', tree_mobile_accuracy) # mostramos la presicion","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"valor = tree_mobile.predict(celularbkanazo ) # predecimos ahora el valor del celular","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# creamos ciclos de condicion para ver en que rango de precios se encuentra el celular\nif valor[0] == 0:   \n  print (\"barato\")\nif valor[0] == 1:\n  print (\"moderado\")\nif valor[0] == 2:\n  print (\"caro\")\nif valor[0] == 3:\n  print (\"muy caro\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Vemos que el algoritmo presento una accuracy del 82% de precision, esto es un valor considerablemente alto, aunque no es un porcentaje que sea muy motivador a nivel comercial, ya que en la actualidad los sistemas inteligentes, para que sean viables deben estar sobre el 90%, no obstante se debe tener en cuenta que los datos de entrenamiento tampoco fueron demasiados lo que disminuiria la presicion del algoritmo."},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":false},"cell_type":"code","source":"svclassifier = SVC(kernel='linear') # definimos el modelo del SVC de SVM con un Kernel lienal\nsvclassifier.fit(x_train, y_train) # le pasamos los datos de x_train y y_train para entrenar el modelo","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svcclassifier_accuracy = svclassifier.score(x_validation, y_validation) # calculamos la precision del modelo\nprint('Accuracy: ', svcclassifier_accuracy) # mostramos la precision","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svm_valor = svclassifier.predict(celularbkanazo) # predecimos ahora el valor...","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# creamos ciclos de condicion para ver en que rango de precios se encuentra el celular\nif svm_valor[0] == 0:\n  print (\"barato\")\nif svm_valor[0] == 1:\n  print (\"moderado\")\nif svm_valor[0] == 2:\n  print (\"caro\")\nif svm_valor[0] == 3:\n  print (\"muy caro\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Luego de desarrollar este algoritmo, vemos que el accuracy arrojo un valor de 95% de precision, lo que si es un valor bastante bueno, presentando mejoras con respecto al algoritmo DECISION TREE, esto a su vez deja en evidencia que los datos estan calaramente diferenciados de manera lienal entre ellos, ya que el kernel utilizado en el algoritmo svm era de este tipo."},{"metadata":{},"cell_type":"markdown","source":"esto es para ver la evaluacion del algoritmo"},{"metadata":{"trusted":false},"cell_type":"code","source":"svm_valor = svclassifier.predict(x_validation)  # guardamos la predicciones de los datos de validacion en la variable de prediccion\nprint(confusion_matrix(y_validation,svm_valor)) # calculamos la matriz de confusion, la cual nos sirva para ver el desempeño del algoritmo\nprint(classification_report(y_validation,svm_valor))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Network Neuronal"},{"metadata":{"trusted":false},"cell_type":"code","source":"scaler = pre.StandardScaler() # llamamos el modulo de la funcion StandardScaler \nscaler.fit(x_train)   # escalamos los datos segun los datos de entrenamiento \nx_train = scaler.transform(x_train) # guardamos los datos escalados de entrenamiento en la variable x_train\nx_test = scaler.transform(x_validation) # guardamos los datos de entrenamiento en la variable x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"neuronal = MLPClassifier(hidden_layer_sizes = (21,21,4), # definimos la arquitectura de la red de las neuronas \nrandom_state = 0,\n\nlearning_rate_init = 0.01 ,            \nactivation = 'relu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"neuronal.fit(x_train,y_train) # entrenamos el modelo","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"neuronal_accuracy = neuronal.score(x_validation, y_validation) # vemos la presicion del modelo\nprint('Accuracy: ', neuronal_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" prediccion = neuronal.predict(x_validation) # guardamos la predicciones de los datos de validacion en la variable de prediccion","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(confusion_matrix(y_validation, prediccion)) # calculamos la matriz de confusion, la cual nos sirva para ver el desempeño del algoritmo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En este último algoritmo, se buscó construir una red neuronal la cual predijera el rango de valores de los equipos móviles. Para nuestra sorpresa, fue el algoritmo que peor desempeño obtuvo, ya que apenas logro el del 24,5%, en donde la mayor parte de las predicciones eran erradas, esto puede deberse a un desacertado modelo de red neuronal propuesto, dado que posiblemente no se ajuste lo suficiente a los parámetros del sistema, además los datos no son de gran volumen, y esto empeoraría más aun la situación."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}