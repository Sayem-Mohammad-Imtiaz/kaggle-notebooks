{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport keras\nimport sklearn\n\ndata = pd.read_csv('../input/deep-learning-az-ann/Churn_Modelling.csv')\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data_to_analyze = data.drop(['CustomerId', 'Surname','Exited','RowNumber'], axis=1)\nlabels = data['Exited']\n\n#substitute values\nmapping_geo = {'France': 1, 'Germany': 2, 'Spain':3}\nmapping_gender = {'Female': 1, 'Male': 2}\n\ndata_to_analyze = data_to_analyze.replace({'Geography': mapping_geo, 'Gender': mapping_gender})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's prepare the DNN by converting the tuples in numpy vectors\nimport numpy as np\n\nlabels_arr = np.asarray(labels)\ndata_to_analyze_arr = np.asarray(data_to_analyze)\n\nprint(data_to_analyze_arr.shape)\nprint(labels_arr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's split train and test arrays\n\nprint(data_to_analyze_arr.shape[0])\n\ndata_to_analyze_arr_train = data_to_analyze_arr[:int(data_to_analyze_arr.shape[0]/2),:]\ndata_to_analyze_arr_test = data_to_analyze_arr[int(data_to_analyze_arr.shape[0]/2):,:]\n\nlabels_arr_train = labels_arr[:int(data_to_analyze_arr.shape[0]/2)]\nlabels_arr_test = labels_arr[int(data_to_analyze_arr.shape[0]/2):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keras model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(260, input_dim=10, activation='tanh'))\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dense(10, activation='tanh'))\nmodel.add(Dense(1, activation='relu'))\n\nprint(model.summary())\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit the keras model on the dataset\nhistory = model.fit(data_to_analyze_arr_train, labels_arr_train, epochs=10, batch_size=64)\n# evaluate the keras model\n_, accuracy = model.evaluate(data_to_analyze_arr_train, labels_arr_train)\nprint('Train accuracy: %.2f' % (accuracy*100))\n\n_, accuracy = model.evaluate(data_to_analyze_arr_test, labels_arr_test)\nprint('Test accuracy: %.2f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting predictions and ROC curve\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nfrom keras.utils import plot_model\nplot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the loss as a function of the epoch\nimport matplotlib.pyplot as plt\n\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(data_to_analyze_arr_test)\n\nfpr, tpr, _ = roc_curve(labels_arr_test, predictions)\nroc_auc = auc(fpr, tpr)\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.05])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic curve')\nprint('AUC: %f' % roc_auc)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_Bkg=[]\npredictions_Sig=[]\n\nfor f in range(labels_arr_test.shape[0]):\n    if(labels_arr_test[f]==0):\n        predictions_Bkg.append(predictions[f])\n    elif(labels_arr_test[f]==1):\n        predictions_Sig.append(predictions[f])\n\npredictions_Bkg_array = np.asarray(predictions_Bkg)\npredictions_Bkg_array = predictions_Bkg_array.astype(np.float)\n\npredictions_Sig_array = np.asarray(predictions_Sig)\npredictions_Sig_array = predictions_Sig_array.astype(np.float)\n\nplt.hist(predictions_Sig_array,label='exited',normed=True,alpha = 0.5)\nplt.hist(predictions_Bkg_array,label='non exited',normed=True,alpha = 0.5)\nplt.legend(loc='upper right')\nplt.title(\"DNN Output\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Number Of Events\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#investigate the predictions\n#try generator\n#improve performance\n#tuning hyperparameters","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}