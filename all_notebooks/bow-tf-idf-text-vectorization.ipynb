{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n\nfrom sklearn.metrics import accuracy_score\nimport warnings \nwarnings.filterwarnings(\"ignore\") \npd.set_option('display.max_colwidth', 200)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Data : "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/imdb_master.csv', encoding='latin')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Unnamed: 0', 'file'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking only positive and negative datapoints. \ndf = df[df['label'] != 'unsup']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'] = df['label'].map({'neg' : 0, 'pos' : 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[df['type'] == 'train'].drop(['type'], axis= 1)\ntest  = df[df['type'] == 'test'].drop(['type'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text Pre-processing "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import re\ndef decontracted(phrase):\n     # specific    \n    phrase = re.sub(r\"won't\", \"will not\", phrase)    \n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase) \n    # general    \n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)  \n    phrase = re.sub(r\"\\'re\", \" are\", phrase)  \n    phrase = re.sub(r\"\\'s\", \" is\", phrase)    \n    phrase = re.sub(r\"\\'d\", \" would\", phrase)  \n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)   \n    phrase = re.sub(r\"\\'t\", \" not\", phrase)   \n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)   \n    phrase = re.sub(r\"\\'m\", \" am\", phrase)   \n    return phrase \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://gist.github.com/sebleier/554280 \n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\" , \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'th ey', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"tha t'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'ha d', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'ove r', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any' , 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'no w', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'might n', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wa sn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def preprocess_text(dff, feature):   \n        preprocessed_text = []   \n        for sentance in tqdm(dff[feature].values):       \n            sent = decontracted(sentance)      \n            sent = sent.replace('\\\\r', ' ')     \n            sent = sent.replace('\\\\\"', ' ')     \n            sent = sent.replace('\\\\n', ' ')     \n            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)      \n            # https://gist.github.com/sebleier/554280     \n            sent = ' '.join(e for e in sent.split() if e not in stopwords)    \n            preprocessed_text.append(sent.lower().strip()) \n        return preprocessed_text ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prep_reviews = preprocess_text(train, 'review')\ntest_prep_reviews = preprocess_text(test, 'review')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Vectorizing Text Data**"},{"metadata":{},"cell_type":"markdown","source":"**1. Bag of Words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(min_df = 10)\ntrain_bow = vectorizer.fit_transform(train_prep_reviews)\ntest_bow = vectorizer.transform(test_prep_reviews)\nprint(\"Shape of train matrix after BOW : \",train_bow.shape)\nprint(\"Shape of test matrix after BOW : \",test_bow.shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Tf-Idf**"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df = 10)\ntrain_tfidf = vectorizer.fit_transform(train_prep_reviews)\ntest_tfidf = vectorizer.transform(test_prep_reviews)\nprint(\"Shape of train matrix after Tfidf : \",train_tfidf.shape)\nprint(\"Shape of test matrix after Tfidf : \",test_tfidf.shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model on BOW"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr = train_bow\ny_tr = train['label']\nX_ts = test_bow\ny_ts = test['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_tr.shape)\nprint(y_tr.shape)\nprint(X_ts.shape)\nprint(y_ts.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [RandomForestClassifier(random_state=77),\n          GradientBoostingClassifier(random_state=77),\n          AdaBoostClassifier(random_state=77)]\n\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nfor model in models:\n    score = cross_val_score(model, X_tr, y_tr, cv=5)\n    msg = (\"{0}:\\n\\tMean accuracy on development set\\t= {1:.3f} \"\n           \"(+/- {2:.3f})\".format(model.__class__.__name__,\n                                  score.mean(),\n                                  score.std()))\n    print(msg)\n    \n    # Fit the model on the dev set and predict and eval independent set\n    model.fit(X_tr, y_tr)\n    pred_eval = model.predict(X_ts)\n    acc_eval = accuracy_score(y_ts, pred_eval)\n    print(\"\\tAccuracy on evaluation set\\t\\t= {0:.3f}\".format(acc_eval))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model on Tf-idf"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr = train_tfidf\ny_tr = train['label']\nX_ts = test_tfidf\ny_ts = test['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_tr.shape)\nprint(y_tr.shape)\nprint(X_ts.shape)\nprint(y_ts.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [RandomForestClassifier(random_state=77),\n          GradientBoostingClassifier(random_state=77),\n          AdaBoostClassifier(random_state=77)]\n\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\nfor model in models:\n    score = cross_val_score(model, X_tr, y_tr, cv=5)\n    msg = (\"{0}:\\n\\tMean accuracy on development set\\t= {1:.3f} \"\n           \"(+/- {2:.3f})\".format(model.__class__.__name__,\n                                  score.mean(),\n                                  score.std()))\n    print(msg)\n    \n    # Fit the model on the dev set and predict and eval independent set\n    model.fit(X_tr, y_tr)\n    pred_eval = model.predict(X_ts)\n    acc_eval = accuracy_score(y_ts, pred_eval)\n    print(\"\\tAccuracy on evaluation set\\t\\t= {0:.3f}\".format(acc_eval))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}