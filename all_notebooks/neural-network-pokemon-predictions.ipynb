{"cells":[{"metadata":{"_uuid":"ce8f87da9f5cd240c05e94030e3a9556d0ca8b5b","_cell_guid":"dbdafe14-224a-43a5-9943-f537e1a80e8d"},"cell_type":"markdown","source":"# Introduction\n\nAs an extension to my earlier models which used XG Boost (https://www.kaggle.com/xagor1/pokemon-type-predictions-using-xgb, https://www.kaggle.com/xagor1/improving-pokemon-generation-1-predictions), I decided to apply other methods to the problem of Pokemon type prediction.\n\nIn this case I wanted to try using a Deep Neural Network from Tensorflow, mainly as practice of building and optimizing one."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport glob\nimport os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport seaborn as sns\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.1f}'.format\nimport statistics\nimport shutil\n\n# Any results you write to the current directory are saved as output.\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"628921a535d4e9485ece5293951a10eea375b259","_cell_guid":"727b809b-1c60-4c69-8707-53a0c20f75ac"},"cell_type":"markdown","source":"# Loading and Modify Data\n\nTo save time at the start, I'm going to load modified data files from my other kernels, and go from there. Previously I was using XGBoost, so didn't really need to worry about doing my own regularization of the data. \n\nRegularization is more useful for a DNN, so I started by transforming my numerical data. Some I did a linear transformation on, and the highly skewed data I used a log transform on. In the latter case, the boundary for 'high skew' is fairly arbitrary, and for now set to 0.75. \n\nChanging this boundary may have a small effect on the results, but due to the randomness I observed for this model, it was a bit hard to test."},{"metadata":{"_uuid":"e84b0e80694ae1ac7213f762f0ff2a8814733313","_kg_hide-input":true,"_cell_guid":"c79ea2d4-2983-413d-9c75-d091dd0c449e","collapsed":true,"trusted":true},"cell_type":"code","source":"#Read data\npath = '../input/improving-pokemon-generation-1-predictions/'\nnumerical_df=pd.read_csv(path+\"numerical_features.csv\")\none_hot_df=pd.read_csv(path+\"one_hot_features.csv\")\nXGB_predictions_df=pd.read_csv(path+\"XGB_Predictions.csv\")\nSimpler_XGB_predictions_df=pd.read_csv(\"../input/pokemon-type-predictions-using-xgb/Simpler_XGB_Predictions.csv\")\npokemon_df=pd.read_csv(\"../input/pokemon/pokemon.csv\")\npokemon_df.type2.replace(np.NaN, 'none', inplace=True)\npokemon_df.type2.iloc[18]='none'\npokemon_df.type2.iloc[19]='none'\npokemon_df.type2.iloc[25]='none'\npokemon_df.type2.iloc[26]='none'\npokemon_df.type2.iloc[27]='none'\npokemon_df.type2.iloc[36]='none'\npokemon_df.type2.iloc[37]='none'\npokemon_df.type2.iloc[49]='none'\npokemon_df.type2.iloc[50]='none'\npokemon_df.type2.iloc[51]='none'\npokemon_df.type2.iloc[52]='none'\npokemon_df.type2.iloc[87]='none'\npokemon_df.type2.iloc[88]='none'\npokemon_df.type2.iloc[104]='none'","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"662a4fdf25e34cab82da84319294827ea117bff9","_kg_hide-input":true,"_cell_guid":"5037acb5-95a6-4bb9-9eb2-d27e1648de37","collapsed":true,"trusted":true},"cell_type":"code","source":"#Manual unskewing / normalizing / standardizing\n#Needed for linear methods etc, but don't need to worry about with XGB.\n\n#Get names of features which I'll class as skewed and unskewed(at least wrt right skewed)\nskewed_feats= numerical_df.skew()\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nunskewed_feats= numerical_df.skew()\nunskewed_feats = unskewed_feats[unskewed_feats < 0.75]\nunskewed_feats = unskewed_feats.index\n\n#The 0.5 is an arbitrary cut-off & can be fine-tuned to get the best result\n\n#Linearize the unskewed features & log transform the skewed features.\ntransform_df=pd.DataFrame()\ntransform_df[unskewed_feats]=(numerical_df[unskewed_feats]\n                               - numerical_df[unskewed_feats].mean()) / (numerical_df[unskewed_feats].max() - numerical_df[unskewed_feats].min())\ntransform_df[skewed_feats] = np.log1p(numerical_df[skewed_feats])\n\n#Make features\nfeatures=pd.concat([transform_df,one_hot_df],axis=1)\n\n#Make targets\ntargets=pd.DataFrame()\ntargets2=pd.DataFrame()\ntargets[\"type1\"]=pokemon_df[\"type1\"]\ntargets=np.ravel(targets)\ntargets2[\"type2\"]=pokemon_df[\"type2\"]\ntargets2=np.ravel(targets2)\n\n#Split features & targets into each generation.\nGen1_features=features[0:151]\nGen2_features=features[151:251]\nGen3_features=features[251:386]\nGen4_features=features[386:493]\nGen5_features=features[493:649]\nGen6_features=features[649:721]\nGen7_features=features[721:801]\nGen1_targets=targets[0:151]\nGen2_targets=targets[151:251]\nGen3_targets=targets[251:386]\nGen4_targets=targets[386:493]\nGen5_targets=targets[493:649]\nGen6_targets=targets[649:721]\nGen7_targets=targets[721:801]\nGen1_targets=np.ravel(Gen1_targets)\nGen2_targets=np.ravel(Gen2_targets)\nGen3_targets=np.ravel(Gen3_targets)\nGen4_targets=np.ravel(Gen4_targets)\nGen5_targets=np.ravel(Gen5_targets)\nGen6_targets=np.ravel(Gen6_targets)\nGen7_targets=np.ravel(Gen7_targets)\n\n#Recombine 6 of them, in 7 different ways, to make my different training sets\n#Ordering of the features & targets should be the same!\n#But doesn't have to be necessarily in numerical order\nGens_not1_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not2_features=pd.concat([Gen1_features,Gen3_features,Gen4_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not3_features=pd.concat([Gen2_features,Gen1_features,Gen4_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not4_features=pd.concat([Gen2_features,Gen3_features,Gen1_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not5_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen1_features,Gen6_features,Gen7_features],axis=0)\nGens_not6_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen5_features,Gen1_features,Gen7_features],axis=0)\nGens_not7_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen5_features,Gen6_features,Gen1_features],axis=0)\nGens_not1_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not2_targets=np.concatenate((Gen1_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not3_targets=np.concatenate((Gen2_targets,Gen1_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not4_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen1_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not5_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen1_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not6_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen1_targets,Gen7_targets),axis=0)\nGens_not7_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen1_targets),axis=0)\n\nGen1_targets2=targets2[0:151]\nGen2_targets2=targets2[151:251]\nGen3_targets2=targets2[251:386]\nGen4_targets2=targets2[386:493]\nGen5_targets2=targets2[493:649]\nGen6_targets2=targets2[649:721]\nGen7_targets2=targets2[721:801]\nGen1_targets2=np.ravel(Gen1_targets2)\nGen2_targets2=np.ravel(Gen2_targets2)\nGen3_targets2=np.ravel(Gen3_targets2)\nGen4_targets2=np.ravel(Gen4_targets2)\nGen5_targets2=np.ravel(Gen5_targets2)\nGen6_targets2=np.ravel(Gen6_targets2)\nGen7_targets2=np.ravel(Gen7_targets2)\nGens_not1_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not2_targets2=np.concatenate((Gen1_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not3_targets2=np.concatenate((Gen2_targets2,Gen1_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not4_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen1_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not5_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen1_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not6_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen1_targets2,Gen7_targets2),axis=0)\nGens_not7_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen1_targets2),axis=0)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"5103ed6b307937d8e2dadd50f4c30d3e0b5052a3","_cell_guid":"0261f1ba-0707-40d5-86d6-0e35cba49c2e"},"cell_type":"markdown","source":"# Getting started with a DNN Classifier\n\nTo start with, I just wanted to get the DNN Classifier working, and not worry about the actual results. I had a couple of false starts, where I forgot to regularize the data, or had the labels set up wrong between the training and test data. Eventually I fixed all these problems and managed to get the DNN running fairly smoothly.\n\nInitial tests gave accuracies in the mid to high 60%, which is approximately what I managed with the XGBoost models. This was a good sign that I was on the right track.\n\nJust like with XGBoost there are lots of parameters to tune to improve your DNN, but this was made more complicated by the fact that the model's predictions were fairly unstable. For exactly the same settings, it was possible to find differences in the test accuracy of 5-10%, so it was not immediately clear how changing parameters actually affected the results. It only became obvious when a bad choice was made, because the accuracy regularly fell below 60%.\n\nOn rare occasions, the accuracy for a single run might go over 70%, but I could not find settings where this would occur regularly. In the end, leaving most of the parameters as the default, and setting learning rate to 0.1, and steps to 1000 was enough to give satisfactory results.\n\nI read elsewhere that often you don't really need more than 1 layer of neurons, so only used 1 layer for now. I also read that the number of neurons should usually be between the number of features and the number of targets, with the mean a good starting point. As such, I started working with hidden_units=[259].\n\nTo deal with the inherent randomness of the models, I'd seen the suggestion to run it 30+ times and compare the results. From initial testing I found that above about 100 hidden units, there was not much difference between the models, but sticking with 259 seemed to perform slightly better, with an average of ~67% and a peak at ~71%.\n\nThese settings were also sufficient to achieve >98% accuracy on the training set, and sometimes 100%.\n\nSince this is a classification problem, it should be possible to combine the predictions from multiple different models to come up with an aggregate solution. In general, I feel it would make most sense to use the modal value for each prediction, taken from across the full set of predictions.\n\nIn this case, since we know what the targets are already, it should also be possible to stack the models on top of each other, adding the new correct predictions from later models onto the first model.\n\nThe stacking model is likely to be slightly more accurate, because it can pick out rare instances of correct predictions from amongst the many models."},{"metadata":{"_uuid":"a4e6d181b000a0c6bbd2d9f1f874def2887f43fe","_cell_guid":"0ca1efde-cf86-41e1-b9ce-69748c13a630"},"cell_type":"markdown","source":"# Main Type Predictions\n\nAs before, I split my models into predictions of the main and sub-types, and used any order mismatches to reinforce the other.\n\nI tested various different runs of the DNN per Type, and even for large numbers of runs (70), or multiple sets of the same number of runs (i.e. 40 runs, 3 times), I still found some variability to the results for the modal and stacked accuracies. The modal accuracies were more stable, varying only over 1-2%, whereas the stacked accuracies could vary by ~6% from ~72% to ~78%, with no guarantee that longer runs would actually be better.\n\nFor example, my best result in testing was 78.81%, which happened during a 30 run test.\n\nI eventually settled on using 30 runs of the DNN per Type, and stacking new correct predictions from later models onto the first run. This was at least partly so the kernel didn't run for too long, since even that takes about an hour."},{"metadata":{"_uuid":"d1fd4c81aa5e63953defcabeefc75d90ae9fc033","_kg_hide-input":true,"_cell_guid":"77022a5e-a98d-4899-b8cb-794dc42c2cb8","_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"#Initial set-up and run of the NN model.\nType1_recombine=np.concatenate((Gen1_targets,Gens_not1_targets))\nType1_labels,Type1_levels = pd.factorize(Type1_recombine)\nType1_test_labels=Type1_labels[0:151]\nType1_train_labels=Type1_labels[151:801]\n# Specify feature\nfeature_columns = set([tf.feature_column.numeric_column(my_feature)\n              for my_feature in Gens_not1_features])\n\n# Build DNN classifier\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[259],\n    optimizer = tf.train.AdamOptimizer(1e-2),\n    n_classes=18,\n    #dropout=0.05,\n    #weight_column=None,\n    #label_vocabulary=None,\n    #activation_fn=tf.nn.dropout,\n    #input_layer_partitioner=None,\n    #config=None,\n    #warm_start_from=None,\n    #loss_reduction=losses.Reduction.SUM\n)\n\n# Define the training inputs\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {key:np.array(value) for key,value in dict(Gens_not1_features).items()},\n    y=Type1_train_labels,\n    num_epochs=None,\n    batch_size=50,\n    shuffle=True\n)\n\nclassifier.train(input_fn=train_input_fn, steps=100)\n\n# Define the test inputs\ntest_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {key:np.array(value) for key,value in dict(Gen1_features).items()},\n    y=Type1_test_labels,\n    num_epochs=1,\n    shuffle=False\n)\n\ntrain_check_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {key:np.array(value) for key,value in dict(Gens_not1_features).items()},\n    y=Type1_train_labels,\n    num_epochs=1,\n    shuffle=False\n)\n#Make predictions\npredictions = classifier.predict(input_fn=test_input_fn)\npredictions=np.array([item['class_ids'][0] for item in predictions])\n# Evaluate accuracy\naccuracy = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\nprint(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy*100))\naccuracy = classifier.evaluate(input_fn=train_check_input_fn)[\"accuracy\"]\nprint(\"\\nTrain Accuracy: {0:f}%\\n\".format(accuracy*100))","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"b7e4f8ba684f0ca93e233e6d8b21f69f5dc9753c","_kg_hide-input":true,"_cell_guid":"67caf566-2c50-4b16-911c-05e644749eb6","trusted":true},"cell_type":"code","source":"#Run the DNN X times and get the modal values for all of the predictions.\nType1_pool_predictions = []\nruns = 30\nfor i in range(0,runs):\n    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[259],\n    optimizer = tf.train.AdamOptimizer(1e-2),n_classes=18,)\n    classifier.train(input_fn=train_input_fn, steps=1000)\n    predictions = classifier.predict(input_fn=test_input_fn)\n    predictions=np.array([item['class_ids'][0] for item in predictions])\n    Type1_pool_predictions.append(predictions)\n    accuracy = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n    #print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy*100))\n    #Remove model after doing all the predictions etc, so that there's space left to do\n    #lots of runs\n    shutil.rmtree(classifier.model_dir)\n    \n#Not the most elegant way I'm sure, \n#but get the mode from this set of predictions, and use that instead.\n\nType1_mode_predict=[]\nType1_values=[[] for y in range(0,len(Gen1_targets))]\n\nfor i in range (0,runs):\n    for j in range(0,len(Gen1_targets)):\n        Type1_values[j].append(Type1_pool_predictions[i][j])\n        \nfrom collections import Counter\nType1_mode_predict=[]\nfor i in range (0,len(Gen1_targets)):\n    c = Counter(Type1_values[i])\n    value, count = c.most_common()[0]\n    Type1_mode_predict.append(value)\n\n#for i in range (0,len(Gen1_targets)):\n#    Type1_mode_value=statistics.mode(Type1_values[i])\n#    Type1_mode_predict.append(Type1_mode_value)\n\nType1_mode_predict=Type1_levels[Type1_mode_predict]\nType1_mode_accuracy = accuracy_score(Gen1_targets, Type1_mode_predict)\nprint(\"Mode Type 1 Accuracy: %.2f%%\" % (Type1_mode_accuracy * 100.0))","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"300ddc65a02ca3b3c4d2a1ffbd571cfa810d3e37","_kg_hide-input":true,"_cell_guid":"b498c62e-4da5-41bb-aafa-3bd745b9af33","trusted":true},"cell_type":"code","source":"#Put code here for the stacking model\nType1_pooled=[[0 for x in range(runs)] for y in range(0,len(Gen1_targets))]\n#Need to do the level conversion.\nfor i in range(0,runs):\n    Type1_pooled[i]=Type1_levels[Type1_pool_predictions[i]]\n\nType1_stack_preds=Type1_pooled[0].copy()\nfor i in range(1,runs):\n    for j in range(0,len(Gen1_targets)):\n        if Type1_pooled[i][j] == Gen1_targets[j]:\n            Type1_stack_preds[j]=Type1_pooled[i][j]\n            \nT1_stacked_accuracy = accuracy_score(Gen1_targets, Type1_stack_preds)\nprint(\"Stacked Type 1 Accuracy: %.2f%%\" % (T1_stacked_accuracy * 100.0))","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"1478216090b62299e45e88a442268aec50432181","_kg_hide-input":true,"_cell_guid":"8b29bd9f-8e97-4aba-b98e-4fc4cd1dec84","collapsed":true,"trusted":true},"cell_type":"code","source":"#T1_preds=Type1_levels[predictions]\nT1_preds=Type1_stack_preds.copy()\n#T1_preds=Type1_mode_predict.copy()","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"46da2acf1ed860e18ba3427859ed8358cbe1c2be","_kg_hide-input":true,"_cell_guid":"5116590a-433f-4545-9d6a-0e87a7d33de2","trusted":true},"cell_type":"code","source":"labels =list(set(Gen1_targets))\ncm = metrics.confusion_matrix(Gen1_targets, T1_preds,labels)\n# Normalize the confusion matrix by row (i.e by the number of samples\n# in each class)\ncm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4)\nplt.figure(figsize=(20,20))\nax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\nax.set_aspect(1)\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title(\"Type 1 Confusion matrix\")\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"4b8d37f0dd75f64c59444981265645b00baa2298","_cell_guid":"4d1f8183-40d1-4e41-af0c-f130cdefd218"},"cell_type":"markdown","source":"Due to the slight variations between runs, it's not possible to comment on the exact output of the final run of this kernel, but the general trends will be the same. The differences in accuracy will amount to probably about 10 Pokemon overall.\n\nDespite this, it's clear that certain types perform well, and others less so. Ghost, Bug, Fairy, Grass and Normal all getting close to 100% accuracy. Most other types are predicted fairly well, with more correct predictions than not. Some like Rock seem to be particularly difficult."},{"metadata":{"_uuid":"13e9d939101756bf26fbc5bc5a1805e5a61a4f47","_kg_hide-input":true,"_cell_guid":"2bac3c44-ecc6-421a-9d5a-3a7ced819cd2","collapsed":true,"trusted":false},"cell_type":"code","source":"#print(\"Pokemon with incorrect types are as follows:\")\n#for i in range(0,len(Gen1_targets)):\n#    if T1_preds[i] != Gen1_targets[i]:\n#        print (pokemon_df[\"name\"][i],T1_preds[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8eebdd57e25cb8fe30788a676577ac7cdc4178df","_kg_hide-input":true,"_cell_guid":"990f994a-b339-427d-9fa9-4890f88dfa52","trusted":true},"cell_type":"code","source":"print(\"Some predictions may match the sub-type, rather than the main type\")\nmismatch_accuracy = accuracy_score(Gen1_targets2, T1_preds)\nprint(\"Mismatch Accuracy: %.2f%%\" % (mismatch_accuracy * 100.0))\nprint(\"The Pokemon whose predicted types match their sub-type are:\")\nfor i in range(0,len(Gen1_targets)):\n    if T1_preds[i] == Gen1_targets2[i]:\n        print (pokemon_df[\"name\"][i])","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"3a699ac4e05bb2a7023c227e127c061961649b08","_cell_guid":"b612e684-91c6-490a-bd8b-a45e0a5dd9da"},"cell_type":"markdown","source":"As I found with the XG Boost models, It's possible that some Pokemon have had their sub-type predicted correctly, rather than the main type. This occurs for a small fraction of the possible Pokemon, and can change slightly from run to run. In general though, the Fossil Pokemon appear nearly all the time. Other common appearances are Dewgong, which mixes up Water and Ice, or Magnemite/Magneton with it's Steel sub-type."},{"metadata":{"_uuid":"c949df0c0f943977161e08d9df4c0bd5ebb56f3c","_cell_guid":"70aa84ff-1f02-48e7-bfab-345fa3893305"},"cell_type":"markdown","source":"# Sub-Type Predictions"},{"metadata":{"_uuid":"17555b85708736cc13c5f332ccd2c3801ca7877d","_cell_guid":"370cb4bb-46ce-4f1e-bab8-68f9d8233d1d"},"cell_type":"markdown","source":"Due to the amount of time it takes to test the results, I just settled on reusing the parameters from the Main type for the sub-type, only adjusting the number of classes to account for the presence of 'none'."},{"metadata":{"_uuid":"1c5299845ff169aa65b1a4b04dc5f27868728790","_kg_hide-input":true,"_cell_guid":"316a2260-b082-4e44-b81e-d3e77829078c","trusted":true},"cell_type":"code","source":"Type2_recombine=np.concatenate((Gen1_targets2,Gens_not1_targets2))\nType2_labels,Type2_levels = pd.factorize(Type2_recombine)\nType2_test_labels=Type2_labels[0:151]\nType2_train_labels=Type2_labels[151:801]\n\n# Specify feature\nfeature_columns = set([tf.feature_column.numeric_column(my_feature)\n              for my_feature in Gens_not1_features])\n\n# Build 2 layer DNN classifier\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[259],\n    optimizer = tf.train.AdamOptimizer(1e-2),\n    n_classes=19,\n    #dropout=0.05,\n    #weight_column=None,\n    #label_vocabulary=None,\n    #activation_fn=tf.nn.dropout,\n    #input_layer_partitioner=None,\n    #config=None,\n    #warm_start_from=None,\n    #loss_reduction=losses.Reduction.SUM\n)\n\n# Define the training inputs\nT2_train_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {key:np.array(value) for key,value in dict(Gens_not1_features).items()},\n    y=Type2_train_labels,\n    num_epochs=None,\n    batch_size=50,\n    shuffle=True\n)\n\nclassifier.train(input_fn=T2_train_input_fn, steps=1000)\n\n# Define the test inputs\nT2_test_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {key:np.array(value) for key,value in dict(Gen1_features).items()},\n    y=Type2_test_labels,\n    num_epochs=1,\n    shuffle=False\n)\n\nT2_train_check_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x = {key:np.array(value) for key,value in dict(Gens_not1_features).items()},\n    y=Type2_train_labels,\n    num_epochs=1,\n    shuffle=False\n)\npredictions = classifier.predict(input_fn=T2_test_input_fn)\npredictions=np.array([item['class_ids'][0] for item in predictions])\n# Evaluate accuracy\n#train_accuracy_score = classifier.evaluate(input_fn=train_input_fn)[\"accuracy\"]\n#print(\"\\nTrain Accuracy: {0:f}%\\n\".format(train_accuracy_score*100))\naccuracy = classifier.evaluate(input_fn=T2_test_input_fn)[\"accuracy\"]\nprint(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy*100))\naccuracy = classifier.evaluate(input_fn=T2_train_check_input_fn)[\"accuracy\"]\nprint(\"\\nTrain Accuracy: {0:f}%\\n\".format(accuracy*100))","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"bc08f1f9033f26223051483285a5d79b86428cf4","_kg_hide-input":true,"_cell_guid":"dcf6ce8b-cbe3-462e-bdb1-e609fae1fffc","trusted":true,"scrolled":true},"cell_type":"code","source":"#Run the DNN X times and get the modal values for all of the predictions.\nType2_pool_predictions = []\nruns = 30\nfor i in range(0,runs):\n    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,hidden_units=[259],\n    optimizer = tf.train.AdamOptimizer(1e-2),n_classes=19,)\n    classifier.train(input_fn=T2_train_input_fn, steps=1000)\n    predictions = classifier.predict(input_fn=T2_test_input_fn)\n    predictions=np.array([item['class_ids'][0] for item in predictions])\n    Type2_pool_predictions.append(predictions)\n    accuracy = classifier.evaluate(input_fn=T2_test_input_fn)[\"accuracy\"]\n    #print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy*100))\n    #Remove model after doing all the predictions etc, so that there's space left to do\n    #lots of runs\n    shutil.rmtree(classifier.model_dir)\n    \n#Not the most elegant way I'm sure, \n#but get the mode from this set of predictions, and use that instead.\n\nType2_mode_predict=[]\nType2_values=[[] for y in range(0,len(Gen1_targets2))]\n\nfor i in range (0,runs):\n    for j in range(0,len(Gen1_targets2)):\n        Type2_values[j].append(Type2_pool_predictions[i][j])\n        \nfrom collections import Counter\nType2_mode_predict=[]\nfor i in range (0,len(Gen1_targets2)):\n    c = Counter(Type2_values[i])\n    value, count = c.most_common()[0]\n    Type2_mode_predict.append(value)\n\n#for i in range (0,len(Gen1_targets)):\n#    Type1_mode_value=statistics.mode(Type1_values[i])\n#    Type1_mode_predict.append(Type1_mode_value)\n\nType2_mode_predict=Type2_levels[Type2_mode_predict]\nType2_mode_accuracy = accuracy_score(Gen1_targets2, Type2_mode_predict)\nprint(\"Mode Type 2 Accuracy: %.2f%%\" % (Type2_mode_accuracy * 100.0))","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"4c0bcc387156f1611df1b0a5b745827217cc9430","_kg_hide-input":true,"_cell_guid":"9e365ce1-80ed-41a8-97d4-8040d0cb7016","trusted":true},"cell_type":"code","source":"#Put code here for the stacking model\nType2_pooled=[[0 for x in range(runs)] for y in range(0,len(Gen1_targets2))]\n#Need to do the level conversion.\nfor i in range(0,runs):\n    Type2_pooled[i]=Type2_levels[Type2_pool_predictions[i]]\n\nType2_stack_preds=Type2_pooled[0].copy()\nfor i in range(1,runs):\n    for j in range(0,len(Gen1_targets2)):\n        if Type2_pooled[i][j] == Gen1_targets2[j]:\n            Type2_stack_preds[j]=Type2_pooled[i][j]\n            \nT2_stacked_accuracy = accuracy_score(Gen1_targets2, Type2_stack_preds)\nprint(\"Stacked Type 2 Accuracy: %.2f%%\" % (T2_stacked_accuracy * 100.0))","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"a59005c1171f79a5b4e563e8e508e4185eb3e27d","_kg_hide-input":true,"_cell_guid":"b128d9b8-75bb-49e0-ae01-13565522bf8b","collapsed":true,"trusted":true},"cell_type":"code","source":"#T2_preds=Type2_levels[predictions]\nT2_preds=Type2_stack_preds.copy()","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"93e7aae2f45d3dec26c6fe1992e1721abf1802fd","_kg_hide-input":true,"_cell_guid":"57d71dc4-1fb4-4cba-9c22-8b63973091fa","trusted":true},"cell_type":"code","source":"labels =list(set(Gen1_targets2))\ncm = metrics.confusion_matrix(Gen1_targets2, T2_preds,labels)\n# Normalize the confusion matrix by row (i.e by the number of samples\n# in each class)\ncm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4)\nplt.figure(figsize=(20,20))\nax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\nax.set_aspect(1)\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title(\"Type 2 Confusion matrix\")\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.show()","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"4da119baa4590ab60a59c235a031f4a95a4bfcaa"},"cell_type":"markdown","source":"By stacking multiple DNN models it is possible to get a higher sub-type accuracy than other methods. This is likely because it can pick out the rare instances of a type from all the 'None' predictions. \n\nSome types, like Ice, Fighting, Poison and Grass still seem to be a problem for the model, but everything else is predicted with relatively high accuracy."},{"metadata":{"_uuid":"a95443c7969ddab8ac6f2dc7c058cd78b2025592","_kg_hide-input":true,"_cell_guid":"e028c244-1ecc-4a2a-b189-6287ad70b98b","collapsed":true,"trusted":false},"cell_type":"code","source":"#print(\"Pokemon with incorrect sub-type are as follows:\")\n#for i in range(0,len(Gen1_targets2)):\n#    if T2_preds[i] != Gen1_targets2[i]:\n#        print (pokemon_df[\"name\"][i],T2_preds[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e18965bea2a28f01783c7dc840f4ab2d05242ea","_kg_hide-input":true,"_cell_guid":"2ec9a92f-2589-4608-afe2-b89351d49f90","trusted":true},"cell_type":"code","source":"print(\"Some predictions may match the main type, rather than the sub type\")\nmismatch_accuracy = accuracy_score(Gen1_targets, T2_preds)\nprint(\"Mismatch Accuracy: %.2f%%\" % (mismatch_accuracy * 100.0))\nprint(\"The Pokemon whose predicted types match their main type are:\")\nfor i in range(0,len(Gen1_targets)):\n    if T2_preds[i] == Gen1_targets[i]:\n        print (pokemon_df[\"name\"][i])","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"ea359b752d7dc58d26b4d1ae6b881331875fcc04","_cell_guid":"f676caae-421e-4a2f-83b4-692bf19ecc15"},"cell_type":"markdown","source":"As always, there are still some correct predictions, but for the wrong type, although the number is relatively small now, since the base model has been improved."},{"metadata":{"_uuid":"eab4942541cd801123193d90507596059f6e3d6a","_cell_guid":"86dbf2bc-110b-40c8-a424-6c85d9aff9d4"},"cell_type":"markdown","source":"# Cross-checking Main and Sub-Type Predictions\n\nAs we saw for the XGBoost predictions, it's possible to improve the overall accuracy of both sets of predictions by transferring across the predictions that are correct, but in the wrong order."},{"metadata":{"_uuid":"58d45cfb896335ba294a9aea31e665bef7f93022","_kg_hide-input":true,"_cell_guid":"b0444764-0af1-4341-9e70-c59383be0b79","trusted":true},"cell_type":"code","source":"T1_preds_v2=T1_preds.copy()\nT2_preds_v2=T2_preds.copy()\nfor i in range(0,len(Gen1_targets)):\n    if T1_preds[i] == Gen1_targets2[i]:\n        T2_preds_v2[i]=T1_preds[i]\n        \nfor i in range(0,len(Gen1_targets)):\n    if T2_preds[i] == Gen1_targets[i]:\n        T1_preds_v2[i]=T2_preds[i]\n        \nType1_accuracy = accuracy_score(Gen1_targets, T1_preds_v2)\nprint(\"New Type 1 Accuracy: %.2f%%\" % (Type1_accuracy * 100.0))\nType2_accuracy = accuracy_score(Gen1_targets2, T2_preds_v2)\nprint(\"New Type 2 Accuracy: %.2f%%\" % (Type2_accuracy * 100.0))","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"b4ea3d19dadcb32cdbb68a2e626295a6964e1f86","_cell_guid":"211e3255-66fa-44ef-b3af-f4d090baebc8"},"cell_type":"markdown","source":"Generally, this will improve both sets of predictions by a couple of %. At best, with a lucky run, I was able to get the accuracies up to ~80% and nearly 75% on the main and sub-types, marginally better than my older XGB predictions."},{"metadata":{"_uuid":"ee10cc29728291ae18b54393277bc9dde4708138","_cell_guid":"13aba96c-2a7c-47bd-b577-196aba0cfeed"},"cell_type":"markdown","source":"# Combine with XGB Predictions\n\nAnother way to improve the model might be to combine it with the XGB predictions, using both the more complicated model with one-hot encoded categories and parameter tuning, and the simpler one with feature selection.\n\nAlone, all 3 models tend to fall somewhere around 70%, but it's possible that the correct predictions are not the same between each model."},{"metadata":{"_uuid":"2b938455ef2ac0d7b3b2fcd1654f68d7233a52d8","_kg_hide-input":true,"_cell_guid":"58349773-0635-4688-928e-2de9a303894e","trusted":true},"cell_type":"code","source":"Type1_accuracy = accuracy_score(Gen1_targets, XGB_predictions_df[\"Type1\"])\nprint(\"XGB Type 1 Accuracy: %.2f%%\" % (Type1_accuracy * 100.0))\nType2_accuracy = accuracy_score(Gen1_targets2, XGB_predictions_df[\"Type2\"])\nprint(\"XGB Type 2 Accuracy: %.2f%%\" % (Type2_accuracy * 100.0))","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"2ac5804f6054fd0ec01af61b4efd64b494343c7c","_kg_hide-input":true,"_cell_guid":"e58f67af-1990-4c56-b314-4ed5a3f58d22","trusted":true},"cell_type":"code","source":"print(\"How much agreement is there between predictions for Type 1?\")\nmethod_agreement = accuracy_score(XGB_predictions_df[\"Type1\"], T1_preds_v2)\nprint(\"Method Agreement: %.2f%%\" % (method_agreement * 100.0))\nprint(\"How much agreement is there between predictions for Type 2?\")\nmethod_agreement = accuracy_score(XGB_predictions_df[\"Type2\"], T2_preds_v2)\nprint(\"Method Agreement: %.2f%%\" % (method_agreement * 100.0))","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"adb4bf0b054783ade3716b695b9b12c70f07c819","_cell_guid":"d29eab05-a8bb-4e4c-bc9e-3485af3411b5"},"cell_type":"markdown","source":"Comparing the DNN predictions against the more complicated version of the XGB predictions shows that in general, they agree more often than not, but still vary by ~20-30%. Now it's likely that a good chunk of this is just different incorrect predictions for certain Pokemon, but it's also possible that one model contains correct predictons absent from the other.\n\nTo check this, I replaced some predictions from the XGB model with correct predictions from the DNN model, and checked how this affected the overall accuracy. In general, it was possible to raise the accuracy for both types closer to the 80% mark, and often higher for the main type.\n\nOn rare occasions, when I had a good set of DNN runs, this could go even higher, with the best result I found during my tests of 91.39% and 79.47%."},{"metadata":{"_uuid":"24c1114c8764d2e1c57d695e0ccee86970bf7fc4","_kg_hide-input":true,"_cell_guid":"84c0daa1-12b1-4f6f-b033-c965a12542cb","trusted":true},"cell_type":"code","source":"#Want to compare NN vs XGB preds, and pool the correct ones into a new model.\n#Start by copying the XGB predictions\n\nType1_Combined_preds=XGB_predictions_df[\"Type1\"].copy()\n\n#Then compare NN against the targets, and replace the predictions when the NN matches\n#Since this will copy over equivalent results in a lot of cases, might waste time?\n\nfor i in range(0,len(Gen1_targets)):\n    if T1_preds_v2[i] == Gen1_targets[i]:\n        Type1_Combined_preds[i]=T1_preds_v2[i]\n        \nType1_combined_accuracy = accuracy_score(Gen1_targets,Type1_Combined_preds)\nprint(\"Blending XGB and NN gives Type 1 Accuracy: %.2f%%\" % (Type1_combined_accuracy * 100.0))\n\nType2_Combined_preds=XGB_predictions_df[\"Type2\"].copy()\n\nfor i in range(0,len(Gen1_targets2)):\n    if T2_preds_v2[i] == Gen1_targets2[i]:\n        Type2_Combined_preds[i]=T2_preds_v2[i]\n        \nType2_combined_accuracy = accuracy_score(Gen1_targets2,Type2_Combined_preds)\nprint(\"Blending XGB and NN gives Type 2 Accuracy: %.2f%%\" % (Type2_combined_accuracy * 100.0))","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"9974532b5e37b7999712e557cb12efd091b9ae72","_cell_guid":"1e01514f-c0a0-4f3d-bb13-7d61f2689778"},"cell_type":"markdown","source":"What about my simpler XGB model with only feature selection & no one-hot encoding? Whilst the weakest model overall, it could be that it was correct on a few Pokemon that the others struggled with. At the time, I hadn't implemented the cross-checks between main and sub-type, so I've added that here."},{"metadata":{"_uuid":"9f69d514f851b726d2470601dbfc5437d2396298","_kg_hide-input":true,"_cell_guid":"e107c632-d82a-43e4-8770-f17fd4934db5","trusted":true},"cell_type":"code","source":"Type1_accuracy = accuracy_score(Gen1_targets, Simpler_XGB_predictions_df[\"Type1\"])\nprint(\"Simpler XGB Type 1 Accuracy: %.2f%%\" % (Type1_accuracy * 100.0))\nType2_accuracy = accuracy_score(Gen1_targets2, Simpler_XGB_predictions_df[\"Type2\"])\nprint(\"Simpler XGB Type 2 Accuracy: %.2f%%\" % (Type2_accuracy * 100.0))","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"3292ebf554d8056c2a7c1e9721b445c364fa5c69","_kg_hide-input":true,"_cell_guid":"f64d5d14-3332-4dd8-a2cc-42c9b49e4cf7","trusted":true},"cell_type":"code","source":"mismatch_accuracy = accuracy_score(Gen1_targets2, Simpler_XGB_predictions_df[\"Type1\"])\nprint(\"Type 1 Mismatch Accuracy: %.2f%%\" % (mismatch_accuracy * 100.0))\nmismatch_accuracy = accuracy_score(Gen1_targets, Simpler_XGB_predictions_df[\"Type2\"])\nprint(\"Type 2 Mismatch Accuracy: %.2f%%\" % (mismatch_accuracy * 100.0))","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"bc0bcfc5babb8850fe36a57531a14d155a470453","_kg_hide-input":true,"_cell_guid":"8c268370-dcfc-41f5-9c58-2c45f2e7d5b2","trusted":true},"cell_type":"code","source":"T1_simpler_preds=Simpler_XGB_predictions_df[\"Type1\"].copy()\nT2_simpler_preds=Simpler_XGB_predictions_df[\"Type2\"].copy()\nfor i in range(0,len(Gen1_targets)):\n    if Simpler_XGB_predictions_df[\"Type1\"][i] == Gen1_targets2[i]:\n        T2_simpler_preds[i]=Simpler_XGB_predictions_df[\"Type1\"][i]\n        \nfor i in range(0,len(Gen1_targets)):\n    if Simpler_XGB_predictions_df[\"Type2\"][i] == Gen1_targets[i]:\n        T1_simpler_preds[i]=Simpler_XGB_predictions_df[\"Type2\"][i]\n        \nType1_accuracy = accuracy_score(Gen1_targets, T1_simpler_preds)\nprint(\"Improved Type 1 Accuracy: %.2f%%\" % (Type1_accuracy * 100.0))\nType2_accuracy = accuracy_score(Gen1_targets2, T2_simpler_preds)\nprint(\"Improved Type 2 Accuracy: %.2f%%\" % (Type2_accuracy * 100.0))","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"437516b07c0a7325a491c675acfe02b060474625","_cell_guid":"f023deae-0b6d-44af-92cd-8dc494be3404"},"cell_type":"markdown","source":"The simpler model can be improved to 72.85 / 71.52 %, which is actually better than the more complicated XGB model for the sub-type!\n\nAs above, it's then possible to combine this with our earlier 2 models, and look for improvements."},{"metadata":{"_uuid":"6cb80efb730e55a85e0639c5f42861ed4a437878","_kg_hide-input":true,"_cell_guid":"2172edf9-ec6f-43a1-9828-ff01b3470868","trusted":true},"cell_type":"code","source":"print(\"How much agreement is there between predictions for Type 1?\")\nmethod_agreement = accuracy_score(T1_simpler_preds, Type1_Combined_preds)\nprint(\"Method Agreement: %.2f%%\" % (method_agreement * 100.0))\nprint(\"How much agreement is there between predictions for Type 2?\")\nmethod_agreement = accuracy_score(T2_simpler_preds, Type2_Combined_preds)\nprint(\"Method Agreement: %.2f%%\" % (method_agreement * 100.0))","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"33480f3dfa1dc2328f17f2a78ac69ca67fecb616","_kg_hide-input":true,"_cell_guid":"34f8bdaa-812d-4ad1-b822-1415dc652bbf","trusted":true},"cell_type":"code","source":"for i in range(0,len(Gen1_targets)):\n    if T1_simpler_preds[i] == Gen1_targets[i]:\n        Type1_Combined_preds[i]=T1_simpler_preds[i]\n        \nType1_combined_accuracy = accuracy_score(Gen1_targets,Type1_Combined_preds)\nprint(\"Blending with the other XGB model gives Type 1 Accuracy: %.2f%%\" \n      % (Type1_combined_accuracy * 100.0))\n\nfor i in range(0,len(Gen1_targets2)):\n    if T2_simpler_preds[i] == Gen1_targets2[i]:\n        Type2_Combined_preds[i]=T2_simpler_preds[i]\n        \nType2_combined_accuracy = accuracy_score(Gen1_targets2,Type2_Combined_preds)\nprint(\"Blending with the other XGB model gives Type 2 Accuracy: %.2f%%\" \n      % (Type2_combined_accuracy * 100.0))","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"46c310b349f6a942a065a8d21d58a36b028e72e0","_cell_guid":"d30e7ae6-e129-421b-8b5e-3af7e9ab4c6c"},"cell_type":"markdown","source":"# Final Predictions\n\nWhen all 3 models were combined, I generally found that the main type accuracy was in the high 80%, with the sub-type accuracy in the low 80%. My best overall result was 92.05% / 82.12%.\n\nWith the new and improved predictions, it's now time to look at overall trends in detail again, and see if any types stand out as particularly problematic, or any individual Pokemon."},{"metadata":{"_uuid":"23c7f276d4a4246cf4190d9e61e78cc25bb2cd3a","_kg_hide-input":true,"_cell_guid":"cfa8cdd8-f0b4-4963-a78b-1b9a8bc4a205","trusted":true},"cell_type":"code","source":"labels =list(set(Gen1_targets))\ncm = metrics.confusion_matrix(Gen1_targets, Type1_Combined_preds,labels)\n# Normalize the confusion matrix by row (i.e by the number of samples\n# in each class)\ncm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4)\nplt.figure(figsize=(20,20))\nax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\nax.set_aspect(1)\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title(\"Type 1 Confusion matrix\")\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.show()","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"221adacd3598062724c386ddeaba3f4a32ee85e4"},"cell_type":"markdown","source":"For the Main type, Ice, Fighting and Poison stand out as particular remaining problems. Ice still has the Ice/Water problem, and the other two are often mistaken for Normal."},{"metadata":{"_uuid":"ccac6544a173cb7f564898974cd59be712490184","_kg_hide-input":true,"_cell_guid":"d70eb648-3669-45ec-bd12-d5301d9b9d63","trusted":true},"cell_type":"code","source":"labels =list(set(Gen1_targets2))\ncm = metrics.confusion_matrix(Gen1_targets2, Type2_Combined_preds,labels)\n# Normalize the confusion matrix by row (i.e by the number of samples\n# in each class)\ncm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4)\nplt.figure(figsize=(20,20))\nax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\nax.set_aspect(1)\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title(\"Type 2 Confusion matrix\")\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.show()","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"8a209665be3d08162b4eb62111e2bda6931f5119"},"cell_type":"markdown","source":"For the sub-type, predictions overall are improved, but Grass and Fighting are still a problem, generally failing to getting any correct predictions. Ice has slightly improved though."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true,"_uuid":"f75c0e908fb1641a45de5321602602fe984b7dfc"},"cell_type":"code","source":"Pokemon_predictions_df=pd.DataFrame()\nPokemon_predictions_df[\"Type1\"]=0\nPokemon_predictions_df[\"Type1\"]=Type1_Combined_preds\nPokemon_predictions_df[\"Type2\"]=0\nPokemon_predictions_df[\"Type2\"]=Type2_Combined_preds\nPokemon_predictions_df.to_csv(\"Pokemon_Predictions.csv\",index=False)","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"3add52817496e5227a84aa845d527a47c21f96e6"},"cell_type":"markdown","source":"In general, a handful of Pokemon are leftover, which are still predicted incorrectly. There is slight variation from run to run, but there are also some common entries.\n\nThe Nidorans is some form often appear, which surprises me, since they can have the ability Poison Point, which I thought would have been a giveaway. However, close inspection of the XGB models (for example), showed that the feature corresponding to Poison Point was not used in the one-hot encoded model.\n\nMankey and Primeape generally come out as Normal, presumably because little about them stands out as being Fighting.\n\nSometimes the problem is an understandable type confusion, for example Graveler as Steel rather than Rock, or Cubone as Rock rather than Ground, since the types are similar.\n\nOther times, it's clear what features could be causing problems, such as Articuno being predicted Water, likely due to being blue, or Koffing and Weezing as Ghost, probably due to their colour, shape and having Levitate.\n\nOthers are just confusing, like Moltres and Voltorb as Pyschic."},{"metadata":{"_uuid":"99f5af095496120d851e9e7702de6aea127fdc8b","_kg_hide-input":true,"_cell_guid":"5a1fd2d2-add0-4c1f-b30e-d9d9dea471b6","trusted":true},"cell_type":"code","source":"print(\"Pokemon which still have the incorrect main type are as follows:\")\nfor i in range(0,len(Gen1_targets)):\n    if Type1_Combined_preds[i] != Gen1_targets[i]:\n        print (pokemon_df[\"name\"][i],Type1_Combined_preds[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4588b54459692d6dc9aea6932f573daf458c04f3"},"cell_type":"markdown","source":"For sub-types the main problem is still prediction as None, when they do actually have types. The majority of these cases are where Poison has been predicted as None, or something else as poison. Most Grass/Poison or Bug/Poison types are incorrectly assigned for example.\n\nSometimes it's just a case of the sub-type being what should be the main type.\n\nA few intersting stand-outs, are Dragon for Charizard, and Flying for Venomoth. As mentioned in another Kernel,  fans have wanted Charizard to be Dragon for years, and eventually got that wish with a Mega Evolution. Venomoth on the other hand has wings, but is not a Flying type, so it's easy to see where that problem comes from.\n\nOverall, I'm happy with these predictions in the end, and think this will be good enough for now."},{"metadata":{"_uuid":"28d549c0b1da051d4a52392fcf812fe51dba9fe1","_kg_hide-input":true,"_cell_guid":"146e701e-de68-4be4-8561-54e764743a3b","trusted":true},"cell_type":"code","source":"print(\"Pokemon which still have the incorrect sub-type are as follows:\")\nfor i in range(0,len(Gen1_targets2)):\n    if Type2_Combined_preds[i] != Gen1_targets2[i]:\n        print (pokemon_df[\"name\"][i],Type2_Combined_preds[i])","execution_count":43,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}