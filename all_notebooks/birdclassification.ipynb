{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Overview of Assignment** : The below activity has been done to classify bird species. Convolutional Neural Network was build and Data Augmntation , Batch Normalization , Dropout , Max Pooling techniques were used to improve the accuracy of the model.Adam Optimizer and RMSprop Optimizer were used to monitor the change in accuracy with two optimizers.Transfer learning was used in the project and InceptionV3 model was used."},{"metadata":{},"cell_type":"markdown","source":"**Description of Data** :\nThe \"100-bird-species\" data contains images of 230 bird species. The data is split into test, validation, and train data with 1150 images, 1150 images, and 32025 images, respectively. The images are all in jpg format. The dimesions of the images are 224, 224, 3."},{"metadata":{},"cell_type":"markdown","source":"**Summary of Methods** : All the required libraries were loaded and data was saved in three different directories namely Train directory(images for training model) , Validation Directory(images for validation) and Test directory(images for testing the accuracy of model).ImageDataGenerator data augmentation was  used to scale the images. InceptionV3 was applied to the ImageNet dataset for training. Adam and RMSprop optimizers were used.Functional API was used as well to classify the birds."},{"metadata":{},"cell_type":"markdown","source":"****Summary of Model: **** \n\nFirst Model : The First model was build using convolutional 2D layers and using Batch Normalization, Droput , Maxpooling . Adam optimizer was used with a learning rate 0.001.Layers were flattened and relu activation function was used. The dense layer output was 230 equal to the number of birds categories and softmax activation function was used\n\nSecond Model: Functional API was used in this model for bird classification. 4 Towers were created with different 2D Convolutional layers. Average Pooling , Dropout techniques were used. Adam Optimizer with learning rate 0.001 was used. Relu and Softmax activation functions were used.\n\nThird Model : Transfer learning was used in this model . InceptionV3 was applied on imagenet and the layers were freeezed. Adam optimizer was used with learning rate 0.001. Batch Normalization and Dropout techniques were applied.\n\nFourth Model and Fifth Model: InceptionV3 was used on imagenet dataset.RMSprop optimizer was used with learning rate 0.001.Fourth model had all the layers freezed and 5th model had all the layers freezed except for bottom 4 layers.\n\nSixth Model: The model was similar to fouth model but this time the images in the train and validation directory were augmented applying different zoom , hight width changes."},{"metadata":{},"cell_type":"markdown","source":"**Analysis of Result **: \n\nFirst Model : The first model test accuracy was only 0.6% . \nSecond Model : The second model test accuracy was 0.3% and loss on the training and validation set were 5.5\n\nThird Model : The Third model gave test accuracy of 93.96% and the loss on train and validation data was ~0.49\n\nFourth Model and Fifth Model : The Fourth model gave test accuracy of 90.73% and fifth model gave the test accuracy 91.5%. The loss observed was slightly less in the fifth model. Model with freezing all the layers except bottom 4 layers performed better than the model where all the layers were freezed\n\nSixth Model: The model gave 86.5% accuracy and the losses were slightly higher compared to Fourth and Fifth model\n"},{"metadata":{},"cell_type":"raw","source":"#Importing all the required libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import backend, models, layers, regularizers , optimizers\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import BatchNormalization , Concatenate\nfrom keras.layers import Activation, Flatten, Dense, Dropout ,Input\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import backend\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport random\nimport os\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Directory for the Train data , Validation data and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_directory ='../input/100-bird-species/train'\nval_directory = '../input/100-bird-species/valid'\ntest_directory = '../input/100-bird-species/test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ImageDataGenerator API in Keras  is used to create augmented image generator. ImageDataGenerator generates batches of image data with real-time data augmentation.Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen=ImageDataGenerator(rescale=1/255)\nval_datagen=ImageDataGenerator(rescale=1/255)\ntest_datagen=ImageDataGenerator(rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Create Data Sets****"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_directory, # The directory where the train data is located\n    target_size=(224, 224), # Reshape the image to 224 by 224 pixels. This is important because it makes sure all images are the same size.\n    batch_size=32, # We will take images in batches of 32.\n    color_mode='rgb',\n    class_mode='sparse') # The classification is not binary.\n\nvalidation_generator = train_datagen.flow_from_directory(\n    val_directory,\n    target_size=(224, 224),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='sparse')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_directory,\n    target_size=(224, 224),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='sparse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes=(len(train_generator.class_indices))\nprint(num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing 25 Bird Species******"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_random_grid(ncols=5, ds_path=train_directory):\n    fig, ax = plt.subplots(ncols=ncols, nrows=ncols, figsize=(15, 15))\n    \n    for i in range(ncols):\n        for j in range(ncols):\n            bird_species = random.choice(os.listdir(ds_path))\n            random_bird_path = random.choice(os.listdir(ds_path + '/'+ bird_species))\n            random_bird = mpimg.imread(ds_path + '/' + bird_species + '/' + random_bird_path)\n            ax[i, j].imshow(random_bird)\n            ax[i, j].set_title(bird_species)\n            ax[i, j].axis('off')\n            \ndisplay_random_grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Creating a  Convolutional Network using Batch Normalization and Droput. Very less accuracy was seen with the below model"},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nmodel_base = models.Sequential()\nmodel_base.add(layers.Conv2D(512, (3,3), activation = 'relu', input_shape = (224, 224, 3)))\nmodel_base.add(layers.MaxPool2D((2,2)))\nmodel_base.add(BatchNormalization())\nmodel_base.add(layers.Conv2D(512, (3,3), activation = 'relu'))\nmodel_base.add(layers.MaxPool2D((2,2)))\nmodel_base.add(BatchNormalization())\nmodel_base.add(layers.Conv2D(256, (3,3), activation = 'relu'))\nmodel_base.add(layers.MaxPool2D((2,2)))\nmodel_base.add(BatchNormalization())\nmodel_base.add(layers.Flatten())\nmodel_base.add(layers.Dense(128, activation='relu'))\nmodel_base.add(layers.Dropout(0.5))\nmodel_base.add(layers.Dense(num_classes, activation='softmax'))\n\nmodel_base.compile(optimizer =optimizers.Adam(lr=0.001),\n               loss = 'sparse_categorical_crossentropy',\n               metrics = ['accuracy'])\n\nhistory = model_base.fit_generator(\n    train_generator,\n    epochs=50,\n    validation_data=validation_generator,\n    validation_steps=20,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights= True)])\n\ntest_loss, test_acc = model_base.evaluate_generator(test_generator, steps = 20)\nprint('test_acc:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Functional API for bird classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nvisible = Input(shape=(224,224,3))\n#Create Tower1\nconv_1_1 = Conv2D(64, (1,1), padding= 'same' , activation= 'relu', strides=2)(visible)\n#Create Tower2\nconv_1_2 = Conv2D(64, (1,1), padding= 'same' , activation = 'relu')(visible)\nconv_2_2 = Conv2D(64, (3,3), padding= 'same' , activation= 'relu', strides=2)(conv_1_2)\n#Create Tower3\nconv_1_3 = AveragePooling2D((3,3), padding= 'same', strides=2)(visible)\nconv_2_3 = Conv2D(64, (3,3), padding= 'same' , activation= 'relu')(conv_1_3)\n#Create Tower4\nconv_1_4 = Conv2D(64, (1,1), padding= 'same' , activation = 'relu')(visible)\nconv_2_4 = Conv2D(64, (3,3), padding= 'same' , activation = 'relu')(conv_1_4)\nconv_3_4 = Conv2D(64, (3,3), padding= 'same' , activation = 'relu', strides=2)(conv_2_4)\n\n# Concatentate\nmerge = Concatenate(axis=-1)([conv_1_1, conv_2_2, conv_2_3, conv_3_4])\n\n# Flatten into fully connected layer\nflat = Flatten()(merge)\n\n# Hidden connected layer and output\nhidden = Dense(32, activation='relu')(flat)\ndrop = Dropout(0.5)(hidden)\noutput = Dense(num_classes, activation='softmax')(drop)\n\nmodel_birdcl= Model(inputs=visible, outputs=output)\n\n\nmodel_birdcl.compile(optimizer = optimizers.Adam(lr=0.001),\n               loss = 'sparse_categorical_crossentropy',\n               metrics = ['accuracy'])\n\nhistory = model_birdcl.fit_generator(\n          train_generator,\n          steps_per_epoch=1001,\n          epochs=50,\n          validation_data=validation_generator,\n          validation_steps=29,\n          verbose=1, \n          callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])\n\ntest_loss , test_acc = model_birdcl.evaluate_generator(test_generator , steps = 29)\n\nprint('Using Functional API and Adam Optimizer the accuracy is ---', test_acc)\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model_birdcl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Using Transfer learning model InceptionV3 for Bird Classification.Optimizer used is Adam\n\nTransfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nincbasemodel4 = InceptionV3(weights = 'imagenet' , include_top = False, input_shape = (224 , 224 , 3))\nincbasemodel4.trainable = False\nmodelinceptionv3_vers4 = models.Sequential()\nmodelinceptionv3_vers4.add(incbasemodel4)\nmodelinceptionv3_vers4.add(layers.Conv2D(1024 , (3,3) , padding = 'same', activation = 'relu'))\nmodelinceptionv3_vers4.add(BatchNormalization())\nmodelinceptionv3_vers4.add(layers.Dropout(0.5))\nmodelinceptionv3_vers4.add(layers.Flatten())\nmodelinceptionv3_vers4.add(layers.Dense(512 , activation = 'relu'))\nmodelinceptionv3_vers4.add(layers.Dropout(0.5))\nmodelinceptionv3_vers4.add(layers.Dense(num_classes, activation = 'softmax'))\nmodelinceptionv3_vers4.compile(optimizer = optimizers.Adam(lr=0.001),\n               loss = 'sparse_categorical_crossentropy',\n               metrics = ['accuracy'])\nhistory = modelinceptionv3_vers4.fit_generator(\n          train_generator,\n          steps_per_epoch=1001,\n          epochs=50,\n          validation_data=validation_generator,\n          validation_steps=29,\n          verbose=1, \n          callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])\ntest_loss , test_acc = modelinceptionv3_vers4.evaluate_generator(test_generator , steps = 29)\nprint('Using InceptionV3 Model and Adam Optimizer the accuracy is ---', test_acc)\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Using Transfer learning model InceptionV3 for Bird Classification.Optimizer used is RMSprop\n\nTransfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nconv_base = InceptionV3 (weights = 'imagenet', \n                  include_top = False,\n                  input_shape = (224, 224, 3))\nconv_base.trainable = False # Freeze the Inception V3 weights.\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(BatchNormalization())\nmodel.add(layers.Flatten())\nmodel.add(Activation('relu'))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\nmodel.compile(optimizer = optimizers.RMSprop(lr=0.001, decay=1e-6, momentum=0.9),\n             loss = 'sparse_categorical_crossentropy',\n             metrics = ['accuracy'])\nhistory = model.fit_generator(\n          train_generator,\n          steps_per_epoch=1001,\n          epochs=50,\n          validation_data=validation_generator,\n          validation_steps=29,\n          verbose = 1,\n          callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])\n\ntest_loss , test_acc = model.evaluate_generator(test_generator , steps = 29)\n\nprint('InceptionV3 Model and using RMSprop optimizer accuracy is ----', test_acc)\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Using Transfer learning model InceptionV3 for Bird Classification.Optimizer used is RMSprop. Freezing weights except for bottom 4 layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nconv_basev2 = InceptionV3 (weights = 'imagenet', \n                  include_top = False,\n                  input_shape = (224, 224, 3))\nconv_basev2.trainable = False # Freeze the Inception V3 weights.\nfor layer in conv_basev2.layers[:-4]:\n  trainable = False\nfor layer in conv_basev2.layers:\n  print(layer, layer.trainable)\nmodel = models.Sequential()\nmodel.add(conv_basev2)\nmodel.add(BatchNormalization())\nmodel.add(layers.Flatten())\nmodel.add(Activation('relu'))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\nmodel.compile(optimizer = optimizers.RMSprop(lr=0.001, decay=1e-6, momentum=0.9),\n             loss = 'sparse_categorical_crossentropy',\n             metrics = ['accuracy'])\nhistory = model.fit_generator(\n          train_generator,\n          steps_per_epoch=1001,\n          epochs=50,\n          validation_data=validation_generator,\n          validation_steps=29,\n          verbose = 1,\n          callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])\n\ntest_loss , test_acc = model.evaluate_generator(test_generator , steps = 29)\n\nprint('InceptionV3 freezing all weights but bottom 4 layers accuracy is -----', test_acc)\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Using Data augmentation to improve accuracy.\n#Data augmentation allows us to randomally transform images before sending them to the model for training.  \n#The random transformation changes the images into 'new' images and allows for an increase in traning data without have additional images. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen2 = ImageDataGenerator(\n    rescale=1./255,# The image augmentaion function in Keras\n    rotation_range=40, # Rotate the images randomly by 40 degrees\n    width_shift_range=0.2, # Shift the image horizontally by 20%\n    height_shift_range=0.2, # Shift the image veritcally by 20%\n    zoom_range=0.2, # Zoom in on image by 20%\n    horizontal_flip=True, # Flip image horizontally \n    fill_mode='nearest') # How to fill missing pixels after a augmentaion opperation\n\n\ntest_datagen2 = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator2 = train_datagen2.flow_from_directory(\n    train_directory,\n    target_size=(224, 224),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='sparse')\n\nvalidation_generator2 = train_datagen2.flow_from_directory(\n    val_directory,\n    target_size=(224, 224),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='sparse')\n\ntest_generator2 = test_datagen2.flow_from_directory( # Resize test data\n    test_directory,\n    target_size=(224, 224),\n    batch_size=32,\n    color_mode='rgb',\n    class_mode='sparse')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nconv_base = InceptionV3 (weights = 'imagenet', \n                  include_top = False,\n                  input_shape = (224, 224, 3))\nconv_base.trainable = False # Freeze the Inception V3 weights.\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(BatchNormalization())\nmodel.add(layers.Flatten())\nmodel.add(Activation('relu'))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\nmodel.compile(optimizer = optimizers.RMSprop(lr=0.001, decay=1e-6, momentum=0.9),\n             loss = 'sparse_categorical_crossentropy',\n             metrics = ['accuracy'])\nhistory = model.fit_generator(\n          train_generator2,\n          steps_per_epoch=1001,\n          epochs=50,\n          validation_data=validation_generator2,\n          validation_steps=29,\n          verbose = 1,\n          callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])\n\ntest_loss , test_acc = model.evaluate_generator(test_generator2 , steps = 29)\n\nprint('InceptionV3_Vers3 adding Droput and Normalization accuracy', test_acc)\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}