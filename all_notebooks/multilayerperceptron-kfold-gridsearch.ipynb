{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir(\"../input\")\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Read"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/eeg-clean/eeg_clean.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[\"eye\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.eye=[1 if each ==\"Open\" else 0 for each in df.eye]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"eye\"].values\nX = df.drop(['eye'], axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Standardization \nfrom sklearn.preprocessing import StandardScaler\nScaler=StandardScaler()\nX=Scaler.fit_transform(X)\n\nX[0:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# shuffle and split training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n                                                    random_state=0)\n# Multi Layer Perceptron Artificial Neural Network\nfrom sklearn.neural_network import MLPClassifier \n\n# Setting up a primitive (non-validated) model\nmlpc = MLPClassifier(random_state = 0)# ANN model object created\n\nmlpc.fit(X_train, y_train) # ANN model object fit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forecasting on the Unvalidated Model\ny_pred = mlpc.predict(X_test) # model prediction process over test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\n\n# Accuracy\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n\n# f1 score\n\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Search Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross Validation Process\n# Parameters for CV created in dictionary structure\n# INFORMATION ABOUT THE INPUTED PARAMETERS\n# alpha: float, default = 0.0001 L2 penalty (regularization term) parameter. (penalty parameter)\n   \nmlpc_params = {\"alpha\": [0.1, 0.01, 0.001],\n              \"hidden_layer_sizes\": [(100,100),\n                                     (100,100,100)],\n              \"solver\" : [\"adam\",\"sgd\"],\n              \"activation\": [\"relu\",\"logistic\"]}\n\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\nmlpc = MLPClassifier(random_state = 0) # ANN model object created\n\n# Model CV process \nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n                         cv = 5, # To make a 5-fold CV\n                         n_jobs = -1, # Number of jobs to be run in parallel (-1: means to use all processors)\n                         verbose = 2) # Controls the level of detail: higher means more messages gets value as integer.\n\nmlpc_cv_model.fit(X_train, y_train) \n\n\n# The best parameter obtained as a result of CV process\n\nprint(\"The best parameters: \" + str(mlpc_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting the Final Model with the best parameter\n\nmlpc_tuned = mlpc_cv_model.best_estimator_\n\n# Fitting Final Model\nmlpc_tuned.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-fold f1_weighted\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test, y_test, cv=kf, scoring= 'f1_weighted')\n\nprint(\"K-fold Cross Validation f1_weigted Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation f1_weigted Results Mean: \",cv_results_kfold.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-fold accuracy\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test,y_test, cv=kf, scoring= 'accuracy')\n\nprint(\"K-fold Cross Validation accuracy Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation accuracy Results Mean: \",cv_results_kfold.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune Model Prediction\n# Prediction process of Final Model over test set\ny_pred = mlpc_tuned.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy and f1_weighted value of Final Model\n\n# %% f1 score\nimport sklearn.metrics as metrics\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))\n\n# %% Accuracy\n\nprint(\"accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% Confusion Matrix and Classification Report\nfrom sklearn.metrics import confusion_matrix, classification_report \n\n# Classification Report\nmodel_report = classification_report(y_test, y_pred)\nprint(model_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n# multilabel-indicator is not supported so np.argmax should be used!\nmodel_conf = confusion_matrix(y_test,y_pred)\nprint(model_conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% ROC-AUC Curve\nimport matplotlib.pyplot as plt\n\n\n\nprobs=mlpc_tuned.predict_proba(X_test)\nfpr,tpr,threshold=metrics.roc_curve(y_test,y_pred)\nroc_auc=metrics.auc(fpr,tpr)\n\n\n\n\nplt.title(\"ROC\")\nplt.plot(fpr,tpr,label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy',  linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}