{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-11-12T07:22:50.107745Z","iopub.status.busy":"2020-11-12T07:22:50.106797Z","iopub.status.idle":"2020-11-12T07:22:50.116049Z","shell.execute_reply":"2020-11-12T07:22:50.115308Z"},"papermill":{"duration":0.099943,"end_time":"2020-11-12T07:22:50.116193","exception":false,"start_time":"2020-11-12T07:22:50.01625","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:22:50.281193Z","iopub.status.busy":"2020-11-12T07:22:50.280321Z","iopub.status.idle":"2020-11-12T07:22:51.386656Z","shell.execute_reply":"2020-11-12T07:22:51.385967Z"},"papermill":{"duration":1.191413,"end_time":"2020-11-12T07:22:51.386783","exception":false,"start_time":"2020-11-12T07:22:50.19537","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/real-time-advertisers-auction/Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:22:52.209234Z","iopub.status.busy":"2020-11-12T07:22:52.208412Z","iopub.status.idle":"2020-11-12T07:22:53.381448Z","shell.execute_reply":"2020-11-12T07:22:53.382094Z"},"papermill":{"duration":1.274635,"end_time":"2020-11-12T07:22:53.382293","exception":false,"start_time":"2020-11-12T07:22:52.107658","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:22:53.554036Z","iopub.status.busy":"2020-11-12T07:22:53.552927Z","iopub.status.idle":"2020-11-12T07:22:53.595147Z","shell.execute_reply":"2020-11-12T07:22:53.594254Z"},"papermill":{"duration":0.134429,"end_time":"2020-11-12T07:22:53.59529","exception":false,"start_time":"2020-11-12T07:22:53.460861","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# df.drop(['order_id' , 'line_item_type_id'], axis = 1, inplace=True)\ndf['date'] = df.date.apply(lambda l: pd.Timestamp(l).value)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:22:53.768609Z","iopub.status.busy":"2020-11-12T07:22:53.767451Z","iopub.status.idle":"2020-11-12T07:22:53.781755Z","shell.execute_reply":"2020-11-12T07:22:53.781092Z"},"papermill":{"duration":0.107352,"end_time":"2020-11-12T07:22:53.781903","exception":false,"start_time":"2020-11-12T07:22:53.674551","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:22:55.035254Z","iopub.status.busy":"2020-11-12T07:22:55.034102Z","iopub.status.idle":"2020-11-12T07:23:08.296198Z","shell.execute_reply":"2020-11-12T07:23:08.295444Z"},"papermill":{"duration":13.353358,"end_time":"2020-11-12T07:23:08.296326","exception":false,"start_time":"2020-11-12T07:22:54.942968","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#calculating CPM\n#calculating the value that the Advertisers Bid for the month of June\n# CPM(the value which was the winning bid value) = \n#((revenue of the publisher*100)/revenue_share_percentage)/measurable_impressions)*1000\n\ndef weird_division(n, d):\n    return n / d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['total_revenue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:23:10.067629Z","iopub.status.busy":"2020-11-12T07:23:10.066332Z","iopub.status.idle":"2020-11-12T07:23:23.139549Z","shell.execute_reply":"2020-11-12T07:23:23.138664Z"},"papermill":{"duration":13.216065,"end_time":"2020-11-12T07:23:23.139689","exception":false,"start_time":"2020-11-12T07:23:09.923624","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# we can remove total impressions as well as that is account the same information as measurable impressions \n# also let us try to see if viewable/measurable impressions are corellated to revenue or not \n\ndf['View/measurable'] = df.apply(lambda x: weird_division(x['viewable_impressions'],x['measurable_impressions']) , axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:23:29.973232Z","iopub.status.busy":"2020-11-12T07:23:29.972389Z","iopub.status.idle":"2020-11-12T07:23:30.032597Z","shell.execute_reply":"2020-11-12T07:23:30.031908Z"},"papermill":{"duration":0.166959,"end_time":"2020-11-12T07:23:30.03273","exception":false,"start_time":"2020-11-12T07:23:29.865771","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#remove the outliers \n\n# df = df[df['CPM'].between(df['CPM'].quantile(.05), df['CPM'].quantile(.95))]\n\nprint(df.shape)\nprint(df.CPM.quantile(.95))\ndf = df[df.CPM >= 0]\ndf = df[df.CPM < df.CPM.quantile(.95)]\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:23:30.254707Z","iopub.status.busy":"2020-11-12T07:23:30.253798Z","iopub.status.idle":"2020-11-12T07:23:30.259715Z","shell.execute_reply":"2020-11-12T07:23:30.258924Z"},"papermill":{"duration":0.120501,"end_time":"2020-11-12T07:23:30.259866","exception":false,"start_time":"2020-11-12T07:23:30.139365","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df.reset_index(inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.121106,"end_time":"2020-11-12T07:23:46.414974","exception":false,"start_time":"2020-11-12T07:23:46.293868","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-12T07:23:46.666273Z","iopub.status.busy":"2020-11-12T07:23:46.665103Z","iopub.status.idle":"2020-11-12T07:23:46.669799Z","shell.execute_reply":"2020-11-12T07:23:46.669031Z"},"papermill":{"duration":0.1335,"end_time":"2020-11-12T07:23:46.669979","exception":false,"start_time":"2020-11-12T07:23:46.536479","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, KFold\n\nX_cols = ['total_impressions', 'viewable_impressions', 'measurable_impressions', 'revenue_share_percent',\n          'site_id', 'ad_type_id', 'geo_id', 'device_category_id', 'advertiser_id', 'order_id',\n          'line_item_type_id', 'os_id', 'integration_type_id', 'monetization_channel_id', 'ad_unit_id']\ny_cols =['CPM']\n\nX_train = df.loc[df.date < pd.Timestamp('06-22-2019').value][X_cols]\ny_train = df.loc[df.date < pd.Timestamp('06-22-2019').value][y_cols]\nX_test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][X_cols]\ny_test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][y_cols]\n\nX_train.fillna(0, inplace=True)\nX_test.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgbr = xgb.XGBRegressor(n_estimators=230, learning_rate=0.06, gamma=0, subsample=0.75,#n_estimators=100 #learning_rate=0.08\n#                            colsample_bytree=0.6, max_depth=9, random_state=1)\n# xgbr.fit(X_train.values,y_train.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n# predictions = xgbr.predict(X_test.values)\n# mse = mean_squared_error(y_test, predictions)\n# print(\"MSE: %.2f\" % mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions[predictions<0] = 0\n# predictions_xgb = predictions.copy()\n# mean_squared_error(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import TimeSeriesSplit, KFold\n\nn_fold = 5\nfolds = KFold(n_splits=n_fold, shuffle=False, random_state=1)\nprediction_xgb_cv = np.zeros(X_test.shape[0])\n\nxgbr = xgb.XGBRegressor(n_estimators=230, learning_rate=0.06, gamma=0, subsample=0.75,#n_estimators=100 #learning_rate=0.08\n                           colsample_bytree=0.6, max_depth=9, random_state=1)\n\nfor fold_n, (train_index, test_index) in enumerate(folds.split(X_train)):\n    print('Fold:', fold_n)\n    X_traincv, X_validcv = X_train.iloc[train_index], X_train.iloc[test_index]\n    Y_traincv, Y_validcv = y_train.iloc[train_index], y_train.iloc[test_index]\n\n    xgbr.fit(X_traincv.values,Y_traincv.values)\n    \n    y_pred = xgbr.predict(X_test.values)\n    prediction_xgb_cv += y_pred\n    \n    print(mean_squared_error(y_test, y_pred))\n    \nprediction_xgb_cv /= n_fold\nprint('--------------')\nmean_squared_error(y_test, prediction_xgb_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_xgb_cv[prediction_xgb_cv<0] = 0\nmean_squared_error(y_test, prediction_xgb_cv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# H2O"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df.loc[df.date < pd.Timestamp('06-22-2019').value].to_csv('train.csv')\ntest = df.loc[df.date >= pd.Timestamp('06-22-2019').value].to_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = h2o.import_file(\"train.csv\")\ntest = h2o.import_file(\"test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = ['total_impressions', 'viewable_impressions', 'measurable_impressions', 'revenue_share_percent',\n          'site_id', 'ad_type_id', 'geo_id', 'device_category_id', 'advertiser_id', 'order_id',\n          'line_item_type_id', 'os_id', 'integration_type_id', 'monetization_channel_id', 'ad_unit_id']\ny = \"CPM\"\n\naml = H2OAutoML(max_models=50, seed=1, stopping_metric='MSE', nfolds = 0)\naml.train(x=x, y=y, training_frame=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = aml.leaderboard\nlb.head(rows=lb.nrows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = aml.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test.values, h2o.as_list(preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_h2o = np.array(h2o.as_list(preds).values).reshape(1, len(preds))[0]\npredictions_h2o[predictions_h2o<0] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['measurable_impressions', 'revenue_share_percent',\n          'site_id', 'ad_type_id', 'geo_id', 'device_category_id', 'advertiser_id', 'order_id',\n          'line_item_type_id', 'os_id', 'integration_type_id', 'monetization_channel_id', 'ad_unit_id']\nfeatures = cat_cols + ['total_impressions', 'viewable_impressions',]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n\n# train = df.loc[df.date < pd.Timestamp('06-22-2019').value]\n# test = df.loc[df.date >= pd.Timestamp('06-22-2019').value]\n\n# scaler = StandardScaler()\n# scaler.fit(train[features])\n# train[features] = pd.DataFrame(scaler.transform(train[features]), columns= features)\n# test[features] = pd.DataFrame(scaler.transform(test[features]), columns= features)\n\n\n\ntrain = df.loc[df.date < pd.Timestamp('06-22-2019').value]\ntest = df.loc[df.date >= pd.Timestamp('06-22-2019').value]\n\ntrain.fillna(0, inplace=True)\ntest.fillna(0, inplace=True)\n\nfor col in cat_cols:\n    train[col] = train[col].astype('category')\n    test[col] = test[col].astype('category')\n    \ntrain, valid = train_test_split(train, test_size=0.05, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'objective': 'regression',\n    'n_estimators': 500,\n    'learning_rate': 0.05,\n    'num_leaves': 250,\n    'metric': 'mse',\n    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(train[features], train[\"CPM\"])\nlgb_valid = lgb.Dataset(valid[features], valid[\"CPM\"])\n\ngbm = lgb.train(params, lgb_train, 25000, \n    valid_sets=[lgb_train, lgb_valid],\n    early_stopping_rounds=100, verbose_eval=1000)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = gbm.predict(test[features])\ny_test = test['CPM']\npred[pred<0]=0\npredictions_lgb = pred.copy()\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbmcv = lgb.LGBMRegressor(objective = 'regression',  # gbm никак далее не использую, но смотрю на важность фич\n#                             max_depth = 9,#было  3\n#                             colsample_bytre = 0.8,\n#                             subsample = 0.8,\n#                             learning_rate = 0.1,\n#                             n_estimators = 300, random_state = 1)\n\n# params = {\n#     'objective': 'regression',\n#     'n_estimators': 500,\n#     'learning_rate': 0.05,\n#     'num_leaves': 250,\n#     'metric': 'mse',\n    \n# }\n\n# n_fold = 10\n# folds = KFold(n_splits=n_fold, shuffle=False, random_state=1)\n\n# X_train = df.loc[df.date < pd.Timestamp('06-22-2019').value][X_cols]\n# y_train = df.loc[df.date < pd.Timestamp('06-22-2019').value][y_cols]\n# X_test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][X_cols]\n# y_test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][y_cols]\n\n# X_train.fillna(0, inplace=True)\n# X_test.fillna(0, inplace=True)\n\n# prediction_lgb_cv = np.zeros(X_test.shape[0])\n\n# for fold_n, (train_index, test_index) in enumerate(folds.split(X_train)):\n#     print('Fold:', fold_n)\n#     X_traincv, X_validcv = X_train.iloc[train_index], X_train.iloc[test_index]\n#     Y_traincv, Y_validcv = y_train.iloc[train_index], y_train.iloc[test_index]\n    \n#     lgb_train = lgb.Dataset(X_traincv, Y_traincv)\n#     lgb_valid = lgb.Dataset(X_validcv, Y_validcv)\n\n#     gbmcv = lgb.train(params, lgb_train, 15000, \n#     valid_sets=[lgb_train, lgb_valid],\n#     early_stopping_rounds=100, verbose_eval=50)\n\n# #     gbmcv.fit(X_traincv, Y_traincv, eval_set=[(X_validcv, Y_validcv)], eval_metric='mse', early_stopping_rounds=25)\n    \n#     y_pred = gbmcv.predict(X_test)\n#     prediction_lgb_cv += y_pred\n    \n#     print(mean_squared_error(y_test, y_pred))\n    \n# prediction_lgb_cv /= n_fold\n# print('--------------')\n# mean_squared_error(y_test, prediction_lgb_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction_lgb_cv[prediction_lgb_cv<0] = 0\n# mean_squared_error(y_test, prediction_lgb_cv)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CAT"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.ensemble import ExtraTreesRegressor\nfrom catboost import CatBoostRegressor\n\ntrain = df.loc[df.date < pd.Timestamp('06-22-2019').value]\ntest = df.loc[df.date >= pd.Timestamp('06-22-2019').value]\n\n# rfr_model = RandomForestRegressor(n_estimators=500)\n# etr_model = ExtraTreesRegressor(n_estimators=500)\ncat_model = CatBoostRegressor(iterations=15500, cat_features=cat_cols, verbose=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rfr_model.fit(train[features], train[\"CPM\"])\n# etr_model.fit(train[features], train[\"CPM\"])\ncat_model.fit(train[features], train[\"CPM\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][features]\n# rfr_predict = rfr_model.predict(test)\n# etr_predict = etr_model.predict(test)\npredictions_cat = cat_model.predict(test)\npredictions_cat[predictions_cat<0] = 0\n\n# mean_squared_error(y_test, rfr_predict), mean_squared_error(y_test, etr_predict)\nmean_squared_error(y_test, predictions_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cat_model2 = CatBoostRegressor(iterations=2500,random_seed = 1)\n\n# X_train = df.loc[df.date < pd.Timestamp('06-22-2019').value][X_cols]\n# y_train = df.loc[df.date < pd.Timestamp('06-22-2019').value][y_cols]\n# X_test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][X_cols]\n# y_test = df.loc[df.date >= pd.Timestamp('06-22-2019').value][y_cols]\n\n# prediction_cat_cv = np.zeros(X_test.shape[0])\n\n# for fold_n, (train_index, test_index) in enumerate(folds.split(X_train)):\n#     print('Fold:', fold_n)\n#     X_traincv, X_validcv = X_train.iloc[train_index], X_train.iloc[test_index]\n#     Y_traincv, Y_validcv = y_train.iloc[train_index], y_train.iloc[test_index]\n\n#     cat_model2.fit(X_traincv, Y_traincv)\n    \n#     y_pred = cat_model2.predict(X_test)\n#     prediction_cat_cv += y_pred\n    \n#     print(mean_squared_error(y_test, y_pred))\n    \n# prediction_cat_cv /= n_fold\n# print('--------------')\n# mean_squared_error(y_test, prediction_cat_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction_cat_cv[prediction_cat_cv<0] = 0\n# mean_squared_error(y_test, prediction_cat_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator\nres = {}\nfor i in np.arange(0,3,step=0.1):\n    for j in np.arange(0,3,step=0.1):\n        for k in np.arange(0,3,step=0.1):\n            for l in np.arange(0,3,step=0.1):\n                if i!=0 or j !=0 or k!=0 or l!=0:\n                    mse = mean_squared_error(y_test, (i*predictions_h2o+j*predictions_lgb+k*predictions_cat+l*prediction_xgb_cv)/(i+j+k+l))\n                    res[(i,j,k,l)] = mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min(res.items(), key=operator.itemgetter(1))[0], res[min(res.items(), key=operator.itemgetter(1))[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i, j, k, l = min(res.items(), key=operator.itemgetter(1))[0]\nmean_squared_error(y_test, (i*predictions_h2o+j*predictions_lgb+k*predictions_cat+l*prediction_xgb_cv)/(i+j+k+l))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator\nres = {}\nfor i in np.arange(0,5,step=0.1):\n    for j in np.arange(0,5,step=0.1):\n        for k in np.arange(0,5,step=0.1):\n            if i!=0 or j !=0 or k!=0:\n                mse = mean_squared_error(y_test, (i*predictions_lgb+j*predictions_cat)/(i+j+k))\n                res[(i,j,k)] = mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min(res.items(), key=operator.itemgetter(1))[0], res[min(res.items(), key=operator.itemgetter(1))[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i, j, k = min(res.items(), key=operator.itemgetter(1))[0]\nmean_squared_error(y_test, (i*predictions_lgb+j*predictions_cat)/(i+j+k))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hochu zachet & podarok!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}