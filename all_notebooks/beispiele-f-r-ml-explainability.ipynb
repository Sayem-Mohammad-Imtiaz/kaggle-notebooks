{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Algorithmik und Statisitik Seminararbeit\n#### Gruppe 3:\nTomasz J., Bernd K., Julian B., Christian B.\n\n\n## Explainability - Anwendungsbeispiel\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"#### Welche Arten von Einsichten in Modelle sind möglich?\n\nWie oben beschrieben sind Modelle für maschinelles Lernen \"Black Boxes\". In diesem Zusammenhang bedeutet das, dass Modelle gute Vorhersagen treffen können, aber der Anwender kann die Logik hinter diesen Vorhersagen nicht verstehen. Folgende Fragen sind wichtig für das Verstehen des ML-Modells:\n\n- Welche Merkmale in den Daten waren nach Ansicht des Modells am wichtigsten?\n- Wie hat sich jedes Merkmal in den Daten für eine einzelne Vorhersage aus einem Modell auf diese bestimmte Vorhersage ausgewirkt?\n- Wie wirkt sich jedes Merkmal auf die Vorhersagen des Modells im Großen und Ganzen aus (was ist der typische Effekt, wenn es über eine große Anzahl möglicher Vorhersagen betrachtet wird)?"},{"metadata":{},"cell_type":"markdown","source":"Folgendes Beispiel wird mit Permutation anhand von Stichproben von Daten dem Kaggle Datensatz [Taxi Fare Prediction] (https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) überlegen und berechnen.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading data, dividing, modeling and EDA below\nimport pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import r2_score\n#from sklearn.inspection import permutation_importance\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ndata = pd.read_csv('/kaggle/input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)\n\n# Remove data with extreme outlier coordinates or negative fares\ndata = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n                  'fare_amount > 0'\n                  )\n\ny = data.fare_amount\n\nbase_features = ['pickup_longitude',\n                 'pickup_latitude',\n                 'dropoff_longitude',\n                 'dropoff_latitude',\n                 'passenger_count']\n\nX = data[base_features]\n\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nfirst_model = RandomForestRegressor(n_estimators=50, random_state=1).fit(train_X, train_y)\n\n\n# Using tuned parameters.\nreg = LGBMRegressor(colsample_bytree = 0.8,max_depth = 3,min_child_weight=0.1,subsample=0.6, # Tuned hyperparameter\n                    importance_type='gain', # Use importance type='gain' (Note default option is 'split')\n                    random_state=42)\nreg.fit(train_X, train_y)\n\nprint(r2_score(train_y,reg.predict(train_X))) # 0.40388748819243725\nprint(r2_score(val_y,reg.predict(val_X))) # 0.3464450279784468\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Analyse des Datensatzes"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Analyse mit Hilfe von *Permutation Feature Importance*\n\nDas erste Model verwendet folgende Features:\n- pickup_longitude\n- pickup_latitude\n- dropoff_longitude\n- dropoff_latitude\n- passenger_count\n\nDurch das Erstellen des PermutationImportance-Objekt mit dem Namen `perm` wird die Wichtigkeiten von `first_model` angezeigt. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ELI5 ist ein Python-Paket, mit dem Klassifizierer für maschinelles Lernen debuggt und ihre Vorhersagen erläutert werden können.\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Make a small change to the code below to use in this problem. \nperm = PermutationImportance(first_model, random_state=1).fit(val_X, val_y)\n\neli5.show_weights(perm, feature_names = val_X.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Folgende Hypothesen könnten aus dem Ergebnis entstehen:\n- Verschiedene Teile der Stadt haben möglicherweise unterschiedliche Preisregeln (z. B. Preis pro Meile), und die Preisregeln können je nach Breitengrad und Längengrad stärker variieren.\n- Auf Straßen, die nach Norden <-> Süden verlaufen (wechselnder Breitengrad), können die Gebühren höher sein als auf Straßen, die nach Osten <-> nach Westen verlaufen (wechselnder Längengrad). Der Breitengrad hätte somit einen größeren Einfluss auf die Vorhersage, da er die Höhe der Mautgebühren erfasst.\n\nOhne detaillierte Kenntnisse von New York City ist es schwierig, die meisten Hypothesen darüber auszuschließen, warum Breitengradmerkmale wichtiger sind als Längengrade.\n\nEin nächster Schritt besteht darin, die Auswirkung des Aufenthalts in bestimmten Teilen der Stadt von der Auswirkung der zurückgelegten Gesamtstrecke zu trennen. Der folgende Code erstellt neue Funktionen für den Längs- und Breitenabstand. Anschließend wird ein Modell erstellt, das diese neuen Funktionen zu den bereits vorhandenen hinzufügt."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['abs_lon_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\ndata['abs_lat_change'] = abs(data.dropoff_latitude - data.pickup_latitude)\n\nfeatures_2  = ['pickup_longitude',\n               'pickup_latitude',\n               'dropoff_longitude',\n               'dropoff_latitude',\n               'abs_lat_change',\n               'abs_lon_change']\n\nX = data[features_2]\nnew_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\nsecond_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n\n# Create a PermutationImportance object on second_model and fit it to new_val_X and new_val_y\nperm2 = PermutationImportance(second_model, random_state=1).fit(new_val_X, new_val_y)\n\n# show the weights for the permutation importance you just calculated\neli5.show_weights(perm2, feature_names = features_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Die Werte für \"abs_lon_change\" und \"abs_lat_change\" sind ziemlich klein (alle Werte liegen zwischen -0,1 und 0,1). Andere Variablen größere Werte haben. \n\nAn den Ergebnissen der *Permutation Feature Importance* kann man in diesem Beispiel nicht erkennen, ob das Befahren einer festen Breitenentfernung mehr oder weniger teuer ist als das Befahren derselben Längsentfernung. Mögliche Gründe, warum Breitengradmerkmale wichtiger sind als Längengradmerkmale\n1. Breitenabstände im Datensatz sind tendenziell größer\n2. Es ist teurer, eine feste Breitenstrecke zurückzulegen\n3. oben genannten Punkte zusammen\nWenn die abs_lon_change-Werte sehr klein wären, könnten Longitues für das Modell weniger wichtig sein, selbst wenn die Kosten pro Meile Fahrt in diese Richtung hoch wären."},{"metadata":{},"cell_type":"markdown","source":"### Teilabhängigkeitsdiagramme\nWährend die Merkmalsbedeutung zeigt, welche Variablen die Vorhersagen am meisten beeinflussen, zeigen Teilabhängigkeitsdiagramme, wie sich ein Merkmal auf Vorhersagen auswirkt.\n\nDies ist nützlich, um Fragen zu beantworten wie:\n- Welche Auswirkungen haben Längen- und Breitengrade bei der Kontrolle aller anderen Hausmerkmale auf die Immobilienpreise? Wie würden ähnlich große Häuser in verschiedenen Bereichen zu Preisen angeboten?\n- Sind vorhergesagte gesundheitliche Unterschiede zwischen zwei Gruppen auf Unterschiede in ihrer Ernährung oder auf einen anderen Faktor zurückzuführen?\n\nÄhnlich wie bei der linearen oder logistischen Regressionsmodellen können partielle Abhängigkeitsdiagramme wie die Koeffizienten in diesen Modellen interpretiert werden. Partielle Abhängigkeitsdiagramme von hoch entwickelten Modellen können jedoch komplexere Muster als Koeffizienten aus einfachen Modellen erfassen. \n\nFolgendes Beispiel zeigt die Erstellung von Abhängigkeitsdiagramme mit Daten aus dem Wettbewerb Tax Fare Prediction.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Code to plot the partial dependence plot for pickup_longitude\nfrom matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\nfeat_name = 'pickup_longitude'\npdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feat_name in base_features:\n    pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X,\n                               model_features=base_features, feature=feat_name)\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aus den Ergebnissen der *Permutation Feature Importance* geht hervor, dass die Entfernung die wichtigste Determinante für den Taxifahrpreis ist.\nDieses Modell enthielt keine Entfernungsmaße (wie die absolute Änderung der Breite oder Länge) als Merkmale, sodass Koordinatenmerkmale (wie pickup_longitude) den Effekt der Entfernung erfassen. In der Nähe der Mitte der Längengrade abgeholt zu werden, senkt die vorhergesagten Tarife im Durchschnitt, da dies (im Durchschnitt) kürzere Fahrten bedeutet. Aus dem gleichen Grund sieht man die allgemeine U-Form in allen unseren partiellen Abhängigkeitsdiagrammen."},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = ['pickup_longitude', 'dropoff_longitude']\nlongitudes_partial_plot = pdp.pdp_interact(\n    model=first_model, dataset=val_X,\n    model_features=base_features, \n    features=fnames\n)\npdp.pdp_interact_plot(\n    pdp_interact_out=longitudes_partial_plot,\n    feature_names=fnames, \n    plot_type='contour'\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the PDP for pickup_longitude without the absolute difference features. Included here to help compare it to the new PDP you create\nfeat_name = 'pickup_longitude'\npdp_dist_original = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n\npdp.pdp_plot(pdp_dist_original, feat_name)\nplt.show()\n\n\n\n# create new features\ndata['abs_lon_change'] = abs(data.dropoff_longitude - data.pickup_longitude)\ndata['abs_lat_change'] = abs(data.dropoff_latitude - data.pickup_latitude)\n\nfeatures_2  = ['pickup_longitude',\n               'pickup_latitude',\n               'dropoff_longitude',\n               'dropoff_latitude',\n               'abs_lat_change',\n               'abs_lon_change']\n\nX = data[features_2]\nnew_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\nsecond_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n\nfeat_name = 'pickup_longitude'\npdp_dist = pdp.pdp_isolate(model=second_model, dataset=new_val_X, model_features=features_2, feature=feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dies garantiert nicht, dass feat_a wichtiger ist als feat_b. Zum Beispiel könnte feat_a in den Fällen, in denen es variiert, einen großen Effekt haben, aber in 99% der Fälle einen einzelnen Wert haben. In diesem Fall würde das Permutieren von feat_a nicht viel ausmachen, da die meisten Werte unverändert bleiben würden."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom numpy.random import rand\n\nn_samples = 20000\n\n# Create array holding predictive feature\nX1 = 4 * rand(n_samples) - 2\nX2 = 4 * rand(n_samples) - 2\n# Create y. you should have X1 and X2 in the expression for y\ny = -2 * X1 * (X1<-1) + X1 - 2 * X1 * (X1>1) - X2\n\n# create dataframe because pdp_isolate expects a dataFrame as an argument\nmy_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\npredictors_df = my_df.drop(['y'], axis=1)\n\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n\npdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n\n# visualize your results\npdp.pdp_plot(pdp_dist, 'X1')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nn_samples = 20000\n\n# Create array holding predictive feature\nX1 = 4 * rand(n_samples) - 2\nX2 = 4 * rand(n_samples) - 2\n# Create y. you should have X1 and X2 in the expression for y\ny = X1 * X2\n\n\n# create dataframe because pdp_isolate expects a dataFrame as an argument\nmy_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\npredictors_df = my_df.drop(['y'], axis=1)\n\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n\n\npdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\npdp.pdp_plot(pdp_dist, 'X1')\nplt.show()\n\nperm = PermutationImportance(my_model).fit(predictors_df, my_df.y)\n\n# show the weights for the permutation importance you just calculated\neli5.show_weights(perm, feature_names = ['X1', 'X2'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SHAP\nSHAP-Werte (SHapley Additive exPlanations) zeigen eine Vorhersage auf, um die Auswirkungen der einzelnen Features anzuzeigen.\n- Ein Modell besagt, dass eine Bank niemandem Geld leihen sollte, und die Bank ist gesetzlich verpflichtet, die Grundlage für jede Kreditverweigerung zu erläutern\n- Ein Gesundheitsdienstleister möchte herausfinden, welche Faktoren das Krankheitsrisiko jedes Patienten beeinflussen, damit er diese Risikofaktoren mit gezielten Gesundheitsmaßnahmen direkt angehen kann\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\n\"\"\"\nAssuming we prepared the data from NY taxi fare data set and \ntrained the model as 'reg' just as in the code of variable importance.\n\"\"\"\n\nprint('Computing SHAP...')\n\n# Using TreeSHAP, not KernelSHAP. The former runs quicker but only available for tree-based model.\n# Example of KernelExplainer: \"shap.KernelExplainer(reg.predict, X_test)\" Notice you need to assign prediction function and data.\n# I test-ran and only to run 100 samples out of 6258, it took 120 seconds!!\nexplainer = shap.TreeExplainer(reg)\nshap_values = explainer.shap_values(val_X)\n\n# Show how the SHAP values output looks like.\npd.DataFrame(shap_values,columns=val_X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.initjs() #SHAP visualization is nicer with JavaScript which can be done with this small line.\n\n# visualize the first prediction's explanation, decomposition between average vs. row specific prediction.\nshap.force_plot(explainer.expected_value, shap_values[0,:], val_X.iloc[0,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variable importance-like plot.\nshap.summary_plot(shap_values, val_X, plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PDP-like plot.\nshap.dependence_plot(\"dropoff_longitude\", shap_values, val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Each plot represents one data row, with SHAP value for each variable,\n# along with red-blue as the magnitude of the original data.\nshap.summary_plot(shap_values, val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pretty visualization of the SHAP values per data row.\nshap.force_plot(explainer.expected_value, shap_values, val_X)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}