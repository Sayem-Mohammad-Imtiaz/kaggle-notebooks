{"cells":[{"metadata":{},"cell_type":"markdown","source":"Objectives:\n* Using pandas and sklearn for modeling\n* Feature engineering\n     a) Using statistical measures\n     b) Using Random Projections\n     c) Using clustering\n     d) USing interaction variables\n* Classifciation using Decision Tree and RandomForest"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%reset -f","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# 1.1 Call data manipulation libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# 1.2 Feature creation libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.random_projection import SparseRandomProjection as sr  # Projection features\nfrom sklearn.cluster import KMeans                    # Cluster features\nfrom sklearn.preprocessing import PolynomialFeatures  # Interaction features\n","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# 1.3 For feature selection**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ref: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif  # Selection criteria\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.4 Data processing\n# 1.4.1 Scaling data in various manner********\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n# 1.4.2 Transform categorical (integer) to dummy\nfrom sklearn.preprocessing import OneHotEncoder","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.5 Splitting data\nfrom sklearn.model_selection import train_test_split","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.6 Decision tree modeling\n# http://scikit-learn.org/stable/modules/classes.html#module-sklearn.tree\n# http://scikit-learn.org/stable/modules/tree.html#tree\nfrom sklearn.tree import  DecisionTreeClassifier as dt","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.7 RandomForest modeling\nfrom sklearn.ensemble import RandomForestClassifier as rf","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.8 Plotting libraries to plot feature importance\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.9 Misc\nimport os, time, gc","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.0 Set working directory and read file\nos.chdir(\"../input\")\nprint(os.listdir())","execution_count":27,"outputs":[{"output_type":"stream","text":"['heart.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.1 Read heart data from files\nheart = pd.read_csv(\"heart.csv\")","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.2 Look at data\nheart.head(2)\nheart.shape                        # 303 X 14","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"(303, 14)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.3 Data types\nheart.dtypes.value_counts()  ","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"int64      13\nfloat64     1\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.4 Target classes are almost balanced\nheart.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**############################ BB. Feature Engineering #########################\n**############################ Using Statistical Numbers #####################"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  4. Feature 1: Row sums of features 1:93. More successful\n#                when data is binary.\n\nheart['sum'] = heart.sum(numeric_only = True, axis=1)  # numeric_only= None is default\nheart.shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# 4.1 Assume that value of '0' in a cell implies missing feature\n#     Transform train and test dataframes\n#     replacing '0' with NaN\n#     Use pd.replace()\ntmp_heart = heart.replace(0, np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4.2 Check if tmp_train is same as train or is a view\n#     of train? That is check if tmp_train is a deep-copy\n\ntmp_heart is heart                # False\n#tmp_train is train.values.base    # False\ntmp_heart._is_view                # False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4.3 Check if 0 has been replaced by NaN\ntmp_heart.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Feature 2 : For every row, how many features exist\n#                that is are non-zero/not NaN.\n#                Use pd.notna()\ntmp_heart.notna().head(1)\nheart[\"count_not0\"] = tmp_heart.notna().sum(axis = 1)\nheart.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. Similary create other statistical features\n#    Feature 3\n#    Pandas has a number of statistical functions\n#    Ref: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#computations-descriptive-stats\n\nfeat = [ \"var\", \"median\", \"mean\", \"std\", \"max\", \"min\"]\nfor i in feat:\n    heart[i] = tmp_heart.aggregate(i,  axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7 Delete not needed variables and release memory\ndel(tmp_heart)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7.1 So what do we have finally\nheart.shape                # 303 X (14 + 1 + 1 + 6) ; 14th Index is target\nheart.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 8. Before we proceed further, keep target feature separately\ntarget = heart['target']\ntarget.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 9.1 Drop 'target' column\nheart.drop(columns = ['target'], inplace = True)\nheart.shape                # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 9.2. Store column names of our data somewhere\n#     We will need these later (at the end of this code)\ncolNames = heart.columns.values\ncolNames","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################################################################\n################ Feature creation Using Random Projections ##################\n**# 10. Random projection is a fast dimensionality reduction feature\n**#     Also used to look at the structure of data\n****"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 11. Transform tmp t0 numpy array\n#      Henceforth we will work with array only\ntmp = heart.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 12. tmp shape\ntmp.shape       # (303, 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 13. Let us create 10 random projections/columns\n#     This decision, at present, is arbitrary\nNUM_OF_COM = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 13.1 Create an instance of class\nrp_instance = sr(n_components = NUM_OF_COM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 13.2 fit and transform the (original) dataset\n#      Random Projections with desired number\n#      of components are returned\nrp = rp_instance.fit_transform(tmp[:, :13])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 13.3 Look at some features\nrp[: 3, :  12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 13.4 Create some column names for these columns\n#      We will use them at the end of this code\nrp_col_names = [\"r\" + str(i) for i in range(12)]\nrp_col_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################ Feature creation using kmeans ####################\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 14. Before clustering, scale data\n# 15.1 Create a StandardScaler instance\nse = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 15.2 fit() and transform() in one step\ntmp = se.fit_transform(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 15.3\ntmp.shape               # 303 X 21 (an ndarray)\ntarget.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 16. Perform kmeans using 93 features.\n#     No of centroids is no of classes in the 'target'\ncenters = target.nunique()    # 2 unique classes\ncenters               # 9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 17.1 Begin clustering\nstart = time.time()\n\n# 17.2 First create object to perform clustering\nkmeans = KMeans(n_clusters=centers, # How many\n                n_jobs = 2)         # Parallel jobs for n_init\n\n\n\n# 17.3 Next train the model on the original data only\nkmeans.fit(tmp[:, : 13])\n\nend = time.time()\n(end-start)/60.0      # 5 minutes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 18 Get clusterlabel for each row (data-point)\nkmeans.labels_\nkmeans.labels_.size   # 303","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 19. Cluster labels are categorical. So convert them to dummy\n\n# 19.1 Create an instance of OneHotEncoder class\nohe = OneHotEncoder(sparse = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 19.2 Use ohe to learn data\n#      ohe.fit(kmeans.labels_)\nohe.fit(kmeans.labels_.reshape(-1,1))     # reshape(-1,1) recommended by fit()\n                                          # '-1' is a placeholder for actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 19.3 Transform data now\ndummy_clusterlabels = ohe.transform(kmeans.labels_.reshape(-1,1))\ndummy_clusterlabels\ndummy_clusterlabels.shape    # 206245 X 9 (as many as there are classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 19.4 We will use the following as names of new nine columns\n#      We need them at the end of this code\n\nk_means_names = [\"k\" + str(i) for i in range(2)]\nk_means_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################ Interaction features #######################\n**# 21. Will require lots of memory if we take large number of features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"degree = 2\npoly = PolynomialFeatures(degree,                 # Degree 2\n                          interaction_only=True,  # Avoid e.g. square(a)\n                          include_bias = False    # No constant term\n                          )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 21.1 Consider only first 5 features\n#      fit and transform\ndf =  poly.fit_transform(tmp[:, : 5])\ndf.shape     # 303 X 15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 21.2 Generate some names for these 15 columns\npoly_names = [ \"poly\" + str(i)  for i in range(15)]\npoly_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"################# concatenate all features now ##############################"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 22 Append now all generated features together\n# 22 Append random projections, kmeans and polynomial features to tmp array\n\ntmp.shape          # 303 X 21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  22.1 If variable, 'dummy_clusterlabels', exists, stack kmeans generated\n#       columns also else not. 'vars()'' is an inbuilt function in python.\n#       All python variables are contained in vars().\n\ntmp = np.hstack([tmp,rp])       # No kmeans and polynomial      <==\ntmp.shape          # 303 X 33   I  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 22.1 Separate train and test\nX = tmp[: 230, : ]\nX.shape                             # 61878 X 135 if no kmeans: (61878, 126)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 22.2\ntest = tmp[230 :, : ]\ntest.shape                         # 144367 X 135; if no kmeans: (144367, 126)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 22.3 Delete tmp\ndel tmp\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"################## Model building #####################"},{"metadata":{"trusted":true},"cell_type":"code","source":"target.shape\nX.shape\n\nt1 = target.head(230)\nt2 = target.tail(73)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 23. Split train into training and validation dataset\nX_train, X_test, y_train, y_test = train_test_split(\n                                                    X,\n                                                    t1,\n                                                    test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 23.1\nX_train.shape    # 43314 X 135  if no kmeans: (43314, 126)\nX_test.shape     # 18564 X 135; if no kmeans: (18564, 126)\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 24 Decision tree classification\n# 24.1 Create an instance of class\nclf = dt(min_samples_split = 5,\n         min_samples_leaf= 5\n        )\nstart = time.time()\n# 24.2 Fit/train the object on training data\n#      Build model\nclf = clf.fit(X_train, y_train)\nend = time.time()\n(end-start)/60                     # 1 minute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 24.3 Use model to make predictions\npredicted_target = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 24.4 Check accuracy\n(predicted_target == y_test).sum()/y_test.size      # 72%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 25. Instantiate RandomForest classifier\nclf = rf(n_estimators=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 25.1 Fit/train the object on training data\n#      Build model\n\nstart = time.time()\nclf = clf.fit(X_train, y_train)\nend = time.time()\n(end-start)/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 25.2 Use model to make predictions\npre_target = clf.predict(X_test)\n# 25.3 Check accuracy\n(pre_target == y_test).sum()/y_test.size      # 72%\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"############################################  DONE ######################\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}