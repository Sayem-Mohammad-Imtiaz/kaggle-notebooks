{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dropout, Dense, Conv2D, MaxPool2D, Flatten\nfrom tensorflow.keras.callbacks import TensorBoard\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport time\nprint(tf.__version__)\n\nimport os\nimport csv\nimport sys\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import load_img\nimport cv2\nfrom PIL import Image\nfrom skimage.transform import resize\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import Sequence,to_categorical\n\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\nfrom keras import applications\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/selfie-classification-basic-dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CSV to DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"root_path = \"/kaggle/input/selfie-classification-basic-dataset\"\nimage_names_csv = os.path.join(root_path, \"merged_dataset.csv\")\nimages_folder = os.path.join(root_path, \"Merged\")\n\np = pd.read_csv(image_names_csv)\nprint(p.head(5),'\\n_____________________________')\n\np = p.sample(frac=1, axis=0) # shuffling the content to ensure the model doesn't learn about the order of the items\n#p = p.head(10000)\n\np['filename'] = p['filename'].apply(lambda x: os.path.join(images_folder,x))\nprint(p.head(5),'\\n_____________________________')\np.reset_index(drop=True, inplace = True)\nprint(p.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img_as_arr(img_path):\n    #return np.array(Image.open(img_path).resize((299,299)))\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #cv2.imshow(\"Resized\",img.resize(300,300))\n    return cv2.resize(img, (299, 299), interpolation = cv2.INTER_AREA)\n\ndef preprocess_img(img_path):\n    img = load_img_as_arr(img_path)\n    img = tf.cast(img, tf.float32)\n    img = (img / 255.)\n    img = (img - 0.5)\n    img = (img * 2.)\n    return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean data from gifs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#valid_idx = [i for i, img_path in X if load_image_as_arr(img_path).shape == (299,299,3)]\nnot_valid_idx = []\n#valid_idx = []\n\nfor i, img_path in enumerate(p['filename']):\n    \n    if img_path[-3:].lower() == 'gif':\n        not_valid_idx.append(i)\n        continue\n        \n    img =  load_img_as_arr(img_path)\n    #if img.shape == (299,299,3):\n        #valid_idx.append(i)\n    if img.shape == (299,299,4) or img.shape == (299,299):\n        print(img_path, \"woooooooooooooooops!\")\n        not_valid_idx.append(i)\n        \nprint(len(not_valid_idx))\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_y = np.array([c for i, c in enumerate(y) if i in valid_idx])\n# y = valid_y\n# valid_x = np.array([x for i, x in enumerate(X) if i in valid_idx])\n# X = valid_x\n# print(y.shape, X.shape)\n\n\n# X = np.array(X.drop(not_valid_idx))\n# y = np.array(y.drop(not_valid_idx))\n\np.drop(not_valid_idx, inplace = True)\np.reset_index(drop=True, inplace = True)\nX = np.array(p['filename'])\ny = np.array(p['class'])\n\nprint(X,'\\n_____________________________\\n', y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train, validation, test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=123, shuffle=True)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.176, stratify=y_train, random_state=123, shuffle=True)\n\nprint(X_train.shape, X_val.shape, X_test.shape, type(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"partition = dict()\n\npartition['train'] = X_train\npartition['test'] = X_test\npartition['validation'] = X_val\n\nlabels = { p['filename'][i] : p['class'][i] for i in range(p.shape[0]) }\n\n# zipbObj = zip(p['filename'].tolist(), p['class'].tolist())\n# labels = dict(zipbObj)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Not used"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def x_to_tensor(X):\n#     #%%time\n#     images_preprocessed = np.zeros((X.shape[0], 299, 299, 3), dtype=np.float32)\n\n#     for i, img_path in enumerate(X):\n#         img_resize = preprocess_img(img_path)\n#         if img_resize.shape != (299,299,3):\n#             print(\"woooooooooooooooops!\")\n#             print(img_resize.shape)\n#             continue\n#         images_preprocessed[i] = np.dstack([img_resize])\n#     return images_preprocessed\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%time\n#train_images_preprocess = x_to_tensor(X_train)\n#test_images_preprocess = x_to_tensor(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(299,299), n_channels=3,\n                 n_classes=3, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        # X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        X = np.zeros((self.batch_size, *self.dim, self.n_channels), dtype=np.float32)\n        y = np.empty((self.batch_size), dtype=int)\n\n        for i, ID in enumerate(list_IDs_temp):\n            img_resize = preprocess_img(ID)\n            if img_resize.shape != (299,299,3):\n                continue\n            # X[i,] = np.load('data/' + ID + '.npy')\n            X[i] = np.dstack([img_resize])\n            y[i] = self.labels[ID]\n        return  X, to_categorical(y, num_classes=self.n_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters\nparams = {'dim': (299, 299),\n          'batch_size': 32,\n          'n_classes': 3,\n          'n_channels': 3}\n\n# Datasets\n#partition = # IDs\n#labels = # Labels\n\n# Generators\ntraining_generator = DataGenerator(partition['train'], labels, **params,\n          shuffle = True)\nvalidation_generator = DataGenerator(partition['validation'], labels, **params,\n          shuffle = False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.98):\n            print(\"\\nReached 98% accuracy so cancelling training!\")\n            self.model.stop_training = True\n        \ncallbacks = myCallback()\n\n\n#More about callbacks. Callbacks + tensorboard and something else\n\n#callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./log/transer_learning_model', update_freq='batch')]\n\n\n\n# file_path=\"weights.best.hdf5\"\n\n# checkpoint = ModelCheckpoint(file_path, monitor='acc', verbose=1, save_best_only=True, mode='max')\n\n# early = EarlyStopping(monitor=\"acc\", mode=\"max\", patience=15)\n\n# callbacks_list = [checkpoint, early] #early\n\n# history = model.fit(train_images_preprocess, \n#                               epochs=2, \n#                               shuffle=True, \n#                               verbose=True) #,\n#                               #callbacks=callbacks_list)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_trained_model = applications.InceptionV3(input_shape = (299, 299, 3), # Shape of our images\n                                include_top = False, # Leave out the last fully connected layer\n                                weights = 'imagenet')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for layer in pre_trained_model.layers:\n#   layer.trainable = False\npre_trained_model.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorboard.plugins.hparams import api as hp\n\n%load_ext tensorboard\n# Clear any logs from previous runs\n!rm -rf ./logs/ \n\nHP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64, 128, 256]))\nHP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.3,  0.5))\nHP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'adagrad', 'sgd', 'rmsprop']))\n\n\n# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64]))\n# HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.4]))\n# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))\n\nMETRIC_ACCURACY = 'accuracy'\n\nwith tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n  hp.hparams_config(\n    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_model(hparams):\n    params = {'dim': (299, 299),\n          'batch_size': hparams[HP_NUM_UNITS],\n          'n_classes': 3,\n          'n_channels': 3}\n\n\n\n    # Generators\n    training_generator = DataGenerator(partition['train'], labels, **params,\n          shuffle = True)\n    validation_generator = DataGenerator(partition['validation'], labels, **params,\n          shuffle = False)\n    test_generator = DataGenerator(partition['test'], labels, **params,\n          shuffle = False)\n \n    nclass = 3\n\n    add_model = Sequential()\n    add_model.add(pre_trained_model)\n    add_model.add(GlobalAveragePooling2D())\n    add_model.add(Dense(1024, activation='relu'))\n    add_model.add(Dropout(hparams[HP_DROPOUT]))\n    add_model.add(Dense(nclass, \n                    activation='softmax'))\n\n    model = add_model\n    model.compile(loss='categorical_crossentropy', \n    #model.compile(loss='sparse_categorical_crossentropy',\n    #               optimizer=optimizers.SGD(lr=1e-4, \n    #                                        momentum=0.9),\n              optimizer=hparams[HP_OPTIMIZER],\n              metrics=['accuracy'])\n\n    history = model.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    use_multiprocessing=False,\n                    workers=2, epochs = 12,\n                             callbacks=[callbacks])\n                                        #tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n                                        #hp.KerasCallback(logdir, hparams)] ) # log hparams]) # Run with 1 epoch to speed things up for demo purposes\n    _, accuracy = model.evaluate_generator(test_generator)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run(run_dir, hparams):\n    with tf.summary.create_file_writer(run_dir).as_default():\n        hp.hparams(hparams)  # record the values used in this trial\n        accuracy = train_test_model(hparams)\n        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"session_num = 0\n\nfor num_units in HP_NUM_UNITS.domain.values:\n    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n    #for dropout_rate in HP_DROPOUT.domain.values:\n        for optimizer in HP_OPTIMIZER.domain.values:\n            hparams = {\n              HP_NUM_UNITS: num_units,\n              HP_DROPOUT: dropout_rate,\n              HP_OPTIMIZER: optimizer\n            }\n            run_name = \"run-%d\" % session_num\n            print('--- Starting trial: %s' % run_name)\n            print({h.name: hparams[h] for h in hparams})\n            run('logs/hparam_tuning/' + run_name, hparams)\n            session_num += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%tensorboard --logdir logs/hparam_tuning\n#!kill 716","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nclass = 3\n\n# add_model = Sequential()\n# add_model.add(pre_trained_model)\n# add_model.add(GlobalAveragePooling2D())\n# #add_model.add(Dense(1024, activation='relu'))\n# add_model.add(Dropout(0.3))\n# add_model.add(Dense(nclass, \n#                     activation='softmax'))\n\n# model = add_model\n# model.compile(loss='categorical_crossentropy', \n# #model.compile(loss='sparse_categorical_crossentropy',\n# #               optimizer=optimizers.SGD(lr=1e-4, \n# #                                        momentum=0.9),\n#               optimizer=optimizers.RMSprop(learning_rate = 0.001),\n#               metrics=['accuracy'])\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model on dataset\n# history = model.fit_generator(generator=training_generator,\n#                     validation_data=validation_generator,\n#                     use_multiprocessing=False,\n#                     workers=2, epochs = 8,\n#                              callbacks=[callbacks])\n\n#model.fit(train_images_preprocess, y_train, epochs=10)\n\n# Now evaluate the model - note that we're evaluating on the new model, not the old one\n#test_loss, test_acc = model.evaluate(test_images_preprocess, y_test)\n\n#print('Test accuracy:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot loss & accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# acc = history.history['accuracy']\n# val_acc = history.history['val_accuracy']\n\n# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n\n# plt.figure(figsize=(8, 16))\n# plt.subplot(2, 1, 1)\n# plt.plot(acc, label='Training Accuracy')\n# plt.plot(val_acc, label='Validation Accuracy')\n# plt.legend(loc='lower right')\n# plt.ylabel('Accuracy')\n# plt.ylim([min(plt.ylim()),1])\n# plt.title('Training and Validation Accuracy')\n\n# plt.subplot(2, 1, 2)\n# plt.plot(loss, label='Training Loss')\n# plt.plot(val_loss, label='Validation Loss')\n# plt.legend(loc='upper right')\n# plt.ylabel('Cross Entropy')\n# plt.ylim([0,1.0])\n# plt.title('Training and Validation Loss')\n# plt.xlabel('epoch')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check number of layers in models\n### To fine-tune the right amount"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(pre_trained_model.layers))\n\n# # Fine-tune from this layer onwards\n# fine_tune_at = 100\n\n# # Freeze all the layers before the `fine_tune_at` layer\n# for layer in base_model.layers[:fine_tune_at]:\n#   layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## From https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub "},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted_batch = model.predict(image_batch)\n# predicted_id = np.argmax(predicted_batch, axis=-1)\n# predicted_label_batch = class_names[predicted_id]\n\n# label_id = np.argmax(label_batch, axis=-1)\n\n# plt.figure(figsize=(10,9))\n# plt.subplots_adjust(hspace=0.5)\n# for n in range(30):\n#   plt.subplot(6,5,n+1)\n#   plt.imshow(image_batch[n])\n#   color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n#   plt.title(predicted_label_batch[n].title(), color=color)\n#   plt.axis('off')\n# _ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import time\n# t = time.time()\n\n# export_path = \"/tmp/saved_models/{}\".format(int(t))\n# model.save(export_path, save_format='tf')\n\n# export_path\n\n# #Now confirm that we can reload it, and it still gives the same results:\n\n# reloaded = tf.keras.models.load_model(export_path)\n\n# result_batch = model.predict(image_batch)\n# reloaded_result_batch = reloaded.predict(image_batch)\n\n# abs(reloaded_result_batch - result_batch).max()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Memory consumpion"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\ndef sizeof_fmt(num, suffix='B'):\n    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n        if abs(num) < 1024.0:\n            return \"%3.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n\nfor name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n                         key= lambda x: -x[1])[:10]:\n    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}