{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThe challenge 'Collision detection AI competition using vibration data' is hosted by the Korea Atomic Energy Research Institute.  The objective is to predict collider parameters using time and acceleration data. \n\nA collider is a type of particle accelerator that brings two opposing particle beams together such that the particles collide [Wikipedia]. The colliders inside the coolant systems inside a nuclear power plant. Detecting any abnormal activity in the collider helps technicians to prevent accidents.  Details of the competitions are available at https://dacon.io/competitions/official/235614/overview/. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport sklearn as sl\nimport scipy as sp\n\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/collision-detection-ai-using-vibration-data/train_features.csv\")\ntrain_target = pd.read_csv(\"/kaggle/input/collision-detection-ai-using-vibration-data/train_target.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/collision-detection-ai-using-vibration-data/test_features.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file = pd.read_csv(\"/kaggle/input/collision-detection-ai-using-vibration-data/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape,train_target.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data.id == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data.id == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data\n\nThe train data contains five attributes. The attribute id and time are self-explanatory. The acceleration parameters in the collider are labeled as S1, S2, S3, and S4. In this data, each id is corresponding to one training instance. The timestamp difference between each observation in id is four seconds, and it can be considered an equispaced time series data-set. For each id, there is a corresponding entry in the training targets data. There are 1050000 in the training data and 2800 entries. The training target contains 2800 entries for X, Y, M, and V. These are the prediction target, the collider parameters. \n\n\nUnlike the traditional data-sets in Machine learning exercises, we can't jump into modeling immediately. The data should be further converted to an appropriate scientific format before approaching the problem. One of the widely adopted methods is to apply Fourier Transform before using any modeling techniques. Let's explore the data further to understand the same. \n\n## EDA\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_data(accelaration_df : pd.DataFrame,features : list, title : str) -> None:\n    \"\"\" Plot the accelaration data\n        :params accelaration_df: accelaration data for one id\n        :params title: string\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,6))\n    fig.tight_layout(pad=10.0)\n    fig.suptitle(title)\n    \n    for idx,feature in enumerate(features):\n        ax = fig.add_subplot(2,2,idx+1)\n        accelaration_df[feature].plot(kind='line',\n                                     title = title + \" \" + feature,\n                                     ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 0],feats_to_plot,\"Accelaration Params\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target[train_target.id == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 100],feats_to_plot,\"Accelaration Params\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 250],feats_to_plot,\"Accelaration Params\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 300],feats_to_plot,\"Accelaration Params\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 400],feats_to_plot,\"Accelaration Params\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fourier Transform \n\nOne of the prominent methods to approach signal data is to apply forurier transformation in the data. The Fourier transformed data can be used for training a model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fs = 5 #sampling frequency\nfmax = 25 #sampling period\ndt = 1/fs #length of signal\nn = 75\n\ndef fft_features(data_set : pd.DataFrame) -> np.ndarray:\n    \"\"\" Convert the dataset to fourier transfomed\n        :params data_set: original collider params data\n        :returns ft_data: Fourier transformed data\n        #Reference - https://dacon.io/competitions/official/235614/codeshare/1174\n    \"\"\"\n    ft_data = list()\n    \n    features = [\"S1\",\"S2\",\"S3\", \"S4\"]\n    \n    id_set = list(data_set.id.unique())\n    \n    for ids in tqdm(id_set):\n        s1_fft = np.fft.fft(data_set[data_set.id==ids]['S1'].values)*dt\n        s2_fft = np.fft.fft(data_set[data_set.id==ids]['S2'].values)*dt\n        s3_fft = np.fft.fft(data_set[data_set.id==ids]['S3'].values)*dt\n        s4_fft = np.fft.fft(data_set[data_set.id==ids]['S4'].values)*dt\n        \n        ft_data.append(np.concatenate([np.abs(s1_fft[0:int(n/2+1)]),\n                                       np.abs(s2_fft[0:int(n/2+1)]),\n                                       np.abs(s3_fft[0:int(n/2+1)]),\n                                       np.abs(s4_fft[0:int(n/2+1)])]))\n    \n    return np.array(ft_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fft = fft_features(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fft.shape[0] == len(train_data.id.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fft = fft_features(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fft.shape[0] == len(test_data.id.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\nLet's create a multi-output Regressor Model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = GradientBoostingRegressor(loss='quantile',\n                                      n_estimators=100,\n                                      criterion='mae',\n                                      random_state=2021,\n                                      max_features='sqrt',\n                                      n_iter_no_change=2)\n\nmult_regressor = MultiOutputRegressor(base_model,\n                                      n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mult_regressor.fit(train_fft,\n                  train_target.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = mult_regressor.predict(test_fft)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file[['X','Y','M','V']] = predictions\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.to_csv(\"submission_1_1.csv\",\n                  index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Result\nThe submission ranked - 13.48313 (score) 226 in Public leaderbord.\n\n# Alternative Fature Engineering\nAn alternative approach in feature engineering is to aggregate the features and compute key statistics such as mean, median, standard deviation, minimum value, and skew. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_agg_feats(data_set : pd.DataFrame) -> pd.DataFrame:\n    \"\"\" Create aggrage features from the data\n        :param data_set: Base data as DataFrame\n        :returns agg_data: Aggragated DataFrame\n    \"\"\"\n    \n    max_feats = data_set.groupby(['id']).max().add_suffix('_max').iloc[:,1:]\n    min_feats = data_set.groupby(['id']).min().add_suffix('_min').iloc[:,1:]\n    mean_feats = data_set.groupby(['id']).mean().add_suffix('_mean').iloc[:,1:]\n    std_feats = data_set.groupby(['id']).std().add_suffix('_std').iloc[:,1:]\n    median_feats = data_set.groupby(['id']).median().add_suffix('_median').iloc[:,1:]\n    skew_feats = data_set.groupby(['id']).skew().add_suffix('_skew').iloc[:,1:]\n    \n    agg_data = pd.concat([max_feats,min_feats,\n                          mean_feats,std_feats,median_feats,skew_feats],\n                        axis=1)\n    \n    return agg_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_train = generate_agg_feats(train_data)\nagg_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_test = generate_agg_feats(test_data)\nagg_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Two with Aggragted Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mult_regressor.fit(agg_train,\n                  train_target.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_pred = mult_regressor.predict(agg_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file[['X','Y','M','V']] = agg_pred\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.to_csv(\"submission_2.csv\",\n                  index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Score\nIn this case also the score is same (13.48313). We need to try alternative modelling approach to make it better.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Regressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.multioutput import RegressorChain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr = SVR(kernel='rbf',\n         gamma='auto',\n         shrinking=True)\nregressor_chain = RegressorChain(svr,\n                                order='random',\n                                random_state=1999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor_chain.fit(agg_train,\n                  train_target.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr_p1 = regressor_chain.predict(agg_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file[['X','Y','M','V']] = svr_p1\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.to_csv(\"submission_3.csv\",\n                  index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Improved\nOur score went to 3.25082 in LB!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor_chain.fit(train_fft,\n                  train_target.drop(['id'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fft_pred = regressor_chain.predict(test_fft)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file[['X','Y','M','V']] = fft_pred\nsubmission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.to_csv(\"submission_4.csv\",\n                  index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission\nSubmission with FFT and aggragated features resulted in the same LB score.\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}