{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (15,10)})\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom numpy.random import seed\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/california-housing-prices/housing.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)\n\n        \ndisplay_all(train.describe(include='all').T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='ocean_proximity',data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='housing_median_age',data=train)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to cateogry dtype\ntrain['ocean_proximity'] = train['ocean_proximity'].astype('category')\n# convert to category codes\ntrain['ocean_proximity'] = train['ocean_proximity'].cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population',\n              'households', 'median_income', 'median_house_value']\n\nscaler = MinMaxScaler()\n\nfor var in continuous:\n    train[var] = train[var].astype('float64')\n    train[var] = scaler.fit_transform(train[var].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_all(train.describe(include='all').T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e8 = 0.8*(len(train))\ndisplay(\"e8 = \"+(str)(e8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[pd.notnull(train['total_bedrooms'])].drop(['median_house_value'], axis=1)[0:(int)(e8)]\ny_train = train[pd.notnull(train['total_bedrooms'])]['median_house_value'][0:(int)(e8)]\nX_test  = train[pd.notnull(train['total_bedrooms'])].drop(['median_house_value'], axis=1)[(int)(e8):len(train)]\ny_test  = train[pd.notnull(train['total_bedrooms'])]['median_house_value'][(int)(e8):len(train)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(\"X train = \"+(str)(len(X_train))+\", Y train = \"+(str)(len(y_train))+\", X test = \"+(str)(len(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_all(X_train.describe(include='all').T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_all(y_train.describe(include='all').T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_all(X_test.describe(include='all').T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(lyrs=[8], act='relu', opt='Adam', dr=0.0):\n\n    model = Sequential()\n    \n    # create first hidden layer\n    model.add(Dense(lyrs[0], input_dim=X_train.shape[1], activation=act))\n    \n    # create additional hidden layers\n    for i in range(1,len(lyrs)):\n        model.add(Dense(lyrs[i], activation=act))\n    \n    # add dropout, default is none\n    model.add(Dropout(dr))\n    \n    # create output layer\n    model.add(Dense(1))  # output layer\n    \n    model.compile(loss='mean_absolute_error', optimizer=opt, metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0, validation_data=(X_test, y_test))\nval_acc = np.mean(training.history['val_accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('val accuracy',(val_acc*100)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KerasClassifier(build_fn=create_model, verbose=0)\n\nbatch_size = [16, 32, 64]\nepochs = [50, 100]\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\n\n# search the grid\ngrid = GridSearchCV(estimator=model, \n                    param_grid=param_grid,\n                    cv=3,\n                    verbose=0)  \n\ngrid_result = grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}