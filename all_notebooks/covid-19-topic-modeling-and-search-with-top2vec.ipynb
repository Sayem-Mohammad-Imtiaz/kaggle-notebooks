{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19: Topic Modeling and Search with Top2Vec\n\n[Top2Vec](https://github.com/ddangelov/Top2Vec) is an algorithm for **topic modelling** and **semantic search**. It **automatically** detects topics present in text and generates jointly embedded topic, document and word vectors. Once you train the Top2Vec model you can:\n* Get number of detected topics.\n* Get topics.\n* Search topics by keywords.\n* Search documents by topic.\n* Find similar words.\n* Find similar documents.\n\nThis notebook preprocesses the [Kaggle COVID-19 Dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge), it treats each section of every paper as a distinct document. A Top2Vec model is trained on those documents. \n\nOnce the model is trained you can do **semantic** search for documents by topic, searching for documents with keywords, searching for topics with keywords, and for finding similar words. These methods all leverage the joint topic, document, word embeddings distances, which represent semantic similarity. \n\n### For an interactive version of this notebook with search widgets check out my [github](https://github.com/ddangelov/Top2Vec/blob/master/notebooks/CORD-19_top2vec.ipynb) or my [kaggle](https://www.kaggle.com/dangelov/covid-19-top2vec-interactive-search)!\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Import and Setup "},{"metadata":{},"cell_type":"markdown","source":"### 1. Install the [Top2Vec](https://github.com/ddangelov/Top2Vec) library"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install top2vec==1.0.6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json\nimport os\nfrom top2vec import Top2Vec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-process Data"},{"metadata":{},"cell_type":"markdown","source":"### 1. Import Metadata"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata_df = pd.read_csv(\"../input/CORD-19-research-challenge/metadata.csv\")\nmetadata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Pre-process Papers\n\nA document will be created for each section of every paper. This document will contain the id, title, abstract, and setion of the paper. It will also contain the text of that section."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = \"../input/CORD-19-research-challenge/\"\ncomm_dir = dataset_dir+\"comm_use_subset/comm_use_subset/pdf_json/\"\nnoncomm_dir = dataset_dir+\"noncomm_use_subset/noncomm_use_subset/pdf_json/\"\ncustom_dir = dataset_dir+\"custom_license/custom_license/pdf_json/\"\nbiorxiv_dir = dataset_dir+\"biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/\"\ndirectories_to_process = [comm_dir,noncomm_dir, custom_dir, biorxiv_dir]\n\npapers_with_text = list(metadata_df[metadata_df.has_pdf_parse==True].sha)\n\npaper_ids = []\ntitles = []\nabstracts = []\nsections = []\nbody_texts = []\n\nfor directory in directories_to_process:\n    \n    filenames = os.listdir(directory)\n\n    for filename in filenames:\n\n      file = json.load(open(directory+filename, 'rb'))\n\n      #check if file contains text\n      if file[\"paper_id\"] in papers_with_text:\n\n        section = []\n        text = []\n\n        for bod in file[\"body_text\"]:\n          section.append(bod[\"section\"])\n          text.append(bod[\"text\"])\n\n        res_df = pd.DataFrame({\"section\":section, \"text\":text}).groupby(\"section\")[\"text\"].apply(' '.join).reset_index()\n\n        for index, row in res_df.iterrows():\n\n          # metadata\n          paper_ids.append(file[\"paper_id\"])\n\n          if(len(file[\"abstract\"])):\n            abstracts.append(file[\"abstract\"][0][\"text\"])\n          else:\n            abstracts.append(\"\")\n\n          titles.append(file[\"metadata\"][\"title\"])\n\n          # add section and text\n          sections.append(row.section)\n          body_texts.append(row.text)\n            \npapers_df = pd.DataFrame({\"id\":paper_ids, \"title\": titles, \"abstract\": abstracts, \"section\": sections, \"text\": body_texts})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"papers_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Filter Short Sections"},{"metadata":{"trusted":true},"cell_type":"code","source":"papers_df[\"token_counts\"] = papers_df[\"text\"].str.split().map(len)\npapers_df = papers_df[papers_df.token_counts>200].reset_index(drop=True)\npapers_df.drop('token_counts', axis=1, inplace=True)\npapers_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Top2Vec Model\n```python\n\n top2vec = Top2Vec(documents=papers_df.text, speed=\"learn\", workers=4)\n\n```\n\nParameters:\n  * ``documents``: Input corpus, should be a list of strings.\n  \n  * ``speed``: This parameter will determine how fast the model takes to train. \n    The 'fast-learn' option is the fastest and will generate the lowest quality\n    vectors. The 'learn' option will learn better quality vectors but take a longer\n    time to train. The 'deep-learn' option will learn the best quality vectors but \n    will take significant time to train.  \n    \n  * ``workers``: The amount of worker threads to be used in training the model. Larger\n    amount will lead to faster training.\n    \nSee [Documentation](https://top2vec.readthedocs.io/en/latest/README.html)."},{"metadata":{},"cell_type":"markdown","source":"## (Recommended) Load Pre-trained Model and Pre-processed Data :)\n\nThe Top2Vec model was trained with the 'deep-learn' speed parameter and took very long to train. It will give much better results than training with 'fast-learn' or 'learn'.\n"},{"metadata":{},"cell_type":"markdown","source":"### 1. Load pre-trained Top2Vec model "},{"metadata":{"trusted":true},"cell_type":"code","source":"top2vec = Top2Vec.load(\"../input/covid19top2vec/covid19_deep_learn_top2vec\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Load pre-processed papers"},{"metadata":{"trusted":true},"cell_type":"code","source":"papers_df = pd.read_feather(\"../input/covid19top2vec/covid19_papers_processed.feather\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Top2Vec Discovered Topics"},{"metadata":{},"cell_type":"markdown","source":"## 1. Get number of topics found by model."},{"metadata":{"trusted":true},"cell_type":"code","source":"top2vec.get_num_topics()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Get topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_words, word_scores, topic_nums = top2vec.get_topics(399)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. View topics 180 through 190"},{"metadata":{"trusted":true},"cell_type":"code","source":"for topic in topic_nums[180:190]:\n    top2vec.generate_topic_wordcloud(topic, background_color=\"black\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use Top2Vec for Semantic Search\n\n### \"What is known about transmission, incubation, and environmental stability?\""},{"metadata":{},"cell_type":"markdown","source":"## 1. Search Topics \n\nDiscover topics relevant to **COVID-19** and **infection**."},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_words, word_scores, topic_scores, topic_nums = top2vec.search_topics(keywords=[\"covid\", \"infect\"],num_topics=10)\nfor topic in topic_nums:\n    top2vec.generate_topic_wordcloud(topic, background_color=\"black\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Search Papers by Topic\n\nSearch by topic **344**, which appears to be about **infectiousness**."},{"metadata":{"trusted":true},"cell_type":"code","source":"documents, document_scores, document_nums = top2vec.search_documents_by_topic(topic_num=344, num_docs=2)\n    \nresult_df = papers_df.loc[document_nums]\nresult_df[\"document_scores\"] = document_scores\n\nfor index,row in result_df.iterrows():\n    print(f\"Document: {index}, Score: {row.document_scores}\")\n    print(f\"Section: {row.section}\")\n    print(f\"Title: {row.title}\")\n    print(\"-----------\")\n    print(row.text)\n    print(\"-----------\")\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Search Papers by Keywords\n\nSearch for documents that are about **coronovirus** **models**."},{"metadata":{"trusted":true},"cell_type":"code","source":"documents, document_scores, document_nums = top2vec.search_documents_by_keyword(keywords=[\"covid\", \"model\"], num_docs=2)\nresult_df = papers_df.loc[document_nums]\nresult_df[\"document_scores\"] = document_scores\n\nfor index,row in result_df.iterrows():\n    print(f\"Document: {index}, Score: {row.document_scores}\")\n    print(f\"Section: {row.section}\")\n    print(f\"Title: {row.title}\")\n    print(\"-----------\")\n    print(row.text)\n    print(\"-----------\")\n    print()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Find Similar Words\n\nFind similar words to **chloroquine**."},{"metadata":{"trusted":true},"cell_type":"code","source":"words, word_scores = top2vec.similar_words(keywords=[\"chloroquine\"], num_words=20)\nfor word, score in zip(words, word_scores):\n    print(f\"{word} {score}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}