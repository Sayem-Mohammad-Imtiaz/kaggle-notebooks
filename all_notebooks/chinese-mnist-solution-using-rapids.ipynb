{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.017738,"end_time":"2020-08-18T08:42:05.895001","exception":false,"start_time":"2020-08-18T08:42:05.877263","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<h1><center><font size=\"6\">Tensorflow/Keras/GPU for Chinese MNIST Prediction</font></center></h1>\n\n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Prepare the analysis</a>   \n- <a href='#4'>Characters classification</a>       \n- <a href='#5'>Conclusions</a>       \n"},{"metadata":{"_uuid":"a8e77ace65f04c89a878bf18249e4d8e23fec996","papermill":{"duration":0.014071,"end_time":"2020-08-18T08:42:05.923475","exception":false,"start_time":"2020-08-18T08:42:05.909404","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# <a id='1'>Introduction</a>  \n\n\nWe will use RAPIDS to solve Chinese MNIST problem.\n\nFor more details about the problem, you can check this Notebook: [Tensorflow/Keras/GPU for Chinese MNIST Prediction](https://www.kaggle.com/gpreda/tensorflow-keras-gpu-for-chinese-mnist-prediction)\n\n\nWe will follow the preparation steps in the model Notebook, changing the solution approach, to use KNN & RAPIDS, as shown in Chris Deotte Notebook: \n[RAPIDS GPU kNN - MNIST - [0.97]](https://www.kaggle.com/cdeotte/rapids-gpu-knn-mnist-0-97/data).\n\nNote: I updated the installation steps for RAPIDS using inspiration from this Notebook: [üë®‚ÄçüéìAnswer Correctness - RAPIDS crazy fast](https://www.kaggle.com/andradaolteanu/answer-correctness-rapids-crazy-fast)\n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>  "},{"metadata":{"_uuid":"4e97555eb77978a29a51c41f39cec67136b18157","papermill":{"duration":0.013784,"end_time":"2020-08-18T08:42:05.951691","exception":false,"start_time":"2020-08-18T08:42:05.937907","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# <a id='2'>Prepare the analysis</a>   \n\n\nBefore starting the analysis, we need to make few preparation: install RAPIDS from the dataset, load the packages, load and inspect the data.\n\n"},{"metadata":{"_uuid":"cb2e73fe056a3dda7eb48eeac2facf0c441816d1","papermill":{"duration":0.014536,"end_time":"2020-08-18T08:42:05.980937","exception":false,"start_time":"2020-08-18T08:42:05.966401","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# <a id='21'>Install RAPIDS & load packages</a>\n\n\n"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"%%time\nimport sys\n!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We load the packages used for the analysis."},{"metadata":{"_kg_hide-input":true,"_uuid":"af08260bfbe163f9132f39d09627899bbc4c1dae","execution":{"iopub.execute_input":"2020-08-18T08:42:06.021504Z","iopub.status.busy":"2020-08-18T08:42:06.020726Z","iopub.status.idle":"2020-08-18T08:42:15.881767Z","shell.execute_reply":"2020-08-18T08:42:15.88052Z"},"papermill":{"duration":9.886477,"end_time":"2020-08-18T08:42:15.881916","exception":false,"start_time":"2020-08-18T08:42:05.995439","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import cudf, cuml\nimport pandas as pd, numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom cuml.neighbors import KNeighborsClassifier, NearestNeighbors\nprint('cuML version',cuml.__version__)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.014277,"end_time":"2020-08-18T08:42:15.911811","exception":false,"start_time":"2020-08-18T08:42:15.897534","status":"completed"},"tags":[]},"cell_type":"markdown","source":"We also set a number of parameters for the data and model."},{"metadata":{"_kg_hide-input":true,"_uuid":"a2082fb1e56fc6cfc91d40820b905267bc1ca468","execution":{"iopub.execute_input":"2020-08-18T08:42:15.949628Z","iopub.status.busy":"2020-08-18T08:42:15.947644Z","iopub.status.idle":"2020-08-18T08:42:15.95042Z","shell.execute_reply":"2020-08-18T08:42:15.950946Z"},"papermill":{"duration":0.024868,"end_time":"2020-08-18T08:42:15.951079","exception":false,"start_time":"2020-08-18T08:42:15.926211","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"IMAGE_PATH = '..//input//chinese-mnist//data//data//'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\nIMAGE_CHANNELS = 1\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"307f656565365ff05faf226e5a447875dd0dfead","papermill":{"duration":0.014071,"end_time":"2020-08-18T08:42:15.979428","exception":false,"start_time":"2020-08-18T08:42:15.965357","status":"completed"},"tags":[]},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n# <a id='22'>Load the data</a>  \n\nLet's see first what data files do we have in the root directory."},{"metadata":{"_kg_hide-input":true,"_uuid":"9f1df6658b17558179d8a9016f544410de16c354","execution":{"iopub.execute_input":"2020-08-18T08:42:16.020308Z","iopub.status.busy":"2020-08-18T08:42:16.018357Z","iopub.status.idle":"2020-08-18T08:42:16.035873Z","shell.execute_reply":"2020-08-18T08:42:16.037599Z"},"papermill":{"duration":0.043446,"end_time":"2020-08-18T08:42:16.037799","exception":false,"start_time":"2020-08-18T08:42:15.994353","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"..//input//chinese-mnist\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"241b8735a85a25e16421fda8c35bc3d3c69e7ea8","papermill":{"duration":0.024081,"end_time":"2020-08-18T08:42:16.08753","exception":false,"start_time":"2020-08-18T08:42:16.063449","status":"completed"},"tags":[]},"cell_type":"markdown","source":"There is a dataset file and a folder with images.  \n\nLet's load the dataset file first."},{"metadata":{"_kg_hide-input":true,"_uuid":"d7b9f11a014428e56e422d97a5b3ef70efec007e","execution":{"iopub.execute_input":"2020-08-18T08:42:16.140125Z","iopub.status.busy":"2020-08-18T08:42:16.139076Z","iopub.status.idle":"2020-08-18T08:42:16.171906Z","shell.execute_reply":"2020-08-18T08:42:16.17303Z"},"papermill":{"duration":0.063017,"end_time":"2020-08-18T08:42:16.173239","exception":false,"start_time":"2020-08-18T08:42:16.110222","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_df=pd.read_csv('..//input//chinese-mnist//chinese_mnist.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"46f15681887fa82ab13224e52df69d91119fc9ad","execution":{"iopub.execute_input":"2020-08-18T08:42:16.702579Z","iopub.status.busy":"2020-08-18T08:42:16.701867Z","iopub.status.idle":"2020-08-18T08:42:16.870723Z","shell.execute_reply":"2020-08-18T08:42:16.87128Z"},"papermill":{"duration":0.191846,"end_time":"2020-08-18T08:42:16.871439","exception":false,"start_time":"2020-08-18T08:42:16.679593","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-08-18T08:42:16.938237Z","iopub.status.busy":"2020-08-18T08:42:16.937385Z","iopub.status.idle":"2020-08-18T08:42:16.940912Z","shell.execute_reply":"2020-08-18T08:42:16.941367Z"},"papermill":{"duration":0.02337,"end_time":"2020-08-18T08:42:16.941576","exception":false,"start_time":"2020-08-18T08:42:16.918206","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_file_name(x):\n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-08-18T08:42:16.976781Z","iopub.status.busy":"2020-08-18T08:42:16.976178Z","iopub.status.idle":"2020-08-18T08:42:17.993276Z","shell.execute_reply":"2020-08-18T08:42:17.992471Z"},"papermill":{"duration":1.03642,"end_time":"2020-08-18T08:42:17.99341","exception":false,"start_time":"2020-08-18T08:42:16.95699","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"457cd17212904bb96f86ec1770cbdbefc5ffb395","execution":{"iopub.execute_input":"2020-08-18T08:42:18.037831Z","iopub.status.busy":"2020-08-18T08:42:18.035949Z","iopub.status.idle":"2020-08-18T08:42:18.040029Z","shell.execute_reply":"2020-08-18T08:42:18.039463Z"},"papermill":{"duration":0.031074,"end_time":"2020-08-18T08:42:18.040142","exception":false,"start_time":"2020-08-18T08:42:18.009068","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b20cd791ede3f23d0c9275aafc75827b9424df4","papermill":{"duration":0.014696,"end_time":"2020-08-18T08:42:18.069747","exception":false,"start_time":"2020-08-18T08:42:18.055051","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's also check the image sizes."},{"metadata":{"_kg_hide-input":true,"_uuid":"6f1c39d0398275215f92f61542544132a0d574a0","execution":{"iopub.execute_input":"2020-08-18T08:43:04.264831Z","iopub.status.busy":"2020-08-18T08:43:04.263285Z","iopub.status.idle":"2020-08-18T08:43:04.269593Z","shell.execute_reply":"2020-08-18T08:43:04.268983Z"},"papermill":{"duration":0.029491,"end_time":"2020-08-18T08:43:04.269707","exception":false,"start_time":"2020-08-18T08:43:04.240216","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(f\"Number of suites: {data_df.suite_id.nunique()}\")\nprint(f\"Samples: {data_df.sample_id.unique()}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2a5e2401b418f1723c859ee9e0b4ad5071e4a82","papermill":{"duration":0.024232,"end_time":"2020-08-18T08:43:04.370546","exception":false,"start_time":"2020-08-18T08:43:04.346314","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# <a id='4'>Characters classification</a>\n\nOur objective is to use the images that we investigated until now to correctly identify the Chinese numbers (characters).   \n\nWe have a unique dataset and we will have to split this dataset in **train** and **test**. The **train** set will be used for training a model and the test will be used for testing the model accuracy against new, fresh data, not used in training.\n\n"},{"metadata":{"_uuid":"e8c0a6df4bb85bcdf90f7c908decab07304d660f","papermill":{"duration":0.023132,"end_time":"2020-08-18T08:43:04.418984","exception":false,"start_time":"2020-08-18T08:43:04.395852","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## <a id='40'>Split the data</a>  \n\nFirst, we split the whole dataset in train and test. We will use **random_state** to ensure reproductibility of results. We also use **stratify** to ensure balanced train/validation/test sets with respect of the labels. \n\nThe train-test split is **80%** for training set and **20%** for test set.\n"},{"metadata":{"_kg_hide-input":true,"_uuid":"352d452d5212d8c9eff074f11820b03a0d44387b","execution":{"iopub.execute_input":"2020-08-18T08:43:04.476035Z","iopub.status.busy":"2020-08-18T08:43:04.475023Z","iopub.status.idle":"2020-08-18T08:43:04.502047Z","shell.execute_reply":"2020-08-18T08:43:04.503163Z"},"papermill":{"duration":0.060317,"end_time":"2020-08-18T08:43:04.503409","exception":false,"start_time":"2020-08-18T08:43:04.443092","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=42, stratify=data_df[\"code\"].values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"856060cc500db00e472b7755c91aba20c953a5f6","papermill":{"duration":0.050345,"end_time":"2020-08-18T08:43:04.581036","exception":false,"start_time":"2020-08-18T08:43:04.530691","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Next, we will split further the **train** set in **train** and **validation**. We want to use as well a validation set to be able to measure not only how well fits the model the train data during training (or how well `learns` the training data) but also how well the model is able to generalize so that we are able to understands not only the bias but also the variance of the model.  \n\nThe train-validation split is **80%** for training set and **20%** for validation set."},{"metadata":{"_kg_hide-input":true,"_uuid":"0dcaa8c2c5423ab8fc2898d4a4aa937801592c2c","papermill":{"duration":0.026971,"end_time":"2020-08-18T08:43:04.785459","exception":false,"start_time":"2020-08-18T08:43:04.758488","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Let's check the shape of the three datasets."},{"metadata":{"_kg_hide-input":true,"_uuid":"8247f70b4deb4600fe322f004733234ed37617f0","execution":{"iopub.execute_input":"2020-08-18T08:43:04.84915Z","iopub.status.busy":"2020-08-18T08:43:04.848208Z","iopub.status.idle":"2020-08-18T08:43:04.854055Z","shell.execute_reply":"2020-08-18T08:43:04.854912Z"},"papermill":{"duration":0.043453,"end_time":"2020-08-18T08:43:04.855106","exception":false,"start_time":"2020-08-18T08:43:04.811653","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee768c083f40fcbd109425182bc55ce86173b69d","papermill":{"duration":0.036463,"end_time":"2020-08-18T08:43:04.917496","exception":false,"start_time":"2020-08-18T08:43:04.881033","status":"completed"},"tags":[]},"cell_type":"markdown","source":"We are now ready to start building our first model."},{"metadata":{"_uuid":"d76e822dd76565d29fcfed323cb034939f307581","papermill":{"duration":0.026542,"end_time":"2020-08-18T08:43:04.984231","exception":false,"start_time":"2020-08-18T08:43:04.957689","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## <a id='41'>Build the model</a>    \n\n\nNext step in our creation of a predictive model.  \n\nLet's define few auxiliary functions that we will need for creation of our models.\n\n* A function for reading images from the image files; resize them to prepare for KNN\n* A function to prepare the data: call the read/resize image function + label encoding"},{"metadata":{"_kg_hide-input":true,"_uuid":"f80b4e20e98ce5bf328fba3a22457c4a994de06b","execution":{"iopub.execute_input":"2020-08-18T08:43:05.038239Z","iopub.status.busy":"2020-08-18T08:43:05.037413Z","iopub.status.idle":"2020-08-18T08:43:05.041136Z","shell.execute_reply":"2020-08-18T08:43:05.041896Z"},"papermill":{"duration":0.033552,"end_time":"2020-08-18T08:43:05.042075","exception":false,"start_time":"2020-08-18T08:43:05.008523","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import cv2\ndef read_image(file_name):\n    image_data = cv2.imread(IMAGE_PATH + file_name, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image_data, (IMAGE_WIDTH * IMAGE_HEIGHT, 1))\n\n    return image[0,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(train_df['character'])\nprint(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(dataset,label_encoding=le):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = label_encoding.transform(dataset['character'])\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"70acefcd6dc5d494b1c7db6dc90bae5f8c856d94","execution":{"iopub.execute_input":"2020-08-18T08:43:05.234422Z","iopub.status.busy":"2020-08-18T08:43:05.233694Z","iopub.status.idle":"2020-08-18T08:43:47.426887Z","shell.execute_reply":"2020-08-18T08:43:47.425906Z"},"papermill":{"duration":42.216746,"end_time":"2020-08-18T08:43:47.427032","exception":false,"start_time":"2020-08-18T08:43:05.210286","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"X_train, y_train = prepare_data(train_df)\nX_test, y_test = prepare_data(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5093354dc9c7f0510ba54a254690db45e38d0bcc","papermill":{"duration":0.016054,"end_time":"2020-08-18T08:43:47.459838","exception":false,"start_time":"2020-08-18T08:43:47.443784","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Now we are ready to start experiment with the KNN model."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for k in range(1,16):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_hat_p = knn.predict_proba(X_test)\n    y_tr_hat_p = knn.predict_proba(X_train)\n    y_pred = pd.DataFrame(y_hat_p).values.argmax(axis=1)\n    y_tr_pred = pd.DataFrame(y_tr_hat_p).values.argmax(axis=1)\n    acc = (y_pred==y_test).sum()/y_test.shape[0]\n    acc_tr = (y_tr_pred==y_train).sum()/y_train.shape[0]\n    print(f\"k: {k} accuracy(train): {round(acc_tr,3)} accuracy(test): {round(acc,3)} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred, target_names=le.classes_))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}