{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"importing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import modules\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/logistic-regression-heart-disease-prediction/framingham_heart_disease.csv\")\ndata.head()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Exploration**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Checking NULL values in the dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will eliminate the Null Values by droping the rows having the NULL values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(axis=0,inplace=True)\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Plotting Data w.r.t. the target class*"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.TenYearCHD.value_counts())\nsns.countplot(x='TenYearCHD',data=data,palette='hls')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data,x=\"diaBP\",y=\"heartRate\",hue=\"TenYearCHD\",size=50,legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healthy=len(data[data['TenYearCHD']==0])\ndiseased=len(data[data['TenYearCHD']==1])\nPercent_of_healthy = healthy/(healthy+diseased)\nPercent_of_diseased= diseased/(healthy+diseased)\nprint(\"Percentage of healthy people is : \",Percent_of_healthy*100)\nprint(\"Percentage of diseased people is : \",Percent_of_diseased*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" From the above plots , we observe that our dataset is unbalanced.\n\nWe will balance it using various methods during fitting the model.Balancing is important as logistic regression on imbalanced dataset will give biased results."},{"metadata":{},"cell_type":"markdown","source":"**Feature Selection**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(data.corr(),annot=True,cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above correlation matrix we can find a very high correlation between currentSmoker and cigsPerDay,hence we can drop any one of them.\n\nAlso,education does not play any important role in heart attack hence we can also drop that column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop('education',axis=1)\n\ndata=data.drop('cigsPerDay',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('TenYearCHD').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As diaBP,BMI,heartRate have values in similar zones and almost equal to one another for 1 or 0 values for TenYearCHD hence they can be dropped.\n\nIn other words,these 3 have low variance for categoreies of TenYearCHD"},{"metadata":{"trusted":true},"cell_type":"code","source":"data= data.drop(['diaBP','BMI','heartRate'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.loc[:,data.columns != 'TenYearCHD']\ny = data.loc[:,data.columns == 'TenYearCHD']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataset Balancing**"},{"metadata":{},"cell_type":"raw","source":"For balancing the dataset we will use Random Undersampling.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"> Random UnderSampling\n\nThis method seeks to randomly select and remove samples from the majority class, consequently reducing the number of examples in the majority class in the transformed data.\n\n“In random under-sampling (potentially), vast quantities of data are discarded. This can be highly problematic, as the loss of such data can make the decision boundary between the minority and majority instances harder to learn, resulting in a loss in classification performance.”\n\nUsing this approach is effective in situations where the minority class has a sufficient amount of examples despite the severe imbalance. On the other hand, it is always important to consider the prospects of valuable information being deleted as we randomly remove them from our data set since we have no way to detect or preserve the examples that are information rich in the majority class."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiating the random undersampler\nrus = RandomUnderSampler() \n# resampling X, y\nX_rus, y_rus = rus.fit_resample(x, y)\n# new class distribution\nprint(Counter(y_rus))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Implementing the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus, test_size=0.3, random_state=0)\nlogreg = LogisticRegression(class_weight=\"balanced\",max_iter=1000)\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncnf = confusion_matrix(y_test, y_pred)\n\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.imshow(cnf)\nax.grid(False)\nax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\nax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\nax.set_ylim(1.5, -0.5)\nfor i in range(2):\n    for j in range(2):\n        ax.text(j, i, cnf[i, j], ha='center', va='center', color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\nmae = mean_absolute_error(y_test,y_pred)\nmse= mean_squared_error(y_test,y_pred)\nr2 = r2_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Absolute Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mae)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Squared error"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mse)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R2 score"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(r2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}