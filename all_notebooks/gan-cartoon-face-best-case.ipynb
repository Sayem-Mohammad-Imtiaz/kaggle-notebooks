{"cells":[{"metadata":{"trusted":true,"_uuid":"7ffe3d16cdd8117a614c0ca35d8612a2c417381a"},"cell_type":"code","source":"!pip install -q tf-nightly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"267600a9f29044d3061a0cfce282d1f9858d6cdc"},"cell_type":"code","source":"import tensorflow as tf\ntf.enable_eager_execution()\n\nimport numpy as np\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport time\nimport pathlib\nimport random\nimport IPython.display as display\n\nfrom IPython import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a70ecd5de9e69437de93d4211cb72dd58d4039a"},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69bff7ade2013f4d0df0a66330a6bd7c110f4697"},"cell_type":"code","source":"cartoon_image_path = os.listdir('../input/cartoonfacedatasetzip/cartoon_face_dataset/cartoonset10k')\ncartoon_image_path = [os.path.join(\"../input/cartoonfacedatasetzip/cartoon_face_dataset/cartoonset10k\", x) for x in cartoon_image_path]\n\ncim = []\nfor x in cartoon_image_path:\n    if x[-3:]=='png':\n        cim.append(x)\ncartoon_image_path = cim\nlen(cartoon_image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"485b9243b94b084433fe032d7df049ab73719853"},"cell_type":"code","source":"def preprocess_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    #image = ndi.gaussian_filter(image, 5)\n    image = tf.image.resize_images(image, [58, 58])\n    image = tf.image.central_crop(central_fraction=0.55, image=image)\n    #image = tf.image.rgb_to_grayscale(image)\n    image -= 127.5\n    image /= 127.5  # normalize to [-1,1] range\n    return image\n\ndef load_image(path):\n    image = tf.read_file(path)\n    return preprocess_image(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90a9c98a998baf24e318c40cc814aa0dac560e27"},"cell_type":"code","source":"cartoon_path_ds = tf.data.Dataset.from_tensor_slices(cartoon_image_path)\ncartoon_image_ds = cartoon_path_ds.map(load_image, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aae11e2397b0c00306b0a53c7572c990944e93b"},"cell_type":"code","source":"def show_images(images, l=2, epoch=-1):\n    plt.figure(figsize=(l*1.5,l*1.5))\n    for n,image in enumerate(images):\n        image = (image + 1 ) / 2 #scale to [0,1]\n        plt.subplot(l,l,n+1)\n        plt.imshow(image)\n        plt.grid(False)\n    plt.show()\n    print(image.shape)\n    if epoch!=-1:\n        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\nshow_images(cartoon_image_ds.take(4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7329a17b40f42f0a4150749c1c8f8ccd16215a2"},"cell_type":"code","source":"cartoon_BATCH_SIZE = 32\ncartoon_ds = cartoon_image_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(cartoon_image_path)))\ncartoon_ds = cartoon_ds.batch(cartoon_BATCH_SIZE)\n# `prefetch` lets the dataset fetch batches, in the background while the model is training.\ncartoon_ds = cartoon_ds.prefetch(buffer_size=AUTOTUNE)\ncartoon_ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4590474b699bf7e336241e99d134002e511ee0f4"},"cell_type":"code","source":"for cartoon in cartoon_ds:\n    test_cartoon = cartoon\n    break\n    \nprint(test_cartoon.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecb032b1f3dd565dd49ca69c9a66e5821ae5b913"},"cell_type":"code","source":"test_cartoon = test_cartoon[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"930f6b23129f0f75760f6426e6bd2f65035dfc60"},"cell_type":"code","source":"show_images(test_cartoon)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc8866b79c640d33f6a6c7050440a5922b70d1ca"},"cell_type":"code","source":"print(np.max(test_cartoon))\nprint(np.min(test_cartoon))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9a0baaaa04e431b5138e9a68dc73a6c7bd2f318"},"cell_type":"code","source":"def make_generator_model():\n    \n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(4*4*512, use_bias=False, input_shape=(100,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.ReLU())\n    model.add(tf.keras.layers.Dropout(0.3))\n\n    model.add(tf.keras.layers.Reshape((4, 4, 512)))\n    \n    model.add(tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.ReLU())\n    model.add(tf.keras.layers.Dropout(0.3))\n    \n    model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.ReLU())\n    model.add(tf.keras.layers.Dropout(0.3))\n\n    model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.ReLU())\n    model.add(tf.keras.layers.Dropout(0.3))\n\n    model.add(tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"5ca58194f6e0871b8caec93d3b875f99e4f9dc53"},"cell_type":"code","source":"generator = make_generator_model()\ngenerator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8923cb147e6dbd7b7fc28b2668b593f10ee76b2"},"cell_type":"code","source":"noise_dim = 100\nnoise = tf.random_normal([1, noise_dim])\ngen_out = generator(noise)\nshow_images(gen_out, l=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd9586338c97cc6c3726c8bb06b81e959e18dda"},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(32,32,3)))\n    model.add(tf.keras.layers.LeakyReLU(0.2))\n    model.add(tf.keras.layers.Dropout(0.3))\n      \n    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU(0.2))\n    model.add(tf.keras.layers.Dropout(0.3))\n    \n    model.add(tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU(0.2))\n    model.add(tf.keras.layers.Dropout(0.3))\n       \n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1))\n    #model.add(tf.keras.layers.Activation('sigmoid'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29d76fe301920041533080115ba31a4a7362e806"},"cell_type":"code","source":"discriminator = make_discriminator_model()\ndiscriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dd27dd035b47bebefa0f2bb7d0aaf59b8da873d"},"cell_type":"code","source":"def generator_loss(generated_output):\n    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"744ddf707291c287b770721ec8362ec6b978e1d8"},"cell_type":"code","source":"def discriminator_loss(real_out, generated_out):\n    real_loss = tf.losses.sigmoid_cross_entropy(tf.ones_like(real_out), real_out)\n    generated_loss = tf.losses.sigmoid_cross_entropy(tf.zeros_like(generated_out), generated_out)\n    total_loss = real_loss + generated_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea669465f9891f0c278ebacf763b786606035dfe"},"cell_type":"code","source":"g_optimizer = tf.train.AdamOptimizer(1e-3, beta1=0.5)\nd_optimizer = tf.train.AdamOptimizer(1e-3, beta1=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3897b3fe7bab35df92355784f2870778c73cb196"},"cell_type":"code","source":"2.5e-4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0565bea6717998a05e5fa279957b29c71026cf8"},"cell_type":"code","source":"noise_dim = 100\nnum_examples_to_generate = 16\n\n# We'll re-use this random vector used to seed the generator so\n# it will be easier to see the improvement over time.\nrandom_vector_for_generation = tf.random_normal([num_examples_to_generate,\n                                                 noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"074723989a94ab41ee14b474a0c668f275628969"},"cell_type":"code","source":"'''def train_step(cartoon_images):\n    \n    noises = tf.random_normal([cartoon_BATCH_SIZE, noise_dim])\n    for noise, cartoon_image in zip(noises, cartoon_images):\n        \n        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n\n            # generating noise from a normal distribution\n\n            generated_image = generator(noise, training = True)\n\n            real_out = discriminator(cartoon_image, training =True)\n            generated_out = discriminator(generated_image, training = True)\n\n            gen_loss = generator_loss(generated_out)\n            dis_loss = discriminator_loss(real_out, generated_out)\n\n        gen_grad = gen_tape.gradient(gen_loss, generator.variables)\n        dis_grad = dis_tape.gradient(dis_loss, discriminator.variables)\n\n        g_optimizer.apply_gradients(zip(gen_grad, generator.variables))\n        d_optimizer.apply_gradients(zip(dis_grad, discriminator.variables))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fefce4fa900852403b7242df262084ee344855c"},"cell_type":"code","source":"def train_step(cartoon_images):\n            \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n\n        noise = tf.random_normal([cartoon_BATCH_SIZE, noise_dim])\n        # generating noise from a normal distribution\n        generated_images = generator(noise, training = True)\n\n        real_out = discriminator(cartoon_images, training = True)\n        generated_out = discriminator(generated_images, training = True)\n\n        gen_loss = generator_loss(generated_out)\n        dis_loss = discriminator_loss(real_out, generated_out)\n\n    gen_grad = gen_tape.gradient(gen_loss, generator.variables)\n    dis_grad = dis_tape.gradient(dis_loss, discriminator.variables)\n\n    g_optimizer.apply_gradients(zip(gen_grad, generator.variables))\n    d_optimizer.apply_gradients(zip(dis_grad, discriminator.variables))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15f3650de7811c6a74b0aacb800e1a22960957d4"},"cell_type":"code","source":"train_step = tf.contrib.eager.defun(train_step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bb8ce66f032d7ac91d4a0a1773e382d5f1b2988"},"cell_type":"code","source":"def generate_test_prediction(model, epoch, test_input):\n    # make sure the training parameter is set to False because we\n    # don't want to train the batchnorm layer when doing inference.\n    \n    gen_out = generator(test_input, training=False)\n    show_images(gen_out, 4, epoch=epoch)\n    #print(discriminator(gen_out[:4]))\n    #print(discriminator(test_cartoon))\n    #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5b4df987a4f349653ceb7900e748c44c804eca7"},"cell_type":"code","source":"gen_out = generator(random_vector_for_generation, training=False)\nprint(np.max(gen_out))\nprint(np.min(gen_out))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a188eca4cba199bc0d21a0b687aa6b50cb014194"},"cell_type":"code","source":"generate_test_prediction(generator, 4, random_vector_for_generation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdf0f35753068a05bd97112e2bfa7a42cc0b2615"},"cell_type":"code","source":"def train(epochs):\n    epoch = 0\n    start = time.time()\n    for cartoon_images in cartoon_ds:\n        train_step(cartoon_images)\n        epoch = epoch + 1\n        if(epoch%10==0):\n            #display.clear_output(wait = True)\n            generate_test_prediction(generator, epoch, random_vector_for_generation)\n        print ('Time taken for epoch {} is {} sec'.format(epoch, time.time()-start))\n        start = time.time()\n        if epoch == epochs:\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d8ec8d17931e9b3125e4a35affbae08827bcdda"},"cell_type":"code","source":"EPOCHS = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09b8cf830f5347b8da56ed4b75909e4bea094ec1","scrolled":false},"cell_type":"code","source":"%%time\ntrain(EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4609bef150abfc18dbbb3b91a4cd6d4d0cbc035d"},"cell_type":"code","source":"gen_out = generator(random_vector_for_generation)\nprint(np.max(gen_out))\nprint(np.min(gen_out))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08d29e07ccf41dcfc02a653cb9a1fd55feaeb5de"},"cell_type":"code","source":"for n,image in enumerate(gen_out):\n    image = image/2 + 0.5\n    plt.subplot(4,4,n+1)\n    plt.imshow(image)\n    plt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46c84403732c0dfbdcbf025d7013a15924b816fd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}