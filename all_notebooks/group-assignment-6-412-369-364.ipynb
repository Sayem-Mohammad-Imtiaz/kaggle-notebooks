{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#ASSIGNMENT NO. 6\n#SWATI.MARUVALLI 01FB16ECS412\n#SHREYA ESWARAIAH 01FB16ECS369\n#SIRISHA R RAO 01FB16ESC364\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37d051bde1d3790fabce10b1c476032cf81624fc"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cfda40412959657ded287ddf731bef43cdf2c62"},"cell_type":"code","source":"data_file = \"../input/Absenteeism_at_work.csv\"\ndf= pd.read_csv(data_file)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9bfbf96fecdc298ae09aee665e3cc5d7fe0fdca"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90f3d36ffe5500a3f27acf9d0cf66b943f71dc87"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#Preprocessing data - stage 1 (Removing outliers in label)\nsns.boxplot(df['Absenteeism time in hours'])\nmedian = np.median(df['Absenteeism time in hours'])\nq75, q25 = np.percentile(df['Absenteeism time in hours'], [75 ,25])\niqr = q75 - q25\nprint(\"Lower outlier bound:\",q25 - (1.5*iqr))\nprint(\"Upper outlier bound:\",q75 + (1.5*iqr))\n#dropping the following outliers above 17\ndf= df[df['Absenteeism time in hours']<=17]\ndf= df[df['Absenteeism time in hours']>=-7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26bd0dbe238b6b991a4f9abad4e9a98ddc8152b8"},"cell_type":"code","source":"#Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\ny=df['Absenteeism time in hours']\nX=df.drop('Absenteeism time in hours',axis=1)#Extracting only the features\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\nprint(df.shape)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\nprint(\"Number of unique ouput classes after preprocessing:\",((np.unique(y_train))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df896e7de21c526544512cbdcab05773c99ae135"},"cell_type":"code","source":"#Calculate the correlation of the above variables\ncor = df.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(cor, square = True,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1881e87f0fd2fcbdb461e1d724d013583d8700a7"},"cell_type":"code","source":"#Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\ny=df['Absenteeism time in hours']\nX=df.drop('Absenteeism time in hours',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b1cc86c9c2685f10818a0755502df17e14af0bb"},"cell_type":"code","source":"#scaling the data\nfrom sklearn import preprocessing\nX_scaled_train = preprocessing.scale(X_train)\nX_scaled_test = preprocessing.scale(X_test)\nX_scaled_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a30ae0d20d1592ae969dcab10589521421963984"},"cell_type":"code","source":"#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\n#We kept ID attribute as we observed that ID was repeated and had a pattern with labels\nknn = KNeighborsClassifier(n_neighbors=19)\nknn.fit(X_scaled_train, y_train)\ny_pred = knn.predict(X_scaled_test)\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bc87de7152a97a4bff4e80aa1170d2edb83afd8"},"cell_type":"code","source":"#SVM (SV classifier)\nfrom sklearn import metrics, svm\nfrom sklearn.svm import SVC\n\nsvm=svm.SVC()\nsvm.fit(X_scaled_train, y_train)\ny_pred = svm.predict(X_scaled_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"655b118213ce8b3a77fca25403a33f086602bd57"},"cell_type":"code","source":"#Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier \n\ndtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_scaled_train, y_train) \ny_pred = dtree_model.predict(X_scaled_test) \nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e6da5d01809d7becb3ba26c16c7a57ef542a23a"},"cell_type":"code","source":"#Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB \n\ngnb = GaussianNB().fit(X_scaled_train, y_train) \ny_pred = gnb.predict(X_scaled_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f3133df0720279c22e96e5bc44b036b326f747f"},"cell_type":"code","source":"#Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier().fit(X_scaled_train, y_train)\ny_pred = rf.predict(X_scaled_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82225cd361f8eb1caa99c6754292695957e3431c"},"cell_type":"code","source":"# Multi Layer Perceptron\nfrom sklearn.neural_network import MLPClassifier\n\nmlp=MLPClassifier(max_iter=4000, alpha=0.1).fit(X_scaled_train,y_train)\ny_pred = mlp.predict(X_scaled_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"------------------------\\n\")\nprint(classification_report(y_test, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b54722502f119365c54a362510c07454a8847a8"},"cell_type":"code","source":"#SVM SVC - 52.85% Accuracy\n# The kernel used for SVC is Radial Basis Function(RBF).\n#One property of the RBF kernel is that it is infinitely smooth\n#They are relatively easy to calibrate, as opposed to other kernels.\n#It has localized and finite response along the entire x-axis.\n\n#MLP - 50% Accuracy \n#Maximum Convergence occured at epoch value of 4000.\n#Alpha-value of 0.1 provides an optimum accuracy as we found by trial-and-error.\n\n\n#SVM model is better than MLP due to the following observations\n#1.Higher Overall Accuracy\n#2. Higher Overall Average Precison over majority of output classes\n#3. Higher Overall F1-Score over majority of Output classes.\n#Also,\n#4.Takes lesser computation power(time).\n#5.Simpler and better for a multi-class classification problem\n#The accuracy for Decision tree classifier is the highest amongst all other models.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}