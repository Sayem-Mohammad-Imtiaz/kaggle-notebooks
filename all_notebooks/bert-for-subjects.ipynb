{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport re\nimport os\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T21:12:30.153619Z","iopub.execute_input":"2021-05-26T21:12:30.153951Z","iopub.status.idle":"2021-05-26T21:12:30.159691Z","shell.execute_reply.started":"2021-05-26T21:12:30.153918Z","shell.execute_reply":"2021-05-26T21:12:30.158837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/questions-chapter-classification/train.csv')\nval=pd.read_csv('../input/questions-chapter-classification/val.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-05-26T21:12:32.593275Z","iopub.execute_input":"2021-05-26T21:12:32.593729Z","iopub.status.idle":"2021-05-26T21:12:33.302515Z","shell.execute_reply.started":"2021-05-26T21:12:32.593605Z","shell.execute_reply":"2021-05-26T21:12:33.301728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install bert-for-tf2\n!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:12:33.303969Z","iopub.execute_input":"2021-05-26T21:12:33.304308Z","iopub.status.idle":"2021-05-26T21:12:51.938753Z","shell.execute_reply.started":"2021-05-26T21:12:33.304273Z","shell.execute_reply":"2021-05-26T21:12:51.937784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nimport tensorflow_hub as hub\n\nfrom tensorflow.keras import layers\nimport bert\n\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\nimport string\nstop_words.extend(list(string.punctuation))\n\nfrom nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:12:51.940887Z","iopub.execute_input":"2021-05-26T21:12:51.941258Z","iopub.status.idle":"2021-05-26T21:12:58.396629Z","shell.execute_reply.started":"2021-05-26T21:12:51.941216Z","shell.execute_reply":"2021-05-26T21:12:58.395807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stopword_remove(sent):\n    tokens=word_tokenize(sent)\n    sentence=[token for token in tokens if token not in stop_words]\n    return ' '.join(sentence) ","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:14:11.986992Z","iopub.execute_input":"2021-05-26T21:14:11.987341Z","iopub.status.idle":"2021-05-26T21:14:11.992477Z","shell.execute_reply.started":"2021-05-26T21:14:11.987293Z","shell.execute_reply":"2021-05-26T21:14:11.991044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['eng'] = train['eng'].apply(lambda x: stopword_remove(x))\nval['eng'] = val['eng'].apply(lambda x: stopword_remove(x))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:14:12.102939Z","iopub.execute_input":"2021-05-26T21:14:12.103203Z","iopub.status.idle":"2021-05-26T21:15:42.940697Z","shell.execute_reply.started":"2021-05-26T21:14:12.103171Z","shell.execute_reply":"2021-05-26T21:15:42.939884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FullTokenizer = bert.bert_tokenization.FullTokenizer\nbert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = FullTokenizer(vocab_file, do_lower_case)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:15:42.942358Z","iopub.execute_input":"2021-05-26T21:15:42.942688Z","iopub.status.idle":"2021-05-26T21:15:49.18448Z","shell.execute_reply.started":"2021-05-26T21:15:42.942661Z","shell.execute_reply":"2021-05-26T21:15:49.18347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_sentence(eng):\n    return [\"[CLS]\"] + tokenizer.tokenize(eng) + [\"[SEP]\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:15:49.185983Z","iopub.execute_input":"2021-05-26T21:15:49.186365Z","iopub.status.idle":"2021-05-26T21:15:49.19226Z","shell.execute_reply.started":"2021-05-26T21:15:49.186312Z","shell.execute_reply":"2021-05-26T21:15:49.191387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ids(tokens):\n    return tokenizer.convert_tokens_to_ids(tokens)\n\ndef get_mask(tokens):\n    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n\ndef get_segments(tokens):\n    seg_ids = []\n    current_seg_id = 0\n    for tok in tokens:\n        seg_ids.append(current_seg_id)\n        if tok == \"[SEP]\":\n            current_seg_id = 1-current_seg_id # turns 1 into 0 and vice versa\n    return seg_ids","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:15:49.19368Z","iopub.execute_input":"2021-05-26T21:15:49.194101Z","iopub.status.idle":"2021-05-26T21:15:49.203492Z","shell.execute_reply.started":"2021-05-26T21:15:49.19405Z","shell.execute_reply":"2021-05-26T21:15:49.202518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def padding(encoded_sentence, length=512):\n    length_now = len(encoded_sentence)\n    if length_now > length:\n        ret = encoded_sentence[:511] + ['[SEP]']\n        return ret\n    pad = ['[PAD]' for i in range(length-length_now)]\n    ret = encoded_sentence + pad\n    return ret","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:15:49.206916Z","iopub.execute_input":"2021-05-26T21:15:49.20731Z","iopub.status.idle":"2021-05-26T21:15:49.216016Z","shell.execute_reply.started":"2021-05-26T21:15:49.207271Z","shell.execute_reply":"2021-05-26T21:15:49.215061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\nencoder = OneHotEncoder()\ny_train = encoder.fit_transform(train[['chapter']]).toarray()\ny_test = encoder.transform(val[['chapter']]).toarray()\n\nencoded_train = [padding(encode_sentence(eng)) for eng in train['eng']]\nencoded_test = [padding(encode_sentence(eng)) for eng in val['eng']]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:15:49.217663Z","iopub.execute_input":"2021-05-26T21:15:49.218153Z","iopub.status.idle":"2021-05-26T21:17:18.289508Z","shell.execute_reply.started":"2021-05-26T21:15:49.218112Z","shell.execute_reply":"2021-05-26T21:17:18.288512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nx_train = []\nfor el in tqdm(encoded_train, total=len(encoded_train)):\n    x_train.append(\n        tf.stack(\n            [tf.cast(get_ids(el), dtype=tf.int32),\n             tf.cast(get_mask(el), dtype=tf.int32),\n             tf.cast(get_segments(el), dtype=tf.int32)],\n            axis=0\n        )\n    )\n    \nx_test = []\nfor el in tqdm(encoded_test, total=len(encoded_test)):\n    x_test.append(\n        tf.stack(\n            [tf.cast(get_ids(el), dtype=tf.int32),\n             tf.cast(get_mask(el), dtype=tf.int32),\n             tf.cast(get_segments(el), dtype=tf.int32)],\n            axis=0\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:17:18.290849Z","iopub.execute_input":"2021-05-26T21:17:18.291187Z","iopub.status.idle":"2021-05-26T21:19:34.738143Z","shell.execute_reply.started":"2021-05-26T21:17:18.291153Z","shell.execute_reply":"2021-05-26T21:19:34.737268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = tf.stack(x_train)\nx_test = tf.stack(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:19:34.7395Z","iopub.execute_input":"2021-05-26T21:19:34.740035Z","iopub.status.idle":"2021-05-26T21:19:35.349659Z","shell.execute_reply.started":"2021-05-26T21:19:34.739993Z","shell.execute_reply":"2021-05-26T21:19:35.348738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DCNNBERTEmbedding(tf.keras.Model):\n    \n    def __init__(self,\n                 nb_filters=50,\n                 FFN_units=512,\n                 nb_classes=202,\n                 dropout_rate=0.1,\n                 name=\"dcnn\"):\n        super(DCNNBERTEmbedding, self).__init__(name=name)\n        \n        self.bert_layer = hub.KerasLayer(\n            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n            trainable=False)\n\n        self.bigram = layers.Conv1D(filters=nb_filters,\n                                    kernel_size=2,\n                                    padding=\"valid\",\n                                    activation=\"relu\")\n        self.trigram = layers.Conv1D(filters=nb_filters,\n                                     kernel_size=3,\n                                     padding=\"valid\",\n                                     activation=\"relu\")\n        self.fourgram = layers.Conv1D(filters=nb_filters,\n                                      kernel_size=4,\n                                      padding=\"valid\",\n                                      activation=\"relu\")\n        self.pool = layers.GlobalMaxPool1D()\n        \n        self.lstm = layers.LSTM(nb_filters)\n        \n        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n        self.dropout = layers.Dropout(rate=dropout_rate)\n        if nb_classes == 2:\n            self.last_dense = layers.Dense(units=1,\n                                           activation=\"sigmoid\")\n        else:\n            self.last_dense = layers.Dense(units=nb_classes,\n                                           activation=\"softmax\")\n    \n    def embed_with_bert(self, all_tokens):\n        _, embs = self.bert_layer([all_tokens[:, 0, :],\n                                   all_tokens[:, 1, :],\n                                   all_tokens[:, 2, :]])\n        return embs\n\n    def call(self, inputs, training):\n        x = self.embed_with_bert(inputs)\n    \n        x_1 = self.bigram(x)\n        x_1 = self.pool(x_1)\n        x_2 = self.trigram(x)\n        x_2 = self.pool(x_2)\n        x_3 = self.fourgram(x)\n        x_3 = self.pool(x_3)\n        x_4 = self.lstm(x)\n        \n        merged = tf.concat([x_1, x_2, x_3, x_4], axis=-1) # (batch_size, 4 * nb_filters)\n        merged = self.dense_1(merged)\n        merged = self.dropout(merged, training)\n        output = self.last_dense(merged)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:12:58.398491Z","iopub.execute_input":"2021-05-26T21:12:58.398818Z","iopub.status.idle":"2021-05-26T21:12:58.420813Z","shell.execute_reply.started":"2021-05-26T21:12:58.398783Z","shell.execute_reply":"2021-05-26T21:12:58.420117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB_FILTERS = 100\nFFN_UNITS = 256\nNB_CLASSES = 202\n\nDROPOUT_RATE = 0.2\n\nBATCH_SIZE = 32\nNB_EPOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:12:58.423794Z","iopub.execute_input":"2021-05-26T21:12:58.424115Z","iopub.status.idle":"2021-05-26T21:12:58.433954Z","shell.execute_reply.started":"2021-05-26T21:12:58.424077Z","shell.execute_reply":"2021-05-26T21:12:58.433034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n                         FFN_units=FFN_UNITS,\n                         nb_classes=NB_CLASSES,\n                         dropout_rate=DROPOUT_RATE)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:12:58.436774Z","iopub.execute_input":"2021-05-26T21:12:58.437071Z","iopub.status.idle":"2021-05-26T21:13:14.027442Z","shell.execute_reply.started":"2021-05-26T21:12:58.437044Z","shell.execute_reply":"2021-05-26T21:13:14.026667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\",\n             optimizer=\"adam\",\n             metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:19:40.820558Z","iopub.execute_input":"2021-05-26T21:19:40.820894Z","iopub.status.idle":"2021-05-26T21:19:40.837584Z","shell.execute_reply.started":"2021-05-26T21:19:40.820864Z","shell.execute_reply":"2021-05-26T21:19:40.836688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train[0:10], y_train[0:10], epochs=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:19:48.403941Z","iopub.execute_input":"2021-05-26T21:19:48.404276Z","iopub.status.idle":"2021-05-26T21:20:03.648675Z","shell.execute_reply.started":"2021-05-26T21:19:48.404245Z","shell.execute_reply":"2021-05-26T21:20:03.646678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../input/bert-model/model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:20:50.029713Z","iopub.execute_input":"2021-05-26T21:20:50.030046Z","iopub.status.idle":"2021-05-26T21:20:55.152529Z","shell.execute_reply.started":"2021-05-26T21:20:50.030013Z","shell.execute_reply":"2021-05-26T21:20:55.151687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T21:21:05.532743Z","iopub.execute_input":"2021-05-26T21:21:05.53315Z","iopub.status.idle":"2021-05-26T21:21:38.676939Z","shell.execute_reply.started":"2021-05-26T21:21:05.533116Z","shell.execute_reply":"2021-05-26T21:21:38.673121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train,\n         y_train,\n         epochs=NB_EPOCHS,\n         validation_data=(x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:14:41.900317Z","iopub.execute_input":"2021-05-26T04:14:41.900876Z","iopub.status.idle":"2021-05-26T04:15:22.835397Z","shell.execute_reply.started":"2021-05-26T04:14:41.900824Z","shell.execute_reply":"2021-05-26T04:15:22.831941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T04:16:16.473844Z","iopub.execute_input":"2021-05-26T04:16:16.47425Z","iopub.status.idle":"2021-05-26T04:16:17.430142Z","shell.execute_reply.started":"2021-05-26T04:16:16.474216Z","shell.execute_reply":"2021-05-26T04:16:17.428985Z"},"trusted":true},"execution_count":null,"outputs":[]}]}