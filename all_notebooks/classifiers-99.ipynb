{"metadata":{"language_info":{"name":"python","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"cells":[{"source":"Three methods are solving it 99%\n\n---\nKNN, decisiontree and random forest","metadata":{},"cell_type":"markdown"},{"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#forked to learn the 'input\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nfrom sklearn.neural_network import MLPClassifier\nimport h5py\nfrom scipy import sparse\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nprint(\"Modules imported!\")\nprint(\"Collecting Data...\")\nhf = h5py.File(\"../input/cdk2.h5\", \"r\")\nids = hf[\"chembl_id\"].value # the name of each molecules\nap = sparse.csr_matrix((hf[\"ap\"][\"data\"], hf[\"ap\"][\"indices\"], hf[\"ap\"][\"indptr\"]), shape=[len(hf[\"ap\"][\"indptr\"]) - 1, 2039])\nmg = sparse.csr_matrix((hf[\"mg\"][\"data\"], hf[\"mg\"][\"indices\"], hf[\"mg\"][\"indptr\"]), shape=[len(hf[\"mg\"][\"indptr\"]) - 1, 2039])\ntt = sparse.csr_matrix((hf[\"tt\"][\"data\"], hf[\"tt\"][\"indices\"], hf[\"tt\"][\"indptr\"]), shape=[len(hf[\"tt\"][\"indptr\"]) - 1, 2039])\nfeatures = sparse.hstack([ap, mg, tt]).toarray() # the samples' features, each row is a sample, and each sample has 3*2039 features\nlabels = hf[\"label\"].value # the label of each molecule\nfeatures","outputs":[],"execution_count":null,"metadata":{"_uuid":"7973f2f7b8e4995a1fb248b7453a38a603e4bb93","_cell_guid":"08891669-be53-4eed-8b54-b44b69cf93c1"},"cell_type":"code"},{"source":"labels","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"from sklearn.preprocessing import normalize\nfrom scipy.sparse import coo_matrix, csr_matrix\n\ndef cosine(plays):\n    normalized = normalize(plays)\n    return normalized.dot(normalized.T)\n\n\ndef bhattacharya(plays):\n    plays.data = np.sqrt(plays.data)\n    return cosine(plays)\n\n\ndef ochiai(plays):\n    plays = csr_matrix(plays)\n    plays.data = np.ones(len(plays.data))\n    return cosine(plays)\n\n\ndef bm25_weight(data, K1=1.2, B=0.8):\n    \"\"\" Weighs each row of the matrix data by BM25 weighting \"\"\"\n    # calculate idf per term (user)\n    N = float(data.shape[0])\n    idf = np.log(N / (1 + np.bincount(data.col)))\n\n    # calculate length_norm per document (artist)\n    row_sums = np.squeeze(np.asarray(data.sum(1)))\n    average_length = row_sums.sum() / N\n    length_norm = (1.0 - B) + B * row_sums / average_length\n\n    # weight matrix rows by bm25\n    ret = coo_matrix(data)\n    ret.data = ret.data * (K1 + 1.0) / (K1 * length_norm[ret.row] + ret.data) * idf[ret.col]\n    return ret\n\n\ndef bm25(plays):\n    plays = bm25_weight(plays)\n    return plays.dot(plays.T)\n\ndef get_largest(row, N=10):\n    if N >= row.nnz:\n        best = zip(row.data, row.indices)\n    else:\n        ind = np.argpartition(row.data, -N)[-N:]\n        best = zip(row.data[ind], row.indices[ind])\n    return sorted(best, reverse=True)\n\n\ndef calculate_similar_artists(similarity, artists, artistid):\n    neighbours = similarity[artistid]\n    top = get_largest(neighbours)\n    return [(artists[other], score, i) for i, (score, other) in enumerate(top)]\n\n\n\nsimilarity = bm25(coo_matrix(features)).todense()\n\nsimilarity","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"U, sigma, Vt = np.linalg.svd(similarity[:,:200], full_matrices=False)\nsigma = np.diag(sigma)\nprint(U.shape,sigma.shape,Vt.shape)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn import linear_model\nimport matplotlib.pyplot as plt\n\nlr = linear_model.LinearRegression()\npredicted = cross_val_predict(lr, U, labels, cv=5)\n\nfig, ax = plt.subplots()\nax.scatter(labels, predicted, edgecolors=(0, 0, 0))\nax.plot([labels.min(), labels.max()], [labels.min(), labels.max()], 'k--', lw=1)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()\n\nfrom sklearn.metrics import r2_score\nprint(r2_score(labels, predicted))","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\nfrom sklearn.preprocessing import MinMaxScaler\n\n# import some data to play with\n       # those ? converted to NAN are bothering me abit...        \n\nfrom sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nparam_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n\nX = U\ndef rmsle(y_predicted, y_real):\n    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\ndef procenterror(y_predicted, y_real):\n     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n\n    \nY=labels\n\n\nnames = [\n         'ElasticNet',\n         'SVC',\n         'kSVC',\n         'KNN',\n         'DecisionTree',\n         'RandomForestClassifier',\n         'GridSearchCV',\n         'HuberRegressor',\n         'Ridge',\n         'Lasso',\n         'LassoCV',\n         'Lars',\n         'BayesianRidge',\n         'SGDClassifier',\n         'RidgeClassifier',\n         'LogisticRegression',\n         'OrthogonalMatchingPursuit',\n         #'RANSACRegressor',\n         ]\n\nclassifiers = [\n    ElasticNetCV(cv=10, random_state=0),\n    SVC(),\n    SVC(kernel = 'rbf', random_state = 0),\n    KNeighborsClassifier(n_neighbors = 1),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators = 200),\n    GridSearchCV(SVC(),param_grid, refit = True, verbose = 1),\n    HuberRegressor(fit_intercept=True, alpha=0.0, max_iter=100,epsilon=2.95),\n    Ridge(fit_intercept=True, alpha=0.0, random_state=0, normalize=True),\n    Lasso(alpha=0.05),\n    LassoCV(),\n    Lars(n_nonzero_coefs=10),\n    BayesianRidge(),\n    SGDClassifier(),\n    RidgeClassifier(),\n    LogisticRegression(),\n    OrthogonalMatchingPursuit(),\n    #RANSACRegressor(),\n]\ncorrection= [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n\ntemp=zip(names,classifiers,correction)\nprint(temp)\n\nfor name, clf,correct in temp:\n    regr=clf.fit(X,Y)\n    #print( name,'% errors', abs(regr.predict(X)+correct-Y).sum()/(Y.sum())*100)\n    print(name,'%error',procenterror(regr.predict(X),Y),'rmsle',rmsle(regr.predict(X),Y))\n    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score, precision_score, recall_score\n\n    # Confusion Matrix\n    print(name,'Confusion Matrix')\n    print(confusion_matrix(Y, np.round(regr.predict(X) ) ) )\n    print('--'*40)\n\n    # Classification Report\n    print('Classification Report')\n    print(classification_report(Y,np.round( regr.predict(X) ) ))\n\n    # Accuracy\n    print('--'*40)\n    logreg_accuracy = round(accuracy_score(Y, np.round( regr.predict(X) ) ) * 100,2)\n    print('Accuracy', logreg_accuracy,'%')","outputs":[],"execution_count":null,"metadata":{"_uuid":"702f94f7688ff0a087781f24286b0be8127d6131","_cell_guid":"885f9443-db0f-4c5b-b8b4-601e7b469b23"},"cell_type":"code"}],"nbformat":4}