{"cells":[{"metadata":{},"cell_type":"markdown","source":"This file contains analysis done on credit history of applicants. \n[Click here to go to previous part](https://www.kaggle.com/jayantb1019/bank-credit-default-case-study-part-1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sidetable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing required Libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport sidetable\nfrom tabulate import tabulate\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The following code is carried over from Analysis of Application Data for the purpose of Merging it with Previous Application Data \n**[Skip to Merged Data Analysis](#Analysis)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#setting max number of columns to be displayed to 100, to get a better view.\npd.set_option('display.max_columns',100)\npd.set_option('display.max_rows',100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"application_data=pd.read_csv('../input/bank-loans-dataset/application_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the columns that have more than or equal to 50% null values and storing it to columns_to_drop.\ncolumns_to_drop=application_data.columns[100*application_data.isnull().sum()/len(application_data)>=50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the columns where the null values are >= 50%.\napplication_data.drop(labels=columns_to_drop,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for Disguised Missing Values\ndef cat_value_counts(column_name) : \n    print(tabulate(pd.DataFrame(application_data.stb.freq([column_name])), headers='keys', tablefmt='psql'))\n    print(pd.DataFrame(application_data[column_name]).stb.missing(),'\\n\\n\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing XAN with np.nan in Gender column : \napplication_data['CODE_GENDER'] = application_data['CODE_GENDER'].replace('XNA',np.nan)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_convert = ['DAYS_BIRTH','DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH']\napplication_data[columns_to_convert] = application_data[columns_to_convert].abs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a new column \"AGE_YEARS\" using 'DAYS_BIRTH' with age in years\ndef days_to_years(x) : \n    if x < 0 : \n        x = -1*x \n    return x//365\napplication_data['AGE_YEARS'] = application_data['DAYS_BIRTH'].apply(days_to_years)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_INCOME_TOTAL - binning continuous variables\nmin_income = int(application_data['AMT_INCOME_TOTAL'].min())\nmax_income = int(application_data['AMT_INCOME_TOTAL'].max())\n\n\nbins = [0,25000,50000,75000,100000,125000,150000,175000,200000,225000,250000,275000,300000,325000,350000,375000,400000,425000,450000,475000,500000,10000000000]\nintervals = ['0-25000', '25000-50000','50000-75000','75000-100000','100000-125000', '125000-150000', '150000-175000','175000-200000',\n       '200000-225000','225000-250000','250000-275000','275000-300000','300000-325000','325000-350000','350000-375000',\n       '375000-400000','400000-425000','425000-450000','450000-475000','475000-500000','500000 and above']\n\napplication_data['AMT_INCOME_CAT']=pd.cut(application_data['AMT_INCOME_TOTAL'],bins,labels=intervals)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_CREDIT\nbins = [0,150000,200000,250000,300000,350000,400000,450000,500000,550000,600000,650000,700000,750000,800000,850000,900000,1000000000]\nintervals = ['0-150000', '150000-200000','200000-250000', '250000-300000', '300000-350000', '350000-400000','400000-450000',\n        '450000-500000','500000-550000','550000-600000','600000-650000','650000-700000','700000-750000','750000-800000',\n        '800000-850000','850000-900000','900000 and above']\n\napplication_data['AMT_CREDIT_RANGE']=pd.cut(application_data['AMT_CREDIT'],bins=bins,labels=intervals)\napplication_data['AMT_CREDIT_RANGE'] = application_data['AMT_CREDIT_RANGE'].astype('category')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columnsForAnalysis = ['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n       'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n       'NAME_HOUSING_TYPE',\n       'DAYS_EMPLOYED','FLAG_MOBIL', 'FLAG_CONT_MOBILE',\n       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS',\n       'REGION_RATING_CLIENT_W_CITY',\n                      'REG_CITY_NOT_LIVE_CITY',\n       'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n       'ORGANIZATIOdN_TYPE', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n        'DAYS_LAST_PHONE_CHANGE' ,'AGE_YEARS', 'AMT_INCOME_CAT',\n       'AMT_CREDIT_RANGE']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Loading Previous Application Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prev_data = pd.read_csv('../input/bank-loans-dataset/previous_application.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging with Previous Application Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting columns from application Data : \napplication_data_columns = '''AMT_ANNUITY\nAMT_INCOME_TOTAL\nAMT_CREDIT\nAMT_GOODS_PRICE\nNAME_CONTRACT_TYPE\nCODE_GENDER\nNAME_INCOME_TYPE\nDAYS_EMPLOYED\nNAME_EDUCATION_TYPE\nSK_ID_CURR\nAGE_YEARS\nAMT_INCOME_CAT\nAMT_CREDIT_RANGE\n'''\napplication_data_columns = application_data_columns.splitlines()\nselected_application_data = application_data[application_data_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting columns from Previous application Data : \nprev_application_data_columns = '''AMT_ANNUITY\nAMT_APPLICATION\nAMT_CREDIT\nAMT_GOODS_PRICE\nCHANNEL_TYPE\nCODE_REJECT_REASON\nDAYS_DECISION\nNAME_CASH_LOAN_PURPOSE\nNAME_CLIENT_TYPE\nNAME_CONTRACT_STATUS\nNAME_CONTRACT_TYPE\nNAME_GOODS_CATEGORY\nNAME_PORTFOLIO\nNAME_PRODUCT_TYPE\nNAME_YIELD_GROUP\nPRODUCT_COMBINATION\nSK_ID_CURR\nSK_ID_PREV\n'''\nprev_application_data_columns = prev_application_data_columns.splitlines()\nselected_prev_data = prev_data[prev_application_data_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging data , adding suffix _prev and _curr\nmerged_data = pd.merge(left=selected_application_data,right=selected_prev_data,on='SK_ID_CURR',how='inner',suffixes=('_curr','_prev'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The Target Variable for analysis is ```NAME_CONTRACT_STATUS```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Data Quality Checks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing disguised missing values 'XAP', 'XNA'\nfor column in merged_data.columns : \n    if merged_data[column].dtype == 'object' or merged_data[column].dtype.name == 'category' : \n        merged_data[column].replace({'XAP' : np.nan, 'XNA' : np.nan}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding Percentage of Missing values in each and every column\ndef color_red(value):\n    '''\n      Colors elements in a dateframe\n      green if nulls <50% and red if\n      >=50%.\n    '''\n    if value >=50:\n        color = 'red'\n    elif value <50:\n        color = 'green'\n\n    return 'color: %s' % color\npd.set_option('precision', 4)\nmissing_data = 100*(merged_data.reset_index().isnull().sum())/merged_data.shape[0]\n\nmissing_data = pd.DataFrame(data={'Column Name' :missing_data.index, 'Null Percentage' : missing_data.values})\nmissing_data.style.applymap(color_red,subset=['Null Percentage'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns 'CODE_REJECT_REASON', 'NAME_CASH_LOAN_PURPOSE', 'NAME_GOODS_CATEGORY','NAME_PRODUCT_TYPE' have null values >=50%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping columns with high null values \nnull_info = pd.DataFrame(100*merged_data.reset_index().isnull().sum()/len(merged_data))\nnull_info.columns = ['Null Percentage']\nhigh_nulls = null_info[null_info['Null Percentage'] >= 50].index\nprint(high_nulls)\nmerged_data = merged_data.drop(columns=high_nulls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remaining columns \nmerged_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking absolute values of days of processsing \nmerged_data['DAYS_DECISION'] = merged_data['DAYS_DECISION'].abs()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Imputation Consideration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the best values to impute below columns that have <=13% of null values\n\n#Finding columns with <= 13% missing columns\n\nnull_info = pd.DataFrame(100*merged_data.isnull().sum()/len(merged_data))\nnull_info.columns = ['Null Percentage']\nnull_info[(null_info['Null Percentage'] > 0) & (null_info['Null Percentage'] <=0.13)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Columns To Impute","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We have chosen the following columns to consider the best value to impute the missing values with\n\n* AMT_CREDIT_prev\n* PRODUCT_COMBINATION   \n* NAME_CLIENT_TYPE\n* NAME_CONTRACT_TYPE_prev\n\nNote that other columns were already examined in analysis of application_data.csv","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### AMT_CREDIT_prev Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot to check for outliers\nmerged_data['AMT_CREDIT_prev'].plot.box()\nplt.title('\\n Box Plot of AMT_CREDIT_prev')\n\n# Calculating Quantiles\nprint('Quantile\\tAMT_CREDIT_prev')\nmerged_data['AMT_CREDIT_prev'].quantile([0.5,0.8,0.85,0.90,0.95,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above box plot of ```AMT_CREDIT_prev``` , there are a lot of outliers.   \nCalculating Quantiles confirms the same. There is a huge jump from 95 percetile to max value.   \nHence, **Median:80595.00** is the best value to impute the missing values.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### PRODUCT_COMBINATION Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data type of PRODUCT_COMBINATION : ',merged_data['PRODUCT_COMBINATION'].dtype,'\\n\\n')\nprint('Category\\tNormalized Count\\n\\n',merged_data['PRODUCT_COMBINATION'].value_counts(normalize=True))\ndata = merged_data['PRODUCT_COMBINATION'].value_counts(normalize=True)\nplt.bar(data.index,data.values)\n# data.hist()\nplt.xticks(rotation=90)\nplt.ylabel('Normalized Value Counts')\nplt.title('\\nPRODUCT_COMBINATION');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"```PRODUCT_COMBINATION``` is a categorical variable.   \nThe best metric to impute missing values is Mode of the data.   \nFrom the above plot, 'Cash' is the Mode  \n\nHence, **Cash** is the best value to impute the missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### NAME_CLIENT_TYPE Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#NAME_CLIENT_TYPE\nprint('Data type of NAME_CLIENT_TYPE : ',merged_data['NAME_CLIENT_TYPE'].dtype,'\\n\\n')\nprint('Category\\tNormalized Count\\n\\n',merged_data['NAME_CLIENT_TYPE'].value_counts(normalize=True))\ndata = merged_data['NAME_CLIENT_TYPE'].value_counts(normalize=True)\nplt.bar(data.index,data.values)\n# data.hist()\nplt.xticks(rotation=90)\nplt.ylabel('Normalized Value Counts')\nplt.title('\\nNAME_CLIENT_TYPE');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"```NAME_CLIENT_TYPE``` is a categorical variable.   \nThe best metric to impute missing values is Mode of the data.   \nFrom the above plot, 'Repeater' is the Mode  \n\nHence, **'Repeater'** is the best value to impute the missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### NAME_CONTRACT_TYPE_prev Imputation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data type of NAME_CONTRACT_TYPE_prev : ',merged_data['NAME_CONTRACT_TYPE_prev'].dtype,'\\n\\n')\nprint('Category\\tNormalized Count\\n\\n',merged_data['NAME_CONTRACT_TYPE_prev'].value_counts(normalize=True))\ndata = merged_data['NAME_CONTRACT_TYPE_prev'].value_counts(normalize=True)\nplt.bar(data.index,data.values)\n# data.hist()\nplt.xticks(rotation=90)\nplt.ylabel('Normalized Value Counts')\nplt.title('\\nNAME_CONTRACT_TYPE_prev');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"```NAME_CONTRACT_TYPE_prev``` is a categorical variable.   \nThe best metric to impute missing values is Mode of the data.   \nFrom the above plot, this is a bimodal distribution.It has two modes : 'Cash Loans' and 'Consumer Loans'  \n**The best value for imputation needs domain knowledge**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Splitting Datasets wrt ```NAME_CONTRACT_STATUS```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# unique categories \nmerged_data['NAME_CONTRACT_STATUS'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting into four data frames wrt to NAME_CONTRACT_STATUS\n\nmerged_a = merged_data[merged_data['NAME_CONTRACT_STATUS'] == 'Approved']\nmerged_c = merged_data[merged_data['NAME_CONTRACT_STATUS'] == 'Canceled']\nmerged_r = merged_data[merged_data['NAME_CONTRACT_STATUS'] == 'Refused']\nmerged_u = merged_data[merged_data['NAME_CONTRACT_STATUS'] == 'Unused offer']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Data Imbalance ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_name = 'NAME_CONTRACT_STATUS'\nprint(tabulate(pd.DataFrame(merged_data.stb.freq([column_name])), headers='keys', tablefmt='psql'))\nprint(pd.DataFrame(merged_data[column_name]).stb.missing(),'\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above percentages show that not all cases are equally represented and that **there is definite Data Imbalance** ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Columns Selection for Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_col_for_analysis = '''\nAMT_ANNUITY_prev\nAMT_APPLICATION\nAMT_CREDIT_prev\nAMT_GOODS_PRICE_prev\nCHANNEL_TYPE\nCODE_REJECT_REASON\nDAYS_DECISION\nNAME_CASH_LOAN_PURPOSE\nNAME_CLIENT_TYPE\nNAME_CONTRACT_TYPE_prev\nNAME_GOODS_CATEGORY\nNAME_PORTFOLIO\nNAME_PRODUCT_TYPE\nNAME_YIELD_GROUP\nPRODUCT_COMBINATION'''\nmerged_col_for_analysis = merged_col_for_analysis.splitlines()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Checking for Outliers ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Checking for outliers in the following numerical columns \n* AMT_ANNUITY_prev\n* AMT_APPLICATION\n* AMT_CREDIT_prev\n* AMT_GOODS_PRICE_prev\n* DAYS_DECISION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking absolute values of days decision\nmerged_data['DAYS_DECISION'] = merged_data['DAYS_DECISION'].abs()\nmerged_data['DAYS_DECISION'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box plots of the above numerical variables \nmerged_outlier_check_col = [\n    'AMT_ANNUITY_prev',\n'AMT_APPLICATION',\n'AMT_CREDIT_prev',\n'AMT_GOODS_PRICE_prev',\n'DAYS_DECISION'\n]\n\nfig,ax = plt.subplots(3,2)\nfig.set_figheight(15)\nfig.set_figwidth(15)\nax[0,0].set_yscale('log')\nax[0,1].set_yscale('log')\nax[1,0].set_yscale('log')\nax[1,1].set_yscale('log')\n\nax[0,0].set(ylabel ='Annuity in Log Scale')\nax[0,1].set(ylabel ='Application Amount in Log Scale')\nax[1,0].set(ylabel ='Credit Amount in Log Scale')\nax[1,1].set(ylabel ='Goods Price in Log Scale')\nax[2,0].set(ylabel ='Processing Days')\n\nmerged_data[merged_outlier_check_col[0]].plot.box(ax=ax[0,0],);\nmerged_data[merged_outlier_check_col[1]].plot.box(ax=ax[0,1]);\nmerged_data[merged_outlier_check_col[2]].plot.box(ax=ax[1,0]);\nmerged_data[merged_outlier_check_col[3]].plot.box(ax=ax[1,1]);\n\nmerged_data[merged_outlier_check_col[4]].plot.box(ax=ax[2,0]); \nax[2,1].axis('off')\nprint('Box Plots of' + ' '.join(merged_outlier_check_col) +'\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quantiles for outlier checks\npd.options.display.float_format = '{:,.2f}'.format\nfor col in merged_outlier_check_col : \n    print(col,'\\n',merged_data[col].quantile([0.5,0.8,0.85,0.90,0.95,1]),'\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Outliers in Numerical Columns \nFrom the above box plots and quantile calculations, we see that  \n```AMT_ANNUITY_prev``` , ```AMT_APPLICATION```, ```AMT_CREDIT_prev```, ```AMT_GOODS_PRICE_prev```,```DAYS_DECISION```\nhave many outliers. These outliers could be capped by the corresponding 95th percentile values. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Merged Data - Binning Continuous Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_CREDIT_prev\nmin_credit = int(merged_data['AMT_CREDIT_prev'].min())\nmax_credit = int(merged_data['AMT_CREDIT_prev'].max())\n\nbins = [0,25000,50000,75000,100000,125000,150000,175000,200000,225000,250000,275000,300000,325000,350000,375000,400000,425000,450000,475000,500000,10000000000]\nintervals = ['0-25000', '25000-50000','50000-75000','75000-100000','100000-125000', '125000-150000', '150000-175000','175000-200000',\n       '200000-225000','225000-250000','250000-275000','275000-300000','300000-325000','325000-350000','350000-375000',\n       '375000-400000','400000-425000','425000-450000','450000-475000','475000-500000','500000 and above']\n\nmerged_data['AMT_CREDIT_prev_cat']=pd.cut(merged_data['AMT_CREDIT_prev'],bins,labels=intervals)\nprint('Credit Range [Prev]\\t Count')\nprint(merged_data['AMT_CREDIT_prev_cat'].value_counts())\n\ncredit_cat = merged_data['AMT_CREDIT_prev_cat'].value_counts()\nplt.hist(credit_cat)\n# (merged_data['AMT_CREDIT_prev_cat'].dropna()).plot.hist()\n\nplt.title('\\n Previous Credit Amount vs No of Applications')\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_APPLICATION\nmin_app_amt = int(merged_data['AMT_APPLICATION'].min())\nmax_app_amt = int(merged_data['AMT_APPLICATION'].max())\n\n\nbins = [0,25000,50000,75000,100000,125000,150000,175000,200000,225000,250000,275000,300000,325000,350000,375000,400000,425000,450000,475000,500000,10000000000]\nintervals = ['0-25000', '25000-50000','50000-75000','75000-100000','100000-125000', '125000-150000', '150000-175000','175000-200000',\n       '200000-225000','225000-250000','250000-275000','275000-300000','300000-325000','325000-350000','350000-375000',\n       '375000-400000','400000-425000','425000-450000','450000-475000','475000-500000','500000 and above']\n\nmerged_data['AMT_APPLICATION_cat']=pd.cut(merged_data['AMT_APPLICATION'],bins,labels=intervals)\nprint('AMT_APPLICATION [Prev]\\t Count')\nprint(merged_data['AMT_APPLICATION_cat'].value_counts())\n\ncredit_cat = merged_data['AMT_APPLICATION_cat'].value_counts()\nplt.hist(merged_data['AMT_APPLICATION_cat'].dropna())\n\nplt.title('\\n Application Amount vs No of Applications')\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merged Data : Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Merged Data : Univariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for categorical variable univariate analysis\n\ndef merged_cat_univariate_analysis(column_name,figsize=(10,5)) : \n    # print unique values\n    print('Approved\\n', merged_a[column_name].unique(),'\\n')\n    print('Canceled\\n',merged_c[column_name].unique(),'\\n')\n    print('Refused\\n',merged_r[column_name].unique(),'\\n')\n    print('Unused offer\\n',merged_u[column_name].unique(),'\\n')\n    \n    # column vs target count plot\n    plt.figure(figsize=figsize)\n    ax = sns.countplot(x=column_name,hue='NAME_CONTRACT_STATUS',data=merged_data)\n    title = column_name + ' vs Number of Applications'\n    ax.set(title= title)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2,\n                height + 10,\n                format(height),\n                ha=\"center\")\n    # Percentages \n    print('Approved\\n', merged_a[column_name].unique(),'\\n')\n    print(tabulate(pd.DataFrame(merged_a.stb.freq([column_name])), headers='keys', tablefmt='psql'),'\\n')\n    print('Canceled\\n',merged_c[column_name].unique(),'\\n')\n    print(tabulate(pd.DataFrame(merged_c.stb.freq([column_name])), headers='keys', tablefmt='psql'),'\\n')\n    print('Refused\\n',merged_r[column_name].unique(),'\\n')\n    print(tabulate(pd.DataFrame(merged_r.stb.freq([column_name])), headers='keys', tablefmt='psql'),'\\n')\n    print('Unused offer\\n',merged_u[column_name].unique(),'\\n')\n    print(tabulate(pd.DataFrame(merged_u.stb.freq([column_name])), headers='keys', tablefmt='psql'),'\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for numerical variable univariate analysis\n\ndef merged_num_univariate_analysis(column_name,scale='linear') : \n    # boxplot for column vs target\n    plt.figure(figsize=(8,6))\n    ax = sns.boxplot(x='NAME_CONTRACT_STATUS', y = column_name, data = merged_data)\n    title = column_name+' vs NAME_CONTRACT_STATUS'\n    ax.set(title=title)\n    if scale == 'log' :\n        plt.yscale('log')\n        ax.set(ylabel=column_name + '(Log Scale)')\n    # summary statistic\n    print('Approved\\n', merged_a[column_name].describe(),'\\n')\n    print('Canceled\\n',merged_c[column_name].describe(),'\\n')\n    print('Refused\\n',merged_r[column_name].describe(),'\\n')\n    print('Unused offer\\n',merged_u[column_name].describe(),'\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to calculate the proportion of applications in a category compared to total applications\ndef merged_cat_proportions(column_name) : \n    values = merged_data[column_name].unique()\n    values=values.dropna()\n    values = values.to_numpy()\n    values.tolist()\n    data_a = merged_a[column_name].value_counts().to_dict()\n    data_c = merged_c[column_name].value_counts().to_dict()\n    data_r = merged_r[column_name].value_counts().to_dict()\n    data_u = merged_u[column_name].value_counts().to_dict()\n    data = merged_data[column_name].value_counts().to_dict()\n\n    for i in values : \n        if data_a[i] != np.nan and data_c[i] != np.nan and data_r[i] != np.nan and data_u[i] != np.nan and data[i] != np.nan:\n            print('Proportion of '+ str(i) + ' Approved : ', round(data_a[i]*100/data[i],2),'\\n')\n            print('Proportion of '+ str(i) + ' Cancelled : ', round(data_c[i]*100/data[i],2),'\\n')\n            print('Proportion of '+ str(i) + ' Refused : ', round(data_r[i]*100/data[i],2),'\\n')\n            print('Proportion of '+ str(i) + ' Unused Offer : ', round(data_u[i]*100/data[i],2),'\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_ANNUITY_prev\nmerged_num_univariate_analysis('AMT_ANNUITY_prev',scale='log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Amount Annuity Previous\n* Since all the above categories in the plot are having outliers, we will look at the median to make the inferences.\n* Median of \"Approved\" category is 10,286.39. Approved and Unused offer are having similar patterns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_APPLICATION\nmerged_num_univariate_analysis('AMT_APPLICATION',scale='log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Amount In Previous Application\n* Since all the above categories in plot have outliers, we will infer using median.\n* The median of \"Approved\" category is 90,000. Anything above that has high risk of refusal.\n* Looking at \"Canceled\" category, all ranges of amounts faced calcellation.\n* Most of the \"Unused offer\" category is below the median value of \"Approved category\".\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_CREDIT_prev\nmerged_num_univariate_analysis('AMT_CREDIT_prev',scale='log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Final Credit Amount\n* Since all the above categories in plot have outliers, we will infer using median.\n* The median of \"Approved\" category is  101,153.25. Anything above that has high risk of refusal.\n* Amount below 101,153.25 are more likely to get approved.\n* Looking at \"Canceled\" category, all ranges of amounts faced calcellation.\n* Most of the \"Unused offer\" category is below the median value of \"Approved category\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_GOODS_PRICE_prev\nmerged_num_univariate_analysis('AMT_GOODS_PRICE_prev',scale='log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Goods Price\n* since all the categories have outliers, we will consider median to infer.\n* Median of \"Approved\" Category is 95,208.48. Any amount above this have high risk of getting refused or being calcelled.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#CHANNEL_TYPE\nmerged_cat_univariate_analysis('CHANNEL_TYPE',figsize=(20,6))\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Channel Type\n* Credit and cash offices are playing a vital role in pipe-lining the loan applications. \n* Country_wide has highest rate of Loan Approvals.\n* 75% of Loans are getting approved in (Country_wide + Credit and cash offices + Stone).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#DAYS_DECISION\nmerged_num_univariate_analysis('DAYS_DECISION')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Days From Previous Application Decision Relative To Current Application\n* Since \"Approved\" category doesnt have outliers, we will use mean to infer.\n* Mean of \"Approved\" category is 1,098.43. Any applicant with number of days below 1,098.43 is less likely to get Approved.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#NAME_CLIENT_TYPE\nmerged_cat_univariate_analysis('NAME_CLIENT_TYPE')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Client Type (New/Refreshed/Repeater)\n* From the above plot, most of the applications belong to \"Repeater\" Category.\n* 54% of Applications from \"Repeater\" category are approved.\n* 93% of Applications from \"New\" category are approved.\n* 72% of Applications from \"Refreshed\" category are approved.\n\n**Overall, applications from \"New\" category are more likely to get approved.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#NAME_CONTRACT_TYPE_prev\nmerged_cat_univariate_analysis('NAME_CONTRACT_TYPE_prev')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Previous Contract Type\n* Majority of Contract Type if \"Cash loans\".\n* 86% of Consumer loans are more likely to get Approved.\n* 42% of Cash loans are more likely to get Approved.\n* 51% of Revolving loans are more likely to get Approved.\n\n** Approval rate is very high in Consumer loans**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#NAME_PORTFOLIO\nmerged_cat_univariate_analysis('NAME_PORTFOLIO')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Name Portfolio\n* Majority of the loans come under \"POS\" category.\n* Percentage of loans approved in each category POS>CASH>CARDS>CARS -- 91%>68%>67%>63%.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#NAME_YIELD_GROUP\nmerged_cat_univariate_analysis('NAME_YIELD_GROUP')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Grouped Interest Rate\n* Major applicants come under \"middle\" Catrgory.\n* Approval percentage of \"low_normal\" and \"low_action\" is similar (77%).\n* Loarge number of loans are approved in \"middle\" category (85%).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_ANNUITY_prev vs AMT_INCOME_CAT vs NAME_CONTRACT_STATUS\nplt.figure(figsize=[20,12])\nplt.title('Annuity Amount vs Income Category vs Loan Application Results')\nsns.barplot(x='AMT_ANNUITY_prev', y = 'AMT_INCOME_CAT', hue='NAME_CONTRACT_STATUS', data=merged_data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Amount of Annuity & Income Category\n* Loans with higher annuity are approved for clients with higher income. \n* Loan refusals follow the opposite trend\n* 450000 - 475000 has higher rate of cancellations compared to the adjacent income ranges. \n\n**Further analysis of income range 450000 - 475000 might bring the bank high income low risk loans (with possible high annuities)**  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_CREDIT_prev - AMT_APPLICATION vs NAME_YIELD_GROUP vs NAME_CONTRACT_STATUS\n\nmerged_data['AMT_DIFF'] = merged_data['AMT_CREDIT_prev'] - merged_data['AMT_APPLICATION']\nplt.figure(figsize=[8,8])\nplt.title('Difference between Approved Loan and Applied Loan vs Interest Rate Category vs Loan Application Results')\nsns.barplot(y='NAME_YIELD_GROUP', x = 'AMT_DIFF', hue='NAME_CONTRACT_STATUS', data=merged_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Difference between Approved Loan and Applied Loan & Interest Rate Category\n* It can be seen that a huge proportion of low interest category loans are being refused by the bank\n* And only high interest rate loans are unused by the clients. \n* Among all interest categories, only 'low_normal' has higher refusals compared to client cancellations. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# DAYS_DECISION vs NAME_CONTRACT_TYPE vs NAME_CONTRACT_STATUS\nplt.figure(figsize=[8,8])\nplt.title('Processing Time vs Client Type vs Loan Application Results')\nsns.barplot(y='NAME_CONTRACT_TYPE_prev', x = 'DAYS_DECISION', hue='NAME_CONTRACT_STATUS', data=merged_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Processing Time & Loan Type \n* Consumer Loans have the longest decision period followed by cash loans followed by Revolving Loans , which makes business sense. \n* A huge proportion of consumer loans are being cancelled by the client because of relatively high processing time. \n* Cash loans that take longer to process are more unused than other loans. \n\n**The bank should expedite the process of approving cash loans and Consumer Loans** ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# NAME_PORTFOLIO vs NAME_YIELD_GROUP vs NAME_CONTRACT_STATUS\n#merged_data.groupby(['NAME_PORTFOLIO','NAME_YIELD_GROUP'])['NAME_CONTRACT_STATUS'].value_counts(normalize=True).plot.bar()\nmerged_data.groupby(['NAME_PORTFOLIO','NAME_YIELD_GROUP'])['NAME_CONTRACT_STATUS'].value_counts(normalize=True)\\\n.unstack()\\\n   .plot( \n    layout=(2,2),\n    figsize=(8,6), kind='barh', stacked=True);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Portfolio & Interest Rate \n* From the above plot, we can see that POS loans are approved irrespective of interest rate. That is POS loans are popular among clients irrespective of interest rate. \n* Car loans at medium interest rate are mostly refused by the bank\n* Highest cancellation rates are found in car loans offered at low interest rates. \n\nThis could be further correlated with the difference in approved amount and applied amount to gather useful insights\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#AMT_CREDIT_prev & DAYS_EMPLOYED vs NAME_CONTRACT_STATUS\n\nplt.figure(figsize=[10,8])\nplt.xticks(rotation=45)\nsns.barplot(y='DAYS_EMPLOYED', x = 'NAME_EDUCATION_TYPE', hue='NAME_CONTRACT_STATUS', data=merged_data)\n\nplt.yscale('log')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Education & Days Employed\n* There are very low unused offers among clients with an Academic degree and recent employment ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### NAME_EDUCATION_TYPE vs NAME_CLIENT_TYPE vs NAME_CONTRACT_STATUS\nmerged_data.groupby(['NAME_EDUCATION_TYPE','NAME_CLIENT_TYPE'])['NAME_CONTRACT_STATUS'].value_counts(normalize=True)\\\n.unstack()\\\n   .plot( \n    layout=(2,2),\n    figsize=(8,6), kind='barh', stacked=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Education & Client Type \n* New customers with Lower Secondary education are the most approved borrowers and they almost always take the loan offer. \n* New customers with Academic degree come a close second in approval rate. \n* Among repeat customers, Academic Degree holding customers have the highest approval rate.\n* 'Refreshed' customers have a uniform approval rate across all education types. \n* Refereshed customers with Incomplete higher education have the maximum unused offers\n* Repeat customers have a uniform cancellation rate that's higher than New and Refreshed customers\n\n**Bank should look into the reasons why Repeat customers who are cancelling their offers. It could also focus on loans catered to academic degree holders who are first time customers** ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#CODE_GENDER vs CHANNEL_TYPE vs NAME_CONTRACT_STATUS\n\nmerged_data.groupby(['NAME_INCOME_TYPE','CODE_GENDER'])['NAME_CONTRACT_STATUS'].value_counts(normalize=True)\\\n.unstack()\\\n   .plot( \n    layout=(2,2),\n    figsize=(8,6), kind='barh', stacked=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gender & Channel Type \n* There is a mark difference in loan approval rates of Male and Female students. \n* Also, unemployed Females have a much lower rejection rate than Unemployed males. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation Analysis ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation(dataframe) : \n    cor0=dataframe.corr()\n    type(cor0)\n    cor0.where(np.triu(np.ones(cor0.shape),k=1).astype(np.bool))\n    cor0=cor0.unstack().reset_index()\n    cor0.columns=['VAR1','VAR2','CORR']\n    cor0.dropna(subset=['CORR'], inplace=True)\n    cor0.CORR=round(cor0['CORR'],2)\n    cor0.CORR=cor0.CORR.abs()\n    cor0.sort_values(by=['CORR'],ascending=False)\n    cor0=cor0[~(cor0['VAR1']==cor0['VAR2'])]\n    return pd.DataFrame(cor0.sort_values(by=['CORR'],ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation for 'Approved' Loans ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation for Approved\n# Absolute values are reported \npd.set_option('precision', 2)\ncor_0 = correlation(merged_a)\ncor_0.style.background_gradient(cmap='GnBu').hide_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation for 'Cancelled' Loans","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation for Cancelled\n# Absolute values are reported \npd.set_option('precision', 2)\ncor_0 = correlation(merged_c)\ncor_0.style.background_gradient(cmap='GnBu').hide_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation for 'Refused' Loans","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation for Refused\n# Absolute values are reported \npd.set_option('precision', 2)\ncor_0 = correlation(merged_r)\ncor_0.style.background_gradient(cmap='GnBu').hide_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Correlation for 'Unused' Loans","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation for Unused Loans\n# Absolute values are reported \npd.set_option('precision', 2)\ncor_0 = correlation(merged_u)\ncor_0.style.background_gradient(cmap='GnBu').hide_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}