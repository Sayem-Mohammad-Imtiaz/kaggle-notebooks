{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T14:35:07.805786Z","iopub.execute_input":"2021-06-28T14:35:07.806209Z","iopub.status.idle":"2021-06-28T14:35:07.822379Z","shell.execute_reply.started":"2021-06-28T14:35:07.80613Z","shell.execute_reply":"2021-06-28T14:35:07.82152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import axes3d\n\ndf_full = pd.read_csv(\"/kaggle/input/hipparcos-star-catalog/hipparcos-voidmain.csv\")\nprint(df_full.columns)\ndf = df_full[df_full[\"Plx\"]>0]\nPAR = np.array(df[\"Plx\"],dtype=float)\n# note there are columns in the database that already have RA and DEC in degrees\nRA = np.array(df[\"RAdeg\"],dtype=float)\nDEC = np.array(df[\"DEdeg\"],dtype=float)\nm = np.array(df[\"Vmag\"],dtype=float)\nbmv = np.array(df[\"B-V\"],dtype=float)\nRA *= np.pi/180 #convert to radians\nDEC *= np.pi/180\n","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:15.190574Z","iopub.execute_input":"2021-06-28T14:48:15.191506Z","iopub.status.idle":"2021-06-28T14:48:16.511475Z","shell.execute_reply.started":"2021-06-28T14:48:15.191445Z","shell.execute_reply":"2021-06-28T14:48:16.510352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"get cartesian corrdinates from parallax, RA, and DEC","metadata":{}},{"cell_type":"code","source":"# Anaconda code \nDistance = 1/PAR*1000   #the 1000 is because parallax in database is in milli arcseconds\n\nPhi = (np.pi/2-DEC)\nTheta = RA\n\nx = Distance*np.cos(Theta)*np.sin(Phi)\ny = Distance*np.sin(Theta)*np.sin(Phi)\nz = Distance*np.cos(Phi)\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(x,y,z,'.')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:18.134559Z","iopub.execute_input":"2021-06-28T14:48:18.13494Z","iopub.status.idle":"2021-06-28T14:48:20.47754Z","shell.execute_reply.started":"2021-06-28T14:48:18.134902Z","shell.execute_reply":"2021-06-28T14:48:20.476528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get x y and z into a single array for processing\nxyz = np.transpose(np.array([x,y,z]))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:24.256576Z","iopub.execute_input":"2021-06-28T14:48:24.257162Z","iopub.status.idle":"2021-06-28T14:48:24.265271Z","shell.execute_reply.started":"2021-06-28T14:48:24.257099Z","shell.execute_reply":"2021-06-28T14:48:24.26449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DBSCN clustering algorithm \n\nfrom sklearn.cluster import DBSCAN\ndb=DBSCAN(eps=2,min_samples=4,metric='euclidean')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:24.88813Z","iopub.execute_input":"2021-06-28T14:48:24.888497Z","iopub.status.idle":"2021-06-28T14:48:24.893685Z","shell.execute_reply.started":"2021-06-28T14:48:24.888463Z","shell.execute_reply":"2021-06-28T14:48:24.892498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=db.fit(xyz)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:25.81969Z","iopub.execute_input":"2021-06-28T14:48:25.820073Z","iopub.status.idle":"2021-06-28T14:48:26.675028Z","shell.execute_reply.started":"2021-06-28T14:48:25.82004Z","shell.execute_reply":"2021-06-28T14:48:26.6741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label=model.labels_","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:28.382093Z","iopub.execute_input":"2021-06-28T14:48:28.382466Z","iopub.status.idle":"2021-06-28T14:48:28.386643Z","shell.execute_reply.started":"2021-06-28T14:48:28.382433Z","shell.execute_reply":"2021-06-28T14:48:28.385457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\"RA\":RA,\"DEC\":DEC,\"label\":label,\"bmv\":bmv})\nfiltered = df[df[\"label\"]>-1]\nimport plotly.express as px\nfig = px.scatter(filtered,x=\"RA\",y=\"DEC\",color=\"bmv\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:48:46.512885Z","iopub.execute_input":"2021-06-28T14:48:46.513289Z","iopub.status.idle":"2021-06-28T14:48:46.606091Z","shell.execute_reply.started":"2021-06-28T14:48:46.513253Z","shell.execute_reply":"2021-06-28T14:48:46.605013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport plotly.express as px\nfig = px.scatter(df,x=\"RA\",y=\"DEC\",color=\"label\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:42:01.007962Z","iopub.execute_input":"2021-06-28T14:42:01.008403Z","iopub.status.idle":"2021-06-28T14:42:01.965043Z","shell.execute_reply.started":"2021-06-28T14:42:01.008367Z","shell.execute_reply":"2021-06-28T14:42:01.960523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\n#identifying the points which makes up our core points\nsample_cores=np.zeros_like(label,dtype=bool)\n\nsample_cores[db.core_sample_indices_]=True\n\n#Calculating the number of clusters\n\nn_clusters=len(set(label))- (1 if -1 in label else 0)\nprint('No of clusters:',n_clusters)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:35:22.950242Z","iopub.execute_input":"2021-06-28T14:35:22.950614Z","iopub.status.idle":"2021-06-28T14:35:22.993858Z","shell.execute_reply.started":"2021-06-28T14:35:22.95058Z","shell.execute_reply":"2021-06-28T14:35:22.992839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_means = db.fit_predict(x)\nplt.figure(figsize=(7,5))\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 50, c = 'pink')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 50, c = 'yellow')\nplt.scatter(x[y_means == 2, 0], x[y_means == 2, 1], s = 50, c = 'cyan')\nplt.scatter(x[y_means == 3, 0], x[y_means == 3, 1], s = 50, c = 'magenta')\nplt.scatter(x[y_means == 4, 0], x[y_means == 4, 1], s = 50, c = 'orange')\nplt.scatter(x[y_means == 5, 0], x[y_means == 5, 1], s = 50, c = 'blue')\nplt.scatter(x[y_means == 6, 0], x[y_means == 6, 1], s = 50, c = 'red')\nplt.scatter(x[y_means == 7, 0], x[y_means == 7, 1], s = 50, c = 'black')\nplt.scatter(x[y_means == 8, 0], x[y_means == 8, 1], s = 50, c = 'violet')\nplt.xlabel('Annual Income in (1k)')\nplt.ylabel('Spending Score from 1-100')\nplt.title('Clusters of Data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:35:22.995163Z","iopub.execute_input":"2021-06-28T14:35:22.995468Z","iopub.status.idle":"2021-06-28T14:35:23.07739Z","shell.execute_reply.started":"2021-06-28T14:35:22.995434Z","shell.execute_reply":"2021-06-28T14:35:23.075449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hierarchial Clustering","metadata":{}},{"cell_type":"code","source":"import scipy.cluster.hierarchy as sch\n\ndendrogram = sch.dendrogram(sch.linkage(x, method = 'ward'))\nplt.title('Dendrogam', fontsize = 20)\nplt.xlabel('Foo')\nplt.ylabel('Foo')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:35:23.078353Z","iopub.status.idle":"2021-06-28T14:35:23.078795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\n\nhc = AgglomerativeClustering(n_clusters = 9, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(x)\n\nplt.scatter(x[y_hc == 0, 0], x[y_hc == 0, 1], s = 50, c = 'pink')\nplt.scatter(x[y_hc == 1, 0], x[y_hc == 1, 1], s = 50, c = 'yellow')\nplt.scatter(x[y_hc == 2, 0], x[y_hc == 2, 1], s = 50, c = 'cyan')\nplt.scatter(x[y_hc == 3, 0], x[y_hc == 3, 1], s = 50, c = 'magenta')\nplt.scatter(x[y_hc == 4, 0], x[y_hc == 4, 1], s = 50, c = 'orange')\nplt.scatter(x[y_hc == 5, 0], x[y_hc == 5, 1], s = 50, c = 'blue')\nplt.scatter(x[y_hc == 6, 0], x[y_hc == 6, 1], s = 50, c = 'red')\nplt.scatter(x[y_hc == 7, 0], x[y_hc == 7, 1], s = 50, c = 'black')\nplt.scatter(x[y_hc == 8, 0], x[y_hc == 8, 1], s = 50, c = 'violet')\n\n\nplt.title('Hierarchial Clustering', fontsize = 20)\nplt.xlabel('Foo')\nplt.ylabel('Foo')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:35:23.079893Z","iopub.status.idle":"2021-06-28T14:35:23.080359Z"},"trusted":true},"execution_count":null,"outputs":[]}]}