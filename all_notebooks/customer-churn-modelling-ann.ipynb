{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Customer Churn Prediction - ANN\nbased on the some independent variables we can predict with Artificial Neural NEtwork that which customer will leave the bank and which will stay","metadata":{}},{"cell_type":"markdown","source":"# 0. Importing Library","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n%config Completer.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-06T11:05:45.004092Z","iopub.execute_input":"2021-07-06T11:05:45.00449Z","iopub.status.idle":"2021-07-06T11:05:50.632964Z","shell.execute_reply.started":"2021-07-06T11:05:45.004397Z","shell.execute_reply":"2021-07-06T11:05:50.632205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:50.634377Z","iopub.execute_input":"2021-07-06T11:05:50.634913Z","iopub.status.idle":"2021-07-06T11:05:50.64311Z","shell.execute_reply.started":"2021-07-06T11:05:50.634872Z","shell.execute_reply":"2021-07-06T11:05:50.641656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Import DataSet","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv(\"../input/churn-predictions-personal/Churn_Predictions.csv\")\nx = dataset.iloc[:,3:-1].values\ny = dataset.iloc[:,-1].values","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:50.647785Z","iopub.execute_input":"2021-07-06T11:05:50.648104Z","iopub.status.idle":"2021-07-06T11:05:50.702073Z","shell.execute_reply.started":"2021-07-06T11:05:50.648075Z","shell.execute_reply":"2021-07-06T11:05:50.701168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x)\nprint(\"\\n\\n-------------------------------------------------------------------------\\n\\n\")\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:50.703419Z","iopub.execute_input":"2021-07-06T11:05:50.703664Z","iopub.status.idle":"2021-07-06T11:05:50.710516Z","shell.execute_reply.started":"2021-07-06T11:05:50.70364Z","shell.execute_reply":"2021-07-06T11:05:50.70942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Encoding Gender Column with 'Label Encoding'","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx[:,2] = le.fit_transform(x[:,2])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:50.713092Z","iopub.execute_input":"2021-07-06T11:05:50.713398Z","iopub.status.idle":"2021-07-06T11:05:51.270903Z","shell.execute_reply.started":"2021-07-06T11:05:50.713346Z","shell.execute_reply":"2021-07-06T11:05:51.26997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.272108Z","iopub.execute_input":"2021-07-06T11:05:51.272372Z","iopub.status.idle":"2021-07-06T11:05:51.276799Z","shell.execute_reply.started":"2021-07-06T11:05:51.272333Z","shell.execute_reply":"2021-07-06T11:05:51.275821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 ONE-HOT Encoding for Geography column","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder = \"passthrough\")\nx = np.array(ct.fit_transform(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.278292Z","iopub.execute_input":"2021-07-06T11:05:51.27874Z","iopub.status.idle":"2021-07-06T11:05:51.307346Z","shell.execute_reply.started":"2021-07-06T11:05:51.278699Z","shell.execute_reply":"2021-07-06T11:05:51.306638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.309033Z","iopub.execute_input":"2021-07-06T11:05:51.309514Z","iopub.status.idle":"2021-07-06T11:05:51.314105Z","shell.execute_reply.started":"2021-07-06T11:05:51.309466Z","shell.execute_reply":"2021-07-06T11:05:51.313206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4 Split dataset into training and testing set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train , y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.315516Z","iopub.execute_input":"2021-07-06T11:05:51.315801Z","iopub.status.idle":"2021-07-06T11:05:51.389546Z","shell.execute_reply.started":"2021-07-06T11:05:51.315775Z","shell.execute_reply":"2021-07-06T11:05:51.388552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.5 Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform (x_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.390755Z","iopub.execute_input":"2021-07-06T11:05:51.391036Z","iopub.status.idle":"2021-07-06T11:05:51.412216Z","shell.execute_reply.started":"2021-07-06T11:05:51.391007Z","shell.execute_reply":"2021-07-06T11:05:51.411223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Building The ANN","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Initializing The ANN","metadata":{}},{"cell_type":"code","source":"#create variable for ann\nann = tf.keras.models.Sequential()    #initialises the ann","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.413424Z","iopub.execute_input":"2021-07-06T11:05:51.413719Z","iopub.status.idle":"2021-07-06T11:05:51.448035Z","shell.execute_reply.started":"2021-07-06T11:05:51.41369Z","shell.execute_reply":"2021-07-06T11:05:51.447341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Add input layer and first hidden layer","metadata":{}},{"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units=6, activation='relu'))  #this add method is use to add any layer","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.448946Z","iopub.execute_input":"2021-07-06T11:05:51.449293Z","iopub.status.idle":"2021-07-06T11:05:51.456553Z","shell.execute_reply.started":"2021-07-06T11:05:51.449265Z","shell.execute_reply":"2021-07-06T11:05:51.455786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Add second Hidden Layer","metadata":{}},{"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units=6, activation='relu'))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:05:51.457962Z","iopub.execute_input":"2021-07-06T11:05:51.458438Z","iopub.status.idle":"2021-07-06T11:05:51.470575Z","shell.execute_reply.started":"2021-07-06T11:05:51.458397Z","shell.execute_reply":"2021-07-06T11:05:51.469386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.4 Add Output Layer","metadata":{}},{"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units=1, activation ='sigmoid'))     #one neuron as output(we have only one dependent variable)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:23:53.470494Z","iopub.execute_input":"2021-07-06T11:23:53.471195Z","iopub.status.idle":"2021-07-06T11:23:53.486841Z","shell.execute_reply.started":"2021-07-06T11:23:53.471142Z","shell.execute_reply":"2021-07-06T11:23:53.485683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 Training the ANN","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Compiling the ANN","metadata":{}},{"cell_type":"code","source":"#Compiling the ann\nann.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:39:37.295098Z","iopub.execute_input":"2021-07-06T11:39:37.295434Z","iopub.status.idle":"2021-07-06T11:39:37.334153Z","shell.execute_reply.started":"2021-07-06T11:39:37.295404Z","shell.execute_reply":"2021-07-06T11:39:37.333258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Training the ANN with Training set\nas always `fit` is use to train the model","metadata":{}},{"cell_type":"code","source":"ann.fit(x_train, y_train, batch_size=32, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:42:34.383762Z","iopub.execute_input":"2021-07-06T11:42:34.384104Z","iopub.status.idle":"2021-07-06T11:42:58.582842Z","shell.execute_reply.started":"2021-07-06T11:42:34.384073Z","shell.execute_reply":"2021-07-06T11:42:58.582113Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 Make the predictions\n\n\" ENter the Values in double 2D Square Brackets and then apply `transform` funtion\"\n\n\nGeography: France(1,0,0)\n\nCredit Score: 600\n\nGender: Male\n\nAge: 40\n\nTenure: 3 Years\n\nbalanace : $ 60000\n\nNo of Products: 2\n\nCredit Card: Yes\n\nActive Member: Yes\n\nEstimated Salary : $ 50000\n","metadata":{}},{"cell_type":"code","source":"pred = ann.predict(sc.transform([[1,0,0, 600,1,40,3,60000,2,1,1,50000]]))\n\nprint(pred>0.5)    #if predicted probability is greater than 0.5 then only print Yes Else No","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:54:33.180798Z","iopub.execute_input":"2021-07-06T11:54:33.181111Z","iopub.status.idle":"2021-07-06T11:54:33.222819Z","shell.execute_reply.started":"2021-07-06T11:54:33.181084Z","shell.execute_reply":"2021-07-06T11:54:33.222036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. False: Customer will not leave the bank\n2. True: Customer Will LEave the bank","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Predicting the Test set Results\n","metadata":{}},{"cell_type":"code","source":"y_pred = ann.predict(x_test)\ny_pred = (y_pred>0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test),1)),1))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:58:25.686019Z","iopub.execute_input":"2021-07-06T11:58:25.686539Z","iopub.status.idle":"2021-07-06T11:58:25.764631Z","shell.execute_reply.started":"2021-07-06T11:58:25.686503Z","shell.execute_reply":"2021-07-06T11:58:25.763938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Making th Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T12:00:04.932043Z","iopub.execute_input":"2021-07-06T12:00:04.932396Z","iopub.status.idle":"2021-07-06T12:00:04.947927Z","shell.execute_reply.started":"2021-07-06T12:00:04.932363Z","shell.execute_reply":"2021-07-06T12:00:04.946792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. 86/100 predicted correctly \n2. 1535 correct prediction that stays bank\n3. 214 correct prediction that customer leave the bank\n4. 60 incorrect prediction that customer leave\n5. 191 incorrect pred that customer stays the bank","metadata":{}},{"cell_type":"markdown","source":"## THank You!\nEnd!","metadata":{}}]}