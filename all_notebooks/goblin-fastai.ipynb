{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://media2.giphy.com/media/BHNVC6suWIKs/200w.webp?cid=ecf05e47wb2oak6u4jxxfy4gogfjmcklykpg2ra9bo536zgw&rid=200w.webp)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Code from Paul Mooney https://www.kaggle.com/paultimothymooney/fastai-v2-with-image-text-and-tabular-data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import *\nfrom fastai import *\n\nimport time\nfrom datetime import datetime\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}')\nprint('Using fastai version ',fastai.__version__)\nprint('And torch version ',torch.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_fastai_results(learn):\n    '''\n    Plots sensitivity, speficificty, prevalence, accuracy, and confusion matrix for a fastai model named \"learn\".\n    Some portions are adapted from https://github.com/fastai/fastai/blob/master/nbs/61_tutorial.medical_imaging.ipynb\n    '''\n    interp = Interpretation.from_learner(learn)\n    interp = ClassificationInterpretation.from_learner(learn)\n    interp.plot_confusion_matrix(figsize=(7,7))\n    losses,idxs = interp.top_losses()\n    len(dls.valid_ds)==len(losses)==len(idxs)\n    upp, low = interp.confusion_matrix()\n    tn, fp = upp[0], upp[1]\n    fn, tp = low[0], low[1]\n    sensitivity = tp/(tp + fn)\n    print('Sensitivity: ',sensitivity)\n    specificity = tn/(fp + tn)\n    print('Specificity: ',specificity)\n    #val = dls.valid_ds.cat\n    prevalance = 15/50\n    print('Prevalance: ',prevalance)\n    accuracy = (sensitivity * prevalance) + (specificity * (1 - prevalance))\n    print('Accuracy: ',accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = aug_transforms(max_rotate=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tfms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#get_transforms Now is aug_transforms.  But I am still looking for an open_image replacement so that I can open a Single image."},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\nimage = Image.open(\"../input/goblin-portraits/images/0078f2ae5ef488769386.jpg\")\nimage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes by Naim Mhedhbi https://www.kaggle.com/naim99/data-augmentation-techniques"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loader_transform = transforms.Resize((140, 140))\n\nimshow('../input/goblin-portraits/images/0078f2ae5ef488769386.jpg', loader_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Rotated Image')\n#rotating the image by 45 degrees\nrotated = rotate(image, angle=45, mode = 'wrap')\n#plot the rotated image\nio.imshow(rotated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#flip image up-to-down\nflipUD = np.flipud(image)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('../input/goblin-portraits/images/0078f2ae5ef488769386.jpg')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Code from Unnat Antani  https://www.kaggle.com/unnatantani/flower-classification-using-fastai"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision.all import *\nfrom fastai.imports import *\nfrom fastai.vision.data import *\nfrom fastai import *\nimport numpy as np\nimport fastai\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"path = Path(\"/kaggle/input/goblin-portraits/images\")\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ndata = ImageDataLoaders.from_folder(path, train=\".\", valid_pct=0.2, item_tfms=RandomResizedCrop(512, min_scale=0.75),\n                                    bs=32,batch_tfms=[*aug_transforms(size=256, max_warp=0), Normalize.from_stats(*imagenet_stats)],num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(nrows=3, figsize=(7,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(nrows=2, figsize=(7,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(nrows=1, figsize=(7,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQgCMv_1Vbk7rcpGlJtqy636vO6yj3RMtwWUw&usqp=CAU)redbubble.com"},{"metadata":{"trusted":true},"cell_type":"code","source":"path2 = Path('/kaggle/input/goblin-portraits/images/')\ndls = ImageDataLoaders.from_folder(path, train='train',\n                                   item_tfms=Resize(224),valid_pct=0.2,\n                                   bs=64,seed=0)\ndls.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn = cnn_learner(dls, resnet34, metrics=accuracy, model_dir='/kaggle/tmp/model/')\n#learn.lr_find()\n#learn.fine_tune(5)\n#learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#That's insane, The pneumothorax from Paul has nothing to do with the Goblins. Therefore the Confusion Matrix does not belong here.\n\n#That snippet above took so long that is why I miss my previous code with no classification,just images."},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_fastai_results(learn=learn)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#2B3A67','#42a7f5','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Marília Prata, not a DS. Stick around, I will be right back. @mpwolke' )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}