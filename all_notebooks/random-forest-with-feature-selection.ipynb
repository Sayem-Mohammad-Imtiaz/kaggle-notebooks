{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ca923f76-285f-55c2-3ae6-f562d70704cc"},"source":"### Goal:\n\n#### In this Glass classification dataset, I want to build a Random Forest model to classify the glasses"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4824fb9-ff2e-5841-6235-f9ebc9c7ed7e"},"source":"### Overview of the dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83ba8889-5e95-88fb-6c9a-cf6cb444649a"},"outputs":[],"source":"### load required packages\nimport pandas as pd \nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport seaborn as sns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5eee764-999c-91f4-21ad-e2bb54d87791"},"outputs":[],"source":"### laod the dataset and get an overview\ndf = pd.read_csv('../input/glass.csv')\nprint(df.info())\nprint()\n\n# the distribution of categories and visualization\nprint(df['Type'].value_counts().sort_values(ascending=False)) # six categories \nprint()\n\ntype_name_li = df['Type'].value_counts().sort_values(ascending=False).index\ntype_value_li = df['Type'].value_counts().sort_values(ascending=False).values\n\nimport matplotlib \nmatplotlib.style.use('ggplot')\nfig, axes = plt.subplots(figsize=[15, 15])\naxes.bar(list(range(len(type_name_li))), type_value_li, color='#2E8b57', width=0.8)\naxes.tick_params(labelsize=15)\naxes.set_xticks(np.arange(len(type_name_li))+0.4)\naxes.set_xticklabels(type_name_li, fontsize=15)\naxes.set_xlabel('Type', fontsize=20)\naxes.set_ylabel('Count', fontsize=20)\naxes.set_ylim(0, np.max(type_value_li)+5)\naxes.set_title('Frequency of each Type', fontsize=25, loc='center')\nplt.subplots_adjust(top=0.8)\n\n# the distribution of features \nprint(df.ix[:, df.columns[:-1]].describe())"},{"cell_type":"markdown","metadata":{"_cell_guid":"4c55ec7b-c398-2f75-8d34-8658bc231a0f"},"source":"### EDA on features "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a2973c6c-1ed4-5462-48d6-e0dd099cb492"},"outputs":[],"source":"### Distributions on features by Glass Type \ncol_name_li = df.columns[:-1]\n\nfor col_name in col_name_li:\n    fig = plt.figure(figsize=[30, 20])\n    plt.suptitle(col_name + ' by Glass Type', fontsize=25, y=0.94)\n    for (i, default) in enumerate(list(np.unique(df['Type'])), start=1):\n        axes = fig.add_subplot(2, 3, i)\n        axes.tick_params(labelsize=15)    \n        sns.distplot(df[col_name][df['Type'] == default].values, color='#2E8B57')\n        axes.set_xlabel(default, fontsize=15)\n        axes.set_ylabel('Density', fontsize=15)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17b79fd0-6c42-9a8e-9958-3fd803976c85"},"outputs":[],"source":"### Pairplot on features by Glass Type \nplt.figure(figsize=[50, 50])\nsns.pairplot(df, vars=df.columns[:-1], hue='Type', palette='Paired', diag_kind='kde')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5524f5a4-ff69-b63f-b386-df312355a819"},"outputs":[],"source":"### correlations between each feature\ncor_mat = df.ix[:, df.columns[:-1]].corr()\n\nplt.figure(figsize=[10, 10])\nsns.heatmap(cor_mat, square=True, annot=True, cmap=\"RdBu\")\n#plt.title('Correlations between each Feature', fontsize=20)\nplt.suptitle('Correlations between each Feature', fontsize=20, y=0.94, horizontalalignment='center')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed964a94-9c75-c9e3-f4e3-01888973d119"},"outputs":[],"source":"### get the correlated feature pairs\n\n#print(cor_mat.index)\n\npair_li = []\n\nfor i in cor_mat.index:\n    for j in cor_mat.index:\n        if i == j:\n            continue\n        else:\n            if np.round(np.abs(cor_mat.ix[i, j]), 1) >= 0.5:\n                pair_li.append(tuple(sorted([i, j])))\n            else:\n                continue\n\nprint('\\n')                \npair_li = list(set(pair_li))\nprint('Features pairs that have high correlations:')\nprint(pair_li)\n\nintersect_li = []\n\nfor i in pair_li:\n    temp_li = []\n    temp_li.append(i)\n    for j in pair_li:\n        if i == j:\n            continue\n        else:\n            if len(np.intersect1d(i, j)) != 0:\n                temp_li.append(j)\n            else:\n                continue\n    temp_li = tuple(sorted(temp_li))\n    intersect_li.append(temp_li)\n\nintersect_li = list(set(intersect_li))\nprint('\\n')\nprint('Features pairs with high correlations that have overlapping values')\nfor i, pair in enumerate(intersect_li, start=1):\n    print(str(i)+':', pair)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f16a0907-f65a-ff83-da07-ddea009cd746"},"source":"Features pairs with high correlations (equal to or higher than 0.5), taking the values close to 0.5 into account: \n(Al, Mg)\n(Si, Rl)\n(Ca, Rl)\n(Ba, Mg)\n(Ba, Al)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03293e88-0a03-e046-bc7f-a65b5573d704"},"outputs":[],"source":"### to test if features has high correlations with the target values\n# using the ANOVA\n\nfrom scipy.stats import f_oneway\n\ndef cal_anova(val, label_val, label_li):\n    val_li = []\n    for label in label_li:\n        val_li.append(val[label_val==label])\n    return f_oneway(*val_li)\n\nanova_table = pd.DataFrame(columns=['F_value', 'P_value'], index=df.columns[:-1])\n\nfor i in df.columns[:-1]:\n    anova_table.ix[i, :] = cal_anova(df[i].values, df['Type'].values, np.unique(df['Type'].values))\nprint(anova_table.sort_values(['F_value'], ascending=False))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b64876fc-b0fe-5b12-5a55-52d35eba5443"},"outputs":[],"source":"### from the correlations outcome above, pick up the useful features\nfor i, pair in enumerate(intersect_li, start=1):\n    print(i, pair)\n\nfrom itertools import chain \nfor i, pair in enumerate(intersect_li, start=1):\n    print(i, np.unique(list(chain(*pair))))\n\n# remove \"RI\" and reserve the \"Ca\" and \"Si\"\n# remove \"Al\" and \"Ba\", and reserve \"Mg\""},{"cell_type":"markdown","metadata":{"_cell_guid":"5b4647d8-3f70-8496-0e4d-93711e2b8b9a"},"source":"Here are the Features not used for modeling: 'RI', 'Al', 'Ba'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecb6b734-30d7-3bd6-f90f-4162ed15685d"},"outputs":[],"source":"### extract the features used for modeling \nfeature_li = df.columns[:-1]\nfeature_not_li = ['RI', 'Al', 'Ba']\n\nfeature_li = np.setdiff1d(feature_li, feature_not_li)\nprint(feature_li)\n\nX = df.ix[:, feature_li]\ny = df['Type']\nprint(X.head())\nprint(y.head())"},{"cell_type":"markdown","metadata":{"_cell_guid":"1ba8a59d-220b-6429-6ef6-eb54d40cebf7"},"source":"### Modeling "},{"cell_type":"markdown","metadata":{"_cell_guid":"7227d124-9b82-07c9-c80b-211a8d5b4832"},"source":"since the number of each label is not large enough, I evaluate the model simply based on the cross-validation set"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e61411a-e800-0cef-528d-5c2049064436"},"outputs":[],"source":"### set the stratified splitter \n\nfrom sklearn.cross_validation import StratifiedKFold\nskf_splitter = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=100)\nfor ind in skf_splitter:\n    print(ind)\nprint(len(skf_splitter))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66fb9e98-0d58-bb73-f038-a8e50c3a783e"},"outputs":[],"source":"### building the model and evaluate\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support\n\naccuracy_mean = 0\nprecision_mean = np.zeros(len(np.unique(y)))\nrecall_mean = np.zeros(len(np.unique(y)))\nf1_mean = np.zeros(len(np.unique(y)))\n\nfor ind in skf_splitter:\n    model = RandomForestClassifier(n_estimators=100)\n    model.fit(X.values[ind[0]], y.values[ind[0]])\n    prediction = model.predict(X.values[ind[1]])\n    \n    print('Accuracy:\\n', model.score(X.values[ind[1]], y.values[ind[1]]))\n    accuracy_mean += model.score(X.values[ind[1]], y.values[ind[1]])\n    print('Preision, Recall and F1:\\n', precision_recall_fscore_support(y.values[ind[1]], prediction))\n    precision_mean += precision_recall_fscore_support(y.values[ind[1]], prediction)[0]\n    recall_mean += precision_recall_fscore_support(y.values[ind[1]], prediction)[1]\n    f1_mean += precision_recall_fscore_support(y.values[ind[1]], prediction)[2]\n    #print('Confusion Matrix:\\n', confusion_matrix(y.values[ind[1]], prediction))\n    print('Confusion Matrix:\\n', pd.DataFrame(confusion_matrix(y.values[ind[1]], prediction), columns=sorted(np.unique(y)), \n                                             index=sorted(np.unique(y))))\n    print('======================================================================\\n\\n')\n\nfold = 5\nprint('Average Accuracy:', accuracy_mean/fold)\nprint('Average Precision:', precision_mean/fold)\nprint('Average Recall:', recall_mean/fold)\nprint('Average F1 score:', f1_mean/fold)"},{"cell_type":"markdown","metadata":{"_cell_guid":"657ae980-6c7c-d49f-0728-e3fb93b0462a"},"source":"The model is not good enough. I'd like to use hyperparameters tuning to produce better model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1de34610-81f7-bc78-ce71-a9e808f66601"},"outputs":[],"source":"### Grid search to choose the best model\nfrom sklearn.grid_search import GridSearchCV\nparam_grid = {'n_estimators': [100, 500, 1000], 'criterion': ['gini', 'entropy'], 'max_features': ['auto', 'sqrt', 'log2'],\n             'max_depth': [5, 10, 15, 20]}\nmodel = RandomForestClassifier(n_jobs=-1)\ngrid = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\ngrid.fit(X, y)\nprint('done')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"112d57fc-85a7-05fb-124c-b9868bf0ebc1"},"outputs":[],"source":"print(grid.best_score_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"344c9274-6865-df67-1df6-64ccebfd6884"},"outputs":[],"source":"print(grid.best_params_) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a52eaba-7a5d-4400-9108-cc5f54005d78"},"outputs":[],"source":"### test on the best model on different subsets\n\nmodel = grid.best_estimator_\n\nfold = 5\n\nfrom sklearn.cross_validation import StratifiedKFold\nskf_splitter = StratifiedKFold(y, n_folds=fold, shuffle=True, random_state=1234) # set 1234 for different subsets\n\naccuracy_mean = 0\nprecision_mean = np.zeros(len(np.unique(y)))\nrecall_mean = np.zeros(len(np.unique(y)))\nf1_mean = np.zeros(len(np.unique(y)))\n\nfor ind in skf_splitter:\n    prediction = model.predict(X.values[ind[1]])\n    \n    print('Accuracy:\\n', model.score(X.values[ind[1]], y.values[ind[1]]))\n    accuracy_mean += model.score(X.values[ind[1]], y.values[ind[1]])\n    print('Preision, Recall and F1:\\n', precision_recall_fscore_support(y.values[ind[1]], prediction))\n    precision_mean += precision_recall_fscore_support(y.values[ind[1]], prediction)[0]\n    recall_mean += precision_recall_fscore_support(y.values[ind[1]], prediction)[1]\n    f1_mean += precision_recall_fscore_support(y.values[ind[1]], prediction)[2]\n    #print('Confusion Matrix:\\n', confusion_matrix(y.values[ind[1]], prediction))\n    print('Confusion Matrix:\\n', pd.DataFrame(confusion_matrix(y.values[ind[1]], prediction), columns=sorted(np.unique(y)), \n                                             index=sorted(np.unique(y))))\n    print('======================================================================\\n\\n')\n\n\nprint('Average Accuracy:', accuracy_mean/fold)\nprint('Average Precision:', precision_mean/fold)\nprint('Average Recall:', recall_mean/fold)\nprint('Average F1 score:', f1_mean/fold)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a7715191-eca6-119e-46be-05e0d8c6c353"},"source":"#### Now the model looks better. If there are more data for further testing, it would give us more insights.*emphasized text*"},{"cell_type":"markdown","metadata":{"_cell_guid":"ceecd4cc-f156-3ddd-e75d-ca692feae543"},"source":"### If you have any questions, feedback or suggestions, feel free to comment below, everything you want to say is quite welcome, thanks!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}