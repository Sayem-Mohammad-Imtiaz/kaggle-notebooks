{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#11ccee','#cc11ee','Ewert','Aladin',24,30\ndef dhtml(string,font_color=c1,font_family=f1,font_size=fs1):\n    display(HTML(\"\"\"\n    <style>@import 'https://fonts.googleapis.com/css?family=\"\"\"+\\\n    font_family+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' \n    style='font-family:\"\"\"+font_family+\\\n    \"\"\"; color:\"\"\"+font_color+\\\n    \"\"\"; font-size:\"\"\"+str(font_size)+\"\"\"px;'>%s</h1>\"\"\"%string))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('Code Modules, Setting, & Functions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os,cv2,h5py,numpy as np,pandas as pd\nimport urllib,pylab as pl,seaborn as sn\nimport torch,tensorflow_hub as th,tensorflow as tf\nimport tensorflow.keras.preprocessing.image as tkimg\nfrom tqdm import tqdm; from PIL import Image\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nfrom IPython.core.magic import register_line_magic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size,batch_size2=16,8\nimg_size,img_size2=160,64\ncrop_size=(img_size2,img_size2)\ndev=torch.device('cuda:0' \\\nif torch.cuda.is_available() else 'cpu')\nfile_path='../input/white-flowers/white_flowers/'\nfile_path2='https://olgabelitskaya.gitlab.io/images/'\nhub_path='https://tfhub.dev/google/magenta/'+\\\n         'arbitrary-image-stylization-v1-256/1'\nobjects=['jasmine','phlox','leucanthemum maximum','cherry',\n         'viola','lily of the valley','apple tree',\n         'snowdrop','perennial aster','blackberry',\n         'strawberry','Nanking cherry','bellflower']\nclasses=['jasmine','phlox','cherry','viola',\n         'lily of the valley','snowdrop']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_file(file_path,file_name):\n    input_file=urllib.request.urlopen(file_path+file_name)\n    output_file=open(file_name,'wb')\n    output_file.write(input_file.read())\n    output_file.close(); input_file.close()\ndef paths2tensor(img_paths,file_path,img_size=160):\n    tensor=[]\n    for img_path in tqdm(img_paths):\n        img0=tkimg.load_img(\n            file_path+img_path,\n            target_size=(img_size,img_size))\n        img=tkimg.img_to_array(img0)\n        tensor.append(np.expand_dims(img,axis=0))\n    return np.vstack(tensor)/255\ndef load_img(path_to_img,max_dim=512):\n    img=tf.io.read_file(path_to_img)\n    img=tf.image.decode_image(img,channels=3)\n    img=tf.image.convert_image_dtype(img,tf.float32)\n    shape=tf.cast(tf.shape(img)[:-1],tf.float32)\n    scale=max_dim/max(shape)\n    new_shape=tf.cast(shape*scale,tf.int32)\n    img=tf.image.resize(img,new_shape)\n    return img[tf.newaxis,:]\ndef tensor2img(tensor):\n    tensor=tensor*255\n    tensor=np.array(tensor,dtype=np.uint8)\n    if np.ndim(tensor)>3:\n        assert tensor.shape[0]==1\n        tensor=tensor[0]\n    return Image.fromarray(tensor)\ndef plcmap(cmap,n):\n    return [pl.cm.get_cmap(cmap)(i/n)[:3] \n            for i in range(1,n+1)]\n@register_line_magic\ndef display_examples(data):\n    for images,labels in dataloaders[data]:  \n        print('image dimensions: %s'%str(images.shape))\n        print('label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,3)\n        fig=pl.figure(figsize=(12,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=classes[labels[i].item()])\n            ax.imshow(np.transpose(images[i],(1,2,0)))\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('One Photo Processing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('opencv playing around',c2,f2,fs2)\nfile_name2='01_036.png'\nget_file(file_path2,file_name2)\nimg=cv2.imread(file_name2)\nimg=cv2.resize(img,(512,384))\ngray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nrgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nhsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\nedge_img=rgb.copy()\nedge=cv2.Canny(gray,80,210)\nedge_img[edge!=0]=(255,0,255) \nlower_white=np.array([10,200,10])\nupper_white=np.array([255,255,255])\nmask=cv2.inRange(hsv,lower_white,upper_white)\nres=cv2.bitwise_and(img,img,mask=mask)\nkernel=np.ones((11,11),np.uint8)\ngradient=cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)\nsobel=cv2.Sobel(\n    gray,cv2.CV_64F,1,0,ksize=27)\nlaplacian=cv2.Laplacian(img,cv2.CV_64F)\npl.figure(figsize=(12,9))\npl.subplot(331),pl.imshow(255-rgb)\npl.subplot(332),pl.imshow(hsv)\npl.subplot(333),pl.imshow(gray,cmap='bone')\npl.subplot(334),pl.imshow(edge_img)\npl.subplot(335),pl.imshow(edge,cmap='flag_r')\npl.subplot(336),pl.imshow(gradient)\npl.subplot(337),pl.imshow(\n    cv2.cvtColor(res,cv2.COLOR_HSV2RGB))\npl.subplot(338),pl.imshow(sobel,cmap='bone')\npl.subplot(339),pl.imshow(laplacian,cmap='bone')\npl.tight_layout(); pl.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('keras applications',c2,f2,fs2)\nimg=load_img(file_path+'03_004.png')\nout=tf.keras.applications.vgg19.preprocess_input(img)\nout=tf.image.resize(out,(224,224))\nvgg19=tf.keras.applications\\\n.VGG19(include_top=True,weights='imagenet')\nprediction_probabilities=vgg19(out)\npredicted_top5=tf.keras.applications.vgg19\\\n.decode_predictions(prediction_probabilities.numpy())[0]\n[print((class_name,prob))\n for (number,class_name,prob) in predicted_top5]\ndhtml(':)))',c2,f2,fs2)\ntensor2img(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('tensorflow hub models',c2,f2,fs2)\nhub_module=th.load(hub_path)  \ncontent_image=load_img(file_path+'03_004.png')\nfile_name3='02_018.png'\nget_file(file_path2,file_name3)\nstyle_image=load_img(file_name3)\nstylized_image=hub_module(\n    tf.constant(content_image),tf.constant(style_image))[0]\ntensor2img(stylized_image)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('TensorFlow Data Processing<br/>'+\\\n      'with Label Selection & Resizing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes=len(classes)\nfile_list=sorted(os.listdir(file_path))\nx=paths2tensor(file_list,file_path)\ny=np.array([int(el[:2]) for el in file_list],\n           dtype='int8')-1\ncond=np.where([l in classes for l in objects])[0]\ncond2=np.where([l in cond for l in y])\nx=x[cond2]; y=y[cond2]\nrd={0:0,1:1,3:2,4:3,5:4,7:5}\ny=np.array([rd.get(el,el) for el in y],dtype='int8')\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(123).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\npd.DataFrame([[x_train.shape,x_valid.shape,x_test.shape],\n              [x_train.dtype,x_valid.dtype,x_test.dtype],\n              [y_train.shape,y_valid.shape,y_test.shape],\n              [y_train.dtype,y_valid.dtype,y_test.dtype]],               \n             columns=['train','valid','test'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('label distribution',c2,f2,fs2)\npl.figure(figsize=(8,4))\nsn.countplot(\n    x=[classes[l] for l in y],facecolor=(0,0,0,0),\n    linewidth=5,linestyle='-.',\n    edgecolor=plcmap('tab10',num_classes))\npl.tight_layout(); pl.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('label: %s'%classes[y_test[2]],c2,f2,fs2)\npl.figure(figsize=(3,3)); pl.xticks([]); pl.yticks([])\npl.imshow(x_test[2]); pl.tight_layout(); pl.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def esrgantf2_superresolution(img,img_size):\n    model=th.load('https://tfhub.dev/captain-pool/esrgan-tf2/1')\n    func=model.signatures[tf.saved_model\\\n                          .DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n    func.inputs[0].set_shape([1,img_size,img_size,3])\n    converter=tf.lite.TFLiteConverter.from_concrete_functions([func])\n    converter.optimizations=[tf.lite.Optimize.DEFAULT]\n    tflite_model=converter.convert()\n    with tf.io.gfile.GFile('ESRGAN.tflite','wb') as f:\n        f.write(tflite_model)\n    esrgan_model_path='./ESRGAN.tflite'\n    if img.mean()<1.: img=img*255.\n    lr=tf.image.resize(img,[img_size,img_size])\n    lr=tf.expand_dims(lr.numpy()[:,:,:3],axis=0)\n    lr=tf.cast(lr,tf.float32)\n    interpreter=tf.lite.Interpreter(model_path=esrgan_model_path)\n    interpreter.allocate_tensors()\n    input_details=interpreter.get_input_details()\n    output_details=interpreter.get_output_details()\n    interpreter.set_tensor(input_details[0]['index'],lr)\n    interpreter.invoke()\n    output_data=interpreter.get_tensor(output_details[0]['index'])\n    sr=tf.squeeze(output_data,axis=0)\n    sr=tf.clip_by_value(sr,0,255)\n    sr=tf.round(sr); sr=tf.cast(sr,tf.uint8)\n    lr=tf.cast(tf.squeeze(lr,axis=0),tf.uint8)\n    return lr,sr\nlr,sr=esrgantf2_superresolution(x[100],img_size2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('super resolution',c2,f2,fs2)\ndef low2superbicubic_imgs(lr,sr):\n    pl.figure(figsize=(9,3))\n    pl.title(f'low resolution',color='slategray')\n    pl.imshow(lr.numpy()); pl.tight_layout(); pl.show()\n    pl.figure(figsize=(9,3)); pl.subplot(1,2,1)\n    pl.title(f'esrgan x4',color=c1)\n    pl.imshow(sr.numpy())\n    img_size=lr.shape[1]\n    bicubic=tf.image.resize(\n        lr,[img_size*4,img_size*4],tf.image.ResizeMethod.BICUBIC)\n    bicubic_contrast=tf.image.adjust_contrast(bicubic,.8)\n    bicubic_contrast=tf.cast(bicubic_contrast,tf.uint8)\n    pl.subplot(1,2,2); pl.title(f'bicubic & contrast',color=c2)\n    pl.imshow(bicubic_contrast.numpy())\n    pl.tight_layout(); pl.show()\nlow2superbicubic_imgs(lr,sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('hierarchical data formatting',c2,f2,fs2)\nwith h5py.File('WhiteFlowerImages.h5','w') as f:\n    f.create_dataset('train_images',data=x_train)\n    f.create_dataset('train_labels',data=y_train)\n    f.create_dataset('valid_images',data=x_valid)\n    f.create_dataset('valid_labels',data=y_valid)\n    f.create_dataset('test_images',data=x_test)\n    f.create_dataset('test_labels',data=y_test)\nst=['st_mode','st_ino','st_dev','st_nlink','st_uid',\n    'st_gid','st_size','st_atime','st_mtime','st_ctime']\npd.DataFrame(os.stat('WhiteFlowerImages.h5'),\n             index=st,columns=['os.stat results'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('PyTorch Data Processing<br/>'+\\\n      'with Label Selection,Cropping, & Resizing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dhtml('pytorch data classes',c2,f2,fs2)\nclass TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffle_ids=np.arange(N)\nnp.random.RandomState(123).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nt1=tf.random.uniform(shape=(N,2),minval=0,maxval=.1)\nt2=tf.random.uniform(shape=(N,2),minval=.9,maxval=1)\nboxes=tf.concat([t1,t2],1)\nbox_indices=list(range(N))\nx=tf.image.crop_and_resize(x,boxes,box_indices,crop_size)\nx=np.transpose(x.numpy(),(0,3,1,2))\nprint(x.mean(),x.std())\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\nrandom_seed=23\ntrain=TData(x_train,y_train)\nvalid=TData(x_valid,y_valid)\ntest=TData(x_test,y_test)\ndataloaders={'train':tdl(dataset=train,shuffle=True, \n                         batch_size=batch_size2), \n             'valid':tdl(dataset=valid,shuffle=True, \n                         batch_size=batch_size2),\n             'test':tdl(dataset=test,shuffle=True, \n                        batch_size=batch_size2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples valid","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}