{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tutorial Part 2 - Cancellation Prediction\n\nThis notebook is based on and extends:\n - [EDA of bookings and ML to predict cancelations](https://www.kaggle.com/marcuswingen/eda-of-bookings-and-ml-to-predict-cancelations) by [Marcus Wingen](https://www.kaggle.com/marcuswingen)\n - [Exploring the Data & analysing the best Regression](https://www.kaggle.com/amarloni/exploring-the-data-analysing-the-best-regression) by [Amar Loni](https://www.kaggle.com/amarloni)\n\n![sklearn-logo](https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n\nWe will use [scikit-learn](https://scikit-learn.org/) to train a model that predicts whether a booking will be canceled.\n\n\n<!-- - [Factors influencing Hotel Booking - Quick Study](https://www.kaggle.com/samiranbera/factors-influencing-hotel-booking-quick-study) by [SamiranBera](https://www.kaggle.com/samiranbera)\n - [EDA of Hotel Bookings](https://www.kaggle.com/listonlt/eda-of-hotel-bookings) by [Liston Tellis](https://www.kaggle.com/listonlt)\n-->\n"},{"metadata":{},"cell_type":"markdown","source":"## Dataset description"},{"metadata":{},"cell_type":"markdown","source":"The [Hotel booking demand](https://www.kaggle.com/jessemostipak/hotel-booking-demand) dataset available on Kaggle has originally been described in [Antonio et al. (2019): Hotel booking demand datasets](https://doi.org/10.1016/j.dib.2018.11.126.). It was cleaned by Thomas Mock and Antoine Bichat for #TidyTuesday during the week of February 11th, 2020.\n\nIt contains booking data (31 variables) on two hotels in Portugal:\n - **H1:** a resort hotel at the Algarve (40,060 observations)\n - **H2:** a city hotel in Lisbon(79,330 observations)\n \nEach observation represents a hotel booking (due to arrive between the July 1, 2015 and the August 31, 2017), including **bookings that effectively arrived and bookings that were canceled**. \n\nThe data is from real hotel bookings, but all data pertaining to hotel or costumer identification were deleted."},{"metadata":{},"cell_type":"markdown","source":"### Complete list of variables"},{"metadata":{},"cell_type":"markdown","source":"- `hotel`: `Resort Hotel` or `City Hotel` *(Categorical)*\n- `is_canceled` Value indicating if the booking was canceled (`1`) or not (`0`) *categorical*\n\n\n\n- `lead_time` Number of days that elapsed betweenthe entering date of the booking into the PMS and the arrival date\n- `arrival_date_year` Year of arrival date (Integer)\n- `arrival_date_month` Month of arrival date with 12 categories: `January` to `December` *(categorical)*\n- `arrival_date_week_number` Week number of the arrival date *(Integer)*\n- `arrival_date_day_of_month` Day of the month of the arrival date *(Integer)*\n\n\n\n- `stays_in_weekend_nights` Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel *(Integer)*\n- `stays_in_week_nights` Number of week nights (Monday to Fri-day) the guest stayed or booked to stay at the hotel *(Integer)*\n\n\n\n- `adults` Number of adults *(Integer)*\n- `children` Number of children *(Integer)*\n- `babies` Number of Babies *(Integer)*\n- `meal` Type of meal booked. Categories arepresented in standard hospitality meal packages: \n    - `Undefined/SC` - no meal package; \n    - `BB` – Bed & Breakfast; \n    - `HB` – Half board (breakfast and one other meal–usually dinner); \n    - `FB` – Full board (breakfast, lunch and dinner)\n- `country` Country of origin. Categories are represented in the ISO 3155–3:2013 format *(Categorical)*\n\n- `market_segment` Market segment designation \n    - `TA` means TravelAgents and \n    - `TO` means TourOperators *(Categorical)*\n- `distribution_channel` Booking distribution channel \n    - `TA` means TravelAgents and \n    - `TO` means Tour Operators *Categorical)*\n\n\n\n- `is_repeated_guest` Value indicating if the booking was from a repeated guest (1) or not (0) *categorical*\n- `previous_cancellations` Number of previous bookings that werecancelled by the customer prior to the current booking *(Integer)*\n- `previous_bookings_not_canceled` Number of previous bookings notcancelled by the customer prior to thecurrent booking *(Integer)*\n\n\n- `reserved_room_type` Code of room type reserved. Code ispresented instead of designation for anonymity reasons\n- `assigned_room_type` Code for the type of room assigned to the booking. Sometimes the assigned roomtype differs from the reserved room typedue to hotel operation reasons (e.g.overbooking) or by customer request. Code is presented instead of designation for anonymity reasons. *(Catgorical)*\n\n\n- `booking_changes` Number of changes/amendments madeto the booking from the moment thebooking was entered on the PMS untilthe moment of check-in or cancellation *(Integer)*\n- `deposit_type`\n\n\n\n- `agent` ID of the travel agency that made thebooking *(Categorical)*\n- `company` ID of the company/entity that made thebooking or responsible for paying thebooking. ID is presented instead of des-ignation for anonymity reasons *(Categorical)*\n\n- `days_in_waiting_list` Number of days the booking was in thewaiting list before it was confirmed to the customer *(Integer)*\n- `customer_type` Type of booking, assuming one of four categories: \n    - `Contract` - when the booking has an allotment or other type of contract associated to it; \n    - `Group` – when the booking is asso-ciated to a group;\n    - `Transient` – when the booking is notpart of a group or contract, and is not associated to other transient booking;\n    - `Transient-party` – when the booking istransient, but is associated to at leastother transient booking\n\n- `adr` Average Daily Rate - Calculated by dividing the sum of all lodging transactions by the total number of staying nights *(Numeric)*\n- `required_car_parking_spaces` Number of car parking spaces requiredby the customer *(Integer)*\n- `total_of_special_requests` Number of special requests made by thecustomer (e.g. twin bed or highfloor) *(Integer)*\n- `reservation_status` Reservation last status, assuming one ofthree categories:\n    - `Canceled` - booking was canceled bythe customer;\n    - `Check-Out` - customer has checked inbut already departed;\n    - `No-Show` - customer did not check-in and did inform the hotel of the reason why\n- `reservation_status_date` Date at which the last status was set. This variable can be used in conjunction with the Reservation Status to understand when was the booking canceled or whendid the customer checked-out of the hotel *(Date)*\n\n**Note:** there are some differences between the original data set described in the paper and the dataset here:\n - in the paper, there is a separate data set for each hotel, which have been merged with an added column `hotel`\n - omission of redundant variables (e.g., Categorical and Integer versions of month)\n \n\nLet's see if that matches the data we have.."},{"metadata":{},"cell_type":"markdown","source":"### Loading and preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load common libraries:\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport folium\n\n# set some display options:\nsns.set(style=\"whitegrid\")\npd.set_option(\"display.max_columns\", 36)\n\n# load data:\nfile_path = \"../input/hotel-booking-demand/hotel_bookings.csv\"\nfull_data = pd.read_csv(file_path)\n\n# Replace missing values:\nnan_replacements = {\"children\": 0.0, \"country\": \"Unknown\", \"agent\": 0, \"company\": 0}\nfull_data_cln = full_data.fillna(nan_replacements)\n\n# \"meal\" contains values \"Undefined\", which is equal to SC.\nfull_data_cln[\"meal\"].replace(\"Undefined\", \"SC\", inplace=True)\n\n# Get rid of bookings for 0 adults, 0 children, and 0 babies:\nzero_guests = list(full_data_cln.loc[full_data_cln[\"adults\"]\n                   + full_data_cln[\"children\"]\n                   + full_data_cln[\"babies\"]==0].index)\nfull_data_cln.drop(full_data_cln.index[zero_guests], inplace=True)\n\n# Delete a record with ADR greater than 5000\nfull_data_cln = full_data_cln[full_data_cln['adr'] < 5000]\nax = sns.boxplot(x=full_data_cln['adr'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cancellation prediction"},{"metadata":{},"cell_type":"markdown","source":"Wo what do we want to predict?\n\n - the **number of cancellations** over time\n - **whether or not** a given booking will be canceled\n - **how likely** it is that a given booking will be canceled"},{"metadata":{},"cell_type":"markdown","source":"### What variables are correlated with cancelations?"},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_mat = full_data.corr()\nfig, ax = plt.subplots(figsize=(17,7))\nsns.heatmap(cor_mat, ax=ax, cmap=\"RdBu\", center=0, linewidths=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our target variable `is_canceled` is positively correlated with:\n - `lead_time`: bookings that are made well in advance are more likely to be canceled.\n - `previous_cancellations`: bookings made by customers who have canceled bookings in the past are more likely to canceled.\n - `adults`: single bookings tend to be canceled less frequently than bookings for larger parties..\n - `days_in_waiting_list`: customers don't like to wait..\n - `adr`: more expensive bookings tend to be canceled more often (a bit).\n\nIt is negatively correlated with:\n - `is_repeat_guest`: repeat guests seem to be more loyal and don't cancel as much\n - `booking_changes`: higher number of changes is associated with less cancelations\n - `required_car_parking_spaces`: customers who come by car don't cancel as much (resort vs. city?)\n - `total_of_special_requests`: bookings with higher number of special requests are canceled less often."},{"metadata":{},"cell_type":"markdown","source":"A few other observations:\n- Pos. corr. between `children` and `adr`: it's expensive to be parents.. ;)\n- Pos. corr. between `previous_cancellations` and `lead_time`: customers that have canceled more often tend to book well in advance..\n- Pos. corr. between `previous_cancellations`and `previous_bookings_not_canceled`: probably due to repeat customers who come more than once (and cancel some of their bookings)\n- Neg. corr. between `arrival_date_week_number` and `arrival_date_year`: not surprising, as the data set begins and ends in August - therefore, the lower first year (2016) has higher week numbers (starting from 35) than the the last year (2017), which only includes week numbers up to 35.\n- Pos. corr. between `stays_in_week_nights` and `stays_in_weekend_nights`: longer stays (1 week in resort) increase both\n\n- the association of `is_repeat_guest`and `company` may be spurious, as `company` is a categorical\n\nLet's have a closer look at the correlation with our target variable again:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cancel_corr = full_data.corr()[\"is_canceled\"]\ncancel_corr.sort_values(ascending=False)[1:]\n#cancel_corr.abs().sort_values(ascending=False)[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**OK, so `lead_time`, `total_of_special_requests`, `required_car_parking_spaces`, `booking_changes` and `previous_cancellations` are the 5 most important numerical features.**\n\nCan we actually use them to make predictions?\n\nAs we'll see..\n- we cannot use `booking_changes`, as this changes over time and is a possible source of leakage (we don't know in advance how often there will be a booking change for a new booking; therefore, we would train the model with data that it's not supposed to have/does not have in real-world use)\n- `total_of_special_requests`: assuming that these requests are made when the booking is made, we can include them; otherwise we may also have to discard that."},{"metadata":{},"cell_type":"markdown","source":"## Preparations"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separate features and predicted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate features and predicted value\ny = full_data[\"is_canceled\"] # what we want to predict\nX = full_data.drop([\"is_canceled\"], axis=1) # remove target variable from features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train-test split"},{"metadata":{},"cell_type":"markdown","source":"Let's divide the data into training and validation sets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 70 % for training, 30 % for validation\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.7,\n                                                                test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that we set a random seed (`random_state`) to get reproducible results."},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"### Numeric Features"},{"metadata":{},"cell_type":"markdown","source":"Let's choose the columns that we want include as features.\n\nLooking at the numeric features we have, we will exclude the following ones to prevent leakage and make the model more general:\n - `arrival_date_year`: we want to avoid correlated features - as we have seen above, the data begins and ends in summer, so there are two years with data only on half of the year; this is likely to introduce spurious patterns.\n - `assigned_room_type`: we only know that once the customer checks in, i.e., we cannot use that to make predictions (\"leakage\")\n - `booking_changes`: same here\n - `reservation_status`: same here; \"predicting\" that `is_canceled=1` if `reservation_status` is `Canceled` won't help us ;) \n - `days_in_waiting_list`: we don't know at the time, how long the booking will be on the waiting list \n\nWe will include the following numeric features:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = [\"lead_time\",\n                \"arrival_date_week_number\",\n                \"arrival_date_day_of_month\",\n                \"stays_in_weekend_nights\",\n                \"stays_in_week_nights\",\n                \"adults\",\n                \"children\",\n                \"babies\",\n                \"is_repeated_guest\",\n                \"previous_cancellations\",\n                \"previous_bookings_not_canceled\",\n                \"agent\",\n                \"company\",\n                \"required_car_parking_spaces\",\n                \"total_of_special_requests\",\n                \"adr\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical features"},{"metadata":{},"cell_type":"markdown","source":"Next, we select which categorical features to include to make our predictions.\n\nHere, we have to exclude `reservation_status` (values: `checked-out`and `Canceled`) to prevent leakage.\n\nDepending on whether or not we want to use the trained model to make predictions only for these specific hotels or whether we want a model that generalizes to other hotels, we may have to think whether to include certain attributes:\nwe may want to exclude `country`, because distance may actually play a role, rather than just nationality.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [\"hotel\",\n                \"arrival_date_month\",\n                \"meal\",\n                \"market_segment\",\n                \"distribution_channel\",\n                \"reserved_room_type\",\n                \"deposit_type\",\n                \"customer_type\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Construct training and validation sets with features"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train_full[num_features + cat_features].copy()\nX_valid = X_valid_full[num_features + cat_features].copy()\n\n# preprocess numerical features: \nnum_transformer = SimpleImputer(strategy=\"constant\") # not really necessary, as we should not have any missing values\n\n# Preprocessing for categorical features:\ncat_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical features:\npreprocessor = ColumnTransformer(transformers=[('num', num_transformer, num_features),\n                                               ('cat', cat_transformer, cat_features)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{},"cell_type":"markdown","source":"We will use a [random forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to make predictions. (cf. [this article](https://towardsdatascience.com/random-forest-and-its-implementation-71824ced454f) for a more in-depth explanation).\n\nRandom forest is a supervised learning algorithm that runs decision trees in parallel and combines their output to obtain final predictions.\n\n![Random forest](https://miro.medium.com/max/1306/0*f_qQPFpdofWGLQqc.png)\n\n<!--\n![Random forest](randomForest.png)\n-->"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Random Forest classifier:\nrfc_model = RandomForestClassifier(random_state=0,n_jobs=-1)\nrfc_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', rfc_model)])\n\n# Preprocessing of training data, fit model:\nrfc_pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Preprocessing of validation data, get predictions:\ny_pred = rfc_pipeline.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model:\nscore = accuracy_score(y_valid, y_pred)\nprint(\"Random Forest accuracy_score: \", score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So with this model, we achieve an accuracy of 0,86..\n\nWhat does that mean?"},{"metadata":{},"cell_type":"markdown","source":"#### Defnition: Accuracy\nWhat does that mean? The [scikit-earn user guide](https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score) says that if $\\hat{y}_i$ is the predicted value of the $i$-th sample and $y$ is the corresponding true value, then the fraction of correct predctions over $n_{samples}$ is defined as\n\n$$\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)$$\n\n"},{"metadata":{},"cell_type":"markdown","source":"**So pretty straingt forward: about 86% of the predictions are correct.**\n\nNow, that sounds impressive, but is that any good?<br/> \nWhat should be our baseline here? <br/>\nWhat would your buest guess if you don't know anything?"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data_cln[\"is_canceled\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So if you follow a naïve strategy and just guess that a booking will not be canceled without knowing anything about it, you will already be correct in 63% (1-0.37) of cases. \n\nSo, 0.863 is not too bad, but also not all *that* impressive.. \n\nTo control for an **imbalanced dataset** like this, we should use the balanced accuracy score:"},{"metadata":{},"cell_type":"markdown","source":"#### Definition: Balanced Accuracy\n\nIf $y_i$ is the true value of the $i$-th sample, and $w_i$ is the corresponding sample weight, then we adjust the sample weight to:\n\n$$\\hat{w}_i = \\frac{w_i}{\\sum_j{1(y_j = y_i) w_j}}$$\n\nBalanced accuracy is then defined as:\n\n$$\\texttt{balanced-accuracy}(y, \\hat{y}, w) = \\frac{1}{\\sum{\\hat{w}_i}} \\sum_i 1(\\hat{y}_i = y_i) \\hat{w}_i$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\n\nbalanced_accuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So not too bad..\n\n\nLet's say you want to act on the predictions, e.g. by overbooking a room. \n\nWhat else would you like to know before you make a decision on whether to do that?"},{"metadata":{},"cell_type":"markdown","source":"Well, if you do, four things may happen:\n - the customer predicted to show up actually shows up (True positive → $T_p$)\n - the customer predicted to cancel actually cancels (True negative → $T_n$)\n \n or\n - the customer not predicted to cancel does cancel (False positive → $F_p$)\n - the customer predicted to cancel does not cancel (False negative → $F_n$)\n \nSo, how can we look into this? The *confusion matrix* does the job here:"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's put this a little more nicely.."},{"metadata":{"trusted":true},"cell_type":"code","source":"true = pd.Categorical(list(np.where(np.array(y_valid) == 1, 'cancelled','not cancelled')), categories = ['cancelled','not cancelled'])\npred = pd.Categorical(list(np.where(np.array(y_pred) == 1, 'cancelled','not cancelled')), categories = ['cancelled','not cancelled'])\n\npd.crosstab(pred, true, \n            rownames=['pred'], \n            colnames=['Actual'], margins=False, margins_name=\"Total\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, this is helpful, but can we summarize these in simple metrics?"},{"metadata":{},"cell_type":"markdown","source":"#### Definition: Precision, Recall, F1 ([Documentation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py))\n\nPrecision (a.k.a. false positive rate, specificity, positive predictive power) $P$ is defined as the number of true positives $T_p$ over the number of true positives plus the number of false positives $F_p$:\n\n$$ P = \\frac{T_p}{T_p+F_p} $$\n\nRecall (a.k.a. true postive rate or sensitivity) $R$ is defined as the number of true positives $T_p$ over the number of true positives plus the number of false negatives $F_n$:\n\n$$R = \\frac{T_p}{T_p + F_n}$$\n\nThese quantities are also related to the $F1$ score, which is defined as the harmonic mean of precision and recall:\n\n$$F1 = 2\\frac{P \\times R}{P+R}$$\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\nprint(\"Precision: \", precision_score(y_valid, y_pred))\nprint(\"Recall: \", recall_score(y_valid, y_pred))\nprint(\"F1: \", f1_score(y_valid, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we deal with a binary classification problem (vs. a multi-label classification problem) here, we can nicely see the trade off between precision vs. recall in a plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_precision_recall_curve\n\ndisp = plot_precision_recall_curve(rfc_pipeline, X_valid, y_valid)\ndisp.ax_.set_title('Precision-Recall curve')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation:** in principle, we could set a different threshold for the classifier (0.5 by default) to favor precision or recall and get, e.g.,\n - (almost) perfect precision (i.e., every predicted cancellation is an actual cancellation), if we are ok with only predicting approx. 40% of the cancellations\n - (almost) perfect recall (i.e., predict all actual cancellations), if we are ok with about 40% of our predictions being incorrect\n - or something in between..\n \n Other important metrics include [Area Under the Curve (AUC)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc), and [Receiver Operating Characteristics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve). \nThere are also various more specialized ones.."},{"metadata":{},"cell_type":"markdown","source":"## How about Regression?"},{"metadata":{},"cell_type":"markdown","source":"Even though the target variable is dichotomous (binary), we can just as well treat this as a regression problem. \n\nRandom forests, which we used for classification before, can also be used for regression tasks.\nIn that case, instead of the mode of the predictions made by the individual trees, the mean prediction is returned.\nIn scikit-learn, we can use the [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and otherwise the same preprocessing pipeline as before."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor \n\nrfe_model = RandomForestRegressor(n_estimators = 100, random_state = 0) \nrfe_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', rfe_model)])\nrfe_pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rfe_pipeline.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nprint('Mean Absolute Error:', mean_absolute_error(y_valid, y_pred).round(4))  \nprint('Mean Squared Error:', mean_squared_error(y_valid, y_pred).round(4))  \nprint('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_valid, y_pred)).round(4))\nprint('r2_score:', r2_score(y_valid, y_pred).round(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  References\n[Nuno Antonio, Ana de Almeida, Luis Nunes: Hotel booking demand datasets, Data in Brief, Volume 22, 2019, p. 41-49](https://doi.org/10.1016/j.dib.2018.11.126.)"}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":4}