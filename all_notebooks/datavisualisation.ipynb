{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-20T13:37:09.433301Z","iopub.execute_input":"2021-08-20T13:37:09.433731Z","iopub.status.idle":"2021-08-20T13:37:09.457736Z","shell.execute_reply.started":"2021-08-20T13:37:09.433647Z","shell.execute_reply":"2021-08-20T13:37:09.456461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:37:09.459789Z","iopub.execute_input":"2021-08-20T13:37:09.460213Z","iopub.status.idle":"2021-08-20T13:37:10.280001Z","shell.execute_reply.started":"2021-08-20T13:37:09.460169Z","shell.execute_reply":"2021-08-20T13:37:10.279069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_path = os.path.join(os.path.abspath(os.path.sep), \"kaggle\", \"input\", \"librispeechtext\", \"data\", \"train-clean-100.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:39:08.388388Z","iopub.execute_input":"2021-08-20T13:39:08.38877Z","iopub.status.idle":"2021-08-20T13:39:08.394335Z","shell.execute_reply.started":"2021-08-20T13:39:08.38873Z","shell.execute_reply":"2021-08-20T13:39:08.393238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_df = pd.read_csv(train_clean_path, index_col=0)\ntrain_clean_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:39:11.395949Z","iopub.execute_input":"2021-08-20T13:39:11.396326Z","iopub.status.idle":"2021-08-20T13:39:11.55449Z","shell.execute_reply.started":"2021-08-20T13:39:11.396295Z","shell.execute_reply":"2021-08-20T13:39:11.553475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:39:20.880725Z","iopub.execute_input":"2021-08-20T13:39:20.881404Z","iopub.status.idle":"2021-08-20T13:39:20.90325Z","shell.execute_reply.started":"2021-08-20T13:39:20.881366Z","shell.execute_reply":"2021-08-20T13:39:20.902516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clean_df['NUM WORDS'] = train_clean_df['REAL TEXT'].apply(lambda x: len(x.split()))\ntrain_clean_df[['NUM WORDS']].hist(figsize=(12, 6), bins=10, xlabelsize=8, ylabelsize=8)\nplt.title(\"Distributon of number of words in the books\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:39:26.090148Z","iopub.execute_input":"2021-08-20T13:39:26.090819Z","iopub.status.idle":"2021-08-20T13:39:26.408407Z","shell.execute_reply.started":"2021-08-20T13:39:26.090782Z","shell.execute_reply":"2021-08-20T13:39:26.407358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nall_words = ''.join([word for word in train_clean_df['REAL TEXT'][0:100000]])\nall_words\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\nplt.figure(figsize=(15, 8))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.title(\"Some frequent words used in the train set\", weight='bold', fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:39:31.457325Z","iopub.execute_input":"2021-08-20T13:39:31.457703Z","iopub.status.idle":"2021-08-20T13:39:36.383986Z","shell.execute_reply.started":"2021-08-20T13:39:31.457673Z","shell.execute_reply":"2021-08-20T13:39:36.382997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_n_words(corpus, n=10):\n  vec = CountVectorizer(stop_words='english').fit(corpus)\n  bag_of_words = vec.transform(corpus)\n  sum_words = bag_of_words.sum(axis=0) \n  words_freq = [(word, sum_words[0, idx]) for word, idx in   vec.vocabulary_.items()]\n  words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n  return words_freq[:n]\nwords = []\nword_values = []\nfor i,j in get_top_n_words(train_clean_df['REAL TEXT'],15):\n  words.append(i)\n  word_values.append(j)\nfig, ax = plt.subplots(figsize=(16,8))\nax.bar(range(len(words)), word_values);\nax.set_xticks(range(len(words)));\nax.set_xticklabels(words, rotation='vertical');\nax.set_title('Top 15 words in the train dataset');\nax.set_xlabel('Word');\nax.set_ylabel('Number of occurences');\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-20T13:39:37.010461Z","iopub.execute_input":"2021-08-20T13:39:37.010818Z","iopub.status.idle":"2021-08-20T13:39:39.185907Z","shell.execute_reply.started":"2021-08-20T13:39:37.010786Z","shell.execute_reply":"2021-08-20T13:39:39.184767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}