{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Project Repository:** https://github.com/GokulKarthik/deep-learning-projects-pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n#from torchsummary import summary\n\nimport string\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#writer = SummaryWriter(os.path.join(\"runs\", \"baby-names\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load data"},{"metadata":{},"cell_type":"markdown","source":"[This Kaggle dataset](https://www.kaggle.com/kaggle/us-baby-names#NationalNames.csv) has names of the child born from 1880 to 2014 along with other features such as Gender and Count. I am going to use this to build a name generator model using sampling of the trained character level LSTM network"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = os.path.join(\"/kaggle\", \"input\", \"us-baby-names\", \"NationalNames.csv\")\ndata = pd.read_csv(data_path)\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Clean data"},{"metadata":{"trusted":false},"cell_type":"code","source":"def clean(name):\n    \n    name = name.lower().strip()\n    name = \"\".join([c for c in name if c in string.ascii_lowercase])\n    name += \".\"\n    return name","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['Name'] = data['Name'].apply(clean)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = data[['Name', 'Count']].groupby('Name').sum()\ndel names.index.name\nprint(len(names))\nnames.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.Series(names.index).apply(len).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"max_length = 11\nlen_filter = pd.Series(names.index).apply(lambda x: len(x)<=max_length).tolist() # max length of 10 excluding '.'\nprint(len_filter[:10])\nprint(names.shape)\nnames = names[len_filter]\nprint(names.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.Series(names.index).apply(len).max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = names.sort_values(by=['Count'], ascending=False)\nnames.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Set training data"},{"metadata":{},"cell_type":"markdown","source":"We need a list of names to start building the name generator model. One naive approach for this dataset could be to just take list of unique names. The number of uniques names is 93889, which is large. So, if we sample uniformly from the unique names, the model may learn to generate uncommon and less interesting names. Also if we use the exact counts the model will generate more common names. So we have to sample in between these two. Normalized counts can be used to sample for training."},{"metadata":{"trusted":false},"cell_type":"code","source":"names['Count'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"alpha = 0.8\nnames['Count'].apply(lambda x: np.power(x, alpha)).apply(np.int).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names['count_normalized'] = names['Count'].apply(lambda x: np.power(x, alpha)).apply(np.int)\nnames.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"count_normalized_sum = names['count_normalized'].sum()\nprint(count_normalized_sum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names['p'] = names['count_normalized'] / count_normalized_sum\nnames.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"np.random.seed(0)\nnames_list = np.random.choice(names.index, size=10**5, p=names['p'], replace=True)\nprint(len(names_list))\nprint(names_list[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.Series(names_list).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"del data, names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Define utilities"},{"metadata":{"trusted":false},"cell_type":"code","source":"chars = \".\" + string.ascii_lowercase\nnum_chars = len(chars)\nprint(chars)\nprint(num_chars)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"char_to_id = {c:i for i, c in enumerate(chars)}\nid_to_char = {v:k for k, v in char_to_id.items()}\nprint(char_to_id)\nprint(id_to_char)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(max_length)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Define dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"class NamesDataset(Dataset):\n    \n    def __init__(self, names_list):\n        self.names_list = names_list\n        \n    def __len__(self):\n        return len(self.names_list)\n    \n    def __getitem__(self, idx):\n        x_str = self.names_list[idx].ljust(max_length, \".\")[:max_length]\n        y_str = x_str[1:] + \".\"\n        \n        x = torch.zeros((max_length, num_chars))\n        y = torch.zeros(max_length)\n        for i, c in enumerate(x_str):\n            x[i, char_to_id[c]] = 1\n        for i, c in enumerate(y_str):\n            y[i] = char_to_id[c]\n            \n        return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"trainset = NamesDataset(names_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Define dataloader"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_batch_size = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cpu_count = os.cpu_count()\nprint(cpu_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_loader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=cpu_count)\nprint(len(train_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_iter = iter(train_loader)\nX, Y = train_iter.next()\nprint(X.size(), Y.size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Define model"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_size = num_chars\nhidden_size = 54\noutput_size = num_chars\nnum_layers = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice = torch.device(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self, input_size, hidden_size, output_size, num_layers):\n        super(Model, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        self.fc3 = nn.Linear(output_size, output_size)\n        \n    def forward(self, X, states):\n        ht, ct = states\n        batch_size = X.size(0)\n        out, (ht, ct) = self.lstm1(X, (ht, ct))\n        out = F.relu(self.fc2(out))\n        out = self.fc3(out)\n        return out, (ht, ct) # out: Size([batch_size, max_length, num_chars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = Model(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers)\nmodel = nn.DataParallel(model)\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#list(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ht = torch.zeros((num_layers, train_batch_size, hidden_size)).to(device)\nct = torch.zeros((num_layers, train_batch_size, hidden_size)).to(device)\n#writer.add_graph(model, (X, (ht, ct)))\n#writer.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#summary(model, input_size=(max_length, num_chars))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Set optimizer"},{"metadata":{"trusted":false},"cell_type":"code","source":"lr = 0.005\nstep_size = len(train_loader) * 1\ngamma = 0.95\nprint(step_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(reduction='mean')\noptimizer = optim.Adam(model.parameters(), lr=lr)\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=step_size, gamma=gamma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Define sampler"},{"metadata":{"trusted":false},"cell_type":"code","source":"def generate_name(model, start='a', k=5):\n    \n    if len(start) >= max_length:\n        return name\n    \n    with torch.no_grad():\n        \n        ht = torch.zeros((num_layers, 1, hidden_size)).to(device)\n        ct = torch.zeros((num_layers, 1, hidden_size)).to(device)\n        length = 0\n        name = start\n        \n        for char in start:\n            X = torch.zeros((1, 1, num_chars)) # [batch_size, timestep, num_chars]\n            X[0, 0, char_to_id[char]] = 1\n            out, (ht, ct) = model(X, (ht, ct))\n            length += 1\n        vals, idxs = torch.topk(out[0], k) # 0 -> first eg in a batch\n        idx = np.random.choice(idxs.cpu().numpy()[0]) # 0 -> first...\n        char = id_to_char[idx]\n        vals, idxs = torch.topk(out[0], k) # 0 -> first eg in a batch\n        idx = np.random.choice(idxs.cpu().numpy()[0]) # 0 -> first...\n        char = id_to_char[idx]\n        \n        while char != \".\" and length <= max_length-1:\n            X = torch.zeros((1, 1, num_chars)) # [batch_size, timestep, num_chars]\n            X[0, 0, char_to_id[char]] = 1\n            out, (ht, ct) = model(X, (ht, ct))\n            vals, idxs = torch.topk(out[0], k) # 0 -> first eg in a batch\n            idx = np.random.choice(idxs.cpu().numpy()[0]) # 0 -> first...\n            char = id_to_char[idx]\n            length += 1\n            name += char\n    \n        if name[-1] != \".\":\n            name += \".\"\n    \n    return name","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def sampler(model, start='a', n=10, k=5, only_new=False):\n    \n    names = []\n    cnt = 0\n    while cnt <= n:\n        name = generate_name(model=model, start=start, k=k)\n        if only_new: \n            if name not in names_list and name not in names:\n                names.append(name)\n                cnt += 1\n        else:\n            if name not in names:\n                names.append(name)\n                cnt += 1\n    names = [name[:-1].title() for name in names]\n    \n    return names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 9. Train model"},{"metadata":{"trusted":false},"cell_type":"code","source":"epochs = 50\nprint_every_n_epochs = epochs // 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"epoch_losses = []\nepoch_lrs = []\niteration_losses = []\niteration_lrs = []\n\nfor epoch in tqdm(range(1, epochs+1), desc=\"Epochs\"):\n    epoch_loss = 0\n    epoch_lr = 0\n    \n    for i, (X, Y) in tqdm(enumerate(train_loader, 1), total=len(train_loader), desc=\"Epoch-{}\".format(epoch)):\n    #for i, (X, Y) in enumerate(train_loader, 1):\n        X, Y = X.to(device), Y.to(device)\n        \n        ht = torch.zeros((num_layers, X.size(0), hidden_size)).to(device)\n        ct = torch.zeros((num_layers, X.size(0), hidden_size)).to(device)\n\n        optimizer.zero_grad()\n        Y_pred_logits, (ht, ct) = model(X, (ht, ct))\n        Y_pred_logits = Y_pred_logits.transpose(1, 2) # Check Loss Doc: [N, d1, C] -> [N, C, d1]\n        loss = criterion(Y_pred_logits, Y.long())\n        loss.backward(retain_graph=True)\n        optimizer.step()\n        lr_scheduler.step()\n        \n        iteration_losses.append(loss.item())\n        iteration_lrs.append(lr_scheduler.get_lr()[0])\n        epoch_loss += loss.item()\n        epoch_lr += lr_scheduler.get_lr()[0]\n        \n    epoch_loss /= len(train_loader)\n    epoch_lr /= len(train_loader)\n    epoch_losses.append(epoch_loss)\n    epoch_lrs.append(epoch_lr)\n    \n    if epoch % print_every_n_epochs == 0:    \n        message = \"Epoch:{}    Loss:{}    LR:{}\".format(epoch, epoch_loss, epoch_lr)\n        print(message)\n        names = sampler(model, start='jo', n=10, k=10, only_new=False)\n        print(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 8))\nax1.plot(epoch_losses, marker=\"o\", markersize=5)\nax1.set_title(\"Loss\")\nax2.plot(epoch_lrs, marker=\"o\", markersize=5)\nax2.set_title(\"LR\")\nplt.xlabel(\"Epochs\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 8))\nax1.plot(iteration_losses[::])\nax1.set_title(\"Loss\")\nax2.plot(iteration_lrs[::])\nax2.set_title(\"LR\")\nplt.xlabel(\"Iterations\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"window = 100\nplt.figure(figsize=(15, 4))\npd.Series(iteration_losses).rolling(window=window).mean().iloc[window-1:].plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"path = os.path.join(\"/kaggle\", \"working\", \"classifier.pth\")\ntorch.save(model.state_dict(), path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 10. Generate new baby names"},{"metadata":{"trusted":false},"cell_type":"code","source":"path = os.path.join(\"/kaggle\", \"working\", \"classifier.pth\")\nmodel = Model(input_size=num_chars, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers)\nmodel = nn.DataParallel(model)\nmodel.load_state_dict(torch.load(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='indi', n=10, k=5, only_new=True)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='herb', n=10, k=5, only_new=False)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='su', n=10, k=5, only_new=True)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='vis', n=10, k=5, only_new=True)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='a', n=10, k=3, only_new=True)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='a', n=10, k=8, only_new=True)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='a', n=10, k=15, only_new=True)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"names = sampler(model, start='jam', n=10, k=2, only_new=False)\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":1}