{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regressão - Preço de Venda da Casa\n\nEste notebook realiza um estudo, um conjunto de experimentos, de algoritmos de regressão sobre o dataset [House Sales in King County, USA](https://www.kaggle.com/harlfoxem/housesalesprediction). Um conjunto de dados que reúne mais de 21 mil casas e 21 atributos, tais como preço, número de quartos, número de banheiros, andares, nota da casa, entre outros. Nosso objetivo é predizer o valor de uma casa baseado nas características da casa.\n\n> Conteúdo voltado para iniciantes na área de Aprendizado de Máquina e Ciência de Dados!\n\n<a id=\"top\"></a>\n\n## Conteúdo\n\n> **Nota**. Alguns códigos foram ocultados a fim de facilitar a leitura e dar destaque para os conteúdos mais importantes.\n\nO notebook está organizado como segue:\n\n- [Dados](#data) - Carregamento dos dados, pré-processamento.\n- [Visualização](#visual) - Análise exploratória dos dados.\n- [Regressão](#regression) - Aplicação de algoritmos de Aprendizado de Máquina.\n    - [KNN Regressor](#knn) - Regressão com k-NN.\n    - [Regressão Linear](#reg) - Regressão com Regressão Linear.\n    - [Support Vector Machines](#svm) - Regressão com Support Vector Machines.\n    - [Árvore de Decisão](#decision) - Regressão com Decision Tree.\n    - [Random Forest](#forest) - Regressão com Random Forest.\n    - [Bagging](#bagging) - Regressão com estratégia de Bagging.\n    - [Ensemble](#ensemble) - Regressão com estratégia de Ensemble.\n    - [AutoML](#automl) - Regressão com Automated Machine Learning."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install auto-sklearn==0.12.0\n!pip install scikit-learn==0.23.2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"data\"></a>\n\n-----\n\n# Dados\n\nEsta seção reúne um conjunto de código para carregamento e pré-processamento sobre os dados.\n\n[Voltar para o Topo](#top)\n"},{"metadata":{},"cell_type":"markdown","source":"## Carregamento dos Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# processamento de dados, algebra linear\nimport numpy as np \nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# imprime os arquivos\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seleção dos Dados\n\nNesta seção observamos os dados e selecionamos apenas aqueles que são interessantes para os modelos de regressão. Além disso, não será proposto nenhum _feature engineer_ para enriquecimento dos dados ou tratamendo dos dados."},{"metadata":{},"cell_type":"markdown","source":"**Descrição dos Dados**\n\n[Column defintions - Nova19](https://www.kaggle.com/harlfoxem/housesalesprediction/discussion/207885)\n\n- id - ID unico para cada casa. _(remover)_\n- date - Data da casa a venda. _(remover)_\n- price - Preço da cada.\n- bedrooms - Número de quartos.\n- bathrooms - Número de banheiros, no qual .5 conta como lavabo.\n- sqft_living - M2 do espaço interior.\n- sqft_lot - M2 do espaço do terreno.\n- floors - Número de andares.\n- waterfront - Tem vista para o mar (1) ou não (0). (categórico)\n- view - Valor de 0 a 4 informando se a vista é boa. (categórico)\n- condition - Valor de 1 a 5 sobre a condição da casa. (categórico)\n- grade - Nota de 1 a 13, no qual 1-3 pequenas construções, 7 construção e desing mediano, e 11-13 para construções de alto nível.\n- sqft_above - M2 do interior da casa, acima do nível do solo.\n- sqft_basement - M2 do interior da casa, abaixo do nível do solo.\n- yr_built - Ano de construção da casa.\n- yr_renovated - Último ano de renovação da casa. _(remover)_\n- zipcode - CEP da residência. _(remover)_\n- lat - Latitude.\n- long - Longitude.\n- sqft_living15 - M2 do espaço interno para os 15 vizinhos mais próximos.\n- sqft_lot15 - M2 do terreno para os 15 vizinhos mais próximos."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_remove = ['id', 'date', 'yr_renovated', 'zipcode']\ndf = df.drop(columns_to_remove, axis=1)\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizando a estatística descritiva dos imóveis a venda."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"lines, columns = df.shape\nprint('linhas :', lines)\nprint('colunas:', columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conjunto de Treinamento e Teste\n\nNesta seção vamos separa os valores de `X` e `Y`, em seguida normalizar os valores de `X`, por fim, separar entre conjunto de dados de treinamento e teste.\n\n> A normalização se faz necessária, pois alguns algoritmos se beneficiam de valores normalizados, tal como o K-NN."},{"metadata":{"trusted":true},"cell_type":"code","source":"# recupera os valores (X), e as classes (Y)\nX = df.drop('price', axis=1)\nY = df['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalização dos Dados\n\nNesta seção vamos utilizar a normalização [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Esta função de preprocessamento normaliza os dados conforme segue: \n\n$$x_{new} = \\frac{(x - \\overline{x})}{\\sigma}$$\n\nOu seja, o novo valor $x_{new}$ é resultado da normalização do $x$, utilizando a média $\\overline{x}$ e o desvio padrão $\\sigma$."},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalizador\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalização dos dados\nmin_max_scaler = StandardScaler()\nX = min_max_scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conjuntos de Dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# treinamento, test split\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=26)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('treinamento:', len(y_train))\nprint('teste      :', len(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"visual\"></a>\n\n-----\n\n# Visualização dos Dados\n\nEsta seção reúne um conjunto de visualizações sobre os dados.\n\n[Voltar para o Topo](#top)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualização de dados\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Qual a correlação dos atributos?\n\n`DataFrame.corr()` calcula a correlação de pares de colunas, excluindo `NaN` e valores nulos. Por padrão é computado a [Correlação de Pearson](https://www.statisticssolutions.com/pearsons-correlation-coefficient/), seu coeficiente de correlação mede a relação estatística, ou associação, entre duas variáveis contínuas. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# extraí a correlação dos dados\ncorr = df.corr(method='pearson')\n\n# heatmap - gráfico de calor\nplt.figure(figsize=(11,8))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\nplt.show()\n# print(corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Histograma dos Valores por Atributo"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(10,8))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"regression\"></a>\n\n-----\n\n# Regressão\n\nEsta seção reúne um conjunto de experimentos. Cada subseção é um algoritmo de Aprendizado de Máquina.\n\n\n[Voltar para o Topo](#top)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# métricas\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# variável de resultado final\n# será armazenado o resultado de todos experimentos\nexperiment = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"knn\"></a>\n\n## K-NN Regressor\n\n_(k-Nearest Neighbors)_"},{"metadata":{"trusted":true},"cell_type":"code","source":"# regressor\nfrom sklearn.neighbors import KNeighborsRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = KNeighborsRegressor(n_neighbors=3,metric='euclidean')\nmodel1.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# R Square Error\nr2 = r2_score(y_test,y_pred)\n\n# Mean Absolute Error (MAE)\nmae = mean_absolute_error(y_test,y_pred)\n\n# Mean Square Error (MSE)\nmse = mean_squared_error(y_test,y_pred, squared=True)\n\n# Root Mean Square Error (RMSE)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['KNN'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão KNN Regressor**   \n\nk-NN obteve um R² próximo de 79%, ou seja, representou bem a função de preços.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"reg\"></a>\n\n## Regressão Linear"},{"metadata":{"trusted":true},"cell_type":"code","source":"# regressor\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = LinearRegression()\nmodel2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model2.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Linear Regression'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Regressão Linear**   \n\nRegressão Linear obteve um resultado inferior ao k-NN, com R² de 70%.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"svm\"></a>\n\n## Support Vector Machines (SVM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# regressor\nfrom sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = SVR()\nmodel3.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model3.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['SVM'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Support Vector Machines (SVM)**   \n\nSVM não conseguiu nem atinguir o caso médio, pois seu R² está negativo.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"decision\"></a>\n\n## Árvore de Decisão"},{"metadata":{"trusted":true},"cell_type":"code","source":"# regressor\nfrom sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = DecisionTreeRegressor(random_state=26)\nmodel4.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model4.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Decision Tree'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização\n\nNós conseguimos visualizar a árvore de decisão, como as ramificações ocorreram.   \nÉ muito útil para uma apresentação de negócio, em que você consegue explicar a inteligência induzida.\n\n> Não será apresentado neste notebook, pois a árvore aqui construída é muito grande e demora para ser executada.\n\n- Referência: [Visualize a Decision Tree in 4 Ways with Scikit-Learn and Python](https://mljar.com/blog/visualize-decision-tree/)"},{"metadata":{},"cell_type":"markdown","source":"**Discussão Árvore de Decisão**   \n\nÁrvore de Decisão obteve um resultado similar à Regressão Linear, com R² de 71%.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"forest\"></a>\n\n## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# regressor\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model5 = RandomForestRegressor(n_estimators=100, random_state=26)\nmodel5.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model5.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Random Forest'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Random Forest**   \n\nRandom Forest obteve o melhor resultado até o momento, R² de 88%.   \n\nAlém disso, Random Forests são um dos algoritmos mais utilizados em competições de Aprendizado de Máquina.\n\n> **Nota**. Possui alto custo computacional, pois tem que treinar vários modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"bagging\"></a>\n\n## Bagging\n\nRegressão com estratégia de Bagging, com algoritmo base Decision Tree."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble\nfrom sklearn.ensemble import BaggingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_base = DecisionTreeRegressor(random_state=26)\nmodel6 = BaggingRegressor(base_estimator=model_base, n_estimators=10, random_state=26)\nmodel6.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model6.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Bagging'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Bagging**   \n\nBagging obteve bons resultados, próximo ao Random Forest.   \n\n> **Nota**. Possui alto custo computacional, pois tem que treinar vários modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ensemble\"></a>\n\n## Ensemble\n\nRegressão com estratégia de Ensemble, utilizando os algoritmos Linear Regression e Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble\nfrom sklearn.ensemble import VotingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r1 = LinearRegression()\nr2 = RandomForestRegressor(n_estimators=10, random_state=26)\n\nmodel7 = VotingRegressor([('LR', r1), ('RF', r2)])\nmodel7.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model7.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['Ensemble'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Discussão Ensemble**   \n\nEnsemble obteve bons resultados, próximo ao Bagging.   \n\n> **Nota**. Possui alto custo computacional, pois tem que treinar vários modelos.\n\n-----"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"automl\"></a>\n\n## AutoML\n\nAutomated Machine Learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# automl\nimport autosklearn.regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"automl = autosklearn.regression.AutoSklearnRegressor(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n    tmp_folder='/automl/tmp/',\n    output_folder='/automl/output/',\n)\nautoml.fit(X_train, y_train, dataset_name='housesalesprediction')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Avaliação"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = automl.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2 = r2_score(y_test,y_pred)\nmae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred, squared=True)\nrmse = mean_squared_error(y_test,y_pred, squared=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"experiment['AutoML'] = {'R2':r2, 'MAE':mae, 'MSE':mse, 'RMSE':rmse}\n\nprint('R2  :',r2)\nprint('MAE :',mae)\nprint('MSE :',mse)\nprint('RMSE:',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualização\n\nPodemos ver o modelo ou o ensemble de modelos utilizado no AutoML.\n\n> Para isto, utilize o comando `automl.show_models()`."},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"automl.show_models()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão\n\nPor fim, o melhor algoritmo foi o Random Forest com R² de 88%.   \nAs demais estratégias de ensemble, Bagging e Ensemble, também apresentaram bons resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"# palheta de cores\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = sns.color_palette('Blues_r', as_cmap=True)\npd.DataFrame(experiment).T.style.background_gradient(subset=['R2'], cmap=cm).highlight_max(subset=['R2'], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}