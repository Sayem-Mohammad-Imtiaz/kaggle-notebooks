{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport requests\nimport json\nimport seaborn as sns\nimport re\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Скрипт, целью которого является сбор данных через API NY Times заголовков статей и выдержек за временной промежуток с 1920 по 2020 год:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bag_of_sentence = {}\n\nfor year in range(1921, 2021):\n    bag_of_sentence = []\n    for month in range(1, 13):\n        articles_request = requests.get(f'https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key=kqUfZjUcBrYxAuOcQFteCDFAGCbeMMJm')\n        if articles_request.ok:\n            articles_content = json.loads(articles_request.text)\n            number_of_news_items = len(articles_content['response']['docs'])\n\n            for i in range(number_of_news_items):\n                if 'abstract' in articles_content['response']['docs'][i].keys():\n                    fragment_abstract = articles_content['response']['docs'][i]['abstract']\n                    fragment_headline = articles_content['response']['docs'][i]['headline']['main']\n                    if fragment_abstract or fragment_headline:\n                        fragment = fragment_abstract + ' ' + fragment_headline\n                    bag_of_sentence.append(fragment)\n                    \n    df_bag_of_sentence = pd.DataFrame(data=bag_of_sentence, index=np.full_like(range(len(bag_of_sentence)), year))\n    df_bag_of_sentence = df_bag_of_sentence.reset_index()\n    df_bag_of_sentence.rename(columns={'index': 'year', 0: 'sentence'}, inplace=True)\n    df_bag_of_sentence.to_csv(f'datasets\\df_{year}.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_year = pd.DataFrame()\n\nfor year in range(1920, 2021):\n    df = pd.read_csv(f'/kaggle/input/nyt-articles-data/df_{year}.csv')\n    sentence_year = pd.concat([sentence_year, df])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получили следующий файл, где Year - это год выхода публикации, а Sentence - это объединенные заголовок и выдержка (изображение ниже):\n\n![](https://clip2net.com/clip/m593032/32ae2-clip-53kb.png?nocache=1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_year.drop(columns=['Unnamed: 0'], inplace=True)\nsentence_year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = sentence_year['sentence']\ny = sentence_year['year']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"С целью улучшения качества модели было принято решение разделить временной промежуток на 10 частей:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import KBinsDiscretizer\n\ndiscretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\ny = discretizer.fit_transform(np.array(y).reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение таргета (есть небольшой дисбаланс): "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\n\nsns.distplot(y)\n\nplt.title('Распределение таргета')\nplt.xlabel('Временной промежуток')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Воспользовася TfidfVectorizer для того, чтобы представить текст в векторном виде:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfvec = TfidfVectorizer(min_df = 0.00001, stop_words='english', token_pattern='\\\\b[A-z][A-z][A-z]+\\\\b')\ntfvec.fit(X_train)\n\nX_train_vec = tfvec.transform(X_train)\nX_test_vec = tfvec.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_vec.shape, X_test_vec.shape # 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучим предсказательную модель для дискретных величин, где таргетом будет являться временной промежуток (так как данные достаточно разнородны, то ожидать высокого скора модели не приходится, но мы преследуем другую цель):"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\nmnb_clf = MultinomialNB()\nmnb_clf.fit(X_train_vec, y_train)\n\nmnb_clf.score(X_train_vec, y_train), mnb_clf.score(X_test_vec, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Достанем словарь, на котором обучалась наша модель:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfvec_voc = np.array(sorted(tfvec.vocabulary_.items(), key=lambda x: x[1]))[:, 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Файл **EmotionLookupTable.txt** (http://sentistrength.wlv.ac.uk/ первоначально задумывалось, что воспользуюсь готовым модулем, но он оказался платным) с размеченными словами с позитивным и негативным окрасом, где каждому из слов присуждается численный балл со знаком + или -:"},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion_words = pd.read_csv('../input/emotion-words/EmotionLookupTable.txt', sep='\\t', names=['word', 'score'])\nemotion_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"С помощью данного кода берем наиболее важные слова (основанные на коэффициентах в модели) и считаем по ним neg_score и pos_score по файлу emotion_words."},{"metadata":{"trusted":true},"cell_type":"code","source":"year_scores = {}\n\nind_year = mnb_clf.coef_.shape[0]\n\nfor i in range(ind_year):\n\n    best_words_by_year = pd.DataFrame(data=np.c_[tfvec_voc, mnb_clf.coef_[i]], columns=['word', 'coeff'])\n    best_words_by_year = best_words_by_year.astype({'coeff': 'float64', 'word': 'str'})\n    best_words_by_year = best_words_by_year[best_words_by_year.coeff > np.quantile(best_words_by_year.coeff, 0.99)]\n    str_best_words_by_year = ' '.join(best_words_by_year['word'].unique())\n\n    neg_score = 0\n    pos_score = 0\n\n    for word, score in emotion_words.values:\n\n        if word.endswith('*'):\n            match_pattern = re.search(f'[ ]?\\\\b{word[:-1]}\\\\w+\\\\b', str_best_words_by_year)\n        else:\n            match_pattern = re.search(f'[ ]?\\\\b{word}\\\\b', str_best_words_by_year)\n\n        if match_pattern and score < 0:\n            match_word = match_pattern.group(0)\n            neg_score += abs(score)\n            str_best_words_by_year = str_best_words_by_year.replace(match_word, '')\n        elif match_pattern and score > 0:\n            match_word = match_pattern.group(0)\n            pos_score += score\n            str_best_words_by_year = str_best_words_by_year.replace(match_word, '')\n    \n    year_scores[i] = [neg_score, pos_score]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_scores = np.array(list(year_scores.values()))[:, 0]\npos_scores = np.array(list(year_scores.values()))[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_scores = pd.DataFrame(np.c_[neg_scores / sum(neg_scores) * 100, pos_scores / sum(pos_scores) * 100], columns=['Negative', 'Positive'], index=list(range(1920, 2019, 10)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Построим итоговый график:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nplt.plot(res_scores.index, res_scores['Negative'], color='tab:red', label='Негативный')\nplt.plot(res_scores.index, res_scores['Positive'], color='tab:blue', label='Позитивный')\n\nxtick_labels = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010]\nplt.xticks(ticks=xtick_labels, rotation=0, fontsize=12, horizontalalignment='center', alpha=.7)\nplt.yticks(fontsize=12, alpha=.7)\nplt.title(\"Информационный фон газеты NY Times\", fontsize=13)\nplt.grid(axis='both', alpha=.3)\n\nplt.gca().spines[\"top\"].set_alpha(0.0)    \nplt.gca().spines[\"bottom\"].set_alpha(0.3)\nplt.gca().spines[\"right\"].set_alpha(0.0)    \nplt.gca().spines[\"left\"].set_alpha(0.3)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_year['size_sentence'] = sentence_year['sentence'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_year.groupby('year')['size_sentence'].agg(['sum']).plot()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}