{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Overview:**\nThe data contains features extracted from the silhouette of vehicles in different angles. \nFour \"Corgie\" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400 cars. \nThis particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily \ndistinguishable, but it would be more difficult to distinguish between the cars.\n\n**Objective:**\nThe purpose is to classify a given silhouette as one of three types of vehicle, using a set of features extracted from the silhouette. \nThe vehicle may be viewed from one of many different angles."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Numerical libraries\nimport numpy as np  \n\n# to handle data in form of rows and columns \nimport pandas as pd  \n\n# preprocessing\nfrom sklearn.preprocessing import StandardScaler\n\n\n#Sklearn package's data splitting function which is based on random function\nfrom sklearn.model_selection import train_test_split\n\n# calculate accuracy measures and confusion matrix\nfrom sklearn import metrics  \n\n# importing ploting libraries\nimport matplotlib.pyplot as plt   \n\n#importing seaborn for statistical plots\nimport seaborn as sns\n\n# Label encoder \nfrom sklearn.preprocessing import LabelEncoder\n\n# Support Vector Classifier\nfrom sklearn.svm import SVC\n\n# PCA Related\nfrom sklearn.decomposition import PCA\n\n# To calculate the accuracy score of the model\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Cross Validation related\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#load the csv file and make the data frame\ndf = pd.read_csv('/kaggle/input/vehicle/vehicle.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\n# 846 rows, 19 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data type and other imp information of each column\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All fields are numeric except class- no need to convert data types\n# There are missing values in many columns like circularity, distance circularity, radius ratio .. etc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore distribution of vehicle in each class\ndf['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cars are almost double in number as compared to bus and van. van is least in number","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encode the target class\nlabelencoder = LabelEncoder()\ndf['class'] = labelencoder.fit_transform(df['class'])\ndf['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1-car\n#0-bus\n#2-van","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pairplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.pairplot(df,diag_kind='kde',hue='class')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inferences:**\n* Spread of compactness is least for van. mean compactness is highest for car. For Bus compactness is right skewed indicating that less number of buses have high compactness.\n* Mean circularity is higher for cars\n* Mean distance_circularity is also higher for cars\n* Mean radius_ratio is higher for cars, followed by Bus. It is least for vans\n* pr.axis_aspect_ratio is has almost same distribution for car, van and buses\n* max.length_aspect_ratio is almost same for cars and vans, lower for buses\n* Mean scatter ratio is highest for cars, followed by bus and van\n* Mean elomngatedness is highest for vans folowed by bus and car\n* pr.axis_rectangularity is highest for cars, followed by bus and then vans\n* distribution of max.length_rectangularity is almost same for cars, bus and vans\n* Mean scaled variance is highest for cars followed by bus then vans\n* Mean scaled variance1 is highest for cars followed by bus then vans\n* 'scaled_radius_of_gyration', 'scaled_radius_of_gyration.1', 'skewness_about', 'skewness_about.1', 'skewness_about.2', have almost similar distribution for cars, buses and vans.\n* 'hollows_ratio' is lower for buses as compared to cars and vans\n* Many columns have lonmg tails indicating outliers\n* pr.axis_aspect ratio and radius ratio varies strongly +ve for van. for cars and buses it varies in small range- mostly cpuld like\n* Scatter ratio & Scaled_variance1 has almost perfect positive linear relationship\n* Many features show high correlation indicating that we need to drop multiple features- we will use PCA for the same"},{"metadata":{},"cell_type":"markdown","source":"### Correlation & Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap\n#Correlation Matrix\ncorr = df.corr() # correlation matrix\nlower_triangle = np.tril(corr, k = -1)  # select only the lower triangle of the correlation matrix\nmask = lower_triangle == 0  # to mask the upper triangle in the following heatmap\n\nplt.figure(figsize = (15,8))  # setting the figure size\nsns.set_style(style = 'white')  # Setting it to white so that we do not see the grid lines\nsns.heatmap(lower_triangle, center=0.5, cmap= 'Blues', annot= True, xticklabels = corr.index, yticklabels = corr.columns,\n            cbar= False, linewidths= 1, mask = mask)   # Da Heatmap\nplt.xticks(rotation = 50)   # Aesthetic purposes\nplt.yticks(rotation = 20)   # Aesthetic purposes\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference from heat map:**\n\nFrom above correlation matrix we can see that there are many features which are highly correlated. if we see carefully then scaled_variance.1 and scatter_ratio has correlation of 1 and many other features are also there which having more than 0.9(positive or negative) correlation e.g sekweness_abou2 and hollows_ratio, scaled variance & scaled_variance1, elongatedness & scaled variance, elongatedness & scaled variance1 etc.\n\nThere are lot of dimensions with correlation above +- 0.7 and it is difficult to determine which dimensions to drop manually. We will use PCA to determine it.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above table it is clear that there are missing values in many columns-circularity,distance_circularity,radius_ratio\nscatter_ratio,elongatedness,pr.axis_rectangularity,scaled_variance,scaled_variance,scaled_radius_of_gyration,scaled_radius_of_gyration.1\nskewness_about,skewness_about.skewness_about.2\t"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Columns having missing values\nmissing_values_cols=df.columns[df.isnull().any()]\n# Number of missing values in each column\ndf[missing_values_cols].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#List all the rows having missing value in any of the single or multiple columns\n\ndf[df.isnull().any(axis=1)][missing_values_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.isnull().any(axis=1)][missing_values_cols].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total 33 rows with missng values in one or more of 14 columns"},{"metadata":{},"cell_type":"markdown","source":"### Missing Values Treatment: \nFind individual row with missing values in each of the columns and then we will make decision on whether to drop or notÂ¶"},{"metadata":{},"cell_type":"markdown","source":" #### Missing Treatment Values for circularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['circularity'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5 rows have missing vales for circularity. one of the 5 rows alsq has missing value for distance_circularity. \n# Another row has missing values for scaled valiance and skewness_about.1. One of the row has missing value for scaled_radius_of_gyration.\n# We will drop those rows which has missing value in any other coulmn as well apart from circularity which is 3. \n# will impute missing value in rest 2 rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Row 105,118,266 has missing values in more than 1 column. drop those\ndf.drop([105,118,266], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets Check the class level of remaining 2 rows- we will replace the value with median value of the corresponding class\ndf.loc[5].loc['class'],df.loc[396].loc['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Belong to Bus Class\nMedian_circularity_bus=df['circularity'][df['class']==0].median()\nMedian_circularity_bus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['circularity'].fillna(Median_circularity_bus, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Douple Check if missing values have been teated for curcularity\ndf[df['circularity'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing value for Circularity treated","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for distance_circularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['distance_circularity'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3 rows have missing values. row 207 has missing  values in more than 1 column- we will drop this\n# row 35, 319 have missing values in just one column, We will fill it woth median of the corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(207, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets Check the class lavel of remeining 2 rows- we will replace the value with median value of the corresponding class\ndf.loc[35].loc['class'],df.loc[319].loc['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_circularity_van=df['distance_circularity'][df['class']==2].median()\nMedian_distance_circularity_bus=df['distance_circularity'][df['class']==0].median()\nMedian_distance_circularity_van,Median_distance_circularity_bus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[35]=df.loc[35].replace(np.nan,Median_distance_circularity_van)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[319]=df.loc[319].replace(np.nan,Median_distance_circularity_bus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[35,319]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Double Check if missing values have been handled\ndf[df['distance_circularity'].isnull()][missing_values_cols]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing values handled for dian_distance_circularity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for radius_ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['radius_ratio'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For all the rows with missing radius_ratio only radius ratio is having missing values all the other columns have values.\n# We will not drop any rather replace with median of corresponding class.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[9,78,159,287,345,467]]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets find median value for car, bus,van\nMedian_distance_radius_ratio_van=df['radius_ratio'][df['class']==2].median()\nMedian_distance_radius_ratio_bus=df['radius_ratio'][df['class']==0].median()\nMedian_distance_radius_ratio_car=df['radius_ratio'][df['class']==1].median()\nMedian_distance_radius_ratio_van,Median_distance_radius_ratio_bus,Median_distance_radius_ratio_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace rows 9,159 and 467 with car median, 78,345 with bus median and 287 with  van","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[9,159,467]]=df.loc[[9,159,467]].replace(np.nan,Median_distance_radius_ratio_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[9,159,467]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[78,345 ]]=df.loc[[ 78,345 ]].replace(np.nan,Median_distance_radius_ratio_bus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[78,345 ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[287]=df.loc[287].replace(np.nan,Median_distance_radius_ratio_van)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[287]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for pr.axis_aspect_ratio "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['pr.axis_aspect_ratio'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are 2 rows with missing values. One row has missing value in one more column in addityion to pr.axis_aspect_ratio\n# We will drop that row but treat the missing value in pr.axis_aspect_ratio with median of corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop row 222\ndf.drop(222, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[19]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nMedian_distance_pr_axis_aspect_ratio_car=df['pr.axis_aspect_ratio'][df['class']==1].median()\nMedian_distance_pr_axis_aspect_ratio_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[19]=df.loc[19].replace(np.nan,Median_distance_pr_axis_aspect_ratio_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['pr.axis_aspect_ratio'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for scatter_ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scatter_ratio'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only one row and 2 cols have missing value in that row including scatter_ratio\n# we will drop this row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(249, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for elongatednes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['elongatedness'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[215]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_elongatedness_car=df['elongatedness'][df['class']==1].median()\nMedian_distance_elongatedness_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[215]=df.loc[215].replace(np.nan,Median_distance_elongatedness_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['elongatedness'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for pr.axis_rectangularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['pr.axis_rectangularity'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3 rows have missing values for pr.axis_rectangularity and only this column has missing value\n# We will replace this with median value of the corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets loom at class level of the missing rows\ndf.loc[[70,237,273]]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_pr_axis_rectangularity_van=df['pr.axis_rectangularity'][df['class']==2].median()\nMedian_distance_pr_axis_rectangularity_car=df['pr.axis_rectangularity'][df['class']==1].median()\nMedian_distance_pr_axis_rectangularity_bus=df['pr.axis_rectangularity'][df['class']==0].median()\nMedian_distance_pr_axis_rectangularity_van,Median_distance_pr_axis_rectangularity_car,Median_distance_pr_axis_rectangularity_bus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[70]=df.loc[70].replace(np.nan,Median_distance_pr_axis_rectangularity_car)\ndf.loc[237]=df.loc[237].replace(np.nan,Median_distance_pr_axis_rectangularity_bus)\ndf.loc[273]=df.loc[273].replace(np.nan,Median_distance_pr_axis_rectangularity_van)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Double Check if missing values have been treated\ndf[df['pr.axis_rectangularity'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for scaled_variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scaled_variance'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 rows have missing values for scaled_variance, no other columns have missing values for these rows. We will replace with median\n# of corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[372,522]]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_scaled_variance_van=df['scaled_variance'][df['class']==2].median()\nMedian_distance_scaled_variance_car=df['scaled_variance'][df['class']==1].median()\nMedian_distance_scaled_variance_van,Median_distance_scaled_variance_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[372]=df.loc[372].replace(np.nan,Median_distance_scaled_variance_van)\ndf.loc[522]=df.loc[522].replace(np.nan,Median_distance_scaled_variance_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scaled_variance'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for scaled_variance.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scaled_variance.1'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 rows have missing values for scaled_variance, no other columns have missing values for these rows. We will replace with median\n# of corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[308,496]]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_scaled_variance1_car=df['scaled_variance.1'][df['class']==1].median()\nMedian_distance_scaled_variance1_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[308,496]]=df.loc[[ 308,496]].replace(np.nan,Median_distance_scaled_variance1_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scaled_variance.1'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Treatment Values for scaled_radius_of_gyration.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scaled_radius_of_gyration.1'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there are 4  rows with scaled_radius_of_gyration.1 as missing values\n# row with index 66 has missing values in 2 columns- will be dropped\n# Other 3 rows missing values will be replaced with median value of cotresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop row 66\ndf.drop(66, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[77,192,329]]['class']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_radius_gyr1_car=df['scaled_radius_of_gyration.1'][df['class']==1].median()\nMedian_distance_radius_gyr1_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[77,192,329]]=df.loc[[ 77,192,329]].replace(np.nan,Median_distance_radius_gyr1_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['scaled_radius_of_gyration.1'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Values Treatment for skewness_about"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['skewness_about'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3 rows have missing values  in skewness_about column , no other column has missing value for these rows. \n# we will replace these values with median of the corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[141,177,285]]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_skewness_about_car=df['skewness_about'][df['class']==1].median()\nMedian_distance_skewness_about_bus=df['skewness_about'][df['class']==0].median()\nMedian_distance_skewness_about_car,Median_distance_skewness_about_bus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[141,177]]=df.loc[[141,177]].replace(np.nan,Median_distance_skewness_about_bus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[285]]=df.loc[[285]].replace(np.nan,Median_distance_skewness_about_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['skewness_about'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Values Treatment for skewness_about.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['skewness_about.1'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  No longer Missing values- corresponding row\n#has been dropped while treating other missing values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Missing Values Treatment for skewness_about.2"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['skewness_about.2'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One row has missing value for skewness_about.2 and no other value is missing for that row\n# Lets replace that value with median of the corresponding class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[419]['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Median_distance_skewness_about2_car=df['skewness_about.2'][df['class']==1].median()\nMedian_distance_skewness_about2_car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[[419]]=df.loc[[419]].replace(np.nan,Median_distance_skewness_about2_car)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['skewness_about.2'].isnull()][missing_values_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Frame Summary Statistics after missing values treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Only 7/846 rows i.e 0.8 % record has been dropped -should be okay"},{"metadata":{},"cell_type":"markdown","source":"### Outlier Treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into train and test set. Outlier treatment will be done only on train set\n# We will divide into feature and target set during PCA and model building","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split into Train -Test set\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random number seeding for reapeatability of the code\ndf_train, df_test= train_test_split(df, test_size=test_size, random_state=seed)\ndf_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## function to find outliers and quantile values.\n# We will analyse each of the outliers and follow below strategy\n# 1. High outliers if close to max value will be replaced with max value of the corresponding class\n# 2. if high outlier is much above 75 Quantile value- we will drop that row from our analysis\n# 3. Low outlier if close to min value will be replaced by min value of the corresponding class\n# 4. low outlier if much lower than 25 quantile value will be dropped fromm analysis\n\ndef handleOutlier(aSeries):\n    \n    q1 = aSeries.quantile(0.25)\n    q3 = aSeries.quantile(0.75)\n   \n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    outliers_low = aSeries[(aSeries < fence_low)]\n    outliers_high= aSeries[(aSeries > fence_high)]\n    \n    print (\"25th Quantile value: \", q1)\n    print('Outlier low Count =', outliers_low.count())\n    print('List of Low outliers: \\n')\n    print(outliers_low)\n\n    print (\"75th Quantile value: \", q3)\n    print('Outlier High Count = ', outliers_high.count())\n    print('List of High outliers: \\n')\n    print(outliers_high)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Compactness"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['compactness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['compactness'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"handleOutlier(df_train['compactness'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see the complete row\ndf_train.loc[[44]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#class is car. Lets observe few rows with class car- in terms of max values as it is high outlier\ndf_train[df_train['class']==1]['compactness'].sort_values( ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are values like 117,116 so we will not treat this outlier. 119 does not seem to be do far.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Circularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['circularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['circularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can see that there are no outliers in circularity"},{"metadata":{},"cell_type":"markdown","source":"#### Distance Circularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['distance_circularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['distance_circularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nFrom above we can see that there are no outliers in distance_circularity column but in distribution plot we can see that there are two peaks and we can see that there is right skewness because long tail is at the right side(mean>median)"},{"metadata":{},"cell_type":"markdown","source":"#### radius_ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['radius_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['radius_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are certain outliers on the right side( high ouliers).Lets analyse them and make decision on their treatment\n handleOutlier(df_train['radius_ratio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full rows for these outliers\ndf_train.loc[[37,135,388]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All these are for class van. Lets observe maximum radius_ratio for class van\ndf_train[df_train['class']==2]['radius_ratio'].sort_values( ascending=False).head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# values of radius ratio for outlier are far away  from the max value 250. Lets replace these values with 250\ndf_train.loc[[37,135,388],'radius_ratio']=250.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Double check the values if replaced correctly\ndf_train.loc[[37,135,388]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#All Done for radius ratio!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### pr.axis_aspect_ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['pr.axis_aspect_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['pr.axis_aspect_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here are many high outliers. Lets observe each of them and treat them"},{"metadata":{"trusted":true},"cell_type":"code","source":" handleOutlier(df_train['pr.axis_aspect_ratio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full rows for these outliers\ndf_train.loc[[4,37,135,291,388,523,706]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index 4  belongs to class Bus while others belong to class van. Lets observe max values of this column for\n#both bus and van","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets Check for Bus first\ndf_train[df_train['class']==0]['pr.axis_aspect_ratio'].sort_values( ascending=False).head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For bus we can see values around 75 and max value 76. It is better to drop this row as the values 103 is\n#significantly higher","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(4, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets Check for van now first\ndf_train[df_train['class']==2]['pr.axis_aspect_ratio'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##From 72 to 97 it is big jump in value and then other outlier values are even higher upto 138. It is better to drop \n#these rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop([37,135,291,388,523,706], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### max.length_aspect_ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['max.length_aspect_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['max.length_aspect_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" handleOutlier(df_train['max.length_aspect_ratio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full rows for these outliers\ndf_train.loc[[391,127,815,544]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# row with index 391 is for van and others are for bus. lets observe max values as ouliers are hgh in nature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets Check for van now first\ndf_train[df_train['class']==2]['max.length_aspect_ratio'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Outlier is double the max value which is 12. better drop this row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(391, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets Check for bus now\ndf_train[df_train['class']==0]['max.length_aspect_ratio'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Again for bus max length aspect ratio is 8 and Junp from 8 to 19/22 is too high. Lets drop this outlier from train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop([127,815,544], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Scatter Ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['scatter_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['scatter_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outlier in scatter ratio"},{"metadata":{},"cell_type":"markdown","source":"#### elongatedness"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['elongatedness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['elongatedness'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outlier in elongetdness"},{"metadata":{},"cell_type":"markdown","source":"#### pr.axis_rectangularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['pr.axis_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['pr.axis_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outlier in pr_axis_rectangularity"},{"metadata":{},"cell_type":"markdown","source":"#### max.length_rectangularity"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['max.length_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['max.length_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outlier in max.length_rectangularity"},{"metadata":{},"cell_type":"markdown","source":"#### scaled_variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['scaled_variance'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['scaled_variance'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outlier in scaled_variance"},{"metadata":{},"cell_type":"markdown","source":"#### scaled_variance.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['scaled_variance.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['scaled_variance.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is one outlier in scaled_Variance.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"handleOutlier(df_train['scaled_variance.1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full row for this outliers\ndf_train.loc[[85]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The outlier belongs to class car. Lets observe max values as it is high outlier\ndf_train[df_train['class']==0]['scaled_variance.1'].sort_values( ascending=False).head(8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are values in contnuity like 982,987, 962 hence 998 does not look very high. We will leave this outlier as is.\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### scaled_radius_of_gyration.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['scaled_radius_of_gyration.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['scaled_radius_of_gyration.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" lot of high outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":" handleOutlier(df_train['scaled_radius_of_gyration.1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full row for this outliers\ndf_train.loc[[687,734,492,834,515,351,41,231,232,160,553,79,568,612,230,655,420,463,790,47,381]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full row for this outliers for class Bus\ndf_train.loc[[687,734,492,834,515,351,41,231,232,160,553,79,568,612,230,655,420,463,790,47,381]][df_train['class']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The outlier belongs to class car. Lets observe max values as it is high outlier\ndf_train[df_train['class']==0]['scaled_radius_of_gyration.1'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Values ouliers for buses are almost in range of max. We will neithr delete them nor replace them-leave as is","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full row for this outliers for class van\ndf_train.loc[[687,734,492,834,515,351,41,231,232,160,553,79,568,612,230,655,420,463,790,47,381]][df_train['class']==2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The outliers belong to class van. Lets observe max values as it is high outlier\ndf_train[df_train['class']==2]['scaled_radius_of_gyration.1'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Values ouliers for vans are almost in range of max. We will neither delete them nor replace them-leave as is","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets observe full row for this outliers for class car\ndf_train.loc[[687,734,492,834,515,351,41,231,232,160,553,79,568,612,230,655,420,463,790,47,381]][df_train['class']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The outlier belongs to class car. Lets observe max values as it is high outlier\ndf_train[df_train['class']==1]['scaled_radius_of_gyration.1'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Values ouliers for cars are almost in range of max. We will neither delete them nor replace them-leave as is","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### skewness_about"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['skewness_about'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['skewness_about'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No outlier in skewness_about field"},{"metadata":{},"cell_type":"markdown","source":"#### skewness_about.1"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['skewness_about.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['skewness_about.1'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is one high outlier"},{"metadata":{"trusted":true},"cell_type":"code","source":" handleOutlier(df_train['skewness_about.1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets observe the full row of the outlier\ndf_train.loc[[132]]\n# Outlier belongs to class 1 that is car","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Lets observe max values for car class\ndf_train[df_train['class']==1]['skewness_about.1'].sort_values( ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Value is well in range of max value of skewness_about.1 for cars. we will not delete or replace it"},{"metadata":{},"cell_type":"markdown","source":"#### skewness_about.2"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['skewness_about.2'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['skewness_about.2'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outliers for skewness_about.2"},{"metadata":{},"cell_type":"markdown","source":"#### hollows ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df_train['hollows_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df_train['hollows_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Outliers for hollows_ratio"},{"metadata":{},"cell_type":"markdown","source":"### Final shape and statistic of train set after missing values and outlier treatmen"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA & Dimensionality Reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide train and test set into feature and target sets\nX_train=df_train.drop(labels='class', axis=1)\ny_train=df_train['class']\nX_test=df_test.drop(labels='class', axis=1)\ny_test=df_test['class']\nX_train.shape,y_train.shape, X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc.fit(X_train) # Fit scaler in train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform train set\n#Transform X_train\nX_train_std=sc.transform(X_train)\n#Transform X_test ( with same fit as train) to prevent data leak\nX_test_std=sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Covariance Matrix\ncov_matrix = np.cov(X_train_std.T)\n\nprint('Covariance Matrix \\n%s', cov_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\nprint('Eigen Vectors \\n%s', eig_vecs)\nprint('\\n Eigen Values \\n%s', eig_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Eigen Values:\")\npd.DataFrame(eig_vals).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tot = sum(eig_vals)\nvar_exp = [( i /tot ) * 100 for i in sorted(eig_vals, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)   # array of size =  as many PC dimensions\nprint(\"Cumulative Variance Explained\", cum_var_exp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ploting \nplt.figure(figsize=(15 , 6))\nplt.bar(range(1, eig_vals.size + 1), var_exp, alpha = 0.5, align = 'center', label = 'Individual explained variance')\nplt.step(range(1, eig_vals.size + 1), cum_var_exp, where='mid', label = 'Cumulative explained variance')\nplt.ylabel('Explained Variance Ratio')\nplt.xlabel('Principal Components')\nplt.legend(loc = 'best')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" First 8 principal components explain 98% of the variance in the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a set of (eigenvalue, eigenvector) pairs\neig_pairs = [(eig_vals[index], eig_vecs[index]) for index in range(len(eig_vals))]\n\n# Sort the (eigenvalue, eigenvector) pairs from highest to lowest with respect to eigenvalue by default take first field for sorting\neig_pairs.sort(reverse=True)\n\n\n# Note: always form pair of eigen vector and values  first before sorting...\n\n# Extract the descending ordered eigenvalues and eigenvectors\neigvalues_sorted = [eig_pairs[index][0] for index in range(len(eig_vals))]\neigvectors_sorted = [eig_pairs[index][1] for index in range(len(eig_vals))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dimesionality reduction \n\nP_reduce = np.array(eigvectors_sorted[0:8]).transpose()   # Selecting first 8 eigen vector out if 18\n\nProj_train_data = np.dot(X_train_std,P_reduce)   # projecting training data onto the eight eigen vectors\n\nProj_test_data = np.dot(X_test_std,P_reduce)    # projecting test data onto the eight eigen vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check shapes of train and test new feature and target set after PCA\nProj_train_data.shape,y_train.shape,Proj_test_data.shape,y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling,Hyperparameter tuning & Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"With Linear Kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use SVM\n\nfrom sklearn.svm import SVC\n\n# Building a Support Vector Machine on train data\nsvc_model = SVC(C= .1, kernel='linear', gamma= 1)\nsvc_model.fit(Proj_train_data, y_train)\n\nprediction = svc_model.predict(Proj_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the accuracy on the training set\nprint(svc_model.score(Proj_train_data, y_train))\nprint(svc_model.score(Proj_test_data, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Confusion Matrix:\\n\",confusion_matrix(prediction,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With Rbf"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a Support Vector Machine on train data\nsvc_model = SVC(kernel='rbf')\nsvc_model.fit(Proj_train_data, y_train)\n\nprediction = svc_model.predict(Proj_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(svc_model.score(Proj_train_data, y_train))\nprint(svc_model.score(Proj_test_data, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Confusion Matrix:\\n\",confusion_matrix(prediction,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyper Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#With Hyper Parameters Tuning\n#2-3,SVM\n#importing modules\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\n#making the instance\nmodel=svm.SVC()\n#Hyper Parameters Set\nparams = {'C': [0.01, 0.05, 0.5, 1], \n      #    'gamma':[0.01, 0.02 , 0.03 , 0.04, 0.05],\n          'kernel': ['linear','rbf']}\n#Making models with hyper parameters sets\ngs = GridSearchCV(model, param_grid=params, n_jobs=-1,cv=10)\n#Learning\ngs.fit(Proj_train_data,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The best hyper parameters set\nprint(\"Best Hyper Parameters:\\n\",gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*K-fold cross validation( On train set using tuned Hyper parameter i.e gs*"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_folds = 10\nseed = 7\n\nkfold = KFold(n_splits=num_folds, random_state=seed)\nmodel = gs\nresults = cross_val_score(gs,Proj_train_data,y_train, cv=kfold)\nprint(results)\nprint(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.hist(results,normed= True)\nsns.distplot(results,kde=True,bins=10)\nplt.xlabel(\"Accuracy\")\nplt.show()\n# confidence intervals\nalpha = 0.95                             # for 95% confidence \np = ((1.0-alpha)/2.0) * 100              # tail regions on right and left .25 on each side indicated by P value (border)\nlower = max(0.0, np.percentile(results, p))  \np = (alpha+((1.0-alpha)/2.0)) * 100\nupper = min(1.0, np.percentile(results, p))\nprint('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Accuracy with Hypertuned parameter "},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=gs.predict(Proj_test_data)\nprint(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))\n#evaluation(Confusion Metrix)\nprint(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test,prediction))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the confusion matrix, model predicts all the vans correctly through Silhoutte(100%) 59/62 buses are predicted correctly(95 %) 129/138 cars are predicted correctyy(93.5%)\n\nTest Accuracy(95.64%) is well in range of 95% confidence interval(86.8% to 99.6%)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}