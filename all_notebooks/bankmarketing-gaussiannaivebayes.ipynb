{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Understanding The Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/bank-marketing/bank-additional-full.csv', sep = ';')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values in the dataset. On the other hand, there are some categorical variables.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Cleaning The Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.rename(columns={'y': 'subscribed'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will check duplicated values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.duplicated().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 12 duplicated values in the dataset. Let's see which data points are duplicated.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset[dataset.duplicated(keep=False)].iloc[:,:7])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will drop duplicated values from the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\033[1mNULL VALUES\\033[0m\\n'+ str(dataset.isnull().values.any()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no null values in the dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3. Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There is a graphic below who subscribe a term deposit or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Subscribed = pd.DataFrame(dataset['subscribed'].value_counts())\nprint(Subscribed.T)\npd.DataFrame(dataset['subscribed'].value_counts()).plot(kind='bar', color='lightgreen')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most people do not subscribe to a term deposit.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,4))\n\nplt.subplot(1,4,1)\nsns.distplot(dataset['age'])\nplt.title('Age Distribution')\n\nplt.subplot(1,4,2)\nsns.countplot(dataset['job'])\nplt.title('Job Distribution')\nplt.xticks(rotation=90)\n\nplt.subplot(1,4,3)\nsns.countplot(dataset['marital'], color='pink')\nplt.title('Marital Status')\n\nplt.subplot(1,4,4)\nsns.countplot(dataset['education'], color='lightgreen')\nplt.xticks(rotation=90)\nplt.title('Education Level')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most people are generally between 20 - 40 years old. Few people are above 60 years old. \n* Most people are administrator, technician or blue-collar workers.\n* Most people are married.\n* Most people have university degree.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,3,1)\nsns.countplot(dataset['default'], palette=\"Set3\")\nplt.title('Default Credit')\n\nplt.subplot(1,3,2)\nsns.countplot(dataset['housing'], palette=\"Set3\")\nplt.title('Housing Loan')\n\nplt.subplot(1,3,3)\nsns.countplot(dataset['loan'], palette=\"Set3\")\nplt.title('Loan')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most people have no credit in default, while almost none of people have credit.\n* The number of people who have housing loan are higher than people who have no housing loan.\n* Most people have no personal loan. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,5))\n\nplt.subplot(1,4,1)\nsns.countplot(dataset['contact'], palette=\"vlag\")\nplt.title('Contact Type')\n\nplt.subplot(1,4,2)\nsns.countplot(dataset['month'], palette=\"vlag\",order = ['mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\nplt.title('Month')\nplt.xticks(rotation=90)\n\nplt.subplot(1,4,3)\nsns.countplot(dataset['day_of_week'], palette=\"vlag\")\nplt.title('Day Of Week')\n\nplt.subplot(1,4,4)\nsns.distplot(dataset['duration'])\nplt.xticks(rotation=90)\nplt.title('Duration of Calls')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Customers were contacted almost everyday. It doesn't convey extra infrmation, that's why I will 'drop day_of_week' from the dataset.\n\n* Most people are reached from cellular phones.\n* In may, most calls are made.\n* Duration of calls are generally between 0 - 1000 sn.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop('day_of_week', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.violinplot(\"contact\", \"campaign\", data=dataset, kind='reg')\nplt.title('Number of Contacts vs Contact Type')\n\nplt.subplot(1,2,2)\nsns.distplot(dataset['campaign'])\nplt.title('Number of Contacts with Customers')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of contacts performed during this campaign and for this client are higher with telephone. On the other hand, the number of contacts is around 0-10 range.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,3,1)\nsns.countplot(dataset['pdays'])\nplt.xticks(rotation=90)\nplt.title('Number of Days Passed Since Previous Campaign')\n\nplt.subplot(1,3,2)\nsns.countplot(dataset['previous'])\nplt.title('Number of Previous Contacts')\n\nplt.subplot(1,3,3)\nsns.countplot(dataset['poutcome'])\nplt.title('Previous Campaign Result')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* \"pdays\" show the number of days that passed by after the client was last contacted from a previous campaign (999 means client was not previously contacted). Graphic tells us that almost all of the customers were not contacted for previous campaign. I will change this variable as previously contacted or not, since most of the clients were not previously contacted. \n\n* The number of previous contacts graphic shows that most people were not contacted previously. That's why previous campaign results do not exist for some customers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.loc[dataset['pdays'] < 999, 'pdays'] = 1\ndataset.loc[dataset['pdays'] == 999, 'pdays'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.rename(columns={'pdays': 'previouslycontacted', 'previous':'previouscontacts'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will change ages as age group and I will drop age column from the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bins= [0,10,20,30,40,50,60,70,80,90,100]\nlabels = [0,1,2,3,4,5,6,7,8,9]\ndataset.insert(1, 'agegroup', pd.cut(dataset['age'], bins=bins, labels=labels, right=False))\ndataset = dataset.drop('age', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting to numerical values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will convert categorical variables to numerical variables with Label Encoder from Sklearn.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = dataset.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in categorical_columns:\n    dataset[i] = le.fit_transform(dataset[i]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking Normal Distribution","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Gaussian Naive Bayes assumes that the predictors take up a continuous value and are not discrete, and these values are sampled from a gaussian distribution. That's why I will check normal distribution.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = dataset.iloc[:, :-1].values.astype('float')\ny_train = dataset['subscribed'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_train[y_train == 1]).plot(kind='density', ind=100, legend=False)\nplt.title('Subscribed Likelihood Plots')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(X_train[y_train == 0]).plot(kind='density', ind=100, legend=False)\nplt.title('Not Subscribed Likelihood Plots')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data points are not normally distributed. I will apply Standard Scaler to get a more normally distributed dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX_train = pd.DataFrame(StandardScaler().fit_transform(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[y_train == 1].plot(kind='density', ind=100, legend=False)\nplt.title('Subscribed Likelihood Plot after Standardization')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[y_train == 0].plot(kind='density', ind=100, legend=False)\nplt.title('Not Subscribed Likelihood Plot after Standardization')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are values that go as 1,2,3 ... These values will not have perfectly normal distribution even after standardization. However, it gives better distribution.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Checking Correlation Between Features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The correlation between variables are not linear, that's why I will use spearman correlation method.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(dataset.corr(method='spearman'), cbar=True, cmap=\"RdBu_r\")\nplt.title(\"Correlation Matrix\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some highly correlated variables in the dataset. Since Naive Bayes assumes that features are independent of each other, I will drop highly correlated varibles.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = X_train.corr(method='spearman').abs()\nupper = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.40)]\nX_train.drop(X_train[to_drop], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngb = GaussianNB()\ngb.fit(X_train, y_train)\npred = gb.predict(pd.DataFrame(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\ngbprob = gb.predict_proba(X_train)[:,1]\nfpr, tpr, thr = roc_curve(y_train, gbprob)\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic Plot')\nprint(auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\nprint('Accuracy score of Gaussian Naive Bayes:' + str(accuracy_score(y_test,pred)))\nprint('Confusion Matrix\\n' + str(confusion_matrix(y_test, pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model predicted 383 false positives. It means it predicted as the 383 customers subscribe to a term deposit, but actually it is not true. These customers don't subscribe. This number is actually high. The model should not miss this, othervise they do not call the customer again, and lose the customer.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}