{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n\nimport optuna\nfrom sklearn import preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-05T08:48:32.830132Z","iopub.execute_input":"2021-08-05T08:48:32.830745Z","iopub.status.idle":"2021-08-05T08:48:32.837658Z","shell.execute_reply.started":"2021-08-05T08:48:32.83069Z","shell.execute_reply":"2021-08-05T08:48:32.836158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nLet's start by reading the data and perform some basix exploration using some descriptive statistics.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:48:36.665733Z","iopub.execute_input":"2021-08-05T08:48:36.666089Z","iopub.status.idle":"2021-08-05T08:48:36.764433Z","shell.execute_reply.started":"2021-08-05T08:48:36.666058Z","shell.execute_reply":"2021-08-05T08:48:36.763492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of rows: {}, Number of columns = {}'.format(train.shape[0], train.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:49:12.276637Z","iopub.execute_input":"2021-08-05T08:49:12.277037Z","iopub.status.idle":"2021-08-05T08:49:12.282729Z","shell.execute_reply.started":"2021-08-05T08:49:12.277001Z","shell.execute_reply":"2021-08-05T08:49:12.281393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.MonthlyCharges.value_counts()[train.MonthlyCharges.value_counts().index < 19]","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:49:15.151204Z","iopub.execute_input":"2021-08-05T08:49:15.151635Z","iopub.status.idle":"2021-08-05T08:49:15.180373Z","shell.execute_reply.started":"2021-08-05T08:49:15.151601Z","shell.execute_reply":"2021-08-05T08:49:15.179168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's explore the data types of the columsn to make sure that every column has its reasonable and expected data type, For instance, we don't wan't datetyme columns to have a string data type or count to be a string.","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:49:33.57425Z","iopub.execute_input":"2021-08-05T08:49:33.574662Z","iopub.status.idle":"2021-08-05T08:49:33.606818Z","shell.execute_reply.started":"2021-08-05T08:49:33.574626Z","shell.execute_reply":"2021-08-05T08:49:33.60522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(train.TotalCharges[0])\ntrain.TotalCharges = train.TotalCharges.replace(' ', None)\ntrain.TotalCharges = train.TotalCharges.apply(lambda x: float(eval(x)))\ntrain.SeniorCitizen.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:34.757433Z","iopub.execute_input":"2021-08-05T08:51:34.757837Z","iopub.status.idle":"2021-08-05T08:51:34.931454Z","shell.execute_reply.started":"2021-08-05T08:51:34.757803Z","shell.execute_reply":"2021-08-05T08:51:34.929506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tenure.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:39.773019Z","iopub.execute_input":"2021-08-05T08:51:39.773403Z","iopub.status.idle":"2021-08-05T08:51:39.784986Z","shell.execute_reply.started":"2021-08-05T08:51:39.773369Z","shell.execute_reply":"2021-08-05T08:51:39.783572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:41.678985Z","iopub.execute_input":"2021-08-05T08:51:41.679372Z","iopub.status.idle":"2021-08-05T08:51:41.702962Z","shell.execute_reply.started":"2021-08-05T08:51:41.679337Z","shell.execute_reply":"2021-08-05T08:51:41.701501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Outliers Detection\n\nThere are many methods that can be used to detect outliers in a dataset. In this workshop we will discuss the following:\n* Box Plot method\n* Standarization (Z-sore) method\n\n##### Box Plot :: Consists of five main components:\n* Q1, first quartile (Midean of the first half of the data)\n* Q2, Midean of the data\n* Q3, midean of the second half of the data\n* Max value\n* Min value\n\n##### Main equations in box plots:\n$$ IQR = Q3 - Q1 $$\n$$ Outliers = Q3 + 1.5 * IQR$$\n$$ Q1 - 1.5 * IQR $$\n\n##### Z-score method\nZ-score represents the number of standard deviations removed from the mean for each data point. In a simpler way, it is the distance for a point from the mean in standard deviations.\n$$ z-score = {x - mean \\over std} $$","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfig = plt.figure(figsize = (20,10))\nax = fig.gca()\nsns.boxplot(data= train['TotalCharges'], orient=\"h\", palette=\"Set1\", ax = ax)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:50.436011Z","iopub.execute_input":"2021-08-05T08:51:50.436395Z","iopub.status.idle":"2021-08-05T08:51:50.621652Z","shell.execute_reply.started":"2021-08-05T08:51:50.43636Z","shell.execute_reply":"2021-08-05T08:51:50.620541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20,10))\nax = fig.gca()\nsns.boxplot(data= train[['tenure', 'MonthlyCharges']], orient=\"h\", palette=\"Set1\", ax = ax)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:50.679382Z","iopub.execute_input":"2021-08-05T08:51:50.679758Z","iopub.status.idle":"2021-08-05T08:51:50.871383Z","shell.execute_reply.started":"2021-08-05T08:51:50.679725Z","shell.execute_reply":"2021-08-05T08:51:50.870341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats\n\nrows = np.any(stats.zscore(train[['tenure', 'MonthlyCharges', 'TotalCharges']].values) > 2.5, axis=1)\noutliers = train.loc[rows]\noutliers.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:50.930451Z","iopub.execute_input":"2021-08-05T08:51:50.930839Z","iopub.status.idle":"2021-08-05T08:51:50.942575Z","shell.execute_reply.started":"2021-08-05T08:51:50.930807Z","shell.execute_reply":"2021-08-05T08:51:50.941248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(train)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:51.089536Z","iopub.execute_input":"2021-08-05T08:51:51.089905Z","iopub.status.idle":"2021-08-05T08:51:54.62317Z","shell.execute_reply.started":"2021-08-05T08:51:51.089872Z","shell.execute_reply":"2021-08-05T08:51:54.621965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tenure.hist()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:54.625082Z","iopub.execute_input":"2021-08-05T08:51:54.625537Z","iopub.status.idle":"2021-08-05T08:51:54.83526Z","shell.execute_reply.started":"2021-08-05T08:51:54.625493Z","shell.execute_reply":"2021-08-05T08:51:54.834264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.TotalCharges.hist(figsize = (20,20), bins = 1000)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:54.837254Z","iopub.execute_input":"2021-08-05T08:51:54.837685Z","iopub.status.idle":"2021-08-05T08:51:56.979558Z","shell.execute_reply.started":"2021-08-05T08:51:54.837643Z","shell.execute_reply":"2021-08-05T08:51:56.978468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Variables\nThe column consists of two categories only, Y and N. Let's explore further if we can order those or just one-hot encode them.\n\n#### Note:\nOne hot encoding a feature adds new features for each unique category, so if you have only two catogries \"Y\" and \"N\" in Churn, you will have two new columns Y and N where Y feature will have 1s in the places diagnosis = \"Y\" and N feature will have 1's in the places diagnosis = \"N\"\n\n#### Example\n\nOne-hot encoding:\n\ndiagnosis &nbsp;&nbsp;&nbsp; Y | N <br>\nY &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         1 | 0 <br>\nN &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         0 | 1 <br>\nN &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         0 | 1 <br>\nY &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         1 | 0 <br>\nY &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         1 | 0 <br>\n\nLabel encoding: if Y is ranked lower than N: <br>\ndiagnosis  &nbsp;    diagnosis_new <br>\nY  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;            1 <br>\nN  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;            2 <br>\nN  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;            2 <br>\nY  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;            1 <br>\nY  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;            1 <br>\n\n\nBut how can we really know if the data is ranked or not? This can be done using dommain knowledge of the data, for example most of the features are described in the main dataset page, You can also determine this in real life problems using your own knowledge of the problem and the data collected.\nHere in this data it is obvious that Y means the customer left and N means still a customer, also note that Churn is the target variable so I will go for label encoding the variable to get one output for each row.","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\nlabel_enc = preprocessing.LabelEncoder()\ntrain.Churn = label_enc.fit_transform(train.Churn)\nlabels = train.Churn","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:56.981498Z","iopub.execute_input":"2021-08-05T08:51:56.981922Z","iopub.status.idle":"2021-08-05T08:51:56.992985Z","shell.execute_reply.started":"2021-08-05T08:51:56.981877Z","shell.execute_reply":"2021-08-05T08:51:56.991859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_enc.classes_","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:56.995581Z","iopub.execute_input":"2021-08-05T08:51:56.99633Z","iopub.status.idle":"2021-08-05T08:51:57.00566Z","shell.execute_reply.started":"2021-08-05T08:51:56.996267Z","shell.execute_reply":"2021-08-05T08:51:57.004337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['Female', 'Male']] = pd.get_dummies(train.gender)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:59.106166Z","iopub.execute_input":"2021-08-05T08:51:59.106592Z","iopub.status.idle":"2021-08-05T08:51:59.117869Z","shell.execute_reply.started":"2021-08-05T08:51:59.106556Z","shell.execute_reply":"2021-08-05T08:51:59.116123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['part_n', 'part_y']] = pd.get_dummies(train.Partner)\ntrain[['dep_n', 'dep_y']] = pd.get_dummies(train.Dependents)\ntrain[['phone_n', 'phone_y']] = pd.get_dummies(train.PhoneService)\ntrain[['senior', 'not-senior']] = pd.get_dummies(train.SeniorCitizen)\ntrain[['one_line', 'no_line', 'multi-line']] = pd.get_dummies(train.MultipleLines)\ntrain[['bt' ,'cc', 'ec', 'mc']] = pd.get_dummies(train.PaymentMethod)\ntrain[['mm' ,'oy', 'ty']] = pd.get_dummies(train.Contract)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:51:59.43589Z","iopub.execute_input":"2021-08-05T08:51:59.436241Z","iopub.status.idle":"2021-08-05T08:51:59.468018Z","shell.execute_reply.started":"2021-08-05T08:51:59.436208Z","shell.execute_reply":"2021-08-05T08:51:59.466934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:00.384708Z","iopub.execute_input":"2021-08-05T08:52:00.385069Z","iopub.status.idle":"2021-08-05T08:52:00.42927Z","shell.execute_reply.started":"2021-08-05T08:52:00.38503Z","shell.execute_reply":"2021-08-05T08:52:00.428234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_COLS = list(train.dtypes[train.dtypes != 'object'].index)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:01.11256Z","iopub.execute_input":"2021-08-05T08:52:01.112941Z","iopub.status.idle":"2021-08-05T08:52:01.119507Z","shell.execute_reply.started":"2021-08-05T08:52:01.112906Z","shell.execute_reply":"2021-08-05T08:52:01.118371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_COLS","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:01.992754Z","iopub.execute_input":"2021-08-05T08:52:01.993147Z","iopub.status.idle":"2021-08-05T08:52:01.999589Z","shell.execute_reply.started":"2021-08-05T08:52:01.993113Z","shell.execute_reply":"2021-08-05T08:52:01.998424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_new = train[NUM_COLS].drop(['Churn'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:02.664528Z","iopub.execute_input":"2021-08-05T08:52:02.664909Z","iopub.status.idle":"2021-08-05T08:52:02.673628Z","shell.execute_reply.started":"2021-08-05T08:52:02.664876Z","shell.execute_reply":"2021-08-05T08:52:02.672505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_new","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:03.244555Z","iopub.execute_input":"2021-08-05T08:52:03.244938Z","iopub.status.idle":"2021-08-05T08:52:03.28189Z","shell.execute_reply.started":"2021-08-05T08:52:03.244905Z","shell.execute_reply":"2021-08-05T08:52:03.280968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Selection\n\nThere are two main methods for feature selection:\n* Statistical based Feature Selection\n    * Correlation coffecients: correlation between the features and the target\n    * Hypothesis testing with the alternative hypothesis being the feature is segnificant to the target variable\n* Model Based Feature Selection\n\nFirst we will split the data into training and testing then check the correlation using correlation Matrix.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split( train_new.values, labels.values, test_size = 0.2, random_state=42 )","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:04.571853Z","iopub.execute_input":"2021-08-05T08:52:04.572232Z","iopub.status.idle":"2021-08-05T08:52:04.5832Z","shell.execute_reply.started":"2021-08-05T08:52:04.572198Z","shell.execute_reply":"2021-08-05T08:52:04.582035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation based feature selection","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n\nimport matplotlib.pyplot as plt\n\n\ncorr = train.corr()\nf, ax = plt.subplots(figsize=(25, 25))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, vmax=1, vmin = -1, center=0,\n            square=True, linewidths=.5)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:09.349266Z","iopub.execute_input":"2021-08-05T08:52:09.349679Z","iopub.status.idle":"2021-08-05T08:52:10.520182Z","shell.execute_reply.started":"2021-08-05T08:52:09.349643Z","shell.execute_reply":"2021-08-05T08:52:10.519081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Based Selection","metadata":{}},{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\n# load the iris datasets\ndataset = datasets.load_iris()\n# fit an Extra Trees model to the data\nclf = ExtraTreesClassifier()\nclf.fit(x_train,y_train)\n# display the relative importance of each attribute\nz = clf.feature_importances_\n#make a dataframe to display every value and its column name\ndf = pd.DataFrame()\nprint(len(z))\nprint(len(list(train_new.columns.values)))\n\ndf[\"values\"] = z\ndf['column'] = list(train_new.columns.values)\n# Sort then descendingly to get the worst features at the end\ndf.sort_values(by='values', ascending=False, inplace = True)\ndf.head(100)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T08:52:10.524352Z","iopub.execute_input":"2021-08-05T08:52:10.526268Z","iopub.status.idle":"2021-08-05T08:52:11.253583Z","shell.execute_reply.started":"2021-08-05T08:52:10.526218Z","shell.execute_reply":"2021-08-05T08:52:11.252359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.gender.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['Churn', 'gender']].groupby('gender').sum().plot(kind = 'bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hypothesis testing based","metadata":{}},{"cell_type":"code","source":"# SelectKBest selects features according to the k highest scores of a given scoring function \nfrom sklearn.feature_selection import SelectKBest # This models a statistical test known as ANOVA \nfrom sklearn.feature_selection import f_classif\n\nk_best = SelectKBest(f_classif, k = 10)\nk_best.fit_transform( x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_best.pvalues_ \np_values = pd.DataFrame({'column': train_new.columns, 'p_value': k_best.pvalues_})\np_values.sort_values('p_value')\np_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the hypothesis testing, the correlations and the model based feature selection we can conclude that the gender feature doesn't have a segnificant effect of the Churn feature. And it is also obvious that the Teneor and MonthlyCharges are the most important features from our analysis based on the above analysis.","metadata":{}},{"cell_type":"markdown","source":"# Model Selection and Optmization using Optuna","metadata":{}},{"cell_type":"code","source":"from mlxtend.classifier import StackingCVClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.ensemble import  GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn import ensemble,model_selection,svm\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nc1 = ExtraTreesClassifier(n_estimators=700,bootstrap=True) \nmeta2 = ExtraTreesClassifier(n_estimators=200,bootstrap=True) \n\nc2 = RandomForestClassifier(n_estimators=500,bootstrap=True)\nc3 = XGBClassifier()\nc4 = svm.LinearSVC()\nc5 = GradientBoostingClassifier()\nc6 = AdaBoostClassifier()\nmeta = LogisticRegression()\n\netc = StackingCVClassifier(classifiers=[c1, c2, c3, meta, c5],use_probas=True,meta_classifier=meta2)\n\netc.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy of classifier on training set: {:.2f}'.format(etc.score(x_train, y_train) * 100))\nprint('Accuracy of classifier on test set: {:.2f}'.format(etc.score(x_test, y_test) * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\ndef objective(trial,data=train_new.values,target=labels.values):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n    \n    param = {\n        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 4000, 100),\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n    }\n    \n    model = XGBClassifier(**param)  \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    acc = accuracy_score(test_y, preds)\n    return acc\n\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param = {'lambda': 0.019097303955226335, 'alpha': 6.255501364107075, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 3000, 'max_depth': 5, 'random_state': 24}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = XGBClassifier(**param)\n\nclf.fit(x_train, y_train)\n\nprint('Accuracy of classifier on training set: {:.2f}'.format(clf.score(x_train, y_train) * 100))\nprint('Accuracy of classifier on test set: {:.2f}'.format(clf.score(x_test, y_test) * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}