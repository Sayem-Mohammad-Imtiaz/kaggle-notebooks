{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\">Assignment</h1>\n<h2 align=\"center\">Faisal Akhtar</h2>\n<h2 align=\"center\">Roll No.: 17/1409</h2>\n<p>Machine Learning - B.Sc. Hons Computer Science - Vth Semester</p>\n<p>Write a python program to implement linear regression and logistic regression using gradient descent algorithm. Remember the different cost functions.</p>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math \nimport random as rn\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/iris-flower-dataset/IRIS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.iloc[:,0]\nY=data.iloc[:,1]\nplt.scatter(X,Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=0\nc=0\nL=0.0001\nepochs=1000\nn=float(len(X))\nfor i in range(epochs): \n    Y_pred = m*X + c  # The current predicted value of Y\n    D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n    D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n    m = m - L * D_m  # Update m\n    c = c - L * D_c  # Update c\n    \nprint (m, c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = m*X + c\n\nplt.scatter(X, Y) \nplt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='red')  # regression line\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/iris-flower-dataset/IRIS.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[0:100, [1, 2]].values\n\ny = df.iloc[0:100,4 ].values\n\ny = np.where(y == 'Iris-setosa', 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_std = np.copy(X)\n\nX_std[:,0] = (X_std[:,0] - X_std[:,0].mean()) / X_std[:,0].std()\nX_std[:,1] = (X_std[:,1] - X_std[:,1].mean()) / X_std[:,1].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(X, theta):\n    \n    z = np.dot(X, theta[1:]) + theta[0]\n    \n    return 1.0 / ( 1.0 + np.exp(-z))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lrCostFunction(y, hx):\n  \n    # compute cost for given theta parameters\n    j = -y.dot(np.log(hx)) - ((1 - y).dot(np.log(1-hx)))\n    \n    return j","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lrGradient(X, y, theta, alpha, num_iter):\n    # empty list to store the value of the cost function over number of iterations\n    cost = []\n    \n    for i in range(num_iter):\n        # call sigmoid function \n        hx = sigmoid(X, theta)\n        # calculate error\n        error = hx - y\n        # calculate gradient\n        grad = X.T.dot(error)\n        # update values in theta\n        theta[0] = theta[0] - alpha * error.sum()\n        theta[1:] = theta[1:] - alpha * grad\n        \n        cost.append(lrCostFunction(y, hx))\n        \n    return cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m, n = X.shape\n\ntheta = np.zeros(1+n)\n\nalpha = 0.01\nnum_iter = 500\n\ncost = lrGradient(X_std, y, theta, alpha, num_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1, len(cost) + 1), cost)\nplt.xlabel('Iterations')\nplt.ylabel('Cost')\nplt.title('Logistic Regression')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('\\n Logisitc Regression bias(intercept) term :', theta[0])\nprint ('\\n Logisitc Regression estimated coefficients :', theta[1:])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}