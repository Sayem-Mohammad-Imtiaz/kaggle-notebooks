{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-09T14:45:21.741217Z","iopub.execute_input":"2021-06-09T14:45:21.742004Z","iopub.status.idle":"2021-06-09T14:45:21.757081Z","shell.execute_reply.started":"2021-06-09T14:45:21.741834Z","shell.execute_reply":"2021-06-09T14:45:21.755796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing basic liberaries\nimport pandas as pd \nimport plotly.express as px\nimport seaborn as sns\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:23.642807Z","iopub.execute_input":"2021-06-09T14:45:23.64336Z","iopub.status.idle":"2021-06-09T14:45:24.754007Z","shell.execute_reply.started":"2021-06-09T14:45:23.643303Z","shell.execute_reply":"2021-06-09T14:45:24.752948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the data\ndf = pd.read_csv('/kaggle/input/social-network-ads/Social_Network_Ads.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:25.661073Z","iopub.execute_input":"2021-06-09T14:45:25.661445Z","iopub.status.idle":"2021-06-09T14:45:25.671815Z","shell.execute_reply.started":"2021-06-09T14:45:25.661412Z","shell.execute_reply":"2021-06-09T14:45:25.670737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking top 5 rows\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:26.802834Z","iopub.execute_input":"2021-06-09T14:45:26.80321Z","iopub.status.idle":"2021-06-09T14:45:26.818951Z","shell.execute_reply.started":"2021-06-09T14:45:26.803177Z","shell.execute_reply":"2021-06-09T14:45:26.817598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the size of data\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:27.622945Z","iopub.execute_input":"2021-06-09T14:45:27.623553Z","iopub.status.idle":"2021-06-09T14:45:27.629475Z","shell.execute_reply.started":"2021-06-09T14:45:27.623493Z","shell.execute_reply":"2021-06-09T14:45:27.628273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:28.492781Z","iopub.execute_input":"2021-06-09T14:45:28.49341Z","iopub.status.idle":"2021-06-09T14:45:28.508705Z","shell.execute_reply.started":"2021-06-09T14:45:28.493358Z","shell.execute_reply":"2021-06-09T14:45:28.507265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualization**","metadata":{}},{"cell_type":"code","source":"# Pairplot\nfig = sns.pairplot(df);","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:33.631237Z","iopub.execute_input":"2021-06-09T14:45:33.631654Z","iopub.status.idle":"2021-06-09T14:45:35.25664Z","shell.execute_reply.started":"2021-06-09T14:45:33.631614Z","shell.execute_reply":"2021-06-09T14:45:35.255529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# heatmap\nsns.heatmap(df.corr(), annot = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:36.463018Z","iopub.execute_input":"2021-06-09T14:45:36.464198Z","iopub.status.idle":"2021-06-09T14:45:36.69999Z","shell.execute_reply.started":"2021-06-09T14:45:36.464136Z","shell.execute_reply":"2021-06-09T14:45:36.698952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Purchased \npur = pd.crosstab(index = df['Purchased'], columns = 'Count')\npur.plot.bar();","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:37.443557Z","iopub.execute_input":"2021-06-09T14:45:37.443998Z","iopub.status.idle":"2021-06-09T14:45:37.603391Z","shell.execute_reply.started":"2021-06-09T14:45:37.44396Z","shell.execute_reply":"2021-06-09T14:45:37.602614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# age and purchased\nfig = px.histogram(df, x = 'Age', color = 'Purchased')\nfig.show()\nfig2 = px.box(df, x = 'Age', color = 'Purchased')\nfig2.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:38.513171Z","iopub.execute_input":"2021-06-09T14:45:38.51374Z","iopub.status.idle":"2021-06-09T14:45:39.035445Z","shell.execute_reply.started":"2021-06-09T14:45:38.513684Z","shell.execute_reply":"2021-06-09T14:45:39.034299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Salary and purchased\nfig = px.histogram(df, x = df['EstimatedSalary'], color = 'Purchased')\nfig.show()\nfig2 = px.box(df, x = df['EstimatedSalary'], color = 'Purchased')\nfig2.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:40.083323Z","iopub.execute_input":"2021-06-09T14:45:40.083742Z","iopub.status.idle":"2021-06-09T14:45:40.199474Z","shell.execute_reply.started":"2021-06-09T14:45:40.083707Z","shell.execute_reply":"2021-06-09T14:45:40.198256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Data","metadata":{}},{"cell_type":"code","source":"# Getting Features\nfeature = ['Age', 'EstimatedSalary']\nx = df[feature]\n\n# getting predicting value\ny = df['Purchased']","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:42.053642Z","iopub.execute_input":"2021-06-09T14:45:42.054073Z","iopub.status.idle":"2021-06-09T14:45:42.060383Z","shell.execute_reply.started":"2021-06-09T14:45:42.054037Z","shell.execute_reply":"2021-06-09T14:45:42.059156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting trainning and testing data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 1/9, random_state = 252)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:43.032953Z","iopub.execute_input":"2021-06-09T14:45:43.033303Z","iopub.status.idle":"2021-06-09T14:45:43.091444Z","shell.execute_reply.started":"2021-06-09T14:45:43.033267Z","shell.execute_reply":"2021-06-09T14:45:43.090421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:43.973274Z","iopub.execute_input":"2021-06-09T14:45:43.973672Z","iopub.status.idle":"2021-06-09T14:45:43.990461Z","shell.execute_reply.started":"2021-06-09T14:45:43.973637Z","shell.execute_reply":"2021-06-09T14:45:43.989456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier, Perceptron, RidgeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC,NuSVC\nfrom sklearn.neighbors import KNeighborsClassifier, NearestCentroid\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import precision_score\n\nmodels =[(\"LR\", LogisticRegression()),(\"SVC\", SVC()),('KNN',KNeighborsClassifier()),(\"DTC\", DecisionTreeClassifier()),(\"GNB\", GaussianNB()),(\"SGDC\", SGDClassifier()),(\"Perc\", Perceptron()),(\"NC\",NearestCentroid()),(\"Ridge\", RidgeClassifier()),(\"NuSVC\", NuSVC()),(\"BNB\", BernoulliNB()),('RF',RandomForestClassifier()),('ADA',AdaBoostClassifier()),('XGB',GradientBoostingClassifier()),('PAC',PassiveAggressiveClassifier())]\npred = []\nnames = []\nmodelsprecision = []\n\nfor name,model in models:\n    model.fit(x_train, y_train)\n    prediction = model.predict(x_test)\n    score = precision_score(y_test, prediction,average = 'macro')\n    pred.append(score)\n    names.append(name)\n    modelsprecision.append((name,score))\n    \nmodelsprecision.sort(key=lambda k:k[1],reverse=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:45.396751Z","iopub.execute_input":"2021-06-09T14:45:45.397181Z","iopub.status.idle":"2021-06-09T14:45:45.838474Z","shell.execute_reply.started":"2021-06-09T14:45:45.397143Z","shell.execute_reply":"2021-06-09T14:45:45.83738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelsprecision","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:47.072922Z","iopub.execute_input":"2021-06-09T14:45:47.073373Z","iopub.status.idle":"2021-06-09T14:45:47.083039Z","shell.execute_reply.started":"2021-06-09T14:45:47.073339Z","shell.execute_reply":"2021-06-09T14:45:47.08206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\n* **AdaBoostClassifier** worked best here with an percision of **96.87%**\n* **Perceptron** was just behind it with the percision of **94.11%**","metadata":{}},{"cell_type":"markdown","source":"**Please Leave Your Valuable feedback in the comments**","metadata":{}}]}