{"cells":[{"metadata":{"id":"JbOIBQmGVn1J"},"cell_type":"markdown","source":"# Creating a dataset for Internet access by county #\n\n1. [Introduction](#introduction_tag)\n2. [Source Datasets](#dataset_tag)\n3. [Notebook Preparation](#prep_tag)\n4. [Organizing the BroadbandNow Set](#organize_tag)\n5. [Merge the Sets and Save](#merge_tag)\n6. [Concluding Comments and Observations](#conclusion_tag)"},{"metadata":{"id":"sW1iZa70Vn1O"},"cell_type":"markdown","source":"<a id=\"introduction_tag\"></a>\n## Introduction ##\n\nI read a [USA Today article][usa_today] from June 2020, where they discuss\nlibrary usage during the pandemic. Some libraries set up wi-fi networks that\nextended outside the building, so that people would have access to the Internet\neven when the library was shutdown.\n\nThis had me curious about how many people have convenient access to the Internet.\nThere are some companies that no longer have live customer service phone numbers,\nso any support relies on being able to read their web page. If someone wanted to\ndetermine the validity of claims and rumors spread by social media, they either\nneed to have a trusted radio/television new source, or they need convenient access\nto the Internet to be able to\ninvestigate the information (by searching for original articles or\nunaltered video).\n\nI found a pair of datasets that had information that would let me look at the situation.\nBut while doing data cleaning, I found some problems that required significant effort\nto diagnose. I figured it would be useful to create a new dataset, and provide it on\nKaggle in case others were interested.\n\n[usa_today]: https://www.usatoday.com/story/news/2020/06/11/when-libraries-reopen-after-coronavirus-might-months/5316591002/"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"dataset_tag\"></a>\n## Source Datasets ##\n\nI started with the [dataset][imlsdb] provided by the Institute of\nMuseum and Library Services [(IMLS)][imls], titled\n\"IMLS Indicators Workbook: Economic Status and Broadband Availability and Adoption\".\nThe workbook contained statistics blended from three sources: the U.S. Census Bureau\nAmerican Community Survey (ACS 5-year 2014-2018 estimates); broadbandnow.com\n(commercial aggregator of FCC data); and the Bureau of Labor Statistics (local area unemployment statistics).\n\nOn December 10, 2020, BroadbandNow.Com [bbn)][bbn] provided a\n[dataset hosted at GitHub][bbndb] as part of their [Open Data Challenge][bbn_open].\nThis had the features I wanted to cross check with the IMLS dataset.\n\nUnfortunately, there are problems with both datasets. Some examples:\n1. The IMLS set has Autauga County, Alabama as having zero broadband providers and\n\"NaN\" for the lowest cost. In the BBN set, there are 6 zip codes in that county,\nand 5 of them have broadband providers and plan prices.\n2. The IMLS set has Baldwin, Alabama  as having zero broadband providers and\n\"NaN\" for the lowest cost. In the BBN set, there are 21 zip codes in that county,\nand 20 of them have broadband providers and plan prices.\n3. The BBN set has 33023 rows, but 4816 of them are duplicates.\n4. The BBN set has some zip codes labeled with counties that I could not find.\nZip code 52626 is labeled as \"Clark, Iowa\", even though it belongs to Van Buren\nand Lee counties. I was unable to find Walsh, Minnesota for zip code 56744.\n5. I don't know what the population numbers are for the BBN set.\nFor example, I looked at the 5 counties for Hawaii.\nThe IMLS population numbers are identical to the 2019 estimates for each county.\nThe BBN population numbers are below the 2010 census numbers for each county\n(Hawaii, Honolulu, Kalawao, Kauai),\nexcept for Maui which is exactly the 2010 census number.\n\nI decided it would be worth it to do a partial clean-up of both sets, and then\nmerge them to create a dataset with fewer problems. However, that still requires\nsome choices and compromises.\n1. The ACS data that was used for the IMLS set was grouped by PUMAS (Public Use Microdata Areas)\n2. The BBN data is grouped by zip code\n3. The set I want to make is group by counties\n\nI have to use what is convenient, since I don't have the resources or knowledge on how\nto best group the data. If someone is curious on what sort of issues are involved, I found\nthis web page from the University of Michigan titled\n[\"Creating County-Level Statistics from Public Use Microdata Areas (PUMAS)\"][umich_puma].\nA zip code can lie in multiple counties, and vice versa.\n\nWhen there wasn't a clear match up between the counties listed in the IMLS and BBN data sets,\nI consulted the [Wikipedia list of US counties][wiki_county]\nand the [zip-codes.com web site][zip_web_site] for more\ninformation.\n\n[imlsdb]: https://www.imls.gov/data/data-catalog/imls-indicators-workbook-economic-status-and-broadband-availability-and-adoption\n[imls]: https://www.imls.gov/research-evaluation\n[bbndb]: https://github.com/BroadbandNow/Open-Data\n[bbn]: https://broadbandnow.com\n[bbn_open]: https://broadbandnow.com/report/open-dataset-announcement\n[umich_puma]: https://www.psc.isr.umich.edu/dis/census/Features/puma2cnty/\n[wiki_county]: https://en.wikipedia.org/wiki/List_of_United_States_counties_and_county_equivalents\n[zip_web_site]: https://www.zip-codes.com/zip-code-database.asp\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"prep_tag\"></a>\n## Notebook Preparation ##\n\nI ran this jupyter notebook on my home computer, so you will likely have to modify it\nfor your computer set-up. I downloaded the IMLS and BBN datasets from the linked web\npages mentioned in the previous section, but I also put a copy with this Kaggle dataset\nfor convenience. The IMLS information is in an Excel spreadsheet, but I put the\ncounty information into a CSV file.\n\nAs an aside, the IMLS set has FIPS codes for each county, but the\n[Wikipedia entry][wiki_fips] mentions: \"On September 2, 2008, FIPS 5-2 was one of ten standards withdrawn by NIST as a Federal Information Processing Standard.\"\n\n[wiki_fips]: https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code"},{"metadata":{"id":"CEwbwMwyVn1W","outputId":"c466871d-d208-48a8-fdba-645afcd9343d","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport statsmodels.api as sm\nimport time\n\nplt.rcParams[\"figure.figsize\"] = (12,10)\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_info_columns', 150)\n\n# suppress warnings about \"value is trying to be set on a copy of a slice from a DataFrame\"\npd.options.mode.chained_assignment = None  # default='warn'\n\n# *** following lines if using Kaggle ***\ndata_imls_df = pd.read_csv('../input/us-broadband-availability/source_sets/IMLS_county_data.csv', skipinitialspace=True)\ndata_bbn_df = pd.read_csv('../input/us-broadband-availability/source_sets/broadbandnow_opendata.csv', skipinitialspace=True)\n\n# *** read from local version of files ***\n#data_imls_df = pd.read_csv('IMLS_county_data.csv')\n#data_bbn_df = pd.read_csv('broadbandnow_opendata.csv')\n\nprint(data_imls_df.info())\nprint(data_bbn_df.info())","execution_count":null,"outputs":[]},{"metadata":{"id":"eY-kl5x5Vn1S"},"cell_type":"markdown","source":"The IMLS dataset has fields that begin with \"MOE\" (margin of error).\nSince I am interested in clustering\nrather than precise error estimates, those features are dropped.\nI am also dropping the GEO and FIPS features.\n\nThe long column names are descriptive, but I've renamed them to shorter versions\nfor easier use.\n\nFor convenience, I am removing entries for Puerto Rico, which will leave the counties\nin the 50 US states and the District of Columbia.\n\nThe \"population\" is listed as an object Dtype, because a handful of the entries\nhad commas at the thousands. I stripped off the commas, and saved it as \"float\".\n(I could have saved it as int64, but later decimal calculations will be using this number.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove MOE features\nmoe_list = [\"MOE, % w/o health ins.\", \"MOE, Poverty Rate (%)\", \"MOE SNAP\",\n           \"MOE No Computer\", \"MOE no Internet\", \"MOE Broadband\"]\nfor feat in moe_list:\n    del data_imls_df[feat]\n\n#remove some identifier features; leave the NAME and Stabr\nid_list = [\"GEO_ID\", \"FIPS_State\", \"FIPS_County\"]\nfor feat in id_list:\n    del data_imls_df[feat]\n\n# Long column names are descriptive, but are making automatically generated plots\n# difficult to read. Shorten them.\n\ndata_imls_df = data_imls_df.rename(\n    columns = {'County':'county', 'State':'state',\n               'NAME':'full_name', 'Stabr': 'state_abr',\n               'Population_2019':'population', 'Unemployment rate 2019':'unemp',\n               'Percent w/o Health insurance':'health_ins', 'Poverty Rate (%)':'poverty',\n               'Percent received SNAP (2018)':'SNAP',\n               'Percent with no home computer (2018)':'no_comp',\n               'Percent with no home Internet (2018)':'no_internet',\n               'Percent with home Broadband (2018)':'home_broad',\n               'Number of Broadband providers (2019)':'broad_num',\n               'Population for whom broadband available, 2019 (%)':'broad_avail',\n               'Lowest broadband cost per month, 2019 ($)':'broad_cost'})\n\n# remove Puerto Rico\ndata_imls_df = data_imls_df[~((data_imls_df['state'] == 'Puerto Rico'))]\n\n# a few of the population numbers have commas\ndata_imls_df['population'] = data_imls_df['population'].apply(lambda x: x.strip(',')\n                                if isinstance(x, str) else x).astype(float)\n\nprint(data_imls_df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Nevada, the \"county\" information does not match the \"name\".\n\nThe \"name\"rows begin with Churchill County, and end with Carson City.\nThe county label starts with \"Carson City\", instead of ending with it.\nThis led to major problems later on when I was using the \"county\" field\nto merge data sets.\n\nAfter verifying that the population numbers were consistent with the \"name\" field,\nI am overwriting the \"county\" label."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('    Before:')\nprint(data_imls_df[data_imls_df['state'] == \"Nevada\"][['full_name', 'county']].head(20))\n\nnevada_reorganize = [\n    (\"Churchill County, Nevada\", \"Churchill\"),\n    (\"Clark County, Nevada\", \"Clark\"),\n    (\"Douglas County, Nevada\", \"Douglas\"),\n    (\"Elko County, Nevada\", \"Elko\"),\n    (\"Esmeralda County, Nevada\", \"Esmeralda\"),\n    (\"Eureka County, Nevada\", \"Eureka\"),\n    (\"Humboldt County, Nevada\", \"Humboldt\"),\n    (\"Lander County, Nevada\", \"Lander\"),\n    (\"Lincoln County, Nevada\", \"Lincoln\"),\n    (\"Lyon County, Nevada\", \"Lyon\"),\n    (\"Mineral County, Nevada\", \"Mineral\"),\n    (\"Nye County, Nevada\", \"Nye\"),\n    (\"Pershing County, Nevada\", \"Pershing\"),\n    (\"Storey County, Nevada\", \"Storey\"),\n    (\"Washoe County, Nevada\", \"Washoe\"),\n    (\"White Pine County, Nevada\", \"White Pine\"),\n    (\"Carson City, Nevada\", \"Carson City\") ]\n\nfor (name,county) in nevada_reorganize:\n    data_imls_df.loc[data_imls_df['full_name'] == name, 'county'] = county\nprint('\\n    After:')\nprint(data_imls_df[data_imls_df['state'] == \"Nevada\"][['full_name', 'county']].head(20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the broadbandnow.com dataset, since I had access to more information, I wanted to save\nmore of the features than were originally used in the IMLS set. (This is still a subset\nof the possible features present in the dataset.)\n- Zip, Population, County, State : identifiers (most counties have multiple Zip codes)\n- WiredCount_2020: Number of Wired (Cable, Copper, DSL, Fiber) Providers present in a zip code\n- AllProviderCount_2020: Number of Providers of any technology present in a zip code, including Fixed Wireless Providers (WISPs)\n- All25_3_2020: Number of Providers (any technology) present in a zip code offering speeds of at least 25 Mbps Download / 3 Mbps Upload\n- AverageMbps: Average Download Speed via M-Lab Speed Tests, rolling 12 months\n- %Access to Terrestrial Broadband: Percent of the Zip's Population that has Access to Terrestrial (Wired + Fixed Wireless) Broadband (25 Mbps Download / 3 Mbps Upload)\n- Lowest Priced Terrestrial Broadband Plan: The Lowest Regular Monthly Priced Terrestrial (Wired + Fixed Wireless) Residential Standalone-Internet Broadband (25 Mbps Download / 3 Mbps Upload) Plan available in the zip\n\nThese fields were renamed to shorter versions, and \"_bbn\" appended to the variable\nname to keep them distinct from the IMLS features.\n\nThe prices have dolar signs, and the access numbers have the percentage symbols.\nThese were stripped off, and saved as floating numbers.\n\nThe BBN set has 33023 rows, but 4816 of them are duplicates.\n(The duplicate rows are identical to the first found entries, so was free to chose\nthe first or the last duplicate found.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_list = [\"Zip\", \"Population\", \"County\", \"State\",\n           \"WiredCount_2020\", \"AllProviderCount_2020\", \"All25_3_2020\",\n           \"AverageMbps\", \"%Access to Terrestrial Broadband\",\n           \"Lowest Priced Terrestrial Broadband Plan\"]\n\ndata_bbn_df = data_bbn_df[id_list].rename(\n    columns = {'Population':'population_bbn', 'County':'county', 'State':'state',\n               'WiredCount_2020':'wired_bbn',\n               'AllProviderCount_2020':'provide_bbn',\n               'All25_3_2020':'all25_bbn',\n               'AverageMbps':'downave_bbn',\n               '%Access to Terrestrial Broadband':'access_bbn',\n               'Lowest Priced Terrestrial Broadband Plan':'price_bbn'})\n\n# The prices are mostly strings (due to $), except for the NaN which are floats\ndata_bbn_df['price_bbn'] = data_bbn_df['price_bbn'].apply(lambda x: x.strip('$')\n                                if isinstance(x, str) else x).astype(float)\n\n# Remove the percentage symbol from the access numbers\ndata_bbn_df['access_bbn'] = data_bbn_df['access_bbn'].apply(lambda x: x.strip('%')\n                                if isinstance(x, str) else x).astype(float)\n\n# over 10% of the data set is duplicates\ndata_bbn_df = data_bbn_df.drop_duplicates()\n\nprint(data_bbn_df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"organize_tag\"></a>\n## Organizing the BroadbandNow Set ##\n\nBoth sets have a \"county\" and \"state\" label, so the plan is to merge the IMLS and BBN sets\nusing those two features. However, there are a few mismatches in the names of counties\nbetween the two sets. These will be dealt with on a case-by-case basis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will loop over all states, and compare the counties in the two data sets,\n# and look for any names that are present in only one of the two sets.\n#\n# This generates a lot of text, so it is commented out.\n# Uncomment if you want to verify my observations.\n\n#state_list = list(data_imls_df['state'].unique())\n#for local_state in state_list:\n#    set1 = set(data_imls_df[data_imls_df['state'] == local_state]['county'].sort_values())\n#    set2 = set(county_bbn_df[county_bbn_df['state'] == local_state]['county'].sort_values())\n#    print(\"Checking for the state of\",local_state,\"have\",\n#          len(set1),\"IMLS counties and\",len(set2),\"BBN counties\")\n#    print(\"Counties missing in BBN list:\",list(set1-set2))\n#    print(\"Counties missing in IMLS list:\",list(set2-set1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Alaska ####\nThe IMLS set has a full_name of \"Kusilvak Census Area\", but has \"null\" for the county label.\nThe BBN set has \"Wade Hampton\" as a county. Looking in Wikipedia, there was a name change\nin 2015. For both data sets, I changed the county label to \"Kusilvak\".\n\n#### Iowa ####\nThe BBN set has a \"Clark county\". This is distinct from \"Clarke county\", which is present in both sets. Looking at the zip code (52626), it belongs to Van Buren and Lee counties.\nI have changed the BBN entry to use \"Van Buren\" for the county.\n\n#### Minnesota ####\nThe BBN set has a \"Walsh county\". My online search only found a Walsh county in North Dakota.\nThe zip code (56744) belongs to the city of Oslo, MN, which is right next to the North Dakota\nborder. This is probably a zip code that crosses state lines. The zip code belongs\nto Marshall and Polk counties.\nI have changed the BBN entry to use \"Marshall\" for the county.\n\n#### counties missing from the BBN set ####\nThe following counties are not in the BBN data set:\n- Geogia: Quitman\n- Hawaii: Kalawao\n- Mississippi: Issaquena, George\n- Nebraska: Loup, Banner\n- Nevada: Storey\n- Virginia: Franklin City, Covington, Lexington, Emporia, Martinsville, Fairfax City, Manassas Park\n\nMost of these have small populations (but not always the smallest). Without investigating every case, I assume most of these are where zip codes and county lines do not conveniently line up.\n\nFor Nebraska, Loup contains zip code 68879, while Banner has zip code 69345. Neither of those numbers was in the BBN data set. (Considering there are almost 42 thousand zip codes in the USA, a dataframe with a little over 28 thousand rows will not cover all cases.)\n\nI will let the user decide how to deal with these cases. After the sets are merged, all the \"_bbn\" variables will be null/NaN for counties not in the BBN dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# handle some of the county mismatches\ndata_imls_df.loc[data_imls_df['full_name'] == \"Kusilvak Census Area, Alaska\", 'county'] = \"Kusilvak\"\ndata_bbn_df.loc[data_bbn_df['county'] == \"Wade Hampton\", 'county'] = \"Kusilvak\"\n\ndata_bbn_df.loc[data_bbn_df['Zip'] == 52626, 'county'] = \"Van Buren\"\ndata_bbn_df.loc[data_bbn_df['Zip'] == 56744, 'county'] = \"Marshall\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The BBN set is organized by zip code, so will need to be grouped into counties.\n\nSome of the variables are obvious. The county population is will use the sum of the zip codes assigned to that county. The lowest plan price will be the minimum (not NaN) value found. The average download speed is the population weighted average of the \"average download speed\" for each zip code.\n\nThe number of providers in the county is more complicated. It is not clear if the same provider covers more than one zip code or how many of them. I have decided to use the population weighted average for the number of providers. This will result in non-integer numbers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# making a copy, in case I want to overwrite some values\nwork_df = data_bbn_df.copy()\n\n# compute the fraction of the population for each zip code in a county\ncounty_pop = work_df.groupby(['county', 'state'])['population_bbn'].transform('sum')\nwork_df['weight'] = work_df['population_bbn'].div(county_pop)\n\n# start with the population of the county\ncounty_bbn_df = work_df.groupby(['county', 'state'])['population_bbn'].sum()\ncounty_bbn_df = county_bbn_df.reset_index(name = 'population_bbn')\n\ntemp_df = work_df.groupby(['county', 'state'])['price_bbn'].min()\ntemp_df = temp_df.reset_index(name = 'price_bbn')\ncounty_bbn_df = county_bbn_df.merge(temp_df, how='left')\n\nid_list = [\"wired_bbn\", \"provide_bbn\", \"all25_bbn\",\n           \"downave_bbn\", \"access_bbn\"]\nfor col_name in id_list:\n    work_df = work_df.astype({col_name:'float'})\n    work_df[col_name] = work_df[col_name] * work_df['weight']\n    temp_df = work_df.groupby(['county', 'state'])[col_name].sum()\n    temp_df = temp_df.reset_index(name = col_name)\n    county_bbn_df = county_bbn_df.merge(temp_df, how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I noticed that some zip codes (likely in cities) can have average download speeds in the hundreds, while other zip codes (likely rural) are in the single digits. I wanted to create a feature that would track this. The BBN set has a feature for the download speed for the 90th percentile of the people, but I won't be able to compute that quantity when grouping the\nzip codes.\n\nI decided to create a measure called \"slowfrac_bbn\".\nI select the zip codes with an average download speed of less than 6 Mb/s,\nand determine what fraction of the county's population are in those zip codes.\n\nThe distribution of average download speeds for all zip codes looks like\nit has an exponential decrease. Six seemed like a reasonable cut-off point.\n\nIf there are no zip codes in a county with an average speed of less than 6,\nthis will result in \"slowfrac\" being NaN. I replace those values with 0.\n\nThis is not a rigorously calculated statistical value, since I am using numbers which\nare already averaged by zip code. However, I think it will still help indicate what\nis going on in the county, if a high average speed is due to some extreme outliers\nor if everyone has good connection speeds."},{"metadata":{"trusted":true},"cell_type":"code","source":"slower_df = work_df[work_df['downave_bbn'] < 6.0].copy()\ntemp_df = slower_df.groupby(['county', 'state'])['weight'].sum()\ntemp_df = temp_df.reset_index(name = 'slowfrac_bbn')\ncounty_bbn_df = county_bbn_df.merge(temp_df, how='left')\n\ncounty_bbn_df['slowfrac_bbn'] = county_bbn_df['slowfrac_bbn'].fillna(0.0)\n\nslower_df = work_df[work_df['downave_bbn'] < 25.0].copy()\nplt.figure(figsize=(12,4))\nplt.subplot(1, 2, 1)\nplt.hist(slower_df['downave_bbn'])\nplt.xlabel('ave download speed by zip code')\n\nplt.subplot(1, 2, 2)\nplt.hist(county_bbn_df['slowfrac_bbn'])\nplt.xlabel('slowfrac measure by county')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"merge_tag\"></a>\n## Merge the Sets and Save ##\n\nThis notebook is saved on Kaggle to show how the dataset was created, but I'm running\nit on a home computer. The line to save the dataframe as a CSV file is commented out."},{"metadata":{"trusted":true},"cell_type":"code","source":"access_data = data_imls_df.merge(county_bbn_df, how='left')\n\nprint(access_data.info())\n\nfile_name = 'broadband_access.csv'\n#access_data.to_csv(file_name,index=False)\n\nprint ('File',file_name,'saved at',time.asctime( time.localtime(time.time()) ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion_tag\"></a>\n## Concluding Comments and Observations ##\n\nHopefully this dataset will be interesting for other people,\nand that this notebook has enough documentation to understand\nhow it was created.\n\nThe user will still have to do some data cleaning before\nproceeding with an analysis. For example, some rows are missing\ncountry unemployment numbers. The cases where BroadbandNow\ndid not have information for a particular county will also\nneed to be dealt with.\n\nI mentioned earlier that the population numbers provided by\nBroadbandNow don't seem to match the census numbers I could\nfind. I don't know if that is due to missing zip codes, sample\nweighting, or if something else went into the methodology.\nThe values are close enough to the 2019 census estimates\nthat I assume they are useful in calculating\naverages and other weighted values, even though I will\nbe using the census estimates for the county population.\n\nThis set also includes the numbers for BroadbandNow that were\nin the original IMLS set (number of providers, % population coverage,\nlowest price). These are kept in case more investigation is desired.\nFor analysis, they will probably be removed, and the newer BBN values used instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = data_imls_df[['state','population']]\nstate1_df = temp_df.groupby(['state'])['population'].sum()\nstate1_df = state1_df.reset_index(name = 'pop')\ntemp_df = data_bbn_df[['state','population_bbn']]\nstate2_df = temp_df.groupby(['state'])['population_bbn'].sum()\nstate2_df = state2_df.reset_index(name = 'pop_bbn')\nstate_df = state1_df.merge(state2_df, how='left')\n\nplt.figure(figsize=(12,4))\n\nplt.subplot(1, 2, 1)\nplt.scatter(access_data[\"population\"], access_data[\"population_bbn\"])\nplt.plot(access_data[\"population\"], access_data[\"population\"], color=\"red\")\nplt.xlabel('pop_census by county')\nplt.ylabel('pop_bbn by county')\n\nplt.subplot(1, 2, 2)\n\nplt.scatter(state_df[\"pop\"], state_df[\"pop_bbn\"])\nplt.plot(state_df[\"pop\"], state_df[\"pop\"], color=\"red\")\nplt.xlabel('pop_census by state')\nplt.ylabel('pop_bbn by state')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"access_data = data_imls_df.merge(county_bbn_df, how='left')\n\nplt.figure(figsize=(12,4))\n\nplt.subplot(1, 3, 1)\nplt.scatter(access_data[\"broad_num\"], access_data[\"all25_bbn\"])\nplt.plot(access_data[\"broad_num\"], access_data[\"broad_num\"], color=\"red\")\nplt.xlabel('# of providers (IMLS set)')\nplt.ylabel('# of providers (BBN set, zip code weighted)')\n\nplt.subplot(1, 3, 2)\nplt.scatter(access_data[\"broad_avail\"], access_data[\"access_bbn\"])\nplt.plot(access_data[\"broad_avail\"], access_data[\"broad_avail\"], color=\"red\")\nplt.xlabel('% population bb access (IMLS set)')\nplt.ylabel('% population bb access (BBN set, zip code weighted)')\n\nplt.subplot(1, 3, 3)\nplt.scatter(access_data[\"broad_cost\"], access_data[\"price_bbn\"])\nplt.plot(access_data[\"broad_cost\"], access_data[\"broad_cost\"], color=\"red\")\nplt.xlabel('lowest price (IMLS set)')\nplt.ylabel('lowest price (BBN set)')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}