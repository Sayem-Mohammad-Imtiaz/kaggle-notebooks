{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The dataset and use case\n- The dataset is looking at a number of basic tasks done with MS and control patients through an open data platform. The data is all collected through the iOS floodlight app\n- Build a classifier for accurately differentiating the MS from the control patients\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset and setup environment"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\\","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"##check current directory\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###change to input directory\nos.chdir(\"/kaggle/input\")\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"complete_dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### quick look of the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data quailty assessment\n- 3 columns are not be able to use for building the model due to lack of data\n- large number of empty value as many tests are not completed by the users\n- not very high quality data"},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and manipulating the dataset\n-  drop columns with too many null values\n-  participantCreatedOn,testStartedAt, testEndedAt, testResultMetricCreatedOn should be datetime data type \n-  participantBirthYear, participantWeightLbs, participantHeightCms, testResultMetricId should be integer\n-  testMetricName and code are repetitive same as testName and testCode"},{"metadata":{"trusted":true},"cell_type":"code","source":"##drop unnamed column and check if successed \ndata = data.drop(\"Unnamed: 19\", 1).drop(\"testResultMetricTimestamp1\", 1).drop(\"testResultMetricTimestamp2\", 1)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['participantCreatedOn','testStartedAt', 'testEndedAt', 'testResultMetricCreatedOn' ]:\n    data[col] = pd.to_datetime(data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in [ \"participantBirthYear\", \"participantWeightLbs\", \"participantHeightCms\", \"testResultMetricId\" ] :\n    data[col] = data[col].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.unique(data['testMetricCode']))\nprint(np.unique(data['testMetricName']))\nprint(np.unique(data['testName']))\nprint(np.unique(data['testCode']))\n###name and code here are repetitive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['testCode', \"testMetricCode\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['test_fullname'] = data['testName'] +\"-\"+ data[\"testMetricName\"]\ndata = data.drop(([\"testName\", \"testMetricName\"]), axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(by = \"floodlightOpenId\")[\"participantCreatedOn\"].count().sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Further manipulating \n- establish a pivot table\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_data=data.groupby(['floodlightOpenId', 'participantIsControl', \n                                'participantSex', 'participantBirthYear']).\\\n  size().reset_index(name='count').sort_values('count', ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nreg_part = re.compile(r\"^part\")\nreg_test = re.compile(r\"^test\")\npart_data_cols = list(filter(reg_part.search, data.columns))\ntest_data_cols = list(filter(reg_test.search, data.columns))\nprint(part_data_cols)\nprint(test_data_cols)\n###alternative \n##part_cols = [x for x in data.columns if x.startswith('participant')]\n##test_cols = [x for x in data.columns if x.startswith('test')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_data = data.pivot_table(index=['floodlightOpenId']+part_data_cols, columns = ['test_fullname'], values= [\"testResultMetricValue\"])\npivot_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measurement_data = pivot_data.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measurement_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore data"},{"metadata":{},"cell_type":"markdown","source":"- Explore the MS distribution regards to genders\n- Explore the MS distribution regards to region\n- Explore the MS distribution regards to patient birth year"},{"metadata":{"trusted":true},"cell_type":"code","source":"MS_data = measurement_data[measurement_data[\"participantIsControl\"] == True]\nMS_data = MS_data.drop((['participantIsControl']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MS_data[\"participantSex\"].value_counts().plot(kind =\"bar\")\n##With in MS patient, female is slightly more than male","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MS_data[\"participantCountryOfResidence\"].value_counts().plot(kind = \"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MS_data[\"participantBirthYear\"].value_counts().plot(kind = \"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nmeasurement_data['participantIsControl'] = measurement_data['participantIsControl'].map(lambda x: 'Healthy' if x else 'MS')\n##Use pair plot to discover each column\nsns.pairplot(data=measurement_data[part_data_cols], hue = \"participantIsControl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n- fill NA values\n- change participantIsControl and participantSex to 0 or 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"measurement_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measurement_data[\"testResultMetricValue\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measurement_data[\"testResultMetricValue\"] = measurement_data[\"testResultMetricValue\"].apply(lambda x : x.fillna(x.mean(), axis = 0))\nmeasurement_data[\"participantSex\"] = measurement_data[\"participantSex\"].map(lambda x : 1 if x == \"female\" else 0 )\nmeasurement_data.rename(columns = {\"participantSex\": \"participantIsFemale\"}, inplace= True)\nmeasurement_data[\"participantIsControl\"] = measurement_data[\"participantIsControl\"].map(lambda x :0 if x ==\"MS\" else 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Further featrue engineering\n- Scale data\n- use lable encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measurement_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##normalize data \ndf = measurement_data.copy()\ndf[\"testResultMetricValue\"] = preprocessing.scale(df[\"testResultMetricValue\"], with_mean = True, with_std = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"testResultMetricValue\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_col = df[\"participantIsControl\"]\n##df_X = df.iloc[:, 3::]\ndf_X = df.iloc[:, 4::]\ndf_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\npart_cols = [\"participantIsFemale\", \"participantBirthYear\", \"participantWeightLbs\", \"participantHeightCms\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X[part_cols] = df_X[part_cols].apply(le.fit_transform)\ndf_X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build the models with machine learning algorithmns\n- partition the data\n- use logistic regression and random forest algorithmns to build two classifier models"},{"metadata":{},"cell_type":"markdown","source":"## Model evaluation\n- use accuracy as evaluation metric\n- confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_X, y_col, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(solver=\"liblinear\", C=1000)\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy = 0.78\nFalse positive rate = 0.16"},{"metadata":{"trusted":true},"cell_type":"code","source":"##now try with randomForest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf=RandomForestClassifier(n_estimators=200)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\nprint(\"Accuracy:\",accuracy_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy = 0.74\nFalse postive rate = 0.18"},{"metadata":{},"cell_type":"markdown","source":"# Build model with a deep learning algorithmn - nerual network\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y_train.to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = y_test.to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model contains 3 layers, the first two layers use relu as activation function, the last layer use sigmoid function, as this is a binary classifier. The loss function is binary crossentropy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 3)\nmean = accuracies.mean()\nvariance = accuracies.std()\nprint(\"Accuracy mean: \"+ str(mean))\nprint(\"Accuracy variance: \"+ str(variance))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy is 0.70, which is lower than logistic regression and random forest model"},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nturned out in this case (small dataset, simple binary classfication task), deep learning algorithmn does not outperform basic logistic regression "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}