{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt \nfrom keras.models import Sequential \nfrom keras.layers import Dense, BatchNormalization, Dropout, Flatten \nfrom keras.optimizers import Adam \nfrom keras.utils.np_utils import to_categorical \nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom sklearn.model_selection import train_test_split\nimport pickle \nimport cv2 \nimport os \nimport pandas as pd \nimport random \nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array \nfrom scipy import misc , ndimage\nfrom tensorflow import keras\nimport tensorflow as tf ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"############################ Parameters ###############################\n\nimageDimensions = (32,32)\ntestRatio = 0.2   #if  1000 images split will 200 for testing \nvalidationRation = 0.2 #if 1000 images 20% of remaining 800 will be 160 for validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## the way ####################################\npath =\"../input/traffic-sign-images-from-turkey/Trafik/Trafik\"\nlabelFile = \"../input/traffic-sign-images-from-turkey/labels.csv\"\n\ncount = 0\nimages = []\nclassNo = []\nmyList = os.listdir(path)\nprint(\"Total Classes Detected:\",len(myList))\nnoOfClasses=len(myList)\nprint(\"Importing Classes.....\")\nfor x in range (0,len(myList)):\n    myPicList = os.listdir(path+\"/\"+str(count))\n    for y in myPicList:\n        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y,cv2.IMREAD_GRAYSCALE ) # Tek kanallı yapıyoruz.. \n        curImg=cv2.resize(curImg, (32,32)) # Boyutlar eşitleniyor.\n        images.append(curImg)\n        classNo.append(count)\n    print(count, end =\" \")\n    count +=1\nprint(\" \")\nimages = np.array(images)\nclassNo = np.array(classNo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(images.shape)\nprint(images[0])\nprint(images.dtype)### Veri type #### ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################################## Split Data\nX_train, X_test , y_train , y_test = train_test_split(images, classNo, test_size=testRatio)\nX_train, X_validation , y_train , y_validation = train_test_split(X_train, y_train , test_size = validationRation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## to check if number of images matches to number of labels for each data set \n\nprint(\"Data Shapes\")\nprint(\"Train\", end=\"\");print(X_train.shape,y_train.shape)\nprint(\"Validation\",end=\"\");print(X_validation.shape,y_validation.shape)\nprint(\"Test\",end=\"\"); print(X_test.shape , y_test.shape)\n\nassert(X_train.shape[0] == y_train.shape[0]),\"The number of images in not equal to the number of labels(hedef değişken) in training set\"\nassert(X_validation.shape[0] == y_validation.shape[0]),\"The number of images in not equal to the number of labels validation set\"\nassert(X_test.shape[0] == y_test.shape[0]),\"The number of images in not equal to the number of labels test set\"\nassert(X_train.shape[1:]== (imageDimensions)), \"The dimension of the Training images are wrong\"\nassert(X_validation.shape[1:]==(imageDimensions)),\"The dimension of the Validation images are wrong\"\nassert(X_test.shape[1:]== imageDimensions),\"The dimension of test images aste wrong\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################################# READ CSV FILE ###################\ndata = pd.read_csv(labelFile, encoding=\"ISO-8859-1\")\nprint(\"Data Shape: \",data.shape, type(data))\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################33 DISPLAY SOME SAMPLES OF ALL CLASSES ###################\n\nplt.figure(figsize=(35,6))\nfor i in range(20):\n    plt.subplot(2,10,i+1)\n    plt.imshow(X_train[i])\n    plt.title(\"{}\".format(data.Name[y_train[i]]))    \n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######################## DISPLAY A BAR CHART SHOWING NO OF SAMPLES FOR EACH CATEGORY \n\nplt.figure(figsize=(12,4))\nplt.hist(classNo, bins=len(data.Classid))\nplt.title(\"Distribution of the training dataset\")\nplt.xlabel(\"Class Number\")\nplt.ylabel(\"Number of images\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.astype(np.uint8)\nX_validation = X_validation.astype(np.uint8)\nX_test = X_test.astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################### PREPROCESSING THE IMAGES \n\ndef equalize(img):\n    img=cv2.equalizeHist(img)\n    return img \n\nrand_num = random.randint(0,len(X_train)-1)\nplt.imshow(X_train[rand_num])\nplt.title(\"GrayScale Images {}\".format(data.Name[y_train[rand_num]]))\nplt.show()\n\n \nX_train = np.array(list(map(equalize, X_train)))\nX_validation = np.array(list(map(equalize, X_validation)))\nX_test = np.array(list(map(equalize, X_test)))\nplt.imshow(X_train[rand_num])\nplt.title(\"GrayScale Images {}\".format(data.Name[y_train[rand_num]]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######################### ADD A DEPTH OF 1 ######## Bır katmanlı yaptık X_train.shape = (13443,32,32,1)\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1],X_train.shape[2],1)\nX_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1],X_validation.shape[2],1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1],X_test.shape[2],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## AUGMENTATION OF IMAGES TO MAKE IT MORE GENERIC \n\ndataGen = ImageDataGenerator(width_shift_range=0.1, \n                            height_shift_range=0.1,\n                            zoom_range=0.2,\n                            shear_range=0.1,\n                            rotation_range=10)\ndataGen.fit(X_train)\nbatches = dataGen.flow(X_train, y_train, batch_size=20)\nX_batch, y_batch = next(batches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TO SHOW AGMENTED IMAGE SAMPLES \n\nfig, axs = plt.subplots(1,15, figsize= (20,5))\nfig.tight_layout()\n\nfor i in range(15):\n    axs[i].imshow(X_batch[i].reshape(imageDimensions[0], imageDimensions[1]))\n    axs[i].axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################ CONVOLUTION NEURAL NETWORK MODEL \n\ndef myModel():\n    no_Of_Filters = 64 \n    size_of_Filter = (5,5)\n    size_of_Filter2 = (3,3)\n    size_of_pool= (3,3)\n    no_Of_Nodes = 500\n    \n    model = Sequential()\n    model.add((Conv2D(no_Of_Filters, size_of_Filter, input_shape=(imageDimensions[0], imageDimensions[1],1), activation=\"relu\")))\n    model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation=\"relu\")))\n    model.add(MaxPooling2D(pool_size = size_of_pool))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    \n    model.add(Dense(no_Of_Nodes, activation=\"relu\"))\n    model.add(Dense(noOfClasses, activation=\"softmax\"))\n    \n    #COMPILE MODEL\n    model.compile('rmsprop',loss='sparse_categorical_crossentropy',metrics=['accuracy']) \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size_val=40 \n \nmodel = myModel()\nprint(model.summary())\nhistory=model.fit_generator(dataGen.flow(X_train,y_train,batch_size=batch_size_val),\n                            epochs=25,validation_data=(X_validation,y_validation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################### PLOT veriler düzeltilmeden önce\nplt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training','validation'])\nplt.title('loss')\nplt.xlabel('epoch')\nplt.figure(2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['training','validation'])\nplt.title('Acurracy')\nplt.xlabel('epoch')\nplt.show()\nscore =model.evaluate(X_test,y_test,verbose=0)\nprint('Test Loss Score:',score[0])\nprint('Test Accuracy:',score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"MY_h5_model_5.h5\") ### Tam dosya yolu gerekli.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing with Open Camera"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport cv2 \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################33 \nlabel = pd.read_csv('../input/traffic-sign-images-from-turkey/labels.csv',encoding=\"ISO-8859-1\")\nframeWidth = 640 \nframeHeight = 480 \nbrightness = 180 \nthreshold = 0.75\nfont = cv2.FONT_HERSHEY_SIMPLEX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup the video camera \n\ncap = cv2.VideoCapture(0)\ncap.set(3,frameWidth)\ncap.set(4,frameHeight)\ncap.set(10, brightness)\n\n# import the trannined model \nmodel = keras.models.load_model(\"MY_h5_model_5.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grayscale(img):\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    return img\n\ndef equalize(img):\n    img =cv2.equalizeHist(img)\n    return img\n\ndef preprocessing(img):\n    img = grayscale(img)\n    img = equalize(img)\n    return img\n\ndef getCalssName(classNo):\n    labels=pd.read_csv(\"labels.csv\",encoding='ISO-8859-1')\n    a=labels[labels[\"Classid\"]==classNo][\"Name\"]\n    return a\n\n\nwhile True:\n \n    # READ IMAGE\n    success, imgOrignal = cap.read()\n \n    # PROCESS IMAGE\n    img = np.asarray(imgOrignal) \n    img = cv2.resize(img, (32, 32))\n    img = preprocessing(img)\n    \n    cv2.imshow(\"Processed Image\", img)\n    img = img.reshape(1, 32, 32, 1)\n    \n    cv2.putText(imgOrignal, \"CLASS: \" , (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n    cv2.putText(imgOrignal, \"PROBABILITY: \", (20, 75), font, 0.75, (255, 0, 0), 2, cv2.LINE_AA)\n    \n    # PREDICT IMAGE\n    predictions = model.predict(img)\n    probabilityValue =np.amax(predictions)\n    classIndex = np.where(predictions == probabilityValue)[1][0]\n    \n    if probabilityValue > threshold:\n        #print(getCalssName(classIndex))\n        cv2.putText(imgOrignal,str(classIndex)+\" \"+str(getCalssName(classIndex)), (120, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n        cv2.putText(imgOrignal, str(round(probabilityValue*100,2) )+\"%\", (180, 75), font, 0.75, (255, 0, 0), 2, cv2.LINE_AA)\n    cv2.imshow(\"Result\", imgOrignal)\n \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Note: Kaggle don't suppose camera. So we take error but if you run this code on your jupyterNotebook , you don't take any error. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}