{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\n#Import models for classification task\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import precision_score,recall_score, accuracy_score,confusion_matrix, plot_confusion_matrix, classification_report, auc,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n\nimport xgboost\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\nfrom tensorflow.keras import optimizers\n\nprint(f\"Tensorflow Version: {tf.version.VERSION}\")\n\n\nimport missingno\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/income-adult/adult_data.csv\")\ntest = pd.read_csv(\"../input/income-adult/adult_test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Column names have spaces on either end, so remove them\nnew_cols = [col.strip() for col in train.columns]\ntrain.columns = new_cols\ntest.columns = new_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Separate training and test set into features and target\n\nX_train = train.drop([\"salary\"], axis = 1)\ny_train = train[[\"salary\"]]\n\nX_test = test.drop([\"salary\"], axis = 1)\ny_test = test[[\"salary\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#separate numerical and categorical variables\nnum_cols = X_train.select_dtypes(include = \"int64\")\ncat_cols = X_train.select_dtypes(include = \"object\")\n\nnum_cols.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot features for better understanding","metadata":{}},{"cell_type":"code","source":"sns.countplot(train[\"salary\"])\nplt.title(\"Count of variable to predict\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(cat_cols.columns)} categorical variables in the training set.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot count plots for all categorical variables\nplt.figure(figsize = (23,15))\n\nfor i,var in enumerate(cat_cols.columns):\n    plt.subplot(4,2,i+1)\n    sns.countplot(X_train[var])\nplt.subplots_adjust(hspace = 0.4)\nplt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(num_cols.columns)} numerical variables in the training set.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (23,12))\nfor i,var in enumerate(num_cols.columns):\n    plt.subplot(2,3,i + 1)\n    sns.histplot(X_train[var])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning\n## Check for missing values and null values","metadata":{}},{"cell_type":"markdown","source":"### Training set","metadata":{}},{"cell_type":"code","source":"\nprint(X_train.isna().mean())\nprint(X_train.isnull().mean())\nmissingno.matrix(X_train, figsize = (10,10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test set","metadata":{}},{"cell_type":"code","source":"print(X_test.isna().mean())\nprint(X_test.isnull().mean())\n\nmissingno.matrix(X_test, figsize = (10,10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean label column","metadata":{}},{"cell_type":"code","source":"#Replace <= 50k with 0 and >50k with 1 for modelling\n\n#print(y_train[\"salary\"].unique(), y_test[\"salary\"].unique())\ny_train = y_train.replace({y_train[\"salary\"].unique()[0]: 0, y_train[\"salary\"].unique()[1] : 1})\ny_test = y_test.replace({y_test[\"salary\"].unique()[0]: 0, y_test[\"salary\"].unique()[1] : 1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The shape of X_train is {X_train.shape}.\")\nprint(f\"The shape of X_test is {X_test.shape}.\")\n\nX_train_len = len(X_train)\nX_test_len = len(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One Hot Encoding\n\nCombine test and training set to one hot encode ensuring all variables are taken into account","metadata":{}},{"cell_type":"code","source":"X = pd.concat([X_train,X_test], axis = 0)\nprint(f\"The shape of X is {X.shape}.\")\n\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One Hot Encoding\nX_new = pd.get_dummies(X, columns = cat_cols.columns)\nprint(X_new.shape)\nX_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Separate training and test set the same way it was previously","metadata":{}},{"cell_type":"code","source":"#Recreate X_train and X_test with one hot encoded features\nX_train = X_new.iloc[0:X_train_len]\nX_test = X_new.iloc[X_train_len:]\n\nprint(f\"The shape of X_train is {X_train.shape}.\")\nprint(f\"The shape of X_test is {X_test.shape}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a validation set from the training data for model fine tuning","metadata":{}},{"cell_type":"code","source":"#Split into validation/test set\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.3, random_state = 1, stratify = y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The shape of X_train is {X_train.shape}.\")\nprint(f\"The shape of X_val is {X_val.shape}.\")\nprint(f\"The shape of X_test is {X_test.shape}.\")\n\nprint(f\"The shape of y_train is {y_train.shape}.\")\nprint(f\"The shape of y_val is {y_val.shape}.\")\nprint(f\"The shape of y_test is {y_test.shape}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensure the data is stratified properly after split as the dataset is unbalanced","metadata":{}},{"cell_type":"code","source":"plt.subplot(1,3,1)\nsns.countplot(y_train[\"salary\"])\nplt.title(\"Train Data\")\n\nplt.subplot(1,3,2)\nsns.countplot(y_val[\"salary\"])\nplt.title(\"Validation Data\")\n\nplt.subplot(1,3,3)\nsns.countplot(y_test[\"salary\"])\nplt.title(\"Test Data\")\nplt.subplots_adjust(wspace = 2)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scale the data ","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler()\n\nX_train[num_cols.columns] =  sc.fit_transform(X_train[num_cols.columns])\nX_val[num_cols.columns] =  sc.transform(X_val[num_cols.columns])\nX_test[num_cols.columns] =  sc.transform(X_test[num_cols.columns])\n\nX_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test[\"salary\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"log_reg = LogisticRegression()\n\n\nlog_reg.fit(X_train,y_train)\n\nprint(f\"Accuracy on the training set is {log_reg.score(X_train,y_train)}.\")\nprint(f\"Accuracy on the validation set is {log_reg.score(X_val,y_val)}.\")\nprint(f\"Accuracy on the test set is {log_reg.score(X_test,y_test)}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grid Search for tuning","metadata":{}},{"cell_type":"code","source":"params = {\"penalty\" : [\"l1\", \"l2\", \"elasticnet\"],\n         \"C\": [0.01, 0.05, 0.1, 0.5, 1, 2]}\n\ngrid_cv = GridSearchCV(LogisticRegression(n_jobs = -1),params)\n\ngrid_cv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(grid_cv.best_params_)\n#Best params are the default values so no need for a new model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_preds = log_reg.predict(X_test)\nlog_cm = confusion_matrix(y_test,log_preds)\nprint(log_cm)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_precision =precision_score(y_test, log_preds)\nlog_recall=recall_score(y_test, log_preds)\nlog_accuracy = accuracy_score(y_test, log_preds)\n\nprint(\"Precision = {}\".format(log_precision))\nprint(\"Recall = {}\".format(log_recall))\nprint(\"Accuracy = {}\".format(log_accuracy))\n\nprint(\"Area under the curve: {}.\".format(roc_auc_score(y_test,log_reg.decision_function(X_test)))) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-nearest Neighbors","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_jobs = -1)\nknn.fit(X_train,y_train)\n\nprint(f\"Accuracy on the training set is {knn.score(X_train,y_train)}.\")\nprint(f\"Accuracy on the validation set is {knn.score(X_val,y_val)}.\")\nprint(f\"Accuracy on the test set is {knn.score(X_test,y_test)}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Manually calculate the best k-value using the validation set","metadata":{}},{"cell_type":"code","source":"validation_accuracies = []\n\nfor i in range(5,50,5):\n    knn = KNeighborsClassifier(n_jobs = -1,n_neighbors = i )\n    knn.fit(X_train,y_train)\n    validation_accuracies.append(knn.score(X_val, y_val))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(5,50,5), validation_accuracies)\nplt.title(\"Validation accuracies for different k values\")\nplt.xlabel(\"k values\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_values = range(5,50,5)\n\nprint(f\"The best k-value is: {k_values[validation_accuracies.index(max(validation_accuracies))]}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_best = KNeighborsClassifier(n_jobs = -1,n_neighbors = 20 )\nknn_best.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_preds = knn_best.predict(X_test)\nknn_cm = confusion_matrix(y_test,knn_preds)\nprint(knn_cm)\n\nknn_precision =precision_score(y_test, knn_preds)\nknn_recall = recall_score(y_test, knn_preds)\nknn_accuracy = accuracy_score(y_test, knn_preds)\n\nprint(\"Precision = {}\".format(knn_precision))\nprint(\"Recall = {}\".format(knn_recall))\nprint(\"Accuracy = {}\".format(knn_accuracy))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{}},{"cell_type":"code","source":"xgb = xgboost.XGBClassifier(nthread = -1)\nxgb.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy on the training set is {xgb.score(X_train,y_train)}.\")\nprint(f\"Accuracy on the validation set is {xgb.score(X_val,y_val)}.\")\nprint(f\"Accuracy on the test set is {xgb.score(X_test,y_test)}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {\n     \"eta\"    : [0.05, 0.15,0.30 ] ,\n     \"n_estimators\" : [ 50,100,200],\n     #\"min_child_weight\" : [ 1, 5, 7 ],\n     #\"gamma\"            : [ 0.0, 0.2 , 0.4 ],\n     #\"colsample_bytree\" : [ 0.3, 0.5 , 0.7 ],\n    \"learning_rate\":[0.001,0.01,0.1]\n     }\n\nrandom_cv = RandomizedSearchCV(xgboost.XGBClassifier(nthreads = -1),\n                    parameters, n_jobs=-1,\n                    cv=3, random_state = 0)\n\nrandom_cv.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_best = xgboost.XGBClassifier(nthreads = -1,n_estimators = 200, learning_rate = 0.1, eta = 0.15 )\nxgb_best.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_preds = xgb_best.predict(X_test)\nxgb_cm = confusion_matrix(y_test,xgb_preds)\nprint(xgb_cm)\n\nxgb_precision =precision_score(y_test, xgb_preds)\nxgb_recall = recall_score(y_test, xgb_preds)\nxgb_accuracy = accuracy_score(y_test, xgb_preds)\n\nprint(\"Precision = {}\".format(xgb_precision))\nprint(\"Recall = {}\".format(xgb_recall))\nprint(\"Accuracy = {}\".format(xgb_accuracy))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs = -1, random_state = 0)\nrf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Accuracy on the training set is {rf.score(X_train,y_train)}.\")\nprint(f\"Accuracy on the validation set is {rf.score(X_val,y_val)}.\")\nprint(f\"Accuracy on the test set is {rf.score(X_test,y_test)}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The random forest is clearly overfitting","metadata":{}},{"cell_type":"code","source":"params = {\"n_estimators\":range(10,400,50),\n         \"max_depth\":range(5,100,10),\n          \"criterion\":[\"gini\", \"entropy\"],\n          \"min_samples_split\":range(2,10,2)\n         }\n\nrandom_cv = RandomizedSearchCV(RandomForestClassifier(), params, n_jobs = -1, random_state = 1)\n\nrandom_cv.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_cv.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_accuracies = []\n\nfor i in range(160,300,10):\n    rf = RandomForestClassifier(n_jobs = -1,n_estimators = i , random_state = 0)\n    rf.fit(X_train,y_train)\n    validation_accuracies.append(rf.score(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(160,300,10), validation_accuracies)\nplt.title(\"Validation accuracies for different number of estimators\")\nplt.xlabel(\"number of estimators\")\nplt.ylabel(\"Accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_estimators = range(160,300,10)\n\nprint(f\"The best number of estimators is: {n_estimators[validation_accuracies.index(max(validation_accuracies))]}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_best = RandomForestClassifier(min_samples_split = 6, max_depth = 25, criterion = 'entropy', n_estimators = 200)\nrf_best.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_preds = rf_best.predict(X_test)\nrf_cm = confusion_matrix(y_test,rf_preds)\nprint(rf_cm)\n\nrf_precision =precision_score(y_test, rf_preds)\nrf_recall = recall_score(y_test, rf_preds)\nrf_accuracy = accuracy_score(y_test, rf_preds)\n\nprint(\"Precision = {}\".format(rf_precision))\nprint(\"Recall = {}\".format(rf_recall))\nprint(\"Accuracy = {}\".format(rf_accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Neural Network","metadata":{}},{"cell_type":"code","source":"def build_nn_model(metric = \"accuracy\", learning_rate = 0.01):\n    \n    model = Sequential()\n    \n    model.add(Dense(32, input_shape = (X_train.shape[1],)))\n    model.add(Dense(64, Activation(\"relu\")))\n    model.add(Dense(128, Activation(\"relu\")))\n    model.add(Dense(128, Activation(\"relu\")))\n    model.add(Dense(1))\n    \n    learning_rate = learning_rate\n    optimizer = optimizers.Adam(learning_rate)\n    model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n                 optimizer = optimizer,\n                 metrics = [metric])\n    \n    return model\n\nmodel = build_nn_model(metric = \"binary_accuracy\")\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 30\nbatch_size = 16\n\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    batch_size = batch_size, \n    epochs = EPOCHS,\n    verbose = 1,\n    validation_data = (X_val,y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_test, y_test)\nscore","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = pd.DataFrame(history.history)\nhist[\"epoch\"] = history.epoch\nhist.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,8))\nplt.plot(history.history[\"binary_accuracy\"])\nplt.plot(history.history[\"val_binary_accuracy\"])\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_preds = model.predict(X_test)\nnn_preds = (nn_preds > 0.5)\n\nnn_precision =precision_score(y_test, nn_preds)\nnn_recall = recall_score(y_test, nn_preds)\nnn_accuracy = accuracy_score(y_test, nn_preds)\n\nprint(\"Precision = {}\".format(nn_precision))\nprint(\"Recall = {}\".format(nn_recall))\nprint(\"Accuracy = {}\".format(nn_accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparing Models","metadata":{}},{"cell_type":"code","source":"#Logistic\nlog_results = [\"Logistic Regression\",log_precision, log_recall, log_accuracy]\n\n#Knn\nknn_results = [\"K-Nearest Neighbours\",knn_precision, knn_recall, knn_accuracy]\n\n#Random Forest\nrf_results = [\"Random Forest\",rf_precision, rf_recall, rf_accuracy]\n\n#XGBoost\nxgb_results = [\"XGBoost\",xgb_precision, xgb_recall, xgb_accuracy]\n\n#Neural Network\nnn_results = [\"Neural Network\",nn_precision, nn_recall, nn_accuracy]\n\n\nall_results = pd.DataFrame([log_results, knn_results, rf_results, xgb_results, nn_results],columns = [\"Model\",\"Precision\", \"Recall\", \"Accuracy\"])\n\nall_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,10))\nall_results.plot(x = \"Model\", y = [\"Precision\", \"Recall\", \"Accuracy\"], kind = \"bar\")\nplt.legend(loc = \"upper right\", bbox_to_anchor=(1.3, 1))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PLot Cm\nplt.figure(figsize = (6,5))\nax = plt.subplot()\nsns.heatmap(xgb_cm, ax=ax, annot = True)\nax.set_ylabel(\"True Labels\")\nax.set_xlabel(\"Predicted Labels\")\nax.set_title(\"Confusion Matrix for XGBoost Classifier\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}