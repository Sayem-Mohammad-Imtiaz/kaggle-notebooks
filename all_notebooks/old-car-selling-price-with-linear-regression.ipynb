{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car = pd.read_csv(\"/kaggle/input/vehicle-dataset-from-cardekho/CAR DETAILS FROM CAR DEKHO.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding new Variable for reference ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car['current']= 2020","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding new variable for Age column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car['age']=car['current']-car['year']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop all non required or repeative data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car.drop(['current','year','name'],axis=1,inplace=True)\ncar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Point to note\n- Dataset has 4340 rows and 7 columns.\n- Looking at the data, there seems to be some fields that are categorical in nature, but in integer/float type.\n\n- We will analyse and finalize whether to convert them to categorical or treat as integer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# DATA QUALITY CHECK","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Check for NULL/MISSING values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentage of missing values in each column\nround(100*(car.isnull().sum()/len(car)),2).sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentage of missing values in each row\nround(100*(car.isnull().sum(axis=1)/len(car)),2).sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding\n- There are no missing / Null values either in columns or rows\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Duplicate Check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_dub=car.copy()\n# Checking for duplicates and dropping the entire duplicate row if any\ncar_dub.drop_duplicates(subset=None, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_dub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insights\n- The shape after running the drop duplicate command is not same as the original dataframe.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Assign non duplicates records to orginal record ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car=car_dub\ncar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n\nChecking value_counts() for entire dataframe.\n\nThis will help to identify any Unknow/Junk values present in the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in car:\n    print(car[col].value_counts(ascending=False), '\\n\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights\n- There seems to be no Junk/Unknown values in the entire dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Creating Dummy Variables\n- We will create DUMMY variables for 4 categorical variables 'mnth', 'weekday', 'season' & 'weathersit'.\n\n- Before creating dummy variables, we will have to convert them into 'category' data types.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#To hold original data & column after duplicates are removed\ncar_o=car.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to 'category' data type\ncar['fuel']=car['fuel'].astype('category')\ncar['seller_type']=car['seller_type'].astype('category')\ncar['transmission']=car['transmission'].astype('category')\ncar['owner']=car['owner'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This code does 3 things:\n# 1) Create Dummy variable\n# 2) Drop original variable for which the dummy was created\n# 3) Drop first dummy variable for each set of dummies created.\n\ncar = pd.get_dummies(car, drop_first=True)\ncar.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SPLITTING THE DATA\n- Splitting the data to Train and Test: - We will now split the data into TRAIN and TEST (70:30 ratio)\n- We will use train_test_split method from sklearn package for this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the shape before spliting\n\ncar.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the info before spliting\n\ncar.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We should specify 'random_state' so that the train and test data set always have the same rows, respectively\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(car, train_size = 0.70, test_size = 0.30, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Verify the info and shape of the dataframes after split:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS\n- We need to perform the EDA on TRAINING (df_train) Dataset.\n\n\n## Visualising Numeric Variables\n- Let's make a pairplot of all the numeric variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new dataframe of only numeric variables:\n\ncar_n=df_train[[ 'selling_price', 'km_driven', 'age']]\n\nsns.pairplot(car_n, diag_kind='kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights\n- The above Pair-Plot tells us that there is a LINEAR RELATION between 'selling_price','km_driven' and 'age'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Visualising Catagorical Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build boxplot of all categorical variables (before creating dummies) againt the target variable 'selling_price' \n# to see how each of the predictor variable stackup against the target variable.\n\nplt.figure(figsize=(25, 10))\nplt.subplot(2,2,1)\nsns.boxplot(x = 'fuel', y = 'selling_price', data = car_o)\nplt.subplot(2,2,2)\nsns.boxplot(x = 'seller_type', y = 'selling_price', data = car_o)\nplt.subplot(2,2,3)\nsns.boxplot(x = 'transmission', y = 'selling_price', data = car_o)\nplt.subplot(2,2,4)\nsns.boxplot(x = 'owner', y = 'selling_price', data = car_o)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There were 4 categorical variables in the dataset.\n\nWe used Box plot (refer the fig above) to study their effect on the dependent variable (‘selling_price’) .\n\nThe inference that We could derive were:\n\n- **season :** Diesel & Petrol consists of 99% of all available fuel column data available. \n- **transmission :** Manual consists of 91% of all available transmission column data available.\n- **seller_type :** Individual consists of 79% of all available seller_type column data available, i.e. highest in all.\n- **seller_type :** First Owner consists of 61% of all available owner column data available, i.e. highest in all.\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the correlation coefficients to see which variables are highly correlated. Note:\n# here we are considering only those variables (dataframe: car) that were chosen for analysis\n\nplt.figure(figsize = (25,20))\nsns.heatmap(car.corr(), annot = True, cmap=\"RdBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights:\n- The heatmap clearly shows which all variable are multicollinear in nature, and which variable have high collinearity with the target variable.\n- We will refer this map back-and-forth while building the linear model so as to validate different correlated values along with VIF & p-value, for identifying the correct variable to select/eliminate from the model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## RESCALING THE FEATURES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the values before scaling\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #Apply scaler() to all the numeric variables\n\nnum_vars = ['selling_price', 'km_driven', 'age']\n\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BUILDING A LINEAR MODEL\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Dividing into X and Y sets for the model building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train.pop('selling_price')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RFE\nRecursive feature elimination: We will be using the **LinearRegression function from SciKit Learn** for its compatibility with RFE (which is a utility from sklearn)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 7\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 7)             # running RFE\nrfe = rfe.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Linear Model using 'STATS MODEL'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Model 1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### VIF Check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\n# Add a constant\nX_train_lm1 = sm.add_constant(X_train_rfe)\n\n# Create a first fitted model\nlr1 = sm.OLS(y_train, X_train_lm1).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the parameters obtained\n\nlr1.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print a summary of the linear regression model obtained\nprint(lr1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2\n- Removing the variable 'fuel_Electric' based on its High p-value ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_rfe.drop([\"fuel_Electric\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add a constant\nX_train_lm2 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr2 = sm.OLS(y_train, X_train_lm2).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the parameters obtained\n\nlr2.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print a summary of the linear regression model obtained\nprint(lr2.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 3  \n- Removing the variable 'owner_Test Drive Car' based on its High p-value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"owner_Test Drive Car\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF Check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add a constant\nX_train_lm3 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr3 = sm.OLS(y_train, X_train_lm3).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the parameters obtained\n\nlr3.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print a summary of the linear regression model obtained\nprint(lr3.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 4\n-Removing the variable 'seller_type_Trustmark Dealer ' based on its High p-value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"seller_type_Trustmark Dealer\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIF Check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add a constant\nX_train_lm4 = sm.add_constant(X_train_new)\n\n# Create a first fitted model\nlr4 = sm.OLS(y_train, X_train_lm4).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the parameters obtained\n\nlr4.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print a summary of the linear regression model obtained\nprint(lr4.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights\n- This model looks good, as there seems to be VERY LOW Multicollinearity between the predictors and the p-values for all the predictors seems to be significant. For now, we will consider this as our final model (unless the Test data metrics are not significantly close to this number).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Final Model Interpretation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Hypothesis Testing:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Hypothesis testing states that:\n\n- H0:B1=B2=...=Bn=0\n- H1: at least one Bi!=0\n\nlr4 model coefficient values\n- const                  0.159292\n- km_driven             -0.081104\n- age                   -0.132559\n- fuel_Diesel            0.032289\n- transmission_Manual   -0.087353","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Insights\n- From the lr4  model summary, it is evident that all our coefficients are not equal to zero which means We REJECT the NULL HYPOTHESIS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### F Statistics\n\n#### F-Statistics is used for testing the overall significance of the Model: Higher the F-Statistics, more significant the Model is.\n\n- F-statistic:                     466.7\n- Prob (F-statistic):          3.70e-299\nThe F-Statistics value of 466.7 (which is greater than 1) and the p-value of '~0.0000' states that the overall model is significant","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# The equation of best fitted surface based on model lr4:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**selling_price** = 0.159292 - (**km_driven** * **0.081104**) - (**age** * 0.132559) + ( **fuel_Diesel** * 0.032289) - ( **transmission_Manual** * 0.087353)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Interpretation of Coefficients:\n\n- **km_driven**: A coefficient value of ‘0.081104’ indicated that a unit increase in km_driven variable, decreases the selling_price numbers by 0.081104 units.\n\n- **age**: A coefficient value of ‘-0.132559’ indicated that, a unit increase in age  variable, decreases the selling_price numbers by 0.132559 units.\n\n- **fuel_Diesel**: A coefficient value of ‘0.032289’ indicated that w.r.t Petrol, a unit increase in fuel_Diesel variable increases the selling_price numbers by 0.032289 units.\n\n- **transmission_Manual**: A coefficient value of ‘-0.087353’ indicated that w.r.t Automatic, a unit increase in transmission_Manual variable decreases the selling_price numbers by 0.087353 units.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  ASSUMPTIONS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Error terms are normally distributed with mean zero (not X, Y)\n\n- Residual Analysis Of Training Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = lr4.predict(X_train_lm4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = y_train-y_train_pred\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((res), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insights\n- From the above histogram, we could see that the Residuals are normally distributed. Hence our assumption for Linear Regression is valid.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## There is a linear relationship between X and Y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"car_n=car[[ 'selling_price', 'km_driven', 'age']]\n\nsns.pairplot(car_n, diag_kind='kde')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insight\n- Using the pair plot, we could see there is a linear relation between km_driven and age variable with the predictor ‘selling_price’.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## There is No Multicollinearity between the predictor variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_new.columns\nvif['VIF'] = [variance_inflation_factor(X_train_new.values, i) for i in range(X_train_new.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Insight\n- From the VIF calculation we could find that there is no multicollinearity existing between the predictor variables, as all the values are within permissible range of below 5","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# MAKING PREDICTION USING FINAL MODEL\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that we have fitted the model and checked the assumptions, it's time to go ahead and make predictions using the final model (lr4)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Applying the scaling on the test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply scaler() to all the numeric variables\n\nnum_vars = ['selling_price', 'km_driven', 'age']\n\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dividing into X_test and y_test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop('selling_price')\nX_test = df_test\nX_test.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting the variables that were part of final model.\ncol1=X_train_new.columns\nX_test=X_test[col1]\n# Adding constant variable to test dataframe\nX_test_lm4 = sm.add_constant(X_test)\nX_test_lm4.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions using the final model (lr6)\n\ny_pred = lr4.predict(X_test_lm4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL EVALUATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y_test, y_pred, alpha=.5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R^2 Value for TEST","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adjusted R^2 Value for TEST","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We already have the value of R^2 (calculated in above step)\n\nr2=0.3618371256083056 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the shape of X_test\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n is number of rows in X\n\nn = X_test.shape[0]\n\n\n# Number of features (predictors, p) is the shape along axis 1\np = X_test.shape[1]\n\n# We find the Adjusted R-squared using the formula\n\nadjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\nadjusted_r2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Result Comparison\n- Train R^2 :0.433\n- Train Adjusted R^2 :0.432\n- Test R^2 :0.362 \n- Test Adjusted R^2 :0.360\n\nThis seems to be a really good model that can moderate 'Generalize' various datasets.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# FINAL REPORT","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As per our final Model, the top predictor variables that influences the selling_prize are:\n- **km_driven**: A coefficient value of ‘0.081104’ indicated that a unit increase in km_driven variable, decreases the selling_price numbers by 0.081104 units.\n\n- **age**: A coefficient value of ‘-0.132559’ indicated that, a unit increase in age  variable, decreases the selling_price numbers by 0.132559 units.\n\n- **fuel_Diesel**: A coefficient value of ‘0.032289’ indicated that w.r.t Petrol, a unit increase in fuel_Diesel variable increases the selling_price numbers by 0.032289 units.\n\n- **transmission_Manual**: A coefficient value of ‘-0.087353’ indicated that w.r.t Automatic, a unit increase in transmission_Manual variable decreases the selling_price numbers by 0.087353 units.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}