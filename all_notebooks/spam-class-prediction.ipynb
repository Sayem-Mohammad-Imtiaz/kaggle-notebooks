{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = 1999\npd.options.display.max_rows = 999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the dataset of CSV file\ndf_train = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv',encoding = 'latin-1')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns = ['label', 'message']\ndf_train.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = {'ham' :0 , 'spam' :1}\ndf_train['label'] = df_train['label'].map(x)\ndf_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['label'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby('label').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (5,5))\nsns.countplot(x = df_train['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change all character to lower case\ndf_train['message'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['message'][0].split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nimport spacy\nsp = spacy.load('en_core_web_sm')\nall_stopwords = sp.Defaults.stop_words\nimport re\ndef punc(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z A-Z 0-9-]+','', text)#Remove special/digit character and punctuation\n    text = re.sub(r'@[A-Za-z0-9]+','',text) #Remove URL\n    text = text.strip(' ')\n    text = text.strip('. .')\n    text = text.replace('.',' ')\n    text = text.replace('-',' ')\n    text = text.replace(\"’\", \"'\").replace(\"′\", \"'\").replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\n    text = text.split(\" \")\n    tokens_filtered= [word for word in text if not word in all_stopwords]\n    lemm = WordNetLemmatizer()\n    lemm_text = [lemm.lemmatize(i) for i in tokens_filtered]\n    return (\" \").join(tokens_filtered)\ndf_train['message']=df_train['message'].apply(lambda x:punc(x))\ndf_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['message'] = df_train['message'].apply(lambda x:''.join(c for c in x if not c.isnumeric()))\ndf_train.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['message'][2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['message'][44]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#contraction to Expansion\ncontractions = {\n\"aight\": \"alright\",\n\"ain't\": \"am not\",\n\"amn't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"can not\",\n\"cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"daren't\": \"dare not\",\n\"daresn't\": \"dare not\",\n\"dasn't\": \"dare not\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"d'ye\": \"do you\",\n\"e'er\": \"ever\",\n\"everybody's\": \"everybody is\",\n\"everyone's\": \"everyone is\",\n\"finna\": \"fixing to\",\n\"g'day\": \"good day\",\n\"gimme\": \"give me\",\n\"giv'n\": \"given\",\n\"gonna\": \"going to\",\n\"gon't\": \"go not\",\n\"gotta\": \"got to\",\n\"hadn't\": \"had not\",\n\"had've\": \"had have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had\",\n\"he'dn't've'd\": \"he would not have had\",\n\"he'll\": \"he will\",\n\"he's\": \"he is\",\n\"he've\": \"he have\",\n\"how'd\": \"how would\",\n\"howdy\": \"how do you do\",\n\"how'll\": \"how will\",\n\"how're\": \"how are\",\n\"I'll\": \"I will\",\n\"I'm\": \"I am\",\n\"I'm'a\": \"I am about to\",\n\"I'm'o\": \"I am going to\",\n\"innit\": \"is it not\",\n\"I've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'll\": \"it will\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"may've\": \"may have\",\n\"methinks\": \"me thinks\",\n\"mightn't\": \"might not\",\n\"might've\": \"might have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"must've\": \"must have\",\n\"needn't\": \"need not\",\n\"ne'er\": \"never\",\n\"o'clock\": \"of the clock\",\n\"o'er\": \"over\",\n\"ol'\": \"old\",\n\"oughtn't\": \"ought not\",\n\"'s\": \"is\",\n\"shalln't\": \"shall not\",\n\"shan't\": \"shall not\",\n\"she'd\": \"she would\",\n\"she'll\": \"she shall\",\n\"she'll\": \"she will\",\n\"she's\": \"she has\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"somebody's\": \"somebody has\",\n\"somebody's\": \"somebody is\",\n\"someone's\": \"someone has\",\n\"someone's\": \"someone is\",\n\"something's\": \"something has\",\n\"something's\": \"something is\",\n\"so're\": \"so are\",\n\"that'll\": \"that shall\",\n\"that'll\": \"that will\",\n\"that're\": \"that are\",\n\"that's\": \"that has\",\n\"that's\": \"that is\",\n\"that'd\": \"that would\",\n\"that'd\": \"that had\",\n\"there'd\": \"there had\",\n\"there'd\": \"there would\",\n\"there'll\": \"there shall\",\n\"there'll\": \"there will\",\n\"there're\": \"there are\",\n\"there's\": \"there has\",\n\"there's\": \"there is\",\n\"these're\": \"these are\",\n\"these've\": \"these have\",\n\"they'd\": \"they had\",\n\"they'd\": \"they would\",\n\"they'll\": \"they shall\",\n\"they'll\": \"they will\",\n\"they're\": \"they are\",\n\"they're\": \"they were\",\n\"they've\": \"they have\",\n\"this's\": \"this has\",\n\"this's\": \"this is\",\n\"those're\": \"those are\",\n\"those've\": \"those have\",\n\"'tis\": \"it is\",\n\"to've\": \"to have\",\n\"'twas\": \"it was\",\n\"wanna\": \"want to\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had\",\n\"we'd\": \"we would\",\n\"we'd\": \"we did\",\n\"we'll\": \"we shall\",\n\"we'll\": \"we will\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'd\": \"what did\",\n\"what'll\": \"what shall\",\n\"what'll\": \"what will\",\n\"what're\": \"what are\",\n\"what're\": \"what were\",\n\"what's\": \"what has\",\n\"what's\": \"what is\",\n\"what's\": \"what does\",\n\"what've\": \"what have\",\n\"when's\": \"when has\",\n\"when's\": \"when is\",\n\"where'd\": \"where did\",\n\"where'll\": \"where shall\",\n\"where'll\": \"where will\",\n\"where're\": \"where are\",\n\"where's\": \"where has\",\n\"where's\": \"where is\",\n\"where's\": \"where does\",\n\"where've\": \"where have\",\n\"which'd\": \"which had\",\n\"which'd\": \"which would\",\n\"which'll\": \"which shall\",\n\"which'll\": \"which will\",\n\"which're\": \"which are\",\n\"which's\": \"which has\",\n\"which's\": \"which is\",\n\"which've\": \"which have\",\n\"who'd\": \"who would\",\n\"who'd\": \"who had\",\n\"who'd\": \"who did\",\n\"who'd've\": \"who would have\",\n\"who'll\": \"who shall\",\n\"who'll\": \"who will\",\n\"who're\": \"who are\",\n\"who's\": \"who has\",\n\"who's\": \"who is\",\n\"who's\": \"who does\",\n\"who've\": \"who have\",\n\"why'd\": \"why did\",\n\"why're\": \"why are\",\n\"why's\": \"why has\",\n\"why's\": \"why is\",\n\"why's\": \"why does\",\n\"won't\": \"will not\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd've\": \"you all would have\",\n\"y'all'dn't've'd\": \"you all would not have had\",\n\"y'all're\": \"you all are\",\n\"you'd\": \"you had\",\n\"you'd\": \"you would\",\n\"you'll\": \"you shall\",\n\"you'll\": \"you will\",\n\"you're\": \"you are\",\n\"you're\": \"you are\",\n\"you've\": \"you have\",\n\" u \": \"you\",\n\" ur \": \"your\",\n\" n \": \"and\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cont_to_exp(x):\n    if type(x) is str:\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key,value)\n        return x\n    else:\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['message'] = df_train['message'].apply(lambda x: cont_to_exp(x))\ndf_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['label']==0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['label']==1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df_train=df_train['message']\ny_df_train=df_train['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nTfidfVect = TfidfVectorizer(max_features=2500)\nx_vector  =TfidfVect.fit_transform(x_df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_vector.todense()[1],x_vector.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_vector.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #cat = x_vector.select_dtypes(include=[np.number])\n# numeric_train = x_vector.select_dtypes(include=[np.number])\n# numeric_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \n\n# split into 70:30 ration \nX_train, X_test, y_train, y_test = train_test_split(x_vector, y_df_train, test_size = 0.3, random_state = 0) \n\n# describes info about train and test set \nprint(\"Number transactions X_train dataset: \", X_train.shape) \nprint(\"Number transactions y_train dataset: \", y_train.shape) \nprint(\"Number transactions X_test dataset: \", X_test.shape) \nprint(\"Number transactions y_test dataset: \", y_test.shape) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts(),y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_features_test = pd.DataFrame(x_vector.toarray())\nx_features_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE()\nxtrain_smote, ytrain_smote = smote.fit_sample(x_vector,y_df_train)\nxtrain_smote","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_smote.shape,ytrain_smote.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_smote.dtype,ytrain_smote.dtype,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(xtrain_smote, ytrain_smote)\n\ny_pred=spam_detect_model.predict(X_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nclass_report = classification_report(y_pred,y_test)\nclass_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconf = confusion_matrix(y_pred,y_test)\nconf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(conf,annot = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}