{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import regularizers\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/real-time-advertisers-auction/Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weird_division(n, d):\n    return n / d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove total revenue and measurable impressions since they are used to calculate the target metric\ndf.drop(['total_revenue'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The dataset has {} rows and {} columns.\".format(*df.shape))\nprint(\"It contains {} duplicates.\".format(df.duplicated().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.CPM.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process categorial features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorial_features = ['site_id', 'ad_type_id', 'geo_id', 'device_category_id', 'advertiser_id', 'os_id',\n                       'integration_type_id', 'monetization_channel_id', 'ad_unit_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorial_features:\n    df[col] = df[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_feats = df.select_dtypes(include=['float64', 'int64', 'bool', 'object']).copy()\n\n# one-hot encoding of categorical features\ncat_feats = df.select_dtypes(include=['category']).copy()\ncat_feats = pd.get_dummies(cat_feats)\ncat_feats = cat_feats[cat_feats.columns[(cat_feats.sum() > 5000).values]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_recoded = pd.concat([num_feats, cat_feats], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_recoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The dataset has {} rows and {} columns.\".format(*features_recoded.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split into train and test datasets (test set will be used in the end)"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_recoded['date'] = pd.to_datetime(df['date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Date cut-off:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = features_recoded[features_recoded.date >= pd.to_datetime('2019-06-22')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply a 95%-condition and a non-negative value condition on a test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test_df[test_df['CPM'] >= 0]\ntest_df = test_df[test_df['CPM'] < test_df['CPM'].quantile(0.95)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set aside test_X and test_y dataframes for later use (to get final results after CV)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X = test_df.drop(['date', 'CPM'], axis = 1)\ntest_y = test_df.CPM","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now get train data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = features_recoded[features_recoded.date < pd.to_datetime('2019-06-22')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df['CPM'] >= 0]\ntrain_df = train_df[train_df['CPM'] < train_df['CPM'].quantile(0.95)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_features = train_df.drop(['date', 'CPM'], axis = 1)\ntrain_target = train_df.CPM","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import train_test_split function\nfrom sklearn.model_selection import train_test_split\n# import metrics\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# split our data\ntrain_X_train, train_X_test, train_y_train, train_y_test = train_test_split(train_df_features, train_target, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale data\nsc = StandardScaler()\nX_train = sc.fit_transform(train_X_train)\nX_test  = sc.transform(train_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nseed = 15\nnp.random.seed(seed)\n\nprint(tf.__version__)\n\nlinear_model = tf.keras.Sequential([\n    layers.Dense(units=700, activation='relu', kernel_regularizer=regularizers.l2(5)),\n    layers.Dropout(0.5),\n    layers.Dense(units=150, activation='relu', kernel_regularizer=regularizers.l2(1)),\n    layers.Dropout(0.5),\n    layers.Dense(units=1, activation='linear')\n])\n\nkeras.backend.set_epsilon(0.01)\nlinear_model.compile(\n    optimizer=tf.optimizers.Adam(),\n    loss='mean_squared_error')\n\nhistory = linear_model.fit(\n    X_train, train_y_train,\n    epochs=150,\n    # suppress logging\n    verbose=2,\n    # Calculate validation results on 20% of the training data\n    use_multiprocessing=True,\n    validation_split=0.2\n    ,batch_size=2048\n)\n\ny_hat = linear_model.predict(X_test).flatten()\nprint(\"Score on cross-validation is \", mean_squared_error(y_hat, train_y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss(model_history):\n    train_loss=[value for key, value in model_history.items() if 'loss' in key.lower()][0]\n    valid_loss=[value for key, value in model_history.items() if 'loss' in key.lower()][1]\n    fig, ax1 = plt.subplots()\n    color = 'tab:blue'\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss', color=color)\n    ax1.plot(train_loss, '--', color=color, label='Train Loss')\n    ax1.plot(valid_loss, color=color, label='Valid Loss')\n    ax1.tick_params(axis='y', labelcolor=color)\n    plt.legend(loc='upper left')\n    plt.title('Model Loss')\n    plt.show()\n    \nplot_loss(history.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train set score is \", mean_squared_error(y_hat, train_y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get predictions and compute MSE on deferred test"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(train_df_features)\nX_test  = sc.transform(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 15\nnp.random.seed(seed)\n\nprint(tf.__version__)\n\nlinear_model = tf.keras.Sequential([\n    layers.Dense(units=700, activation='relu', kernel_regularizer=regularizers.l2(5)),\n    layers.Dropout(0.5),\n    layers.Dense(units=150, activation='relu', kernel_regularizer=regularizers.l2(1)),\n    layers.Dropout(0.5),\n    layers.Dense(units=1, activation='linear')\n])\n\nkeras.backend.set_epsilon(0.01)\nlinear_model.compile(\n    optimizer=tf.optimizers.Adam(),\n    loss='mean_squared_error')\n\n\nhistory = linear_model.fit(\n    X_train, train_target, \n    epochs=150,\n    # suppress logging\n    verbose=2,\n    # Calculate validation results on 20% of the training data\n    use_multiprocessing=True,\n    validation_split=0.2\n    ,batch_size=2048\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = linear_model.predict(X_test).flatten()\nprint(\"Test Set MSE is \", mean_squared_error(y_hat, test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}