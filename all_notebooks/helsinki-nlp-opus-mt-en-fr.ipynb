{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nimport torch\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using only 200000 rows\nr_rows = 200000\ndf = pd.read_csv('../input/en-fr-translation-dataset/en-fr.csv' , nrows = r_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting every letter to lower case\ndf['en'] = df['en'].apply(lambda x: str(x).lower())\ndf['fr'] = df['fr'].apply(lambda x: str(x).lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing apostrophe from the sentences\ndf['en'] = df['en'].apply(lambda x: re.sub(\"'\",\"\",x))\ndf['fr'] = df['fr'].apply(lambda x: re.sub(\"'\",\"\",x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude = set(string.punctuation)\n# removing all the punctuations\ndf['en'] = df['en'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\ndf['fr'] = df['fr'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing digits from the sentences\ndigit = str.maketrans('','',string.digits)\ndf['en'] = df['en'].apply(lambda x: x.translate(digit))\ndf['fr'] = df['fr'].apply(lambda x: x.translate(digit))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using pretrained model and then finetunig it on our dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ntokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\").to('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(),lr=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_train():\n    model.train()\n    losses = 0\n    X = df['en']\n    y = df['fr']\n    max_epochs = 15\n    n_batches = 32\n    for epoch in tqdm(range(max_epochs)):\n        for i in tqdm(range(n_batches)):\n            # making batches \n            local_X, local_y = X[i*n_batches:(i+1)*n_batches,], y[i*n_batches:(i+1)*n_batches,]\n            # preparing the data according to the model input\n            batch = tokenizer.prepare_seq2seq_batch(list(local_X),list(local_y),return_tensors='pt').to('cuda')\n            output = model(**batch)\n            # loss can be taken directly from the model output\n            loss = output.loss\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            losses = losses+loss\n    average = losses/len(df)\n    print('Loss: ' + str(average) )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = model.generate(**tokenizer.prepare_seq2seq_batch(['Hello , I have food'],return_tensors='pt').to('cuda'))\ntokenizer.batch_decode(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model , 'model.pkl')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}