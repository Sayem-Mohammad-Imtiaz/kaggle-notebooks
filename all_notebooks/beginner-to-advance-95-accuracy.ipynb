{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Contents:\n\n1. Import Libraries\n2. Import DataSets\n3. Handle Missing Value\n4. Exploratory Data Analysis(EDA)\n5. Feature selection\n6. Feature Engineering\n7. Train Xgboost Classifier\n8. Artificial Intelligence\n\nXgBoost - 92% Accuracy, AI - 95% Accuracy\n\n**check my beginners nodebook to know why i aaplied feature enginnering and Xgboost Classifier:**\n[Beginners Notebook-90% Accuracy][1] \n\n[1]: https://www.kaggle.com/harshkothari21/beginners-notebook-90-accuracy","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ny = train['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handle Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train.isnull(),yticklabels=False, cmap='plasma')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)[0:19]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum().sort_values(ascending=False)[0:33]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop columns with too much missing values\nPlus there is so much features to analyse that it may be better to concentrate on the ones which can give us real insights. Also I tried including these features in model but score was not up do the mark","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Alley', 'MiscFeature', 'Fence', 'GarageYrBlt']\n\ntrain.drop(columns=columns, inplace=True)\ntest.drop(columns=columns, inplace=True)\ntrain['PoolQC'] = train['PoolQC'].fillna('None')\ntest['PoolQC'] = test['PoolQC'].fillna('None')\n\ntrain.drop(columns=['Id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use mean for filling null values for numerical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['LotFrontage', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',  'TotalBsmtSF', 'GarageArea']\n\nfor item in columns:\n    train[item] = train[item].fillna(train[item].mean())\n    test[item] = test[item].fillna(test[item].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use mode for filling null values for categorical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['BsmtCond', 'BsmtQual', 'FireplaceQu', 'GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'MSZoning',\n           'MasVnrType', 'MasVnrArea', 'BsmtExposure','BsmtFinType2', 'BsmtFinType1', 'Electrical',  'Utilities',\n           'BsmtFullBath', 'BsmtHalfBath', 'Functional', 'SaleType', 'Exterior2nd', 'Exterior1st', 'KitchenQual']\n\nfor item in columns:\n    train[item] = train[item].fillna(train[item].mode()[0])\n    test[item] = test[item].fillna(test[item].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for missing values if any!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis(EDA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['SalePrice'], bins=100);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this information we can see that the prices are skewed right and some outliers lies above ~500,000. We will eventually want to get rid of the them to get a normal distribution of the independent variable (`SalePrice`) for machine learning.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Data Frame with only numerical features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num = train.select_dtypes(include = ['float64', 'int64'])\ndf_num.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take Top strongly correlated values with SalePrice:\n\n**I tried Selecting Top 10 features and trained my model but score was not up to the mark**","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_num_corr = df_num.corr()['SalePrice'][:-1]\ngolden_features_list = df_num_corr[abs(df_num_corr) >= 0].sort_values(ascending=False)\ngolden_features_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation by itself does not always explain the relationship between data so ploting them could even lead us to new insights and in the same manner, check that our correlated values have a linear relationship to the `SalePrice`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0, len(df_num.columns), 5):\n    sns.pairplot(data=df_num,\n                x_vars=df_num.columns[i:i+5],\n                y_vars=['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"if we look closely at the data we can see that a lot of data points are located on `x = 0` which may indicate the absence of such feature in the house.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Let's examine feature by correlation matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df_num.drop('SalePrice', axis=1).corr() # We already examined SalePrice correlations\nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's examine Non Numerical Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_not_num = train.select_dtypes(include = ['O'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(round(len(df_not_num.columns) / 3), 3, figsize=(12, 30))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(df_not_num.columns):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n        sns.countplot(x=df_not_num.columns[i], alpha=0.7, data=df_not_num, ax=ax)\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that some categories are predominant for some features such as `Utilities`, `Heating`, `GarageCond`, `Functional`... These features may not be relevant for our predictive model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's Just exclude that features from our model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"golden_features_list1 = list(df_not_num.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"excluded_features = ['GarageCond', 'Functional', 'Heating', 'BsmtFinType2', 'RoofMatl', 'Street', 'Utilities']\n\nfor item in excluded_features:\n    golden_features_list1.remove(item)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"golden_features_list = list(golden_features_list.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"golden_features_list.extend(golden_features_list1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[golden_features_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test[golden_features_list]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will be using onehot encoding technique for feature engineering ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.concat([train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ensuring null values is any**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def One_hot_encoding(columns):\n    df_final=final_df\n    i=0\n    for fields in columns:\n        df1=pd.get_dummies(final_df[fields],drop_first=True)\n        \n        final_df.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:           \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([final_df,df_final],axis=1)\n        \n    return df_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = One_hot_encoding(golden_features_list1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = df_final.loc[:,~df_final.columns.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train=df_final.iloc[:1460,:]\ndf_Test=df_final.iloc[1460:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_temp = pd.concat([df_Train,y],axis=1)\n#my_temp.to_csv('train_conv_1.csv',index=False)\n#df_Test.to_csv('test_conv_1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Xgboost Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### If you want know how I selected best parameter for XgBosst(HyperParameter Tunning): \n\n[Beginners Notebook-90% Accuracy][1] \n\n[1]: https://www.kaggle.com/harshkothari21/beginners-notebook-90-accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=None, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n             objective='reg:squarederror', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n             validate_parameters=1, verbosity=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.fit(df_Train,y);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regressor.predict(df_Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=pd.DataFrame(y_pred)\nsamp = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nsub = pd.concat([samp['Id'],pred], axis=1)\nsub.columns=['Id','SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub.to_csv('My_sub3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Artificial Intelligence\n\n**Below csv files have all features with applied feature engineering. If you want to know in detail, check my notebook :**\n\n[Beginners Notebook-90% Accuracy][1] \n\n[1]: https://www.kaggle.com/harshkothari21/beginners-notebook-90-accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/my-data/train_conv.csv')\ndf_test = pd.read_csv('../input/my-data/test_conv.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.drop(['Id'],axis=1, inplace=True)\ndf_Test=pd.concat([df_test,sub],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Train=pd.concat([df_train,df_Test],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=df_Train.drop(['SalePrice'],axis=1)\ny_train=df_Train['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout\n\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n\n# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n\n# Adding the third hidden layer\nclassifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n# Adding the output layer\nclassifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n\n# Compiling the ANN\nclassifier.compile(loss=root_mean_squared_error,optimizer='Adamax')\n\n# Fitting the ANN to the Training set\nmodel_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_pred=pd.DataFrame(ann_pred)\nsamp = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nsub = pd.concat([samp['Id'],ann_pred], axis=1)\nsub.columns=['Id','SalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sub.to_csv('My_sub_final.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}