{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nnp.set_printoptions(precision=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Working With CSV files"},{"metadata":{"trusted":true},"cell_type":"code","source":"Data = pd.read_csv('../input/pandas-practice-files/Required files/ex1.csv')    \nprint(type(Data))             \nData.head(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Working with TSV file (Tab Seprated Values)"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"Data_tsv = pd.read_table('../input/pandas-practice-files/Required files/test.tsv') \nData_tsv.head()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading tsv using read_csv\npd.read_table('../input/pandas-practice-files/Required files/ex1.csv', sep=',')\n# If We will not use sep=',' parameter it will read all the data into one column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_table('../input/pandas-practice-files/Required files/ex1.csv', sep=',',header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If we want our complete data, dont want to include it in header\npd.read_csv('../input/pandas-practice-files/Required files/ex2.csv', header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If we want to new columns explicitly\ndf =pd.read_csv('../input/pandas-practice-files/Required files/ex2.csv', names=['asdfdsfs','fsdf', 'b', 'c', 'sudh', 'message'])\n# for those columns which are not present in dataframe it will put Nan values\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can set index by passing column names, Which can be used for multi-level indexing also\nparsed = pd.read_csv('../input/pandas-practice-files/Required files/csv_mindex.csv',index_col=['key1', 'key2'])\nparsed","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# We can Skip the uncessary data to be loaded into our DataFrame by passing the index of rows we want to skip.\n# !cat ex4.csv\npd.read_csv('../input/pandas-practice-files/Required files/ex4.csv', skiprows=[0, 2, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.read_csv('../input/pandas-practice-files/Required files/ex5.csv')\nresult\n# To check is there any NaN Value in our DataFrame\npd.isnull(result)\n# It will Return a DataFrame of True where there is NaN value and False Where there is not a Nan Value.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can Set what Value to be filled in Nan Values\nresult = pd.read_csv('../input/pandas-practice-files/Required files/ex5.csv',na_values='world')\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can read data from Diffrent Sheets within a Single file also.\ndraft3 = pd.read_excel('../input/pandas-practice-files/Required files/ex1.xlsx',sheet_name = 0) # Name of sheet to read from\ndraft3.head(6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading HTML tables\n#### Note: It will the only data which is present in tabular form on website."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install lxml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"http://www.basketball-reference.com/leagues/NBA_2015_totals.html\"\nBB_data = pd.read_html(url)         # Read data from the specified url\nBB_data[0].iloc[:, 0:20].head(5)      # Check 5 rows (10 columns only)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train = pd.read_csv(\"https://gist.githubusercontent.com/michhar/2dfd2de0d4f8727f873422c5d959fff5/raw/ff414a1bcfcba32481e4d4e8db578e55872a2ca1/titanic.csv\",\n                           sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.head(10) # checking 10 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we set others string or charater to be treated as Nan values\nresult = pd.read_csv('../input/pandas-practice-files/Required files/ex5.csv',na_values='world')\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting Column with index ('Name','Pclass')\ntitanic_train[[\"Name\",\"Pclass\"]].head() # by default head read first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Data type of each column\ntitanic_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Python allows us to customise some Settings\npd.options.display.max_rows = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.read_csv('../input/pandas-practice-files/Required files/ex6.csv')\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It will only read 5 rows to our dataSet, We can save our resources in this way\npd.read_csv('../input/pandas-practice-files/Required files/ex6.csv', nrows=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chunk = pd.read_csv('../input/pandas-practice-files/Required files/ex6.csv', chunksize=100)\nfor i in chunk:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Writing Data to Text Format"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/pandas-practice-files/Required files/ex5.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving our DataFrame to file csv\ndata.to_csv('Processed_DataFrame.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\ndata.to_csv('out1.csv', sep='@')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv(sys.stdout, na_rep='Purvansh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('out2.csv', index=False, header=False,sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('out3.csv', index=False, columns=['a', 'b', 'c'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = pd.date_range('1/1/2000', periods=7)\nts = pd.Series(np.arange(7), index=dates)\nts.to_csv('tseries.csv')\ndates =pd.DataFrame(dates)\ndates.to_csv('Dates.csv')\n#! tseries.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Working with Delimited Formats"},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nf = open('../input/pandas-practice-files/Required files/ex7.csv')\nreader = csv.reader(f)\nfor text in reader:\n    print(text)\nreader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/pandas-practice-files/Required files/ex7.csv') as f:\n    lines = list(csv.reader(f))\nprint(lines)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"header, values = lines[0], lines[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict = {h: v for h, v in zip(header, zip(*values))}\ndata_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(data_dict,index=['one','two'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working With JSON Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"obj = \"\"\"\n{\"name\": \"Wes\",\n \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n \"pet\": null,\n \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n              {\"name\": \"Katie\", \"age\": 38,\n               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n}\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nresult = json.loads(obj)\nprint(type(result))\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"asjson = json.dumps(result)\nprint(type(asjson))\nasjson","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"siblings = pd.DataFrame(result['siblings'], columns=['name', 'age','pets'])\nsiblings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_json('../input/pandas-practice-files/Required files/example.json')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.to_json())\nprint(data.to_json(orient='records'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XML and HTML: Web Scraping"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"tables = pd.read_html('fdic_failed_bank_list.html')\nlen(tables)\nfailures = tables[0]\nfailures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"close_timestamps = pd.to_datetime(failures['Closing Date'])\nclose_timestamps.dt.year.value_counts()\n#close_timestamps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binary Data Formats"},{"metadata":{"trusted":true},"cell_type":"code","source":"frame = pd.read_csv('../input/pandas-practice-files/Required files/ex1.csv')\nframe\nframe.to_pickle('frame_pickle')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_pickle('frame_pickle')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using HDF5 Format"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HDF5 Hierarchical Data Format (HDF) is an open source file format for storing huge amounts of numerical data.\nframe = pd.DataFrame({'a': np.random.randn(100)})\nstore = pd.HDFStore('mydata.h5')\nstore['obj1'] = frame\nstore['obj1_col'] = frame['a']\nstore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store['obj1'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.put('obj2', frame, format='table')\nstore.select('obj2', where=['index >= 10 and index <= 15'])\nstore.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame.to_hdf('mydata.h5', 'obj3', format='table')\npd.read_hdf('mydata.h5', 'obj3', where=['index < 5'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Web APIs"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nurl = 'https://api.github.com/repos/pandas-dev/pandas/issues'\nresp = requests.get(url)\ntype(resp)\nprint(resp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = resp.json()\ndata[2]['user']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"issues = pd.DataFrame(data, columns=['number', 'title',\n                                     'labels', 'state'])\nissues","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Interacting with Databases"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sqlite3\n#connecting with the database.\ndb = sqlite3.connect(\"my_database4.db\")\n# Drop table if it already exist using execute() method.\ndb.execute(\"drop table if exists test\")\nquery = \"\"\"\nCREATE TABLE test\n(a VARCHAR(20), b VARCHAR(20),\n c REAL,        d INTEGER\n);\"\"\"\ncon = sqlite3.connect('mydata2.sqlite')\ncon.execute(query)\ncon.commit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [('Atlanta', 'Georgia', 1.25, 6),\n        ('Tallahassee', 'Florida', 2.6, 3),\n        ('Sacramento', 'California', 1.7, 5)]\nstmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\ncon.executemany(stmt, data)\ncon.commit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cursor = con.execute('select * from test')\nrows = cursor.fetchall()\nrows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cursor.description)\npd.DataFrame(rows, columns=[x[0] for x in cursor.description])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sqlite3\n#connecting with the database.\ndb = sqlite3.connect(\"my_database5.db\")\n# Drop table if it already exist using execute() method.\ndb.execute(\"drop table if exists grades1\")\n# Create table as per requirement\ndb.execute(\"create table grades1(id int, name text, score int)\")\n#inserting values inside the created table\ndb.execute(\"insert into grades1(id, name, score) values(101, 'John',99 )\")\ndb.execute(\"insert into grades1(id, name, score) values(102, 'Gary',90 )\")\ndb.execute(\"insert into grades1(id, name, score) values(103, 'James', 80 )\")\ndb.execute(\"insert into grades1(id, name, score) values(104, 'Cathy', 85 )\")\ndb.execute(\"insert into grades1(id, name, score) values(105, 'Kris',95 )\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"db.commit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = db.execute(\"select * from grades1 order by id\")\nfor row in results:\n    print((row))\nprint(\"-\" * 60 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = db.execute(\"select * from grades1 where name = 'Gary' \")\nfor row in results: print(row)\nprint(\"-\"* 60 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = db.execute(\"select * from grades1 where score >= 90 \")\nfor row in results:\n    print(row)\nprint(\"-\" * 60 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = db.execute(\"select name, score from grades1 order by score desc \")\nfor row in results:\n    print(row)\nprint(\"-\" * 60 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = db.execute(\"select name, score from grades1 order by score\")\nfor row in results:\n    print(row)\nprint(\"-\" * 60 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = db.execute(\"select name, score from grades1 order by score\")\nfor row in results:\n    print(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}