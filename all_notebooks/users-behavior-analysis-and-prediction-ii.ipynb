{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IMPORT DATA"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\ndb = pd.read_csv('/kaggle/input/ecommerce-users-of-a-french-c2c-fashion-store/6M-0K-99K.users.dataset.public.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Delete unused variables "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"repeat_columns = []\n# unused and repeated metadata are dropped\nrepeat_columns += ['identifierHash', 'type','country','gender','civilityTitle']\ndb1=db.drop(repeat_columns,axis=1)\ndb1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Encode variables"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\n\nstring_columns = ['language','countryCode','hasAnyApp','hasAndroidApp','hasIosApp','hasProfilePicture']\n\nfor var in string_columns:\n    var_cat = db[[var]] #use double brakets to make sure i'm taking a dataframe \n    var_cat_encoded = ordinal_encoder.fit_transform(var_cat)\n    var_cat_df = pd.DataFrame(var_cat_encoded)\n    var_cat_df.columns = [var + '_encoded'] \n    db1 = db1.merge(var_cat_df, how = 'inner', left_index = True, right_index = True)\n\ndb2 = db1.drop(string_columns, axis = 1)\ndb2.head()\ndb2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove variables with no correlations\nno_columns=['seniority','seniorityAsMonths','seniorityAsYears']\n#week_columns=['language_encoded']\n#unused_columns=no_columns+week_columns\ndb3 = db2.drop(no_columns, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictor Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def models(X_train,y_train,X_test,y_test):\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.linear_model import LinearRegression\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error as mae\n    from sklearn.metrics import mean_squared_error as mse\n    from sklearn.metrics import r2_score as r2\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.ensemble import GradientBoostingRegressor as gb\n    from sklearn.linear_model import Ridge\n    from sklearn.linear_model import Lasso\n    from sklearn.svm import SVR\n    from sklearn.model_selection import cross_val_score\n    import warnings\n    warnings.simplefilter('ignore')\n    from sklearn.metrics import confusion_matrix , classification_report\n    from sklearn.metrics import accuracy_score\n    from sklearn.linear_model import LogisticRegression \n    from sklearn import svm\n    import xgboost as xgb\n    print('Select 1 : Naive Bayes, 2: Support Vector Machines, 3: Logistic Regression, 4: Decision Tree, 5: RandomForestClassifier,6:Xtreme gradient boosting')\n    mo = int(input())\n    list=[1,2,3,4,5,6]\n\n    if mo == 1 :\n        model = GaussianNB()\n    elif mo == 2 :\n        model = svm.SVC()\n    elif mo == 3 :\n        model = LogisticRegression()\n    elif mo == 4 :\n        model = DecisionTreeClassifier()\n    elif mo == 5 :\n        model = RandomForestClassifier(random_state=15325)\n    elif mo == 6 :\n        model = xgb.XGBClassifier()\n    else :\n        print('Invalid Entry')\n    model.fit(X_train,Y_train)\n    predict= model.predict(X_test)\n    print(\"testing set accuracy score: \",accuracy_score(Y_test,predict))\n    accuracies = cross_val_score(estimator = model , X= X_train , y=Y_train , cv =10)\n    print(\"testing set accuracy mean: \", accuracies.mean())\n    print(classification_report(Y_test,predict))\n    print(\"confusion matrix: \")\n    print(confusion_matrix(Y_test,predict))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define confusion matrix visualization function\nimport matplotlib.pyplot as plt\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    import itertools\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define accuracy function\ndef predAcc(x_train,x_test,y_train,y_test,model):\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import confusion_matrix , classification_report\n    model.fit(x_train,y_train)\n    predictTR= model.predict(x_train)\n    predictTT= model.predict(x_test)\n    print('Accuracy on train set: {:.3f}'.format(accuracy_score(y_train,predictTR)))\n    print('Accuracy on test set: {:.3f}'.format(accuracy_score(y_test,predictTT)))\n    print('Model Evaluation:')\n    print(\"classification report of train set: \")\n    print(classification_report(y_train,predictTR))\n    print(\"classification report of test set: \")\n    print(classification_report(y_test,predictTT))\n    \n    \n    print(\"Confusion matrix of test set: \")\n    cnf_matrix = confusion_matrix(y_test, predictTT)\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, \n                      #classes=['Inactive buyers','Occational buyers','Frequent buyers'],\n                      classes=['Inactive sellers','Occational sellers','Frequent sellers'],  \n                      title='Confusion matrix  accumulate')\n    \n    #Y_pred_prob=logreg.predict_proba(X_test)\n    #if (func in ['logreg','logregf','rlogreg','rlogregf']):\n        #print(f\"Coefficient: {func.coef_} \")\n        #print(f\"intercept: {logreg.intercept_} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define feature selection function\ndef feaSelect(x_train,y_train,func,x):\n    import warnings\n    warnings.simplefilter('ignore')\n    from sklearn.feature_selection import RFE\n    predictors=x_train\n    selector=RFE(func,n_features_to_select=1)\n    selector=selector.fit(predictors,y_train)\n    order=selector.ranking_\n    order\n\n    feature_ranks=[]\n    for i in order:\n        feature_ranks.append(f\"{i-1}.{x.columns[i-1]}\")\n    \n    print(feature_ranks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def org(x,y):\n    #split the dataset\n    X_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.33, random_state=42)\n    #rebuild model\n    model.fit(X_train,Y_train)\n    print(\"Original Model Evaluation: \")\n    predAcc(X_train, X_test, Y_train, Y_test, model)\n    print(\"Original Model's features selection: \")\n    feaSelect(X_train,Y_train,model,x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def filt(xf,yf):\n    #re-split the filtered dataset\n    Xf_train,Xf_test,Yf_train,Yf_test=train_test_split(xf,yf,test_size=0.33, random_state=42)\n    #rebuild model\n    model.fit(Xf_train,Yf_train)\n    print(\"Filtered Model Evaluation: \")\n    predAcc(Xf_train, Xf_test, Yf_train, Yf_test, model)\n    print(\"Filtered Model's Feature Importance Ranking: \")\n    feaSelect(Xf_train,Yf_train,model,xf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def balanced(x_ros,y_ros):\n    #re-split the balanced dataset\n    X_ros_train,X_ros_test,Y_ros_train,Y_ros_test=train_test_split(x_ros,y_ros,test_size=0.33, random_state=42)\n    #rebuild model\n    model.fit(X_ros_train,Y_ros_train)\n    print(\"Balanced Model Evaluation: \")\n    predAcc(X_ros_train, X_ros_test, Y_ros_train, Y_ros_test, model)\n    print(\"Balanced Model's feature Selections: \")\n    feaSelect(X_ros_train,Y_ros_train,model,x_ros)\n    print('Resample training dataset shape', Y_ros_train.shape[0])\n    print('Resample testing dataset shape', Y_ros_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def balancedFilt(xf_ros,yf_ros):\n    #re-split the balanced filtered dataset\n    Xf_ros_train,Xf_ros_test,Yf_ros_train,Yf_ros_test=train_test_split(xf_ros,yf_ros,test_size=0.33, random_state=42)\n    #Rebuild model\n    model.fit(Xf_ros_train,Yf_ros_train)\n    print(\"Balanced Filtered Model Evaluation: \")\n    predAcc(Xf_ros_train, Xf_ros_test, Yf_ros_train, Yf_ros_test, model)\n    print(\"Balanced Filtered Model's Feature Importance Ranking: \")\n    feaSelect(Xf_ros_train,Yf_ros_train,model,xf_ros)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HasBought As Predictor"},{"metadata":{},"cell_type":"markdown","source":"Define X and Y "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=db3[['socialNbFollowers','socialNbFollows','socialProductsLiked','productsListed','productsSold','productsPassRate',\n          'productsWished','civilityGenderId','daysSinceLastLogin','language_encoded','countryCode_encoded','hasAnyApp_encoded',\n          'hasAndroidApp_encoded','hasIosApp_encoded','hasProfilePicture_encoded']]\n#Y=db3['HasBought'] = db3['productsBought'].apply(lambda x: '1' if x >0 else '0')\nY=db3['HasBought'] = db3['productsBought'].apply(lambda x: '2' if x >=3 else('1' if x <3 and x>0 else '0'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applied two classification models(Naive Bayes, Support Vector Machines), two regression models(Logistic Regression, Decision Tree), and two advanced supervised models(RandomForestClassifier, Xtreme gradient boosting) for model performance."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33, random_state=42)\nmodels(X_train,Y_train,X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Improve two models with the best performance"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"Model Built"},{"metadata":{"trusted":true},"cell_type":"code","source":"#define logistic regression function\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nmodel= LogisticRegression(multi_class='multinomial',solver='newton-cg') #other solvers not converge","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"org(X,Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F1-score of both train and test set is extremely low"},{"metadata":{"trusted":false},"cell_type":"code","source":"#according to the correlation heatmap, pairplot and feature selection, keep top 7\n \nd_columns=['productsSold', 'hasAnyApp_encoded', 'productsPassRate', 'hasProfilePicture_encoded', \n           'productsListed', 'socialNbFollows', 'socialProductsLiked', 'socialNbFollowers']\n\n#socialNBFollows & socialProductsLiked has no relationship with a user's willingness to buy a product\nXf = X.drop(d_columns, axis = 1)\nYf = db3['HasBought']\nXy=db3[['productsBought']]\nXf_pp = pd.concat([Xf,Xy], join = 'outer', axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the relationship between individual variable and dependent variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(Xf_pp, x_vars=Xf.columns, y_vars='productsBought', height=7, aspect=0.7, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No strong linear relationship, only week linear relationship on productsWished and productsBought"},{"metadata":{},"cell_type":"markdown","source":"Model Re-evaluation with the Filtered Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"filt(Xf,Yf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" In logistic regression, if the intercept is below 1 implies a reduction in the probability that the event happens. To sum up:\nb) logit negative value = logistic < 1 = decrease in the probability of the event when you have a positive change in the independent variables"},{"metadata":{},"cell_type":"markdown","source":"New users' prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"c=Xf\nc.dataframeName = \"Formean\"\nc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#try to predict when a user using mean\nnewdata=[[2,2,581,2,94,0,0]]\nY_pred1 = model.predict(newdata)\nprint(\"prediction with mean features: \",Y_pred1)\n#socialNbFollowers affect the prediction the most\n\n#try to predict when a user using max\nnewdata1=[[2635,3,709,4,198,1,1]]\nY_pred2=model.predict(newdata1)\nprint(\"prediction with max features: \", Y_pred2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"print(db3['HasBought'].value_counts())\n#very imbalanced sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bootstrap to resample the imbalanced data"},{"metadata":{},"cell_type":"markdown","source":"Re-split the balanced dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\nros = RandomOverSampler(random_state=42)\n\n # fit predictor and target variable\nX_ros, Y_ros = ros.fit_resample(X, Y)\nprint('Original dataset shape', Counter(Y))\nprint('Resample dataset shape', Counter(Y_ros))\n\nX_ros=pd.DataFrame(X_ros,columns=['socialNbFollowers', 'socialNbFollows', 'socialProductsLiked',\n       'productsListed', 'productsSold', 'productsPassRate', 'productsWished',\n       'civilityGenderId', 'daysSinceLastLogin', 'language_encoded',\n       'countryCode_encoded', 'hasAnyApp_encoded', 'hasAndroidApp_encoded',\n       'hasIosApp_encoded', 'hasProfilePicture_encoded'])\nY_ros.to_frame() \n#Y_ros=pd.DataFrame(Y_ros,columns=['HasBought'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Balanced Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"balanced(X_ros,Y_ros)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We could clearly observe more balanced f1-score that the f1-score of case 'HasBought'=1 increased significantly although 0's dropped slightly."},{"metadata":{},"cell_type":"markdown","source":"Re-split the filtered dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"#according to the correlation heatmap, pairplot and feature selection, keep top 7\nd_columns=[ 'productsPassRate', 'hasAndroidApp_encoded', 'daysSinceLastLogin', 'hasProfilePicture_encoded', \n           'productsListed', 'socialProductsLiked', 'socialNbFollows', 'socialNbFollowers']\n#socialNBFollows & socialProductsLiked has no relationship with a user's willingness to buy a product\nXf_ros = X_ros.drop(d_columns, axis = 1)\nYf_ros = Y_ros","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Balanced Model Re-evaluation with Filtered Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"balancedFilt(Xf_ros,Yf_ros)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Updated New users’ prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"c=Xf_ros\nc.dataframeName = \"Formean\"\nc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#try to predict when a user using mean\nnewdata=[[1,22,2,2,90,0,0]]\nY_pred1 = model.predict(newdata)\nprint(\"prediction with mean features: \",Y_pred1)\n#socialNbFollowers affect the prediction the most\n\n#try to predict when a user using max\nnewdata1=[[174,2635,3,4,198,1,1]]\nY_pred2=model.predict(newdata1)\nprint(\"prediction with max features: \", Y_pred2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They both used countryCode_encoded, language_encoded, hasIosApp_encoded, productsWished, civilityGenderId\nImbalanced used daysSinceLast Login, hasAndroidApp_encoded\nBalanced used productsSold\n\nBalanced dataset prediction has significantly higher f1socre on HasBought=1   "},{"metadata":{},"cell_type":"markdown","source":"# Extreme Gradient Boosting"},{"metadata":{},"cell_type":"markdown","source":"Model Built"},{"metadata":{"trusted":false},"cell_type":"code","source":"import xgboost as xgb\nmodel= xgb.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"org(X,Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F1-score of both train and test set increased significantly comparing to LR's"},{"metadata":{},"cell_type":"markdown","source":"Re-split the filtered dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"#according to the correlation heatmap, pairplot and feature selection, keep top 7\n\nd_columns=[ 'productsSold', 'socialNbFollowers', 'language_encoded', 'hasAndroidApp_encoded', 'productsListed', \n           'hasAnyApp_encoded', 'daysSinceLastLogin', 'hasProfilePicture_encoded']\n\n#socialNBFollows & socialProductsLiked has no relationship with a user's willingness to buy a product\nXf = X.drop(d_columns, axis = 1)\nYf = db3['HasBought']\nXy=db3[['productsBought']]\nXf_pp = pd.concat([Xf,Xy], join = 'outer', axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the relationship between individual variable and dependent variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(Xf_pp, x_vars=Xf.columns, y_vars='productsBought', height=7, aspect=0.7, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Re-evaluation with the Filtered Dataset"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"filt(Xf,Yf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New users' prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"c=Xf\nc.dataframeName = \"Formean\"\nc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n\n#try to predict when a user using mean and max\nnUser = {'socialNbFollows': [8,13764],\n        'socialProductsLiked': [4,51671],\n        'productsPassRate':[1,100],\n        'productsWished':[2,2635],\n        'civilityGenderId':[2,3],\n        'countryCode_encoded':[94,198],\n        'hasIosApp_encoded' :[0,1]  \n        }\n\ndf2 = pd.DataFrame(nUser, columns = ['socialNbFollows','socialProductsLiked','productsPassRate','productsWished','civilityGenderId',\n                'countryCode_encoded','hasIosApp_encoded'])\n\nY_pred2 = model.predict(df2)\nY_pred2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(db3['HasBought'].value_counts())\n#very imbalanced sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bootstrap to resample the imbalanced data"},{"metadata":{},"cell_type":"markdown","source":"Balanced Model Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"balanced(X_ros,Y_ros)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#according to the correlation heatmap, pairplot and feature selection, keep top 7\nd_columns=[ 'productsPassRate', 'socialNbFollowers', 'countryCode_encoded', 'daysSinceLastLogin', \n           'productsListed', 'hasAnyApp_encoded', 'productsWished', 'language_encoded']\nXf_ros = X_ros.drop(d_columns, axis = 1)\nYf_ros = Y_ros","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Balanced Model Re-evaluation with the Filtered Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"balancedFilt(Xf_ros,Yf_ros)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New User's Prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"c=Xf_ros\nc.dataframeName = \"Formean\"\nc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#try to predict when a user using mean and max\nnUser = {'socialNbFollows': [10,13764],\n        'socialProductsLiked': [47,51671],\n        'productsSold':[1,174],\n        'civilityGenderId':[2,3],\n        'hasAndroidApp_encoded':[0,1],\n        'hasIosApp_encoded':[0,1],\n        'hasProfilePicture_encoded' :[1,1]  \n        }\n\ndf2 = pd.DataFrame(nUser, columns = ['socialNbFollows','socialProductsLiked','productsSold','civilityGenderId',\n                                     'hasAndroidApp_encoded','hasIosApp_encoded', 'hasProfilePicture_encoded'])\n\nY_pred2 = model.predict(df2)\nY_pred2\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For filtered dataset(both imbalanced and balanced):\nThe both used productsWished, civilityGenderId, countryCode_encoded, hasIosApp_encoded\nImbalanced used socialProductsLiked, socialNbFollows, productsPassRate\nBalanced used productsSold, language_encoded, hasAnyApp_encoded\n\nBalanced dataset prediction has significantly higher f1socre on HasBought=1"},{"metadata":{},"cell_type":"markdown","source":"# HasSold As Predictor"},{"metadata":{},"cell_type":"markdown","source":"Define X and Y"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=db3[['socialNbFollowers','socialNbFollows','socialProductsLiked','productsListed','productsBought','productsPassRate',\n          'productsWished','civilityGenderId','daysSinceLastLogin','language_encoded','countryCode_encoded','hasAnyApp_encoded',\n          'hasAndroidApp_encoded','hasIosApp_encoded','hasProfilePicture_encoded']]\nY=db3['HasSold'] = db3['productsSold'].apply(lambda x: '2' if x >=6 else('1' if x <6 and x>0 else '0'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applied two classification models(Naive Bayes, Support Vector Machines), two regression models(Logistic Regression, Decision Tree), and two advanced supervised models(RandomForestClassifier, Xtreme gradient boosting) for model performance."},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33, random_state=42)\nmodels(X_train,Y_train,X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Improve model with the best performance\nsince all have almost the same accuracy on the test set"},{"metadata":{},"cell_type":"markdown","source":"Model Built"},{"metadata":{"trusted":false},"cell_type":"code","source":"import xgboost as xgb\nmodel= xgb.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"org(X,Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Re-split the filtered dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"#according to the correlation heatmap, pairplot and feature selection, keep top 7\nd_columns=[ 'productsBought', 'productsListed', 'productsPassRate', 'civilityGenderId', 'language_encoded',\n           'hasAndroidApp_encoded', 'hasProfilePicture_encoded', 'productsWished']\n\n#socialNBFollows & socialProductsLiked has no relationship with a user's willingness to buy a product\nXf = X.drop(d_columns, axis = 1)\nYf = db3['HasSold']\nXy=db3[['productsSold']]\nXf_pp = pd.concat([Xf,Xy], join = 'outer', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the relationship between individual variable and dependent variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(Xf_pp, x_vars=Xf.columns, y_vars='productsSold', height=7, aspect=0.7, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Re-evaluation with the Filtered Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"filt(Xf,Yf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"f1-score on HasSold=1 dropped significantly on filtered dataset"},{"metadata":{},"cell_type":"markdown","source":"New users' prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"c=Xf\nc.dataframeName = \"Formean\"\nc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#try to predict when a user using mean and max\nnUser = {'socialNbFollowers': [3,744],\n        'socialNbFollows': [8,13764],\n        'socialProductsLiked':[4,51671],\n        'daysSinceLastLogin':[581,709],\n        'countryCode_encoded':[94,198],\n        'hasAnyApp_encoded':[0,1],\n        'hasIosApp_encoded' :[0,1]  \n        }\n\ndf2 = pd.DataFrame(nUser, columns = ['socialNbFollowers','socialNbFollows','socialProductsLiked','daysSinceLastLogin',\n                                     'countryCode_encoded','hasAnyApp_encoded','hasIosApp_encoded'])\n\nY_pred2 = model.predict(df2)\nY_pred2\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bootstrap to resample the imbalanced data"},{"metadata":{"trusted":false},"cell_type":"code","source":"from collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\nros = RandomOverSampler(random_state=42)\n\n # fit predictor and target variable\nX_ros, Y_ros = ros.fit_resample(X, Y)\nprint('Original dataset shape', Counter(Y))\nprint('Resample dataset shape', Counter(Y_ros))\n\nX_ros=pd.DataFrame(X_ros,columns=['socialNbFollowers', 'socialNbFollows', 'socialProductsLiked',\n       'productsListed', 'productsBought', 'productsPassRate', 'productsWished',\n       'civilityGenderId', 'daysSinceLastLogin', 'language_encoded',\n       'countryCode_encoded', 'hasAnyApp_encoded', 'hasAndroidApp_encoded',\n       'hasIosApp_encoded', 'hasProfilePicture_encoded'])\nY_ros.to_frame()\n#Y_ros=pd.DataFrame(Y_ros,columns=['HasSold'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Balanced Model Evaluation"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"balanced(X_ros,Y_ros)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#according to the correlation heatmap, pairplot and feature selection, keep top 7\n\nd_columns=[ 'productsWished', 'productsListed', 'productsPassRate', 'daysSinceLastLogin',\n           'hasIosApp_encoded', 'hasProfilePicture_encoded', 'hasAndroidApp_encoded', 'productsBought']\n\nXf_ros = X_ros.drop(d_columns, axis = 1)\nYf_ros = Y_ros","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Balanced Model Re-evaluation with the Filtered Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"balancedFilt(Xf_ros,Yf_ros)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"overall accuracy and f1-score on HasSold=1 decreased on filtered dataset for both balanced and imbalanced cases.\nEspecially the f1-score on HasSold=1 decreased significantly on imbalanced cases."},{"metadata":{},"cell_type":"markdown","source":"New User's Prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"c=Xf_ros\nc.dataframeName = \"Formean\"\nc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#try to predict when a user using mean and max\nnUser = {'socialNbFollowers': [13,744],\n        'socialNbFollows': [31,13764],\n        'socialProductsLiked':[78,51671],\n        'civilityGenderId':[2,3],\n        'language_encoded':[2,4],\n        'countryCode_encoded':[86,198],\n        'hasAnyApp_encoded' :[1,1]  \n        }\n\ndf2 = pd.DataFrame(nUser, columns = ['socialNbFollowers','socialNbFollows','socialProductsLiked','civilityGenderId',\n                                     'language_encoded','countryCode_encoded','hasAnyApp_encoded'])\n\nY_pred2 = model.predict(df2)\nY_pred2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"For filtered dataset(both imbalanced and balanced):\nThey both had variables socialNbFollwers, countryCode_encoded, socialNbFollows, socialProductsLiked, hasAnyApp_encoded\nImbalanced dataset used variables daysSinceLastLogin, hasIosApp_encoded\nBalanced dataset used language_encoded, civilityGenderId\n\nThey chosed almost the same varibles for model building\nBut balanced dataset prediction only has slightly lower f1socre on HasBought=1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}