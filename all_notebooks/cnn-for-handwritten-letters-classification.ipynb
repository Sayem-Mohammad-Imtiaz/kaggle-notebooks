{"cells":[{"metadata":{},"cell_type":"markdown","source":"### In this notebook, we will use convolutional neural networks to classify letters written by hand.\n\nWe will see how to:\n- Preprocess images and metadata\n- Configure CNN\n- Use callbacks performing various actions during CNN training\n- Plot the training info \n- Plot the model's predictions on test images\n- Save the model to disk"},{"metadata":{"id":"RmIRkL8gb2Oz","executionInfo":{"status":"ok","timestamp":1605818394458,"user_tz":-300,"elapsed":627,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport random\nimport os\n\nfrom PIL import ImageFile\nfrom tqdm import tqdm\nimport h5py\nimport cv2\n\nimport matplotlib.pylab as plt\nfrom matplotlib import cm\n%matplotlib inline\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image as keras_image\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import models\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.metrics import top_k_categorical_accuracy,categorical_accuracy\n\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import Input, BatchNormalization\nfrom keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU\n\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nimport scipy\nfrom scipy import misc\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"ScNIEZ_6dEmQ","executionInfo":{"status":"ok","timestamp":1605809565154,"user_tz":-300,"elapsed":1725,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"4b5d4f99-f5c2-47e8-d9a1-c2153a900ab4","trusted":true},"cell_type":"code","source":"#check version of library\nimport tensorflow as tf\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"id":"Oam1OF_wcAvW","executionInfo":{"status":"ok","timestamp":1605812362421,"user_tz":-300,"elapsed":647,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"disk_folder=\"/kaggle/working/\"\nfolder='/kaggle/input/classification-of-handwritten-letters/'","execution_count":null,"outputs":[]},{"metadata":{"id":"Le40Iv2hzPGa"},"cell_type":"markdown","source":"### Loading the dataframe containing the information about the images"},{"metadata":{"id":"unkpPXgyiabh","executionInfo":{"status":"ok","timestamp":1605811136837,"user_tz":-300,"elapsed":995,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"data_info =  ['letters.csv', 'letters2.csv', 'letters3.csv']","execution_count":null,"outputs":[]},{"metadata":{"id":"aoSVvY-10HK0","executionInfo":{"status":"ok","timestamp":1605811606078,"user_tz":-300,"elapsed":590,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"def import_data(data_info):\n\n  \"\"\"Creates an additional column: the path to the image\"\"\"\n  data = pd.read_csv(folder + '/' + data_info)\n  data['source'] = data_info[:-4]+'/'\n  return data","execution_count":null,"outputs":[]},{"metadata":{"id":"UgkpW2fJi1z8","executionInfo":{"status":"ok","timestamp":1605811607135,"user_tz":-300,"elapsed":551,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"letters = [import_data(file) for file in data_info]\ndata = pd.concat(letters, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ypc64IyQ2DcX","executionInfo":{"status":"ok","timestamp":1605811923383,"user_tz":-300,"elapsed":608,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"# Shuffle the data \n\ndata = shuffle(data, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"id":"_PQZQEMwiagx","executionInfo":{"status":"ok","timestamp":1605811942022,"user_tz":-300,"elapsed":595,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"cc17ffd9-192c-402a-c16b-7eacbb81abba","trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"id":"dJO8NWg7zgdE"},"cell_type":"markdown","source":"We see that our dataset contains the following information: the letter, the encoded label, the filename, the background on the paper and the path to the file."},{"metadata":{"id":"avAOnAcglUYC"},"cell_type":"markdown","source":"### Target preprocessing \n\nSince we are going to use neural networks, it would be better to use One-hot encoding rather than ordinal. One-hot encoding means that each class (letter) will be represented by a separate column. The values will be either 0 or 1 depending on whether the image contains the letter."},{"metadata":{"id":"WlBSCiAOma3j","executionInfo":{"status":"ok","timestamp":1605811948607,"user_tz":-300,"elapsed":607,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"# Get all labels in one string\nletters = '' \nfor letter in data.letter.unique():\n    letters += letter\n    \n# Which letter is written on each image\nlabels = data.label","execution_count":null,"outputs":[]},{"metadata":{"id":"WhCzAd05iakg","executionInfo":{"status":"ok","timestamp":1605811951309,"user_tz":-300,"elapsed":628,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"def ohe_letter(label):\n    result = np.zeros(len(letters))\n    index = letters.index(label)\n    result[index] = 1\n    return result\n\ndef ohe_background(label):\n    result = np.zeros(len(data.background.unique()))\n    result[label] = 1\n    return result","execution_count":null,"outputs":[]},{"metadata":{"id":"9eQWSUb9ianD","executionInfo":{"status":"ok","timestamp":1605812039015,"user_tz":-300,"elapsed":2110,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"9f920d1a-2967-414d-be92-a2bd9f4544e9","trusted":true},"cell_type":"code","source":"data['enc_letter'] = data['letter'].apply(ohe_letter)\ndata['enc_background'] = data['background'].apply(ohe_background)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"OL1vHszz3Loh"},"cell_type":"markdown","source":"### Image preprocessing"},{"metadata":{"id":"4WZldwyyiaqE","executionInfo":{"status":"ok","timestamp":1605813926914,"user_tz":-300,"elapsed":620,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"52c5f24b-57e6-4c41-ee74-9e72c6c22668","trusted":true},"cell_type":"code","source":"# set the image size\nimg_width, img_height = 32, 32\ninput_shape = (img_width, img_height, 3) # 3 - число каналов\n\n# let's look at one of the images\nimage_file_name = folder + 'letters2/27_212.png'\nimg = image.load_img(image_file_name, target_size=(img_width, img_height))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"id":"3GiRmDurko1A","executionInfo":{"status":"ok","timestamp":1605813610454,"user_tz":-300,"elapsed":35897,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"# Store all png images into one numpy array\nimages = []\n\n# Will be the target\nencoded_labels = []\n\nbackgrounds = []\nencoded_backgrounds = []\n\n# Want to be sure that every image is consitent\nfor i, row in data.iterrows():\n    img_name = row['file']\n    numpy_image = cv2.imread(os.path.join(folder + row['source'], img_name))\n    if numpy_image.shape == (32, 32, 3):\n        images.append(numpy_image)\n        encoded_labels.append(row['enc_letter'])\n        backgrounds.append(row['background'])\n        encoded_backgrounds.append(row['enc_background'])\n        \n# Normalize array of images\nimages = np.array(images)/255","execution_count":null,"outputs":[]},{"metadata":{"id":"aDUGR85q82tS","executionInfo":{"status":"ok","timestamp":1605813645634,"user_tz":-300,"elapsed":908,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"90c57575-cb40-435c-eec7-20b68b7937a5","trusted":true},"cell_type":"code","source":"len(images), len(encoded_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating train and test sets\n\nAs we are dealing with the classification problem, it's important to make sure that the class distribution is consistent in both train and test sets.\n\nIn order to control this, we will use `stratify` -- the parameter of `train_test_split` function."},{"metadata":{"id":"49dv_jYXko38","executionInfo":{"status":"ok","timestamp":1605813673179,"user_tz":-300,"elapsed":1492,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"a0ea68ae-b7af-4cee-ef5c-0a92024b74f8","trusted":true},"cell_type":"code","source":"X = np.array(images.copy())\ny = np.array(encoded_labels.copy())\n\n# Stratified train_test split on labels\nX_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                  test_size=.2, \n                                                  stratify = y, \n                                                  random_state=42)\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"6O7JXSfLko9G","executionInfo":{"status":"ok","timestamp":1605813793194,"user_tz":-300,"elapsed":826,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"#create generators\ndatagen = ImageDataGenerator(rescale=1. / 255,\n                              rotation_range=40,\n                              width_shift_range=0.2,\n                              height_shift_range=0.2,\n                              zoom_range=0.2,\n                              horizontal_flip=True,\n                              fill_mode='nearest')\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"iessl7uO-Tsl"},"cell_type":"markdown","source":"## Configuring of CNN"},{"metadata":{"id":"WrZY7Sue-Z8o","executionInfo":{"status":"ok","timestamp":1605815568019,"user_tz":-300,"elapsed":590,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"# The shape of input tensors\ninput_shape = (img_width, img_height, 3)\n\n# Number of classes to consider\nnum_classes = len(letters)\n\n# Group of training samples\nbatch_size = 64\n\n# Number of complete presentations of the dataset to be learned\nepochs = 100","execution_count":null,"outputs":[]},{"metadata":{"id":"QJAIlDFDIStJ","executionInfo":{"status":"ok","timestamp":1605816778625,"user_tz":-300,"elapsed":603,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"# custom metric\ndef top_3_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we define our neural network and print its structure as an image."},{"metadata":{"id":"DG2bp3LT-Z2s","executionInfo":{"status":"ok","timestamp":1605816779569,"user_tz":-300,"elapsed":1323,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"2e26ecfb-143a-43d9-827b-1c181d74e397","trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))\nmodel.add(Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(Conv2D(128, (4, 4), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation = 'softmax'))\n\n# Compile the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy', top_3_categorical_accuracy])\nmodel.summary()\nplot_model(model, expand_nested=True, show_shapes=True, show_layer_names=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the following cell, we define the callbacks that will make our life a bit easier:\n- `ReduceLROnPlateau` will automatically reduce learning rate when a metric has stopped improving\n- `ModelCheckpoint` will save the best model to disk so we can re-use it later.\n\n"},{"metadata":{"id":"33dX3YTsAq-m","executionInfo":{"status":"ok","timestamp":1605816673961,"user_tz":-300,"elapsed":431,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":true},"cell_type":"code","source":"lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 patience=10, \n                                 verbose=2, \n                                 factor=.75)\n\n\nmodel_checkpoint= ModelCheckpoint(disk_folder+\"/best_result_checkpoint\", monitor='val_loss', save_best_only=True, verbose=0)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, it's time to train our CNN.\n\nMake sure you have enabled GPU, as the training will take a considerable amount of time!"},{"metadata":{"id":"4FjOFTF926o0","executionInfo":{"status":"ok","timestamp":1605817035099,"user_tz":-300,"elapsed":249457,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"bd666960-708a-4912-98a6-2c0fb954449b","trusted":true},"cell_type":"code","source":"%%time\n\nhistory = model.fit(X_train, y_train,\n                    batch_size = batch_size,\n                    epochs = epochs,\n                    verbose = 1,\n                    validation_data = (X_val, y_val),\n                    callbacks = [model_checkpoint, lr_reduction])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the training info\n\nLet's look at the training process.\n\nThis plot shows how the accuracy changed over epochs on both train and val sets."},{"metadata":{"id":"qdeEOCEm26bO","executionInfo":{"status":"ok","timestamp":1605817244080,"user_tz":-300,"elapsed":1251,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"99d41c4d-417d-4c18-909b-b4e461a66bea","trusted":false},"cell_type":"code","source":"print(history.history['accuracy'])\n\nplt.plot(history.history['accuracy'],'--', label='accuracy on training set')\nplt.plot(history.history['val_accuracy'], label='accuracy on validation set')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also see how the loss was changing."},{"metadata":{"id":"mYnHyLOWko_4","executionInfo":{"status":"ok","timestamp":1605817295731,"user_tz":-300,"elapsed":683,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"32050747-d1e2-4a44-bfcc-18705f5ab006","trusted":false},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we can also see the change of the learning rate."},{"metadata":{"id":"sBHzXn0nKySM","executionInfo":{"status":"ok","timestamp":1605817358986,"user_tz":-300,"elapsed":654,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"08858eac-432f-4ca1-a798-803c69cc60e4","trusted":false},"cell_type":"code","source":"plt.plot(history.history['lr'])\nplt.title('learning rate')\nplt.ylabel('lr')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's restore model from the checkpoint it was saved to."},{"metadata":{"id":"TwWjynatML7Z","executionInfo":{"status":"ok","timestamp":1605817927077,"user_tz":-300,"elapsed":2183,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"d7dd3b78-c3c0-4525-f9a4-bc7cd8563793","trusted":false},"cell_type":"code","source":"cnn_model=models.load_model(disk_folder+\"/best_result_checkpoint\",\n                            custom_objects={'top_3_categorical_accuracy':top_3_categorical_accuracy}) \ncnn_model.summary()\nplot_model(cnn_model, expand_nested=True, show_shapes=True, show_layer_names=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating the model\n\nLet's evaluate the model performance on the test set."},{"metadata":{"id":"Ojzh9hB5K_MH","executionInfo":{"status":"ok","timestamp":1605818082633,"user_tz":-300,"elapsed":1107,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"bb6bcd57-0766-45f5-a697-c0dbc873da93","trusted":false},"cell_type":"code","source":"loss, acc, top3_cat_acc = cnn_model.evaluate(X_val, y_val)\nprint(\"loss\", loss)\nprint(\"acc\", acc)\nprint(\"top 3 category acc\", top3_cat_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the model's predictions on the test set\n\nAnd at last the most interesting part -- the model's predicitions!"},{"metadata":{"id":"JxtcqaW4LtSI","executionInfo":{"status":"ok","timestamp":1605818401837,"user_tz":-300,"elapsed":659,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":false},"cell_type":"code","source":"def get_true_label(path_filename, dataframe, column_to_get):\n    filename = os.path.basename(os.path.normpath(path_filename))\n    index_row = data[data['file']==filename].index[0]\n    return data.loc[index_row, column_to_get]\n\n\ndef load_image(path_filename):\n\t# load the image\n\timg = load_img(path_filename, target_size=(32, 32))\n\t# convert to array\n\timg = img_to_array(img)\n\t# reshape into a single sample with 1 channel\n\timg = img.reshape(1, 32, 32, 3)\n\t# prepare pixel data\n\timg = img.astype('float32')\n\timg = img / 255.0\n\treturn img\n\ndef load_random_images(number_of_images_to_load = 9):\n    images = []\n    true_labels = []\n    true_backgrounds = []\n    \n    which_folder = [random.randint(1,3) for _ in range(number_of_images_to_load)]\n    for index_folder in which_folder:\n        if index_folder == 1:\n            path = folder +'letters/'\n        else:\n            path = folder +'letters'+str(index_folder)+'/'\n        nb_files = len(os.listdir(path))\n        \n        index_image = random.randint(0, len(os.listdir(path)))\n        \n        image = load_image(path + os.listdir(path)[index_image])\n        label = get_true_label(path + os.listdir(path)[index_image], data, 'letter')\n        background = get_true_label(path + os.listdir(path)[index_image], data, 'background')\n\n        images.append(image)\n        true_labels.append(label)\n        true_backgrounds.append(background)\n        \n    return images, true_labels, true_backgrounds\n\ndef classes_predictions(images_list_to_classify, true_labels, model):\n    \n    # plot first few images\n    plt.figure(figsize=(12,12))\n    for index, image in enumerate(images_list_to_classify):\n        \n        a_letter = model.predict_classes(image)\n        associated_letter = letters[a_letter[0]]\n        \n        # define subplot\n        plt.subplot(330 + 1 + index)\n        plt.title('Predicted Label: %s \\n'%associated_letter+\\\n                  'True Label: %s\\n'%true_labels[index],\n                 fontsize=18)\n        # plot raw pixel data\n        plt.imshow(image[0])\n        \n    plt.subplots_adjust(bottom = 0.001)  # the bottom of the subplots of the figure\n    plt.subplots_adjust(top = 0.99)\n        \n    # show the figure\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"ozChFTvAOO_t","executionInfo":{"status":"ok","timestamp":1605818404994,"user_tz":-300,"elapsed":3060,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"trusted":false},"cell_type":"code","source":"test_images, true_labels, true_backgrounds = load_random_images()","execution_count":null,"outputs":[]},{"metadata":{"id":"nCJisNqEOPDz","executionInfo":{"status":"ok","timestamp":1605818425840,"user_tz":-300,"elapsed":2292,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"d616e35f-c918-45b2-fdd7-9dd3315d95cb","trusted":false},"cell_type":"code","source":"classes_predictions(test_images, true_labels, cnn_model)","execution_count":null,"outputs":[]},{"metadata":{"id":"VQhbLsHgLtKF","trusted":false},"cell_type":"markdown","source":"## Saving the model\n\nWhen we are happy with the model's results, we can save the model to a file. We can also save weights and structure in different files."},{"metadata":{"id":"2s_x1vhkK_Qm","executionInfo":{"status":"ok","timestamp":1605818207064,"user_tz":-300,"elapsed":638,"user":{"displayName":"Maya Bikmetova","photoUrl":"https://lh5.googleusercontent.com/-QRgiu4M7ecc/AAAAAAAAAAI/AAAAAAAAAK8/sZiY_g9q3yY/s64/photo.jpg","userId":"15065936059830327605"}},"outputId":"79ff1a4a-f067-430d-c0ba-f98b70b5cdc0","trusted":false},"cell_type":"code","source":"#save model\nmodel_json = cnn_model.to_json()\njson_file = open(disk_folder+\"/my_model\" + \".json\", \"w\")\n#write structure\njson_file.write(model_json)\njson_file.close()\n# write wtights\nmodel.save_weights(disk_folder+\"/my_model\"+\".h5\")\nprint(\"saving done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## That's it! Hope you find this quick notebook useful :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}