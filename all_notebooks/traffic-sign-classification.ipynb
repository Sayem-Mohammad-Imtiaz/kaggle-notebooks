{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-22T21:08:30.855118Z","iopub.execute_input":"2021-07-22T21:08:30.85577Z","iopub.status.idle":"2021-07-22T21:08:30.884724Z","shell.execute_reply.started":"2021-07-22T21:08:30.855664Z","shell.execute_reply":"2021-07-22T21:08:30.883353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Project Overview:","metadata":{}},{"cell_type":"markdown","source":"<font color=\"blue\">\nTraffic Sign Classification is very crucial for self-driving cars.\n    \nIn this project, I will use convolutional neural networks that can classify 43 different traffic signs.","metadata":{}},{"cell_type":"markdown","source":"<font color=\"blue\">\n\nThe dataset consists of 43 different classes of images.\n\nClasses are as listed below:\n\n0 = Speed limit (20km/h)\n    \n1 = Speed limit (30km/h)\n    \n2 = Speed limit (50km/h)\n    \n3 = Speed limit (60km/h)\n    \n4 = Speed limit (70km/h)\n    \n5 = Speed limit (80km/h)\n    \n6 = End of speed limit (80km/h)\n    \n7 = Speed limit (100km/h)\n    \n8 = Speed limit (120km/h)\n    \n9 = No passing\n    \n10 = No passing for vehicles over 3.5 metric tons\n    \n11 = Right-of-way at the next intersection\n    \n12 = Priority road\n    \n13 = Yield\n    \n14 = Stop\n    \n15 = No vehicles\n    \n16 = Vehicles over 3.5 metric tons prohibited\n    \n17 = No entry\n    \n18 = General caution\n    \n19 = Dangerous curve to the left\n    \n20 = Dangerous curve to the right\n    \n21 = Double curve\n    \n22 = Bumpy road\n    \n23 = Slippery road\n    \n24 = Road narrows on the right\n    \n25 = Road work\n    \n26 = Traffic signals\n    \n27 = Pedestrians\n    \n28 = Children crossing\n    \n29 = Bicycles crossing\n    \n30 = Beware of ice/snow\n    \n31 = Wild animals crossing\n    \n32 = End of all speed and passing limits\n    \n33 = Turn right ahead\n    \n34 = Turn left ahead\n    \n35 = Ahead only\n    \n36 = Go straight or right\n    \n37 = Go straight or left\n    \n38 = Keep right\n    \n39 = Keep left\n    \n40 = Roundabout mandatory\n    \n41 = End of no passing\n    \n42 = End of no passing by vehicles over 3.5 metric tons","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport pickle\nimport random\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:46:02.714382Z","iopub.execute_input":"2021-07-22T21:46:02.714916Z","iopub.status.idle":"2021-07-22T21:46:02.946614Z","shell.execute_reply.started":"2021-07-22T21:46:02.714865Z","shell.execute_reply":"2021-07-22T21:46:02.945235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/traffic-signs/train.p\", mode='rb') as training_data:\n    train = pickle.load(training_data)\nwith open(\"../input/traffic-signs/valid.p\", mode='rb') as validation_data:\n    valid = pickle.load(validation_data)\nwith open(\"../input/traffic-signs/test.p\", mode='rb') as testing_data:\n    test = pickle.load(testing_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:38.352131Z","iopub.execute_input":"2021-07-22T21:08:38.352526Z","iopub.status.idle":"2021-07-22T21:08:43.339043Z","shell.execute_reply.started":"2021-07-22T21:08:38.352486Z","shell.execute_reply":"2021-07-22T21:08:43.337813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = train[\"features\"], train[\"labels\"]\nX_train.shape\n#we have 34799 images with 32 x 32 size in 3 color channels.","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:43.341694Z","iopub.execute_input":"2021-07-22T21:08:43.342166Z","iopub.status.idle":"2021-07-22T21:08:43.352734Z","shell.execute_reply.started":"2021-07-22T21:08:43.342121Z","shell.execute_reply":"2021-07-22T21:08:43.35161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:43.354543Z","iopub.execute_input":"2021-07-22T21:08:43.354911Z","iopub.status.idle":"2021-07-22T21:08:43.373374Z","shell.execute_reply.started":"2021-07-22T21:08:43.354859Z","shell.execute_reply":"2021-07-22T21:08:43.372005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test,y_test = test[\"features\"], test[\"labels\"]\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:43.374737Z","iopub.execute_input":"2021-07-22T21:08:43.375104Z","iopub.status.idle":"2021-07-22T21:08:43.387862Z","shell.execute_reply.started":"2021-07-22T21:08:43.37507Z","shell.execute_reply":"2021-07-22T21:08:43.385794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid, y_valid = valid[\"features\"], valid[\"labels\"]\nprint(X_valid.shape)\nprint(y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:43.389493Z","iopub.execute_input":"2021-07-22T21:08:43.389817Z","iopub.status.idle":"2021-07-22T21:08:43.40326Z","shell.execute_reply.started":"2021-07-22T21:08:43.389783Z","shell.execute_reply":"2021-07-22T21:08:43.40171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Visualization","metadata":{}},{"cell_type":"code","source":"i = random.randint(0,len(X_train))\nplt.imshow(X_train[i])\ny_train[i]","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:43.404699Z","iopub.execute_input":"2021-07-22T21:08:43.405179Z","iopub.status.idle":"2021-07-22T21:08:43.606803Z","shell.execute_reply.started":"2021-07-22T21:08:43.405141Z","shell.execute_reply":"2021-07-22T21:08:43.605202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets visualize multiple images:\nfig,axes = plt.subplots(5,5,figsize=(20,15))\naxes = axes.ravel() # flatten 5x5 matrix into 25 array\nfor i in range(0,25):\n    index = random.randint(1,len(X_train))\n    axes[i].imshow(X_train[index])\n    axes[i].set_title(y_train[index], fontsize = 15)\n    axes[i].axis(\"off\")\nplt.subplots_adjust(hspace=0.4)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:08:43.609332Z","iopub.execute_input":"2021-07-22T21:08:43.609653Z","iopub.status.idle":"2021-07-22T21:08:45.077114Z","shell.execute_reply.started":"2021-07-22T21:08:43.609623Z","shell.execute_reply":"2021-07-22T21:08:45.07626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data Preparation and Analysis:","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\nX_train, y_train = shuffle(X_train,y_train)\n# I do now want that neural networks a meaning from the sequence of the data.","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:40:11.157229Z","iopub.execute_input":"2021-07-22T21:40:11.157703Z","iopub.status.idle":"2021-07-22T21:40:11.244888Z","shell.execute_reply.started":"2021-07-22T21:40:11.157659Z","shell.execute_reply":"2021-07-22T21:40:11.243281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets normalize the images as follows:\nX_train = X_train/255\nX_test = X_test/255\nX_valid = X_valid/255","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:48:21.101329Z","iopub.execute_input":"2021-07-22T21:48:21.101711Z","iopub.status.idle":"2021-07-22T21:48:21.73787Z","shell.execute_reply.started":"2021-07-22T21:48:21.101677Z","shell.execute_reply":"2021-07-22T21:48:21.736568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets visualize the images after normalization:\nfig,axes = plt.subplots(4,4,figsize=(20,15))\naxes = axes.ravel() # flatten 5x5 matrix into 25 array\nfor i in range(0,16):\n    index = random.randint(1,len(X_train))\n    axes[i].imshow(X_train[index])\n    axes[i].set_title(y_train[index], fontsize = 15)\n    axes[i].axis(\"off\")\nplt.subplots_adjust(hspace=0.4)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T21:50:39.666184Z","iopub.execute_input":"2021-07-22T21:50:39.666566Z","iopub.status.idle":"2021-07-22T21:50:40.57285Z","shell.execute_reply.started":"2021-07-22T21:50:39.666535Z","shell.execute_reply":"2021-07-22T21:50:40.571679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Training Neural Networks:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,15))\nplt.imshow(plt.imread(\"../input/convolution/conv.png\"))\n#How neural networks work:","metadata":{"execution":{"iopub.status.busy":"2021-07-22T22:00:47.489377Z","iopub.execute_input":"2021-07-22T22:00:47.490136Z","iopub.status.idle":"2021-07-22T22:00:48.239774Z","shell.execute_reply.started":"2021-07-22T22:00:47.490077Z","shell.execute_reply":"2021-07-22T22:00:48.238943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#> we will also add dropout layer in order to avoid from overfitting\nplt.figure(figsize=(20,15))\nplt.imshow(plt.imread(\"../input/dropout/dropout.jpg\"))\n#Dropout layer drops some of the perceptrons. How dropout layer work:","metadata":{"execution":{"iopub.status.busy":"2021-07-22T22:06:20.45226Z","iopub.execute_input":"2021-07-22T22:06:20.452794Z","iopub.status.idle":"2021-07-22T22:06:21.067502Z","shell.execute_reply.started":"2021-07-22T22:06:20.452751Z","shell.execute_reply":"2021-07-22T22:06:21.066153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D, Flatten, Dense, Dropout\ncnn = Sequential()\ncnn.add(Conv2D(filters=16,  kernel_size=3, activation=\"relu\",input_shape=(32,32,3)))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\ncnn.add(Dropout(0.2))\ncnn.add(Conv2D(filters=64, activation=\"relu\",kernel_size=3))\ncnn.add(MaxPool2D(pool_size=2, strides=2))\ncnn.add(Flatten())\ncnn.add(Dense(units=512,activation=\"relu\"))\n#cnn.add(Dense(units=80,activation=\"relu\"))\ncnn.add(Dropout(0.2))\ncnn.add(Dense(units=43,activation=\"softmax\"))\ncnn.summary()\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-07-22T22:59:37.239374Z","iopub.execute_input":"2021-07-22T22:59:37.2398Z","iopub.status.idle":"2021-07-22T22:59:37.318859Z","shell.execute_reply.started":"2021-07-22T22:59:37.239762Z","shell.execute_reply":"2021-07-22T22:59:37.318015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-22T22:59:40.734618Z","iopub.execute_input":"2021-07-22T22:59:40.73518Z","iopub.status.idle":"2021-07-22T22:59:40.748281Z","shell.execute_reply.started":"2021-07-22T22:59:40.735142Z","shell.execute_reply":"2021-07-22T22:59:40.747193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = cnn.fit(X_train,y_train, validation_data=(X_valid,y_valid),epochs=10, batch_size=500)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T22:59:42.590508Z","iopub.execute_input":"2021-07-22T22:59:42.591272Z","iopub.status.idle":"2021-07-22T23:02:37.216487Z","shell.execute_reply.started":"2021-07-22T22:59:42.591215Z","shell.execute_reply":"2021-07-22T23:02:37.215467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T22:59:02.039503Z","iopub.execute_input":"2021-07-22T22:59:02.039913Z","iopub.status.idle":"2021-07-22T22:59:05.015598Z","shell.execute_reply.started":"2021-07-22T22:59:02.039863Z","shell.execute_reply":"2021-07-22T22:59:05.014709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Model Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:02:39.361483Z","iopub.execute_input":"2021-07-22T23:02:39.361836Z","iopub.status.idle":"2021-07-22T23:02:39.366223Z","shell.execute_reply.started":"2021-07-22T23:02:39.361798Z","shell.execute_reply":"2021-07-22T23:02:39.365054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = cnn.predict_classes(X_test)\nprint(classification_report(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:02:39.368149Z","iopub.execute_input":"2021-07-22T23:02:39.36869Z","iopub.status.idle":"2021-07-22T23:02:42.934637Z","shell.execute_reply.started":"2021-07-22T23:02:39.368636Z","shell.execute_reply":"2021-07-22T23:02:42.933541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test,predictions)\nplt.figure(figsize=(20,20))\nsns.heatmap(cm,annot=True, cmap=\"magma\")","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:04:07.592529Z","iopub.execute_input":"2021-07-22T23:04:07.592989Z","iopub.status.idle":"2021-07-22T23:04:15.72811Z","shell.execute_reply.started":"2021-07-22T23:04:07.592951Z","shell.execute_reply":"2021-07-22T23:04:15.726678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets compare our predictions with the true values in visualization:\n#Lets visualize multiple images:\nfig,axes = plt.subplots(5,5,figsize=(20,15))\naxes = axes.ravel() # flatten 5x5 matrix into 25 array\nfor i in range(0,25):\n    axes[i].imshow(X_test[i])\n    axes[i].set_title(f\"Prediction = {predictions[i]}\\n True Value = {y_test[i]}\")\n    axes[i].axis(\"off\")\nplt.subplots_adjust(hspace=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-22T23:10:13.892181Z","iopub.execute_input":"2021-07-22T23:10:13.892735Z","iopub.status.idle":"2021-07-22T23:10:15.288547Z","shell.execute_reply.started":"2021-07-22T23:10:13.892693Z","shell.execute_reply":"2021-07-22T23:10:15.286848Z"},"trusted":true},"execution_count":null,"outputs":[]}]}