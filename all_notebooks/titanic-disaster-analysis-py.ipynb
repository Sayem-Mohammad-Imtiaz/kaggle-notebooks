{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8810a379-951d-8238-4a07-c3aa76bf9cd1"},"source":"Learn to use Kaggle Kernel to analyze Titanic Disaster in Py\nFollowing Manav Sehgal in step by step (https://www.kaggle.com/startupsci/titanic-data-science-solutions)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31398bc0-4259-92d3-c475-4814c4c6b3bc"},"outputs":[],"source":"# Library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rnd\n\n# For visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# For machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e6ca6e5c-e7a8-d518-8e05-8063defded1b"},"outputs":[],"source":"# Load data\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\ncombine = [train_data, test_data]\n\nprint(train_data.columns.values)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc321bc1-67b1-6d0a-7db7-a8da0e98ef98"},"outputs":[],"source":"# Distribution of numeric data\ntrain_data.describe()\n\n#train_data.describe(percentile = [.62, .63])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"414386fe-0351-6713-25d0-4985a4b0cd68"},"outputs":[],"source":"# Distribution of String data\ntrain_data.describe(include = [np.object])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"333bd618-597b-fd2b-234b-a042430c4c68"},"outputs":[],"source":"# Correlation between PClass and Survived\ntrain_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"017392f1-6b28-75df-2434-469994358fd3"},"outputs":[],"source":"# Correlation between Sex and Survived\ntrain_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9beb89ef-9b46-4e11-47c3-6d63ba0aa595"},"outputs":[],"source":"# Visualization analysis for correlation between Age and Survived\ng = sns.FacetGrid(train_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)\n\n#sns.countplot(x=\"Age\", hue=\"Survived\", data=train_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f109f95e-bf76-11f4-e3cc-1f305dd62e08"},"outputs":[],"source":"# Further visualization analysis for correlation between Age, Pclass and Survived\ngrid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82f02625-d1c4-380c-05b3-c7d1edbc4cec"},"outputs":[],"source":"# Dropping features\nprint(\"Before\", train_data.shape, test_data.shape, combine[0].shape, combine[1].shape)\n\ntrain_data = train_data.drop(['Ticket', 'Cabin'], axis=1)\ntest_data = test_data.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_data, test_data]\n\nprint(\"After\", train_data.shape, test_data.shape, combine[0].shape, combine[1].shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83d27290-a930-21f7-0c8c-796b337503c9"},"outputs":[],"source":"# Extract Title from Name\nfor data in combine:\n    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    \npd.crosstab(train_data['Title'], train_data['Sex'])\n\n#train_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f8168f7-7b0f-dbc1-be67-a2834f0aa9bb"},"outputs":[],"source":"# Group the Title\nfor data in combine:\n    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n    \ntrain_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ba6820d-41dd-a3d0-4f00-c27d985971ce"},"outputs":[],"source":"# Change Title to Ordinal\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor data in combine:\n    data['Title'] = data['Title'].map(title_mapping)\n    data['Title'] = data['Title'].fillna(0)\n    \ntrain_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03140f20-01a0-1072-62eb-669144f13e4a"},"outputs":[],"source":"# Drop Name and ID\ntrain_data = train_data.drop(['Name', 'PassengerId'], axis=1)\ntest_data = test_data.drop(['Name'], axis=1)\ncombine = [train_data, test_data]\ntrain_data.shape, test_data.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05b62483-f017-48b4-1039-e21f454ac891"},"outputs":[],"source":"# Change Sex to Ordinal\nfor data in combine:\n    data['Sex'] = data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c7135d5-a8dd-5eba-b363-b12657179d19"},"outputs":[],"source":"# Predict Age using Median and Correlation between Age, Sex, Pclass\nguess_ages = np.zeros((2,3))\nfor data in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = data[(data['Sex'] == i) & \\\n                                  (data['Pclass'] == j+1)]['Age'].dropna()\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            data.loc[ (data.Age.isnull()) & (data.Sex == i) & (data.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    data['Age'] = data['Age'].astype(int)\n\ntrain_data.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"771039d8-f7f5-88a0-c49f-b098017b9e0e"},"outputs":[],"source":"# Cut the Age (Create AgeBand)\ntrain_data['AgeBand'] = pd.cut(train_data['Age'], 5)\ntrain_data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb29bcca-a7cd-fa32-1db9-5a245e637690"},"outputs":[],"source":"# Replace Age with Ordinal (According to AgeBand) and remove AgeBand\nfor data in combine:    \n    data.loc[ data['Age'] <= 16, 'Age'] = 0\n    data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n    data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n    data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n    data.loc[ data['Age'] > 64, 'Age']\n    \ntrain_data = train_data.drop(['AgeBand'], axis=1)\ncombine = [train_data, test_data]\n\ntrain_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31bf3f5f-5fcc-515d-4984-ad46001b0f06"},"outputs":[],"source":"# Combine SibSp and Parch\nfor data in combine:\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n\ntrain_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25b2e2c5-5443-4d8b-cbf6-56caa57ef6e9"},"outputs":[],"source":"# Create isAlone\nfor data in combine:\n    data['IsAlone'] = 0\n    data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc7f01be-2a2c-78f0-e9e9-96d27d6c949f"},"outputs":[],"source":"# Drop Parch, SibSp and FamilySize\ntrain_data = train_data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_data = test_data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_data, test_data]\n\ntrain_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42fffaab-376f-ce61-fcbc-69bc34649793"},"outputs":[],"source":"# Artificial Feature for Age * Class (how important a Person)\nfor data in combine:\n    data['Age*Class'] = data.Age * data.Pclass\n\ntrain_data.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbe08632-ff8b-7ab7-1eaf-b73498d88b9c"},"outputs":[],"source":"# Handle null in Embark\nfreq_port = train_data.Embarked.dropna().mode()[0]\nfor data in combine:\n    data['Embarked'] = data['Embarked'].fillna(freq_port)\n    \ntrain_data.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b86f062-0a59-588f-43ad-be160e4ae7cb"},"outputs":[],"source":"# Change Embarked to Ordinal\nfor data in combine:\n    data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d535d236-a5f1-43e6-d211-aadc98091b49"},"outputs":[],"source":"# Handle null in Fare\ntest_data['Fare'].fillna(test_data['Fare'].dropna().median(), inplace=True)\ntest_data.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e119451f-4c20-2668-78cb-ce221e7be2f3"},"outputs":[],"source":"# Cut the Fare (Create FareBand)\ntrain_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\ntrain_data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"622a8113-4012-a558-0b52-87a908c4389b"},"outputs":[],"source":"# Replace Fare with Ordinal (According to FareBand) and remove FareBand\nfor data in combine:\n    data.loc[ data['Fare'] <= 7.91, 'Fare'] = 0\n    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare']   = 2\n    data.loc[ data['Fare'] > 31, 'Fare'] = 3\n    data['Fare'] = data['Fare'].astype(int)\n\ntrain_data = train_data.drop(['FareBand'], axis=1)\ncombine = [train_data, test_data]\n    \ntrain_data.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d7fff76-8cb0-9248-939e-5184e075670b"},"outputs":[],"source":"test_data.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bf3270f-c870-24de-a3c6-9c68f07881e2"},"outputs":[],"source":"# Prepare for learning\nX_train = train_data.drop(\"Survived\", axis=1)\nY_train = train_data[\"Survived\"]\nX_test  = test_data.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a8bf32f-14c5-2922-2ccb-0224c37ddc99"},"outputs":[],"source":"# Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ac9ef38-b012-b17e-07b4-e92864582374"},"outputs":[],"source":"# Coefficient of Features\ncoeff_data = pd.DataFrame(train_data.columns.delete(0))\ncoeff_data.columns = ['Feature']\ncoeff_data[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_data.sort_values(by='Correlation', ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0ec1368e-2432-0ffb-6ac6-02a3382d83b7"},"outputs":[],"source":"# Support Vector Machines\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0631782-1cbd-d52b-2106-1079d0818427"},"outputs":[],"source":"# KNN\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd6ed068-28be-b660-2c12-f03bf4391d91"},"outputs":[],"source":"# Gaussian Naive Bayes\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8ecf950-1e11-b7db-2178-b7ae948bbea9"},"outputs":[],"source":"# Perceptron\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33805638-3e08-2b0c-ebcf-02fb661c87f0"},"outputs":[],"source":"# Linear SVC\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7cf2c051-57c7-2574-ed11-0a286678d069"},"outputs":[],"source":"# Stochastic Gradient Descent\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e6302cb6-d974-1341-7d60-bffbb4d07264"},"outputs":[],"source":"# Decision Tree\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37256f53-8958-bbf8-97f5-19fcd2a1ac5e"},"outputs":[],"source":"# Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46f4b6bc-4726-d6b2-d9a1-959d27a4996b"},"outputs":[],"source":"# Model Evaluation\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8e3f169-150f-3bba-a4e3-78a704795250"},"outputs":[],"source":"# Submission\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}