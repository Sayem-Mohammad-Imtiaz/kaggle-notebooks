{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip -qq install focal-loss","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nimport random\nimport gc\nfrom tqdm import tqdm\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Model\nwarnings.filterwarnings(\"ignore\")\n# from focal_loss import SparseCategoricalFocalLoss\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import mean_squared_error as mse\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Input, Dropout, BatchNormalization, Dense, Conv2D, Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/cmsnewsamples/new-smaples.csv').drop(columns = 'Unnamed: 0')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/cmsnewsamples/new-smaples.csv').drop(columns = 'Unnamed: 0')\ndf = df.drop(columns = [i for i in df.columns if '_1' in i])\ndf['non_hits'] = df[[i for i in df.columns if 'mask' in i]].sum(axis=1)\ndf = df[df['non_hits']==0].reset_index(drop=True)\n\ndf['1/pT'] = df['q/pt'].abs()\ndef label(a):\n    if a<=10:\n        return 0\n    if a>10 and a<=30:\n        return 1\n    if a>30 and a<=100:\n        return 2\n    if a>100:\n        return 3\n\ndf['pT'] = 1/df['1/pT']\n    \ndf['pT_classes'] = df['pT'].apply(label)\n\nfeatures = ['emtf_phi_'+str(i) for i in [0,2,3,4]] + ['emtf_theta_'+str(i) for i in [0,2,3,4]] + ['fr_'+str(i) for i in [0,2,3,4]] + ['old_emtf_phi_'+str(i) for i in [0,2,3,4]]\nlabels_1 = ['pT']\nlabels_2 = ['pT_classes']\nlabels_3 = ['vx']\n\nscaler_1 = StandardScaler()\ndf[features] = scaler_1.fit_transform(df[features])\n\nscaler_3 = MinMaxScaler()\ndf[labels_3] = scaler_3.fit_transform(df[labels_3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffled_list = list(range(len(df)))\nrandom.Random(242).shuffle(shuffled_list)\nshuffled_list = np.array_split(np.array(shuffled_list), 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OOF_preds = pd.DataFrame()\nOOF_preds['row'] = []\nOOF_preds['true_value'] = []\nOOF_preds['preds'] = []\n# OOF_preds['pT_classes'] = []\n# OOF_preds['0-10'] = []\n# OOF_preds['10-30'] = []\n# OOF_preds['30-100'] = []\n# OOF_preds['100-inf'] = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss(y_true,y_pred):\n    y_t = K.cast(y_true<80,K.dtype(y_true))*y_true + K.cast(y_true>=80,K.dtype(y_true))*K.cast(y_true<250,K.dtype(y_true))*y_true*2.4 + K.cast(y_true>=160,K.dtype(y_true))*10 \n    return K.mean(y_t*K.pow((y_pred-y_true)/y_true,2))/250","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def swish(x):\n    return x * K.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def FCNN(X_train, Y1_train, Y2_train, Y3_train):\n    \n    I = Input(shape=(4,4,1))\n    x = Conv2D(64, kernel_size=(2, 2),activation=swish)(I)\n    x = Flatten()(x)\n    x = Dense(128, activation=swish)(x)\n    x = Dropout(0.1)(x)\n    x1 = Dense(32, activation=swish)(x)\n    x1 = Dropout(0.1)(x1)\n    x1 = Dense(16, activation=swish)(x1)\n    x1 = Dense(1, activation='linear')(x1)\n    model = Model(inputs=I, outputs=x1)\n\n    batch_size=128\n    path = \"model.h5\"\n\n    checkpoint = ModelCheckpoint(path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    early_stop = EarlyStopping(monitor='val_loss',patience=10,verbose=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1,verbose=True)\n\n#     model.compile(optimizer = 'adam', loss=['mse', SparseCategoricalFocalLoss(gamma=2),'mse'], loss_weights = [70, 1, 70])\n    model.compile(optimizer = 'adam', loss=loss)\n    model.summary()\n\n    history = model.fit(x=X_train, y=Y1_train, batch_size=batch_size, epochs=100, verbose=0, validation_split=0.11, callbacks=[checkpoint,early_stop,reduce_lr])\n\n    model.load_weights(path)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    X_train = df[features].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n    Y1_train = df[labels_1].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n    Y2_train = df[labels_2].astype('float32').iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n    Y3_train = df[labels_3].iloc[np.concatenate([shuffled_list[j] for j in range(10) if j not in (i,100)])]\n\n    X_test = df[features].iloc[shuffled_list[i]]\n    Y1_test = df[labels_1].iloc[shuffled_list[i]]\n    Y2_test = df[labels_2].astype('float32').iloc[shuffled_list[i]]\n    Y3_test = df[labels_3].iloc[shuffled_list[i]]\n    \n    X_train = X_train.to_numpy().reshape((-1,4,4,1))\n    X_test = X_test.to_numpy().reshape((-1,4,4,1))\n    \n    model = FCNN(X_train, Y1_train, Y2_train, Y3_train)\n    \n    P = model.predict(X_test)\n    \n    test_preds_1 = P.reshape((len(X_test)))\n#     test_preds_1 = P[0].reshape((len(X_test)))\n#     test_preds_2 = P[1]\n    \n    OOF_preds_ = pd.DataFrame()\n    OOF_preds_['row'] = shuffled_list[i]\n    OOF_preds_['true_value'] = Y1_test['pT'].to_list()\n    OOF_preds_['preds'] = test_preds_1\n#     OOF_preds_['pT_classes'] = Y2_test['pT_classes'].values\n#     OOF_preds_['0-10'] = test_preds_2[:,0].reshape((len(X_test)))\n#     OOF_preds_['10-30'] = test_preds_2[:,1].reshape((len(X_test)))\n#     OOF_preds_['30-100'] = test_preds_2[:,2].reshape((len(X_test)))\n#     OOF_preds_['100-inf'] = test_preds_2[:,3].reshape((len(X_test)))\n    \n    OOF_preds = pd.concat([OOF_preds,OOF_preds_],axis = 0).reset_index(drop = True)\n    \n    X_train, Y1_train, Y2_train, Y3_train, X_test, Y1_test, Y2_test, Y3_test, model, P, test_preds_1, test_preds_2, OOF_preds_ = [0]*13\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OOF_preds = OOF_preds.sort_values(by = 'row').reset_index(drop = True)\nOOF_preds.to_csv('OOF_preds.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('OOF_preds.csv').drop(columns = ['Unnamed: 0'])\ndf = df.sort_values(by = 'row').reset_index(drop = True)\ndf['True_pT'] = df['true_value']\ndf['Predicted_pT'] = df['preds']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAE1 = []\ndx = 0.5\nfor i in tqdm(range(int(2/dx),int(150/dx))):\n    P = df[(df['True_pT']>=(i-1)*dx)&(df['True_pT']<=(i+1)*dx)]\n    try:\n        p = mae(P['True_pT'],P['Predicted_pT'])\n    except:\n        p=0\n    MAE1.append(p)\nMAE1 = MAE1[:146]\nplt.plot([i*dx for i in range(int(75/dx))],[0]*int(int(75/dx)-len(MAE1))+MAE1,label = 'FCNN')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[(df['preds']>0) & (df['preds']<=0.5)]['preds'])\nplt.ylabel('pdf')\nplt.xlabel('1/pT')\nplt.title('Distribution of Predicted 1/pT')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pT_classes(a):\n    if a<=10:\n        return 0\n    if a>10 and a<=30:\n        return 1\n    if a>30 and a<=100:\n        return 2\n    if a>100:\n        return 3\n\nprint(classification_report(df['True_pT'].apply(pT_classes), df['Predicted_pT'].apply(pT_classes)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(classification_report(df['True_pT'].apply(pT_classes), df.iloc[:,4:8].to_numpy().argmax(axis = 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(df['True_pT'].apply(pT_classes), df['Predicted_pT'].apply(pT_classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion_matrix(df['True_pT'].apply(pT_classes), df.iloc[:,4:8].to_numpy().argmax(axis = 1))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}