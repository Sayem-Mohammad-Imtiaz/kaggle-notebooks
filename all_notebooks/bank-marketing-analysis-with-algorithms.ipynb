{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font color = 'red'>\nContent:\n    \n1. [Load and check data](#1)\n3. [Univariate Variable Analysis](#3)\n    *          [Categorical Variable ](#4)\n    *          [Numerical Variable ](#5)\n1. [Outlier Detection](#20)    \n1. [Missing Value](#21)     \n1. [Correlation matrix](#6)    \n1. [Data Manipulation](#7) \n    *           [One-Hot Encoding ](#8)\n    *           [Others](#9)\n    *           [Data Normalization](#10)\n                       \n1. [Algorithm Works](#222) \n    *           [Logistic Regression](#12)\n    *           [Random Forest](#13)\n    *           [Naive Bayes Classifier](#14)\n    *           [Stochastic Gradient Descent Classifier](#15) \n    *           [KNN](#16)  \n    *           [Decision Tree](#17) \n    *           [Neural Network-Perceptron](#18)\n    *           [Gradient Boosting Classifier](#22)\n    *           [Xgboost Classifier](#23)\n1. [Comparison of algorithms](#19) \n2. [Comparison of Kappa Scores](#24)\n3. [Comparison of F1 Scores](#25) \n    "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"1\"></a><br>\n# Load and check data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/bank-marketing-dataset/bank.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n1. Age / Age\n2. Job / Job\n3. Marital Status / Marital Status\n4. Education / Education Level\n5. Default / Having a previously broken credit\n6. Housing / home loan?\n7. Loan / Personal Loan?\n8. Contact / Was the customer contacted on his home or mobile phone?\n9. Month: Last month of contact\n10. Day: The day of the contacted.\n11. Duration: Talk time on last call\n12. Campaign: The number of contacts reaching the customer during the current campaign (including the last contact)\n13. Pdays: The number of days since the previous campaign, if reached (-1 if it was never reached before)\n14. Previous: The number of contacts that reached the customer before this campaign\n15. Poutcome: Previous campaign success, failure or failure"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"3\"></a><br>\n# Univariate Variable Analysis\n* Categorical Variables:job,marital, default, education,housing,loan,contact,poutcome,mounth,deposit,day\n* Numerical Variables: age, campaign,duration, pdays,balance,previous"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"4\"></a><br>\n## Categorical Variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_plot(variable):\n    var =data[variable]\n    varValue = var.value_counts()\n    plt.figure(figsize=(15,3))\n    plt.bar(varValue.index, varValue,color=['#00008b','#00e5ee','#cd1076', '#008080','#cd5555','red','blue',])\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    \n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryc = [\"job\",\"marital\",\"education\", \"housing\", \"loan\",\"contact\",\"poutcome\",\"month\",\"deposit\"]\nfor c in categoryc:\n    bar_plot(c)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"5\"></a><br>\n## Numerical Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hist(variable):\n    plt.figure(figsize=(9,6))\n    plt.hist(data[variable], bins=40,color='#cd1076')\n    plt.xlabel(variable)\n    plt.ylabel(\"frequency\")\n    plt.title(\"{} distrubition with hist\".format(variable))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numericVar = [\"age\",\"campaign\",\"duration\"]\nfor n in numericVar:\n    plot_hist(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data.age,data.deposit).plot(kind=\"area\",figsize=(15,7),color=['#0000ff','#000000' ])\nplt.title('Age Distribution')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### The number of people who are 25 to 40 years old with a time deposit account is high."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data.job,data.deposit).plot(kind=\"barh\",figsize=(15,7),color=['#0000ff','#000000'])\nplt.title('Deposit Age Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('Job')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In people at the executive level  have more deposit accounts."},{"metadata":{},"cell_type":"markdown","source":"<a id = \"20\"></a><br>\n# Outlier Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ndef detect_outliers(data,features):\n    outlier_indices = []\n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(data[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(data[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = data[(data[c] < Q1 - outlier_step) | (data[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[detect_outliers(data,['age',\n                               'day','duration','campaign','previous'])]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I do not include this row"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop([3945], axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"21\"></a><br>\n# Missing Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No missing value.."},{"metadata":{},"cell_type":"markdown","source":"<a id = \"6\"></a><br>\n# Correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig, ax = plt.subplots(figsize=(13,13))         # Sample figsize in inches\nsns.heatmap(data.corr(), annot=True, linewidths=.5, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## * Calculated correlation between two variables (r) gets a value between -1 and 1.\n* No correlaiton r=0\n* Very weak correlation: r<20\n* Weak correlation: between 0.20-0.49\n* Moderate correlation: between 0.5-0.79\n* Strong correlation: between 0.8-0.99\n* Perfect correlation: r=1 \n\n### Looking at it, there is a moderate correlation between the *days* and the *previous* ones. (r=0.51)"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"7\"></a><br>\n# Data Manipulation"},{"metadata":{},"cell_type":"markdown","source":"### I do not include the *Duration column* in the dataset, as it is unknown data at the time of the prediction.\n**duration: Talk Time on Last Call**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['duration'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"8\"></a><br>\n# One-Hot Encoding "},{"metadata":{},"cell_type":"markdown","source":"### **One Hot Encoding means that categorical variables are represented as binary.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=data.select_dtypes(include=[object]).columns\ndata=pd.concat([data,pd.get_dummies(data[columns])],axis=1)\ndata=data.drop(['job','marital','education','default','housing','loan','contact','month','day','poutcome'],axis=1)\ndata.info()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"9\"></a><br>\n# Others.."},{"metadata":{},"cell_type":"markdown","source":"## 1. The ***pdays*** data indicates how many times the customer has been contacted before.\n\n### Updated as follows.\n\nif the **pdays = 0**, it indicates that it has not been contacted before\n\nif the **pdays = 1**, it indicates that it was contacted earlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"def pdayswork(pdays):\n    if(pdays == -1):\n        return(0)\n    elif(pdays >= 0):\n        return(1)\ndata['pdays2'] = data['pdays'].apply(pdayswork)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. For a single target column"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['deposit_no', 'deposit_yes'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def deposit1(deposit):\n    if(deposit=='yes'):\n        return(1)\n    elif(deposit=='no'):\n        return(0)\ndata['depositNew'] = data['deposit'].apply(deposit1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['deposit'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In this way, our target column, whose data type is object, turned into numerical values. And new target column name is *depositNew*. Also as this is a classification problem, the target column can remain as an object. But I chose to convert it to int data type."},{"metadata":{},"cell_type":"markdown","source":"# the current state of our data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"10\"></a><br>\n# Data Normalization"},{"metadata":{},"cell_type":"markdown","source":"### StandartScaler, normalizes the data with a standard deviation of 1 with an average of 0.\n\n**The target column is not normalized.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX = data.iloc[:, 0:50]\nY = data.iloc[:, 50]\nnd = StandardScaler()\nnd.fit(X)\nX =nd.transform(X)\nprint(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"222\"></a><br>\n# Algorithm Works"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import f1_score\nX = data.iloc[:, 0:50]\nY = data.iloc[:, 50]\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)\n\naccuracies = {}\nkappaScores= {}\nf1scores={}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"12\"></a><br>\n# Logistic Regression "},{"metadata":{},"cell_type":"markdown","source":"Logistic regression is a predictive linear model that aims to explain the relationship between a dependent binary variable and one or more independent variables. \nThe output of Logistic Regression is a number between  *0 and 1* which you can think about as being the probability that a given class is true or not.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(random_state=101,multi_class='ovr',solver='liblinear',class_weight='balanced',C=0.2)\nlr.fit(X_train,y_train)\nprediction = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,prediction))\nacc = accuracy_score(y_test,prediction)*100\nprint(\"Logistic Regression accuracy:\",acc)\naccuracies['Logistic Regression']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['Logistic Regression']=f1\n\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Logistic Regression']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=round(accuracy_score(y_test,prediction),3)\ncm= confusion_matrix\ncm1=cm(y_test,prediction)\nsns.heatmap(cm1, annot=True,fmt=\".1f\",linewidths=3,square=True, cmap='PuBu',color=\"#cd1076\")\nplt.ylabel('actual label')\nplt.xlabel('predicted label')\nplt.title('accuracy score: {0}'.format(score),size=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <a id = \"13\"></a><br>\n # Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, max_depth=12,\n                             random_state=50)\n\nclf.fit(X_train,y_train)\n\nprediction = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test,prediction)*100\nprint(\"Random Forest accuracy:\",acc)\naccuracies['Random Forest']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['Random Forest']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Random Forest']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"14\"></a><br>\n# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb=GaussianNB()\nnb.fit(X_train,y_train)\nnaiveb=nb.predict(X_test)\nprediction= nb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test,prediction)*100\nprint(\"Naive Bayes accuracy:\",acc)\naccuracies['Naive Bayes']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['Naive Bayes']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Naive Bayes']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <a id = \"15\"></a><br>\n # Stochastic Gradient Descent Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd=SGDClassifier(loss='modified_huber',shuffle=True,random_state=100,penalty='l1',alpha=0.004\n                  ,max_iter=100,eta0=0.2,learning_rate='optimal')\nsgd.fit(X_train,y_train)\nprediction=sgd.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test,prediction)*100\nprint(\"SGD Classifier accuracy:\",acc)\naccuracies['SGDC']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['SGDC']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['SGDC']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"16\"></a><br>\n# KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn= KNeighborsClassifier(n_neighbors = 4,algorithm='ball_tree')\nknn.fit(X_train, y_train)\nprediction=knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test,prediction)*100\nprint(\"Knn accuracy:\",acc)\naccuracies['KNN']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['KNN']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['KNN']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"17\"></a><br>\n# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree= DecisionTreeClassifier(criterion='gini',max_depth=10,random_state=100,min_samples_leaf=10)\ndtree.fit(X_train, y_train)\nprediction=dtree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test,prediction)*100\nprint(\"Decision Tree accuracy:\",acc)\naccuracies['Decision Tree']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['Decision Tree']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Decision Tree']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"18\"></a><br>\n# Neural Network - Perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Perceptron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = Perceptron(alpha=0.07,max_iter=100, random_state=100,penalty='l1')\npr.fit(X_train, y_train)\nprediction = pr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test, prediction)*100\nprint(\"Perceptron accuracy:\",acc)\naccuracies['Perceptron']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['Perceptron']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Perceptron']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"22\"></a><br>\n# Gradient Boosting Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.8,\n    max_depth=2, random_state=0)\nclf.fit(X_train, y_train)\nprediction = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test, prediction)*100\nprint(\"Gradient Boosting Classifier accuracy:\",acc)\naccuracies['Gradient Boosting']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1-Score: \",f1)\nf1scores['Gradient Boosted']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Gradient Boosting']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"23\"></a><br>\n# Xgboost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb =XGBClassifier(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.78,\n                           colsample_bytree=1, max_depth=7)\nxgb.fit(X_train,y_train)\nprediction = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = accuracy_score(y_test, prediction)*100\nprint(\"Xgboost Classifier accuracy:\",acc)\naccuracies['Xgboost Classifier']=acc\n\nf1=f1_score(y_test,prediction)*100\nprint(\"F1 Score: \",f1)\nf1scores['Xgboost Classifier']=f1\n\ncohen_kappa = cohen_kappa_score(y_test, prediction)*100\nprint('Cohen Kappa score: ',cohen_kappa)\nkappaScores['Xgboost Classifier']=cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"19\"></a><br>\n# Comparison of accuracies"},{"metadata":{},"cell_type":"markdown","source":"## Accuracy is a metric used to measure the success of a model but is not sufficient by itself."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"#00008b\", \"#00e5ee\", \"#cd1076\", \"#008080\",\"#cd5555\",'black']\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,3))\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"\\n\\n Algorithms\")\nsns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"24\"></a><br>\n# Comparison of Kappa Scores"},{"metadata":{},"cell_type":"markdown","source":"### Cohen's kappa, (7), symbolized by the lowercase Greek letter, is a powerful statistic useful for testing reliability. Similar to the correlation coefficients, between -1 and +1; where 0 represents the availability that can be expected from random chance, and 1 represents the perfect match between raters.\n\n* 0 indicates no information agreement\n* 0.01-0.20 **Slight agreement**\n* 0.21-0.40 **Fair agreement**\n* 0.41-0.60 **Moderate agreement**\n* 0.61-0.80 **Substantial agreement**\n* 0.81-1.00 **Almost perfect agreement**"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"#00008b\", \"#00e5ee\", \"#cd1076\", \"#008080\",\"#cd5555\",'black']\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,3))\nplt.ylabel(\"Kappa Score %\")\nplt.xlabel(\"\\n\\n Algorithms\")\nsns.barplot(x=list(kappaScores.keys()), y=list(kappaScores.values()), palette=colors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"25\"></a><br>\n# Comparison of F1 Scores"},{"metadata":{},"cell_type":"markdown","source":" ### The F1 Score value shows us the harmonic mean of the Precision and Recall values.\n \n## The main reason for using the F1 Score value instead of Accuracy is not to make an incorrect model selection in non-uniform data sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"#00008b\", \"#00e5ee\", \"#cd1076\", \"#008080\",\"#cd5555\",'black']\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,3))\nplt.ylabel(\"F1 Score %\")\nplt.xlabel(\"\\n\\n Algorithms\")\nsns.barplot(x=list(f1scores.keys()), y=list(f1scores.values()), palette=colors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Please do not forget to write down your positive or negative opinions."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}