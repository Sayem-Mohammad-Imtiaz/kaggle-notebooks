{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sms = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')\nsms.head()\n\n#Dataframe possède 5 colonnes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Surppression des 3 colonnes \"Unnamed\"\n\nsms.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\nsms.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Renommer la colonne \"v1\" par \"label\" et la colonne \"v2\" par \"message\" et affiche du résultat\n\nsms=sms.rename(columns={\"v1\":\"label\",\"v2\":\"message\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataframe avec les colonnes renommées\n\nsms.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Diagramme de la colonne label avec la fonction countplot\n#Affichage de ka quatité de Ham et Spam\n\nsns.countplot(sms.label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Afficher la taille de la DataFrame\nsms.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Réduction de la taille de la police en minuscules\nsms['message']=sms['message'].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Supprimession des ponctuations\n\ndef remove_punct(text):\n    text_tok = word_tokenize(text)\n    l=[]\n    for word in text_tok: \n        if not word in string.punctuation:\n            l.append(word)\n           \n    resultat=\" \".join(l)  \n    return resultat\n\nsms['message']=sms.message.apply(remove_punct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Supprimession des Stop words \n\nstop=set(stopwords.words('english'))\n\ndef remove_stopword(text):\n    #On divise le texte en morceau\n    text_tok = word_tokenize(text)\n    #Initialisation liste vide\n    l = []\n    for a in text_tok:\n        if not a in stop:\n            l.append(a)\n            \n    resultat = \" \".join(l)\n    return resultat\n\nsms['message']=sms.message.apply(remove_stopword)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remplacer les mots par leur forme canonique \n\nlemmatizer=WordNetLemmatizer()\n\ndef lemm(text):\n    text_tok = word_tokenize(text) \n    l=[]\n    for word in text_tok:\n        l.append(lemmatizer.lemmatize(word))\n        \n    resultat = \" \".join(l)\n\n    return resultat\n\nsms.message=sms.message.apply(lemm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bag of words","metadata":{}},{"cell_type":"code","source":"# Vectoriser la colonne des messages par la méthode Bag of words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x#Impirtation de la fonction CoutVectorizer de la bibliothèque sklearn.feature_extraction.text\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#Corpus prend la valeur de la colonne message du tableau sms\n\ncorpus=sms['message'].values\nbw_vect = CountVectorizer()\n# tokenize et construire le vocabulaire\nbw_fit=bw_vect.fit(corpus)\n# vectoriser les mots\nbw_corpus = bw_fit.transform(corpus)\nbw_sms=pd.DataFrame(bw_corpus.toarray(),columns=bw_fit.get_feature_names())\nbw_sms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF IDF","metadata":{}},{"cell_type":"code","source":"#Vectoriser la colonne des messages par le méthode TF IDF\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n#Initialiser les paramètres du vectoriseur\ntf_vect = TfidfVectorizer(max_features=500)\n#Apprendre le vocabulaire du vectoriseur basé sur le paramètre initialisé\ntfidf_fit=tf_vect.fit(corpus)\n#Vectoriser le corpus\ntfidf_corpus= tfidf_fit.transform(corpus)\ntfidf_sms=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names())\ntfidf_sms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1ère méthode : avec TFIDF","metadata":{}},{"cell_type":"markdown","source":"## Vectorisation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXtfidf=tfidf_sms\nY=sms.label\n# Split train / test data :\nX_traintfidf, X_testtfidf, Y_train, Y_test = train_test_split(Xtfidf, Y, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Arbre de décision","metadata":{}},{"cell_type":"code","source":"#Importation de la fonction tree de la bibliothèque sklearn\n\nfrom sklearn import tree\ntree_model = tree.DecisionTreeClassifier()\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model = tree_model.fit(X_traintfidf, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importation des librairies matplotlib.pyplot et renommer en plt\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'non spam']\ntree.plot_tree(tree_model,feature_names = Xtfidf.columns, \n               class_names=names,\n               filled = True)\n\n# Affichage de l'arbre de trie entre les spam et ham","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Création de la variable de prédilection\n\nY_predicttfidf=tree_model.predict(X_testtfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Évaluation de l'arbre","metadata":{}},{"cell_type":"code","source":"# En utilisant l'arbre de décision il faut deviner si chaque message de la variable Y_test est spam ou non\n# Il faut sauvegarder la réponse dans la variable Y_prredicttfidf\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix \nmat = confusion_matrix(Y_predicttfidf, Y_test)\nprint(mat)\n\n#Afficher mat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')\n\n#Création du tableau permettant de comparer les valeurs prédites avec les valeurs déjà entrées","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2ème méthode : avec Bag of words","metadata":{}},{"cell_type":"markdown","source":"## Vectorisation","metadata":{}},{"cell_type":"code","source":"#Importation de la fonction train_test_split de la bibliothèque sklearn.model_selection\n\nfrom sklearn.model_selection import train_test_split\nXbw=bw_sms\nY=sms.label\n# Split train / test data : on récupère les sms du tableau et on explique au logiciel ce qu'est un spam \nX_trainbw, X_testbw, Y_train, Y_test = train_test_split(Xbw, Y, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Arbre de décision\n\nArbre de décision est un arbre orienté dont les noeuds sont étiquetés par un test et les ars contiennent mes résultats du test. On choisit de faire un test sur la variable qui disperse le mieux les classes. Pour cela, on calcule le coefficient de Gini qui mesure l'impurité d'un sous ensemble de donnée.","metadata":{}},{"cell_type":"code","source":"#Importation de la fonction tree de la bibliothèque sklearn\n\nfrom sklearn import tree\ntree_model = tree.DecisionTreeClassifier()\n\n#Choisir le nombre d'étapes de l'arbre, sa profondeur \n\ntree_model = tree.DecisionTreeClassifier(max_depth = 2)\ntree_model = tree_model.fit(X_trainbw, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importation de la fonction matplotlib.pyplot qui prends le nom de plt\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nnames = ['spam', 'non spam']\ntree.plot_tree(tree_model,feature_names = Xbw.columns, \n               class_names=names,\n               filled = True)\n\n#Création et affichage de l'arbre de choix du logicel permettant de dire si les sms sont des spam ou ham","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_predictbw=tree_model.predict(X_testbw)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Évaluation de l'arbre\n\nOn compare les valeurs devinées par la machine (Y_predictbw) par rapport aux vraies valeurs (Y_test)","metadata":{}},{"cell_type":"code","source":"#Importation de la fonction accuracy_score et confusion_matrix de la bibliothèque sklearn.metrics\nsklearn.metrics import accuracy_score, confusion_matrix\n\n#Défintion du tableau mat qui regroupe les avelurs de Y_predict et Y_test\nmat = confusion_matrix(Y_predictbw, Y_test)\nprint(mat)\n\n#Afficher du tableau des valeurs de Y_predict et Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')\n\n#Affichage du tableau comparant les valeurs prédites avec les valeurs réelles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Suite avec la méthode TFIDF","metadata":{}},{"cell_type":"markdown","source":"## Gridsearch\n\nPour déterminer la meilleure profondeur entre 10 et 40 pour l'algorithme de l'arbre de décision","metadata":{}},{"cell_type":"code","source":"#Importation de la fonction GridSearchCV de la bibliothèque sklearn.model_selection\nfrom sklearn.model_selection import GridSearchCV\n#Importation de la fonction numpy et cette dernière prend le nom de np\nimport numpy as np\ndepths = np.arange(10, 40,5)\nparam_grid = [{'max_depth':depths}]\ngrid_tree= GridSearchCV(estimator=tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\ngrid_tree.fit(X_traintfidf, Y_train)\nbest_model_tree = grid_tree.best_estimator_\nY_grid=best_model_tree.predict(X_testtfidf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mat = confusion_matrix(Y_grid, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Forêt d'arbres\n\nSi on a un nombre important de variables explicatives (features). on utilise la Forêt d'arbres qui fonctionne comme le suivant:\n- on prend des sous ensembles de données et des sous ensembles de variables explicatives.\n- on applique l'Arbre de décision sur chaque sous ensemble.\n- la prédiction de la forêt aléatoire est alors un simple vote majoritaire des arbes construites.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRf_model = RandomForestClassifier()\nRf_model=Rf_model.fit(X_traintfidf, Y_train)\nY_predicttfidf=Rf_model.predict(X_testtfidf)\na_CART = accuracy_score(Y_test,Y_predicttfidf)\nprint(\"L'accuracy score du modèle RF est de : \",a_CART)\nmat = confusion_matrix(Y_predicttfidf, Y_test)\nsns.heatmap(mat, annot=True,  xticklabels=names, yticklabels=names)\nplt.xlabel('Test')\nplt.ylabel('Predicted')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classer\n\nFonction \"classer\" qui prend en entrée un texte et retourne comme résultat si ce texte est spam ou non","metadata":{}},{"cell_type":"code","source":"#Définition de la fonction reponse\n\ndef reponse(text):\n    text=text.lower()\n    text=text.replace('covid-19','coronavirus')\n    text=remove_punct(text)\n    text=remove_stopword(text)\n    text=lemm(text)\n    tfidf_text=tfidf_fit.transform([text])\n   \n    cm=cosine_similarity(tfidf_text, tfidf_corpus)\n    pos=np.argmax(cm[0])\n    data.answers[pos]\n    return data.answers[pos]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code à tester","metadata":{}},{"cell_type":"code","source":"while True:\n    text = str(input(\"Input: \"))\n    if text== \"exit\":\n        print(\"Response: Exiting.....\")\n        break\n    print(\"Response:\",reponse(text))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}