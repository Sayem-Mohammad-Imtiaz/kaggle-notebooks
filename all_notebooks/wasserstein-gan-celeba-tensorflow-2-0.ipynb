{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow.keras.utils import Progbar\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 25\nz_dim = 100\nc_lambda = 10\ntrain_size = 60000\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1./255)\ntraining_data = data_gen.flow_from_directory(directory = \"../input/celeba-dataset/img_align_celeba\",\n                                             target_size= (224,224),\n                                             batch_size = batch_size,\n                                             shuffle = True,\n                                             class_mode = None,\n                                             classes = None\n                                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_noise(batch_size , z_dim):\n    return tf.random.normal([batch_size,z_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(7*7*512 , input_shape = (z_dim,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Reshape((7,7,512)))\n    \n    model.add(tf.keras.layers.UpSampling2D()) #14x14\n    model.add(tf.keras.layers.Conv2D(256 , (5,5) , strides = (1,1), padding = \"same\")) #14x14\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n\n    model.add(tf.keras.layers.UpSampling2D())  #28X28\n    model.add(tf.keras.layers.Conv2D(128 , (5,5) , strides = (1,1), padding = \"same\")) #28x28\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n\n    model.add(tf.keras.layers.UpSampling2D())  #56X56\n    model.add(tf.keras.layers.Conv2D(64 , (5,5) , strides = (1,1), padding = \"same\")) #56x56\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n        \n    model.add(tf.keras.layers.UpSampling2D())  #112X112\n    model.add(tf.keras.layers.Conv2D(32 , (5,5) , strides = (1,1), padding = \"same\")) #112x112\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n        \n    model.add(tf.keras.layers.UpSampling2D())  #224X224\n    model.add(tf.keras.layers.Conv2D(3 , (5,5) , strides = (1,1), padding = \"same\" , activation = \"tanh\")) #28x28\n        \n    return model     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing generator\ns = tf.random.normal([1,z_dim])\n\ngen = generator()\nx = gen(s)\nassert x.shape == (1,224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def critic():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Conv2D(32,(5,5), strides = (2,2) , padding = \"same\"  ,input_shape = (224,224,3)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Conv2D(64,(5,5), strides = (2,2) , padding = \"same\"  ,))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    \n    model.add(tf.keras.layers.Conv2D(128,(5,5), strides = (2,2) , padding = \"same\"))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Conv2D(256,(5,5), strides = (2,2) , padding = \"same\"))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1028,activation = \"relu\"))\n    model.add(tf.keras.layers.Dense(1))\n    \n    \n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing Critic\ncrit = critic()\ns = tf.random.normal([1,224,224,3])\nx = crit(s)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef get_gradient(crit,real,fake,epsilon):\n    \n    mixed = real * epsilon + (1 - epsilon)* fake\n    with tf.GradientTape() as gtape:\n        gtape.watch(mixed)\n        mixed_score = crit(mixed , training = True)\n        \n    grad = gtape.gradient(mixed_score , mixed)\n    return grad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gradient_penalty(gradient):\n    \n    grad_norm = tf.norm(gradient)\n    penalty = tf.reduce_mean((grad_norm - 1)**2)\n    \n    return penalty\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_loss(fake_output):\n    \n    \n    loss = -1 * tf.reduce_mean(fake_output)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef critic_loss(fake_output , real_output , gp , c_lambda):\n    \n    \n    loss = -(tf.reduce_mean(real_output) - tf.reduce_mean\n             (fake_output)) + (c_lambda * gp)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing gradient\nreal = tf.random.normal([1,224,224,3])\nfake = tf.random.normal([1,224,224,3])\ngrad = get_gradient(crit ,real = real , fake = fake , epsilon = 0.1)\ngrad.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing gradient_panalty\npenalty = gradient_penalty(grad)\npenalty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testinf critic's loss\nfake_output = crit(fake)\nreal_output = crit(real)\n\nloss = critic_loss(fake_output, real_output , penalty , 0.5)\nloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_optimizer = tf.keras.optimizers.Adam(0.002,0.5,0.99)\ncritic_optimizer = tf.keras.optimizers.Adam(0.002,0.5,0.99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(real_images):\n    \n    \n    \n    with tf.GradientTape() as gen_tape , tf.GradientTape() as crit_tape:\n        \n        noises = get_noise(real_images.shape[0] , z_dim)\n        fake_images = gen(noises,training = True)\n        fake_outputs = crit(fake_images , training = True)\n        real_outputs = crit(real_images , training = True)\n        epsilon = tf.random.uniform([real_images.shape[0],224,224,3])\n        grad = get_gradient(crit,real = real_images,fake = fake_images,epsilon = epsilon)\n        penalty = gradient_penalty(grad)\n        ######################################################################\n        g_loss = gen_loss(fake_outputs )\n        c_loss = critic_loss(fake_outputs, real_outputs , penalty , c_lambda )\n        \n    gen_grad = gen_tape.gradient(g_loss , gen.trainable_variables)\n    critic_grad = crit_tape.gradient(c_loss, crit.trainable_variables)\n    \n    gen_optimizer.apply_gradients(zip(gen_grad ,gen.trainable_variables ))\n    critic_optimizer.apply_gradients(zip(critic_grad , crit.trainable_variables))\n    \n    return g_loss , c_loss\n    \n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset , epochs):\n    \n    \n    mean_gen_loss_list = []\n    mean_critic_loss_list = []\n    \n    for epoch in range(epochs):\n        gen_loss_list = []\n        critic_loss_list = []\n        \n        progress_bar = Progbar(train_size)\n        i = 0\n        for image in dataset:\n            i = i + batch_size\n            if i <= train_size:\n                g_loss, c_loss , = train_step(image)\n                gen_loss_list.append(g_loss)\n                critic_loss_list.append(c_loss)\n                progress_bar.add(batch_size)\n            else:\n                break\n            \n        \n        \n        mean_g_loss = sum(gen_loss_list)/len(gen_loss_list)\n        mean_c_loss = sum(critic_loss_list)/len(critic_loss_list)\n        mean_gen_loss_list.append(mean_g_loss)\n        mean_critic_loss_list.append(mean_c_loss)    \n            \n        print (f'Epoch {epoch+1}, gen loss={mean_g_loss},critic loss={mean_c_loss}')\n        \n    return mean_gen_loss_list , mean_critic_loss_list\n            \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G_loss , C_loss = train(training_data , epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/kaggle/working/saved_models\")\ntf.saved_model.save(gen , \"/kaggle/working/saved_models\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noise = tf.random.normal([1,100])\nimage = gen(noise).numpy()\nimage = image.reshape(224,224,3)\nplt.imshow(image  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mode collapse is not observed \n\n\nnoises = np.random.randn(10,100)\nimages = []\nnoises[0].reshape(1,100)\nfor i in range(noises.shape[0]):\n    images.append(gen(noises[i].reshape(1,100)).numpy().reshape(224,224,3))\n\nfig , ax = plt.subplots(2,5 , figsize = (10,8))\n\nfor j in range(2):\n  for i in range(5):\n    plt.sca(ax[j][i])\n    if j == 0:\n      plt.imshow(images[i] )\n    else:\n      plt.imshow(images[i+5])\n    plt.axis(\"off\")\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.plot(G_loss , label = \"Generator loss\" , linewidth = 1.5)\nplt.plot(C_loss, label = \"Critic's loss\" , linewidth = 1.5)\nplt.legend()\nplt.title(\"Loss per Epoch\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}