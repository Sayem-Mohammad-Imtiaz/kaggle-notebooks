{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n       # print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing relevant libraries\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.metrics import fbeta_score\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom tensorflow import keras\nfrom skimage import io\nfrom sklearn.preprocessing import MultiLabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the csv metadata files\n\ntrain_classes = pd.read_csv(\"../input/planets-dataset/planet/planet/train_classes.csv\")\nsample_sub = pd.read_csv(\"../input/planets-dataset/planet/planet/sample_submission.csv\")\ntrain_classes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dict for converting labels to numerical classes\n\nlabel_map = {'agriculture': 14,\n 'artisinal_mine': 5,\n 'bare_ground': 1,\n 'blooming': 3,\n 'blow_down': 0,\n 'clear': 10,\n 'cloudy': 16,\n 'conventional_mine': 2,\n 'cultivation': 4,\n 'habitation': 9,\n 'haze': 6,\n 'partly_cloudy': 13,\n 'primary': 7,\n 'road': 11,\n 'selective_logging': 12,\n 'slash_burn': 8,\n 'water': 15}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the training images\n\n#x_train, y_train = [], []\n\n#for img_name, tags in tqdm(train_classes.values, miniters=1000):\n    #arr = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img_name))\n    #targets = np.zeros(17)\n    #for t in tags.split(' '):\n   #     targets[label_map[t]] = 1 \n  #  x_train.append(cv2.resize(arr, (64, 64)))\n #   y_train.append(targets)\n\n# normalizing train image pixels\n#y_train = np.array(y_train, np.uint8)\n#x_train = np.array(x_train,np.float16)/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# numbers of tags and their names\ncounts = {}\nsplitted_tags = train_classes['tags'].map(lambda x: x.split(' '))\nfor labels in splitted_tags.values:\n    for label in labels:\n        counts[label] = counts[label] + 1  if label in counts else 0\n\nplt.figure(figsize=(18, 6))\nplt.title('Classes')\nidxs = range(len(counts.values()))\nplt.xticks(idxs, counts.keys(), rotation=-45)\nplt.bar(idxs, counts.values());","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(splitted_tags)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load data\nall_labels = splitted_tags.values\nlabels = list(set([y for x in all_labels for y in x]))\n\ndef load_data(train_classes, labels, resize):\n    x_train = []\n    y_train = []\n\n    label_map = {l: i for i, l in enumerate(labels)}\n    inv_label_map = {i: l for l, i in label_map.items()}\n\n    for f, tags in train_classes.values:\n        img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f)) \n        targets = np.zeros(17)\n        for t in tags.split(' '):\n            targets[label_map[t]] = 1 \n\n        x_train.append(cv2.resize(img,resize))\n        y_train.append(targets)\n        \n    y_train = np.array(y_train, np.uint8)\n    x_train = np.array(x_train, np.float16) / 255.\n\n    return x_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = load_data(train_classes, labels, resize=(64, 64))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the images of the datasets\n\nprint(train_classes.shape)\nprint(sample_sub.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x,y, test_size=0.2, random_state = int(time.time()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.shape)\nprint(x_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making use of the training set\n\n\n#img='train_10016.jpg'\n#path = '../input/planets-dataset/planet/planet/train-jpg/{}'.format(img)\n\n#plt.imshow(io.imread(path))\n\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n\n\n\npath = Path('/kaggle/input/planets-dataset/planet/planet')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nsrc = (ImageList.from_csv(path,'train_classes.csv', folder='train-jpg', suffix='.jpg')\n       .split_by_rand_pct(0.2)\n       .label_from_df(label_delim=' '))\n\n\ndata = (src.transform(tfms, size=128)\n        .databunch(num_workers=0).normalize(imagenet_stats))\n\ndata.show_batch(rows=3, figsize=(12,9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since this is a multi lable task and the labels are given as tags in a single dataframe series\n\nbiner = MultiLabelBinarizer()\ntags = train_classes['tags'].str.split()\ny = biner.fit_transform(tags)\n\nlabels = biner.classes_\nprint('Number of labels: ', len(labels))\nprint('\\n')\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the labels into one hot encoded form for EDA ease. \n\n#for label in labels:\n    #train_classes[label] = train_classes['tags'].apply(lambda x: 1 if label in x.split()  else 0)\n    \n#train_classes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_classes[labels].sum().sort_values(ascending=False).plot(kind='barh', figsize=(8,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Learning curve**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef learning_curve(model_fit, key='acc', ylim=(0.8, 1.01)):\n    plt.figure(figsize=(12,6))\n    plt.plot(model_fit.history[key])\n    plt.plot(model_fit.history['val_' + key])\n    plt.title('Learning Curve')\n    plt.ylabel(key.title())\n    plt.xlabel('Epoch')\n    plt.ylim(ylim)\n    plt.legend(['train', 'test'], loc='best')\n    plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **F beta score - metric**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef fbeta_score_K(y_true, y_pred):\n    beta_squared = 4\n\n    tp = K.sum(y_true * y_pred) + K.epsilon()\n    fp = K.sum(y_pred) - tp\n    fn = K.sum(y_true) - tp\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    result = (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n    return result\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.applications import ResNet50, VGG16\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Using V G G**"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(0.003, decay=0.0005)\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n    model = Sequential([\n    base_model,\n \n    Flatten(), \n        \n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(17, activation='sigmoid')  \n])\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[fbeta_score_K])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit = model.fit( x_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_val, batch_size=64)\nscore = fbeta_score(y_val, np.array(y_pred) > 0.2, beta=2, average='samples')\n\nprint(\"Test score (f1): \", score)\nprint(\"Error: %.2f%%\" % (100-score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_curve(model_fit, key='loss', ylim=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# decrease learning step and decay\n\noptimizer = Adam(0.0001, decay=0.00001)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[fbeta_score_K])\n\nmodel_fit = model.fit(\n    x_train, y_train,\n    batch_size=64,\n    epochs=10,\n    verbose=1,\n    validation_data=(x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_val, batch_size=64)\nscore = fbeta_score(y_val, np.array(y_pred) > 0.2, beta=2, average='samples')\n\nprint(\"Test score (f1): \", score)\nprint(\"Error: %.2f%%\" % (100-score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_curve(model_fit, key='loss', ylim=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding more layer to learn\n\nfor layer in model.layers[0].layers[1:]:\n    layer.trainable = True\n\nfor layer in model.layers[0].layers:\n    print(layer.name, layer. trainable)\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[fbeta_score_K])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit = model.fit(\n    x, y,\n    batch_size=64,\n    epochs=20,\n    verbose=1,\n    validation_data=(x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_val, batch_size=64)\nscore = fbeta_score(y_val, np.array(y_pred) > 0.2, beta=2, average='samples')\n\nprint(\"F beta score: \", score)\nprint(\"Error: %.2f%%\" % (100-score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_curve(model_fit, key='loss', ylim=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I will check fit_generator for my the best solution\n\naug = keras.preprocessing.image.ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n                         width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n                         horizontal_flip=True, fill_mode=\"nearest\")\n \nmodel_fit = model.fit_generator(aug.flow(x, y, batch_size=64),\n                        validation_data=(x_val, y_val), steps_per_epoch=len(x) // 128,\n                        epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_val, batch_size=64)\nscore = fbeta_score(y_val, np.array(y_pred) > 0.2, beta=2, average='samples')\n\nprint(\"F beta score: \", score)\nprint(\"Error: %.2f%%\" % (100-score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_curve(model_fit, key='loss', ylim=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now to check the Test data\n\n\nX_test=[]\n\nfor img, label in tqdm(sample_sub[:40669].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (64,64)))\n\nfor img, label in tqdm(sample_sub[40669:].values, miniters = 1000):\n  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (64,64)))\n\nx_test = np.array(X_test, np.float16)/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_Predictions = model.predict(x_test, batch_size = 64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_Predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(Test_Predictions, columns= labels)\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# kaggle submission\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_curve(model_fit, key='loss', ylim=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = []\n\nfor i in tqdm(range(pred.shape[0]), miniters=1000):\n    a = pred.loc[[i]]\n    a = a.apply(lambda x:x>0.2, axis =1)\n    a = a.transpose()\n    a = a.loc[a[i]==True]\n    ' '.join(list(a.index))\n    final_pred.append(' '.join(list(a.index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub['tags'] = final_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.to_csv('My_Final_Result.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"My_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}