{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm.notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix as cm, classification_report as cr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/fairface/FairFace/train_labels.csv')\ndf_train['split'] = 'train'\ndf_train['file'] = '../input/fairface/FairFace/' + df_train.file\ndf_test = pd.read_csv('../input/fairface/FairFace/val_labels.csv')\ndf_test['file'] = '../input/fairface/FairFace/' + df_test.file\ndf_test['split'] = 'test'\ndf = pd.concat([df_train, df_test])\n\ndf.race, labels_map = pd.Categorical(df.race).factorize()\n\ndf = df.drop(columns=['service_test', 'gender', 'age'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['race'].value_counts().plot.bar()\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df[df.split == 'train'].drop(columns=['split'])\ndf_train, df_val = train_test_split(df_train, test_size=0.1, random_state=0, shuffle=True)\ndf_test = df[df.split == 'test'].drop(columns=['split'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 224\nAUTOTUNE = tf.data.AUTOTUNE\nBATCH_SIZE = 224\nNUM_CLASSES = len(labels_map)\n\n# Dataset creation\ny_train = tf.keras.utils.to_categorical(df_train.race, num_classes=NUM_CLASSES, dtype='float32')\ny_test = tf.keras.utils.to_categorical(df_test.race, num_classes=NUM_CLASSES, dtype='float32')\ny_val = tf.keras.utils.to_categorical(df_val.race, num_classes=NUM_CLASSES, dtype='float32')\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((df_train.file, y_train)).shuffle(len(y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((df_val.file, y_val))\ntest_ds = tf.data.Dataset.from_tensor_slices((df_test.file, y_test))\n\nassert len(train_ds) == len(df_train.file) == len(df_train.race)\nassert len(val_ds) == len(df_val.file) == len(df_val.race)\nassert len(test_ds) == len(df_test.file) == len(df_test.race)\n\n# Read files\ndef map_fn(path, label):\n    image = tf.io.decode_jpeg(tf.io.read_file(path))\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    return image, label\n\n# Read files\ntrain_ds = train_ds.map(lambda path, lbl: (tf.io.decode_jpeg(tf.io.read_file(path)), lbl), num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(lambda path, lbl: (tf.io.decode_jpeg(tf.io.read_file(path)), lbl), num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(lambda path, lbl: (tf.io.decode_jpeg(tf.io.read_file(path)), lbl), num_parallel_calls=AUTOTUNE)\n\n# Batch and resize after batch, then prefetch\ntrain_ds = train_ds.map(lambda imgs, lbls: (tf.image.resize(imgs, (IMG_SIZE, IMG_SIZE)), lbls), num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(lambda imgs, lbls: (tf.image.resize(imgs, (IMG_SIZE, IMG_SIZE)), lbls), num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(lambda imgs, lbls: (tf.image.resize(imgs, (IMG_SIZE, IMG_SIZE)), lbls), num_parallel_calls=AUTOTUNE)\n\ntrain_ds = train_ds.batch(BATCH_SIZE)\nval_ds = val_ds.batch(BATCH_SIZE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n\n# Performance enchancement - cache, batch, prefetch\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n# Display some\nimgs, lbls = list(train_ds.take(1))[0]\nn = 3\nfig, ax = plt.subplots(1, n, figsize=(5*n, 5))\nfor i, (img, lbl) in enumerate(zip(imgs[:n], lbls[:n])):\n    ax[i].imshow(img.numpy().astype('uint8'))\n    ax[i].set(xlabel=lbl.numpy().argmax())\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define model and pre-processing layers\n\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n])\n\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n\nbase_model = tf.keras.applications.MobileNetV2(\n    include_top=False,\n    weights='imagenet',\n    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    pooling=\"avg\"\n)\n\nbase_model.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train\nLEARNING_RATE = 1e-3\n\ninputs = x = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nx = data_augmentation(x)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=x)\n\nmodel.compile(\n    optimizer=tf.optimizers.Adam(LEARNING_RATE),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"categorical_accuracy\"]\n)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 50\n\ncallbacks = [\n    tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_delta=0.0001),\n    tf.keras.callbacks.ModelCheckpoint(\n        'weights.tf', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True),\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', min_delta=0, patience=15, verbose=1, restore_best_weights=True)\n]\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    verbose=1,\n    callbacks=callbacks,\n    epochs=EPOCHS,\n)\n\nmodel.load_weights('weights.tf')\n\nmodel.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true, y_pred = [], []\nfor imgs, lbls in test_ds.take(len(test_ds)):\n    y_true.append(lbls.numpy())\n    y_pred.append(model.predict(imgs))\n\ny_pred = np.argmax(np.concatenate(y_pred), axis=1) \ny_true = np.argmax(np.concatenate(y_true), axis=1)   \n\nprint(cr(y_pred=y_pred, y_true=y_true))\nprint(cm(y_pred=y_pred, y_true=y_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7.5))\n\nax1.plot(history.history['categorical_accuracy'])\nax1.plot(history.history['val_categorical_accuracy'])\nax1.set_title('model accuracy')\nax1.set(ylabel='accuracy', xlabel='epoch')\nax1.legend(['train', 'val'], loc='upper left')\n\nax2.plot(history.history['loss'])\nax2.plot(history.history['val_loss'])\nax2.set_title('model loss')\nax2.set(ylabel='loss', xlabel='epoch')\nax2.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fine tuning\nFINE_TUNE_EPOCHS = 50\n\nbase_model.trainable = True\nprint(\"Number of layers in the base model: \", len(base_model.layers))\nfine_tune_at = 30\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False\n\nmodel.compile(\n    optimizer=tf.optimizers.Adam(LEARNING_RATE / 10),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"categorical_accuracy\"]\n)\n\nprint(model.summary())\n\ncallbacks = [\n    tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_delta=0.0001),\n    tf.keras.callbacks.ModelCheckpoint(\n        'weights_fine.tf', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True),\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', min_delta=0, patience=15, verbose=1, restore_best_weights=True)\n]\n\nhistory_fine = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=history.epoch[-1]+FINE_TUNE_EPOCHS,\n    initial_epoch=history.epoch[-1],\n    callbacks=callbacks,\n    verbose=1,\n)\n\nmodel.save_weights('weights_fine.tf')\n\nmodel.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true, y_pred = [], []\nfor imgs, lbls in test_ds.take(len(test_ds)):\n    y_true.append(lbls.numpy())\n    y_pred.append(model.predict(imgs))\n\ny_pred = np.argmax(np.concatenate(y_pred), axis=1) \ny_true = np.argmax(np.concatenate(y_true), axis=1)   \n\nprint(cr(y_pred=y_pred, y_true=y_true))\nprint(cm(y_pred=y_pred, y_true=y_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7.5))\nacc = history.history['categorical_accuracy'] + history_fine.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy'] + history_fine.history['val_categorical_accuracy']\nloss = history.history['loss'] + history_fine.history['loss']\nval_loss = history.history['val_loss'] + history_fine.history['val_loss']\n\nax1.plot(acc)\nax1.plot(val_acc)\nax1.set_title('model accuracy')\nax1.set(ylabel='accuracy', xlabel='epoch')\nax1.vlines(history.epoch[-1], 0, 1, colors='green')\nax1.legend(['train', 'val', 'fine_tune_start'], loc='upper left')\n\n\nax2.plot(loss)\nax2.plot(val_loss)\nax2.set_title('model loss')\nax2.set(ylabel='loss', xlabel='epoch')\nax2.vlines(history.epoch[-1], 0, max(loss), colors='green')\nax2.legend(['train', 'val', 'fine_tun_start'], loc='upper left')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}