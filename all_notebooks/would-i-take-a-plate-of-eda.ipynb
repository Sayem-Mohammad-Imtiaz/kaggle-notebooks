{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nHello people, welcome to this kernel. In this kernel I am going to examine the indian food 101 dataset, I will do some EDA and machine learning. Before starting, let's take a look at the content\n\n# Content\n1. Importing All The Things\n1. Data Overview\n1. Feature Engineering / Ingredients\n1. Random Color Function\n1. Simple Data Analyses\n    * Distribution Of Diet\n    * Distribution Of Preparation Time\n    * Distribution Of Cook Time\n    * Distribution Of Flavor Profile\n    * Distribution of Course\n    * Distribution Of State\n    * Distribution Of Region\n1. Detailed Data Analyses\n    * Correlation Between Preparation Time and Cook Time\n    * Detailed Analyses: Diet\n1. Data Preprocessing\n1. Machine Learning\n1. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"# Importing All The Things\n\nIn this section I am gonna import all the things that I will use in the EDA."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/indian-food-101/indian_food.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Overview\n\nIn this section I am going to take a look at the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 9 features in the dataset. \n* 7 of them are object and 2 of them are numerical\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 255 foods in this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is only one missing value in the dataset. We can fill it easily."},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering / Ingredients\n\nIn this section I am going to handle the ingredients feature, before starting let's take a look at that."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.ingredients[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.ingredients[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.ingredients[2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As we can see, materials seperated with seperator. So we can easily split them."},{"metadata":{},"cell_type":"markdown","source":"1. First, I will determine all unique materials."},{"metadata":{"trusted":true},"cell_type":"code","source":"material_list = []\nfor material_string in data.ingredients:\n    \n    material_string = material_string.lower()\n    materials = material_string.split(\",\")\n    materials = [material.strip() for material in materials]\n    for material in materials:\n        \n        if material not in material_list:\n            material_list.append(material)\n            \n\nprint(\"There are {} unique materials in the dataset\".format(len(material_list)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 417. Such a number!\n* Let's take a look at the materials"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(material_list[:20])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Now I am going to convert each ingredients string to sparse matrix. "},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_list = []\n\nfor material in material_list:\n    column = []\n    for ingredient in data.ingredients:\n        \n        ingredient = ingredient.lower().replace(\",\",\" \")\n        \n        \n        if material in ingredient:\n            column.append(1)\n        else:\n            column.append(0)\n            \n    matrix_list.append(column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* let's take a look at the matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"material_matrix = np.array(matrix_list)\nprint(\"Shape of material_matrix is {}\".format(material_matrix.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(material_matrix[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now I am going to convert this matrix to pandas dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"material_df = pd.DataFrame(material_matrix.T)\nmaterial_df.columns = material_list\nmaterial_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* For this moment, I am not going to add this dataset, into our dataset. But we will use this."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Color Function\n\nIn this section I am going to define a function that creates random colors. I will use this function when I start the data analyses."},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef random_color(number):\n    color_li = []\n    for i in range(number):\n        R = str(random.randint(0,255))\n        G = str(random.randint(0,255))\n        B = str(random.randint(0,255))\n        A = \"0.7\"\n        STRING = \"rgba({},{},{},{})\".format(R,G,B,A)\n        color_li.append(STRING)\n    return color_li\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_color(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Data Analyses\n\nIn this section, I am going to examine the distribution of all the features. Let's start with diet."},{"metadata":{},"cell_type":"markdown","source":"## Distribution Of Diet"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"trace1 = go.Bar(x=data.diet.value_counts().index\n          ,y=data.diet.value_counts().values\n          ,marker=dict(color=random_color(len(data.diet.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Diet\",\n                   xaxis=dict(title=\"Diet Type\")\n                  ,yaxis=dict(title=\"Count\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the foods are vegetarian."},{"metadata":{},"cell_type":"markdown","source":"# Distrubution Of Preparation Time\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(x=data.prep_time,\n                      marker=dict(color=\"blue\"),\n                     )\n\nlayout = go.Layout(title=\"Histogram Of Preparation Time\",\n                   xaxis=dict(title=\"Preparation Time\"),\n                   yaxis=dict(title=\"Count\")\n                  )\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Although most of the foods' preparation time is less than 100 minutes, there are the foods that have preparation time higher than 200."},{"metadata":{},"cell_type":"markdown","source":"# Distribution Of Cook Time\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(x=data.cook_time,\n                      marker=dict(color=\"green\"),\n                     )\n\nlayout = go.Layout(title=\"Histogram Of Cook Time\",\n                   xaxis=dict(title=\"Cook Time\"),\n                   yaxis=dict(title=\"Count\")\n                  )\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the foods' cook time is less than 100\n* There is an interesting food that have cook time 700 minutes. It equals 11.5 hours."},{"metadata":{},"cell_type":"markdown","source":"# Distribution Of Flavor Profile"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Bar(x=data.flavor_profile.value_counts().index\n          ,y=data.flavor_profile.value_counts().values\n          ,marker=dict(color=random_color(len(data.flavor_profile.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Flavor Profile\",\n                   xaxis=dict(title=\"Flavor Profile\")\n                  ,yaxis=dict(title=\"Count\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* What? There is a flavor profile named -1.\n* Most of the dataset is spicy and sweet.\n* Everyone knows that. In India, people like spicy tastes\n"},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Course"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Bar(x=data.course.value_counts().index\n          ,y=data.course.value_counts().values\n          ,marker=dict(color=random_color(len(data.course.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Course\",\n                   xaxis=dict(title=\"Course Type\")\n                  ,yaxis=dict(title=\"Count\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the foods are main course.\n* Starters are really rare.\n"},{"metadata":{},"cell_type":"markdown","source":"# Distribution Of State\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Bar(x=data.state.value_counts().index\n          ,y=data.state.value_counts().values\n          ,marker=dict(color=random_color(len(data.state.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - State\",\n                   xaxis=dict(title=\"State Name\")\n                  ,yaxis=dict(title=\"Number Of Foods\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Again -1. I guess data collector named missing values as -1.\n* Gujarat,Punjab,Maharashtra are good places to try something new."},{"metadata":{},"cell_type":"markdown","source":"# Distribution Of Region"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Bar(x=data.region.value_counts().index\n          ,y=data.region.value_counts().values\n          ,marker=dict(color=random_color(len(data.region.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Region\",\n                   xaxis=dict(title=\"Region Name\")\n                  ,yaxis=dict(title=\"Number Of Foods\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the indian cousine came from West and South."},{"metadata":{},"cell_type":"markdown","source":"# Detailed Data Analyses\n\n## Correlation Between Preparation Time and Cook Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can say that, correlation between preparation time and cook time is not high enough to be significant."},{"metadata":{},"cell_type":"markdown","source":"# Detailed Analyses: Diet"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(\"diet\").mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Vegetarian foods' preparation and cook time is shorter than non vegetarian foods. \n* So we can use this features in machine learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"veg_foods = data[data.diet==\"vegetarian\"]\nnon_veg_foods = data[data.diet==\"non vegetarian\"]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"veg_foods.flavor_profile.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_veg_foods.flavor_profile.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can say that if a food is not vegetarian, its flavor profile must be spicy.\n* But in vegetarian foods, we can't say anything."},{"metadata":{"trusted":true},"cell_type":"code","source":"veg_foods.course.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_veg_foods.course.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the non vegetarian foods are main course.\n* There is no non vegetarian dessert or snack, all of them are vegetarian.\n* There is no vegetarian starter.\n* We can use this feature in machine learning.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"veg_foods.state.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_veg_foods.state.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"veg_foods.region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_veg_foods.region.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\n\nIn this section I am going to process the dataset. Let's start."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* First, I will drop the ingredients feature because I will add the ingredients sparse matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"ingredients\",axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Name is unrelevant. We can drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"name\",axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now I am going to convert diet feature to 0 and 1. If the food is vegetarian, its diet will be 0 else it will be 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"diet_li = []\n\nfor diet in data.diet:\n    \n    if diet == \"vegetarian\":\n        diet_li.append(1)\n    else:\n        diet_li.append(0)\n        \n        \ndata.diet = diet_li","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Let's encode flavor_profile,course,state and region."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data=data,columns=[\"flavor_profile\",\"course\",\"state\",\"region\"])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now I am going to add add our ingredients sparce matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([data,material_df],axis=1)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now I am going to split the data to train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = data.drop(\"diet\",axis=1)\ny = data.diet\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"x_train's shape is\",x_train.shape)\nprint(\"x_test's shape is\",x_test.shape)\nprint(\"y_train's shape is\",y_train.shape)\nprint(\"y_test's. shape is \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now I am going to split train set to train and validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning\n\nIn this section I am going to classify foods by their diet type. As machine learning model, I will use Logistic Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings as wrn\nfrom sklearn.linear_model import LogisticRegression\n\nwrn.filterwarnings('ignore')\nLR = LogisticRegression()\nLR.fit(x_train,y_train)\nprint(\"Validation score is\",LR.score(x_val,y_val))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Validation score is %90. Now let's predict x_test."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\ny_pred = LR.predict(x_test)\n\nprint(\"Accuracy score of test: {}\".format(accuracy_score(y_pred,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our score looks great. Let's take a look at the confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_matrix = confusion_matrix(y_pred=y_pred,y_true=y_test)\nsns.heatmap(conf_matrix,annot=True,linewidths=1.5,cmap=\"CMRmap_r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Just as we expected, model predicted vegetarian foods great, but when the food was non vegetarian, model was confused. \n* It happened because of unbalanced data. If we have more non-vegetarian food, our model would have predicted better."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nThanks for your attention. If you have any question in your mind, please ask me. I will definetely return to you.\n\nHave a good day!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}