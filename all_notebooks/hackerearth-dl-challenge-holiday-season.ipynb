{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HackerEarth DL Challenge - Holiday Season\n\nYou work for a social media platform. Your task is to create a solution using deep learning to discern whether a post is holiday-related in an effort to better monetize the platform.\n\nClasses:-\n- Miscellaneous\n- Christmas_Tree\n- Jacket\n- Candle\n- Airplane\n- Snowman\n\n# Reading & Understanding Data\n## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nfrom skimage.io import imread\nfrom skimage.transform import resize\nseed = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runSeed():\n    global seed\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()\n\n## Checking the GPU configuration\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"basePath = '/kaggle/input/hackerearth-deep-learning-challenge-holidayseason/dataset/'\ntrainPath = basePath + 'train/'\ndf_base = pd.read_csv('/kaggle/input/hackerearth-deep-learning-challenge-holidayseason/dataset/train.csv')\ndf_base.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About the dataset"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Dataset has\",df_base.shape[0],\"samples\")\nprint(\"Count of samples\")\ndf_base['Class'].value_counts().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def scanImgFeatures(path):\n#     features = []\n#     files = sorted(os.listdir(path))\n#     for x in files:\n#         fp = os.path.join(path, x)\n#         img = imread(fp)/255.0\n#         features.append(img)\n#     return np.array(features), files\n\ndef showImage(img):\n    plt.figure(figsize=(4,4))\n    plt.imshow(img)\n    plt.show()\n\n# def getPathLabels(p):\n#     return [df_base[df_base['Image'] == x].iloc[0,1] for x in p]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data_img, train_files_img = scanImgFeatures(trainPath)\n# test_data_img, test_files_img = scanImgFeatures(testPath)\n# train_labels = getPathLabels(train_files_img)\n# showImage(test_data_img[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation\n"},{"metadata":{},"cell_type":"markdown","source":"## Split Train & Validation Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffle samples\ndf_shuffle = df_base.sample(frac=1, random_state=seed).reset_index(drop=True)\n\n# remove irrelevant columns\ndf_shuffle.drop(['Image'], axis=1, inplace=True)\ndf_y = df_shuffle.pop('Class')\n\n# split into train dev and test\ny_train, y_valid = skms.train_test_split(df_y, train_size=0.9, random_state=seed, stratify=df_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train set has {y_train.shape[0]} records out of {len(df_shuffle)} which is {round(y_train.shape[0]/len(df_shuffle)*100)}%\")\nprint(f\"Test set has {y_valid.shape[0]} records out of {len(df_shuffle)} which is {round(y_valid.shape[0]/len(df_shuffle)*100)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stratified split check\nprint(y_train.value_counts())\nprint(y_valid.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide df_base to df_train and df_valid\ndf_train = df_base.iloc[y_train.index.tolist(), :].reset_index(drop=True)\nprint(\"Train data:\",df_train['Class'].value_counts())\n\ndf_valid = df_base.iloc[y_valid.index.tolist(), :].reset_index(drop=True)\nprint(\"Validation data:\",df_valid['Class'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup Image Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"# constants\nbatch_size = 128\nimg_dim = 224\ndef getImgTensor(img_d):\n    return (img_d, img_d, 3)\ngetImgTensor(img_dim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading training and validation separately to prevent overlapping \n\ntrain_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255, \n#                                                          shear_range=0.2, \n                                                         zoom_range=0.2, \n                                                         horizontal_flip=True, \n#                                                          width_shift_range=0.1, \n#                                                          height_shift_range=0.1\n                                                        )\n\ntrain_generator=train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                  directory=trainPath,\n                                                  x_col=\"Image\",\n                                                  y_col=\"Class\",\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate class weights as classes are imbalanced\nclass_weights = sku.class_weight.compute_class_weight('balanced',\n                                                      np.unique(train_generator.classes), \n                                                      train_generator.classes)\ntrain_class_weights = {i:x for i, x in enumerate(class_weights)}\ntrain_class_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = train_generator.next()[0]\nshowImage(batch[0])\nshowImage(batch[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\nvalid_generator=valid_datagen.flow_from_dataframe(dataframe=df_valid,\n                                                  directory=trainPath,\n                                                  x_col=\"Image\",\n                                                  y_col=\"Class\",\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_generator=test_datagen.flow_from_directory(basePath, \n                                                batch_size=1,\n                                                color_mode=\"rgb\",\n                                                seed=seed,\n                                                shuffle=False,\n                                                classes=['test'],\n                                                target_size=getImgTensor(img_dim)[:2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotModelHistory(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n    ax[0].plot(h.history['loss'])   \n    ax[0].plot(h.history['val_loss'])\n    ax[0].legend(['loss','val_loss'])\n    ax[0].title.set_text(\"Train loss vs Validation loss\")\n\n    ax[1].plot(h.history['categorical_accuracy'])   \n    ax[1].plot(h.history['val_categorical_accuracy'])\n    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n\n    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n    print(\"Max. Validation Accuracy\", max(h.history['val_categorical_accuracy']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        ACCURACY_THRESHOLD = 0.98\n        if(logs.get('val_categorical_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def trainModel(model, epochs, optimizer, vb=1, modelName='model'):\n    bestModelPath = './'+modelName+'_model.hdf5'\n    callback = myCallback()\n    callbacks_list = [\n        callback,\n        k.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, verbose = 1, min_lr=0.00001), \n        k.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1, restore_best_weights = True), \n        k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n    ]\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=[k.metrics.CategoricalAccuracy(), k.metrics.Precision(), k.metrics.Recall()]\n    )\n    train_generator.reset()\n    if (train_generator.n%train_generator.batch_size) == 0:\n        steps_per_epoch = int(train_generator.n/train_generator.batch_size)\n    else:\n        steps_per_epoch = (train_generator.n//train_generator.batch_size) + 1\n\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        validation_steps = int(valid_generator.n/valid_generator.batch_size)\n    else:\n        validation_steps = (valid_generator.n//valid_generator.batch_size) + 1\n\n    return model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch, \n                               validation_data=valid_generator, validation_steps=validation_steps, \n                               epochs=epochs, verbose=vb, \n#                                class_weight=train_class_weights,\n                               callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model with time\ndef evaluateModel(model, path=True):\n    batch_size = valid_generator.batch_size\n    num_train_sequences = valid_generator.n\n    valid_generator.reset()\n    steps_per_epoch = 0\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        steps_per_epoch = int(valid_generator.n/valid_generator.batch_size)\n    else:\n        steps_per_epoch = int(valid_generator.n//valid_generator.batch_size) + 1\n\n    t1 = time.time()\n    if path:\n        model = k.models.load_model(model)\n    eval_results = model.evaluate_generator(valid_generator, steps=steps_per_epoch)\n    t2 = time.time()\n    print(f'\\nLoss: {eval_results[0]}, Accuracy: {eval_results[1]}, Precision: {eval_results[2]}, Recall: {eval_results[3]}')\n    print(f'Prediction Time per Image: {(t2-t1)/valid_generator.n}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict images using model\ndef predictModel(modelPath):\n    batch_size = test_generator.batch_size\n    num_train_sequences = test_generator.n\n    steps_per_epoch = 0\n    if (test_generator.n%test_generator.batch_size) == 0:\n        steps_per_epoch = int(test_generator.n/test_generator.batch_size)\n    else:\n        steps_per_epoch = int(test_generator.n//test_generator.batch_size) + 1\n\n    test_generator.reset()\n\n    t1 = time.time()\n    model = k.models.load_model(modelPath)\n    predictions = model.predict_generator(test_generator, steps=steps_per_epoch, verbose=1)\n    t2 = time.time()\n    print(f'Prediction Time per Image: {(t2-t1)/test_generator.n}')\n    \n    print(\"Generating Predictions file..\")    \n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predicted_class_indices=np.argmax(predictions, axis=1)\n    predictions_label = [labels[k] for k in predicted_class_indices]\n    filenames = list(map(lambda x: x.split('/')[-1], test_generator.filenames))\n    submission=pd.DataFrame({\n        \"Image\":filenames, \n        \"Class\":predictions_label\n    })\n    submission_file = \"submission_\"+modelPath.split('/')[-1].split('_')[0]+\".csv\"\n    submission.to_csv(submission_file,index=False)\n    print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n    submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train MobileNetV2 - Light Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dim=224\nmobilenet = k.applications.MobileNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nmobilenet.trainable = False\n\nmodel = k.models.Sequential([\n                             mobilenet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n#                              k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.25),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_1 = trainModel(model, 50, 'adam', modelName='mobilenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train ResNet152 - Heavy Model"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"img_dim=224\nresnet152 = k.applications.ResNet152V2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nresnet152.trainable = False\n\nmodel_2 = k.models.Sequential([\n                             resnet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n#                              k.layers.Dense(1024, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.3),\n\n#                              k.layers.Dense(512, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.3),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_2 = trainModel(model_2, 20, 'adam', modelName='resnet152')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train InceptionV3 - Medium Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dim=224\ninceptionv3 = k.applications.InceptionV3(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionv3.trainable = False\n\nmodel_3 = k.models.Sequential([\n                             inceptionv3,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_3 = trainModel(model_3, 50, 'adam', modelName='inceptionv3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train NASNetLarge - Heavy Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dim=331\nnasnet = k.applications.nasnet.NASNetLarge(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nnasnet.trainable = False\n\nmodel_4 = k.models.Sequential([\n                             nasnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_4 = trainModel(model_4, 50, k.optimizers.Adam(1e-4), modelName='nasnet_large')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train InceptionResNetV2 - Heavy Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dim=224\ninceptionresnet = k.applications.InceptionResNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionresnet.trainable = False\n\nmodel_5 = k.models.Sequential([\n                             inceptionresnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_5.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_5 = trainModel(model_5, 50, k.optimizers.Adam(1e-4), modelName='inceptionresnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train DenseNet169 - Light Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dim=224\ndensenet152 = k.applications.DenseNet169(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ndensenet152.trainable = False\n\nmodel_6 = k.models.Sequential([\n                             densenet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_6.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_6 = trainModel(model_6, 50, 'adam', modelName='densenet169')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Custom Conv2D Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dim=224\nmodel_7 = k.models.Sequential([\n                             k.layers.Conv2D(128, 3, activation='relu', input_shape=getImgTensor(img_dim)),\n                             k.layers.MaxPooling2D(2),\n\n                             k.layers.Conv2D(128, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n\n                             k.layers.Conv2D(128, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n    \n                             k.layers.Conv2D(256, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n\n                             k.layers.Conv2D(256, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.4),\n\n                             k.layers.Conv2D(256, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n    \n                             k.layers.Flatten(),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(128, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(64, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_7.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_7 = trainModel(model_7, 50, 'adam', modelName='custom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotModelHistory(history_7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mobile net\nimg_dim=224\nevaluateModel('./mobilenet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resnet152\nimg_dim=224\nevaluateModel('./resnet152_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inceptionv3\nimg_dim=224\nevaluateModel('./inceptionv3_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nasnet\nimg_dim=331\nevaluateModel('./nasnet_large_model.hdf5')\n# evaluateModel(model_4, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inceptionresnet\nimg_dim=224\nevaluateModel('./inceptionresnet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# densenet169\nimg_dim=224\nevaluateModel('./densenet169_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom\nimg_dim=224\nevaluateModel('./custom_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mobile net\nimg_dim=224\npredictModel('./mobilenet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resnet152\nimg_dim=224\npredictModel('./resnet152_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inceptionv3\nimg_dim=224\npredictModel('./inceptionv3_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nasnet\nimg_dim=331\npredictModel('./nasnet_large_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inceptionresnet\nimg_dim=224\npredictModel('./inceptionresnet_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# densenet169\nimg_dim=224\npredictModel('./densenet169_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom\nimg_dim=224\npredictModel('./custom_model.hdf5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}