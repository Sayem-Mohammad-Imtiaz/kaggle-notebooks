{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"6\"> (BikeShare_Toronto_Ridership_Data_2017-2020.)</font>\n\n [BikeShare Toronto Ridership Data 2017-2020](https://www.kaggle.com/jasonzxho/bikeshare-toronto-ridership-data-20172020)\n \n<font size=\"6\"> by (Peter Gamal Girgis)</font>\n\n<span style=\"color:orange\"><font size=\"4\"> **Task Details:** </font></span>\n\n><font size=\"5\"> About the Dataset</font>\n>\n>The following dataset contain bike trips taken during the year 2017-2020 across more than 600 stations across the City of Toronto. The CSVs for 2017 and 2018 contains 9 features. The description of each feature is listed below:\n>\n>>    `trip_id`: Unique ID code for individual trip taken.\n>>\n>>    `trip_start_time`: Trip start time.\n>>\n>>    `trip_end_time`: Trip end time.\n>>\n>>    `trip_duration_seconds`: Duration of the trip in seconds.\n>>\n>>    `from_station_id`: Unique ID code for the start station.\n>>\n>>    `from_station_name`: Name of start station.\n>>\n>>    `to_station_id`: Unique ID code for the end station.\n>>\n>>    `to_station_name`: Name of end station.\n>>\n>>    `user_type`: Type of user, either Member or Casual.\n>>\n>\n> The CSVs for 2019 and 2020 contains 11 features. The description of each feature is listed below:\n>\n>>    `Trip Id`: Unique ID code for individual trip taken.\n>>    Subscription Id: Unique ID code for the individual member, this can be used to track Annual Member usage.\n>>\n>>    `Trip Duration`: Duration of the trip in seconds.\n>>\n>>    `Start Station Id`: Unique ID code for the start station.\n>>\n>>    `Start Time`: Trip start time.\n>>\n>>    `Start Station Name`: Name of start station.\n>>\n>>    `End Station Id`: Unique ID code for the end station.\n>>\n>>    `End Time`: Trip end time.\n>>\n>>    `End Station Name`: Name of end station.\n>>\n>>   `Bike Id`: Unique ID for the individual bike used.\n>> \n>>   `User Type`: Type of user, either Annual or Casual.\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import all Requiring Libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport requests\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom datetime import timedelta\n\n# Combining several CSV files\nfrom glob import glob \n\n# to get web contents\nimport json\nfrom urllib.request import urlopen\n\nimport holidays\n\nimport pycountry\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom collections import namedtuple\n\n# for offline ploting\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# hide warnings\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **1. Year_2017** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using glob function to combine several CSV files with same strucure at 2017 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2017/2017-Q*.csv'))\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using concat to combined all files and assign() methods\nY_2017 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check unique file's names\nY_2017.filename.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modify file path to Y_2017 number.\nY_2017.filename = Y_2017.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2017/', '')\nY_2017.filename = Y_2017.filename.str.replace('.csv', '')\n\nY_2017.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change column \"filename to \"Quarter\"\nY_2017 = Y_2017.rename(columns = {'filename' :'Quarter'})\nY_2017.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe shape\nY_2017.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe info()\nY_2017.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check Dataframe NULL values\nY_2017.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Found \"NULLNULL\" values\nY_2017.query('trip_stop_time == \"NULLNULL\"')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Cancel trip while `trip_duration_seconds` & `trip_stop_time` equal Zero and no distination at `to_station_name` or `to_station_id`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULLNULL Values\nY_2017 = Y_2017[Y_2017['trip_stop_time'] != 'NULLNULL']\nY_2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check \"NULLNULL\" values are droped\nY_2017.query('trip_stop_time == \"NULLNULL\"')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_2017.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Y_17\"\nY_17 = Y_2017[['from_station_id','from_station_name']]\nY_17 = Y_17.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Z_17\"\nZ_17 = Y_2017[['to_station_id','to_station_name']]\nZ_17 = Z_17.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate new Dtaframes \"Y_17 & Z_17\" at new Dtaframe \"X_17\"\nX_17 = pd.concat([Y_17,Z_17])\nX_17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check number of Unique values\nX_17.station_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe duplication\nX_17.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop douplication at X_17\nX_17 = X_17.drop_duplicates()\nX_17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULL Values in column \"station_id\"\nX_17 = X_17[pd.notnull(X_17['station_id'])]\nX_17","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 2 Dataframe \"X_17\" and \"Y_2017\"\nY_2017 = Y_2017.merge(X_17, left_on = 'from_station_name', right_on = 'station_name', how = 'left')\nY_2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"from_station_id\" with data at column \"station_id\"\nY_2017['from_station_id'] = Y_2017.from_station_id.fillna(Y_2017.station_id)\n\n# Drop un-necessary columns\nY_2017 = Y_2017.drop(['station_id','station_name'], axis = 1)\n\n# check Dataframe NULL values\nY_2017.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge 2 Dataframe \"X_17\" and \"Y_2017\"\nY_2017 = Y_2017.merge(X_17, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\nY_2017['to_station_id'] = Y_2017.to_station_id.fillna(Y_2017.station_id)\n\n# Drop un-necessary columns\nY_2017 = Y_2017.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2017.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save \"Y_2017\" dataframe in CSV format at new created folder(gathering_data)\nY_2017.to_csv('/kaggle/working/Y_2017.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **2. Year_2018** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Using glob function to combine several CSV files with same strucure at 2018 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2018/2018-Q*.csv'))\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using concat to combined all files and assign() methods\nY_2018 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2018","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique file's names\nY_2018.filename.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modify file path to Y_2018 number.\nY_2018.filename = Y_2018.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2018/', '')\nY_2018.filename = Y_2018.filename.str.replace('.csv', '')\n\nY_2018.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change column \"filename to \"Quarter\"\nY_2018 = Y_2018.rename(columns = {'filename' :'Quarter'})\nY_2018.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe shape\nY_2018.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe info()\nY_2018.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Y_18\"\nY_18 = Y_2018[['from_station_id','from_station_name']]\nY_18 = Y_18.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Z_18\"\nZ_18 = Y_2018[['to_station_id','to_station_name']]\nZ_18 = Z_18.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate new Dtaframes \"Y_18 & Z_18\" at new Dtaframe \"X_18\"\nX_18 = pd.concat([Y_18,Z_18])\nX_18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check number of Unique values\nX_18.station_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check Dataframe duplication\nX_18.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop douplication at X_18\nX_18 = X_18.drop_duplicates()\nX_18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULL Values\nX_18 = X_18.dropna(axis = 0)\nX_18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_2018.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe duplication\nY_2018.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save \"Y_2018\" dataframe in CSV format at new created folder(gathering_data)\nY_2018.to_csv('/kaggle/working/Y_2018.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **3. Year_2019** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Using glob function to combine several CSV files with same strucure at 2019 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2019/2019-Q*.csv'))\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using concat to combined all files and assign() methods\nY_2019 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2019","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique file's names\nY_2019.filename.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modify file path to Y_2019 number.\nY_2019.filename = Y_2019.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2019/', '')\nY_2019.filename = Y_2019.filename.str.replace('.csv', '')\n\nY_2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change column \"filename to \"Quarter\"\nY_2019 = Y_2019.rename(columns = {'filename' :'Quarter'})\nY_2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe shape\nY_2019.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe info()\nY_2019.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename columns to matching with columns at other years.\nY_2019 = Y_2019.rename(columns = {'Trip Id':'trip_id', 'Trip  Duration':'trip_duration_seconds', 'Start Station Id':'from_station_id',\n                                  'Start Time':'trip_start_time', 'Start Station Name':'from_station_name', 'End Station Id':'to_station_id',\n                                 'End Time':'trip_stop_time', 'End Station Name':'to_station_name', 'User Type': 'user_type'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop un-necessary column\nY_2019 = Y_2019.drop(['Subscription Id','Bike Id'], axis = 1)\nY_2019.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_2019.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Y_19\"\nY_19 = Y_2019[['from_station_id','from_station_name']]\nY_19 = Y_19.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Z_19\"\nZ_19 = Y_2019[['to_station_id','to_station_name']]\nZ_19 = Z_19.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate new Dtaframes \"Y_19 & Z_19\" at new Dtaframe \"X_19\"\nX_19 = pd.concat([Y_19,Z_19])\nX_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check number of Unique values\nX_19.station_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe duplication\nX_19.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop douplication at X_19\nX_19 = X_19.drop_duplicates()\nX_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULL Values related column \"station_name\"\nX_19 = X_19[pd.notnull(X_19['station_name'])]\nX_19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_2019.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 2 Dataframe \"X_19\" and \"Y_2019\"\nY_2019 = Y_2019.merge(X_19, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_2019","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\n# Replace NUll Value in column \"to_station_name\" with data at column \"station_name\"\nY_2019['to_station_id'] = Y_2019.to_station_id.fillna(Y_2019.station_id)\nY_2019['to_station_name'] = Y_2019.to_station_name.fillna(Y_2019.station_name)\n\n# Drop un-necessary column\nY_2019 = Y_2019.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2019.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe duplication\nY_2019.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save \"Y_2019\" dataframe in CSV format at new created folder(gathering_data)\nY_2019.to_csv('/kaggle/working/Y_2019.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **4. Year_2020** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Using glob function to combine several CSV files with same strucure at 2020 \nfiles = sorted (glob('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-*.csv'))\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using concat to combined all files and assign() methods\nY_2020 = pd.concat((pd.read_csv(file).assign(filename = file) for file in files), ignore_index = True)\nY_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check unique file's names\nY_2020.filename.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modify file path to Y_2020 number.\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-01','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-02','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-03','2020-Q1')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-04','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-05','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-06','2020-Q2')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-07','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-08','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-09','2020-Q3')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-10','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-11','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('/kaggle/input/bikeshare-toronto-ridership-data-20172020/Bikeshare 2020/2020-12','2020-Q4')\nY_2020.filename = Y_2020.filename.str.replace('.csv', '')\n\nY_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change column \"filename to \"Quarter\"\nY_2020 = Y_2020.rename(columns = {'filename' :'Quarter'})\nY_2020.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Columns names at DataFrame \"Y_2020\"\nY_2020.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe shape\nY_2020.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe info()\nY_2020.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename columns to matching with columns at other years.\nY_2020 = Y_2020.rename(columns = {'Trip Id':'trip_id', 'Trip  Duration':'trip_duration_seconds', 'Start Station Id':'from_station_id',\n                                  'Start Time':'trip_start_time', 'Start Station Name':'from_station_name', 'End Station Id':'to_station_id',\n                                 'End Time':'trip_stop_time', 'End Station Name':'to_station_name', 'User Type': 'user_type'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe info()\nY_2020.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop un-necessary column\nY_2020 = Y_2020.drop(['Subscription Id','Bike Id', '10293877', '863410', '905', '7038', '11/01/2020 00:00', 'Dundas St W / Yonge St',\n                     '7253', '11/01/2020 00:15', 'John St  / Mercer St - SMART', '2260', 'Casual Member', '10529965', '832983', '304', '7542',\n                     '12/01/2020 00:02', 'Queen St W / John St', '7544', '12/01/2020 00:07', 'Foster Pl / Elizabeth St - SMART', '1182',\n                     'Annual Member'], axis = 1)\nY_2020.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_2020.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULL Values related column \"trip_id\"\nY_2020 = Y_2020[pd.notnull(Y_2020['trip_id'])]\nY_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_2020.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Y_20\"\nY_20 = Y_2020[['from_station_id','from_station_name']]\nY_20 = Y_20.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY_20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Z_20\"\nZ_20 = Y_2020[['to_station_id','to_station_name']]\nZ_20 = Z_20.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ_20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate new Dtaframes \"Y_20 & Z_20\" at new Dtaframe \"X_20\"\nX_20 = pd.concat([Y_20,Z_20])\nX_20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe duplication\nX_20.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop douplication at X_20\nX_20 = X_20.drop_duplicates()\nX_20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULL Values related column \"station_name\"\nX_20 = X_20[pd.notnull(X_20['station_name'])]\nX_20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 2 Dataframe \"X_20\" and \"Y_2020\"\nY_2020 = Y_2020.merge(X_20, left_on = 'from_station_id', right_on = 'station_id', how = 'left')\nY_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"from_station_name\" with data at column \"station_name\"\nY_2020['from_station_name'] = Y_2020.from_station_name.fillna(Y_2020.station_name)\n\n# Drop un-necessary column\nY_2020 = Y_2020.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2020.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 2 Dataframe \"X_20\" and \"Y_2020\"\nY_2020 = Y_2020.merge(X_20, left_on = 'to_station_id', right_on = 'station_id', how = 'left')\nY_2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"to_station_name\" with data at column \"station_name\"\nY_2020['to_station_name'] = Y_2020.to_station_name.fillna(Y_2020.station_name)\n\n# Drop un-necessary column\nY_2020 = Y_2020.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_2020.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check Dataframe duplication\nY_2020.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save \"Y_2020\" dataframe in CSV format at new created folder(gathering_data)\nY_2020.to_csv('/kaggle/working/Y_2020.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **5. Combine All DF's** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Using glob function to combine several CSV files with same strucure at gathering_data\nfiles = sorted (glob('/kaggle/working/Y_20*.csv'))\nfiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using concat to combined all files\nY_All = pd.concat((pd.read_csv(file) for file in files), ignore_index = True)\nY_All","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Y\"\nY = Y_All[['from_station_id','from_station_name']]\nY = Y.rename(columns = {'from_station_id':'station_id','from_station_name':'station_name'})\nY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select certian columns and add it at new DataFrame \"Z\"\nZ = Y_All[['to_station_id','to_station_name']]\nZ = Z.rename(columns = {'to_station_id':'station_id','to_station_name':'station_name'})\nZ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate new Dtaframes \"Y & Z\" at new Dtaframe \"X\"\nX = pd.concat([Y,Z])\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe duplication\nX.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop douplication at X\nX = X.drop_duplicates()\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check NULL values at Column \"station_id\"\nX.query('station_id.isnull()', engine='python')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update the repeated stations with same ID number\n# Update station_id = 7183 for station \"Margueretta St / College St\"\nX['station_id'][465831] = 7183.0\n\n# Update station_id = 7180 for station \"Lansdowne Subway Green P\"\nX['station_id'][465850] = 7180.0\n\n# Update station_id = 7161 for station \"Beverly St / College St\"\nX['station_id'][465532] = 7161.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update station without ID by adding ID for them\n# Station \"Michael Sweet Ave / St. Patrick St\" using station_id = 7080.0\nX['station_id'][465490] = 7080.0\n\n# Station \"Roxton Rd / College St\" using station_id = 7081.0\nX['station_id'][728511] = 7081.0\n\n# Station \"Base Station\" using station_id = 7082.0\nX['station_id'][731204] = 7082.0\n\n# Station \"Lake Shore Blvd W / Ontario Dr(Ontario Place)\" using station_id = 7212.0\nX['station_id'][734637] = 7212.0\n\n# Station \"Dovercourt Rd / Harrison St - SMART\" using station_id = 7213.0\nX['station_id'][797267] = 7213.0\n\n# Station \"Summerhill Ave / MacLennan Ave - SMART\" using station_id = 7214.0\nX['station_id'][800483] = 7214.0\n\n# Station \"Fringe Next Stage - 7219\" using station_id = 7215.0\nX['station_id'][1038094] = 7215.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check above stations name related column\"station_name\"\nX.query('station_name == \"Fringe Next Stage - 7219\" ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check NULL values at Column \"station_id\"\nX.query('station_id.isnull()', engine='python')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have NULL Values at X\nX = X.dropna(axis = 0)\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_All.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 2 Dataframe \"X\" and \"Y_All\"\nY_All = Y_All.merge(X, left_on = 'from_station_name', right_on = 'station_name', how = 'left')\nY_All","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"from_station_id\" with data at column \"station_id\"\nY_All['from_station_id'] = Y_All.from_station_id.fillna(Y_All.station_id)\n\n# Drop un-necessary column\nY_All = Y_All.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_All.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge 2 Dataframe \"X\" and \"Y_All\"\nY_All = Y_All.merge(X, left_on = 'to_station_name', right_on = 'station_name', how = 'left')\nY_All","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace NUll Value in column \"to_station_id\" with data at column \"station_id\"\nY_All['to_station_id'] = Y_All.to_station_id.fillna(Y_All.station_id)\n\n# Drop un-necessary column\nY_All = Y_All.drop(['station_id','station_name'], axis = 1)\n\n# Check Dataframe NULL values\nY_All.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correct data type for \"trip_start_time , trip_stop_time\" to be time stamp\nY_All['trip_start_time']= pd.to_datetime(Y_All.trip_start_time)\nY_All['trip_stop_time'] = pd.to_datetime(Y_All.trip_stop_time)\nY_All.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check total trip time in seconds for all trips and convert it to integer \nY_All['trip_duration_seconds'] = (Y_All.trip_stop_time - Y_All.trip_start_time).dt.total_seconds().astype('int64')\n\n# Check Dataframe info()\nY_All.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check trip_duration_seconds = zero values ( that mean trips are cancelled)\nY_All.query('trip_duration_seconds == 0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop Row's have trip_duration_seconds = zero values \nY_All = Y_All[(Y_All['trip_duration_seconds'] > 0)]\nY_All","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check trip_duration_seconds = zero values are all removed\nY_All.query('trip_duration_seconds == 0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Dataframe NULL values\nY_All.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modify \"Casual\" to \"Casual Member\" at \"user_type\" column\nY_All.user_type = Y_All.user_type.replace('Casual', 'Casual Member')\n\n# Modify \"Member\" to \"Annual Member\" at \"user_type\" column\nY_All.user_type = Y_All.user_type.replace('Member', 'Annual Member')\n\n# Check changes applied\nY_All.user_type.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save \"Y_All\" dataframe in CSV format at new created folder(gathering_data)\nY_All.to_csv('/kaggle/working/Y_All.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **6. Copying DataFrame** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copying the merged DataFrame\ndf_All = Y_All.copy()\ndf_All","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<span style=\"color:orange\"><font size=\"4\"> **7. Exploratory Data Analysis ( Analyzing and Visualization)** </font></span>\n><span style=\"color:orange\"><font size=\"3\"> **Q1:How Many user type at All Period?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot \"user_type\" Analysis\nplt.figure(figsize=[6, 6])\ncolor_base = sns.color_palette()[0]\n\nax = sns.countplot(data = df_All, x = 'user_type', color = color_base, order = df_All.user_type.value_counts().index)\n\nfor i,j in enumerate (df_All.user_type.value_counts()):\n    ax.text(i,100 + df_All.user_type.value_counts()[i], j, weight = \"bold\", size = 13,va='baseline', ha='center')\n    \nplt.yticks([0, 1e6, 2e6, 3e6, 4e6, 5e6, 6e6],['0','1M','2M','3M','4M','5M','6M'])\nplt.xlabel(\"User's Type\", size = 15)\nplt.ylabel(\"Total User's Count\", size = 15)\nplt.title(\"User's Type Distribution\", size = 15, weight = 'bold')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q2:How Many User Type / Quarter in each Year ?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot \"user_type\" Analysis\ndate_quarter = df_All.groupby(df_All.Quarter)['user_type'].count()\n\nax = date_quarter.plot(kind ='line',figsize = (20,10), marker = 'o')       \nplt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], ['2017-Q1', '2017-Q2', '2017-Q3', '2017-Q4','2018-Q1', '2018-Q2', '2018-Q3', '2018-Q4',\n                                                                    '2019-Q1', '2019-Q2', '2019-Q3', '2019-Q4','2020-Q1', '2020-Q2', '2020-Q3', '2020-Q4'])\nplt.yticks([0, 0.2e6, 0.4e6, 0.6e6, 0.8e6, 1.0e6, 1.2e6, 1.4e6, 1.6e6],['0', '200K', '400K', '600K','800K', '1M', '1.2M', '1.4M', '1.6M'])\nplt.xlabel(\"Date(Year-Quarter)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.title(\"User's Type Distribution / Quarter\", weight = 'bold', size = 15)\n\nplt.grid(True)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q3:What's Total Trips per year?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"date_year = df_All.trip_start_time.groupby(df_All.trip_start_time.dt.year).count()\n\nax = date_year.plot(kind ='line',figsize = (6,6), marker = 'o')       \nplt.title('Trips per Years', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Year's)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.xticks([2017.0,2018.0, 2019.0, 2020.0], ['2017', '2018', '2019','2020'])\nplt.yticks([1.6e6, 1.8e6, 2.0e6, 2.2e6, 2.4e6, 2.6e6], ['1.6M', '1.8M', '2M','2.2M', '2.4M', '2.6M'])\nplt.grid(True)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q4:What's the Total Count Trips per Month?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"trips_month = df_All.trip_start_time.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month]).count()\n\nax = trips_month.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Total Count Trips per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([100000, 200000, 300000, 400000, 500000], ['100K', '200K', '300K','400K', '500K'])\nplt.grid(True)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q5: What's the Total Count Trips per Quarter as (Annual / Casual) Member?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot \"user_type\" Analysis\ntrips_quarter = df_All.groupby(['Quarter','user_type'])['trip_id'].count().reset_index()\ntrips_quarter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine 2 colums \"user_type\" & \"trip_start_time\" \nAnnual = pd.DataFrame(trips_quarter.query('user_type == \"Annual Member\"').value_counts()).reset_index()\n# combine 2 colums \"user_type\" & \"trip_start_time\" \nCasual = pd.DataFrame(trips_quarter.query('user_type == \"Casual Member\"').value_counts()).reset_index()\nAnnual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots (1,2,figsize = (20,20))\n\n# figure \"a\" represent number of Annual Member in user type \na = sns.barplot (x = Annual.trip_id, y = Annual.Quarter, ax = ax1 , \n                 linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# figure \"a\" represent number of  Casual Member in user type\nb = sns.barplot (x = Casual.trip_id, y = Casual.Quarter, ax = ax2 , \n                 linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count number of Trips in each Annual Member\nfor i,j in enumerate(Annual.trip_id):\n        ax1.text(.07,i+0.15,j,weight = \"bold\", size = 15)\n\n# create loop to count number of Trips in each Casual Member\nfor k,l in enumerate(Casual.trip_id):\n        ax2.text(.07,k+0.15,l,weight = \"bold\", size = 15)     \n        \na.set_title(\"Total Count Trips / Quarter as Annual Member\" , weight = 'bold', size = 15)\na.set_xlabel('Total Annual Member Count / Quarter', size = 15)\na.set_ylabel(\"Date(Year-Quarter)\", size = 15)\n\n\nb.set_title(\"Total Count Trips / Quarter as Casual Member\" , weight = 'bold', size = 15)\nb.set_xlabel('Total Casual Member Count / Quarter', size = 15)\nb.set_ylabel(\"Date(Year-Quarter)\", size = 15)\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q6: What's the Total Period Trip / Month?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].sum())\n\nax = total_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([1e8, 2e8, 3e8, 4e8, 5e8, 6e8, 7e8, 8e8, 9e8], ['100M', '200M', '300M','400M', '500M', '600M', '700M', '800M', '900M'])\nplt.grid(True)\nplt.legend('')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q7: What's the Min. Period Trip / Month?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"min_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].idxmin())\n\nax = min_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([0, 1e6, 2e6, 3e6, 4e6, 5e6, 6e6, 7e6, 8e6, 9e6], ['0', '1M', '2M', '3M','4M', '5M', '6M', '7M', '8M', '9M'])\nplt.grid(True)\nplt.legend('')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q8: What's the Max. Period Trip / Month?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].idxmax())\n\nax = max_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([1e6, 2e6, 3e6, 4e6, 5e6, 6e6, 7e6, 8e6, 9e6], ['1M', '2M', '3M','4M', '5M', '6M', '7M', '8M', '9M'])\nplt.grid(True)\nplt.legend('')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q9: What's the Average Period Trip / Month?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"average_month_trip = pd.DataFrame(df_All.groupby([df_All.trip_start_time.dt.year, df_All.trip_start_time.dt.month])['trip_duration_seconds'].mean())\n\nax = average_month_trip.plot(kind ='line',figsize = (20,8), marker = 'o')       \nplt.title('Max. Period Trip per Month', weight = 'bold', size = 15)\nplt.xlabel(\"Date(Month-Year)\", size = 15)\nplt.ylabel('Total Trips / Seconds', size = 15)\nplt.xticks([0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47], ['Jan-17', 'Mar-17', 'Jun-17', 'Sep-17', 'Dec-17', 'Mar-18', 'Jun-18', 'Sep-18', 'Dec-18',\n                                                                  'Mar-19', 'Jun-19', 'Sep-19', 'Dec-19', 'Mar-20', 'Jun-20', 'Sep-20', 'Dec-20' ])\nplt.yticks([2e3, 4e3, 6e3, 8e3, 10e3, 12e3, 14e3], ['2K', '4K', '6K','8K', '10K', '12K', '14K'])\nplt.grid(True)\nplt.legend('')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q10: What's the Top 20 Stations at Start Point?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine 2 colums \"from_station_id\" & \"trip_id\" then sort stations desending regarding number of trips results\nmost_Start_id = df_All.groupby('from_station_name')['trip_id'].count().reset_index().sort_values( by = 'trip_id', ascending = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots (1,figsize = (10,12))\n\n# figure \"a\" represent number of player heighest\na = sns.barplot (x = most_Start_id.trip_id, y = most_Start_id.from_station_name[:20], ax = ax1 , linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count players depend on height player.\nfor i,j in enumerate(most_Start_id.trip_id[:20]):\n        ax1.text(.7,i+0.08,j,weight = \"bold\", size = 15)\n\na.set_title(\"Top 20 Stations at start Point Distribution\" , weight = 'bold', size = 15)\na.set_xlabel('Total Count', size = 15)\na.set_ylabel(\"Top Station's Distribution\", size = 15)\nplt.xticks([0, 2e4, 4e4, 6e4, 8e4, 1e5], ['0', '20K', '40K','60K', '80K', '100K'])\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q11: What's the Top 20 Stations at End Point?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine 2 colums \"to_station_name\" & \"trip_id\" then sort stations desending regarding number of trips results\nmost_End_id = df_All.groupby('to_station_name')['trip_id'].count().reset_index().sort_values( by = 'trip_id', ascending = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots (1,figsize = (10,12))\n\n# figure \"a\" represent number of player heighest\na = sns.barplot (x = most_End_id.trip_id, y = most_End_id.to_station_name[:20], ax = ax1 , linewidth = 1 ,alpha = 0.7, palette = 'Blues_r')\n\n# create loop to count players depend on height player.\nfor i,j in enumerate(most_End_id.trip_id[:20]):\n        ax1.text(.7,i+0.08,j,weight = \"bold\", size = 15)\n\na.set_title(\"Top 20 Stations at End Point Distribution\" , weight = 'bold', size = 15)\na.set_xlabel('Total Count', size = 15)\na.set_ylabel(\"Top Station's Distribution\", size = 15)\nplt.xticks([0, 2e4, 4e4, 6e4, 8e4, 1e5], ['0', '20K', '40K','60K', '80K', '100K'])\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q12: What's the Q10: What's Correlation Between Variables?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get correlation in specific columns\ncorrelation = df_All.corr()\nplt.figure(figsize=(8,8))\n\n# create heatmap plot\nsns.heatmap(correlation,annot=True ,cmap = plt.cm.plasma, linecolor='white', linewidths=2)\nplt.title('Correlation Between Variables')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"><span style=\"color:orange\"><font size=\"3\"> **Q13: Using \"worldcloud\" to print Top stations at Start Point?** </font></span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n# get player counts value acheived gameId > 32000 \ntop_rate = most_Start_id[most_Start_id.trip_id  > 30000 ]['from_station_name'].value_counts().index\n\n# using bckground\" WorldCloud\nw_c = WordCloud(background_color=\"white\",scale=2).generate(\" \".join(top_rate))\nfig = plt.figure(figsize=(15,8))\n\n# plot show in \"bilionear style\"\nplt.imshow(w_c,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Top stations at Start Point\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}