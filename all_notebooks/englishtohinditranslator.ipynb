{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/hindienglish-corpora/Hindi_English_Truncated_Corpus.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"source\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[310:320]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pattern=\"[a-zA-Z]\"\nb=[]\nfor i in range(15000):\n    result=re.findall(pattern,data[\"english_sentence\"].iloc[i])\n    if len(result)==0:\n        b.append(i)\n    if len(data[\"english_sentence\"].iloc[i])>100:\n        b.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(15000):\n    result=re.findall(pattern,data[\"hindi_sentence\"].iloc[i])\n    if len(result)!=0:\n        b.append(i)\n    if len(data[\"hindi_sentence\"].iloc[i])>100:\n        b.append(i)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"hindi_sentence\"].iloc[73]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"english_texts=[]\nhindi_texts=[]\nenglish_character=[]\nhindi_character=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(15000):\n    if i not in b:\n        english_texts.append(data[\"english_sentence\"].iloc[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(15000):\n    if i not in b:\n         hindi=\"\\t\"+data[\"hindi_sentence\"].iloc[i]+\"\\n\"\n         hindi_texts.append(hindi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(hindi_texts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in english_texts:\n    for c in i:\n        if c not in english_character:\n            english_character.append(c)\n            english_character.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in hindi_texts:\n    for c in j:\n        if c not in hindi_character:\n            hindi_character.append(c)\n            hindi_character.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"english_d={}\nfor i in range(len(english_character)):\n    english_d[english_character[i]]=i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hindi_d={}\nfor i in range(len(hindi_character)):\n    hindi_d[hindi_character[i]]=i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"english_encoder_tokens = len(english_character)\nhindi_decoder_tokens = len(hindi_character)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_encoder_seq_length=0\nfor i in english_texts:\n    if len(i)>max_encoder_seq_length:\n        max_encoder_seq_length=len(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_decoder_seq_length=0\nfor i in hindi_texts:\n    if len(i)>max_decoder_seq_length:\n        max_decoder_seq_length=len(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_decoder_seq_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_input_data=[]\nfor bb in range(len(english_texts)):\n    a=[]\n    b=[]\n    c=[]\n    k=len(english_texts[bb])\n    m=0\n    while m<k:\n        for char in english_texts[bb][m]:\n                           for i in range(len(english_character)):\n                                            if english_d[char]==i:\n                                                a.append(1)\n                                            else:\n                                                a.append(0)\n       \n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\n    while m<max_encoder_seq_length:\n        for i in range(len(english_character)):\n            if i==0:\n                a.append(1)\n            else:\n                a.append(0)\n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\n    encoder_input_data.append(c)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_input_data=np.array(encoder_input_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_input_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_input_data=[]\nfor bb in range(len(hindi_texts)):\n    a=[]\n    b=[]\n    c=[]\n    k=len(hindi_texts[bb])\n    m=0\n    while m<k:\n        for char in hindi_texts[bb][m]:\n                           for i in range(len(hindi_character)):\n                                            if hindi_d[char]==i:\n                                                a.append(1)\n                                            else:\n                                                a.append(0)\n       \n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\n    while m<max_decoder_seq_length:\n        for i in range(len(hindi_character)):\n            if i==0:\n                a.append(1)\n            else:\n                a.append(0)\n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\n    decoder_input_data.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_input_data=np.array(decoder_input_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_input_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_target_data=[]\nfor bb in range(len(hindi_texts)):\n    a=[]\n    b=[]\n    c=[]\n    k=len(hindi_texts[bb])\n    m=1\n    while m<k:\n        for char in hindi_texts[bb][m]:\n                           for i in range(len(hindi_character)):\n                                            if hindi_d[char]==i:\n                                                a.append(1)\n                                            else:\n                                                a.append(0)\n       \n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\n    m=m-1\n    while m<max_decoder_seq_length:\n        for i in range(len(hindi_character)):\n            if i==0:\n                a.append(1)\n            else:\n                a.append(0)\n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\n    decoder_target_data.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_target_data=np.array(decoder_target_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_target_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64  # Batch size for training.\nepochs = 100 # Number of epochs to train for.\nlatent_dim = 256 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense\nfrom keras.layers import LSTM,Input\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_inputs = Input(shape=(None,len(english_character)))\nencoder = LSTM(latent_dim,dropout=0.2,return_sequences=True,return_state=True)\nencoder_outputs_1, state_h_1, state_c_1 = encoder(encoder_inputs)\nencoder = LSTM(latent_dim,dropout=0.2,return_state=True)\nencoder_outputs, state_h, state_c = encoder(encoder_outputs_1)\nencoder_states = [state_h_1,state_c_1,state_h, state_c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_inputs = Input(shape=(None, len(hindi_character)))\ndecoder_lstm = LSTM(latent_dim,return_sequences=True,dropout=0.2,return_state=True)\ndecoder_outputs_1, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h_1,state_c_1])\ndecoder_lstm_1 = LSTM(latent_dim, return_sequences=True,dropout=0.2,return_state=True)\ndecoder_outputs, _, _ = decoder_lstm_1(decoder_outputs_1, initial_state=[state_h,state_c])\ndecoder_dense = Dense(len(hindi_character), activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\nmodel=Model([encoder_inputs, decoder_inputs], decoder_outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n)\nmodel.fit(\n    [encoder_input_data, decoder_input_data],\n    decoder_target_data,\n    batch_size=batch_size,\n    epochs=epochs,\n    validation_split=0.2,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"engtohindi.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.load_model(\"engtohindi.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_inputs = model.input[0]\nencoder_outputs_1, state_h_enc_1, state_c_enc_1 = model.layers[2].output \nencoder_outputs, state_h_enc, state_c_enc = model.layers[4].output \nencoder_states = [state_h_enc_1, state_c_enc_1,state_h_enc, state_c_enc]\nencoder_model_1 = keras.Model(encoder_inputs, encoder_states)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder_inputs = model.input[1]  \ndecoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\ndecoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\ndecoder_state_input_h1 = Input(shape=(latent_dim,),name=\"input_5\")\ndecoder_state_input_c1 = Input(shape=(latent_dim,),name=\"input_6\")\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c,decoder_state_input_h1,decoder_state_input_c1]\ndecoder_lstm = model.layers[3]\ndec_o, state_h, state_c = decoder_lstm(\n    decoder_inputs, initial_state=decoder_states_inputs[:2])\ndecoder_lstm_1=model.layers[5]\ndec_o_1, state_h1, state_c1 = decoder_lstm_1(\n    dec_o, initial_state=decoder_states_inputs[-2:])\ndecoder_states = [state_h,state_c,state_h1,state_c1]\ndecoder_dense = model.layers[6]\ndecoder_outputs = decoder_dense(dec_o_1)\ndecoder_model = keras.Model(\n    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_input_char_index ={}\nfor i in range(len(english_character)):\n    reverse_input_char_index[i]=english_character[i]\nreverse_target_char_index ={}\nfor i in range(len(hindi_character)):\n    reverse_target_char_index[i]=hindi_character[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_sequence(input_seq):\n    states_value=encoder_model_1.predict(input_seq)\n    target_seq = np.zeros((1, 1, len(hindi_character)))\n    target_seq[0, 0, hindi_d[\"\\t\"]] = 1.0\n    flag=0\n    sent=\"\"\n    while flag==0:\n        output_tokens, h, c,h1,c1 = decoder_model.predict([target_seq] + states_value)\n        sample = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sample]\n        sent+=sampled_char\n        if sampled_char == \"\\n\" or len(sent) > max_decoder_seq_length:\n            flag=1\n        target_seq = np.zeros((1, 1, len(hindi_character)))\n        target_seq[0, 0,sample] = 1.0\n        states_value = [h, c,h1,c1]\n    return sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"english_texts[21]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"english='Can you imagine saying that?'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=len(english)\nm=0\na=[]\nb=[]\nc=[]\ninpu=[]\nwhile m<k:\n    for char in english[m]:\n        for i in range(len(english_character)):\n            if english_d[char]==i:\n                a.append(1)\n            else:\n                a.append(0)\n    for kp in a:\n        b.append(kp)\n    c.append(b)\n    b=[]\n    a=[]\n    m=m+1\nwhile m<max_encoder_seq_length:\n        for i in range(len(english_character)):\n            if i==0:\n                a.append(1)\n            else:\n                a.append(0)\n        for kp in a:\n            b.append(kp)\n        c.append(b)\n        b=[]\n        a=[]\n        m=m+1\ninpu.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inpu=np.array(inpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d=decode_sequence(inpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(d)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}