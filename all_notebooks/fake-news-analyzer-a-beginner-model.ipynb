{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import the usual suspects ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport nltk\nimport os \nimport io \nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Load the datasets ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#load fake news \nfake=pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\n#load true news \ntrue=pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## show some infos ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the head \nfake.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show the head of true news \ntrue.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analaysis ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#add a label column to both datasets \nfake['label']='fake'\ntrue['label']= 'true'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now , lest's concat the two datasets \nnews=pd.concat([true,fake])\nnews.sample(frac = 1) #Shuffle 100%\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.groupby('label').size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# a funstion that converts list to string \ndef listostring(lst):\n    \n        listToString = ' '.join([str(elem) for elem in lst]) \n        \n        return listToString\n    \n# let's define a function that processes the text of news \n  \ndef text_tokenizer(txt):\n    \n    text_blob = TextBlob(txt)\n    text_cleaned= ' '.join(text_blob.words)\n    words=text_cleaned.split(' ')\n\n    text=[]\n    for word in words:\n        if word.lower()  not in stopwords.words('english'):\n            text.append(word)\n     \n    \n    listToString = ' '.join([str(elem) for elem in text]) \n  \n    return listToString","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add another column to dataset contains text preprocessed \nnews['clean_text'] = news['clean_text'].apply(listostring)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(news['clean_text'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create bag of words \nbow_transformer = CountVectorizer(analyzer=text_tokenizer).fit_transform(news['clean_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show the sparce Matrix \nprint('Shape of Sparse Matrix: ', bow_transformer.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create tfidf \ntfidf_transformer= TfidfTransformer()\ntfidf = tfidf_transformer.fit_transform(bow_transformer)\nprint(tfidf.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the model \nrfc= RandomForestClassifier(n_estimators=100)\nrfc.fit(tfidf, news['label'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict\npredictions= rfc.predict(tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show some metrics \nlabel=news['label']\n\nprint(\"Metrics Report \\n :\",classification_report(label, predictions))\nprint('\\n')\nprint('\\n')\nprint(\"Accuracy Score :\",accuracy_score(label, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=news['text']\ny=news['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the pipline ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#now let's try the easy way and build our pipline \n#But this time with RFC classifier \n\npipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_tokenizer)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', RandomForestClassifier(n_estimators=600)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the pipline \npipeline.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict \npreds= pipeline.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print some outcomes \nprint(list(preds)[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Metrics Report \\n :\",classification_report(y_test, preds))\nprint('\\n')\n\nprint('\\n')\nprint(\"Accuracy Score :\",accuracy_score(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submit the results \nsubmission = pd.DataFrame({'news_Id':X_test.index , 'Label':preds})\nsubmission.to_csv('submission.csv', index=False)\nprint(\" Submission  successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}