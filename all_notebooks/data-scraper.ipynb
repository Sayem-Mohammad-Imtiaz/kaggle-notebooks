{"cells":[{"metadata":{"id":"78jxBXzubICN"},"cell_type":"markdown","source":"Connect to Google Drive."},{"metadata":{"id":"EocqWjAhsH1b","outputId":"0098c58e-6915-42fa-ca62-2b908888436d","trusted":false},"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"id":"lv9Td7obbKxN"},"cell_type":"markdown","source":"Install all libraries needed for the **Create Lyrics-Metadata Dataset**. The usage of the downloaded libraries is as follows:\n\n1. `pyphen` - split words into syllables.\n2. `pronouncing` - retrieves the phonetic spelling of words as per the CMU Pronouncing Dictionary.\n3. `langdetect` - detect language of lyrics.\n4. `musicbraings` - originally intended for retrieving song length, but the API malfunctioned at the time. `nested-lookup` was needed to search for the `length` key in the JSON response.\n5. `spotipy` - call the Spotify API to retrieve song metadata.\n"},{"metadata":{"id":"q5VV17WXFvdZ","trusted":false},"cell_type":"code","source":"!pip install pyphen\n!pip install pronouncing\n!pip install langdetect\n!pip install musicbrainzngs\n!pip install nested-lookup\n!pip install spotipy","execution_count":null,"outputs":[]},{"metadata":{"id":"kc5QplWnsGLu","trusted":false},"cell_type":"code","source":"import os, glob, requests, uuid, json, re, random, itertools, math\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n% matplotlib inline\nimport seaborn as sns\n\nimport pyphen\nimport musicbrainzngs as mb\nfrom nested_lookup import nested_lookup\nfrom langdetect import detect\nmb.set_useragent('app', 1)\nimport spotipy as spotify\nfrom spotipy.oauth2 import SpotifyClientCredentials\nspotify = spotify.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id='your client id', \n                                                                              client_secret='your client secret'))","execution_count":null,"outputs":[]},{"metadata":{"id":"5C0QFendmdg8"},"cell_type":"markdown","source":"# Processing"},{"metadata":{"id":"D1hkRC36mMxC"},"cell_type":"markdown","source":"## Load Original Data"},{"metadata":{"id":"VdobEP1YtZgi","trusted":false},"cell_type":"code","source":"df_train = pd.read_csv(\"/content/drive/My Drive/Lyrics-Genre-Train.csv\", \n                       delimiter=',')\ndf_test = pd.read_csv(\"/content/drive/My Drive/Lyrics-Genre-Test-GroundTruth.csv\", \n                      delimiter=',')\n\ndf_train.drop(['Song year', 'Track_id'], axis=1, inplace=True)\ndf_test.drop(['Song year', 'Track_id', 'Song', 'Artist'], axis=1, inplace=True)\n\ndf_train['Lyrics'] = df_train['Lyrics'].astype(str)\ndf_test['Lyrics'] = df_test['Lyrics'].astype(str)\n\ndf_train['Lyrics'] = df_train['Lyrics'].map(lambda x: ' '.join(x.split('\\n')))\ndf_test['Lyrics'] = df_test['Lyrics'].map(lambda x: ' '.join(x.split('\\n')))\n\ndf_train['Song'] = df_train['Song'].map(lambda x: ' '.join(x.split('-')))\ndf_train['Artist'] = df_train['Artist'].map(lambda x: ' '.join(x.split('-')))\n\nprint(df_train.shape, df_test.shape)\n\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(pd.DataFrame(data=[df_train['Genre'].value_counts(), \n                             df_test['Genre'].value_counts()],\n                    columns=['Rock', 'Pop', 'Hip-Hop', 'Country', 'Metal', \n                             'Jazz', 'Electronic', 'R&B', 'Indie', 'Folk'], \n                    index=['Train Data Distribution', 'Test Data Distribution']))","execution_count":null,"outputs":[]},{"metadata":{"id":"U2goyeVFmKQy"},"cell_type":"markdown","source":"## Enrich Data\n\nWe used several kaggle lyrics datasets in order to augment our original dataset. The datasets in question are [150K Lyrics Labeled with Spotify Valence](https://www.kaggle.com/edenbd/150k-lyrics-labeled-with-spotify-valence), [dataset lyrics musics](https://www.kaggle.com/italomarcelo/dataset-lyrics-musics) and [AZLyrics song lyrics](https://www.kaggle.com/albertsuarez/azlyrics). Another dataset which would've been interesting to integrate into the project is [Million Song Dataset](https://www.kaggle.com/c/msdchallenge/data), but I figured I wouldn't physically have the time to restructure, label and merge this dataset with the original data and the two previously mentioned datasets.\n\nThe kaggle datasets, however, do not come in an useful format for us. Namely, they don't have a `Genre` column. The reasons why we chose these three datasets is:\n\n1. They each number over 150.000 samples, enough to train BERT model properly.\n2. They contain `Artist` and `Song` features, which will help us filter out duplicates when we merge the 3 datasets. \n\nIn order to deal with the lack of `Genre` labelling, we have built our own labelling function using the `spotipy` library, which uses the **Spotify API** in order to retrieve the genre of an `Artist`.\n\nPlease note that the Spotify API returns a list of genres for one artist, so we consider the most common genre to be said artists dominant genre.\n\nAditionally, the AZLyrics data was badly encoded, namely the column delimiter character, the comma, was also used as a verse delimiter in the `Lyrics` column. Fortunately, the dataset comes with two URL columns that conveniently separate the `Artist`, `Song` and `Lyrics` columns, so with a bit of regex magic we were able to extract the useful data using `https://` as a delimiter.\n\nOn a last note, I used Nakatani Shuyo's [langdetect](https://pypi.org/project/langdetect/) library to automatically label the lyrics with a language.\n\n#### The dataset resulting from merging the original data with the three scraped datasets has over 290.000 unique train samples.\n"},{"metadata":{"id":"QNcvagOojBPF","trusted":false},"cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile('/content/drive/MyDrive/dataset-lyrics-musics.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('/content/')\nwith zipfile.ZipFile('/content/drive/MyDrive/labeled_lyrics_cleaned.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall('/content/')\nwith zipfile.ZipFile('/content/drive/MyDrive/archive.zip', 'r') as zip_ref:\n    zip_ref.extractall('/content/')","execution_count":null,"outputs":[]},{"metadata":{"id":"yX5jwykS9W3R","trusted":false},"cell_type":"code","source":"def determine_genre(row):\n    artist_name = ' '.join(row['Artist'].split('-'))\n    possible_genres = {'Rock': 0, 'Metal': 0, 'Folk': 0, 'Jazz': 0, 'Indie': 0, \n                       'Pop': 0, 'Hip-Hop': 0, 'R&B':0, 'Electronic': 0}\n\n    results = spotify.search(q='artist:' + artist_name, type='artist')\n\n    if len(results['artists']['items']) > 0:\n        genres = [genre.lower() for genre in results['artists']['items'][0]['genres']]\n        for genre in results['artists']['items'][0]['genres']:\n            for key in possible_genres.keys():\n                if key.lower() in genre:\n                    possible_genres[key] += 1\n\n        if all(value == 0 for value in possible_genres.values()):\n            return 'NaN'\n        else:\n            return max(possible_genres, key=possible_genres.get)\n    else:\n        return 'NaN'\n\ndef extract_song(elem):\n    return re.search(',\"(.*)\",', elem)[0][2:-2]\n\ndef extract_lyrics(elem):\n    return re.search('.html\",\"(.*)', elem)[0][8:-1]\n\ndef restructure_azlyrics_data():\n    df3 = pd.DataFrame(columns=[\"Artist\", \"Song\", \"Lyrics\"])\n\n    for name in glob.glob('/content/azlyrics-scraper/*'):\n        df_temp = pd.read_csv(name, delimiter='https://', error_bad_lines=False, quoting=3)\n        artists = [elem[0][1:-3] for elem in df_temp['\"ARTIST_NAME\",\"ARTIST_URL\",\"SONG_NAME\",\"SONG_URL\",\"LYRICS\"'].index.to_numpy()]    \n        songs = [extract_song(elem[1]) for elem in df_temp['\"ARTIST_NAME\",\"ARTIST_URL\",\"SONG_NAME\",\"SONG_URL\",\"LYRICS\"'].index.to_numpy()]\n        lyrics = [extract_lyrics(elem) for elem in df_temp['\"ARTIST_NAME\",\"ARTIST_URL\",\"SONG_NAME\",\"SONG_URL\",\"LYRICS\"'].to_numpy()]\n        lyrics = ['\\n'.join(lyric.split(', ')) for lyric in lyrics]\n        dict_temp = {'Artist': artists, 'Song': songs, 'Lyrics': lyrics}\n        df_temp = pd.DataFrame(dict_temp)\n        df3 = pd.concat([df3, df_temp], axis=0)\n        \n    return df3","execution_count":null,"outputs":[]},{"metadata":{"id":"BAeBS5sDs60F"},"cell_type":"markdown","source":"#### Read and Prepare Data"},{"metadata":{"id":"yz1slExCnERA","outputId":"4e4777eb-713e-4ed1-8f83-a26c4568fc62","trusted":false},"cell_type":"code","source":"df1 = pd.read_csv('/content/dataset-lyrics-musics.csv', header=0, names=['ArtistID', 'Artist', 'Song', 'Lyrics'])\ndf2 = pd.read_csv('/content/labeled_lyrics_cleaned.csv', header=0, names=['ArtistID', 'Artist', 'Lyrics', 'Song', 'Label'])\ndf3 = read_and_restructure_azlyrics_data()\ndf1.drop(['ArtistID'], axis=1, inplace=True)\ndf2.drop(['ArtistID', 'Label'], axis=1, inplace=True)\nprint(df1.shape, df2.shape, df3.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"xEVw5T9wx6ZY","trusted":false},"cell_type":"code","source":"df1['Genre'] = df1.apply(lambda x: determine_genre(x), axis=1)\ndf1.drop(df1[df1['Genre'] == 'NaN'].index, axis=0, inplace=True)\ndf1.to_csv('/content/drive/MyDrive/df1.csv', index=False)\n\ndf2['Genre'] = df2.apply(lambda x: determine_genre(x), axis=1)\ndf2.drop(df1[df1['Genre'] == 'NaN'].index, axis=0, inplace=True)\ndf2.to_csv('/content/drive/MyDrive/df2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"xwwwftHhKBLc","trusted":false},"cell_type":"code","source":"df1 = pd.read_csv('/content/drive/MyDrive/df1.csv', header=0)\ndf2 = pd.read_csv('/content/drive/MyDrive/df2.csv', header=0)\ndf3 = pd.read_csv('/content/drive/MyDrive/df3.csv', header=0)\n\ndf1['Lyrics'] = df1['Lyrics'].astype(str)\ndf1['Song'] = df1['Song'].map(lambda x: x.lower())\ndf1['Artist'] = df1['Artist'].map(lambda x: ' '.join(x.split('-')))\ndf1['Lyrics'] = df1['Lyrics'].map(lambda x: x.replace('. ', '\\n'))\n\ndf2['Lyrics'] = df2['Lyrics'].astype(str)\ndf2['Song'] = df2['Song'].map(lambda x: x.lower())\ndf2['Artist'] = df2['Artist'].map(lambda x: x.lower())\ndf2['Lyrics'] = df2['Lyrics'].map(lambda x: x.replace('\\r', ''))\n\ndf3['Lyrics'] = df3['Lyrics'].astype(str)\ndf3['Song'] = df3['Song'].map(lambda x: x.lower())\ndf3['Artist'] = df3['Artist'].map(lambda x: x.lower())\ndf3['Lyrics'] = df3['Lyrics'].map(lambda x: x.replace('\\r', ''))\n\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(pd.DataFrame(data=[df1['Genre'].value_counts(), \n                             df2['Genre'].value_counts(), \n                             df3['Genre'].value_counts()],\n                    columns=['Rock', 'Pop', 'Hip-Hop', 'Country', 'Metal', \n                             'Jazz', 'Electronic', 'R&B', 'Indie', 'Folk'], \n                    index=['Dataset 1 Distribution', 'Dataset 2 Distribution', 'Dataset 3 Distribution']))","execution_count":null,"outputs":[]},{"metadata":{"id":"KHikSnqbstnH"},"cell_type":"markdown","source":"#### Merge datasets"},{"metadata":{"id":"2bxgr_IHRJAa","trusted":false},"cell_type":"code","source":"df_dict = {'Artist': [], 'Song': [], 'Genre': [], 'Lyrics': []}\n\nfor row in df1.iterrows():\n    if row[1]['Artist'] not in df2['Artist'] and row[1]['Song'] not in df2['Song'] and \\\n        row[1]['Artist'] not in df3['Artist'] and row[1]['Song'] not in df3['Song'] and \\\n        row[1]['Artist'] not in df_train['Artist'] and row[1]['Song'] not in df_train['Song']:\n        df_dict['Genre'].append(row[1]['Genre'])\n        df_dict['Lyrics'].append(row[1]['Lyrics'])\n        df_dict['Artist'].append(row[1]['Artist'])\n        df_dict['Song'].append(row[1]['Song'])\n\nfor row in df2.iterrows():\n    if row[1]['Artist'] not in df1['Artist'] and row[1]['Song'] not in df1['Song'] and \\\n        row[1]['Artist'] not in df2['Artist'] and row[1]['Song'] not in df3['Song'] and \\\n        row[1]['Artist'] not in df_train['Artist'] and row[1]['Song'] not in df_train['Song']:\n        df_dict['Genre'].append(row[1]['Genre'])\n        df_dict['Lyrics'].append(row[1]['Lyrics'])\n        df_dict['Artist'].append(row[1]['Artist'])\n        df_dict['Song'].append(row[1]['Song'])\n\nfor row in df3.iterrows():\n    if row[1]['Artist'] not in df1['Artist'] and row[1]['Song'] not in df1['Song'] and \\\n        row[1]['Artist'] not in df2['Artist'] and row[1]['Song'] not in df2['Song'] and \\\n        row[1]['Artist'] not in df_train['Artist'] and row[1]['Song'] not in df_train['Song']:\n        df_dict['Genre'].append(row[1]['Genre'])\n        df_dict['Lyrics'].append(row[1]['Lyrics'])\n        df_dict['Artist'].append(row[1]['Artist'])\n        df_dict['Song'].append(row[1]['Song'])\n\nfor row in df_train.iterrows():\n    if row[1]['Artist'] not in df1['Artist'] and row[1]['Song'] not in df1['Song'] and \\\n        row[1]['Artist'] not in df2['Artist'] and row[1]['Song'] not in df2['Song'] and \\\n        row[1]['Artist'] not in df2['Artist'] and row[1]['Song'] not in df3['Song']:\n        df_dict['Genre'].append(row[1]['Genre'])\n        df_dict['Lyrics'].append(row[1]['Lyrics'])\n        df_dict['Artist'].append(row[1]['Artist'])\n        df_dict['Song'].append(row[1]['Song'])\n\ndf_train = pd.DataFrame(df_dict)","execution_count":null,"outputs":[]},{"metadata":{"id":"FVkwrDtXsxHf"},"cell_type":"markdown","source":"#### Add Language Feature"},{"metadata":{"id":"IPLo38OXNP2p","trusted":false},"cell_type":"code","source":"def add_language(df):\n    lang = []\n\n    for row in df.iterrows():\n        try:\n            lyrics = ' '.join(row[1]['Lyrics'].lower().split('\\n'))\n            lyrics = re.sub(r'[^\\w\\s]', '', lyrics) \n            lang.append(detect(' '.join(lyrics.split()[:500])))\n        except:\n            lang.append('nan')\n\n    df['Language'] = lang\n\n    return df\n\ndf_train = add_language(df_train)\nnewcols = ['Artist', 'Song', 'Genre', 'Language', 'Lyrics']\ndf_train_new = df_train[newcols]\ndf_train_new.to_csv('/content/drive/MyDrive/train.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"1luAEleFXXLI","trusted":false},"cell_type":"code","source":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(pd.DataFrame(data=[df_train['Genre'].value_counts()],\n                       columns=['Rock', 'Pop', 'Hip-Hop', 'Country', 'Metal', \n                                'Jazz', 'Electronic', 'R&B', 'Indie', 'Folk'], \n                       index=['Train Data Distribution']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}