{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nfrom collections import Counter\nimport keras\nfrom keras.models import Sequential \nfrom keras.layers import Activation, MaxPooling1D, Dropout, Flatten, Reshape, Dense, Conv1D, LSTM,SpatialDropout1D\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom random import randrange\nfrom random import seed\nfrom random import random\nimport pickle\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"      \ndf = pd.read_csv('/kaggle/input/final-opcodes/all_data.csv')\nprint(df.shape)\n\ndef subsample(X, Y, errors, ratio=1.0):\n    sampleX = np.empty((0,0), dtype = np.int8)\n    sampleY = np.empty((0,0), dtype = np.int8)\n    for i in errors:\n        sampleX = np.append(sampleX, X.iloc[i, :].values)\n        sampleY = np.append(sampleY, Y[i])\n    \n    n_sample = round(len(Y) * ratio)\n    while len(sampleY) < n_sample:\n        index = randrange(Y.shape[0])\n        X_row = X.iloc[index, :].values\n        Y_row = Y[index]\n        sampleX = np.append(sampleX, X_row)\n        sampleY = np.append(sampleY, Y_row)\n    arr = [sampleX, sampleY]\n    return arr\n\nmodel = Sequential()\nmodel.add(LSTM(512, dropout=0,  recurrent_dropout=0,go_backwards=True, input_shape=(1000,1)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(21,activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#Getting X and Y Data\nX = df.iloc[:, 34:]\nY = df.iloc[:, 1]\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nY = le.fit_transform(Y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 23)\n\nprint(X_test.shape)\nX_test = tf.reshape(X_test, (X_test.shape[0], 1000, 1))\n\n\n#file = '/kaggle/working/errors0.sav' \n#errors = pickle.load(open(file, 'rb'))\n#type(errors)\n\nacc = []\nvalacc = []\n#file = '/kaggle/working/errors0.sav' \n#errors = pickle.load(open(file, 'rb'))\n\nprint(\"training model\", 1, \"--------------------------\")\nsample = subsample(X_train, y_train, errors, ratio=0.6)\nbaggingSampleX = sample[0].reshape(-1, 1000)\nbaggingSampleY = sample[1]\n\n#print(X_train.shape)\n#print(X_test.shape)\nprint(baggingSampleX.shape)\n\nbaggingSampleX = tf.reshape(baggingSampleX, (baggingSampleX.shape[0], 1000, 1))\n\n#print(baggingSampleX.shape)\n#print(X_test.shape)\n\nhistory = model.fit(baggingSampleX,baggingSampleY, epochs = 150, batch_size = 32, validation_data = (X_test, y_test), shuffle = True)\n\n\naccuracy_logs = history.history[\"accuracy\"]\nval_accuracy_logs = history.history[\"val_accuracy\"]\nacc.append(accuracy_logs)\nvalacc.append(accuracy_logs)\n\nfile_name = \"boosted_cnn_1\" \n\njson = file_name + \".json\"\nh5 = file_name + \".h5\"\n\nmodel_json = model.to_json()\nwith open(json, \"w\") as json_file:\n    json_file.write(model_json)\n    model.save_weights(h5)\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"\ndef predict(row, modelFile): #data is 2d np array\n    jsonFile = modelFile + '.json'\n    json_file = open(jsonFile, 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n\n    loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n    h5File = modelFile + '.h5'\n    loaded_model.load_weights(h5)\n    \n    y_pred = loaded_model.predict_classes(row.reshape(1, 1000))\n    print(y_pred[0])\n    return y_pred[0]\n\ndef checkPred(array):\n    bestScore = -1\n    count = -1\n    best_model = -1\n    for i in range(21):\n        if array[i] > count:\n            count = array[i]\n            best_model = i\n#             bestScore = scores[i]\n#         elif array[i] == count and scores[i] > bestScore: --> USE IF CAN OBTAIN CONFIDENCE LEVEL\n#             best_model = i\n#             bestScore = scores[i]\n    return best_model\n\n#Getting X and Y Data\nX = df.iloc[:, 34:]\nY = df.iloc[:, 1]\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nY = le.fit_transform(Y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 23)\n\nprint(X_test.shape)\nX_train = tf.reshape(X_train, (X_train.shape[0], 1000, 1))\nX_test = tf.reshape(X_test, (X_test.shape[0], 1000, 1))\n\nX_train.shape\nX_test.shape\n\nfor i in range(0,1):\n    file = \"/kaggle/working/boosted_cnn_\"\n    modelFile = file + str(i)\n    jsonFile = modelFile + '.json'\n    json_file = open(jsonFile, 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n\n    loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n    h5File = modelFile + '.h5'\n    loaded_model.load_weights(h5)\n    \n    preds = loaded_model.predict_classes(X_train)\n    print(preds.shape)\n    \n    predFile = \"/kaggle/working/y_pred\" + str(i) + \".sav\"\n    pickle.dump(preds, open(predFile, 'wb'))\n    \nY_pred = np.empty(0, dtype=np.int8)\nfor i in range(7780):\n    predFile = \"/kaggle/working/y_pred\"\n    array = [0] * 21\n    for j in range (0,1):\n        file = predFile + str(j) + \".sav\"\n        y_pred = pickle.load(open(file, 'rb'))\n        array[y_pred[i]] += 1\n    final_Pred = checkPred(array)\n    Y_pred = np.append(Y_pred, final_Pred)\n    print(families[final_Pred])\n    array = [0] * 21\n    \nprint(Y_pred.shape)\n#predBoostFile = \"/kaggle/working/y_pred_boosted0.sav\"\n#pickle.dump(Y_pred, open(predBoostFile, 'wb'))\n\nfrom sklearn.metrics import accuracy_score\nprint(\"-------------------------\")\n\nprint(accuracy_score(y_train, Y_pred))\n\nerror = [np.empty((0,0), dtype = np.int8)] * 21\nfor i in range(7284):\n    if(y_train[i] != Y_pred[i]):\n        error = np.append(error, i)\n        \nerrorFile = \"/kaggle/working/errors0.sav\"\npickle.dump(error, open(errorFile, 'wb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}