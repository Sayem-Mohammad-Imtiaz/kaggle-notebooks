{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n#### Phishing is a method of trying to gather personal information like login credentials or credit card information using deceptive e-mails or  websites.\n\n#### Phishing websites are created to dupe unsuspecting users into thinking they are on a legitimate site. The criminals will spend a lot of time making the site seem as credible as possible and many sites will appear almost indistinguishable from the real thing"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing some useful libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns  \nimport time \n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom nltk.tokenize import RegexpTokenizer  \nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer  \nfrom sklearn.pipeline import make_pipeline\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport pickle ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the dataset\ndf= pd.read_csv(\"../input/phishing-site-urls/phishing_site_urls.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### About data\n#### It consist 549346 rows and 2 columns .The first column consist of links of website and the second column states whether the site is good or bad(phishing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Label\",data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PREPROCESSING"},{"metadata":{},"cell_type":"markdown","source":"#### Now we can Vectoize the URLs.We can gather words from the URLs using Tokenizer\n### RegexpTokenizer\n#### we are able to extract the tokens from string by using regular expression with RegexpTokenizer() method."},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = RegexpTokenizer(r'[A-Za-z]+')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.tokenize(df.URL[0]) # this will fetch all the words from the first URL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tokenizing all the rows \nprint('Getting words tokenized ...')\nt0= time.perf_counter()\ndf['text_tokenized'] = df.URL.map(lambda t: tokenizer.tokenize(t))\nt1 = time.perf_counter() - t0\nprint('Time taken',t1 ,'sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SnowballStemmer\n#### Snowball is a small string processing language that gives the root words"},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = SnowballStemmer(\"english\") # choose a language","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting all the stemmed words\nprint('Getting words stemmed ...')\nt0= time.perf_counter()\ndf['text_stemmed'] = df['text_tokenized'].map(lambda l: [stemmer.stem(word) for word in l])\nt1= time.perf_counter() - t0\nprint('Time taken',t1 ,'sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining all the stemmmed words.\nprint('Get joiningwords ...')\nt0= time.perf_counter()\ndf['text_sent'] = df['text_stemmed'].map(lambda l: ' '.join(l))\nt1= time.perf_counter() - t0\nprint('Time taken',t1 ,'sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_sites = df[df.Label == 'bad']\ngood_sites = df[df.Label == 'good']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_sites.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"good_sites.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Creating Model\n### CountVectorizer- Convert a collection of text documents to a matrix of token counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature = cv.fit_transform(df.text_sent) #transform all text which we tokenize and stemed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature[:5].toarray() # convert sparse matrix into array to print transformed features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, testX, trainY, testY = train_test_split(feature, df.Label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LogisticRegression\n#### Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.score(testX,testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression provide 96% accuracy,Now we will store the score in the dictionary so that we can find which model performs the best.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Scores_ml = {}\nScores_ml['Logistic Regression'] = np.round(lr.score(testX,testY),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating confusing matrix\nprint('Training Accuracy :',lr.score(trainX,trainY))\nprint('Testing Accuracy :',lr.score(testX,testY))\ncon_mat = pd.DataFrame(confusion_matrix(lr.predict(testX), testY),\n            columns = ['Predicted:Bad', 'Predicted:Good'],\n            index = ['Actual:Bad', 'Actual:Good'])\n\n\nprint('\\nCLASSIFICATION REPORT\\n')\nprint(classification_report(lr.predict(testX), testY,\n                            target_names =['Bad','Good']))\n\nprint('\\nCONFUSION MATRIX')\nplt.figure(figsize= (6,4))\nsns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MultinomialNB\n#### The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create mnb object\nmnb = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb.score(testX,testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### MultinomialNB provide 95% accuracy,so we can store the score in the dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"Scores_ml['MultinomialNB'] = np.round(mnb.score(testX,testY),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy :',mnb.score(trainX,trainY))\nprint('Testing Accuracy :',mnb.score(testX,testY))\ncon_mat = pd.DataFrame(confusion_matrix(mnb.predict(testX), testY),\n            columns = ['Predicted:Bad', 'Predicted:Good'],\n            index = ['Actual:Bad', 'Actual:Good'])\n\n\nprint('\\nCLASSIFICATION REPORT\\n')\nprint(classification_report(mnb.predict(testX), testY,\n                            target_names =['Bad','Good']))\n\nprint('\\nCONFUSION MATRIX')\nplt.figure(figsize= (6,4))\nsns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets compare the two models and find out which one is best.\nacc = pd.DataFrame.from_dict(Scores_ml,orient = 'index',columns=['Accuracy'])\nsns.set_style('darkgrid')\nsns.barplot(acc.index,acc.Accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So, Logistic Regression is the best fit model, Now lets make sklearn pipeline using Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ls = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words='english'), LogisticRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, testX, trainY, testY = train_test_split(df.URL, df.Label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ls.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ls.score(testX,testY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy :',pipeline_ls.score(trainX,trainY))\nprint('Testing Accuracy :',pipeline_ls.score(testX,testY))\ncon_mat = pd.DataFrame(confusion_matrix(pipeline_ls.predict(testX), testY),\n            columns = ['Predicted:Bad', 'Predicted:Good'],\n            index = ['Actual:Bad', 'Actual:Good'])\n\n\nprint('\\nCLASSIFICATION REPORT\\n')\nprint(classification_report(pipeline_ls.predict(testX), testY,\n                            target_names =['Bad','Good']))\n\nprint('\\nCONFUSION MATRIX')\nplt.figure(figsize= (6,4))\nsns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets dump the model in pickle."},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(pipeline_ls,open('phishing.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loaded_model = pickle.load(open('phishing.pkl', 'rb'))\nresult = loaded_model.score(testX,testY)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Thats it. Now the pkl file is deployed into Heroku and can be used to create an app.\n#### If you like the Notebook , do upvote."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}