{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandarallel python-chess","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-03T16:39:43.846393Z","iopub.execute_input":"2021-06-03T16:39:43.847163Z","iopub.status.idle":"2021-06-03T16:39:55.037217Z","shell.execute_reply.started":"2021-06-03T16:39:43.847039Z","shell.execute_reply":"2021-06-03T16:39:55.036067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport matplotlib.pyplot as plt\nimport random\nfrom tqdm import tqdm\nfrom pandarallel import pandarallel\nfrom multiprocessing import  Pool\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nimport chess\n\nrandom.seed(420)\nnp.random.seed(420)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-03T16:40:00.509768Z","iopub.execute_input":"2021-06-03T16:40:00.510349Z","iopub.status.idle":"2021-06-03T16:40:01.664135Z","shell.execute_reply.started":"2021-06-03T16:40:00.510293Z","shell.execute_reply":"2021-06-03T16:40:01.663145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\npandarallel.initialize(progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:40:04.451428Z","iopub.execute_input":"2021-06-03T16:40:04.451945Z","iopub.status.idle":"2021-06-03T16:40:04.458038Z","shell.execute_reply.started":"2021-06-03T16:40:04.451914Z","shell.execute_reply":"2021-06-03T16:40:04.457083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/chess-evaluations/chessData.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:40:07.097966Z","iopub.execute_input":"2021-06-03T16:40:07.098372Z","iopub.status.idle":"2021-06-03T16:40:32.671924Z","shell.execute_reply.started":"2021-06-03T16:40:07.098334Z","shell.execute_reply":"2021-06-03T16:40:32.670798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate computed features of\n* Pieces on the board\n* Evaluation in pawns\n* Material advantage using accepted valuations of pieces\n* Cutoff material advantage - material advantage capped to 2 pawns\n* Win Lose Draw - put position into categories:\n  0. Black is absurdly winning\n  1. Black is convincingly winning\n  2. Drawish\n  3. White is convincingly winning\n  4. White is absurdly winning\n* Normalized Evaluation - arctan(evaluation in pawns / 3)\n* Normalized WLD - divide into three groups stratified by normalized evaluation\n  \nUsing material advantages however may be misleading since if a piece was just taken, the material advantage found by counting pieces and their values will yield a result that could be anywhere from 1 to 9 pawns off. This can introduce a lot of noise and detracts away from those positions where there truly is a material advantage.","metadata":{}},{"cell_type":"code","source":"values = {\n    \"P\": 1,\n    \"R\": 5,\n    \"B\": 3,\n    \"N\": 3,\n    \"K\": 0, # 0 since both sides have one king\n    \"Q\": 9\n}\nfor k, v in list(values.items()):\n    values[k.lower()] = -v\n\ndef material_advantage(fen, pat=re.compile(r\"[a-zA-Z]\"), val=values):\n    return sum(map(val.get, re.findall(pat, fen.split(' ')[0])))\n\ndef material_advantage_with_cutoff(fen):\n    return min(2, max(-2, material_advantage(fen)))\n\ndef clamp(bot, top):\n    return lambda num: min(top, max(bot, num))\n\ndef win_lose_draw(evaluation):\n    if evaluation < -10:\n        return 0\n    if evaluation < -1.5:\n        return 1\n    if evaluation < 1.5:\n        return 2\n    if evaluation < 10:\n        return 3\n    return 4\n\ndef tan_eval_categories(evaluation):\n    if evaluation < -.5:\n        return 0\n    if evaluation > .5:\n        return 1\n    return 2\n\ndef eval_to_int(evaluation):\n    try:\n        res = int(evaluation)\n    except ValueError:\n        res = 10000 if evaluation[1] == '+' else -10000\n    return res / 100\n\ncount_pieces = lambda fen, pat=re.compile(r\"[a-zA-Z]\"): len(re.findall(pat, fen.split(' ')[0]))\ntransform_eval = lambda x: np.arctan(x / 3)\nuntransform_eval = lambda x: 3 * np.tan(x)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-03T16:40:39.097305Z","iopub.execute_input":"2021-06-03T16:40:39.097689Z","iopub.status.idle":"2021-06-03T16:40:39.110849Z","shell.execute_reply.started":"2021-06-03T16:40:39.097656Z","shell.execute_reply":"2021-06-03T16:40:39.109548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Don't generate unneeded fields to speed up execution\ndf[\"Pieces\"] = df[\"FEN\"].parallel_map(count_pieces)\ndf[\"Evaluation\"] = df[\"Evaluation\"].parallel_map(eval_to_int)\ndf[\"Normalized Evaluation\"] = transform_eval(df[\"Evaluation\"])\n# df[\"Material advantage\"] = df[\"FEN\"].parallel_map(material_advantage)\n# df[\"Cutoff Material advantage\"] = df[\"Material advantage\"].parallel_map(clamp(-2, 2))\n# df[\"Win Lose Draw\"] = df[\"Evaluation\"].parallel_map(win_lose_draw)\ndf[\"Normalized WLD\"] = df[\"Normalized Evaluation\"].parallel_map(tan_eval_categories)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-03T16:42:33.128251Z","iopub.execute_input":"2021-06-03T16:42:33.128847Z","iopub.status.idle":"2021-06-03T16:43:30.634934Z","shell.execute_reply.started":"2021-06-03T16:42:33.128811Z","shell.execute_reply":"2021-06-03T16:43:30.633805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a stratified sample based on pieces on the board and the category of the evaluation","metadata":{}},{"cell_type":"code","source":"bdf = df[df[\"Pieces\"] >= 5].groupby(\"Pieces\").apply(lambda x: x.sample(n=80000)).reset_index(drop=True)\nbbdf = bdf.groupby(\"Normalized WLD\").apply(lambda x: x.sample(n=400000)).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:43:52.871935Z","iopub.execute_input":"2021-06-03T16:43:52.872331Z","iopub.status.idle":"2021-06-03T16:44:01.017185Z","shell.execute_reply.started":"2021-06-03T16:43:52.872294Z","shell.execute_reply":"2021-06-03T16:44:01.016129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The normalized evaluations are somewhat uniformly distributed.","metadata":{}},{"cell_type":"code","source":"plt.hist(bbdf[\"Normalized Evaluation\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:44:08.127246Z","iopub.execute_input":"2021-06-03T16:44:08.127644Z","iopub.status.idle":"2021-06-03T16:44:08.359316Z","shell.execute_reply.started":"2021-06-03T16:44:08.127604Z","shell.execute_reply":"2021-06-03T16:44:08.358522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# r1bqk2r/pp2ppbp/2np1np1/8/4P3/2N3P1/PPP1NPBP/R1BQK2R b KQkq - 4 8\ndef to_bitboard(fen):\n    boards = np.zeros((29, 8, 8), dtype=np.uint8)\n    board = chess.Board(fen)\n\n    piece_to_layer = {\n        'R': 1,\n        'N': 2,\n        'B': 3,\n        'Q': 4,\n        'K': 5,\n        'P': 6,\n        'p': 7,\n        'k': 8,\n        'q': 9,\n        'b': 10,\n        'n': 11,\n        'r': 12\n    }\n\n    piece_to_material = {\n        'R': 5,\n        'N': 3,\n        'B': 3,\n        'Q': 9,\n        'K': 0,\n        'P': 1,\n        'p': -1,\n        'k': 0,\n        'q': -9,\n        'b': -3,\n        'n': -3,\n        'r': -5\n    }\n\n    color = bool(board.turn)\n\n    cr = board.castling_rights\n    wkcastle = bool(cr & chess.H1)\n    wqcastle = bool(cr & chess.A1)\n    bkcastle = bool(cr & chess.H8)\n    bqcastle = bool(cr & chess.A8)\n\n    boards[0, :, :]  = color\n    boards[25, :, :] = wkcastle\n    boards[26, :, :] = wqcastle\n    boards[27, :, :] = bkcastle\n    boards[28, :, :] = bqcastle\n\n    material = 0\n\n    piece_map = board.piece_map()\n    for i, p in piece_map.items():\n        rank, file = to_square(i)\n        piece = p.symbol()\n        # Mark the position of the piece on the bitboard\n        boards[piece_to_layer[piece], rank, file] = 1\n        material += piece_to_material[piece]\n        # Attack maps\n        for sq in board.attacks(i):\n            attack_rank, attack_file = to_square(sq)\n            boards[piece_to_layer[piece]+12, attack_rank, attack_file] = 1\n\n    return boards\n\ndef to_square(number):\n    rank, file = divmod(number, 8)\n    return 7 - rank, file","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:44:23.09118Z","iopub.execute_input":"2021-06-03T16:44:23.09155Z","iopub.status.idle":"2021-06-03T16:44:23.105516Z","shell.execute_reply.started":"2021-06-03T16:44:23.091519Z","shell.execute_reply":"2021-06-03T16:44:23.10432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = len(bbdf)\nbbdf = bbdf.sample(frac=1)\ntrain_df, test_df, cv_df = bbdf[:int(.8 * l)], bbdf[int(.8 * l): int(.9 * l)], bbdf[int(.9 * l):]","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:44:50.490316Z","iopub.execute_input":"2021-06-03T16:44:50.490719Z","iopub.status.idle":"2021-06-03T16:44:50.945254Z","shell.execute_reply.started":"2021-06-03T16:44:50.490676Z","shell.execute_reply":"2021-06-03T16:44:50.944184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:44:52.719048Z","iopub.execute_input":"2021-06-03T16:44:52.71944Z","iopub.status.idle":"2021-06-03T16:44:52.845653Z","shell.execute_reply.started":"2021-06-03T16:44:52.719401Z","shell.execute_reply":"2021-06-03T16:44:52.844558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ChessDataset(Dataset):\n    def __init__(self, df):\n        self.fens = torch.from_numpy(np.array([*map(to_bitboard, df[\"FEN\"])], dtype=np.uint8))\n        self.evals = torch.Tensor([[x] for x in df[\"Normalized Evaluation\"]])\n        self._len = len(self.evals)\n        \n    def __len__(self):\n        return self._len\n    \n    def __getitem__(self, index):\n        return self.fens[index], self.evals[index]\n\nd_train, d_test, d_cv = map(ChessDataset, [train_df, test_df, cv_df])","metadata":{"execution":{"iopub.status.busy":"2021-06-03T16:45:19.814197Z","iopub.execute_input":"2021-06-03T16:45:19.814569Z","iopub.status.idle":"2021-06-03T16:52:19.652407Z","shell.execute_reply.started":"2021-06-03T16:45:19.814536Z","shell.execute_reply":"2021-06-03T16:52:19.651346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Beeg model\n# model = nn.Sequential(\n#     nn.Conv2d(in_channels = 25, out_channels=200, kernel_size=5, padding=2),\n#     nn.ReLU(),\n#     nn.AvgPool2d(2, stride=(2, 2)),\n#     nn.BatchNorm2d(200),\n#     nn.Conv2d(200, 400, kernel_size=3, padding=1),\n#     nn.Flatten(),\n#     nn.Dropout(.1),\n#     nn.Linear(6400, 100),\n#     nn.Dropout(.6),\n#     nn.Tanh(),\n#     nn.Linear(100, 1)\n# ).to(device)\n\n# Architecture partially yoinked from geohotz\nmodel = nn.Sequential(\n    nn.Conv2d(29, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 32, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(32),\n    nn.Conv2d(32, 64, kernel_size=3, stride=2),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(64),\n    nn.Conv2d(64, 128, kernel_size=3, stride=2),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 128, kernel_size=2, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 128, kernel_size=2, padding=1),\n    nn.ReLU(),\n    nn.BatchNorm2d(128),\n    nn.Conv2d(128, 256, kernel_size=2, stride=2),\n    nn.Flatten(),\n    nn.Dropout(.5),\n    nn.Linear(256, 1)\n).to(device)\n\ndef init_weights(m):\n    try:\n        nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)\n    except Exception:\n        return\n\nmodel.apply(init_weights)\n    \n# model(next(iter(cv_loader))[0].float())","metadata":{"execution":{"iopub.status.busy":"2021-06-03T17:02:02.09681Z","iopub.execute_input":"2021-06-03T17:02:02.097344Z","iopub.status.idle":"2021-06-03T17:02:02.130635Z","shell.execute_reply.started":"2021-06-03T17:02:02.097309Z","shell.execute_reply":"2021-06-03T17:02:02.129626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_loader = DataLoader(dataset=d_cv, batch_size=512, shuffle=False, num_workers=1)\ntrain_loader = DataLoader(dataset=d_train, batch_size=512, shuffle=True, num_workers=1)\ncriterion = nn.MSELoss()\noptimizer = optim.AdamW(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-06-03T17:02:05.665285Z","iopub.execute_input":"2021-06-03T17:02:05.66566Z","iopub.status.idle":"2021-06-03T17:02:05.671373Z","shell.execute_reply.started":"2021-06-03T17:02:05.665627Z","shell.execute_reply":"2021-06-03T17:02:05.670436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\ncv_losses = []\n\nfor epoch in range(40):\n    model.train()\n    running_loss = []\n    for data, target in train_loader:\n        optimizer.zero_grad()\n        data, target = data.to(device), target.to(device)\n        y_pred = model(data.float())\n        loss = criterion(y_pred, target)\n        running_loss.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    train_losses.append(sum(running_loss) / len(running_loss))\n    print(f\"[TRAIN] epoch: {epoch:5}, loss: {train_losses[-1]:10}\", end=\"\\t\")\n    \n    with torch.no_grad():\n        model.eval()\n        running_loss = []\n        for data, target in cv_loader:\n            data, target = data.to(device), target.to(device)\n            y_pred = model(data.float())\n            loss = criterion(y_pred, target)\n            running_loss.append(loss.item())\n        cv_losses.append(sum(running_loss) / len(running_loss))\n        print(f\"[CV] epoch: {epoch:5}, loss: {cv_losses[-1]:10}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T17:02:07.437231Z","iopub.execute_input":"2021-06-03T17:02:07.437636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = np.array(train_losses)\ncv_losses = np.array(cv_losses)\nepochs = np.array([*range(1, len(train_losses) + 1)])\nplt.plot(epochs, train_losses)\nplt.plot(epochs, cv_losses)\nplt.legend([\"Train Loss\", \"CV Loss\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T04:45:33.993459Z","iopub.execute_input":"2021-06-02T04:45:33.993794Z","iopub.status.idle":"2021-06-02T04:45:34.142395Z","shell.execute_reply.started":"2021-06-02T04:45:33.993765Z","shell.execute_reply":"2021-06-02T04:45:34.141201Z"},"trusted":true},"execution_count":null,"outputs":[]}]}