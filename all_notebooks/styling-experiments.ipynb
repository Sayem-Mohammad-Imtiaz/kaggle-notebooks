{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Code Modules & Helpful Functions","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\nimport numpy as np,pandas as pd,pylab as pl\nimport tensorflow_hub as th\nimport tensorflow as tf\nimport tensorflow.keras.backend as tfkb\nfrom IPython.display import display,HTML\nimport cv2,PIL.Image\nfrom IPython.core.magic import register_line_magic\nfrom tqdm import tqdm\nfpath='../input/image-examples-for-mixed-styles/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def load_img(path_to_img):\n    max_dim=512\n    img=tf.io.read_file(path_to_img)\n    img=tf.image.decode_image(img,channels=3)\n    img=tf.image.convert_image_dtype(img,tf.float32)\n    shape=tf.cast(tf.shape(img)[:-1],tf.float32)\n    long_dim=max(shape)\n    scale=max_dim/long_dim\n    new_shape=tf.cast(shape*scale,tf.int32)\n    img=tf.image.resize(img,new_shape)\n    img=img[tf.newaxis,:]\n    return img\ndef tensor_to_image(tensor):\n    tensor=tensor*255\n    tensor=np.array(tensor,dtype=np.uint8)\n    if np.ndim(tensor)>3:\n        assert tensor.shape[0]==1\n        tensor=tensor[0]\n    return PIL.Image.fromarray(tensor)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def preprocess(img):\n    img=img.copy()\n    img=np.expand_dims(img,axis=0) \n    return tf.keras.applications.vgg16\\\n           .preprocess_input(img)\ndef deprocess(img):\n    img=img.copy()[0]                        \n    img[:,:,0]+=103.939\n    img[:,:,1]+=116.779\n    img[:,:,2]+=123.68             \n    img=img[:,:,::-1]              \n    img=np.clip(img,0,255)         \n    return img.astype('uint8') ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def inputs(original_img,style_img):\n    original_img=original_img.astype('float32')\n    style_img=style_img.astype('float32')\n    original_input=tf.constant(preprocess(original_img))\n    style_input=tf.constant(preprocess(style_img))\n    generated_input=tf.compat.v1\\\n    .placeholder(tf.float32,original_input.shape)\n    return original_input,style_input,generated_input\ndef calculate_original_loss(layer_dict,original_layer_names):\n    loss=0\n    for name in original_layer_names:\n        layer=layer_dict[name]\n        original_features=layer.output[0,:,:,:]  \n        generated_features=layer.output[2,:,:,:] \n        loss+=tfkb.sum(tfkb.square(generated_features-original_features))\n    return loss/len(original_layer_names)\ndef gram_matrix(x):    \n    features=tfkb.batch_flatten(tfkb.permute_dimensions(x,(2,0,1))) \n    gram=tfkb.dot(features,tfkb.transpose(features))\n    return gram\ndef get_style_loss(style_features,generated_features,size):\n    S=gram_matrix(style_features)\n    G=gram_matrix(generated_features)\n    channels=3\n    return tfkb.sum(tfkb.square(S-G))/(4.*(channels**2)*(size**2))\ndef calculate_style_loss(layer_dict,style_layer_names,size):\n    loss=0\n    for name in style_layer_names:\n        layer=layer_dict[name]\n        style_features=layer.output[1,:,:,:] \n        generated_features=layer.output[2,:,:,:] \n        loss+=get_style_loss(style_features,generated_features,size) \n    return loss/len(style_layer_names)\ndef calculate_variation_loss(x):\n    row_diff=tfkb.square(x[:,:-1,:-1,:]-x[:,1:,:-1,:])\n    col_diff=tfkb.square(x[:,:-1,:-1,:]-x[:,:-1,1:,:])\n    return tfkb.sum(tfkb.pow(row_diff+col_diff,1.25))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef display_img(s):\n    imgs=[picture01,pattern01]\n    pl.figure(1,figsize=(10,4))\n    pl.subplot(121)\n    pl.imshow(cv2.cvtColor(\n        imgs[0],cv2.COLOR_BGR2RGB))\n    pl.subplot(122)\n    pl.imshow(cv2.cvtColor(\n        imgs[1],cv2.COLOR_BGR2RGB));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hub Modules","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hpath='https://tfhub.dev/google/magenta/'+\\\n      'arbitrary-image-stylization-v1-256/1'\nhub_module=th.load(hpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef hm_run(pars):\n    pars=pars.split()\n    content_image=load_img(fpath+'pattern'+pars[0]+'.png')\n    style_image=load_img(fpath+'pattern'+pars[1]+'.png')\n    imgs=[content_image,style_image]\n    pl.figure(1,figsize=(10,4))\n    pl.subplot(121)\n    pl.imshow(np.squeeze(imgs[0].numpy()))\n    pl.subplot(122)\n    pl.imshow(np.squeeze(imgs[1].numpy()))\n    stylized_image=hub_module(tf.constant(content_image),\n                              tf.constant(style_image))[0]\n    display(tensor_to_image(stylized_image))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%hm_run 10 05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%hm_run 10 06","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VGG16 Transfer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"picture01=cv2.imread(fpath+'pattern10.png')\npattern01=cv2.imread(fpath+'pattern03.png')\npicture01=cv2.resize(picture01,(500,500))\npattern01=cv2.resize(pattern01,(500,500))\npicture01.shape,pattern01.shape,\\\npicture01.dtype,pattern01.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_layers=['block1_conv1','block2_conv1','block3_conv1',\n              'block4_conv1','block5_conv1']\n@register_line_magic\ndef train_run(pars):\n    pars=pars.split()\n    epochs=int(pars[0]); ol=float(pars[1])\n    sl=float(pars[2]); vl=float(pars[3])\n    sh=pattern01.shape[0]*pattern01.shape[1]\n    with tf.Graph().as_default():\n        original_input,style_input,generated_input=\\\n        inputs(picture01,pattern01)\n        input_tensor=tf.concat([original_input,style_input,\n                                generated_input],axis=0)\n        print(input_tensor.shape)\n        vgg16_model=tf.keras.applications.vgg16.\\\n        VGG16(input_tensor=input_tensor,include_top=False)\n        vgg16_layer_dict={layer.name:layer \n                          for layer in vgg16_model.layers}\n        original_loss=\\\n        calculate_original_loss(vgg16_layer_dict,\n                                ['block5_conv2'])\n        style_loss=\\\n        calculate_style_loss(vgg16_layer_dict,style_layers,sh)\n        variation_loss=\\\n        calculate_variation_loss(generated_input)\n        loss=ol*original_loss+sl*style_loss+vl*variation_loss       \n        gradients=tfkb.gradients(loss,generated_input)[0]\n        calculate=tfkb.function([generated_input],\n                                [loss,gradients])\n        generated_data=preprocess(picture01)\n        for i in tqdm(range(epochs)):\n            _,gradients_value=calculate([generated_data])\n            generated_data-=gradients_value*.001\n    generated_image=deprocess(generated_data)\n    pl.figure(1,figsize=(8,8))\n    pl.title(\"loss: %.1f*original_loss+%.1f*style_loss+\"%(ol,sl)+\\\n             \"%.1f*variation_loss => %d steps\"%(vl,epochs))\n    pl.imshow(cv2.cvtColor(generated_image,cv2.COLOR_BGR2RGB));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_img y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%train_run 100 .7 .7 .7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"picture01=cv2.imread(fpath+'pattern10.png')\npattern01=cv2.imread(fpath+'picture03.png')\npicture01=cv2.resize(picture01,(500,500))\npattern01=cv2.resize(pattern01,(500,500))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_img y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%train_run 50 .5 .5 .1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}