{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EN PROCESO"},{"metadata":{},"cell_type":"markdown","source":" **OBJETIVOS**\n 1. Sacar nubes de palabras por personaje (a ser posible con la forma de cada personaje)\n 2. Estudiar qué personaje dice más una palabra específica (jew, fuck, etc.) o frases características (you're breaking my balls, mooom...)\n 3. Análisis de sentimientos por personaje, por temporada\n 4. Comparar vocabulario usado con puntuación en IMDB (¿influye?)\n 5. Analizar cómo varía la participación de personajes de distinta etnia o género a lo largo de la serie\n 6. Ver cómo fluctúa la participación de cada personaje en cada temporada de la serie"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport difflib\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\nimport urllib\nimport requests\nfrom matplotlib import pyplot as plt\nimport imageio\nimport textblob\nimport nltk\nimport twython\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## UTILS\n\nclass color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/southparklines/All-seasons.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ordenamos las líneas de diálogo por la temporada y por el capítulo** \n\n*Antes quitamos las líneas de 'marcaje' (las que separan las temporadas)*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Season'].unique()\ndf = df[df['Season']!='Season']\ndf['Season'] = [int(season) for season in df['Season']]\ndf['Episode'] = [int(episode) for episode in df['Episode']]\ndf = df.sort_values(by=['Season', 'Episode'], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comprobamos distintas hipótesis\n1. ** ¿Las canciones cuentan como diálogo?**"},{"metadata":{},"cell_type":"markdown","source":"Sabemos que el capítulo 7x09 ***Christian Rock Hard*** Cartman tiene un grupo de rock cristiano. ¿Aparecerán las canciones como diálogo?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sing = df[(df['Season']==7) & (df['Episode']==9)]\n\nsing\n\nfor i in range(len(sing[:8])):\n    print(sing.iloc[i,:]['Character'] + ': ' + sing.iloc[i,:]['Line'] + '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"¡Parece que sí cuenta las canciones!"},{"metadata":{},"cell_type":"markdown","source":"2. *¿Se cuentan las frases de Jimmy como diálogo? ¿Starvin' Marvin aparece como personaje? ¿Salen los balbuceos de Timmy? etc.*"},{"metadata":{},"cell_type":"markdown","source":"Vamos a hacer una función que nos de el guion de un capítulo en particular, para poder leerlo y dar respuesta a estas preguntas."},{"metadata":{"trusted":true},"cell_type":"code","source":"## UTILS\n\nclass color:\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\ndef df_read_episode(season, episode, max_number_of_lines=None):\n    df_script = df[(df['Season']==season) & (df['Episode']==episode)]\n    if max_number_of_lines is None: ## Mejorar eficiencia\n        for i in range(len(df_script)):\n            print(color.UNDERLINE + df_script.iloc[i,:]['Character'] + color.END + ': ' + df_script.iloc[i,:]['Line'] + '\\n')\n    else:\n        for i in range(len(df_script[:max_number_of_lines])):\n            print(color.UNDERLINE + df_script.iloc[i,:]['Character'] + color.END + ': ' + df_script.iloc[i,:]['Line'] + '\\n')\n            \n#Capítulo: 'Starvin' Marvin'\ndf_read_episode(season = 1, episode = 8, max_number_of_lines=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **1. Limpiamos la columna de personajes**"},{"metadata":{},"cell_type":"markdown","source":"# 1.1. Personajes grupales\n\nSe consideran como personajes *Boys y Kids*. Entendiendo que se refieren a los cuatro chicos protagonistas, sustituimos cada línea con ese *Character* asociado por cuatro líneas, una para cada uno de los chicos."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(df)):\n    line = df.iloc[i,:]\n    if line['Character'] == 'Boys' or line['Character'] == 'Kids':\n        for character in ['Stan','Kyle','Cartman','Kenny']:\n            line['Character'] = character\n            df = df.append(line, ignore_index=True)\n            \ndf = df[df['Character']!='Boys']        \ndf = df[df['Character']!='Kids']       \ndf = df.sort_values(by=['Season', 'Episode'], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  1.2. Quitamos el carácter '\\n' del final de las líneas\n \n NOTA: Hay varias líneas que tienen '...' como reducción de texto. Parece que no son muchas.. A mejorar en futuro.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## OPTIMIZAR\n\n#for i in range(len(df)):\n#    line = df.iloc[i,:]\n#    line_Line = line['Line']\n#    last_characters = line_Line[-1:]\n#    if last_characters=='\\n':\n#        line['Line'] = line_Line[:-1]\n#        df.iloc[i,:] = line\n       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.3. Varios personajes hablan a la vez \n \nSi hay varios personajes que dicen lo mismo al mismo tiempo, los separa por comas, guiones o por un 'and'. Haremos una línea para cada personaje involucrado.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# POR HACER\n\n# Hay 215 filas, algunas dan problemas\n\ndf_commas = [characters for characters in df['Character'] if (',' in characters or '/' in characters)]\n\ndict_commas_conflictive = {\n    'Celine, Terrance, Bob, Phillip, and people on the field' : 'Celine, Terrance, Bob, Phillip',\n    'Boys 1/2': 'Stan, Kyle, Kenny, Cartman',\n    'Lola, Jenny, Red, and Wendy' : 'Lola, Jenny, Red, Wendy',\n    'Mike, Michael, and Pete': 'Mike, Michael, Pete',\n    'The Boys (except Cartman) and Dr. Phillips' : 'Stan, Kyle, Kenny, Dr. Phillips'\n}\n\ncommas_conflictive = ['You And Me, Girl', 'The New Lyrics, part II', 'Stuart and wife, and Receptionist',\n                     'Sixth Graders 2/3','A singer, Goth Kids (singing)']\n\n\nfor character in commas_conflictive:\n    df = df[df['Character']!=character]\n\nfor i in range(len(df)):\n    line = df.iloc[i,:]\n    character = line['Character']\n    if character in df_commas:\n        if character in dict_commas_conflictive.keys():\n            character = dict_commas_conflictive[character]\n            df.iloc[i,:]['Character'] = character\n        if ',' in character:\n            character = character.split(',')\n        elif '/' in character:\n            character = character.split('/')\n        elif ' and ' in character:\n            character = character.split(' and ')\n            \n        for character_element in character:\n            line['Character'] = character_element\n            df = df.append(line, ignore_index=True)\n\n\ndf_commas_aux = [character for character in df_commas if character not in commas_conflictive]\n            \nfor character_non_valid in df_commas_aux:\n    df = df[df['Character']!=character_non_valid]\n    \ndf = df.sort_values(by=['Season', 'Episode'], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  1.4. Personajes con varios nombres asociados \n\nHay personajes que aparecen con distinto nombre a lo largo de la serie, ya sea por errata, cambio de mayúsculas, minúsculas, puntos, etc. Quitamos todas las versiones posible de cada personaje."},{"metadata":{"trusted":true},"cell_type":"code","source":"#for character in df['Character'].unique():\n#    ratio = difflib.SequenceMatcher(None, 'Cartman', character).ratio()\n#    if ratio>0.6:\n#        print(character + ': ' + str(ratio))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.5. Personajes con menos de diez líneas de diálogo\n# \nIdentificamos los personajes con menos de diez líneas de diálogo, puesto que puede haber cuestiones dentro del análisis para las que no nos interese considerarlos."},{"metadata":{"trusted":true},"cell_type":"code","source":"for character in df['Character'].unique()[:50]:\n    len_character = len(df[df['Character']==character])\n    if len_character <= 10:\n        print(character)\n        \n## Por cuestiones de compilación, el código ahora mismo solo muestran los personajes con menos\n## de diez líneas entre los cincuenta primeros, en orden de aparición. Se cambiará.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Generamos Word Clouds"},{"metadata":{},"cell_type":"markdown","source":"Generamos una nube de palabras con las palabras más dichas por los personajes principales a lo largo de toda la serie"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Line'] = [a.lower() for a in df['Line']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_wordcloud(words, mask, colors):\n    #word_cloud = WordCloud(width = 1600, height = 1600, background_color= None, mode='RGBA',color_func = colors, max_font_size= 400, stopwords=STOPWORDS, mask=mask).generate(words)\n    word_cloud = WordCloud(width = 1600, height = 1600, background_color= None, mode='RGBA',color_func = colors, max_font_size= 400, stopwords=STOPWORDS, mask=mask).generate(words)\n    word_cloud.generate(words)\n\n    plt.figure(figsize = (11, 11))\n    plt.imshow(word_cloud)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_cartman = ''\n\ndf_cartman = df[df['Character']=='Cartman']\n\nfor i in range(len(df_cartman)):\n    line = df_cartman.iloc[i,:]\n    text_cartman += ' ' + line['Line'] + ' '\n    \ntext_cartman = text_cartman.replace('\\n', ' ')\n\n#mask_cartman = np.array(Image.open('../input/pictures/cartman.png'))\nmask_cartman = imageio.imread('../input/pictures/cartman.png', pilmode='RGB')\ncolors_cartman = ImageColorGenerator(mask_cartman)\n\n\n#INFO: https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html\n#RECURSOS IMÁGENES: https://www.freepng.es/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(text_cartman[:100])\n\ngenerate_wordcloud(text_cartman, mask_cartman,colors_cartman) # Arreglar\n\n## HAY QUE MEJORARLO, USAREMOS:  https://www.datacamp.com/community/tutorials/wordcloud-python","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_stan = ''\n\ndf_stan = df[df['Character']=='Stan']\n\nfor i in range(len(df_stan)):\n    line = df_stan.iloc[i,:]\n    text_stan += ' ' + line['Line'] + ' '\n    \ntext_stan = text_stan.replace('\\n', ' ')\n\n#mask_stan = np.array(Image.open('../input/pictures/stan.png'))\nmask_stan = imageio.imread('../input/pictures/stan.png', pilmode='RGB')\ncolors_stan = ImageColorGenerator(mask_stan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(text_stan, mask_stan, colors_stan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_kenny = ''\n\ndf_kenny = df[df['Character']=='Kenny']\n\nfor i in range(len(df_kenny)):\n    line = df_kenny.iloc[i,:]\n    text_kenny += ' ' + line['Line'] + ' '\n    \ntext_kenny = text_kenny.replace('\\n', ' ')\n\nmask_kenny = np.array(Image.open('../input/pictures/kenny.png'))\ncolors_kenny = ImageColorGenerator(mask_kenny)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(text_kenny, mask_kenny, colors_kenny) # Arreglar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Falta limpiar paréntesis\n\ntext_kyle = ''\n\ndf_kyle = df[df['Character']=='Kyle']\n\nfor i in range(len(df_kyle)):\n    line = df_kyle.iloc[i,:]\n    text_kyle += ' ' + line['Line'] + ' '\n    \ntext_kyle = text_kyle.replace('\\n', ' ')\n\nmask_kyle = imageio.imread('../input/pictures/kyle.png', pilmode='RGB')\ncolors_kyle = ImageColorGenerator(mask_kyle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(text_kyle, mask_kyle, colors_kyle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_towelie = ''\n\ndf_towelie = df[df['Character']=='Towelie']\n\nfor i in range(len(df_towelie)):\n    line = df_towelie.iloc[i,:]\n    text_towelie += ' ' + line['Line'] + ' '\n    \ntext_towelie = text_towelie.replace('\\n', ' ')\n\nmask_towelie = np.array(Image.open('../input/pictures/towelie.png'))\ncolors_towelie = ImageColorGenerator(mask_towelie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(text_towelie, mask_towelie, colors_towelie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_butters = ''\n\ndf_butters = df[df['Character']=='Butters']\n\nfor i in range(len(df_butters)):\n    line = df_butters.iloc[i,:]\n    text_butters += ' ' + line['Line'] + ' '\n    \ntext_butters = text_butters.replace('\\n', ' ')\n\nmask_butters = np.array(Image.open('../input/pictures/butters.png'))\ncolors_butters = ImageColorGenerator(mask_butters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(text_butters, mask_butters, colors_butters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Ver qué personajes aparecen en todas las temporadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"allseasons = df['Season'].unique()\ncharacters_in_all_seasons = df['Character'].unique()\n# Ya tenemos todos los personajes y todas las temporadas.\nprint(\"Total number of unique characters: {}\".format(len(characters_in_all_seasons)))\n# Comparamos ahora para cada temporada, dentro de la columna 'Season' del df, aquellos que se encuentren en la lista que hemos creado\n# con los personajes. Estamos buscando caractéres dentro de una lista que hemos creado y que tiene formato string.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for season in allseasons:\n    character = df[df['Season'] == season].Character.unique()\n    characters_in_all_seasons = [name for name in characters_in_all_seasons if name in character]\nprint(\"Number of characters who appear in all 18 seasons: {}\".format(len(characters_in_all_seasons)))\nprint(characters_in_all_seasons)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Análisis de sentimientos"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nvader = SentimentIntensityAnalyzer()\n\n# https://www.nltk.org/api/nltk.sentiment.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Cartman: ' + str(vader.polarity_scores(text_cartman)))\nprint('Kyle: ' + str(vader.polarity_scores(text_kyle)))\nprint('Stan: ' + str(vader.polarity_scores(text_stan)))\nprint('Kenny: ' + ('Polarity:' +str(vader.polarity_scores(text_kenny))+','+'Polarity:' +str(vader.polarity_scores(text_kenny))+','+'Polarity:' +str(vader.polarity_scores(text_kenny)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(TextBlob(text_cartman).sentiment)\nprint(TextBlob(text_kyle).sentiment)\nprint(TextBlob(text_stan).sentiment)\nprint(TextBlob(text_kenny).sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode1 = df[(df['Season']==1) & (df['Episode']==1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_episode1 = ''\n\nfor line in episode1['Line']:\n    text_episode1 += ' ' + line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Episode 1: ' + str(vader.polarity_scores(text_episode1)))\n\nprint('Episode 1: ' + str(TextBlob(text_episode1).sentiment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for line in df['Line']:    \n    words = line.split(' ')\n    for word in words:\n        ratio = difflib.SequenceMatcher(None, 'fuck', word).ratio()\n        if ratio>0.7:\n            print(word + ': ' + str(ratio))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nltk.sentiment.vader import VaderConstants\n\n\n#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n#vader = SentimentIntensityAnalyzer()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}