{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/cdc/national-health-and-nutrition-examination-survey/home\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nprint(\"Input Directory:\")\nos.listdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4539874d6db15b25679cf1a95e6b09dae0deb58a"},"cell_type":"code","source":"\"\"\"\nDiseases of the rich -> Heart disease\nLinked to high cholesteral\nUse demog and habbtis to see who's at risk of high cholesteral\n\nhttps://www.webmd.com/heart-disease/guide/heart-disease-lower-cholesterol-risk#1\nhttps://www.medicalnewstoday.com/articles/315900.php\nhttps://www.who.int/nutrition/topics/2_background/en/\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f79a58bb3e47b023da357af48b2766087bd11c6"},"cell_type":"code","source":"\"\"\"\nJust going to use Demographic, questionnaire (habbits) & cholestoral level to help us answer the question:\n\nCOULD WE IDENTIFY PEOPLE AT RISK OF HIGH CHOLESTEROL LEVELS FROM A SHORT BEHAVIOURAL SURVEY\n\"\"\"\n\ndemog = pd.read_csv(\"../input/national-health-and-nutrition-examination-survey/demographic.csv\")\nques = pd.read_csv(\"../input/national-health-and-nutrition-examination-survey/questionnaire.csv\")\nlabs = pd.read_csv(\"../input/national-health-and-nutrition-examination-survey/labs.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe909354b9fb1a82547e89734a4465b1890fc4a1"},"cell_type":"code","source":"# check to see if there are shared column names in our two tables, before combining\ndemog_cols = demog.columns\nques_cols = ques.columns\nprint(\"The demog and question datasets share the {} column\".format(set(demog_cols).intersection(ques_cols)))\nprint(\"So will join them on this column\")\n\n# check shaped of these columne\nprint(\"\\nShape of Demographics dataset: {}\".format(demog.shape))\nprint(\"Shape of Questionnaire dataset: {}\".format(ques.shape))\n\n# Join the two datasets on the unique number for respondants\ndataset = demog.join(ques.set_index('SEQN'), on='SEQN')\nprint(\"\\nShape of COMBINED dataset: {}**\".format(dataset.shape))\nprint(\"\\n** one less column since SEQN is shared\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a8a20a33992fbc7714baf1147dd4d9eaf576077"},"cell_type":"code","source":"# Get cholesteral levels info, first see how many answers we have\nlabs['LBXTC'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeabb4d9841d0951d92f481215735179e8b464b9"},"cell_type":"code","source":"cholesterol = labs[['SEQN','LBXTC']]\ndataset = dataset.join(cholesterol.set_index('SEQN'), on='SEQN')\n\nprint(\"Finally, add the cholesterol level (target) column.\")\nprint(\"New Shape: {}\".format(dataset.shape))\n\n# only keep the rows where we have cholesteral info\ndataset = dataset[dataset['LBXTC'].isna() == False]\nprint(\"/nFiltering for records where we have Cholesterol info gives final shape: {}\".format(dataset.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9e08d4d0a54f6cf80aacc3d3eb245b969024779"},"cell_type":"code","source":"## define function to categorise the cholesteral level\ndef cholesterol_level(mg):\n    \"\"\"\n    1 - OK\n    2 - Borderline High (at risk)\n    3 - High\n    \"\"\"\n    if mg < 200.0:\n        return 1\n    elif mg < 240:\n        return 2\n    else:\n        return 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83d734e75cd1117a8b801374696baea1bf948f4d"},"cell_type":"code","source":"# categorise cholesterol\ndataset['Target'] = dataset['LBXTC'].apply(lambda x: cholesterol_level(x))\n\nprint(\"Group cholesterol levels in to 3 categories:\")\nprint(\"1 - OK\")\nprint(\"\\n2 - Borderline High (at risk)\")\nprint(\"\\n3 - High\")\n\nprint(\"\\nWith the following totals:\")\nprint(dataset['Target'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceffc2a217f183dd3f09d6a5f5403886c0bd16c9"},"cell_type":"markdown","source":"* 999 features is quite a lot to start with\n* lets check for missing values to see if we should drop some of these\n\n## Demographic feature selection"},{"metadata":{"trusted":true,"_uuid":"0d5682a971f7f66a1658668f7e2d18d9304c22c1"},"cell_type":"code","source":"### first check for the Demographics\nmsno.matrix(dataset.iloc[:, 0:47])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea884ea7e70add8aca9873f1550a625f2336ab08"},"cell_type":"markdown","source":"#### Get a list of these columns with missing values"},{"metadata":{"trusted":true,"_uuid":"65c7774c50c37cc87c18d140941582cf8d40ee14"},"cell_type":"code","source":"#print(dataset.columns[0:47])\n#dataset.iloc[:,0:47].isna().sum()\ncols_missing_vals = []\ntot_missing_vals = []\nfor col,missing in zip(dataset.columns[0:47], dataset.iloc[:,0:47].isna().sum()):\n    if missing > 0:\n        cols_missing_vals.append(col)\n        tot_missing_vals.append(missing)\n\ncols_missing_vals_df = pd.DataFrame({'Variable Name': cols_missing_vals,'Records Mising': tot_missing_vals})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"58c404950c9196e1a82fe3790deaca86b39155b2"},"cell_type":"code","source":"## using data from https://wwwn.cdc.gov/Nchs/Nhanes/Search/variablelist.aspx?Component=Demographics&CycleBeginYear=2013\n## get decription of the questions asked\n\ndemog_qs = pd.read_csv(\"../input/goodhealth/demog_qs.csv\")\nprint(\"Total number of cols in description file (should be 47): {}\".format(len(demog_cols)))\nprint(\"Display descriptions with missing records where relevant\")\n\n# filter out duplicate Qs by only using those Qs with no use constraints\ndemog_description  = demog_qs[demog_qs['Variable Name'].isin(demog_cols)]\ndemog_description  = demog_description[demog_description['Use Constraints']=='None']\n\n# View descriptions of columns with missing data\npd.set_option('display.max_colwidth', -1)\npd.merge(demog_description, cols_missing_vals_df, how='outer', on=['Variable Name'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bd17c44e23bcffaa1da29d2823ed23b543e08f8"},"cell_type":"markdown","source":"#### Based on this we can:\n* Remove those columsn with many missing values\n* Remove many of the other columns as well\n* Goal is to have a survey someone could fill out online or their mobile\n* Keep:\n    * RIDAGEYR - Age\n    * 'WTINT2YR' -  Weight\n    * RIAGENDR - Gender\n    * INDFMIN2- Total FAMIL  income (need to remove 84 records?)\n    * DMDFMSIZ\tTotal number of people in the Family\t\n    * DMDHHSIZ\tTotal number of people in the Household\t\n    * DMDHHSZA\tNumber of children aged 5 years or younger in the household\t\n    * DMDHHSZB\tNumber of children aged 6-17 years old in the household\t\n    * DMDHHSZE\tNumber of adults aged 60 years or older in the household"},{"metadata":{"trusted":true,"_uuid":"f7eeb6899b836dbd1c29493942cbee44fd1080db"},"cell_type":"code","source":"##TRY TO COMBINE DMDEDUC2 & DMDEDUC3\nDEMO_KEEP_COLS = ['SEQN','RIAGENDR','WTINT2YR','RIDAGEYR','INDFMIN2','DMDHHSIZ','DMDHHSZA','DMDHHSZB','DMDHHSZE']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faa288f67e4a36773b3f7215f1426a3ac34ea64c"},"cell_type":"markdown","source":"* Let's fix the education"},{"metadata":{"trusted":true,"_uuid":"cf23ab13aa9c3e1880997319931bb575c57c1cf0"},"cell_type":"code","source":"msno.matrix(dataset[['DMDEDUC2','DMDEDUC3']])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0ea69bb524125592b9f7b66ea4b8801e80a5747"},"cell_type":"markdown","source":"### As suspected there missing values complement each other"},{"metadata":{"trusted":true,"_uuid":"fdcc71c8ea63d19f2f72341fc9758fd0807baf53"},"cell_type":"code","source":"dataset['YearsOfEduc'] = dataset.fillna(0)['DMDEDUC3'] + dataset.fillna(0)['DMDEDUC2']\nprint(\"Number of missing records in combined colum: {}\".format(dataset['YearsOfEduc'].isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae93ff13cb050a3a895e1892ad619a7a26669bec"},"cell_type":"markdown","source":"### AWESOME!"},{"metadata":{"trusted":true,"_uuid":"b770d8363d193cc9b1ccacf5b3d227b84fb8d689"},"cell_type":"code","source":"DEMO_KEEP_COLS = DEMO_KEEP_COLS + ['YearsOfEduc']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7679151649ec76bd3e5f7c61451792dc6b42f53"},"cell_type":"markdown","source":"## QUESTIONNAIRE Feature Selection"},{"metadata":{"trusted":true,"_uuid":"29945cb93134cced59f89f6e0514bd48f74a04f8"},"cell_type":"code","source":"# see if missing values in these columns\ncount_missing =[]\nname_ques_missing =[]\nfor col, missing in zip(dataset.columns[48:],dataset.iloc[:,48:].isna().sum()):\n    if missing > 380:\n        count_missing.append(1)\n        name_ques_missing.append(col)\nprint(\"{} columns with 5% or more missing records\".format(len(count_missing)))\n      \nmsno.matrix(dataset.iloc[:, 48:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8307ced4ad998d85028bd3fd6f241163ac3760d7"},"cell_type":"markdown","source":"* This is A LOT of missing data. 822 have > 1000 missing! \n* NOT all might be relevant (could be subquestions)\n* Let's remove the ones with >5% missing - kepp in mind could be eliminating **useful** gender specific data here\n* However, let's hand pick some features."},{"metadata":{"trusted":true,"_uuid":"16df9752f7f921f3af334f3a9b7345d112479345"},"cell_type":"code","source":"### our list of columns in the questionnaire\n### dropping those with so many missing\nques_cols_new = ques_cols.drop(name_ques_missing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00963052ebe8d41196e34589b7e51c0c1cc51c02","scrolled":false},"cell_type":"code","source":"ques_qs = pd.read_csv(\"../input/goodhealth/questionnaire_qs.csv\")\nprint(\"Total number of cols in description file (should be 47): {}\".format(len(ques_cols)))\nprint(\"Display descriptions with missing records where relevant\")\n\n# filter out duplicate Qs by only using those Qs with no use constraints and where >5% of records are NaN\nques_description  = ques_qs[ques_qs['Variable Name'].isin(ques_cols.drop(name_ques_missing))]\nprint(ques_description.shape)\nques_description  = ques_description[(ques_description['Use Constraints']=='None') & (ques_description['Variable Name'] != 'SEQN')]\nprint(ques_description.shape)\nlen(ques_description['Variable Name'].unique())\nques_description\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"161edc3e832789e54203d9bfcd8446ebca6f49f4"},"cell_type":"markdown","source":"### Based on the info we've selected the below columns to start"},{"metadata":{"trusted":true,"_uuid":"aacb6db883c53dd4afcf0a16e9f233e949eedeb1"},"cell_type":"code","source":"QUES_KEEP_COLS = ['DLQ010','DLQ020','DLQ040','DLQ050','DLQ060','MCQ010','MCQ053','MCQ082','MCQ086','MCQ092','MCQ203','HIQ011','HUQ051',\n                  'HUQ071','HUQ090','PAQ710','PAQ715','DIQ010','SMD460','HOD050','HOQ065','INQ060','INQ080','INQ090','INQ132','INQ140',\n                  'INQ150','CBD120','CBD130','FSD032A','FSD032B','FSD032C','FSD151','FSQ165','OHQ030']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f4097c44eebe408e18285c1b5f776816d2070a4"},"cell_type":"code","source":"KEEP_COLS = DEMO_KEEP_COLS + QUES_KEEP_COLS + ['Target']\nprint(\"A total of {} columns to keep\".format(len(KEEP_COLS)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42687ae21e69d666634241bf845f261196233500"},"cell_type":"code","source":"dataset = dataset[KEEP_COLS]\nmsno.matrix(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91d106c4d42e5ff35707b47232ba2c35436794c8"},"cell_type":"code","source":"### Not to many NaNs. Lets just take them all out.\ndataset = dataset.dropna(axis='index')\nprint(\"Final Dataset has {} unique records\".format(len(dataset['SEQN'].unique())))\nprint(\"{} missing data points\".format(dataset.isna().sum().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d796ec7500370531e8e7ed41ab9a5522c9b450c"},"cell_type":"markdown","source":"## Great. FINALLY have our dataset. Now we can explore it a bit"},{"metadata":{"trusted":true,"_uuid":"18e01082a2e65173247b95b5890bfc2537b41d84"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85814efd3d28826f4ca229e676ea53890a6c8531","scrolled":false},"cell_type":"markdown","source":"###  Some more data cleaning\n*  These data are BINAY, CATEGORICAL, NUMERICAL\n*  From the data scource we can see that there are several options for \"don't know\" or \"refused to answer\"\n* We'll clean these out aswell"},{"metadata":{"trusted":true,"_uuid":"dd5226e597b5b4819a21a50fc3a04e2893c8ce49"},"cell_type":"code","source":"### CATEGORIZE THE COLUMNS\nBINARY_COLS = ['RIAGENDR','DLQ010','DLQ020','DLQ040','DLQ050','DLQ060','MCQ010','MCQ053','MCQ082','MCQ086','MCQ092','MCQ203','HIQ011','HUQ071','HUQ090','INQ060','INQ080','INQ090','INQ132','INQ140','INQ150']\n# INQ060 7,9\nCAT_COLS = ['INDFMIN2','PAQ710','PAQ715','DIQ010','SMD460','HOQ065','FSD032A','FSD032B','FSD032C','FSD151','FSQ165'] #remove don't know/refused as 7,9,77,99,777,999\nCAT_COLS_SPEC = ['HUQ051','OHQ030'] # these have 7 & 9 as vals so treat seperate\nNUM_COLS = ['WTINT2YR','RIDAGEYR','DMDHHSIZ','DMDHHSZA','DMDHHSZB','DMDHHSZE','YearsOfEduc','HOD050','CBD120','CBD130']\n# HOD050 remove 777,999; CBD120/CBD130 remove 777777, 999999\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c3b0cecf732c4d65ff7cd33b7b35a8ff4c8dac1"},"cell_type":"code","source":"### Define a function to remove the rows of \"don't know\" and \"refused\"\ndef remove_refused_dontknow(dataframe, cols_list, removal_list):\n    for col in cols_list:\n        dataframe = dataframe[~dataframe[col].isin(removal_list)]\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"176dcf7e9149cca4925053746fa1fa3431a294ad"},"cell_type":"code","source":"print(\"Original number of records: {}\".format(dataset.shape))\n\ndataset = remove_refused_dontknow(dataset, BINARY_COLS, [7,9])\nprint(\"Records after BINARY processed: {}\".format(dataset.shape))\n\ndataset = remove_refused_dontknow(dataset, CAT_COLS, [7,9,77,99,777,999])\nprint(\"Records after CAT processed: {}\".format(dataset.shape))\n\ndataset = remove_refused_dontknow(dataset, CAT_COLS_SPEC, [77,99,777,999])\nprint(\"Records after CAT_SPEC processed: {}\".format(dataset.shape))\n\ndataset = remove_refused_dontknow(dataset, NUM_COLS, [777,999,777777,999999])\nprint(\"Records after NUM processed: {}\".format(dataset.shape))\n\ndataset = remove_refused_dontknow(dataset, ['YearsOfEduc'], [55,66,99])\nprint(\"Records after  Years of Education processed: {}\".format(dataset.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72efe40d51ede1d5fa44e4b288b025c005454c27"},"cell_type":"code","source":"### DROP THE SEQN COLUMN\ndataset = dataset.drop(columns=['SEQN'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"466be8d248a05b6c21c8bd56cbd32db3a7422aae"},"cell_type":"markdown","source":"# Target Column\n* Above we created 3 options for Cholesterol - OK, borderline-high, High\n* Since the values for high are relvatively low we are going to re-categorize the problem as OK vs At Risk\n* Makes sense since if we identified someone as having Borderline-high or High we'd advise them to see doctor and get tested"},{"metadata":{"trusted":true,"_uuid":"c459e9b0a4acc26438f66991c9dbd00886b962c0"},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(9, 5)})\nsns.countplot(dataset['Target'])\nplt.title(\"Target Variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"920d563927b6850ce14f01e5baee5db398bb7be2"},"cell_type":"code","source":"def at_risk(score):\n    if score == 1:\n        return 0 # no risk\n    else:\n        return 1 # at risk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a82e49354b78b84dddba47a92dba487d07a300bc"},"cell_type":"code","source":"dataset['Target'] = dataset['Target'].apply(lambda x: at_risk(x))\nprint(dataset.Target.value_counts() / dataset.Target.count()) #not balanced yet, but we'll come back to it\nprint(dataset.Target.value_counts())\n# look at response variable\nsns.set(rc={'figure.figsize':(9, 5)})\nsns.countplot(dataset['Target'])\nplt.title(\"Target Variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8858d78b3cf81a40ff5af0add658221d32470fab"},"cell_type":"markdown","source":"# EDA\n## Correlation"},{"metadata":{"trusted":true,"_uuid":"bdd8553ba82a19d7a1ac8160ed3f24a29f6770d1"},"cell_type":"code","source":"def plot_corr_matrix(dataset):\n    # Correlation analasys\n    corrMatt = dataset.corr()\n    mask = np.array(corrMatt)\n    mask[np.tril_indices_from(mask)] = False\n    plt.figure(figsize = (20,10))\n    sns.heatmap(corrMatt, mask = mask, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"101e95f1c76e49b39d1dfdc2f1ba2d35ad909ab0"},"cell_type":"code","source":"plot_corr_matrix(dataset[NUM_COLS])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dbc09462e4b011b79e0c37de5e48b77336339d6"},"cell_type":"markdown","source":"* Some sizable correlations amongst the household size figures and age\n* in retrospect was a bit silly to include all\n* will remove the HH size variables since AGE is important for sure\n\nFirst lets correlation with Response variable"},{"metadata":{"trusted":true,"_uuid":"05c60294786880e8a00fd720bdb3c48fcc645706"},"cell_type":"code","source":"# see correlatiosn with the RESPONSE variable\ndataset.iloc[:,:-1].corrwith(dataset.Target).plot.bar(figsize= (20,10),\n                                            title = 'Correlations with Response Variable',\n                                            fontsize = 15, rot = 45, grid = True) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8188f80b094da28f213824ad03d0d6365a4b9ff2"},"cell_type":"markdown","source":"* HH size variable do correlate, but not as strongly as age.\n* let's still take them out"},{"metadata":{"trusted":true,"_uuid":"708ba498b596eec3a6f1db15a1852dc5f8d568cc"},"cell_type":"code","source":"NUM_COLS = [e for e in NUM_COLS if e not in ('DMDHHSIZ','DMDHHSZA','DMDHHSZB','DMDHHSZE')]\ndataset = dataset.drop(columns = ['DMDHHSIZ','DMDHHSZA','DMDHHSZB','DMDHHSZE'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4352b8bbc533cd6726eb274428a13601d6d7bd57"},"cell_type":"code","source":"sns.pairplot(dataset, hue='Target', vars=NUM_COLS)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bfba129910cf6d7f1625c755a30acf392a23926"},"cell_type":"markdown","source":"## Check out spread of the data first"},{"metadata":{"trusted":true,"_uuid":"1f2d206d7fe17555bd01800b6c36c28299ab17db"},"cell_type":"code","source":"## Box plots of features and response\nsns.set(style=\"whitegrid\")\nfig, axes = plt.subplots(nrows=1, ncols=2)\nfig.set_size_inches(18,10)\na = sns.boxplot(data=dataset[NUM_COLS[1:]], orient='v', ax=axes[0]) # numerical features except salary\nb = sns.boxplot(data=dataset['WTINT2YR'], orient='v', ax=axes[1])  #salary\na.set_xticklabels(labels = NUM_COLS[1:], rotation=90)\nb.set_xticklabels(labels=['Household Income'])\na.set_title('Box plot of numerical features (not salary)')\nb.set_title('Box plot of salary')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc89a5ab4728f3da25a730141df871763c1d8d6f"},"cell_type":"markdown","source":"* Amounts spent on foodout and takeaways have some outliers, lets remove"},{"metadata":{"trusted":true,"_uuid":"c4bcc35cd139c0a3f3655dc29e9f49260507220e"},"cell_type":"code","source":"def remove_outliers(dataframe, column, num_std_dev):\n    \"\"\"\n    dataframe -- dataframe to trim\n    column -- column in the datarame to trim\n    num_std -- the number of Standard dev above which to remove (for normal disribution > 2 std is 2.2%)\n    \"\"\"\n    mean = np.mean(dataset[column])\n    std = np.std(dataset[column])\n    \n    dataframe = dataframe[dataframe[column] < mean + num_std_dev*std]\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"513ed8a1c0b176872821760a2ce702f10d1aebb2"},"cell_type":"code","source":"## REMOVE OUTLIERS\ndataset = remove_outliers(dataset, 'CBD120', 2)\ndataset = remove_outliers(dataset, 'CBD130', 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"570cdf322016783b204aa2beed7a43e321f2e4eb"},"cell_type":"code","source":"## CHECK HOW IT LOOKS\nsns.set(rc={'figure.figsize':(18, 10)})\nax = sns.boxplot(data=dataset[NUM_COLS[1:]], orient='v') # numerical features except salary\nax.set_xticklabels(labels = NUM_COLS[1:], rotation=90)\nax.set_title('Box plot of numerical features (not salary) - OUTLIERS REMOVED')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e1e2b677f65c43f6ed5d76bf90aa0280f020e92"},"cell_type":"markdown","source":"## How about Binary and Categorical columns"},{"metadata":{"trusted":true,"_uuid":"f55a83a7fc9b9b825627f8ba061e05be48beb666"},"cell_type":"code","source":"(dataset[BINARY_COLS].shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"208be4b56d987048c00eff1f9755148d4992ce8d"},"cell_type":"code","source":"fig = plt.figure(figsize=(18,10))\n\nplt.suptitle('Pie Chart Distributions - BINARY', fontsize = 20)\n\nfor i in range(1, dataset[BINARY_COLS].shape[1]+1):\n    plt.subplot(5, 5, i)\n    f = plt.gca()\n    f.axes.get_yaxis().set_visible(False)\n    f.set_title(dataset[BINARY_COLS].columns.values[i-1])\n    \n    values = dataset[BINARY_COLS].iloc[:, i-1].value_counts(normalize = True).values\n    index = dataset[BINARY_COLS].iloc[:, i-1].value_counts(normalize = True).index\n    plt.pie(values, labels = index, autopct='%1.1f%%')\n    plt.axis('equal')\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac3b107cb893fb8f55ec037da9fe7f02978bf576"},"cell_type":"markdown","source":"* Take a look at those small values"},{"metadata":{"trusted":true,"_uuid":"0f6b807fc02e203cc5268c946ff6190e7d8f383f"},"cell_type":"code","source":"dataset[dataset['DLQ060'] == 1].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdfac71916ace35a127d1c515a19dd2ceded90e3"},"cell_type":"code","source":"dataset[dataset['MCQ053'] == 1].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6a35b6c5fc223b2de8f080bf9827f41a22c7b6a"},"cell_type":"code","source":"dataset[dataset['MCQ082'] == 1].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28fcf9d87f5699e2d75090e83a6c3bae405b5bd7"},"cell_type":"code","source":"dataset[dataset['MCQ086'] == 1].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df5e8f8c5f5b92bbf4e646ae23909df6b7b7cc9f"},"cell_type":"code","source":"dataset[dataset['MCQ203'] == 1].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b461a5ef6a9fefe2fff49db5308621ec532d067d"},"cell_type":"markdown","source":"* Both values are represented so we can leave these features"},{"metadata":{"_uuid":"e43c72b150cbd5dd653c0fca05f69ab76579cd00"},"cell_type":"markdown","source":"### Same for CATEGORICAL features"},{"metadata":{"trusted":true,"_uuid":"f1435f233fccf4ca3b7f64935dbb84037cc0a965"},"cell_type":"code","source":"CAT_COLS = CAT_COLS + CAT_COLS_SPEC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2b393c920c00afbca0776352a259dbb045b1990"},"cell_type":"code","source":"plt.suptitle('Pie Chart Distributions - CATEGORICAL', fontsize = 20)\n\nfor i in range(1, dataset[CAT_COLS].shape[1]+1):\n    plt.subplot(5, 5, i)\n    f = plt.gca()\n    f.axes.get_yaxis().set_visible(False)\n    f.set_title(dataset[CAT_COLS].columns.values[i-1])\n    \n    values = dataset[CAT_COLS].iloc[:, i-1].value_counts(normalize = True).values\n    index = dataset[CAT_COLS].iloc[:, i-1].value_counts(normalize = True).index\n    plt.pie(values, labels = index, autopct='%1.1f%%')\n    plt.axis('equal')\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"574cd937da5c28a2bf44058cd21327aa18ad224f"},"cell_type":"code","source":"dataset[dataset['INDFMIN2'] == 13].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"359013d258b26acf8ed615efa36b3da800dd36e4"},"cell_type":"code","source":"dataset[dataset['PAQ710'] == 8].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8403dd410266e1641ec6d0a1b734ffed51bae14"},"cell_type":"code","source":"dataset[dataset['DIQ010'] == 3].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0e9928d5ac4e3221f8142956d77af36bae73470"},"cell_type":"code","source":"dataset[dataset['SMD460'] == 3].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21170b8753adbf8b8f260e2363ae6fd870e8f0c1"},"cell_type":"code","source":"dataset[dataset['HUQ051'] == 7].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5987ceabed46686294d24d770c8e3183ef63e1a1"},"cell_type":"code","source":"dataset[dataset['OHQ030'] == 7].Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65416eb6c2a3a8ce00f8d5c984b1251c07e719cb"},"cell_type":"markdown","source":"* OK these are also good"},{"metadata":{"_uuid":"f043c43c0c16c356d385c60148049998f3921c86"},"cell_type":"markdown","source":"# OHE"},{"metadata":{"trusted":true,"_uuid":"2d814487604ac270fe5c322fe30632353badfa5d"},"cell_type":"code","source":"cat_str = dataset[CAT_COLS].astype('category')\ncat_ohe = pd.get_dummies(cat_str)\n\n## since these \"binary\" columns are currently stored as 1 or 2\nbin_str = dataset[BINARY_COLS].astype('category')\nbin_ohe = pd.get_dummies(bin_str)\n\ndataset = dataset.drop(columns=CAT_COLS, axis=1)\ndataset = dataset.drop(columns=BINARY_COLS, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c94e0f26ec81d819a826360ef3e92c2ef6fa7846"},"cell_type":"code","source":"print(cat_ohe.shape)\nprint(bin_ohe.shape)\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9caaeddb7c7c3cf7038e2e532480e3dc4ff308d"},"cell_type":"code","source":"## drop the extra columns to remove dependency\ncat_ohe = cat_ohe.drop(columns=['INDFMIN2_1.0','PAQ710_0.0','PAQ715_0.0','DIQ010_1.0','SMD460_0.0','HOQ065_1.0','FSD032A_1.0','FSD032B_1.0',\n                          'FSD032C_1.0','FSD151_1.0','FSQ165_1.0','HUQ051_0','OHQ030_1.0'], axis=1)\n\nbin_ohe = bin_ohe.drop(columns = ['RIAGENDR_1','DLQ010_1.0','DLQ020_1.0','DLQ040_1.0','DLQ050_1.0','DLQ060_1.0','MCQ010_1.0','MCQ053_1.0',\n                        'MCQ082_1.0','MCQ086_1.0','MCQ092_1.0','MCQ203_1.0','HIQ011_1','HUQ071_1','HUQ090_1.0','INQ060_1.0','INQ080_1.0',\n                        'INQ090_1.0','INQ132_1.0','INQ140_1.0','INQ150_1.0'], axis=1)\n\nprint(cat_ohe.shape)\nprint(bin_ohe.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ac3e44579e51e083d865bde647f66cf5db4194f"},"cell_type":"code","source":"dataset = dataset.join(cat_ohe).join(bin_ohe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ced443b34ba4fe5ac71a27172b20704c18a7298"},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63ec1e9a8a561dde3870027dd685ce587198c1e1"},"cell_type":"markdown","source":"# SPLIT dataset"},{"metadata":{"trusted":true,"_uuid":"54ed33b26101ff94597fcdf190fade40fe6e937e"},"cell_type":"code","source":"X = dataset.drop(columns=['Target'], axis=1)\ny = dataset['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"599c89e928fc08ee00e0014343a1771eaf930ec9"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b21e8262eac32e57521c71935b2aa7afd7fec849"},"cell_type":"code","source":"X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8c091aedc04dd9fb387a1593997d41094f940fe"},"cell_type":"code","source":"print(\"Size of Training set is {} records\".format(X_train.shape[0]))\nprint(\"Size of Dev set is {} records\".format(X_dev.shape[0]))\nprint(\"Size of Test set is {} records\".format(X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"441d06cbdf03cf3b03a09dd2ae1e1f964543ae6d"},"cell_type":"markdown","source":"# Scale dataset"},{"metadata":{"trusted":true,"_uuid":"b9203f0b8e7d1e570074880bff6cf526e2b99be1"},"cell_type":"code","source":"X_Sc = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9080e4a781f443b8a2fb9f83e46c06c85f2b8eb1"},"cell_type":"code","source":"## Only Scaling the Numerical Columns not Binary\nX_train_bin = X_train.drop(NUM_COLS, axis = 1) \nX_dev_bin = X_dev.drop(NUM_COLS, axis = 1) \nX_test_bin = X_test.drop(NUM_COLS, axis = 1) \n\n\nX_train = X_train[NUM_COLS]\nX_dev = X_dev[NUM_COLS] \nX_test = X_test[NUM_COLS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"200e2d8ea55bfd9fe51224e92b3de8fb25ebfbca"},"cell_type":"code","source":"X_train2 = pd.DataFrame(X_Sc.fit_transform(X_train))\nX_dev2 = pd.DataFrame(X_Sc.transform(X_dev))\nX_test2 = pd.DataFrame(X_Sc.transform(X_test))\n\n#scaler returns numpy array and lose index and columns names which we don't want!\nX_train2.columns = X_train.columns.values\nX_dev2.columns = X_dev.columns.values\nX_test2.columns = X_test.columns.values\n\nX_train2.index = X_train.index.values\nX_dev2.index = X_dev.index.values\nX_test2.index = X_test.index.values\n\n# combine the numerical and categorical values\nX_train = pd.concat([X_train2, X_train_bin],axis=1, sort=False)\nX_dev = pd.concat([X_dev2, X_dev_bin],axis=1, sort=False)\nX_test = pd.concat([X_test2, X_test_bin],axis=1, sort=False)\n\n# check shape\nprint(X_train.shape)\nprint(X_dev.shape)\nprint(X_test.shape)\n\nprint(y_train.shape)\nprint(y_dev.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a056b812947740d9bac3b52a83b7f4fe0b364c0","scrolled":true},"cell_type":"code","source":"X_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3003a83e83cd08af3a0ce02cca88265fb76c0b96"},"cell_type":"markdown","source":"# **FINALLY** Lets build some models!"},{"metadata":{"trusted":true,"_uuid":"2667a6524001b780d2f885fb33a280bafec43d89"},"cell_type":"code","source":"## First lets have make a table to store our results\nresults_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e335442d5a44e4bd72eab925a468cfbbd64d4d13"},"cell_type":"markdown","source":"## 1.Random Forest"},{"metadata":{"trusted":true,"_uuid":"b9aedf2f390ca388054366693a4fdcbefb3d71c4"},"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=400)\n\ny_train = pd.DataFrame(y_train)\nrandom_forest.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be884a4510ec59fade882961ec94f81b89928061"},"cell_type":"code","source":"### function for plotting scores\n\ndef how_did_it_do(ml_model, X_dev, y_dev, use_model_dot_score=True, cf_matrix=True):\n    ## predict from dev set\n    y_pred = ml_model.predict(X_dev)\n    print(\"performance on X_dev:\")\n    \n    if use_model_dot_score:\n        # Accuracy\n        print(\"\\nAccuracy:\")\n        acc = round(ml_model.score(X_dev, y_dev), 3)\n        print(acc)\n    else:\n        print(\"\\nAccuracy score:\")\n        acc = round(accuracy_score(y_dev, y_pred), 3)\n        print(acc)    \n    \n\n\n    # of predicted +ve, how many correct\n    print(\"Precision score:\")\n    prec = round(precision_score(y_dev, y_pred, average='macro'), 3)\n    print(prec)\n\n\n    # of all actual +ve how many did we get\n    print(\"Recall score:\")\n    rec = round(recall_score(y_dev, y_pred, average='macro'), 3)\n    print(rec)\n\n    # f1 combines\n    print(\"Global F1 score:\")\n    f1 = round(f1_score(y_dev, y_pred, average='macro'), 3)\n    print(f1)\n    \n    ### plot confusion matrix if needed\n    if cf_matrix:\n        cm = confusion_matrix(y_dev, y_pred.round())\n        df_cm = pd.DataFrame(cm, index = (0,1), columns=(0,1))\n        plt.figure(figsize = (10,7))\n        sns.set(font_scale=1.4)\n        sns.heatmap(df_cm, annot = True, fmt='g')\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        plt.show()\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc2f92a94240b0d4f31cecce35a6f33b3a86fc27"},"cell_type":"code","source":"how_did_it_do(random_forest, X_dev, y_dev, cf_matrix=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38eaae987f0fcaef6503e595867aef7cecbd7d08"},"cell_type":"code","source":"model_results = pd.DataFrame([['RandomForest_1 (n=400)', 0.753, 0.663, 0.571, 0.57]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61da052e3f422e65e41621fe3cf3d9f8d589da10"},"cell_type":"markdown","source":"### predicting OK when at risk... could be due to unbalnced data set. Lets balance training set"},{"metadata":{"_uuid":"78a2bd4e2ef5dd2e1246c173c977fdd59a92693b"},"cell_type":"markdown","source":"# Balance Training Data"},{"metadata":{"trusted":true,"_uuid":"5d6a9bacaaf1656452b40ad059ee379d955a8eff"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nX_train_nonBal = X_train\ny_train_nonBal = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d29638498c297bf8f29406f304984ac70ca5747"},"cell_type":"code","source":"train_cols = X_train.columns\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\nX_train_res = pd.DataFrame(X_train_res, columns=train_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"217406a36a27c873d88ccd29fbfff922b756d240"},"cell_type":"code","source":"X_train = X_train_res\ny_train = pd.DataFrame(y_train_res, columns=[\"Target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04f17938141f1f8f6c5805a6fbdf27d0cf7a9784"},"cell_type":"code","source":"y_train.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27b1f83787c756c5e4706e577c5a41573068b477"},"cell_type":"markdown","source":"### **DATA IS BALANCED - MODELLING AGAIN!!**"},{"metadata":{"_uuid":"c948b315ee0aeef1fa72f0368cb38bff59433322"},"cell_type":"markdown","source":"## 2. RANDOM FOREST"},{"metadata":{"trusted":true,"_uuid":"a32f4d6a6194f746ef25ad1fe8238791f8725fa8"},"cell_type":"code","source":"random_forest_2 = RandomForestClassifier(n_estimators=400)\n\ny_train = pd.DataFrame(y_train)\nrandom_forest_2.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9da9c2821be71447099dda54643a856af20bc58a"},"cell_type":"code","source":"how_did_it_do(random_forest_2, X_dev, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60319443fda2fcfb0202fdc705a82d8548cc8ddf"},"cell_type":"code","source":"model_results = pd.DataFrame([['RandomForest_2 (Balanced Data, n=400)', 0.74, 0.639, 0.595, 0.603]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5176e0c323e9226e463e7cb2de001b93e0c18896"},"cell_type":"markdown","source":"### Improve with Grid Search"},{"metadata":{"trusted":true,"_uuid":"edd4493cc037766d8f6965fcf8dd7c859cd30fbd"},"cell_type":"code","source":"## Set the params we're gonna try\nparameters = {'max_depth': [100, None],\n             \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n             'n_estimators': [400, 500],\n             'min_samples_split': [2, 5, 10],\n             'min_samples_leaf': [1, 5, 10],\n             'bootstrap': [True, False],\n             'criterion': ['gini','entropy']}\n\nfrom sklearn.model_selection import GridSearchCV\n\n# n_job = -1tells it to use all cores on your computer\ngrid_search = GridSearchCV(estimator = random_forest_2,\n                           param_grid = parameters,\n                           scoring = 'f1_macro',\n                           verbose=1,\n                           cv = 2,\n                           n_jobs = 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8286a2e4cdd0ef56afb33272f6c68033a0766e31"},"cell_type":"code","source":"\"\"\"import time\nt0 = time.time()\ngrid_search = grid_search.fit(X_train, y_train.values.ravel())\nt1 = time.time()\n\nprint(\"Took %0.2f seconds\" % (t1 - t0))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb35d410dc0e9069a53c8c5587d6dee6b4468ad2"},"cell_type":"code","source":"\"\"\"rf_best_accuracy = grid_search.best_score_\nfr_best_paramaters = grid_search.best_params_\n\nprint(rf_best_accuracy)\nfr_best_paramaters\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bd29be2ec2f98846b8218077a1977f07a16b2ad"},"cell_type":"markdown","source":"## 3. Random Forest"},{"metadata":{"trusted":true,"_uuid":"6ee151aa63a1fabeb980d229d5a674585f5cdda1"},"cell_type":"code","source":"random_forest_3 = RandomForestClassifier(n_estimators=400, bootstrap=False, criterion='gini', max_depth=100, max_features='log2',\n                                        min_samples_leaf=1, min_samples_split=2)\n\ny_train = pd.DataFrame(y_train)\nrandom_forest_3.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6fa7ff7265027be84f3925a64750dfdf19467472"},"cell_type":"code","source":"how_did_it_do(random_forest_3, X_dev, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f20c70c313c8f121fad49b44e67da8006de3feda"},"cell_type":"code","source":"model_results = pd.DataFrame([['RandomForest_3 (Grid Search x1)', 0.738, 0.628, 0.573, 0.577]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25f23b6e90dbbc44c595a20da35e4228cd252280"},"cell_type":"markdown","source":"## 4. Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"fdb0724380a0b2a49f008f21e54e1bf0a56eea3a"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogistic_regression = LogisticRegression(random_state = 0)\n\nlogistic_regression.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"ec954d1918cb9833c94668bb95be6c79a09e2b3c"},"cell_type":"code","source":"how_did_it_do(logistic_regression, X_dev, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0d113058139ff225515695bde7e822a39c9d70e"},"cell_type":"code","source":"model_results = pd.DataFrame([['Logistic Regression', 0.638, 0.601, 0.628, 0.595]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd4f31cb6ed7663b8fd139eefb57aa56ee2950a3"},"cell_type":"code","source":"### K-Fold Cross Val \nfrom sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = logistic_regression,\n                            X = X_train, \n                            y = y_train.values.ravel(),\n                            scoring = 'f1',\n                            cv = 5)\nprint(accuracies)\nprint(accuracies.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b44eded7443a0ae57396ae73c106be0b4865473"},"cell_type":"markdown","source":"* Analyze coefficinets\n*  RFE"},{"metadata":{"_uuid":"67be9a8985f9a703696e593e0b836341ec4cd5e0"},"cell_type":"markdown","source":"## 5. SVM (Linear)"},{"metadata":{"trusted":true,"_uuid":"f9c47926372378998751b0007889ca4669293ef1"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc_linear = SVC(random_state = 0, kernel = 'linear')\n\nsvc_linear.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d192dd83284e99709fc26209ef14e9df19d18302"},"cell_type":"code","source":"how_did_it_do(svc_linear, X_dev, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a93b13b29e883509ba59344cd6383ecb006bdb8"},"cell_type":"code","source":"model_results = pd.DataFrame([['SVM (linear)', 0.636, 0.61, 0.642, 0.6]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f6e7e614a7b1524979a5bf808ff5963094151f0"},"cell_type":"markdown","source":"## 6. SVM (RBF)"},{"metadata":{"trusted":true,"_uuid":"3b13f2d82cc49366a1078bc6a85720b2e9a57fd7"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc_rbf = SVC(random_state = 0, kernel = 'rbf')\n\nsvc_rbf.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe37138e27b01403f70c9483005588d1c30326e"},"cell_type":"code","source":"how_did_it_do(svc_rbf, X_dev, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6de837b62500c1de917897d6dc49e1ed38237cb9"},"cell_type":"code","source":"model_results = pd.DataFrame([['SVM (RBF)', 0.63, 0.624, 0.662, 0.604]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c3978836d2550c2a749a13e169e5d4c56b7d13c"},"cell_type":"code","source":"from sklearn import svm\ndef svc_param_selection(X, y, nfolds):\n    Cs = [0.001, 0.01, 0.1, 1, 10]\n    gammas = [0.001, 0.01, 0.1, 1]\n    param_grid = {'C': Cs, 'gamma' : gammas}\n    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds, verbose=1)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0bc2b0998fa846436f8273f3d29c41d01940794d"},"cell_type":"code","source":"svc_param_selection(X_train, y_train.values.ravel(), 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6434c7d6159519158839dc331d8781dd0f4ab247"},"cell_type":"code","source":"svc_rbf_2 = svm.SVC(kernel = 'rbf', C=10, gamma=1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d16124cdb47610297974b1e44417a4f5c579a8c1"},"cell_type":"code","source":"svc_rbf_2.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc279fe83136a7d89752219d8eff218d2053cb5b"},"cell_type":"code","source":"how_did_it_do(svc_rbf_2, X_dev, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96b21ce43c615e2a09cc76df9e3f080ba466941a"},"cell_type":"code","source":"model_results = pd.DataFrame([['SVM (RBF 2) C=10, gamma=1', 0.743, 0.371, 0.5, 0.426]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e39b2b7d725a1cd3c5c40f56a97e0fd7c580208"},"cell_type":"markdown","source":"# 6. DNN"},{"metadata":{"trusted":true,"_uuid":"ddc882c79ba97a7866ca969edb26b853d275e18f"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41eaa2abb4a9c7c864fe53c4abd1da52b43fe478"},"cell_type":"code","source":"model = Sequential([\n    Dense(units = 16, input_dim = 79, activation = 'relu'),\n    Dense(units = 24, activation = 'relu'),\n    Dropout(0.7),\n    Dense(20, activation = 'relu'),\n    Dropout(0.7),\n    Dense(20, activation = 'relu'),\n    Dropout(0.7),\n    Dense(24, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc9c53f37dd6194d567e3d549ec007d4340e0692"},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e7ee920ea0866f44ac47c73e962473189dd34da","scrolled":true},"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=32, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37c19e2762d29f80f480adacfd5a154473eee498","scrolled":false},"cell_type":"code","source":"y_pred = model.predict(X_dev)\ny_pred = y_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39f3136bd2d846386152a63eeed297b67e57f693"},"cell_type":"code","source":"    print(\"\\nAccuracy score:\")\n    print(round(accuracy_score(y_dev, y_pred), 3))    \n\n    # of predicted +ve, how many correct\n    print(\"Precision score:\")\n    print(round(precision_score(y_dev, y_pred, average='macro'), 3))\n\n\n    # of all actual +ve how many did we get\n    print(\"Recall score:\")\n    print(round(recall_score(y_dev, y_pred, average='macro'), 3))\n\n    # f1 combines\n    print(\"Global F1 score:\")\n    print(round(f1_score(y_dev, y_pred, average='macro'), 3))\n    \n    ### plot confusion matrix \n\n    cm = confusion_matrix(y_dev, y_pred.round())\n    df_cm = pd.DataFrame(cm, index = (0,1), columns=(0,1))\n    plt.figure(figsize = (10,7))\n    sns.set(font_scale=1.4)\n    sns.heatmap(df_cm, annot = True, fmt='g')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3fd426d8133fa71aebfa977870dad844d3b7b8b"},"cell_type":"code","source":"model_results = pd.DataFrame([['DNN', 0.637, 0.601, 0.629, 0.595]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3400a62c9bc85bdceeee932b6a6bd587a724c3e"},"cell_type":"markdown","source":"# 7. DNN (On original Data - no balance)"},{"metadata":{"trusted":true,"_uuid":"c8714d89340fc1c349dd166860db0c777dee032f"},"cell_type":"code","source":"model_2 = Sequential([\n    Dense(units = 16, input_dim = 79, activation = 'relu'),\n    Dense(units = 24, activation = 'relu'),\n    Dropout(0.7),\n    Dense(20, activation = 'relu'),\n    Dropout(0.7),\n    Dense(20, activation = 'relu'),\n    Dropout(0.7),\n    Dense(24, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])\n\nmodel_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40d45f69e4d994c6570d708aae4b223bbb6ac224","scrolled":true},"cell_type":"code","source":"model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_2.fit(X_train_nonBal, y_train_nonBal, batch_size=32, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cea0c837a63cdd6d3ccc85c14e6c8d3fda2ee665"},"cell_type":"code","source":"y_pred = model_2.predict(X_dev)\ny_pred = y_pred.round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf5571322d6df56f70a7f8d805f119f2d289eb94"},"cell_type":"code","source":"    print(\"\\nAccuracy score:\")\n    print(round(accuracy_score(y_dev, y_pred), 3))    \n\n    # of predicted +ve, how many correct\n    print(\"Precision score:\")\n    print(round(precision_score(y_dev, y_pred, average='macro'), 3))\n\n\n    # of all actual +ve how many did we get\n    print(\"Recall score:\")\n    print(round(recall_score(y_dev, y_pred, average='macro'), 3))\n\n    # f1 combines\n    print(\"Global F1 score:\")\n    print(round(f1_score(y_dev, y_pred, average='macro'), 3))\n    \n    ### plot confusion matrix \n\n    cm = confusion_matrix(y_dev, y_pred.round())\n    df_cm = pd.DataFrame(cm, index = (0,1), columns=(0,1))\n    plt.figure(figsize = (10,7))\n    sns.set(font_scale=1.4)\n    sns.heatmap(df_cm, annot = True, fmt='g')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d93713b70eac3d914ad0c06e4ea6bfd8c8018b9"},"cell_type":"code","source":"model_results = pd.DataFrame([['DNN 2 (Original Data)', 0.643, 0.371, 0.5, 0.426]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nresults_df = results_df.append(model_results, ignore_index=True)\nresults_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36db9b1e6c6111f0fcd63e3b8e9f44c68261ac86"},"cell_type":"markdown","source":"### **Seems like the SVM RBF (1) is best for us since it minimizes false negatives i.e. catches most people at risk**\n### Let's test on the test set. Then let's plot some trainnig graphs on the DNN for fun"},{"metadata":{"_uuid":"7e90c29391d9b29e5759cef4594aa6cb6af27fd5"},"cell_type":"markdown","source":"# Test set"},{"metadata":{"trusted":true,"_uuid":"fedab4823a0787cb697047de22a94cc78fc64001"},"cell_type":"code","source":"how_did_it_do(svc_rbf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02f1cc9fa4cbd7dfd141fda627ae04d41ad33c45"},"cell_type":"markdown","source":"## Keras training graphs (for fun)"},{"metadata":{"trusted":true,"_uuid":"d2e773232cca22ec31ca7eef2ca72c15e35120e6","scrolled":true},"cell_type":"code","source":"### re-run first DNN but plot learning curve\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=50, batch_size=16, verbose=1)\n\n# list all data in history\nprint(history.history.keys())\n\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e43bec3f1cf7d231e0f9b66e677664682845a5d5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e81678749051230a03517417029f793f385fd44"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e782c8ff5f5a90f5641f8bd9cc5da406b9311d6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}