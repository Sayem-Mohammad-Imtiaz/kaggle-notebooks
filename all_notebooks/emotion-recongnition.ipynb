{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset= \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_list = os.listdir(dataset)\ndir_list[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion=[]\npath = []\nfor i in dir_list:\n    if i[-8:-6]=='_a':\n        emotion.append('male_angry')\n    elif i[-8:-6]=='_d':\n        emotion.append('male_disgust')\n    elif i[-8:-6]=='_f':\n        emotion.append('male_fear')\n    elif i[-8:-6]=='_h':\n        emotion.append('male_happy')\n    elif i[-8:-6]=='_n':\n        emotion.append('male_neutral')\n    elif i[-8:-6]=='sa':\n        emotion.append('male_sad')\n    elif i[-8:-6]=='su':\n        emotion.append('male_surprise')\n    else:\n        emotion.append('male_error') \n    path.append(dataset + i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emotion","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_col = pd.DataFrame(emotion, columns = ['class'])\nclass_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_col[\"class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df=pd.DataFrame(path,columns=['path'])\ndataset_df['source'] = 'SAVEE'\ndataset_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df['class']=class_col\ndataset_df[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\n\n#\nfname = path[0]  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(5, 2.5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3,ncols=3, sharex=False, sharey=False,figsize=(25,15))\n\nx=0\nfor i in range(3):\n    for j in range(3):\n        fname = path[x]  \n        data, sampling_rate = librosa.load(fname)\n        plt.figure(figsize=(25, 25))\n        ax[i][j].set(title=dataset_df['class'][x])\n        ax[i][j].set_ylabel('Amplitude Envelope')\n        librosa.display.waveplot(data, sr=sampling_rate, ax=ax[i][j])\n        x+=1\nfig.suptitle('MONOPHONIC PLOT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3,ncols=3, sharex=False, sharey=False,figsize=(25,15))\n\nx=0\nfor i in range(3):\n    for j in range(3):\n        fname = path[x]  \n        data, sampling_rate = librosa.load((fname), mono=False, duration=10)\n        plt.figure(figsize=(25, 25))\n        ax[i][j].set(title=dataset_df['class'][x])\n        ax[i][j].set_ylabel('Amplitude Envelope')\n        librosa.display.waveplot(data, sr=sampling_rate, ax=ax[i][j])\n        x+=1\nfig.suptitle('STEREO PLOT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3,ncols=3, sharex=False, sharey=False,figsize=(25,15))\n\nx=0\nfor i in range(3):\n    for j in range(3):\n        fname = path[x]  \n        data, sampling_rate = librosa.load(fname)\n        y_harm, y_perc = librosa.effects.hpss(data)\n        \n        plt.figure(figsize=(25, 25))\n        ax[i][j].set(title=dataset_df['class'][x])\n        ax[i][j].set_ylabel('Amplitude Envelope')\n        librosa.display.waveplot(y_harm, sr=sampling_rate, alpha=0.25,ax=ax[i][j])\n        librosa.display.waveplot(y_perc, sr=sampling_rate, ax=ax[i][j], alpha=0.5,color='r')\n        \n        x+=1\nfig.suptitle('Harmonic + Percussive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3,ncols=3, sharex=False, sharey=False,figsize=(25,15))\n\nx=0\nfor i in range(3):\n    for j in range(3):\n        fname = path[x]  \n        data, sampling_rate = librosa.load((fname), mono=False, duration=10)\n        plt.figure(figsize=(25, 25))\n        ax[i][j].set(title=dataset_df['class'][x])\n        ax[i][j].set_ylabel('Amplitude Envelope')\n        \n        D = librosa.amplitude_to_db(np.abs(librosa.stft(data)), ref=np.max)\n        librosa.display.specshow(D, y_axis='linear', x_axis='time',\n                               sr=sampling_rate, ax=ax[i][j])\n\n        \n        x+=1\nfig.suptitle('Linear-frequency power spectrogram')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3,ncols=3, sharex=False, sharey=False,figsize=(25,15))\n\nx=0\nhop_length = 1024\nfor i in range(3):\n    for j in range(3):\n        fname = path[x]  \n        data, sampling_rate = librosa.load((fname), mono=False, duration=10)\n        plt.figure(figsize=(25, 25))\n        ax[i][j].set(title=dataset_df['class'][x])\n        ax[i][j].set_ylabel('Amplitude Envelope')\n        \n        D = librosa.amplitude_to_db(np.abs(librosa.stft(data, hop_length=hop_length)),\n                            ref=np.max)\n        img=librosa.display.specshow(D, y_axis='log', x_axis='time', hop_length=hop_length,\n                               sr=sampling_rate, ax=ax[i][j])\n\n        img\n        x+=1\nfig.suptitle('Log-frequency power spectrogram')\nfig.colorbar(img, ax=ax, format=\"%+2.f dB\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TESS = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\nRAV = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\nCREMA = \"/kaggle/input/cremad/AudioWAV/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_list = os.listdir(RAV)\n\nemotion = []\ngender = []\npath = []\nfor i in dir_list:\n    fname = os.listdir(RAV + i)\n    for f in fname:\n        part = f.split('.')[0].split('-')\n        emotion.append(int(part[2]))\n        temp = int(part[6])\n        if temp%2 == 0:\n            temp = \"female\"\n        else:\n            temp = \"male\"\n        gender.append(temp)\n        path.append(RAV + i + '/' + f)\n\nnew_data1=pd.DataFrame(path,columns=['path'])\nnew_data1['source'] = 'RAVDESS'\nRAV_df = pd.DataFrame(emotion)\nRAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\nRAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\nRAV_df.columns = ['gender','emotion']\nnew_data1['class']=RAV_df.gender + '_' + RAV_df.emotion\nnew_data1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data1['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_list = os.listdir(TESS)\ndir_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = []\nemotion = []\n\nfor i in dir_list:\n    fname = os.listdir(TESS + i)\n    for f in fname:\n        if i == 'OAF_angry' or i == 'YAF_angry':\n            emotion.append('female_angry')\n        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n            emotion.append('female_disgust')\n        elif i == 'OAF_Fear' or i == 'YAF_fear':\n            emotion.append('female_fear')\n        elif i == 'OAF_happy' or i == 'YAF_happy':\n            emotion.append('female_happy')\n        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n            emotion.append('female_neutral')                                \n        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n            emotion.append('female_surprise')               \n        elif i == 'OAF_Sad' or i == 'YAF_sad':\n            emotion.append('female_sad')\n        else:\n            emotion.append('Unknown')\n        path.append(TESS + i + \"/\" + f)\n\nnew_dataset2=pd.DataFrame(path,columns=['path'])\nnew_dataset2['source']='TESS'\nnew_dataset2['class']=pd.DataFrame(emotion)\nnew_dataset2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_list = os.listdir(CREMA)\ndir_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender = []\nemotion = []\npath = []\nfemale = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n\nfor i in dir_list: \n    part = i.split('_')\n    if int(part[0]) in female:\n        temp = 'female'\n    else:\n        temp = 'male'\n    gender.append(temp)\n    if part[2] == 'SAD' and temp == 'male':\n        emotion.append('male_sad')\n    elif part[2] == 'ANG' and temp == 'male':\n        emotion.append('male_angry')\n    elif part[2] == 'DIS' and temp == 'male':\n        emotion.append('male_disgust')\n    elif part[2] == 'FEA' and temp == 'male':\n        emotion.append('male_fear')\n    elif part[2] == 'HAP' and temp == 'male':\n        emotion.append('male_happy')\n    elif part[2] == 'NEU' and temp == 'male':\n        emotion.append('male_neutral')\n    elif part[2] == 'SAD' and temp == 'female':\n        emotion.append('female_sad')\n    elif part[2] == 'ANG' and temp == 'female':\n        emotion.append('female_angry')\n    elif part[2] == 'DIS' and temp == 'female':\n        emotion.append('female_disgust')\n    elif part[2] == 'FEA' and temp == 'female':\n        emotion.append('female_fear')\n    elif part[2] == 'HAP' and temp == 'female':\n        emotion.append('female_happy')\n    elif part[2] == 'NEU' and temp == 'female':\n        emotion.append('female_neutral')\n    else:\n        emotion.append('Unknown')\n    path.append(CREMA + i)\n    \nnew_dataset3=pd.DataFrame(path,columns=['path'])\nnew_dataset3['source']='CREMA'\nnew_dataset3['class']=pd.DataFrame(emotion)\nnew_dataset3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df=pd.concat([dataset_df,new_data1,new_dataset2,new_dataset3],axis=0, ignore_index=True)\ndataset_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df_1=dataset_df\ndf = pd.DataFrame(columns=['feature'])\n# loop feature extraction over the entire dataset\ncounter=0\nfor index,path in enumerate(dataset_df_1.path):\n    X, sample_rate = librosa.load(path\n                                  , res_type='kaiser_fast'\n                                  ,duration=2.5\n                                  ,sr=44100\n                                  ,offset=0.5\n                                 )\n    sample_rate = np.array(sample_rate)\n    \n    # mean as the feature. Could do min and max etc as well. \n    mfccs = np.mean(librosa.feature.mfcc(y=X, \n                                        sr=sample_rate, \n                                        n_mfcc=13),\n                    axis=0)\n    df.loc[counter] = [mfccs]\n    counter=counter+1   \n\n# Check a few records to make sure its processed successfully\nprint(len(df))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df_1 = pd.concat([dataset_df_1,pd.DataFrame(df['feature'].values.tolist())],axis=1)\ndataset_df_1[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df_1.to_csv(\"Data_path_proc.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_df_1.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split between train and test \nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nX_train, X_test, y_train, y_test = train_test_split(dataset_df_1.drop(['path','class','source'],axis=1)\n                                                    , dataset_df_1['class']\n                                                    , test_size=0.3\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\n#X_test = (X_test - mean)/std\n\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import regularizers\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\nfilename = 'class'\noutfile = open(filename,'wb')\npickle.dump(lb,outfile)\noutfile.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=2)\nX_test = np.expand_dims(X_test, axis=2)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}