{"cells":[{"metadata":{"id":"pTcEeP4l4Boo"},"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1173320%2F57353fe4130fbcc013272cc1313112c6%2F1.png?generation=1609000146483661&alt=media)\n###SHAP Values - Explicando os impactos das vari√°veis em suas previs√µes\n\nDetectar anomalias de dados √© um desafio constante, nesse \"**Kernelicle**' _(kernel + artigo)_, tentarei dar uma pequena exposi√ß√£o ao [**SHAP**](https://shap.readthedocs.io/en/latest/), um framework especializado em explica√ß√µes aditivas aplicadas para modelos supervisionados.\n\nVamos fazer um tour pela visualiza√ß√£o de dados e constru√ß√£o de modelo  usando o dataset [**Titanic - Machine Learning from Disaster**](https://www.kaggle.com/c/titanic) por meio deste kernel. \n\nSe voc√™ gosta deste trabalho, por favor, mostre seu apoio por votos positivos.\n\n**Feliz Kaggling!** üññüòä\n\n_____\n\n##### **Conte√∫do**\n0. [Etapas em resumo, para irmos direto ao ponto!](#p1) üòè\n> * _Data Analysis_\n> * _Feature Engineering_\n> * _Data Clean_\n> * _Preprocessing_\n> * _Model_\n1. [SHAP](#p2)\n>  1. [KernelExplainer](#p3)\n>  1. [TreeExplainer](#p4)\n2. [Refer√™ncias](#p5)\n\n"},{"metadata":{"id":"DTtfutejEPIA"},"cell_type":"markdown","source":"<a id=\"p1\"></a>\n# 0. Etapas em resumo para seguirmos direto ao ponto!\n> _Data Analysis,Feature Engineering, Data Clean, Preprocessing e Model.._\n<br />\n<img src=\"https://memegenerator.net/img/images/16435405.jpg\" style=\"height:90px\" height=\"90\" />\n<hr />\n\n<i>Como esse n√£o √© o foco, decidi encurtar as coisas...</i>"},{"metadata":{"id":"Tv-dhznv5ANb","outputId":"c83adca0-89e3-4f30-a5e2-5cddcafee743","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport shap\nfrom sklearn.ensemble import RandomForestClassifier\ndata = pd.read_csv('../input/titanic-machine-learning-from-disaster/train.csv')\nprint('missing...')\ndfnulls = data.isnull().sum()\ncols_isnull = list(dfnulls[dfnulls.values>0].index)\nprint(dfnulls[dfnulls.values>0])","execution_count":null,"outputs":[]},{"metadata":{"id":"rX9CUzg4_Y4Z","trusted":true},"cell_type":"code","source":"data.loc[data.Sex=='male', 'Sex'] = 1\ndata.loc[data.Sex=='female', 'Sex'] = 2\ndata.Sex= pd.to_numeric(data.Sex)\n\ndata.Age.fillna(value=data.Age.median() ,inplace=True)\n\ndata.Fare.fillna(data.Fare.describe().loc['50%'], inplace = True) \ndata.Fare = data.Fare.astype('float')\n\ndata.Embarked.fillna(value='S', inplace=True)\nembark = pd.get_dummies(data.Embarked)\ndata = pd.concat([data,embark],axis=1)\n\ndata.Cabin.fillna(value='U', inplace=True)\ndata.Cabin = pd.Series([i[0] if not pd.isnull(i) else 'U' for i in data.Cabin ])\ndata.Cabin  = data.Cabin .map({\"U\":0, \"A\":1, \"B\" : 2 , \"C\":3, \"D\":4, \"E\":5, \"F\":6, \"G\":7,\"T\":0})\ndata.Cabin  = data.Cabin .astype(int)\n\ndata.Ticket = data.Ticket.apply(lambda x: x[:3].strip())\ndata.Ticket = data.Ticket.astype('category')\ndata.Ticket = data.Ticket.cat.codes\n\ndata[\"Family\"]=-1\ndata.Family = data.SibSp + data.Parch + 1\ndata.loc[(data['Family']==1),'Family'] =0\ndata.loc[(data['Family']>1),'Family'] =1\n\ndropColumns =['Name','SibSp','Parch','PassengerId','Embarked']\ndata.drop(columns=dropColumns, inplace=True)\ny = data.Survived","execution_count":null,"outputs":[]},{"metadata":{"id":"avuOl2MdBboO","outputId":"3b873222-7e0a-44ae-f239-25476c5c766e","trusted":true},"cell_type":"code","source":"data.tail(1)","execution_count":null,"outputs":[]},{"metadata":{"id":"TDV21FmK_rWS","outputId":"58ddedda-2c1d-464e-f873-cf6ddd5a5816","trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"3l_nsargEEHw","outputId":"6f8d94d6-122e-4b9b-b3b8-7013122d89d3","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"iD14rfSTDhI5","outputId":"4da611a4-fb41-416d-e66a-32cc20e8634b","trusted":true},"cell_type":"code","source":"x = data.drop(labels = \"Survived\", axis = 1)\ny = data.Survived\nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"EtLXQvf8-Qti"},"cell_type":"markdown","source":"*Contruindo um model em √°rvore para verificar quais vari√°veis s√£o as mais importantes*\n\n<img src=\"https://instagram.fsdu6-1.fna.fbcdn.net/v/t51.2885-15/e35/105404732_609825429911783_742267563808032849_n.jpg?_nc_ht=instagram.fsdu6-1.fna.fbcdn.net&_nc_cat=111&_nc_ohc=4K2z5Oxx_mIAX8JUtax&tp=1&oh=41d867aa0932b78b070e8990aa23a17c&oe=6011B3BA\" style=\"height:200px\" />\n"},{"metadata":{"id":"RO-VeOjHNYfC","outputId":"16e62519-7452-4be8-e77c-639cf5fed9d9","trusted":true},"cell_type":"code","source":"random_state = 3\nmax_depth = 5\nn_estimators = 8 \nimport matplotlib.pyplot as plt\n#em Fibonacci  we trust eheheh\nrfc = RandomForestClassifier(max_depth=max_depth, random_state=random_state, n_estimators=n_estimators)\nrfc.fit(x, y)\nimportances = rfc.feature_importances_\nindices = np.argsort(importances)\nfeatures = x.columns\nplt.figure(figsize=(10,5))\nplt.title('Features +importante')\nplt.barh(range(len(indices)), importances[indices], color='g', align='center',linestyle=\"solid\",alpha=0.8)\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Import√¢ncia')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"2ytM1-AyXM77"},"cell_type":"markdown","source":"<a id=\"p2\"></a>\n# 1. SHAP\n\n**SHAP** (SHapley Additive exPlanations) √© uma t√©cnica usada para interpretar os \"black-box models\" para explicar a sa√≠da de qualquer modelo de Machine Learning.\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1173320%2F4d39e3a335b20b0bb8e25d58f0e00337%2F1.png?generation=1609003097648061&alt=media) \n\nEle conecta a aloca√ß√£o de cr√©dito ideal com explica√ß√µes locais usando os valores cl√°ssicos de Shapley da teoria dos jogos e suas extens√µes relacionadas ([ver artigos para detalhes e cita√ß√µes](https://github.com/slundberg/shap#citations)).\n\n**Desenvolvido por** [Scott M. Lundberg](https://scottlundberg.com/)."},{"metadata":{"id":"_0vVijx6EdAk"},"cell_type":"markdown","source":"\n**O SHAP mede o impacto das vari√°veis, levando em considera√ß√£o a intera√ß√£o com outras vari√°veis.**  \n*Os valores de Shapley calculam a import√¢ncia de um recurso comparando o que um modelo prev√™ com e sem o recurso. No entanto, como a ordem na qual um modelo v√™ recursos pode afetar suas previs√µes, isso √© feito em todas as ordens poss√≠veis, para que os recursos sejam comparados de maneira justa.*  \n[fonte](https://medium.com/@gabrieltseng/interpreting-complex-models-with-shap-values-1c187db6ec83)\n\n![](https://meichenlu.com/img/SHAP_Clustering_XGB.png)\n\n<hr />\n\n**Quais s√£o as vantagens?**\n> * **Interpretabilidade global** \n>> Os SHAP Values podem mostrar o quanto cada preditor contribui, positiva ou negativamente, para a vari√°vel de destino.¬†\n>> √â como o gr√°fico de import√¢ncia da vari√°vel, mas √© capaz de mostrar a rela√ß√£o positiva ou negativa de cada vari√°vel com o destino (consulte os gr√°ficos de resumo abaixo).\n> * **Interpretabilidade local**¬†\n>> Cada observa√ß√£o obt√©m seu pr√≥prio conjunto de SHAP Values.¬†\n>> Isso aumenta muito sua transpar√™ncia.¬†¬†\n\n"},{"metadata":{"id":"RzD2JeIgFbxS"},"cell_type":"markdown","source":"<a id=\"p3\"></a>\n# 1.1 KernelExplainer\n\nO KernelExplainer constr√≥i uma regress√£o linear ponderada usando os dados de treinamento.¬†Ele calcula os valores de import√¢ncia de cada feature com base nos valores de Shapley e os coeficientes de uma regress√£o linear local.\n¬†¬†\n> **Desvantagem:**¬†eu longo tempo de execu√ß√£o.\n\nEssa foi a raz√£o de usar um n√∫mero pequeno na amostragem abaixo! üòÖ"},{"metadata":{"id":"pREi-rdtawhU","outputId":"ffe44792-c8c2-4d6c-f0ed-b5fff426f7bc","trusted":true},"cell_type":"code","source":"explainer = shap.KernelExplainer(rfc.predict_proba,x[:100])\nshap_values = explainer.shap_values(x[:100])\nshap.summary_plot(shap_values, x[:100])","execution_count":null,"outputs":[]},{"metadata":{"id":"eeswkwnfGq-r"},"cell_type":"markdown","source":"_A Demora ao executar a celula acima  nos da uma vis√£o unica da for√ßa bruta do Kernel SHAP que enumera todo o espa√ßo amostral._ \n\nüí•‚õèÔ∏è Observe que KernelExplainer faz uma aproxima√ß√£o de amostragem para o valores.\n\nA importancia das features (vari√°veis) por sua ordena√ß√£o decrescente. \n_(mais acima, mais importante)_\n> * *Class 0* = Morto\n> * *Class 1* = Sobrevivente\n"},{"metadata":{"id":"L3uEpmJukjir"},"cell_type":"markdown","source":"<a id=\"p4\"></a>\n# 1.2 TreeExplainer\n\nO TreeExplainer foi otimizado para renderizar de forma mais eficar modelos em √°rvore. Como nosso modelo √© baseado em **√°rvore**, o mais apropriado seria usar o¬†TreeExplainer. üòè\n\n> **Nota**: _Em caso de modelos profundos, ele disp√µes do¬†¬†DeepExplainer._"},{"metadata":{"id":"gv17IGW7kjFl","outputId":"ca59dfea-bff8-41ce-faa1-f3ae9da17e84","trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(rfc)\nshap_values = explainer.shap_values(x)\nshap.summary_plot(shap_values, x)","execution_count":null,"outputs":[]},{"metadata":{"id":"K5K0wvZ1Q1xM","outputId":"e96dbaba-04e5-4394-889b-d6956c481cc7","trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values[1], x)\nshap.summary_plot(shap_values[0], x)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"jcpHoMq2LPQC"},"cell_type":"markdown","source":"**Observa√ß√£o:**\nQuando comparado com a sa√≠da de nosso modelo random forest, o grafico de resumo, mostra a mesma classifica√ß√£o de vari√°vel para as primeiras quatro vari√°veis, mas difere para as demais vari√°veis.\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F1173320%2F7a36de4343025b64c1f27a060301d63f%2F1.png?generation=1609005407405063&alt=media)"},{"metadata":{"id":"qujfNxIheyK0"},"cell_type":"markdown","source":"**Gr√°fico de depend√™ncia**\n\nO gr√°fico de depend√™ncia √© um gr√°fico de dispers√£o que mostra o efeito que um √∫nico feature (vari√°vel) em suas previs√µes.\n\n> * Cada ponto √© uma √∫nica previs√£o (linha) em nosso dataset.\n> * O eixo x √© o valor da feature (nosso xtest).\n> * O eixo y √© o valor SHAP para a feature especificada.\n"},{"metadata":{"id":"QNVPOPUkdkLE","outputId":"ef7c0bc9-9504-40da-946e-30660ad8eb4c","trusted":true},"cell_type":"code","source":"shap.dependence_plot(\"Age\", shap_values[1], x)","execution_count":null,"outputs":[]},{"metadata":{"id":"HmnFyBOmRIz7","outputId":"cf9cf442-9e38-49a7-eb0c-6350296e0166","trusted":true},"cell_type":"code","source":"shap.dependence_plot('Ticket', shap_values[1], x, interaction_index=\"Pclass\")","execution_count":null,"outputs":[]},{"metadata":{"id":"wtpWM8ZTM0sr"},"cell_type":"markdown","source":"‚¨ÜÔ∏è O gr√°fico de depend√™ncia acima,  nos mostra que existe uma tend√™ncia aproximadamente linear e positiva entre **Age** e **Sex**.\n"},{"metadata":{"id":"Z1948CMoN2Dj"},"cell_type":"markdown","source":"**Gr√°fico de for√ßa coletiva**\n\nCada observa√ß√£o tem seu pr√≥prio gr√°fico de for√ßa. \nSe todos os gr√°ficos de for√ßa s√£o combinados, girados 90 graus e empilhados horizontalmente.\n\n\n"},{"metadata":{"id":"WFeyTl8YOpo8","outputId":"d5ca8dab-8721-4737-e821-35252c743486","trusted":true},"cell_type":"code","source":"shap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[0], x)","execution_count":null,"outputs":[]},{"metadata":{"id":"R-hTTTRVO-a8"},"cell_type":"markdown","source":"**Gr√°fico de for√ßa individual**"},{"metadata":{"id":"PJO47zN9ZH0k","outputId":"195937bc-1cba-4311-9234-651221b98237","trusted":true},"cell_type":"code","source":"shap.initjs()\ncolumIndex= 2\nshap.force_plot(explainer.expected_value[1], shap_values[1][columIndex,:], x.iloc[columIndex,:], link=\"logit\")","execution_count":null,"outputs":[]},{"metadata":{"id":"tohAwsjeVsj9"},"cell_type":"markdown","source":"**Gr√°fico de decis√£o**\n* O eixo x representa a sa√≠da do modelo. Nesse caso, as unidades s√£o probabilidades de log.\n* O gr√°fico √© centralizado no eixo x em explainer.expected_value\n>Todos os valores de SHAP s√£o relativos ao valor esperado do modelo, como os efeitos de um modelo linear s√£o relativos √† intercepta√ß√£o.\n* Na parte inferior do gr√°fico, as observa√ß√µes convergem em explainer.expected_value."},{"metadata":{"id":"mQDAjTMRVZwM","outputId":"195c9958-d4b7-49dd-991f-c62d657d8523","trusted":true},"cell_type":"code","source":"shap.decision_plot(explainer.expected_value[1], shap_values[1], x,link=\"logit\",highlight=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"i4-1o7ulXESe"},"cell_type":"markdown","source":"**Fim**  \n\n*SHAP √© uma ferramenta poderosa na  explora√ß√£o de padr√µes que um algoritmo de aprendizadoidentificou*"},{"metadata":{"id":"P4gxPrw6FTT5"},"cell_type":"markdown","source":"<a id=\"p5\"></a>\n# Refer√™ncias\n\n* https://www.mdeditor.tw/pl/paB9\n* https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values\n* https://github.com/slundberg/shap#citations\n* https://www.kaggle.com/cast42/feature-importance-and-dependence-plot-with-shap\n* https://shap.readthedocs.io/en/latest/overviews.html"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}