{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Check out the interactive plots at the bottom."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nPath.ls = lambda x: list(x.iterdir())\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport math\nfrom scipy import stats\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"path = Path('/kaggle/input/ccdata/')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pd.read_csv(path/'CC GENERAL.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to use PCA and KMeans clustering to perform customer segmentation with credit card data in this notebook.\nWe have the following features: \n\n* CUSTID : Identification of Credit Card holder (Categorical)\n* BALANCE : Balance amount left in their account to make purchases (\n* BALANCEFREQUENCY : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n* PURCHASES : Amount of purchases made from account\n* ONEOFFPURCHASES : Maximum purchase amount done in one-go\n* INSTALLMENTSPURCHASES : Amount of purchase done in installment\n* CASHADVANCE : Cash in advance given by the user\n* PURCHASESFREQUENCY : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n* ONEOFFPURCHASESFREQUENCY : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n* PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n* CASHADVANCEFREQUENCY : How frequently the cash in advance being paid\n* CASHADVANCETRX : Number of Transactions made with \"Cash in Advanced\"\n* PURCHASESTRX : Numbe of purchase transactions made\n* CREDITLIMIT : Limit of Credit Card for user\n* PAYMENTS : Amount of Payment done by user\n* MINIMUM_PAYMENTS : Minimum amount of payments made by user\n* PRCFULLPAYMENT : Percent of full payment paid by user\n* TENURE : Tenure of credit card service for user"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations: \n\n* We have skewed data. We can see 0's in `25th` and `50th` percentile. We will have to plot the histograms to find out more.\n* The Tenure looks like a categorical column which makes sense. \n"},{"metadata":{},"cell_type":"markdown","source":"Lets check for NAs"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df.info(), df.isna().sum(), df.isna().sum()/len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* We can see there are missing values in `CREDIT_LIMIT` and `MINIMUM_PAYMENTS`. \n* We can also see that the missing values account for only 3 percent data in `MINIMUM_PAYMENTS` and there is only one missing value in `CREDIT_LIMIT`. \n* We can easily use median to fill the NAs.\n"},{"metadata":{},"cell_type":"markdown","source":"Lets fill the nas with median"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"na_cols = df.columns[df.isna().sum() > 0].tolist()\ndf.loc[:,na_cols] = df.loc[:,na_cols].fillna(df[na_cols].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have handled the null values. Lets move on now. Lets list all the columns by their type.\n\n* `categorical_cols`: 'TENURE'\n* `continuous_cols`: 'BALANCE', 'BALANCE_FREQUENCY', 'PURCHASES', 'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'PURCHASES_FREQUENCY', 'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY', 'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX', 'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS', 'PRC_FULL_PAYMENT'.\n* `index_col`: 'CUST_ID'"},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# I am too lazy to write down all the columns for cont cols ;) \ncat_cols = ['TENURE']\ncont_cols = df.columns.tolist()\ncont_cols.remove(cat_cols[0])\ncont_cols.remove('CUST_ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_univariable_plots(df, cat_cols, cont_cols):\n    total_cols = len(cat_cols)+len(cont_cols)\n    fig, axes = plt.subplots(math.ceil(total_cols/3),3, figsize=(20,20),constrained_layout=True)\n    axes = axes.flatten()\n    fig.suptitle(f'Univariate plots'.title(),fontsize=18)\n    \n    for i, (col, ax) in enumerate(zip(cont_cols, axes)):\n        sns.distplot(df[col], ax=ax)\n        ax.set_title(f'Histogram of {col}')\n    \n    for col in cat_cols:\n        sns.countplot(df[col],ax=axes[i+1])\n        ax.set_title(f'Histogram of {col}')\n        \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at the data distribution"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_univariable_plots(df, cat_cols, cont_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations: \n* We can see most of the features are heavily skewed. We can try transforming with log\n* We can see that some features are left skewed and most are right skewed. \n\nLets transform skewed data with boxcox transform from scipy.stats."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"transformed_df = df.copy()\ntransformed_df.loc[:,cont_cols] = transformed_df[cont_cols].apply(lambda x: stats.boxcox(x+1)[0], axis=0)\nplot_univariable_plots(transformed_df, cat_cols, cont_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalizing Data for PCA"},{"metadata":{},"cell_type":"markdown","source":"To perform PCA on our data, we need to scale our data between 0 and 1. We will use MinMaxScaler from scikit learn to achieve that"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(transformed_df[cont_cols+cat_cols])\nscaled = scaler.transform(transformed_df[cont_cols+cat_cols])\nscaled_df = pd.DataFrame(scaled, columns=cont_cols+cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA"},{"metadata":{},"cell_type":"markdown","source":"Now that our data is scaled, we are ready to apply PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"N_COMPONENTS = 15\npca = PCA(n_components=N_COMPONENTS)\npca.fit(scaled_df)\npca.explained_variance_ratio_[:4].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get a 84% explained variance with just 4 components. We have successfully reduced the dimensions from 16 continuous variables to 4. It will help a lot in visualizing the data now."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_data = pca.transform(scaled_df)\npca_df = pd.DataFrame(pca_data).iloc[:,:4]\npca_df.columns = list(map(lambda x: f'pca_{x+1}', pca_df.columns))\n# pca_df['TENURE'] = df.TENURE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(pca_df,x='pca_1',y='pca_2',z='pca_3',opacity=0.3,color='pca_4')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can already see the clusters in the 3d scatterplot. **The plots are interactive. Try playing with it.**"},{"metadata":{},"cell_type":"markdown","source":"# KMeans Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"cost = []\nks = []\nfor i in range(3,30):\n    kmeans = KMeans(n_clusters=i)\n    kmeans.fit(pca_df)\n    cost.append(kmeans.inertia_)\n    ks.append(i)\nsns.lineplot(x=np.array(ks), y=np.array(cost))\nplt.xticks(ks)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=5)\nkmeans.fit(pca_df)\nout = kmeans.predict(pca_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(pca_df,x='pca_1',y='pca_2',z='pca_3',color=out,opacity=0.5,\n                    title='KMeans cluster with k=5')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Please have a look at the 3d plots to understand the clusters. "},{"metadata":{},"cell_type":"markdown","source":"# Understanding the clusters"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def display_component(v, features_list, component_num,ax):\n    \n    row_idx = component_num\n    \n    v_1_row = v.iloc[:,row_idx]\n    v_1 = np.squeeze(v_1_row.values)\n    \n    comps = pd.DataFrame(list(zip(v_1, features_list)),\n                         columns=['weights', 'features'])\n    \n    comps['abs_weights']=comps['weights'].apply(lambda x: np.abs(x))\n    sorted_weight_data = comps.sort_values('abs_weights',ascending=False).head()\n    \n    sns.barplot(data=sorted_weight_data,\n                   x=\"weights\",\n                   y=\"features\",\n                   palette=\"Blues_d\",ax=ax)\n    ax.set_title(\"PCA Component Makeup, Component #\" + str(component_num), fontsize=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"features_list = np.array(cont_cols+cat_cols)\nv = pd.DataFrame(pca.components_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(2,2,figsize=(20,8),constrained_layout=True)\naxes=axes.flatten()\nfor i,ax in enumerate(axes):\n    display_component(v, features_list, i,ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that how pca features correspond to the actual features in the dataset. \n\n**The 1st PCA component has high positive correlation with BALANCE_FREQUENCY and is has negative correlation with ONEOFF_PURCHASES and so on**"},{"metadata":{},"cell_type":"markdown","source":"# Finally Understanding Customer behaviour"},{"metadata":{},"cell_type":"markdown","source":"We will now take the cluster centers and use the features in the **PCA** feature space to visualize customer behaviour"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cluster_centers = kmeans.cluster_centers_\nbehaviours = cluster_centers.dot(v[:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(3,2,figsize=(15,12),constrained_layout=True)\naxes=axes.flatten()\nthreshold = 0.2\nfor i,behaviour in enumerate(behaviours):\n    thresh_mask = np.nonzero(np.abs(behaviour)>threshold)[0].tolist()\n    sns.barplot(behaviour[thresh_mask], y=features_list[thresh_mask],ax=axes[i])\n    axes[i].set_title(f'Cluster {i+1} features')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Behaviours observed:\n\n* **Cluster 1** : Customers who use credit card for Installment Purchases. They do not make oneoff purchases at all. \n* **Cluster 2** : Customers who use their credit card for all types of purchases and pay their bills in advance.  \n* **Cluster 3** : Customers who have a huge tendency of oneoff purchases and do it frequently. They also have high amount purchases.\n* **Cluster 4** : Customers who dont make huge purchases on the credit card. Also, they pay the bill in advance. \n* **Cluster 5** : Customers who use the credit card mostly for oneoff Purchases only. They also don't pay bills in advance."},{"metadata":{},"cell_type":"markdown","source":"## Please upvote the notebook if you like my work. Keeps me motivated."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}