{"cells":[{"metadata":{},"cell_type":"markdown","source":"Removing the default index column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\ndf = pd.read_csv('/kaggle/input/irish-weather-hourly-data/hourly_irish_weather.csv').iloc[:,1:]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing the column name 'date' to 'date_stamp' as it contains both date and time values"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df.columns.tolist()\ncols[0] = 'date_stamp'\ndf.columns = cols\n\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperating the date and time stamp into date, time, year, month, day and hour columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['date','timestamp']] = df['date_stamp'].str.split(' ',expand=True)\n\ndf[['year','month','day']] = df['date'].str.split('-',expand=True)\n\ndf['hour'] = df['timestamp'].str[0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation matrix between the variables in the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrx =df.corr()\ncorr_matrx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filtering only the strongly correlated variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrx[(corr_matrx > 0.5) | (corr_matrx < - 0.5)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"High correlation between 1) Temp - Wet bulb temp - dew point temp - vapour pressure\n                         2) Cloud Ceiling Height - clamtCloud Amount"},{"metadata":{},"cell_type":"markdown","source":"Subsetting only Galway weather data"},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_df = df[(df['county'] == 'Galway') ]\ngalway_df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping the data by year and month and then aggregating the mean data for Temperature variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_gpby =galway_df.groupby(['year','month']).agg({'temp':np.mean})\n\ntmp_gpby[tmp_gpby == np.nan].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filtering indexes of rows with null value for temperature"},{"metadata":{"trusted":true},"cell_type":"code","source":"rolling_index_diff_df = pd.DataFrame(pd.Series(galway_df[galway_df['temp'].isna()].index),columns=['index'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"User defined function to fill the missing values in Temperature variable\n\nThe missing values for a particular day and time are filled by that particular month's average temperature "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncheck_list = galway_df['temp'].isna().index.tolist()\n\ndef impute():\n    \n    op = []\n    \n    for i in galway_df[galway_df['temp'].isna()].index:\n        [year,month] = galway_df.loc[i,['year','month']].tolist()\n        op.append(tmp_gpby.loc[(year,month)][0])\n    return op\n\nop = impute()\n\ngalway_df.loc[galway_df['temp'].isna(),'temp'] = op\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting 'date_stamp' column as DateTime Index"},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_df.index = pd.DatetimeIndex(galway_df['date_stamp'])\n#galway_df.drop(columns=['date_stamp','rolling_temp','rolling_sd'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = galway_df['temp'].rolling(window = 24*30).mean()\nsd =  galway_df['temp'].rolling(window = 24*30).std()\n\ndummy = galway_df.copy()\ndummy['rolling_temp'] = mean\ndummy['rolling_sd'] =  sd\n\ngalway_df = dummy.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1 Grouping the county galway weather data using date column and collecting the mean aggregate for the Temperature     column\n\n2 Dropping the variables which has no data captured"},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_daywise_df = galway_df.groupby(['date']).agg({'temp':np.mean})\ngalway_daywise_df.index = pd.DatetimeIndex(galway_daywise_df.index)\ngalway_df.drop(columns=['w','ww','sun','vis','clht','clamt'],inplace=True) #no captures for this variables [**GALWAY***]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) Plotting the day wise weather data for galway \n2) Configuring the plotting parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.dates as mdates\n\n\n\nax = galway_daywise_df.plot(figsize=(20,10))\n\nax.xaxis.set_major_locator(mdates.YearLocator(1))\n# set formatter\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\nax","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing Augmented Dickey Fuller Test - A Statistical Test for checking the stationarity of the time series data\n\nNull Hypothesis : The data is not stationary\nAlternate Hpothesis: The data is stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\nadfuller(galway_daywise_df['temp'])\n\n#p-value is less than 0.05 (95% CI), so rejecting the null hypothesis, therefore at 95% confidence, we have enough evidence to\n#support the claim that the data is stationary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting Lag plot for correlation between current temperature and lagged observations and Auto Correlation Function (ACF) and Partial Autocorrelation Function (PACF) Plots for getting optimal 'p' and 'q' parameters of AR (Auto Regression) and MA (Moving Average) models"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for the relationship between the current temperature observations and the lagged observations - should indicate either strong \n#positive or strong negative correlation - for the data to be stationary\nfrom pandas.plotting import lag_plot\nlag_plot(galway_daywise_df['temp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n\np = plot_acf(galway_daywise_df['temp'],lags=30)\n\np.set_size_inches(15, 8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = plot_pacf(galway_daywise_df['temp'],lags=30)\n\np.set_size_inches(15, 8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decomposing the galway daywise weather time series data into Trend,Seasonality and Residuals \n\nThe frequency is set to year"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nseasonal_decompose(galway_daywise_df['temp'],freq=30*12).plot();\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelling the galway county time series data using SARIMAX (Seasonal Auto Regression Integrating Moving Average with Exogeneous Variable) model "},{"metadata":{},"cell_type":"markdown","source":"### SARIMAX - MULTIVARIATE"},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_multivariate_df = galway_df.copy()\ngalway_multivariate_df.drop(columns=['station','county','longitude','latitude'],inplace=True)\ngalway_multivariate_df = galway_multivariate_df.iloc[:,0:14]\ngalway_multivariate_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping the data by year and month and finding the mean for all the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"multivariate_gpy = galway_multivariate_df.groupby(['year','month']).agg({'rain':'mean', 'temp':'mean', 'wetb':'mean', 'dewpt':'mean', 'vappr':'mean', 'rhum':'mean', 'msl':'mean', 'wdsp':'mean', 'wddir':'mean'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'Interpolating the multivariate time series data using time interpolation"},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_multivariate_df = galway_multivariate_df.interpolate(method='time')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensuring no missing values after time interpolation"},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_multivariate_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"galway_multivariate_daywise_df = galway_multivariate_df.groupby(['date']).agg({'rain':'mean', 'temp':'mean', 'wetb':'mean', 'dewpt':'mean', 'vappr':'mean', 'rhum':'mean', 'msl':'mean', 'wdsp':'mean', 'wddir':'mean'})\ngalway_multivariate_daywise_df.index = pd.DatetimeIndex(galway_multivariate_daywise_df.index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the data into train set and test set\n\nTrain set is used for modelling and the test set is used for validating the model\n\nTrain set - Except last year data\nTest set - Last year data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = galway_multivariate_daywise_df.iloc[:4525,:]\ntest = galway_multivariate_daywise_df.iloc[4525:,:]\n\ntrain.index  = pd.DatetimeIndex(train.index).to_period('D')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exogenous variables are the variables which probably has relationship with dependent variable and influential in predicting the dependent variable "},{"metadata":{},"cell_type":"markdown","source":"Training the data with SARIMAX model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\nmodel = SARIMAX(train['temp'],exog=train[['wdsp', 'vappr', 'wetb', 'dewpt', 'rhum', 'msl', 'rain', 'wddir']],order=(3, 0, 2), seasonal_order=(0,0,0,12))\n\nmodel_fit = model.fit()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forecasting the next 1 year data using the model built above and comparing the results with the test set 'temperature' values"},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = model_fit.predict(4525, 4525+364,exog=test[['wdsp', 'vappr', 'wetb', 'dewpt', 'rhum', 'msl', 'rain', 'wddir']])\nprint(yhat)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparing the test set temperatures and forecasted temperatures by plotting them"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_df = yhat.to_frame()\nprediction_df['actual'] = test['temp'].values\n\nprediction_df.rename(columns={0:'pred'},inplace=True)\nprediction_df.index =  test.index\n\n\nprediction_df.plot(figsize=(20,12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the SARIMAX model summary "},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the variance in the forecasted values and the actual test values by getting the MSE (Mean Squared Error) and MAE (Mean Absolute Error)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,mean_absolute_error\n\nprint(mean_squared_error(prediction_df['actual'],prediction_df['pred']))\nprint(mean_absolute_error(prediction_df['actual'],prediction_df['pred']))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}