{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Models\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n# Stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Misc\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\npd.set_option('display.max_columns', None)\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/zs-challenge-find-sentiment-of-news/train_file.csv')\ntest = pd.read_csv('/kaggle/input/zs-challenge-find-sentiment-of-news/test_file.csv')\nsample = pd.read_csv('/kaggle/input/zs-challenge-find-sentiment-of-news/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas_profiling as pp\n\nprof = pp.ProfileReport(train, title=\"Pandas Profiling Report\")\nprof","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install hiplot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import hiplot as hip\ndata = train.drop(['IDLink', 'Facebook', 'GooglePlus','LinkedIn'], axis = 1).to_dict(orient = 'records')\nhip.Experiment.from_iterable(data).display()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As per above Graph, Ranking of News on different Social Networks have no effect on Sentiment of the headline or Title\n","metadata":{}},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Topic'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import wraps\nimport datetime as dt\n\ndef log_step(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        tic = dt.datetime.now()\n        result = func(*args, **kwargs)\n        time_taken = str(dt.datetime.now() - tic)\n        print(f\"just ran step {func.__name__} shape={result.shape} took {time_taken}s\")\n        return result\n    return wrapper","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()\n\n\n@log_step\ndef find_sentiment_nltk(data):\n    \n    from nltk.sentiment import SentimentIntensityAnalyzer\n    sia = SentimentIntensityAnalyzer()\n    \n    y = data['Headline'].apply(sia.polarity_scores)\n    data['sentihead'] = y.apply(pd.Series)['compound']\n    \n    z =  data['Title'].apply(sia.polarity_scores)\n    data['sentititle'] = z.apply(pd.Series)['compound']\n    \n    return data\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n@log_step\ndef encoding(data):\n\n    \"\"\"\n    One Hot Encoding and Label Encoding \n    \n    \n    le = LabelEncoder()\n    data['Source'] = le.fit_transform(data['Source'])\n\n    var_mod = ['Topic']\n\n    for i in var_mod:\n        data[i] = le.fit_transform(data[i])\n        \n    \"\"\"\n    \n    le = LabelEncoder()\n    data['Source'] = le.fit_transform(data['Source'])\n\n    var_mod = ['Topic']\n\n    for i in var_mod:\n        data[i] = le.fit_transform(data[i])\n\n    # One Hot Encoding : \n    # data = pd.get_dummies(data, columns = ['Topic', 'Source'])\n    \n    return data\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@log_step\ndef impute(data):\n    \n    data['Source'] = data['Source'].fillna('Empty')\n    return data\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@log_step\ndef start_pipeline(dataf):\n    return dataf.copy() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['PublishDate'] = pd.to_datetime(train['PublishDate'])\ntrain['PublishDate-Month'] = train['PublishDate'].dt.month\ntrain['PublishDate-Year'] = train['PublishDate'].dt.year\ntrain['PublishDate-Day'] = train['PublishDate'].dt.day","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['IDLink', 'PublishDate'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = (train\n      .pipe(start_pipeline)\n      .pipe(impute)\n      .pipe(find_sentiment_nltk)\n      .pipe(encoding))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= train_df.drop(columns = ['SentimentTitle', 'SentimentHeadline'], axis=1)\ny= train_df[['SentimentTitle','SentimentHeadline']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = RandomForestRegressor(n_estimators=500, n_jobs=-1)\nclf.fit(X_train, y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(X_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns = []\n\nfor col in train_df.select_dtypes('object').columns:\n    print(col)\n    cat_columns.append(col)\n    le = LabelEncoder()\n    train_df[col] = le.fit_transform(train_df[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features_index = [i for i, col in enumerate(train_df.columns) if col in cat_columns]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_OF_BOOST_ROUND = 10000\nEARLY_STOPPING = 300","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'cat_features': cat_features_index,\n    'eval_metric': 'MAE',\n    'random_seed': 2021,\n    'n_estimators' : NUM_OF_BOOST_ROUND\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bst = CatBoostRegressor(**params, early_stopping_rounds = EARLY_STOPPING)\n_ = bst.fit(X_train , y_train, eval_set = (X_valid, y_valid), plot = True, verbose = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bst = CatBoostRegressor()\nbst.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}