{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nplt.style.use('ggplot')\nimport re\nimport nltk\nfrom nltk.util import ngrams\nfrom nltk.corpus import stopwords\nstop=set(stopwords.words('english'))\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.initializers import Constant\nfrom keras.layers import (LSTM, \n                          Embedding, \n                          BatchNormalization,\n                          Dense, \n                          TimeDistributed, \n                          Dropout, \n                          Bidirectional,\n                          Flatten, \n                          GlobalMaxPool1D)\nfrom nltk.tokenize import word_tokenize\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers.embeddings import Embedding\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import (\n    precision_score, \n    recall_score, \n    f1_score, \n    classification_report,\n    accuracy_score\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet = pd.read_csv('../input/disaster-tweets/tweets.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the class distribution\nx = tweet.target.value_counts()\nsns.barplot(x.index, x, palette='cool')\nplt.gca().set_ylabel('tweets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of characters in tweets\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\ntweet_len = tweet[tweet['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='crimson')\nax1.set_title('Disaster tweets')\ntweet_len = tweet[tweet['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='skyblue')\nax2.set_title('Non disaster tweets')\nfig.suptitle('Characters in tweets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of words in a tweet\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\ntweet_len = tweet[tweet['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len, color='black')\nax1.set_title('Disaster tweets')\ntweet_len = tweet[tweet['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='purple')\nax2.set_title('Non disaster tweets')\nfig.suptitle('Words in a tweet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword = tweet[tweet['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='darkblue')\nax1.set_title('Disaster')\nword = tweet[tweet['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='magenta')\nax2.set_title('Non disaster')\nfig.suptitle('Average word length in each tweet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_corpus(target):\n    corpus=[]\n    for x in tweet[tweet['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_corpus_df(tweet, target):\n    corpus=[]\n    for x in tweet[tweet['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Punctuations in non-disaster class\nplt.figure(figsize=(10,5))\ncorpus = create_corpus(0)\ndic = defaultdict(int)\nimport string\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\nx,y=zip(*dic.items())\nplt.bar(x, y,color='magenta')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Punctuations in disaster class\nplt.figure(figsize=(10,5))\ncorpus = create_corpus(1)\ndic = defaultdict(int)\nimport string\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\nx,y = zip(*dic.items())\nplt.bar(x, y, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Common words\ncounter = Counter(corpus)\nmost = counter.most_common()\nx=[]\ny=[]\nfor word, count in most[:40]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)\nsns.barplot(x=y, y=x, palette='Greens_r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bigram analysis\ndef get_top_tweet_bigrams(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\nplt.figure(figsize=(10,5))\ntop_tweet_bigrams = get_top_tweet_bigrams(tweet['text'])[:10]\nx,y = map(list,zip(*top_tweet_bigrams))\nsns.barplot(x=y,y=x, palette='Reds_r')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}