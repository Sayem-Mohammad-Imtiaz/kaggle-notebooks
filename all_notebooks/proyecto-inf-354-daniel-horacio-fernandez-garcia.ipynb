{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Se empieza importando el dataset. Este dataset es de ventas de juegos, en sus columnas incluye el nombre del juego, la consola en la que fue lanzado, el año, el genero, la editora y las ventas en norteamerica, europa, japon, resto del mundo y finalmente ventas globales. En este caso la columna objetivo será la plataforma o consola para la que fue lanzado un juego, utilizando como datos las ventas, año, genero y editora.\nSe utilizó aprendizaje supervisado.\n\nLink dataset: https://www.kaggle.com/gregorut/videogamesales ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\ndf = pd.read_csv ('../input/videogamesales/vgsales.csv')\npd.set_option('max_columns', None)\ndf = df.replace(np.nan,\"0\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-22T02:43:52.976291Z","iopub.execute_input":"2021-06-22T02:43:52.976757Z","iopub.status.idle":"2021-06-22T02:43:53.051756Z","shell.execute_reply.started":"2021-06-22T02:43:52.97672Z","shell.execute_reply":"2021-06-22T02:43:53.05064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación se inicia con el preprocesamiento. Para las columnas categoricas, como plataforma(consola), editora y genero del juego se utilizó LabelEncoder y para las columnas numéricas, que incluyen todas las columnas de ventas, se utilizó MinMaxScaler para llevar los datos a un rango, 0 a 100 en este caso y StandardScaler para estandarizar las columnas y tener media = 0 y varianza = 1.","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ndf['Publisher'] = encoder.fit_transform(df.Publisher.values)\ndf['Genre'] = encoder.fit_transform(df.Genre.values)\n\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 100))\ndf.iloc[:,6:11] = min_max_scaler.fit_transform(df.iloc[:,6:11].values)\n\nscaler = preprocessing.StandardScaler()\ndf.iloc[:,6:11] = scaler.fit_transform(df.iloc[:,6:11].values)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:43:53.053706Z","iopub.execute_input":"2021-06-22T02:43:53.054048Z","iopub.status.idle":"2021-06-22T02:43:53.126218Z","shell.execute_reply.started":"2021-06-22T02:43:53.054017Z","shell.execute_reply":"2021-06-22T02:43:53.12532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Posteriormente seleccionamos las columnas de datos y la de objetivo. El objetivo será platform(consola o plataforma) y las de datos serán las columnas de ventas, año, editora y genero.","metadata":{}},{"cell_type":"code","source":"X = df[['Genre','Publisher','Year','NA_Sales','JP_Sales','EU_Sales','Other_Sales','Global_Sales']]\ny = df['Platform']","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:43:53.127346Z","iopub.execute_input":"2021-06-22T02:43:53.127782Z","iopub.status.idle":"2021-06-22T02:43:53.138749Z","shell.execute_reply.started":"2021-06-22T02:43:53.127752Z","shell.execute_reply":"2021-06-22T02:43:53.137871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación se prepara train y test, el 20% del dataset quedará para realizar las pruebas y el 80% restante se utilizará para entrenar el clasificador. También se prepara KFold que separará el split en 10 y realizará las prubeas en cada división. Comentado queda RepeatedKFold, que repite KFold n veces. ","metadata":{}},{"cell_type":"code","source":"from sklearn import model_selection\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n#kf = model_selection.RepeatedKFold(n_splits=10, n_repeats=3)   RepeatedKfold\nkf = model_selection.KFold(n_splits=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:43:53.139927Z","iopub.execute_input":"2021-06-22T02:43:53.140337Z","iopub.status.idle":"2021-06-22T02:43:53.153351Z","shell.execute_reply.started":"2021-06-22T02:43:53.140308Z","shell.execute_reply":"2021-06-22T02:43:53.152268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación se prepara y utliza el clasificador. Se utiliza RandomForestClassifier, despues de probar con varios clasificadores, los que daban mejores resultados fueron RandomForestClassifier y DecisionTreeClassifier. Jugando con los parametros, no variaba mucho, pero el mejor resultado fue con entropia como criterio de RandomForest. \nRandomForest crea varios DecisionTrees, cada árbol da una clasificación y el resultado es la clase con mayor número de votos en todo el bosque. Si se busca precisión RandomForest es una de las mejores opciones.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclasificador = RandomForestClassifier(criterion='entropy')\nclasificador = clasificador.fit(X_train, y_train)\npredictions = clasificador.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:43:53.156235Z","iopub.execute_input":"2021-06-22T02:43:53.156539Z","iopub.status.idle":"2021-06-22T02:43:56.712687Z","shell.execute_reply.started":"2021-06-22T02:43:53.15651Z","shell.execute_reply":"2021-06-22T02:43:56.711869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación se imprime el puntaje de acierto de cada división del dataset realizada con KFold.","metadata":{}},{"cell_type":"code","source":"scores = model_selection.cross_val_score(clasificador, X_train, y_train, cv=kf, scoring=\"accuracy\")\nprint(\"Precision K-fold:\", scores)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:43:56.713989Z","iopub.execute_input":"2021-06-22T02:43:56.714465Z","iopub.status.idle":"2021-06-22T02:44:29.689184Z","shell.execute_reply.started":"2021-06-22T02:43:56.714417Z","shell.execute_reply":"2021-06-22T02:44:29.688334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente se imprime el reporte de clasificación de la clasificación realizada y la matriz de confusión. La clasificación siempre ronda el 60% de acierto, con el clasificador que mejor funciona. Esto puede ser porque las ventas de juegos muchas veces pueden ser impredecibles. Sobre todo en consolas más recientes como PS3, PS4, Xbox 360 o Xbox One los generos que venden mucho un año, o la editora que fue exitosa un año puede tener un bajón al año siguiente y juegos que venden muy bien en Japón, pueden no vender bien en Europa y Norte América o viceversa. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nreporte = classification_report(y_test,predictions)\nmatriz = confusion_matrix(y_test,predictions)\n\nprint(reporte)\n#print(matriz)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:44:29.690459Z","iopub.execute_input":"2021-06-22T02:44:29.690737Z","iopub.status.idle":"2021-06-22T02:44:29.845795Z","shell.execute_reply.started":"2021-06-22T02:44:29.690709Z","shell.execute_reply":"2021-06-22T02:44:29.844695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para hacer el clasificador utilizando Pipeline, primero se importa el dataset y se realiza la división de columnas de datos y columna objetivo. ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv ('../input/videogamesales/vgsales.csv')\npd.set_option('max_columns', None)\ndf = df.replace(np.nan,\"0\")\n\nX = df[['Publisher', 'Genre','Year','NA_Sales','JP_Sales','EU_Sales','Other_Sales','Global_Sales']]\ny = df['Platform']","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:44:29.847424Z","iopub.execute_input":"2021-06-22T02:44:29.847846Z","iopub.status.idle":"2021-06-22T02:44:29.920365Z","shell.execute_reply.started":"2021-06-22T02:44:29.847787Z","shell.execute_reply":"2021-06-22T02:44:29.919133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"para las columnas numericas se utiliza el mismo preprocesamiento, MinMaxScaler, StandardScaler y se realiza un Pipeline para preprocesar estas columnas. Para las categoricas solo se utiliza OneHotEncoder, porque LabelEncoder da problemas con el número de parametros.","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nnumericas = ['Year','NA_Sales','JP_Sales','EU_Sales','Other_Sales','Global_Sales']\nnumeric_transformer = Pipeline(steps=[('minmax',MinMaxScaler()),('scaler', StandardScaler())])\n\nfrom sklearn.preprocessing import OneHotEncoder\ncategoricas = ['Publisher', 'Genre']\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:44:29.921731Z","iopub.execute_input":"2021-06-22T02:44:29.92207Z","iopub.status.idle":"2021-06-22T02:44:29.928498Z","shell.execute_reply.started":"2021-06-22T02:44:29.922033Z","shell.execute_reply":"2021-06-22T02:44:29.927342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación se utiliza ColumnTransformer para unir las columnas categoricas y numéricas. ","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[('cat', categorical_transformer, categoricas),('num', numeric_transformer, numericas)])","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:44:29.929846Z","iopub.execute_input":"2021-06-22T02:44:29.930155Z","iopub.status.idle":"2021-06-22T02:44:29.943671Z","shell.execute_reply.started":"2021-06-22T02:44:29.930125Z","shell.execute_reply":"2021-06-22T02:44:29.942661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se prepara el pipeline con el columntransformer y el clasificador, se utilizó DecisionTree para ver la diferencia con RandomForest. A continuación se realiza la separación para train y test.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\npipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', DecisionTreeClassifier())])\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:44:29.94596Z","iopub.execute_input":"2021-06-22T02:44:29.946297Z","iopub.status.idle":"2021-06-22T02:44:29.963615Z","shell.execute_reply.started":"2021-06-22T02:44:29.946264Z","shell.execute_reply":"2021-06-22T02:44:29.962736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finalmente se realiza la clasificación y se imprime el puntaje. Un acierto menor pero se acerca a la precisión de RandomForest.","metadata":{}},{"cell_type":"code","source":"pipe.fit(X_train, y_train)\nprint('Puntaje clasificador:', pipe.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-22T02:44:29.964719Z","iopub.execute_input":"2021-06-22T02:44:29.96508Z","iopub.status.idle":"2021-06-22T02:44:30.577027Z","shell.execute_reply.started":"2021-06-22T02:44:29.965048Z","shell.execute_reply":"2021-06-22T02:44:30.576167Z"},"trusted":true},"execution_count":null,"outputs":[]}]}