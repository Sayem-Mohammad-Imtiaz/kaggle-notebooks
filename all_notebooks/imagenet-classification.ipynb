{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.metrics import accuracy_score\nimport os\nimport scipy.io\nimport math\n\nfrom sklearn.utils import shuffle\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\nfrom tensorflow.keras.applications import resnet50\nfrom keras.preprocessing import image\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nfrom keras.applications.imagenet_utils import preprocess_input, decode_predictions\n\nimport tensorflow as tf\nfrom keras.preprocessing import image\n\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import spatial\nfrom tqdm import tqdm\n\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"resnet50_model = resnet50.ResNet50(weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"styles = pd.read_csv('/kaggle/input/fashion-product-images-dataset/fashion-dataset/styles.csv', error_bad_lines=False)\n\nshirts = styles[styles['articleType'].isin(['Shirts'])]\ntshirts = styles[styles['articleType'].isin(['Tshirts'])]\npants =  styles[styles['articleType'].isin(['Track Pants','Shorts', 'Trunk', 'Trousers', 'Track Pants', 'Tights', 'Lounge Pants', 'Lounge Shorts', 'Leggings', 'Jeans', 'Jeggings'])]\n# np.unique(styles['articleType'])\nshirts, tshirts, pants = shirts['id'].to_numpy(), tshirts['id'].to_numpy(), pants['id'].to_numpy()\nshirts.shape, tshirts.shape, pants.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Constants","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = '/kaggle/input/fashion-product-images-dataset/fashion-dataset/images/'\n\nIMG_SIZE = 224\nLIMIT_IMAGES = 2000\nNUM_OUTPUTS = 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Image Files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_imgs(names):\n    imgs = []\n    for i, image_name in enumerate(tqdm(names)):\n#         if i% 50 == 0 :\n#             print(f\"Loading Image {i}\")\n        try:\n            img = image.load_img(f'{image_path}{image_name}.jpg', target_size=(IMG_SIZE, IMG_SIZE))\n        except:\n            img = None\n        if img is None:\n            continue\n        img = np.array(img)\n        imgs.append(img)\n    return np.array(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Loading Images...\")\nprint(\"Shirts\")\nshirt_images = load_imgs(shirts[:LIMIT_IMAGES])\ngc.collect()\nprint(\"TShirts\")\ntshirt_images = load_imgs(tshirts[:LIMIT_IMAGES])\ngc.collect()\nprint(\"Pants\")\npant_images = load_imgs(pants[:LIMIT_IMAGES])\ngc.collect()\nprint(\"Done\")\nshirt_images.shape, tshirt_images.shape, pant_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_shirt_images, test_shirt_images, _, _ = train_test_split(shirt_images, np.repeat(0, shirt_images.shape[0]), test_size = 0.2)\ntrain_shirt_images.shape, test_shirt_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tshirt_images, test_tshirt_images, _, _ = train_test_split(tshirt_images, np.repeat(0, tshirt_images.shape[0]), test_size = 0.2)\ntrain_tshirt_images.shape, test_tshirt_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pant_images, test_pant_images, _, _ = train_test_split(pant_images, np.repeat(0, pant_images.shape[0]), test_size = 0.2)\ntrain_pant_images.shape, test_pant_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_vectors(imgs):\n    processed_batch = preprocess_input(imgs, mode=\"caffe\")\n    return resnet50_model.predict(processed_batch)\n\ndef get_average_vector(imgs):\n    vectors = get_vectors(imgs)\n    print(vectors.shape)\n    return np.mean(vectors, axis=0)\n\ndef closeness(a, b):\n#     print(a.shape)\n#     print(b.shape)\n    return 1 - spatial.distance.cosine(a, b)\n\ndef closest(vector, compared_to):\n    best = -5\n    best_idx = -1\n#     print(compared_to.shape)\n    for i, cmp in enumerate(compared_to):\n        c = closeness(vector, cmp)\n        if c > best:\n            best_idx = i\n            best = c\n    return best_idx, best\n\ndef b_closest(vectors, compared_to):\n    return np.array([closest(vector, compared_to)[0] for vector in vectors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Test And Train Sets\ntrain_X = np.concatenate((train_shirt_images, train_tshirt_images, train_pant_images), axis = 0)\ntrain_Y = np.repeat((0, 1, 2), (train_shirt_images.shape[0], train_tshirt_images.shape[0], train_pant_images.shape[0]), axis = 0)\n\ntrain_vecs = get_vectors(train_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X = np.concatenate((test_shirt_images, test_tshirt_images, test_pant_images), axis = 0)\ntest_Y = np.repeat((0, 1, 2), (test_shirt_images.shape[0], test_tshirt_images.shape[0], test_pant_images.shape[0]), axis = 0)\n\ntest_vecs = get_vectors(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Average Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shirt_vector = get_average_vector(train_shirt_images)\ntshirt_vector = get_average_vector(train_tshirt_images)\npant_vector = get_average_vector(train_pant_images)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_classes = decode_predictions(np.expand_dims(shirt_vector, axis=0), top=3)\npred_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_classes = decode_predictions(np.expand_dims(tshirt_vector, axis=0), top=3)\npred_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_classes = decode_predictions(np.expand_dims(pant_vector, axis=0), top=3)\npred_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_vector = np.array([shirt_vector, tshirt_vector, pant_vector])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_predictions = b_closest(train_vecs, test_vector)\n\ntrain_accuracy = accuracy_score(train_Y, train_predictions)\nprint(f\"In Sample Accuracy: {train_accuracy}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_predictions = b_closest(test_vecs, test_vector)\n\ntest_accuracy = accuracy_score(test_Y, test_predictions)\nprint(f\"Out Of Sample Accuracy: {test_accuracy}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NN To Classify","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx, trainy = shuffle(train_vecs, train_Y)\n# trainx = np.expand_dims(trainx, axis=1)\ntrainx.shape, trainy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim=1000, activation='relu'))\n    model.add(Dense(3, activation='softmax'))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classify_model = estimator.fit(trainx, trainy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = estimator.predict(train_vecs)\nacc = accuracy_score(train_Y, preds)\nprint(f\"In sample Accuracy: {acc}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = estimator.predict(test_vecs)\nacc = accuracy_score(test_Y, preds)\nprint(f\"Out of sample Accuracy: {acc}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator.model.save('/kaggle/working/keras-vlarge-963.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ADA to classify","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = AdaBoostClassifier(n_estimators=400, learning_rate=1)\nabcm = abc.fit(trainx, trainy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = abc.predict(train_vecs)\nacc = accuracy_score(train_Y, preds)\nprint(f\"In sample Accuracy: {acc}\")\n\nprint(classification_report(train_Y, preds))\n\npreds = abc.predict(test_vecs)\nacc = accuracy_score(test_Y, preds)\nprint(f\"Out of sample Accuracy: {acc}\")\n\nprint(classification_report(test_Y, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\npickle.dump(abc, open('/kaggle/working/ada-vvlarge-964.pickle', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DL for classify","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nfrom sklearn.preprocessing import MinMaxScaler    \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx, trainy = shuffle(train_vecs, train_Y)\ntrainx.shape, trainy.shape\ntx, vx, ty, vy = train_test_split(trainx, trainy, test_size = 0.2)\ntestx, testy = test_vecs.copy(), test_Y.copy()\ntx.shape, ty.shape, vx.shape, vy.shape, testx.shape, testy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\ntx = scaler.fit_transform(tx)\nvx = scaler.transform(vx)\ntestx = scaler.transform(testx)\n\ntx.shape, ty.shape, vx.shape, vy.shape, testx.shape, testy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 300\nBATCH_SIZE = 100\nLEARNING_RATE = 0.00007\nNUM_FEATURES = 1000\nNUM_CLASSES = NUM_OUTPUTS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MulticlassClassification(nn.Module):\n    def __init__(self, num_feature, num_class):\n        super(MulticlassClassification, self).__init__()\n        \n        self.layer_1 = nn.Linear(num_feature, 512)\n        self.layer_2 = nn.Linear(512, 128)\n        self.layer_3 = nn.Linear(128, 64)\n        self.layer_out = nn.Linear(64, num_class) \n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.2)\n        self.batchnorm1 = nn.BatchNorm1d(512)\n        self.batchnorm2 = nn.BatchNorm1d(128)\n        self.batchnorm3 = nn.BatchNorm1d(64)\n        \n    def forward(self, x):\n        x = self.layer_1(x)\n        x = self.batchnorm1(x)\n        x = self.relu(x)\n        \n        x = self.layer_2(x)\n        x = self.batchnorm2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_3(x)\n        x = self.batchnorm3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_out(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\ntorch_model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(torch_model.parameters(), lr=LEARNING_RATE)\nprint(torch_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_acc(y_pred, y_test):\n    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n    \n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() / len(correct_pred)\n    \n    acc = torch.round(acc) * 100\n    \n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_stats = {\n    'train': [],\n    \"val\": []\n}\nloss_stats = {\n    'train': [],\n    \"val\": []\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassifierDataset(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\ntrain_dataset = ClassifierDataset(torch.from_numpy(tx).float(), torch.from_numpy(ty).long())\nval_dataset = ClassifierDataset(torch.from_numpy(vx).float(), torch.from_numpy(vy).long())\ntest_dataset = ClassifierDataset(torch.from_numpy(testx).float(), torch.from_numpy(testy).long())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset=train_dataset,\n                          batch_size=BATCH_SIZE\n)\nval_loader = DataLoader(dataset=val_dataset, batch_size=1)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Begin training.\")\nfor e in tqdm(range(1, EPOCHS+1)):\n    # TRAINING\n    train_epoch_loss = 0\n    train_epoch_acc = 0\n    torch_model.train()\n    for X_train_batch, y_train_batch in train_loader:\n        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_train_pred = torch_model(X_train_batch)\n        \n        train_loss = criterion(y_train_pred, y_train_batch)\n        train_acc = multi_acc(y_train_pred, y_train_batch)\n        \n        train_loss.backward()\n        optimizer.step()\n        \n        train_epoch_loss += train_loss.item()\n        train_epoch_acc += train_acc.item()\n        \n        \n    # VALIDATION    \n    with torch.no_grad():\n        \n        val_epoch_loss = 0\n        val_epoch_acc = 0\n        \n        torch_model.eval()\n        for X_val_batch, y_val_batch in val_loader:\n            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n            \n            y_val_pred = torch_model(X_val_batch)\n                        \n            val_loss = criterion(y_val_pred, y_val_batch)\n            val_acc = multi_acc(y_val_pred, y_val_batch)\n            \n            val_epoch_loss += val_loss.item()\n            val_epoch_acc += val_acc.item()\n            loss_stats['train'].append(train_epoch_loss/len(train_loader))\n    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n                              \n    \n    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_list = []\nwith torch.no_grad():\n    torch_model.eval()\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = torch_model(X_batch)\n        y_pred_softmax = torch.log_softmax(y_test_pred, dim = 1)\n        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n        y_pred_list.append(y_pred_tags.cpu().numpy())\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(testy, y_pred_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(scaler, open('/kaggle/working/torch-vvlarge.scaler.pickle', 'wb'))\ntorch.save(torch_model.state_dict(), '/kaggle/working/torch-vvlarge.dict')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# New Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainx2, trainy2 = shuffle(train_vecs, train_Y)\ntrainx2.shape, trainy2.shape\ntx2, vx2, ty2, vy2 = train_test_split(trainx, trainy, test_size = 0.2)\ntestx2, testy2 = test_vecs.copy(), test_Y.copy()\ntx2.shape, ty2.shape, vx2.shape, vy2.shape, testx2.shape, testy2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\ntx2 = scaler.fit_transform(tx2)\nvx2 = scaler.transform(vx2)\ntestx2 = scaler.transform(testx2)\n\ntx2.shape, ty2.shape, vx2.shape, vy2.shape, testx2.shape, testy2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 300\nBATCH_SIZE = 100\nLEARNING_RATE = 0.00007\nNUM_FEATURES = 1000\nNUM_CLASSES = NUM_OUTPUTS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MulticlassClassification2(nn.Module):\n    def __init__(self, num_feature, num_class):\n        super(MulticlassClassification2, self).__init__()\n        \n        self.layer_1 = nn.Linear(num_feature, 512)\n        self.layer_2 = nn.Linear(512, 128)\n        self.layer_3 = nn.Linear(128, 256)\n        self.layer_4 = nn.Linear(256, 64)\n        self.layer_out = nn.Linear(64, num_class) \n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.2)\n        self.batchnorm1 = nn.BatchNorm1d(512)\n        self.batchnorm2 = nn.BatchNorm1d(128)\n        self.batchnorm3 = nn.BatchNorm1d(256)\n        self.batchnorm4 = nn.BatchNorm1d(64)\n        \n    def forward(self, x):\n        x = self.layer_1(x)\n        x = self.batchnorm1(x)\n        x = self.relu(x)\n        \n        x = self.layer_2(x)\n        x = self.batchnorm2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_3(x)\n        x = self.batchnorm3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_4(x)\n        x = self.batchnorm4(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        x = self.layer_out(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_model2 = MulticlassClassification2(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\ntorch_model2.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(torch_model2.parameters(), lr=LEARNING_RATE)\nprint(torch_model2)\n\n\n\ndef multi_acc(y_pred, y_test):\n    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n    \n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() / len(correct_pred)\n    \n    acc = torch.round(acc) * 100\n    \n    return acc\n\naccuracy_stats = {\n    'train': [],\n    \"val\": []\n}\nloss_stats = {\n    'train': [],\n    \"val\": []\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassifierDataset(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\ntrain_dataset2 = ClassifierDataset(torch.from_numpy(tx2).float(), torch.from_numpy(ty2).long())\nval_dataset2 = ClassifierDataset(torch.from_numpy(vx2).float(), torch.from_numpy(vy2).long())\ntest_dataset2 = ClassifierDataset(torch.from_numpy(testx2).float(), torch.from_numpy(testy2).long())\n\ntrain_loader2 = DataLoader(dataset=train_dataset2,\n                          batch_size=BATCH_SIZE\n)\nval_loader2 = DataLoader(dataset=val_dataset2, batch_size=1)\ntest_loader2 = DataLoader(dataset=test_dataset2, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Begin training.\")\nfor e in tqdm(range(1, EPOCHS+1)):\n    gc.collect()\n    # TRAINING\n    train_epoch_loss = 0\n    train_epoch_acc = 0\n    torch_model2.train()\n    for X_train_batch, y_train_batch in train_loader2:\n        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n        optimizer.zero_grad()\n        \n        y_train_pred = torch_model2(X_train_batch)\n        \n        train_loss = criterion(y_train_pred, y_train_batch)\n        train_acc = multi_acc(y_train_pred, y_train_batch)\n        \n        train_loss.backward()\n        optimizer.step()\n        \n        train_epoch_loss += train_loss.item()\n        train_epoch_acc += train_acc.item()\n        \n        \n    # VALIDATION    \n    with torch.no_grad():\n        \n        val_epoch_loss = 0\n        val_epoch_acc = 0\n        \n        torch_model2.eval()\n        for X_val_batch, y_val_batch in val_loader:\n            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n            \n            y_val_pred = torch_model2(X_val_batch)\n                        \n            val_loss = criterion(y_val_pred, y_val_batch)\n            val_acc = multi_acc(y_val_pred, y_val_batch)\n            \n            val_epoch_loss += val_loss.item()\n            val_epoch_acc += val_acc.item()\n            loss_stats['train'].append(train_epoch_loss/len(train_loader))\n    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n                              \n    gc.collect()\n    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_list = []\nwith torch.no_grad():\n    torch_model2.eval()\n    for X_batch, _ in test_loader2:\n        X_batch = X_batch.to(device)\n        y_test_pred = torch_model2(X_batch)\n        y_pred_softmax = torch.log_softmax(y_test_pred, dim = 1)\n        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n        y_pred_list.append(y_pred_tags.cpu().numpy())\ny_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n\nprint(classification_report(testy, y_pred_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(scaler, open('/kaggle/working/torch-2-vlarge.scaler.pickle', 'wb'))\ntorch.save(torch_model2.state_dict(), '/kaggle/working/torch-2-vlarge.dict')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img(names):\n    print(names)\n    imgs = []\n    for i, image_name in enumerate(names):\n        if i% 50 == 0 :\n            print(f\"Loading Image {i}\")\n        img = image.load_img(f'/kaggle/input/vernacular-set/{image_name}.jpeg', target_size=(IMG_SIZE, IMG_SIZE))\n        if img is None:\n            continue\n        img = np.array(img)\n        imgs.append(img)\n    return np.array(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_imgs = load_img(list(range(1,17)))\npred_imgs.shape\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_vecs = get_vectors(pred_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = abc.predict(pred_vecs)\nmap_to_names = lambda x: map(lambda y: \"Shirt\" if y == 0 else \"T-Shirt\" if y == 1 else \"Pant\", x)\npred_results = list(zip(map_to_names([0,1,0,0,0,0,1,0,1,1,1,0,2,2,0,0]), map_to_names(preds)))\nprint(pred_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for result, image in zip(pred_results, pred_imgs):\n    plt.figure()\n    plt.title(f\"Actual: {result[0]} | Predicted: {result[1]}\")\n    plt.imshow(image)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}