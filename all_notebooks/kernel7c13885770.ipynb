{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding treatment feature according to the medication prescribed"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing diabetes data\ndata = pd.read_csv('C:/Users/makam/Desktop/Capstone Project/diabetic_data.csv')\ndata1 = pd.read_csv('C:/Users/makam/Desktop/Capstone Project/diabetic_data.csv')\n#Now we label encode the values for the drug columns.\ndrugs = ['metformin',\n       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol',\n       'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin',\n       'glyburide-metformin', 'glipizide-metformin',\n       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n       'metformin-pioglitazone']\ndrug_d = pd.DataFrame()\nfor x in drugs:\n    del data1[x]\n    drug_d[x]=data[x]\n    mapping_dict={x:{'No':0,'Down':1,'Steady':1,'Up':1}}\n    drug_d.replace(mapping_dict,inplace=True)\n    \n#One hot encoding other columns in diabetes data\ncont = pd.get_dummies(data1['max_glu_serum'],prefix='max_glu_serum',drop_first=False)\n#Adding the results to the master dataframe\ndata1 = pd.concat([data1,cont],axis=1)\ndel data1['max_glu_serum']\n\ncont = pd.get_dummies(data1['A1Cresult'],prefix='A1Cresult',drop_first=False)\n#Adding the results to the master dataframe\ndata1 = pd.concat([data1,cont],axis=1)\ndel data1['A1Cresult']\n\ncont = pd.get_dummies(data1['change'],prefix='change',drop_first=False)\n#Adding the results to the master dataframe\ndata1 = pd.concat([data1,cont],axis=1)\ndel data1['change']\n\n\ndata1['diabetesMed'].replace({'No':0,'Yes':1},inplace=True)\n\ncont = pd.get_dummies(data1['readmitted'],prefix='readmitted',drop_first=False)\n#Adding the results to the master dataframe\ndata1 = pd.concat([data1,cont],axis=1)\ndel data1['readmitted']\n\n\n#We will now check which encounters are having combination of insulin & which are having solo insulin treatment.\ndrug_d['encounter_id']=data['encounter_id']\nids = data['encounter_id']\nids1 = pd.DataFrame(ids)\nids1['key'] = ids1.index\ndrug_dt=drug_d.T\ninsulin_data = drug_d['insulin']\ndrug_dt.drop(['insulin'],inplace=True)\ncols = drug_dt.columns.values.tolist()\ndrug_dt.drop(['encounter_id'],inplace=True)\nno_combo=[]\ncombo=[]\nfor x in cols:\n    if(drug_dt[x].sum()==0):\n        no_combo.append(x)\n    else:\n        combo.append(x)\ncombo1 = pd.DataFrame(combo)\ncombo1.rename(columns={0:'key'},inplace=True)\ncombo2 = pd.merge(combo1,ids1,on='key',how='inner')\ndel combo2['key']\nno_combo1 = pd.DataFrame(no_combo)\nno_combo1.rename(columns={0:'key'},inplace=True)\nno_combo2 = pd.merge(no_combo1,ids1,on='key',how='inner')\ndel no_combo2['key']\nins_data=pd.DataFrame(insulin_data,columns=['insulin'])\nins_data['encounter_id']=data['encounter_id']\ncombo3 = pd.merge(combo2,ins_data,on='encounter_id',how='inner')\nno_combo3 = pd.merge(no_combo2,ins_data,on='encounter_id',how='inner')\nno_diabetes = no_combo3[no_combo3['insulin']==0]\ntype1 = no_combo3[no_combo3['insulin']!=0]\ntype2 = combo3[combo3['insulin']==0]\nt1t2 = combo3[combo3['insulin']!=0]\n\n\nno_diabetes['treatment']=0\ntype1['treatment']=1\ntype2['treatment']=0\nt1t2['treatment']=1\n\n\ndiabetes = pd.merge(drug_d,data1,on='encounter_id',how='inner')\n\n\n\n#Reading pateint data & one hot encoding the features.\npatient_data = pd.read_excel('C:/Users/makam/Desktop/Capstone Project/Paitent_details.xlsx')\ndf1 = pd.merge(patient_data,data,on='encounter_id',how='inner')\n\ncont = pd.get_dummies(patient_data['race'],prefix='race',drop_first=False)\n#Adding the results to the master dataframe\npatient_data = pd.concat([patient_data,cont],axis=1)\ndel patient_data['race']\n\ncont = pd.get_dummies(patient_data['gender'],prefix='gender',drop_first=False)\n#Adding the results to the master dataframe\npatient_data = pd.concat([patient_data,cont],axis=1)\ndel patient_data['gender']\n\n\npatient_data['age'].replace({'[70-80)':7,'[60-70)':6,'[50-60)':5,'[80-90)':8,'[40-50)':4,'[30-40)':3,'[90-100)':9,'[20-30)':2,'[10-20)':1,'[0-10)':0},inplace=True)\ndel patient_data['weight']\nfinal_diabetes = pd.merge(patient_data,diabetes,on='encounter_id',how='inner')\nndc = pd.merge(no_diabetes['encounter_id'],final_diabetes,on='encounter_id',how='inner')\nt1 = pd.merge(type1['encounter_id'],final_diabetes,on='encounter_id',how='inner')\nt2= pd.merge(type2['encounter_id'],final_diabetes,on='encounter_id',how='inner')\nt12 = pd.merge(t1t2['encounter_id'],final_diabetes,on='encounter_id',how='inner')\n\nndc['treatment']=0\nt1['treatment']=1\nt2['treatment']=0\nt12['treatment']=1\n\nNDC = pd.merge(no_diabetes[['encounter_id','treatment']],df1,on='encounter_id',how='inner')\nT1 = pd.merge(type1[['encounter_id','treatment']],df1,on='encounter_id',how='inner')\nT2= pd.merge(type2[['encounter_id','treatment']],df1,on='encounter_id',how='inner')\nT12 = pd.merge(t1t2[['encounter_id','treatment']],df1,on='encounter_id',how='inner')\n\ndiabetes = pd.concat([t1,t2,t12])\norg_diabetes = pd.concat([NDC,T1,T2,T12])\n#We can now delete all the drug columns as we have captured the data in treatment column.\nfor x in drugs:\n    del diabetes[x]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We will now merge admission details data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"d = pd.read_excel('C:/Users/makam/Desktop/Capstone Project/admission_details.xlsx')\ndel d['patient_nbr']\n#We will do label encoding for the columns.\nd['payer_code'].replace({'?':'Others'},inplace=True)\nd['medical_specialty'].replace({'?':'Others'},inplace=True)\n\ncont = pd.get_dummies(d['payer_code'],prefix='payer_code',drop_first=False)\n#Adding the results to the master dataframe\nd = pd.concat([d,cont],axis=1)\ndel d['payer_code']\n\ndel d['medical_specialty']\n\ncont = pd.get_dummies(d['admission_type_id'],prefix='admission_type_id',drop_first=False)\n#Adding the results to the master dataframe\nd = pd.concat([d,cont],axis=1)\ndel d['admission_type_id']\n\ncont = pd.get_dummies(d['discharge_disposition_id'],prefix='discharge_disposition_id',drop_first=False)\n#Adding the results to the master dataframe\nd = pd.concat([d,cont],axis=1)\ndel d['discharge_disposition_id']\n\ncont = pd.get_dummies(d['admission_source_id'],prefix='admission_source_id',drop_first=False)\n#Adding the results to the master dataframe\nd = pd.concat([d,cont],axis=1)\ndel d['admission_source_id']\n\n\ndiabetes1 = pd.merge(diabetes,d,on='encounter_id',how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(diabetes1.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging lab session data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"d1 = pd.read_excel('C:/Users/makam/Desktop/Capstone Project/Lab-session.xlsx')\ndiabetes2 = pd.merge(diabetes1,d1,on='encounter_id',how='inner')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging diagnosis session data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\ndig_d = pd.read_excel('C:/Users/makam/Desktop/Capstone Project/Diagnosis_session.xlsx')\n'''\ner = pd.concat([dig_d['diag_1'],dig_d['diag_2'],dig_d['diag_3']],axis=0).tolist()\ny = 0\nfor x in er:\n    er[y] = str(x)\n    y = y+1\ner1 = pd.DataFrame(er)\nl = LabelEncoder()\nl.fit(er1[0])\ny = 0\nl1 = dig_d['diag_1'].tolist()\nl2 = dig_d['diag_2'].tolist()\nl3 = dig_d['diag_3'].tolist()\nfor x in l1:\n    l1[y] = str(x)\n    y = y+1\ny = 0\nfor x in l2:\n    l2[y] = str(x)\n    y = y+1\ny = 0\nfor x in l3:\n    l3[y] = str(x)\n    y = y+1\nm1 = l.transform(l1).tolist()\nm2 = l.transform(l2).tolist()\nm3 = l.transform(l3).tolist()\ndig_d['diag_1']=m1\ndig_d['diag_2']=m2\ndig_d['diag_3']=m3\ndel dig_d['patient_nbr']\n'''\ndf = pd.merge(diabetes2,dig_d[['encounter_id','number_diagnoses']],on='encounter_id',how='inner')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Readmission \nsns.countplot(df['treatment']).set_title('Distribution of Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5))\nsns.countplot(x= df['age'], hue = df['treatment']).set_title('Age of Patient VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(x = org_diabetes['race'], hue = org_diabetes['treatment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.barplot(x = df['treatment'], y = (df['num_medications'])).set_title(\"Number of medication used VS. Treatment\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(x = org_diabetes['max_glu_serum'], hue = org_diabetes['treatment']).set_title('Glucose test serum test result VS. Treatment')\n                                                                                            \n                                                                                            \n                                                                                            \n                                                                                            \n                                                                                                                                                                                                             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(x= org_diabetes['A1Cresult'], hue = org_diabetes['treatment']).set_title('A1C test result VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,8))\nsns.countplot(x= org_diabetes['treatment'], hue = org_diabetes['readmitted']).set_title('readmission VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,6),)\nax=sns.kdeplot(df.loc[(df['treatment'] == 0),'num_lab_procedures'] , color='b',shade=True,label='No Insulin')\nax=sns.kdeplot(df.loc[(df['treatment'] == 1),'num_lab_procedures'] , color='r',shade=True, label='Insulin Present')\nax.set(xlabel='Number of lab procedure', ylabel='Frequency')\nplt.title('Number of lab procedure VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(13,7),)\nax=sns.kdeplot(df.loc[(df['treatment'] == 0),'time_in_hospital'] , color='b',shade=True,label='No Insulin')\nax=sns.kdeplot(df.loc[(df['treatment'] == 1),'time_in_hospital'] , color='r',shade=True, label='Insulin present')\nax.set(xlabel='Time in Hospital', ylabel='Frequency')\nplt.title('Time in Hospital VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5),)\nax=sns.kdeplot(df.loc[(df['treatment'] == 0),'number_diagnoses'] , color='b',shade=True,label='No Insulin')\nax=sns.kdeplot(df.loc[(df['treatment'] == 1),'number_diagnoses'] , color='r',shade=True, label='Insulin present')\nax.set(xlabel='number_diagnoses', ylabel='Frequency')\nplt.title('number_diagnoses VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5),)\nax=sns.kdeplot(df.loc[(df['treatment'] == 0),'num_medications'] , color='b',shade=True,label='No Insulin')\nax=sns.kdeplot(df.loc[(df['treatment'] == 1),'num_medications'] , color='r',shade=True, label='Insulin present')\nax.set(xlabel='number_diagnoses', ylabel='Frequency')\nplt.title('num_medications VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,5),)\nax=sns.kdeplot(df.loc[(df['treatment'] == 0),'number_diagnoses'] , color='b',shade=True,label='No Insulin')\nax=sns.kdeplot(df.loc[(df['treatment'] == 1),'number_diagnoses'] , color='r',shade=True, label='Insulin present')\nax.set(xlabel='number_diagnoses', ylabel='Frequency')\nplt.title('number_diagnoses VS. Treatment')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performing chi-square analysis to identify imp features"},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stats\nfrom scipy.stats import chi2_contingency\nclass ChiSquare:\n    def __init__(self, dataframe):\n        self.df = dataframe\n        self.p = None #P-Value\n        self.chi2 = None #Chi Test Statistic\n        self.dof = None\n        \n        self.dfObserved = None\n        self.dfExpected = None\n        \n    def _print_chisquare_result(self, colX, alpha):\n        result = \"\"\n        if self.p<alpha:\n            result=\"{0} is IMPORTANT for Prediction\".format(colX)\n        else:\n            result=\"{0} is NOT an important predictor. (Discard {0} from model)\".format(colX)\n\n        print(result)\n        \n    def TestIndependence(self,colX,colY, alpha=0.05):\n        X = self.df[colX].astype(str)\n        Y = self.df[colY].astype(str)\n        \n        self.dfObserved = pd.crosstab(Y,X) \n        chi2, p, dof, expected = stats.chi2_contingency(self.dfObserved.values)\n        self.p = p\n        self.chi2 = chi2\n        self.dof = dof \n        \n        self.dfExpected = pd.DataFrame(expected, columns=self.dfObserved.columns, index = self.dfObserved.index)\n        \n        self._print_chisquare_result(colX,alpha)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cT = ChiSquare(df)\n#Feature Selection\ntestColumns = diabetes2.columns.values.tolist()\ntestColumns.remove('treatment')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for var in testColumns:\n    cT.TestIndependence(colX=var,colY=\"treatment\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cT1 = ChiSquare(org_diabetes)\ntestcolumns1 = org_diabetes.columns.values.tolist()\ntestcolumns1.remove('treatment')\nfor var in testcolumns1:\n    cT1.TestIndependence(colX=var,colY=\"treatment\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list = ['encounter_id', \n       'race_Hispanic', \n       'gender_Unknown/Invalid', 'diabetesMed', \n       'A1Cresult_>7',  'readmitted_>30',\n        'payer_code_CP', \n       'payer_code_FR',  'payer_code_OT',\n        'payer_code_WC',\n        'admission_type_id_4',\n        'discharge_disposition_id_2',\n       \n       'discharge_disposition_id_9', 'discharge_disposition_id_10'\n       , 'discharge_disposition_id_12',\n        'discharge_disposition_id_16',\n       'discharge_disposition_id_17',\n       'discharge_disposition_id_19', 'discharge_disposition_id_20',\n       'discharge_disposition_id_22', \n       'discharge_disposition_id_24', \n       'discharge_disposition_id_27', 'discharge_disposition_id_28',\n        'admission_source_id_6',\n       'admission_source_id_8',\n        'admission_source_id_10',\n       'admission_source_id_11', 'admission_source_id_13',\n       'admission_source_id_14','admission_source_id_22',\n       'admission_source_id_25']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in list:\n    del df[x]       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deleting non-imp features "},{"metadata":{},"cell_type":"markdown","source":"# Building base model"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop('treatment',axis=1)\ny = df['treatment']\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(random_state=100)\nfrom sklearn.ensemble import RandomForestClassifier\nmodel5 = RandomForestClassifier(random_state=100,n_estimators=85,max_features=7)\nprint(model5)\nfrom sklearn.ensemble import BaggingClassifier\nmodel1 = BaggingClassifier(bootstrap_features=True,n_estimators=100,random_state=100)\nprint(model1)\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3,random_state=100)\nmodel5.fit(xtrain,ytrain)\ny_pred_test= model5.predict(xtest)\nfrom sklearn.metrics import *\nprint('Testing set accuracy')\nprint(accuracy_score(ytest, y_pred_test))\nprint(confusion_matrix(ytest,y_pred_test))\ny_pred_train = model5.predict(xtrain)\nprint('Training set accuracy')\nprint(accuracy_score(ytrain, y_pred_train))\nprint(confusion_matrix(ytrain,y_pred_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\n\nm1=KNeighborsClassifier()\nm1.fit(xtrain,ytrain)\ny_pred_lr=m1.predict(xtest)\nTrain_Score_lr = m1.score(xtrain,ytrain)\nTest_Score_lr = accuracy_score(ytest,y_pred_lr)\n\n\nprint('Training Accuracy is:',Train_Score_lr)\nprint('Testing Accuracy is:',Test_Score_lr)\nprint(classification_report(ytest,y_pred_lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GridSearchCV to find optimal max_depth\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n\n# specify number of folds for k-fold CV\nn_folds = 3\n\n# parameters to build the model on\nparameters = {'max_depth': np.arange(1,5,1),\n    'min_samples_leaf': np.arange(1,15,1),\n    'min_samples_split': np.arange(2,5,1),\n    'criterion': [\"entropy\", \"gini\"]}\n\n# instantiate the model\ndtree = DecisionTreeClassifier(random_state = 100)\n\n# fit tree on training data\ntree = GridSearchCV(dtree, parameters, \n                    cv=n_folds, \n                   scoring=\"accuracy\")\ntree.fit(xtrain, ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier(random_state = 100,criterion= 'gini',max_depth= 4,min_samples_leaf= 14,min_samples_split= 2)\ndtree.fit(xtrain,ytrain)\ny_pred_test = dtree.predict(xtest)\nprint('Testing set accuracy')\nprint(accuracy_score(ytest, y_pred_test))\nprint(confusion_matrix(ytest,y_pred_test))\ny_pred_train = model5.predict(xtrain)\nprint('Training set accuracy')\nprint(accuracy_score(ytrain, y_pred_train))\nprint(confusion_matrix(ytrain,y_pred_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tuning KNeighbors Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gridsearch CV to find Optimal K value for KNN model\ngrid = {'n_neighbors':np.arange(1,50)}\nknn=KNeighborsClassifier()\nknn_cv=GridSearchCV(knn,grid,cv=3)\nknn_cv.fit(xtrain,ytrain)\n \n\nprint(\"Tuned Hyperparameter k: {}\".format(knn_cv.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1= KNeighborsClassifier(n_neighbors= 47)\nd1.fit(xtrain,ytrain)\ny_pred_test = d1.predict(xtest)\nprint('Testing set accuracy')\nprint(accuracy_score(ytest, y_pred_test))\nprint(confusion_matrix(ytest,y_pred_test))\ny_pred_train = d1.predict(xtrain)\nprint('Training set accuracy')\nprint(accuracy_score(ytrain, y_pred_train))\nprint(confusion_matrix(ytrain,y_pred_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}