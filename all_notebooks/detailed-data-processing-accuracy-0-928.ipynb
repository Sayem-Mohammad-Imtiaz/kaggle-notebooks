{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import the necessary packages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom scipy.stats import skew\nfrom scipy import stats\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy.sparse import hstack\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read the dataset and display top 5"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"filename = '../input/diabetes.csv'\ndata = pd.read_csv(filename)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Well, the data set has no null value"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From this result, we can see that the Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI all have a value of 0. But actually, can they be 0?  \n### I think Glucose,BloodPressure,SkinThickness,Insulin,BMI cannot be 0.  \n### fill the dataset with a median\n### First, the result of Outcome is 0 and 1 are calculated separately, because the results are different, maybe their values are different.\n### Second, the value of 0 is removed to calculate the median or average."},{"metadata":{"trusted":true},"cell_type":"code","source":"glucose_0 = data[data['Glucose'] > 0][data['Outcome'] == 0]['Glucose'].median()\nglucose_1 = data[data['Glucose'] > 0][data['Outcome'] == 1]['Glucose'].median()\nbloodPressure_0 = data[data['BloodPressure'] > 0][data['Outcome'] == 0]['BloodPressure'].median()\nbloodPressure_1 = data[data['BloodPressure'] > 0][data['Outcome'] == 1]['BloodPressure'].median()\nSkinThickness_0 = data[data['SkinThickness'] > 0][data['Outcome'] == 0]['SkinThickness'].median()\nSkinThickness_1 = data[data['SkinThickness'] > 0][data['Outcome'] == 1]['SkinThickness'].median()\ninsulin_0 = data[data['Insulin'] > 0][data['Outcome'] == 0]['Insulin'].median()\ninsulin_1 = data[data['Insulin'] > 0][data['Outcome'] == 1]['Insulin'].median()\nbmi_0 = data[data['BMI'] > 0][data['Outcome'] == 0]['BMI'].median()\nbmi_1 = data[data['BMI'] > 0][data['Outcome'] == 1]['BMI'].median()\n\nprint(glucose_0,glucose_1,bloodPressure_0,bloodPressure_1,SkinThickness_0,SkinThickness_1,insulin_0,insulin_1,bmi_0,bmi_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill median to the data set\ndata.loc[(data[\"Glucose\"]==0) & (data['Outcome']==0),'Glucose'] = glucose_0\ndata.loc[(data[\"Glucose\"]==0) & (data['Outcome']==1),'Glucose'] = glucose_1\n\ndata.loc[(data[\"BloodPressure\"]==0) & (data['Outcome']==0),'BloodPressure'] = bloodPressure_0\ndata.loc[(data[\"BloodPressure\"]==0) & (data['Outcome']==1),'BloodPressure'] = bloodPressure_1\n\ndata.loc[(data[\"SkinThickness\"]==0) & (data['Outcome']==0),'SkinThickness'] = SkinThickness_0\ndata.loc[(data[\"SkinThickness\"]==0) & (data['Outcome']==1),'SkinThickness'] = SkinThickness_1\n\ndata.loc[(data[\"Insulin\"]==0) & (data['Outcome']==0),'Insulin'] = insulin_0\ndata.loc[(data[\"Insulin\"]==0) & (data['Outcome']==1),'Insulin'] = insulin_1\n\ndata.loc[(data[\"BMI\"]==0) & (data['Outcome']==0),'BMI'] = bmi_0\ndata.loc[(data[\"BMI\"]==0) & (data['Outcome']==1),'BMI'] = bmi_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's look at the distribution of features"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,12))\n\nax1 = fig.add_subplot(3,3,1)\nax2 = fig.add_subplot(3,3,2)\nax3 = fig.add_subplot(3,3,3)\nax4 = fig.add_subplot(3,3,4)\nax5 = fig.add_subplot(3,3,5)\nax6 = fig.add_subplot(3,3,6)\nax7 = fig.add_subplot(3,3,7)\nax8 = fig.add_subplot(3,3,8)\n\nax1.hist(data['Pregnancies'])\nax1.set_title('Distribution of Pregnancies')\n\nax2.hist(data['Glucose'])\nax2.set_title('Distribution of Glucose')\n\nax3.hist(data['BloodPressure'])\nax3.set_title('Distribution of BloodPressure')\n\nax4.hist(data['SkinThickness'])\nax4.set_title('Distribution of SkinThickness')\n\nax5.hist(data['Insulin'])\nax5.set_title('Distribution of Insulin')\n\nax6.hist(data['BMI'])\nax6.set_title('Distribution of BMI')\n\nax7.hist(data['DiabetesPedigreeFunction'])\nax7.set_title('Distribution of DiabetesPedigreeFunction')\n\nax8.hist(data['Age'])\nax8.set_title('Distribution of Age')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the above figure, we can see that some of the data is not normally distributed. \n### Let us look at the skewness value of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"skewed_feats = data.drop('Outcome', axis = 1).apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Filter out features with a skewness greater than 0.75"},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness = skewness[abs(skewness) > 0.75]\nskewness","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The Box-Cox transformation is a generalized power transformation method proposed by Box and Cox in 1964. It is a kind of data transformation commonly used in statistical modeling for the case where continuous response variables do not satisfy the normal distribution.  \n###  Here we use the scipy boxcox1p function for Box-Cox transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.245\nfor feat in skewed_features:\n    data[feat] = boxcox1p(data[feat], lam)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separate X and y"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['Outcome'].values\nX = data.drop('Outcome', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compared with before doing data processing, the variance is much smaller.\n### Label the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use pandas.cut() function to label the data set\nX1=pd.DataFrame()\nX1[\"Pregnancies\"] =pd.cut(X[\"Pregnancies\"],3,labels=[1,2,3]).astype(int)\nX1[\"Glucose\"] =pd.cut(X[\"Glucose\"],3,labels=[1,2,3]).astype(int)\nX1[\"BloodPressure\"] =pd.cut(X[\"BloodPressure\"],3,labels=[1,2,3]).astype(int)\nX1[\"SkinThickness\"] =pd.cut(X[\"SkinThickness\"],3,labels=[1,2,3]).astype(int)\nX1[\"Insulin\"] =pd.cut(X[\"Insulin\"],3,labels=[1,2,3]).astype(int)\nX1[\"BMI\"] =pd.cut(X[\"BMI\"],3,labels=[1,2,3]).astype(int)\nX1[\"DiabetesPedigreeFunction\"] =pd.cut(X[\"DiabetesPedigreeFunction\"],3,labels=[1,2,3]).astype(int)\nX1[\"Age\"] = pd.cut(X[\"Age\"],3,labels=[1,2,3]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Vectorization of categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = list(X1.columns)\n\n#The data type becomes object before it can be processed by get_dummies\nfor col in categorical_features:\n    X1[col] = X1[col].astype('object')\n    \nX1 = pd.get_dummies(X1[categorical_features])\nX1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([X, X1], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Randomly sample 20% of the data to build test samples, and the rest as training samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train, y, random_state=64, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use the LogisticRegression to build the model\n### Use cross_val_score to calculate the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(solver = 'liblinear')\nloss = cross_val_score(lr, X_train, y_train, cv=10, scoring='accuracy')\nprint( 'accuracy of each fold is:\\n',loss)\nprint('cv accuracy is:', loss.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parameter tuning on LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"penaltys = ['l1','l2']\nCs = [0.001, 0.01, 0.1,0.2, 1, 1.01, 4, 10, 100]\n#Cs = [x for x in range(1,100)]\ntuned_parameters = dict(penalty = penaltys, C = Cs)\n\nlr_penalty= LogisticRegression(solver = 'liblinear')\ngrid= GridSearchCV(lr_penalty, tuned_parameters,cv=10, scoring='accuracy')\ngrid.fit(X_train,y_train)\nprint('accuracy on train data set:',grid.score(X_train,y_train))\nprint('best_score_:',grid.best_score_)\nprint('best_params_:',grid.best_params_)\nprint('accuracy on test data set',grid.score(X_test,y_test))\nprint('confusion_matrix:\\n',metrics.confusion_matrix(y_test,grid.predict(X_test), labels=[1, 0]))\nprint('classification_report:\\n',metrics.classification_report(y_test, grid.predict(X_test), labels=[1,0], digits=4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use the LinearSVC to build the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC1 = LinearSVC().fit(X_train, y_train)\n\n#Test on the check set to estimate model performance\ny_predict = SVC1.predict(X_test)\n\ny_train_predict = SVC1.predict(X_train)\nprint('*' * 40,'train data set','*' * 40)\nprint(\"Classification report for classifier %s:\\n%s\\n\"\n      % (SVC1, metrics.classification_report(y_train,y_train_predict)))\nprint(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_train, y_train_predict))\nprint('*' * 40,'test data set','*' * 40 )\nprint(\"Classification report for classifier %s:\\n%s\\n\"\n      % (SVC1, metrics.classification_report(y_test, y_predict)))\nprint(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parameter tuning on LinearSVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_grid_point_Linear(C, X_train, y_train, X_val, y_val):\n    # Train the model on the training data set\n    SVC2 = LinearSVC(C=C)\n    SVC2.fit(X_train, y_train)\n\n    # Return accuracy on the checksum\n    accuracy = SVC2.score(X_val, y_val)\n    return accuracy\n\n# Parameters that need to be optimized\n# C_s = [0.001, 0.01, 0.1,0.2, 1,1.01, 10, 100, 1000]\nC_s = [x/10 for x in range(1,100)]\n\naccuracy_s = []\nfor i, oneC in enumerate(C_s):\n    tmp = fit_grid_point_Linear(oneC, X_train, y_train, X_test, y_test)\n    accuracy_s.append(tmp)\n\nx_axis = np.log10(C_s)\n\nplt.plot(x_axis, np.array(accuracy_s), 'b-')\n\nplt.legend()\nplt.xlabel('log(C)')\nplt.ylabel('accuracy')\n\nplt.show()\nprint(max(accuracy_s))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}