{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Churn (attrition) de clients Telecom"},{"metadata":{},"cell_type":"markdown","source":"On veut prédire le départ de clients d'un opérateur telecom à partir de données comme la formule d'abonnement, ou le temps de communication consommé.\n\nOn peut trouver le dataset sur :  \nhttps://www.kaggle.com/mnassrib/telecom-churn-datasets \n"},{"metadata":{},"cell_type":"markdown","source":"## Librairies et fonctions utiles"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"# Pandas : librairie de manipulation de données\n# NumPy : librairie de calcul scientifique\n# MatPlotLib : librairie de visualisation et graphiques\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.core.display import HTML # permet d'afficher du code html dans jupyter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour standardiser les données quantitatives (cont_feat est une liste des colonnes correspondant à des caractéristiques quantitatives) :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_feat(df,cont_feat) :\n    df1=df\n    scaler = preprocessing.RobustScaler()\n    df1[cont_feat] = scaler.fit_transform(df1[cont_feat])\n    return df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour tracer les courbes d'apprentissage sur l'ensemble d'apprentissage et l'ensemble de validation :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\ndef plot_learning_curve(est, X_train, y_train) :\n    train_sizes, train_scores, test_scores = learning_curve(estimator=est, X=X_train, y=y_train, train_sizes=np.linspace(0.1, 1.0, 10),\n                                                        cv=5,\n                                                        n_jobs=-1)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.figure(figsize=(8,10))\n    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training accuracy')\n    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n    plt.plot(train_sizes, test_mean,color='green', linestyle='--',marker='s', markersize=5,label='validation accuracy')\n    plt.fill_between(train_sizes,test_mean + test_std,test_mean - test_std,alpha=0.15, color='green')\n    plt.grid(b='on')\n    plt.xlabel('Number of training samples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim([0.6, 1.0])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fonction pour tracer la courbe ROC :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(est,X_test,y_test) :\n    probas = est.predict_proba(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,probas[:, 1])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.figure(figsize=(8,8))\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n    plt.legend(loc='lower right')\n    plt.plot([0,1],[0,1],'r--')        # plus mauvaise courbe\n    plt.plot([0,0,1],[0,1,1],'g:')     # meilleure courbe\n    plt.xlim([-0.05,1.2])\n    plt.ylim([-0.05,1.2])\n    plt.ylabel('Taux de vrais positifs')\n    plt.xlabel('Taux de faux positifs')\n    plt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Traitement du dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/telecom-churn-datasets/churn-bigml-80.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On mappe les valeurs de la colonne cible en 0/1 :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Churn'] = df['Churn'].map({ False: 0, True: 1 })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discr_feat = ['State', 'International plan', 'Voice mail plan', 'Customer service calls','Area code', 'Number vmail messages']\ncont_feat = list(set(df.columns) - set(discr_feat)-{'Churn'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On convertit les catégories en étiquettes numériques :"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in discr_feat :\n    df[col]=df[col].astype('category')\n    df[col] = df[col].cat.codes\n    df[col]=df[col].astype('int8')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On vérifie s'il y a des valeurs indéterminées dans le dataset :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().values.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Les valeurs numériques ont des caractéristiques très différentes :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cont_feat].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On normalise ces valeurs :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=scale_feat(df,cont_feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cont_feat].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On affiche les distributions des valeurs continues :"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cont_feat :\n    plt.figure(figsize=[10,5])\n    sns.kdeplot(df[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Est-il nécessaire d'appliquer une transformation sur les distributions ?"},{"metadata":{},"cell_type":"markdown","source":"## Forêts aléatoires"},{"metadata":{},"cell_type":"markdown","source":"On construit les ensembles d'apprentissage et de test :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['Churn'], axis=1)\ny = df.Churn\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On teste les forêts aléatoires :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\n\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sous-échantillonage"},{"metadata":{},"cell_type":"markdown","source":"Il y a beaucoup moins de clients qui partent que de clients qui restent (heureusement pour l'opérateur ...) :"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Churn.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On va garder autant de clients fidèles que de churners dans l'ensemble d'apprentissage (X_train), en tirant aléatoirement ceux qu'on va garder\nOn dit qu'on \"sous-échantillonne la classe majoritaire\""},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler \n\nrus = RandomUnderSampler()\nX_train, y_train = rus.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On vérifie qu'on a bien équilibré l'ensemble d'apprentissage :"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On applique les forêts aléatoires sur le nouvel ensemble d'apprentissage"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)\n\nprint(classification_report(y_test, y_rf))\n\ncm = confusion_matrix(y_test, y_rf)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On a moins de données d'apprentissage, mais les résultats sont plutôt meilleurs ..."},{"metadata":{},"cell_type":"markdown","source":"## Suréchantillonnage"},{"metadata":{},"cell_type":"markdown","source":"On va rééquilibrer le dataset en sur-échantillonnant la classe minoritaire :"},{"metadata":{},"cell_type":"markdown","source":"La méthode SMOTE (Synthetic Minority Oversampling TEchnique) consiste à synthétiser des éléments pour la classe minoritaire, à partir de ceux qui existent déjà. Elle fonctionne en choisissant au hasard un point de la classe minoritaire et en calculant les k-voisins les plus proches pour ce point. Les points synthétiques sont ajoutés entre le point choisi et ses voisins."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/rafjaa/machine_learning_fecib/master/src/static/img/smote.png\">"},{"metadata":{},"cell_type":"markdown","source":"On crée donc de \"fausses données\" (mais \"vraisemblables\") pour l'apprentissage"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Churn'], axis=1)\ny = df.Churn\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nX_train, y_train = smote.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On a bien équilibré l'ensemble d'apprentissage (en \"ajoutant\" des données) :"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On teste les forêts aléatoires avec les données suréchantillonnées :"},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_rf))","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Que pensez-vous de cette matrice de confusion ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(rf, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(rf,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extreme Gradient Boosting : XGBoost avec suréchantillonage SMOTE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\nprint(xgb.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_xgb = xgb.predict(X_test)\n\nprint(classification_report(y_test, y_xgb))\n\ncm = metrics.confusion_matrix(y_test, y_xgb)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(xgb, X_train, y_train)\nplot_roc_curve(xgb,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_xgb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost pondéré"},{"metadata":{},"cell_type":"markdown","source":"On va utiliser une amélioration de la méthode XGBoost, sans suréchantillonage"},{"metadata":{},"cell_type":"markdown","source":"On reconstitue les jeux de données sans échantillonnage :"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Churn'], axis=1)\ny = df.Churn\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Churn.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On utilise le paramètre *scale_pos_weight* pour donner plus d'impact aux erreurs commises sur la classe minoritaire :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier(scale_pos_weight=2278/388)\n# xgb = XGBClassifier()\nxgb.fit(X_train,y_train)\ny_xgb = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_xgb))\ncm = confusion_matrix(y_test, y_xgb)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(xgb, X_train, y_train)\nplot_roc_curve(xgb,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exercice : détection de fraude"},{"metadata":{},"cell_type":"markdown","source":"Prédire les fraudes à la carte bancaire sur le dataset :  \nhttps://www.kaggle.com/mlg-ulb/creditcardfraud"},{"metadata":{},"cell_type":"markdown","source":"*Ces données contiennent les transactions effectuées par carte de crédit en septembre 2013 par les détenteurs de cartes européennes.\nCet ensemble de données présente les transactions qui ont eu lieu en deux jours, où nous avons 492 fraudes sur 284 807 transactions. L'ensemble de données est très déséquilibré, la classe positive (fraudes) représente 0,172 % de toutes les transactions.*\n\n*Il ne contient que des variables d'entrée numériques qui sont le résultat d'une transformation ACP (analyse en composantes principales - une méthode de réduction de dimension). Malheureusement, pour des raisons de confidentialité, nous ne pouvons pas fournir les caractéristiques originales et plus d'informations sur le contexte des données. Les caractéristiques V1, V2, ... V28 sont les principales composantes obtenues avec l'ACP, les seules caractéristiques qui n'ont pas été transformées avec l'ACP sont \"Temps\" et \"Montant\". La caractéristique \"Temps\" contient les secondes écoulées entre chaque transaction et la première transaction de l'ensemble de données. La caractéristique \"Montant\" est le montant de la transaction, cette caractéristique peut être utilisée par exemple pour l'apprentissage dépendant des coûts. La caractéristique \n\"Class\" est la variable de réponse et prend la valeur 1 en cas de fraude et 0 dans le cas contraire.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}