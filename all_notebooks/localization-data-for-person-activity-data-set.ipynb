{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing few libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing dataset\n\ndata = pd.read_csv(\"../input/posture-reconstruction/ConfLongDemo_JSI.csv\", header=None)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head() #Let;'s see how data look's like","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Changing the names of columns according to given data description\n\ndata.columns = ['Sequence_Name', 'Tag_identificator', 'timestamp', 'date_FORMAT', \n                'x_coordinate', 'y_coordinate', 'z_coordinate', 'activity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info() #Lets see if their is any Null Values and Dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all').T # It describes the data acc. to Mean, Median, percentile etc and Unique values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 25 Unique Sequence Name\n\n4 Unique Tag_identifier\n\n11 Unique Activities"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = data.select_dtypes(include='object').columns.to_list() # Extracting all categorical values to list\ncat.remove(\"date_FORMAT\") # Removing Date \nfor i in cat:\n    print(\"Name of {} col\".format(i)) # Name of Column\n    print(\"No. of NUnique\", data[i].nunique()) # Total Nunique Values\n    print(\"Unique Values\", data[i].unique()) # All unique values\n    print('*'*30)\n    print()\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoding(df):\n    '''\n    Encoding all Categorical Values to Label\n    '''\n    from sklearn.preprocessing import LabelEncoder\n\n    tag_encoder = LabelEncoder()\n    sequence_encoder =  LabelEncoder()\n    activity_encoder = LabelEncoder()\n\n    df['Tag_identificator'] = tag_encoder.fit_transform(df['Tag_identificator'])\n    df['Sequence_Name'] = sequence_encoder.fit_transform(df['Sequence_Name'])\n    df['activity'] = activity_encoder.fit_transform(df['activity'])\n    return \"Successful\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.select_dtypes(include=['int64', 'float64']):\n    sns.boxplot(data[i]) #Boxlot for all Numerical Values to check how well data is distributed\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.select_dtypes(include=['int64', 'float64']):\n    sns.distplot(data[i]) # Distribution plot to check how data is distributed\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes(projection='3d') # 3D plot\nax.scatter3D(data['x_coordinate'],\n         data['y_coordinate'],\n         data['z_coordinate'],\n         c = data['z_coordinate'], cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_col(df):\n    '''\n    Creating new columns of day, month, year, hour, minute, second, microsecond from date_time Column\n    \n    It is created to check how our data is calculated and what is represent\n    '''\n    from datetime import datetime as dt # Importing Datetime library\n    \n    # transforming Datetime Column to Date_time format\n    df['date_FORMAT'] = pd.to_datetime(df['date_FORMAT'], format=\"%d.%m.%Y %H:%M:%S:%f\")\n    \n    # Extracting day, month, year, hour, minute, second, microsecond from Date_time Column\n    df['day'] = df['date_FORMAT'].dt.day\n    df['month'] = df['date_FORMAT'].dt.month\n    df['year'] = df['date_FORMAT'].dt.year\n    df['hour'] = df['date_FORMAT'].dt.hour\n    df['minute'] = df['date_FORMAT'].dt.minute\n    df['second'] = df['date_FORMAT'].dt.second\n    df['microsecond'] = df['date_FORMAT'].dt.microsecond\n    \n    del df['date_FORMAT'] # Removing Date_time Column\n    return 'Successfull'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trasnforming our data\n\nencoding(data)\nnew_col(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation Graph\n\nplt.figure(figsize=(20,12))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = ['day', 'month', 'year',\n       'hour', 'minute', 'second', 'microsecond']\n\nfor i in col:\n    print(\"Name of {} col\".format(i)) # Name of Column\n    print(\"No. of NUnique\", data[i].nunique()) # Total N_Unique Values in Column\n    print(\"Unique Values\", data[i].unique()) # All Unique values in column\n    print('*'*30)\n    print()\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# After Extracting We have found that the data is of 5 Hours from 11 to 15 and It is collected on 27th May 2009"},{"metadata":{},"cell_type":"markdown","source":"As all data is of same date we don't need Columns naming Day, Month and Year"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['day', 'month', 'year'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = ['hour', 'minute', 'second']\n\nfor i in col:\n    print(\"Name of {} col\".format(i)) # Name of Column\n    print(\"No. of NUnique\", data[i].nunique()) # Total N_Unique Values in Column\n    print(\"Unique Values\", data[i].unique()) # All Unique values in column\n    print('*'*30)\n    print()\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in col:\n    sns.distplot(data[i]) # Distribution plot to check how data is distributed\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape # Shape of data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for Spliting Data and Hyperparameter Tuning \nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\n#Importing Machine Learning Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom catboost import CatBoostClassifier\n    \n#Bagging Algo\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.neural_network import MLPClassifier\n\n#To tranform data\nfrom sklearn import preprocessing\n\n#statistical Tools\nfrom sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score,f1_score\n\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['activity'].value_counts() # Count of all Activity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(['activity'], axis=1) # Input Variable\ny = data['activity'] # Target Varibale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE # Library to Balance Dataset\nsmote = SMOTE()\n\nX_tf,y_tf = smote.fit_resample(X,y) # Balancing our Data\nX_tf.shape, y_tf.shape # Checking our new shape after Over_Sampling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\nx = scaler.fit_transform(X_tf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into training and testing sets \nx_train,x_test,y_train,y_test = train_test_split(x, y_tf, test_size=.1)\n\nprint(x_train.shape[0], x_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = {}\n\ndef train_model(model, model_name):\n    print(model_name)\n    \n    # Fitting model\n    model = model.fit(x_train, y_train)\n    pred = model.predict(x_test)\n    \n    #Model accuracy\n    acc = accuracy_score(y_test, pred)*100\n    accuracy[model_name] = acc\n    print('accuracy_score',acc)\n    print()\n    \n    # Classification Report\n    print('Classification Report')\n    print(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMClassifier(n_estimators=720, n_jobs=-1, max_depth=15, min_child_weight=5, \n                      min_child_samples=5, num_leaves=10, learning_rate=0.15)\n\ntrain_model(lgbm, 'LGBMClassifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = CatBoostClassifier(verbose = 0, n_estimators = 1000)\n\ntrain_model(cat, \"Cat Boost\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(n_estimators = 1500, nthread  = 4, max_depth = 15, min_child_weight = 5, learning_rate=0.01)\n\ntrain_model(xgb, 'XGBClassifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators = 1500, n_jobs=-1, max_depth=15, \n                             min_samples_split=5, min_samples_leaf=3)\n\ntrain_model(rfc, 'Random Forest Classifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc = DecisionTreeClassifier(criterion='gini', splitter='random', max_depth=25, min_samples_split=4,\n                            min_samples_leaf=2)\n\ntrain_model(dtc, 'Decision Tree Classifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGB Classifier is giving the Best Result"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}