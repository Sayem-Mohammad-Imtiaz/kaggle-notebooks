{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking whether there is any null value\ndata.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying the heatmap\nimport seaborn as sns\ncorrmat = data.corr()\ntop_corr_factors = corrmat.index\nplt.figure(figsize = (10,8))\nsns.heatmap(corrmat, annot = True, cmap = \"YlGnBu\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking whether the data is balanced or not\n\nis_diabetes = len(data.loc[data['Outcome']==1])\nno_diabetes = len(data.loc[data['Outcome']==0])\nprint('total people with diabetes are : {}'.format(is_diabetes))\nprint(\"total people who don't have diabetes are : {}\".format(no_diabetes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = (corrmat.index)\nprint(index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing the total number of 0 entries in each column\nfor value in index:\n    print(f\"Total no of missing data in column {value} : {len(data.loc[data[value]==0])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting X and y\nX = data.iloc[:,:8]\ny = data['Outcome']\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting training and testing data\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing all the 0 entries by the mean of the respectiv column\nfrom sklearn.impute import SimpleImputer\n\nimp = SimpleImputer(missing_values = 0, strategy = \"mean\")\nX_train[:] = imp.fit_transform(X_train)\nX_test[:] = imp.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn.impute import SimpleImputer\n\nimp = SimpleImputer(missing_values = 0, strategy = 'mean')\nX_train[1:,:] = imp.fit_transform(X_train)\nX_test.iloc[1:,:] = imp.fit_transform(X_test)\nX_newtest = pd.DataFrame(X_test)\nX_newtrain = pd.DataFrame(X_train)\nX_newtest.head()'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Random Forest for the classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params_rf = {\n    \"n_estimators\" : [50,100,150,200]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying the RandomizedSearchCV approach for getting the best best of hyperparameters \nfrom sklearn.model_selection import RandomizedSearchCV\n\nrandom_search_rf = RandomizedSearchCV(rf, param_distributions = params_rf)\nrandom_search_rf.fit(X_train,y_train)\nrandom_search_rf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                       warm_start=False)\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\nacc = accuracy_score(y_pred, y_test)\ncm = confusion_matrix(y_pred, y_test)\nf1 = f1_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"accuracy is : {acc}\")\nprint(f\"confusion matrix is : {cm}\")\nprint(f\"f1 score is : {f1}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using XGboost for the classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nclassifier = xgboost.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n\"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30],\n\"max_depth\" : [3,4,5,6,8,10,12,15],\n\"min_child_weight\" : [1,3,5,7],\n\"gamma\" : [0.0,0.1,0.2,0.3,0.4],\n\"colsample_bytree\" : [0.3,0.4,0.5,0.7]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying the RandomizedSearchCV approach for getting the best best of hyperparameters \nfrom sklearn.model_selection import RandomizedSearchCV\n\nrandom_search_xg = RandomizedSearchCV(classifier, param_distributions = params)\nrandom_search_xg.fit(X_train,y_train)\nrandom_search_xg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = xgboost.XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.7, gamma=0.3, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.05, max_delta_step=0, max_depth=5,\n              min_child_weight=7, monotone_constraints=None,\n              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n              objective='binary:logistic', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n              validate_parameters=False, verbosity=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_xg = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_xg = accuracy_score(y_pred_xg,y_test)\ncm_xg = confusion_matrix(y_pred_xg,y_test)\nf1_xg = f1_score(y_pred_xg,y_test)\nprint(f\"accuracy by xgboost is : {acc_xg}\")\nprint(f\"f1 score by xgboost is : {f1_xg}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 15,n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_params = {\n    \"n_neighbors\" : [5,7,10,12,15,17,20],\n    \"leaf_size\" : [10,20,30,40,50,60,70]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_search = RandomizedSearchCV(knn, knn_params)\nknn_search.fit(X_train,y_train)\nknn_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=-1, n_neighbors=15, p=2,\n                     weights='uniform')\nknn.fit(X_train,y_train)\nknn_pred = knn.predict(X_test)\nacc_knn = accuracy_score(knn_pred, y_test)\nf1_knn = f1_score(knn_pred, y_test)\nprint(\"The model accuracy is : {}\".format(acc_knn))\nprint(\"The f1 score of the model is : {}\".format(f1_knn))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Permutation Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n#Importing PermutationImportance\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"head = [*data]\nX_test = pd.DataFrame(X_test)\nX_test.colums = head\nX_train = pd.DataFrame(X_train)\nX_train.colums = head\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Permutation importance for the RF model\nperm_rf = PermutationImportance(rf, random_state = 42).fit(X_train,y_train)\neli5.show_weights(perm_rf, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Permutation importance for the XGBoost model\nperm_xg = PermutationImportance(classifier, random_state = 42).fit(X_train,y_train)\neli5.show_weights(perm_xg, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Permutation importance for the KNN model\nperm_knn = PermutationImportance(knn, random_state = 42).fit(X_train,y_train)\neli5.show_weights(perm_knn, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the three classifiers report Glucose to be the most important feature, which actually is quite intuitive."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}