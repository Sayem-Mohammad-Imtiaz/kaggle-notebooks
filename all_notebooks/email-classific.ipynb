{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport email\nimport email.policy\nfrom bs4 import BeautifulSoup\n\nos.listdir('../input/ham-and-spam-dataset/')\nos.listdir('../input/ham-and-spam-dataset/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ham_filenames = [name for name in sorted(os.listdir('../input/ham-and-spam-dataset/ham')) ]\nspam_filenames = [name for name in sorted(os.listdir('../input/ham-and-spam-dataset/spam')) ]\nplt.bar([0],[len(ham_filenames),], align='center', alpha=0.5,)\nplt.bar([1],len(spam_filenames), align='center', alpha=0.5)\nplt.legend(['ham','spam'])\nplt.ylabel('No of mailes')\nplt.title('No of mails Analysis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_email(is_spam, filename):\n    directory = \"../input/ham-and-spam-dataset/spam\" if is_spam else \"../input/ham-and-spam-dataset/ham\"\n    with open(os.path.join(directory, filename), \"rb\") as f:\n        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n    \nham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\nspam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testEmail = ham_emails[11]\ntestEmailContent = testEmail.get_content()\nprint(testEmailContent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\ndef get_email_structure(email):\n    if isinstance(email, str):\n        return email\n    payload = email.get_payload()\n    if isinstance(payload, list):\n        return \"multipart({})\".format(\", \".join([\n            get_email_structure(sub_email)\n            for sub_email in payload\n        ]))\n    else:\n        return email.get_content_type()\n\ndef structures_counter(emails):\n    structures = Counter()\n    for email in emails:\n        structure = get_email_structure(email)\n        structures[structure] += 1\n    return structures\n\nham_structure = structures_counter(ham_emails)\nspam_structure = structures_counter(spam_emails)\nfor email in spam_emails:\n    if get_email_structure(email) == 'text/html':\n        testEmail = email\n        break\ndef html_to_plain(email):\n    try:\n        soup = BeautifulSoup(email.get_content(), 'html.parser')\n        return soup.text.replace('\\n\\n','')\n    except:\n        return \"empty\"\n\ndef email_to_plain(email):\n    struct = get_email_structure(email)\n    for part in email.walk():\n        partContentType = part.get_content_type()\n        if partContentType not in ['text/plain','text/html']:\n            continue\n        try:\n            partContent = part.get_content()\n        except: # in case of encoding issues\n            partContent = str(part.get_payload())\n        if partContentType == 'text/plain':\n            return partContent\n        else:\n            return html_to_plain(part)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orig=[]\nh=[]\ns=[]\nimport pandas as pd \nimport re\ncount=0\nfor text in ham_emails:\n    \n   \n    text=email_to_plain(text)\n        \n    try:\n            \n        text = text.replace('.','')\n        text = text.replace(':','')\n        text = text.replace(',','')\n        text = text.replace('!','')\n        text = text.replace('?','')\n        text=text.replace('\\n','')\n        text=text.replace('\\t','')\n        h.append(text)\n\n    except:\n       pass\n    \n   \n#label=[1]*len(ham_emails)\n\nfor text in spam_emails:\n   \n        text=email_to_plain(text)\n\n        try:\n            \n            text = text.replace('.','')\n            text = text.replace(':','')\n            text = text.replace(',','')\n            text = text.replace('!','')\n            text = text.replace('?','')\n            text = text.replace('\\n','')\n            text=text.replace('\\t','')\n            s.append(text)\n\n        except:\n            pass\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label=[0]*len(h)+[1]*len(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = h+s # Extract text\ntarget = label # Extract target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wl=50000\ntokenizer=Tokenizer(wl,filters='!@#$%^&*{}]~`[',lower=True)\ntokenizer.fit_on_texts(texts)\ntext=tokenizer.texts_to_sequences(texts)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(text[9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msl=250\ntext=pad_sequences(text,msl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Embedding, LSTM,Dense,Dropout,Dense\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" help(Embedding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical\ny=to_categorical(target)\nx_train,x_test,y_train,y_test=train_test_split(text,y,test_size=0.3, random_state=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_train[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(50000,64,input_length=250))\nmodel.add(LSTM(64,input_shape=(250,10),activation='tanh'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(x_train,y_train,epochs=10, validation_split=0.2 ,batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=model.evaluate(x_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_complaint = ['I am a victim of identity theft and someone stole my identity and personal information to open up a Visa credit card account with Bank of America. The following Bank of America Visa credit card account do not belong to me : XXXX.']\nseq = tokenizer.texts_to_sequences(new_complaint)\npadded = pad_sequences(seq, maxlen=250)\npred = model.predict(padded)\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accr = model.evaluate(x_test,y_test)\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nhist=history\n# visualizing losses and accuracy\ntrain_loss=hist.history['loss']\nval_loss=hist.history['val_loss']\ntrain_acc=hist.history['accuracy']\nval_acc=hist.history['val_accuracy']\nxc=range(10)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(x_test)\ny_test\nlabels=[1,0]\ny_test_label=[]\ny_pred_label=[]\n\nfor i in y_test:\n   y_test_label.append(labels[np.argmax(i)])\nfor i in y_pred:\n    y_pred_label.append(labels[np.argmax(i)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import metrics \ndata = metrics.confusion_matrix(y_test_label, y_pred_label)\nimport seaborn as sb\nsb.heatmap(data, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nnew_complaint = ['I am a victim of identity theft and someone stole my identity and personal information to open up a Visa credit card account with Bank of America. The following Bank of America Visa credit card account do not belong to me : XXXX.']\n\nseq = tokenizer.texts_to_sequences(new_complaint)\npadded = pad_sequences(seq, maxlen=250)\npred = model.predict(padded)\nlabels = ['ham','spam']\nprint( labels[np.argmax(pred)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_complaint = ['todays weather is cool ,isnt it']\n\nseq = tokenizer.texts_to_sequences(new_complaint)\npadded = pad_sequences(seq, maxlen=250)\npred = model.predict(padded)\nlabels = ['ham','spam']\nprint( labels[np.argmax(pred)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}