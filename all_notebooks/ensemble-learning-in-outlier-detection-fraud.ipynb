{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Install complementary packages\n!pip install pyod","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import packages\nimport pandas as pd\nimport matplotlib as plt\nimport numpy as np\nimport pyod\nimport sklearn\nimport pyod\n\n\n# Extract and prepare Dataset\ncreditCard_df = pd.read_csv('../input/creditcardfraud/creditcard.csv')\nautoInsurance_df = pd.read_csv('../input/auto-insurance-claims-data')\n\nX = creditCard_df.iloc[:,0:29]\ny = creditCard_df.iloc[:,[30]]\n\n# Training and Test Split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(autoInsurance)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers = {\n     'Angle-based Outlier Detector (ABOD)'   : ABOD(contamination=outlier_fraction),\n     'K Nearest Neighbors (KNN)' :  KNN(contamination=outlier_fraction)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#When you do unsupervised learning, it is always a safe step to standardize the predictors\nX = StandardScaler().fit_transform(X)\nX = pd.DataFrame(X)\n\npca = PCA(2)\nx_pca = pca.fit_transform(X)\nx_pca = pd.DataFrame(x_pca)\nx_pca.columns=['PC1','PC2']\nx_pca.head()\n\ny_color = pd.DataFrame(np.where(y==1,'red','blue'), columns=['Color'])\nx_pca = pd.concat([x_pca,y_color], axis=1)\nprint(x_pca)\n\nx_pca.plot(kind='scatter', x='PC1', y='PC2', c='Color')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1 = IForest(behaviour=\"new\",max_samples=X_train.shape[0]) \nclf1.fit(X_train)\n\n# clf.decision_function: Predict raw anomaly score of X using the fitted detector.\n# We apply the model to the test data X_test to get the outlier scores.\ny_test_scores = clf1.decision_function(X_test)  # outlier scores\ny_test_scores = pd.Series(y_test_scores)\ny_test_scores.head()\n\nimport matplotlib.pyplot as plt\nplt.hist(y_test_scores, bins='auto')  # arguments are passed to np.histogram\nplt.title(\"Histogram for Model clf1 Anomaly Scores\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_cluster = X_test.copy()\nX_test_cluster['distance'] = y_test_scores\nX_test_cluster['cluster'] = np.where(X_test_cluster['distance']<0.05, 0, 1)\nX_test_cluster['cluster'].value_counts()\n\nX_test_cluster.groupby('cluster').mean()\n\n\n# The predictions of the training data can be obtained by clf.decision_scores_.\n# It is already generated during the model building process.\ntrain_scores = pd.DataFrame({'clf1': clf1.decision_scores_})\n\n# The predictions of the test data need to be predicted using clf.decision_function(X_test)\ntest_scores  = pd.DataFrame({'clf1': clf1.decision_function(X_test)})\n\nprint(test_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}