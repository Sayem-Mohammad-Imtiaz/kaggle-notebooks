{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Uninstall fastai for solving dependence problems\n!pip uninstall fastai -y\n# Install packages without internet\n!pip install ../input/packages/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/packages/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nsys.path.append('../input/pytorch-optimizers/')\nsys.path.append('../input/repvgg/')\nsys.path.append('../input/repvggmodels/')\n\nimport timm\nfrom torch_optimizer.radam import RAdam\nfrom repvgg import RepVGG, create_RepVGG_B2, create_RepVGG_B3g4, create_RepVGG_B3, repvgg_model_convert","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport copy\nimport random\nimport joblib\nimport sklearn\nimport warnings\nimport multiprocessing\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom glob import glob\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom datetime import datetime\nfrom skimage import io\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom IPython.display import display\nfrom catalyst.data.sampler import BalanceClassSampler\n\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision import models\nfrom torchvision import transforms\n\nfrom albumentations.pytorch import ToTensor, ToTensorV2\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n    ShiftScaleRotate, CenterCrop, Resize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Move some weights to torch cache dir\ncache_dir = os.path.expanduser(os.path.join('~', '.cache/torch/hub/checkpoints'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \n!cp ../input/pretrained-pytorch-models/* ~/.cache/torch/hub/checkpoints/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CFG = {\n    'fold_num': 3,\n    'seed'    : 42,\n    'img_size': 400,\n    'epochs'  : 18,\n    'train_bs': 16,\n    'valid_bs': 32,\n    'tta'     : 3,\n    'T_0'     : 10,\n    'lr'      : 1e-3,\n    'momentum': 0.9,\n    'min_lr'  : 1e-6,\n    'weight_decay'  : 1e-4,\n    'early_stopping': 5,\n    'num_workers'   : 4,\n    'accum_iter'    : 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'verbose_step'  : 1,\n    'device': 'cuda:0'}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train      = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\nsubmission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\ndisplay(train.head(2))\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb\n\nimg = get_img('../input/cassava-leaf-disease-classification/train_images/1000015157.jpg')\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define re-train dataset with public models"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n\n    def __init__(self, df, data_root, transforms=None, output_label=True):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms   = transforms\n        self.data_root    = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        path = f\"{self.data_root}/{self.df.iloc[index]['image_id']}\"\n        img  = get_img(path)\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        if self.output_label == True:\n            return img, self.df.iloc[index]['label']\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_inference_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)], p=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassvaImgClassifier(nn.Module):\n    \n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    image_preds_all = []\n    for step, imgs in pbar:\n        imgs = imgs.to(device).float()\n        image_preds      = model(imgs)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_ds = CassavaDataset(train.copy(),\n                          '../input/cassava-leaf-disease-classification/train_images/',\n                          transforms=get_inference_transforms(),\n                          output_label=False)\nval_loader = torch.utils.data.DataLoader(valid_ds, \n                                         batch_size=CFG['valid_bs'],\n                                         num_workers=CFG['num_workers'],\n                                         shuffle=False,\n                                         pin_memory=False)\ndevice = torch.device(CFG['device'])\nmodel  = CassvaImgClassifier('tf_efficientnet_b4_ns', train.label.nunique()).to(device)\n\nval_preds = []\nfor i, epoch in enumerate([9]):\n    model.load_state_dict(torch.load(f'../input/cassava-pytorch-efficientnet-baseline-models/tf_efficientnet_b4_ns_fold_0_{epoch}'))\n    with torch.no_grad():\n        for _ in range(CFG['tta']):\n            val_preds += [1/CFG['tta']*inference_one_epoch(model, val_loader, device)]\nval_preds = np.sum(val_preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_result = pd.DataFrame({\"image_id\": train.image_id,\n                                \"label\"   : train.label,\n                                \"pred\"    : np.argmax(val_preds,1),\n                                \"prob\"    : np.max(val_preds,1)})\ndf_train_result[\"res\"] = df_train_result.label == df_train_result.pred\n\nthr = 0.6\nretrain = pd.DataFrame()\nnoised  = pd.DataFrame()\nfor l in sorted(df_train_result.label.unique()):\n    df_l = df_train_result[(df_train_result.res)&(df_train_result.label==l)].copy()\n    retrain = retrain.append(df_l[df_l.prob>=thr].copy())\n    noised  = noised .append(df_l[df_l.prob< thr].copy())\nnoised  = noised.append(df_train_result[(df_train_result.res==False)])\nretrain = retrain.reset_index(drop=True).iloc[:,:2]\nnoised  = noised .reset_index(drop=True).iloc[:,:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.label.value_counts(normalize=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([retrain.label.value_counts(sort=False), noised.label.value_counts(sort=False)], axis=1)\ndf.columns = [\"retrain\", \"noised\"]\ndf[\"retrain_rate\"] = df.retrain / df.retrain.sum()\ndf[\"noised_rate\"]  = df.noised  / df.noised.sum()\nprint(df.retrain.sum(), df.noised.sum())\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train with pre-trained weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    \n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms    = transforms\n        self.data_root     = data_root\n        self.output_label  = output_label\n        \n        if output_label:\n            self.labels = self.df['label'].values\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.labels[index]\n        img = get_img(f\"{self.data_root}/{self.df.loc[index]['image_id']}\")\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.output_label:\n            return img, target\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0)], p=1)\n  \ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)], p=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#backbone = models.resnet50(pretrained=True)\nbackbone = create_RepVGG_B3g4(deploy=False)\n#backbone.load_state_dict(torch.load(\"../input/byol-model/byol.pt\"))\nbackbone.load_state_dict(torch.load(\"../input/repvgg/RepVGG-B3g4-200epochs-train.pth\"))\n\n# Freeze the weights\n#for param in backbone.parameters():\n#    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self):\n        super(FFN, self).__init__()\n        self.backbone = backbone\n        self.lr1      = nn.Linear(1000, 256)\n        self.relu     = nn.ReLU()\n        self.dropout  = nn.Dropout(0.5)\n        self.lr2      = nn.Linear(256, 5)\n        \n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.relu(self.lr1(x))\n        x = self.dropout(x)\n        x = self.lr2(x)\n        return x\n    \ndef sgd_optimizer(model, lr, momentum, weight_decay):\n    params = []\n    for key, value in model.named_parameters():\n        if not value.requires_grad:\n            continue\n        apply_weight_decay = weight_decay\n        apply_lr = lr\n        if 'bias' in key or 'bn' in key:\n            apply_weight_decay = 0\n        if 'bias' in key:\n            apply_lr = 2 * lr       #   Just a Caffe-style common practice. Made no difference.\n        params += [{'params': [value], 'lr': apply_lr, 'weight_decay': apply_weight_decay}]\n    optimizer = torch.optim.SGD(params, lr, momentum=momentum)\n    return optimizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_dataloader(df, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/'):\n    train_   = df.loc[trn_idx,:].reset_index(drop=True)\n    valid_   = df.loc[val_idx,:].reset_index(drop=True)\n    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True)\n    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n    train_loader = torch.utils.data.DataLoader(train_ds,\n                                               batch_size=CFG['train_bs'],\n                                               pin_memory=False,\n                                               drop_last=False,\n                                               shuffle=True,\n                                               num_workers=CFG['num_workers'])\n    val_loader = torch.utils.data.DataLoader(valid_ds,\n                                             batch_size=CFG['valid_bs'],\n                                             num_workers=CFG['num_workers'],\n                                             shuffle=False,\n                                             pin_memory=False)\n    return train_loader, val_loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n    model.train()\n\n    running_loss = None\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = image_labels.to(device).long()\n\n        with autocast():\n            image_preds = model(imgs)\n            loss = loss_fn(image_preds, image_labels)\n            scaler.scale(loss).backward()\n\n            if running_loss is None:\n                running_loss = loss.item()\n            else:\n                running_loss = running_loss * .99 + loss.item() * .01\n\n            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad() \n                if scheduler is not None and schd_batch_update:\n                    scheduler.step()\n\n            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n                description = f'epoch {epoch} loss: {running_loss:.4f}'\n                pbar.set_description(description)\n                \n    if scheduler is not None and not schd_batch_update:\n        scheduler.step()\n        \ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n    model.eval()\n\n    loss_sum   = 0\n    sample_num = 0\n    image_preds_all   = []\n    image_targets_all = []\n    \n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n    for step, (imgs, image_labels) in pbar:\n        imgs = imgs.to(device)\n        image_labels = image_labels.to(device).long()\n        \n        image_preds = model(imgs)\n        image_preds_all   += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n        image_targets_all += [image_labels.detach().cpu().numpy()]\n        \n        loss = loss_fn(image_preds, image_labels)\n        loss_sum   += loss.item()*image_labels.shape[0]\n        sample_num += image_labels.shape[0]  \n\n        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n            pbar.set_description(description)\n            \n    image_preds_all   = np.concatenate(image_preds_all)\n    image_targets_all = np.concatenate(image_targets_all)\n    acc = (image_preds_all==image_targets_all).mean()\n    print('validation multi-class accuracy = {:.4f}'.format(acc))\n    \n    if scheduler is not None:\n        if schd_loss_update:\n            scheduler.step(loss_sum/sample_num)\n        else:\n            scheduler.step()\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample_batch = next(iter(train_loader))[0]\n#model.to(\"cuda:0\")\n#with torch.no_grad():\n#    output = model(sample_batch.to(\"cuda:0\").float())\n#output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(retrain.shape[0]), retrain.label.values)\n    \nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    print('Training with {} started'.format(fold))\n    print(len(trn_idx), len(val_idx))\n    train_loader, val_loader = prepare_dataloader(retrain, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/')\n\n    not_improved_cnt = 0\n    best_acc = 0\n    device   = torch.device(CFG['device'])\n    model    = FFN()\n    \n    backbone.to(device)\n    model.to(device)\n    scaler    = GradScaler()\n    #optimizer = RAdam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n    optimizer = sgd_optimizer(model, CFG['lr'], CFG['momentum'], CFG['weight_decay'])\n    scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=CFG['T_0'])\n    \n    loss_tr = nn.CrossEntropyLoss().to(device)\n    loss_fn = nn.CrossEntropyLoss().to(device)\n\n    for epoch in range(CFG['epochs']):\n        train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n\n        with torch.no_grad():\n            acc = valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n\n        if best_acc < acc:\n            print('Best model will be saved to output path after completing this fold')\n            converted_model = copy.deepcopy(model)\n            best_acc = acc\n            not_improved_cnt = 0\n        elif CFG['early_stopping'] == not_improved_cnt:\n            print(\"Met early stopping.\")\n            break\n        else:\n            not_improved_cnt += 1\n            \n    converted_model.backbone = repvgg_model_convert(converted_model.backbone, create_RepVGG_B3g4)\n    torch.save(converted_model.state_dict(), f'tuned_cnn_fold_{fold}')\n\n    del model, converted_model, optimizer, train_loader, val_loader, scaler\n    torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference with trained RepVGG to get noise labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    \n    def __init__(self, df, data_root, transforms=None, output_label=True):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms   = transforms\n        self.data_root    = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        path = f\"{self.data_root}/{self.df.iloc[index]['image_id']}\"\n        img  = get_img(path)\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        if self.output_label == True:\n            return img, self.df.iloc[index]['label']\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_ds = CassavaDataset(noised.copy(),\n                          '../input/cassava-leaf-disease-classification/train_images/',\n                          transforms=get_inference_transforms(),\n                          output_label=False)\nval_loader = torch.utils.data.DataLoader(valid_ds, \n                                         batch_size=CFG['valid_bs'],\n                                         num_workers=CFG['num_workers'],\n                                         shuffle=False,\n                                         pin_memory=False)\ndevice   = torch.device(CFG['device'])\nbackbone = create_RepVGG_B3g4(deploy=True)\n\nval_preds = []\nfor fold in range(CFG['fold_num']):\n    model = FFN()\n    model.load_state_dict(torch.load(f\"./tuned_cnn_fold_{fold}\"))\n    backbone.to(device)\n    model.to(device)\n    with torch.no_grad():\n        for _ in range(CFG['tta']):\n            val_preds += [1/(CFG['fold_num']*CFG['tta'])*inference_one_epoch(model, val_loader, device)]\nval_preds = np.sum(val_preds, axis=0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_labels   = pd.DataFrame(np.vstack([np.identity(5)[retrain.label], val_preds]),\n                           columns=[f\"label_{i}\" for i in range(5)])\nall_dataset = pd.concat([retrain, noised]).reset_index(drop=True)\nall_dataset = all_dataset.join(df_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(16, 4))\nall_dataset[all_dataset.label==0].label_0.hist(ax=axes[0])\nall_dataset[all_dataset.label==1].label_1.hist(ax=axes[1])\nall_dataset[all_dataset.label==2].label_2.hist(ax=axes[2])\nall_dataset[all_dataset.label==3].label_3.hist(ax=axes[3])\nall_dataset[all_dataset.label==4].label_4.hist(ax=axes[4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_dataset.to_csv(\"./noised_label_data.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}