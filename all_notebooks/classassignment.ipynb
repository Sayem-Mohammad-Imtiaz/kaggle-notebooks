{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfilename = '/kaggle/input/pima-indians-diabetes-database/diabetes.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_folds = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = KFold(n_splits=10, random_state=7)\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nX = array[:,0:8]\nY = array[:,8]\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = LinearDiscriminantAnalysis()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = KNeighborsClassifier()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nkfold = KFold(n_splits=10, random_state=7)\nmodel = GaussianNB()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nkfold = KFold(n_splits=10, random_state=7)\nmodel = DecisionTreeClassifier()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\nkfold = KFold(n_splits=10, random_state=7)\nmodel = SVC()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfilename = '/kaggle/input/boston-house-prices/housing.csv'\nnames = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO',\n'B', 'LSTAT', 'MEDV']\ndataframe = read_csv(filename, delim_whitespace=True, names=names)\narray = dataframe.values\nX = array[:,0:13]\nY = array[:,13]\nkfold = KFold(n_splits=10, random_state=7)\nmodel = LinearRegression()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we have an implementation of ridge regression it is different from the linear regression as a penalty term is included in the cost function which is lambda constant multiplyed with the sum of square of weights. This cost function is displayed below.\n![image.png](attachment:image.png)\n","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = Ridge()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nkfold = KFold(n_splits=10, random_state=7)\nmodel = Lasso()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nkfold = KFold(n_splits=10, random_state=7)\nmodel = ElasticNet()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below knearest neighbours is demonstrated. The "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nkfold = KFold(n_splits=10, random_state=7)\nmodel = KNeighborsRegressor()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\nkfold = KFold(n_splits=10, random_state=7)\nmodel = DecisionTreeRegressor()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = SVR()\nscoring = 'neg_mean_squared_error'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(results.mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"comparing various machine learning methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n# load dataset\nfilename = '/kaggle/input/pima-indians-diabetes-database/diabetes.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\n# prepare models\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n# boxplot algorithm comparison\nfig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('lda', LinearDiscriminantAnalysis()))\nmodel = Pipeline(estimators)\n# evaluate pipeline\nkfold = KFold(n_splits=10, random_state=7)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest\nfeatures = []\nfeatures.append(('pca', PCA(n_components=3)))\nfeatures.append(('select_best', SelectKBest(k=6)))\nfeature_union = FeatureUnion(features)\n# create pipeline\nestimators = []\nestimators.append(('feature_union', feature_union))\nestimators.append(('logistic', LogisticRegression()))\nmodel = Pipeline(estimators)\n# evaluate pipeline\nkfold = KFold(n_splits=10, random_state=7)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nseed = 7\nkfold = KFold(n_splits=10, random_state=seed)\ncart = DecisionTreeClassifier()\nnum_trees = 100\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nnum_trees = 100\nmax_features = 3\nkfold = KFold(n_splits=10, random_state=7)\nmodel = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import ExtraTreesClassifier\nnum_trees = 100\nmax_features = 7\nkfold = KFold(n_splits=10, random_state=7)\nmodel = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\nnum_trees = 30\nseed=7\nkfold = KFold(n_splits=10, random_state=seed)\nmodel = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import GradientBoostingClassifier\nseed = 7\nnum_trees = 100\nkfold = KFold(n_splits=10, random_state=seed)\nmodel = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nkfold = KFold(n_splits=10, random_state=7)\n# create the sub models\nestimators = []\nmodel1 = LogisticRegression()\nestimators.append(('logistic', model1))\nmodel2 = DecisionTreeClassifier()\nestimators.append(('cart', model2))\nmodel3 = SVC()\nestimators.append(('svm', model3))\n# create the ensemble model\nensemble = VotingClassifier(estimators)\nresults = cross_val_score(ensemble, X, Y, cv=kfold)\nprint(results.mean())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\n\nfrom sklearn.model_selection import GridSearchCV\nalphas = numpy.array([1,0.1,0.01,0.001,0.0001,0])\nparam_grid = dict(alpha=alphas)\nmodel = Ridge()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid)\ngrid.fit(X, Y)\nprint(grid.best_score_)\nprint(grid.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\nfrom pandas import read_csv\nfrom scipy.stats import uniform\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import RandomizedSearchCV\nparam_grid = {'alpha': uniform()}\nmodel = Ridge()\nrsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100,\nrandom_state=7)\nrsearch.fit(X, Y)\nprint(rsearch.best_score_)\nprint(rsearch.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom pickle import dump\nfrom pickle import load\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n# Fit the model on 33%\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n# save the model to disk\nfilename = 'finalized_model.sav'\ndump(model, open(filename, 'wb'))\n# some time later...\n# load the model from disk\nloaded_model = load(open(filename, 'rb'))\nresult = loaded_model.score(X_test, Y_test)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.externals.joblib import dump\nfrom sklearn.externals.joblib import load\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n# Fit the model on 33%\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\nfilename = 'finalized_model.sav'\ndump(model, filename)\n# some time later...\n# load the model from disk\nloaded_model = load(filename)\nresult = loaded_model.score(X_test, Y_test)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}