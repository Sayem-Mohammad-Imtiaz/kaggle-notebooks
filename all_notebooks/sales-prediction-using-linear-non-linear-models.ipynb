{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Settings & Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Connect Google Cloud\nPROJECT_ID = 'advertising-linear-nonlinear'\nfrom google.cloud import storage\nstorage_client = storage.Client(project=PROJECT_ID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data manipulation\nimport seaborn as sns # data visualization\nfrom matplotlib import pyplot as plt # data visualization","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import data\nadvs = pd.read_csv(\"../input/advertising-dataset/advertising.csv\")\ndf = advs.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() # metadata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe statistics\ndf.describe([0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_dist_plots(dataframe):\n    for col in dataframe.columns:\n        sns.distplot(dataframe[col],hist=False).set_title(f\"{col} Distribution Graph\")\n        plt.axvline(dataframe[col].mean(),color='r',label='mean')\n        plt.axvline(np.median(dataframe[col]),color='b',label='median')\n        plt.axvline((dataframe[col].mode())[0],color='g',label='mode')\n        plt.legend()\n        plt.show();\n\ncustom_dist_plots(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales related other variables\ndef target_scatter(dataframe):\n    cols = [col for col in dataframe.columns if col != \"Sales\"]\n    sns.pairplot(dataframe, x_vars=cols, y_vars=\"Sales\", height=4, aspect=1, kind='scatter')\n    plt.show()\n\ntarget_scatter(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation graph\nsns.heatmap(df.corr(), cmap=\"Dark2\", annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_detection(dataframe, method=\"boxplot\"):\n    if method == \"boxplot\":\n        var_names = [col for col in df.columns if col != \"Sales\"]\n        fig, axs = plt.subplots(len(var_names), figsize=(5, 5))\n        for i, col in enumerate(var_names):\n            sns.boxplot(df[col], ax=axs[i])\n        plt.tight_layout()\n    elif method == \"lof\":\n        from sklearn.neighbors import LocalOutlierFactor\n        clf = LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)\n        clf.fit_predict(dataframe)\n        scores_df = pd.DataFrame(np.sort(clf.negative_outlier_factor_))\n        scores_df.plot(stacked=True, xlim=[0,20], style='.-')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_detection(df) # boxplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_detection(df, \"lof\") # LOF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We did not interfere with outliers.**"},{"metadata":{},"cell_type":"markdown","source":"# Model Building\n\nWe used the following models:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression # Multiple Linear Regression\nfrom sklearn.linear_model import Ridge # Ridge Regression\nfrom sklearn.linear_model import Lasso # Lasso Regression\nfrom sklearn.linear_model import ElasticNet # ElasticNet Regression\nfrom sklearn.neighbors import KNeighborsRegressor # KNN\nfrom sklearn.tree import DecisionTreeRegressor # CART\nfrom sklearn.ensemble import RandomForestRegressor # Random Forests\nfrom sklearn.ensemble import GradientBoostingRegressor # GBM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# holdout method\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nX = df.drop(\"Sales\", axis=1)\ny = df.Sales\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=6106)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_grid = {\"Linear\": LinearRegression(),\n              \"Ridge\": Ridge(),\n              \"Lasso\": Lasso(),\n              \"ElasticNet\": ElasticNet(),\n              \"KNN\": KNeighborsRegressor(),\n              \"CART\": DecisionTreeRegressor(),\n              \"RF\": RandomForestRegressor(random_state=6106),\n              \"GBM\": GradientBoostingRegressor()}\n\nscores_dict = {}\nfor name, model in model_grid.items():\n    model.fit(X_train, y_train)\n    rmse = np.mean(np.sqrt(-cross_val_score(model, X_test, y_test, cv=10, scoring=\"neg_mean_squared_error\")))\n    scores_dict[name] = rmse\n\nscores_dict = {k: v for k, v in sorted(scores_dict.items(), key=lambda item: item[1])}\nscores_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you want the top 4 models do the following codes\n\nfrom itertools import islice\ntop_4_scores = dict(islice(scores_dict.items(), 4))\nprint(\"Top 4 Scores\")\ntop_4_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forests Regression\n\n# setting model\nrf_model = RandomForestRegressor(random_state=6106)\n\n# seting param grid\nrf_params = {\"max_depth\": [5, 8, None],\n             \"n_estimators\": [200, 500],\n             \"min_samples_split\": [2, 5, 10]}\n\n# search best params\nrf_cv_model = GridSearchCV(rf_model, rf_params, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nrf_tuned = RandomForestRegressor(**rf_cv_model.best_params_).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lasso Regression\n\n# setting model\nlasso_model = Lasso()\n\n# seting param grid\nlasso_param = {\"alpha\": 10 ** (np.linspace(10, -2, 100) * 0.5)}\n\n# search best params\nlasso_cv_model = GridSearchCV(lasso_model, lasso_param, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nlasso_tuned = Lasso(**lasso_cv_model.best_params_).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ElasticNet Regression\n\n# setting model\nenet_model = ElasticNet()\n\n# seting param grid\nenet_params = {\"l1_ratio\": [0.1, 0.4, 0.5, 0.6, 0.8, 1],\n               \"alpha\": [0.1, 0.01, 0.001, 0.2, 0.3, 0.5, 0.8, 0.9, 1]}\n\n# search best params\nenet_cv_model = GridSearchCV(enet_model, enet_params, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nenet_tuned = ElasticNet(**enet_cv_model.best_params_).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge Regression\n\n# setting model\nridge_model = Ridge()\n\n# seting param grid\nridge_param = {\"alpha\": 10 ** (np.linspace(10, -2, 100) * 0.5)}\n\n# search best params\nridge_cv_model = GridSearchCV(ridge_model, ridge_param, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nridge_tuned = ElasticNet(**ridge_cv_model.best_params_).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\n# set tuned models\ntuned_grid = dict([(\"RF\", rf_tuned), (\"Lasso\", lasso_tuned), (\"ElasticNet\", enet_tuned), (\"Ridge\", ridge_tuned)])\n\n# get rmse values from tuned models\ntuned_scores = {}\nfor name, model in tuned_grid.items():\n    y_pred = model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    tuned_scores[name] = rmse\n\n# sorting rmse\ntuned_scores = {k: v for k, v in sorted(tuned_scores.items(), key=lambda item: item[1])}\n\n# choose best model\nbest_model = dict(islice(tuned_scores.items(), 1))\nbest_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization RF (first tree)\nfrom sklearn.tree import plot_tree\n\nplt.figure(figsize=(20,20))\nplot_tree(rf_tuned.estimators_[0], filled=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_new_model = RandomForestRegressor(max_depth=3, min_samples_split=2, n_estimators=200).fit(X_train, y_train)\nplt.figure(figsize=(20,20))\nplot_tree(rf_new_model.estimators_[0], filled=True)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}