{"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"version":"3.6.1","nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","name":"python","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"cells":[{"execution_count":null,"source":"95% accuracy by Unsupervised Learning (Gaussian Mixture Model)","cell_type":"markdown","metadata":{"collapsed":false,"_cell_guid":"73db85b8-bf0d-4699-8c8f-4076c4af919a","_uuid":"75982e5e309f6022b73b7d32ed4fd32de50ff784","_execution_state":"idle"},"outputs":[]},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e7a1341b-d27f-404a-8bcd-7d533403cd8d","_uuid":"76da43bd418ec359d6e057ded521ce05a08e3089"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.metrics import f1_score\nfrom time import time\nimport matplotlib.pyplot as plt\n\ndef get_data(Path='../input/data.csv'):\n    # load the breast_cancer dataset from csv\n    BC_Data = pd.read_csv(Path, skiprows=1, header=None)\n    # the second column is the types of Cancer (categorical--M/B)\n    BC_Type = BC_Data[1].unique()\n    # replace 'M' with 0, replace 'B' with 1\n    for i, type in enumerate(BC_Type):\n        # DataFrame.set_value(index, col, value, takeable=False)\n        BC_Data.set_value(BC_Data[1] == type, 1, i)\n    # split the features and labels\n    # numpy.split(ary, indices_or_sections, axis=0)\n    Y, X = np.split(BC_Data.values, (2,), axis=1)\n    # set the features to float, set the labels to int\n    X = X.astype(np.float)\n    Y = Y.astype(np.int)\n    # drop the 'id' column, since it is useless for analyzing\n    Y=Y[:, 1]\n    # return the features X and labels Y\n    return X, Y\n\n# replace 0 with 1, and replace 1 with 0, for comparing the true labels and the clustered labels in clustering algorithm\ndef data_reverve(pred):\n    predict = []\n    if 1.0 * np.sum(pred) / len(pred) < 0.5:\n        for i, label in enumerate(pred):\n            if pred[i] == 0:\n                n = 1\n            else:\n                n = 0\n            predict.append(n)\n    predict = np.array(predict)\n    return predict\n\n# to visualize the scatter plot of the data in different color\ndef scatter_vis2(X1, X2, n):\n    name=['Actual Groups after PCA', 'Predictive Clustering after PCA']\n    plt.figure()\n    plt.scatter(X1[:, 0], X1[:, 1], color='r', marker='^')    # red stands for 'M'\n    plt.scatter(X2[:, 0], X2[:, 1], color='b', marker='s')    # blue stands for 'B'\n    plt.xlabel('PC1')\n    plt.ylabel('PC2')\n    plt.title(name[n])\n    plt.show()\n\n# to visualize the comparison of the centers of clusters\ndef center_comp_vis(cluster_center):\n    plt.bar(np.arange(1, len(cluster_center[0]) + 1), cluster_center[0], 0.5, color='b')\n    plt.bar(np.arange(1.5, len(cluster_center[1]) + 1), cluster_center[1], 0.5, color='r')\n    plt.xlabel('features')\n    plt.ylabel('feature centers')\n    plt.title('feature centers presentation')\n    plt.show()\n        \n# perform unsupervised learning on data set(Gaussian Mixture)\nif __name__==\"__main__\":\n\n    time_results = {}  # for calculate the time efficiency\n\n    X, Y = get_data()\n\n    # capture the index of label 0 ('M') and label 1 ('B')\n    cluster_M = []\n    cluster_B = []\n    for i, label in enumerate(Y):\n        if label == 0:\n            cluster_M.append(i)\n        if label == 1:\n            cluster_B.append(i)\n\n    # visualize the actual data grouping\n    scatter_vis2(X[cluster_M], X[cluster_B], 0)\n\n    # data training\n    start1 = time()\n    EM = GaussianMixture(n_components=2, random_state=0).fit(X)    # use 2 clusters\n    end1=time()\n    time_results['training time'] = end1 - start1\n\n    # make prediction\n    start2=time()\n    pred = EM.predict(X)\n    end2=time()\n    time_results['prediction time'] = end2 - start2\n\n    predict=data_reverve(pred)    # make the labels easy to compare\n\n    # capture the index of label predicted as 0 ('M') and label predicted as 1 ('B')\n    cluster_M_pre=[]\n    cluster_B_pre=[]\n    for i, label in enumerate(predict):\n        if label==0:\n            cluster_M_pre.append(i)\n        if label==1:\n            cluster_B_pre.append(i)\n\n    # visualize the result of clustering\n    scatter_vis2(X[cluster_M_pre], X[cluster_B_pre], 1)\n\n    # compute the matrics\n    cluster_accuracy= accuracy_score(Y, predict)\n    cluster_fscore=f1_score(Y, predict)\n\n    cluster_center= EM.means_    # center of each cluster\n\n    print (cluster_accuracy)\n    print (cluster_fscore)\n    print (time_results)\n\n    # visualization\n    center_comp_vis(cluster_center)"},{"execution_count":null,"source":"","cell_type":"code","metadata":{"trusted":false,"collapsed":false,"_cell_guid":"67eade71-3d56-48ee-95ea-c8796228ce0a","_uuid":"12c0d870ca27be4406cdd61a9e792c2444233a48","_execution_state":"idle"},"outputs":[]}],"nbformat_minor":0}