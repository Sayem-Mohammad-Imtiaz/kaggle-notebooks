{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom pandas_profiling import ProfileReport\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel (\"E:\\python\\Insaid test\\Churn.xlsx\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import missingno as msno","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.fillna(value=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in df.columns:\n    try:\n        df[item] = df[item].str.lower()\n    except:\n        print(item, \"couldn't convert\")\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing Yes, No to 0 and 1\ncolumns_to_convert = ['Partner', \n                      'Dependents', \n                      'PhoneService', \n                      'PaperlessBilling', \n                      'Churn']\n\nfor item in columns_to_convert:\n    df[item].replace(to_replace='yes', value=1, inplace=True)\n    df[item].replace(to_replace='no',  value=0, inplace=True)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns.to_series().groupby(df.dtypes).groups","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalCharges'] = df['TotalCharges'].astype(float)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Balance the labels so we have the same number of non-churners as churners.\nchurners_number = len(df[df['Churn'] == 1])\nprint(\"Number of churners\", churners_number)\n\nchurners = (df[df['Churn'] == 1])\n\nnon_churners = df[df['Churn'] == 0].sample(n=churners_number)\nprint(\"Number of non-churners\", len(non_churners))\ndf2 = churners.append(non_churners)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(3, 3))\nlabels =[\"Churn: Yes\",\"Churn:No\"]\nvalues = [1869,5163]\nlabels_gender = [\"F\",\"M\",\"F\",\"M\"]\nsizes_gender = [939,930 , 2544,2619]\ncolors = ['#ff6666', '#66b3ff']\ncolors_gender = ['#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6']\nexplode = (0.3,0.3) \nexplode_gender = (0.1,0.1,0.1,0.1)\ntextprops = {\"fontsize\":15}\n#Plot\nplt.pie(values, labels=labels,autopct='%1.1f%%',pctdistance=1.08, labeldistance=0.8,colors=colors, startangle=90,frame=True, explode=explode,radius=10, textprops =textprops, counterclock = True, )\nplt.pie(sizes_gender,labels=labels_gender,colors=colors_gender,startangle=90, explode=explode_gender,radius=7, textprops =textprops, counterclock = True, )\n#Draw circle\ncentre_circle = plt.Circle((0,0),5,color='black', fc='white',linewidth=0)\nfig = plt.gcf()\nfig.gca().add_artist(centre_circle)\n\nplt.title('Churn Distribution w.r.t Gender: Male(M), Female(F)', fontsize=15, y=1.1)\n\n# show plot \n \nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n#There is negligible difference in customer percentage/ count who chnaged the service provider. Both genders behaved in similar fashion when it comes to migrating to another service provider/firm.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation\ncorelation = df.corr()  \nfig, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(df.corr(), annot = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25, 10))\n\ncorr = df.apply(lambda x: pd.factorize(x)[0]).corr()\n\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\nax = sns.heatmap(corr, mask=mask, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, linewidths=.2, cmap='coolwarm', vmin=-1, vmax=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile = ProfileReport(df, title=\"Churn detection\", explorative=True)\nprofile","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist()\nplt.figure(figsize=(6, 6))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nlabels = df['PaymentMethod'].unique()\nvalues = df['PaymentMethod'].value_counts()\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.update_layout(title_text=\"<b>Payment Method Distribution</b>\")\nfig.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df, x=\"Churn\", color=\"PaymentMethod\", title=\"<b>Customer Payment Method distribution w.r.t. Churn</b>\")\nfig.update_layout(width=700, height=500, bargap=0.1)\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Major customers who moved out were having Electronic Check as Payment Method.\nCustomers who opted for Credit-Card automatic transfer or Bank Automatic Transfer and Mailed Check as Payment Method were less likely to move out.","metadata":{}},{"cell_type":"code","source":"g_labels = ['Male', 'Female']\nc_labels = ['No', 'Yes']\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\nfig.add_trace(go.Pie(labels=g_labels, values=df['gender'].value_counts(), name=\"Gender\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=c_labels, values=df['Churn'].value_counts(), name=\"Churn\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\", textfont_size=8)\n\nfig.update_layout(\n    title_text=\"Gender and Churn Distributions\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Gender', x=0.16, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Churn', x=0.84, y=0.5, font_size=20, showarrow=False)])\nfig.show()\n#26.6 % of customers switched to another firm. Customers are 49.5 % female and 50.5 % male.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" df[df[\"gender\"]==\"Male\"][[\"InternetService\", \"Churn\"]].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df[\"gender\"]==\"Female\"][[\"InternetService\", \"Churn\"]].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Bar(\n  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n  y = [965, 992, 219, 240],\n  name = 'DSL',\n))\n\nfig.add_trace(go.Bar(\n  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n  y = [889, 910, 664, 633],\n  name = 'Fiber optic',\n))\n\nfig.add_trace(go.Bar(\n  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n  y = [690, 717, 56, 57],\n  name = 'No Internet',\n))\n\nfig.update_layout(title_text=\"<b>Churn Distribution w.r.t. Internet Service and Gender</b>\")\n\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A lot of customers choose the Fiber optic service and it's also evident that the customers who use Fiber optic have high churn rate, this might suggest a dissatisfaction with this type of internet service.\nCustomers having DSL service are majority in number and have less churn rate compared to Fibre optic service.","metadata":{}},{"cell_type":"code","source":"color_map = {\"Yes\": \"Red\", \"No\": \"Yellow\"}\nfig = px.histogram(df, x=\"Churn\", color=\"Dependents\", barmode=\"group\", title=\"<b>Dependents distribution</b>\", color_discrete_map=color_map)\nfig.update_layout(width=500, height=600, bargap=0.1)\nfig.show()\n#Customers without dependents are more likely to churn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_map = {\"Yes\": 'yellow', \"No\": 'Green'}\nfig = px.histogram(df, x=\"Churn\", color=\"Partner\", barmode=\"group\", title=\"<b>Chrun distribution w.r.t. Partners</b>\", color_discrete_map=color_map)\nfig.update_layout(width=200, height=300, bargap=0.1)\nfig.show()\n#Customers that doesn't have partners are more likely to churn","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_map = {\"Yes\": 'Red', \"No\": 'Yellow'}\nfig = px.histogram(df, x=\"Churn\", color=\"SeniorCitizen\", title=\"<b>Chrun distribution w.r.t. Senior Citizen</b>\", color_discrete_map=color_map)\nfig.update_layout(width=300, height=400, bargap=0.1)\nfig.show()\n#It can be observed that the fraction of senior citizen is very less.Most of the senior citizens churn.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_map = {\"Yes\": \"Green\", \"No\": \"Yellow\"}\nfig = px.histogram(df, x=\"Churn\", color=\"OnlineSecurity\", barmode=\"group\", title=\"<b>Churn w.r.t Online Security</b>\", color_discrete_map=color_map)\nfig.update_layout(width=300, height=400, bargap=0.1)\nfig.show() \n#Most customers churn in the absence of online security,","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_map = {\"Yes\": 'Green', \"No\": 'Yellow'}\nfig = px.histogram(df, x=\"Churn\", color=\"PaperlessBilling\",  title=\"<b>Chrun distribution w.r.t. Paperless Billing</b>\", color_discrete_map=color_map)\nfig.update_layout(width=200, height=250, bargap=0.1)\nfig.show()\n#Customers with Paperless Billing are most likely to churn.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.box(df, x='Churn', y = 'tenure')\n\nfig.update_yaxes(title_text='Tenure (Months)', row=1, col=1)\nfig.update_xaxes(title_text='Churn', row=1, col=1)\n\nfig.update_layout(autosize=True, width=350, height=300,\n    title_font=dict(size=25, family='Courier'),\n    title='<b>Tenure vs Churn</b>',\n)\n\nfig.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\ndf.corr()['Churn'].sort_values(ascending = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    customer_id = df2['customerID'] # Store this as customer_id variable\n    del df2['customerID'] # Don't need in ML DF\nexcept:\n    print(\"already removed customerID\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use one-hot encoding to convert categorical data to binary (0 or 1)\nml_dummies = pd.get_dummies(df2)\nml_dummies.fillna(value=0, inplace=True)\nml_dummies.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies)) # Add a random column to the dataframe","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    label = ml_dummies['Churn'] # Remove the label before training the model\n    del ml_dummies['Churn']\nexcept:\n    print(\"label already removed.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_train, feature_test, label_train, label_test = train_test_split(ml_dummies, label, test_size=0.3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers = [\n    KNeighborsClassifier(5),    \n    DecisionTreeClassifier(max_depth=5)\n]\n    \n\n# iterate over classifiers\nfor item in classifiers:\n    classifier_name = ((str(item)[:(str(item).find(\"(\"))]))\n    print (classifier_name)\n    \n    # Create classifier, train it and test it.\n    clf = item\n    clf.fit(feature_train, label_train)\n    pred = clf.predict(feature_test)\n    score = clf.score(feature_test, label_test)\n    print (round(score,3),\"\\n\", \"- - - - - \", \"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_df = pd.DataFrame()\nfeature_df['features'] = ml_dummies.columns\nfeature_df['importance'] = clf.feature_importances_\nfeature_df.sort_values(by='importance', ascending=False)    \nfeature_df.set_index(keys='features').sort_values(by='importance', ascending=True).plot(kind='barh', figsize=(15, 15))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(label_test, pred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nclass_names = ['Not churned','churned']\n\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()\n\n\nfrom sklearn.metrics import classification_report\neval_metrics = classification_report(label_test, pred, target_names=class_names)\nprint(eval_metrics)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_depth_range = range(2,20,2)\nleaf_range = range(1,10,2)\nn_estimators_range = range(10,200,10)\nmax_features_range = range(1,len(ml_dummies.columns),5)\n\n\nparam_grid = dict(max_depth = max_depth_range,\n                 min_samples_leaf = leaf_range,\n                 n_estimators = n_estimators_range,\n                 max_features = max_features_range\n                )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing original dataframe\ndef preprocess_df(dataframe):\n    x = dataframe.copy()\n    try:\n        customer_id = x['customerID']\n        del x['customerID'] # Don't need in ML DF\n    except:\n        print(\"already removed customerID\")\n    ml_dummies = pd.get_dummies(x)\n    ml_dummies.fillna(value=0, inplace=True)\n\n    # import random done above\n    ml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies))\n\n    try:\n        label = ml_dummies['Churn']\n        del ml_dummies['Churn']\n    except:\n        print(\"label already removed.\")\n    return ml_dummies, customer_id, label\n\noriginal_df = preprocess_df(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_df = original_df[0].copy()\noutput_df['---randomColumn---']\noutput_df['prediction'] = clf.predict_proba(output_df)[:,1]\noutput_df['churn'] = original_df[2]\noutput_df['customerID'] = original_df[1]\nprint('Mean predict proba of churn:',round(output_df[output_df['churn'] == 1]['prediction'].mean(),2))\nprint('Mean predict proba of NON-churn:',round(output_df[output_df['churn'] == 0]['prediction'].mean(),2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activate = output_df[output_df['churn'] == 0] # Using media, target the customers who haven't churned but wants to.\nactivate[['customerID','churn','prediction']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the classification module \nfrom pycaret import classification\nfrom pycaret.classification import *","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the classification module \nfrom pycaret import classification\nclf = setup(data = ml_dummies, target = 'PhoneService', silent = True, session_id = 123, train_size = 0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compare_models()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = create_model('knn')    #train a model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_knn = tune_model(knn, n_iter = 50)   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_knn = tune_model(knn, n_iter = 150)   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_knn = tune_model(knn, optimize = 'AUC') #default is 'Accuracy'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_knn = tune_model(knn, optimize = 'Accuracy') #default is 'Accuracy'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = create_model('svm')    #train a model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_svm = tune_model(svm, n_iter = 50)   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_svm = tune_model(svm, n_iter = 100)   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_svm = tune_model(svm, optimize = 'Accuracy') #default is 'Accuracy'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best results from the model:\n\n        Accuracy  AUC\t Recall\tPrec.\t  F1\t      Kappa\t     MCC\nMean\t0.9050\t 0.7899\t  1.0000\t0.9048\t 0.9500\t      0.0421\t    0.1134    #knn\n\n\nMean\t0.9391\t 0.0000\t  1.0000\t0.9370\t 0.9674\t      0.5105 \t    0.5856    #svm ","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_model = SVC(random_state = 1)\nsvc_model.fit(feature_train,label_train)\npredict_y = svc_model.predict(feature_test)\naccuracy_svc = svc_model.score(feature_test,label_test)\nprint(\"SVM accuracy is :\",accuracy_svc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(label_test, predict_y))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(4,3))\nsns.heatmap(confusion_matrix(label_test, pred),\n                annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n    \nplt.title(\"FINAL CONFUSION MATRIX\",fontsize=14)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the confusion matrix we can see that: There are total 435+156=570 actual non-churn values and the algorithm predicts 435 of them as non churn and 156 of them as churn. While there are 128+424=552 actual churn values and the algorithm predicts 124 of them as non churn values and 424 of them as churn values.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}