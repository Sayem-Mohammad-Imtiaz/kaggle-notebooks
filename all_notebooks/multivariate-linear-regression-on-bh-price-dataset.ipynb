{"cells":[{"metadata":{"id":"EluqnRbypFgR","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nimport warnings #to remove warning from the notebook\nwarnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"zGfNDO8wprE6","outputId":"1df1f123-76f1-4573-c087-4db1bf8ccb10","trusted":true},"cell_type":"code","source":"#loading dataset\nname= ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndf = pd.read_csv('../input/boston-house-prices/housing.csv',delim_whitespace=True,names=name)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"hTuNTNsV8o2m"},"cell_type":"markdown","source":"# Review Boston House prices dataset"},{"metadata":{"id":"P-xTWNK9tLyw","outputId":"6275b606-a86c-452f-de2c-fe99f3801306","trusted":true},"cell_type":"code","source":"nRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"id":"fUA1THJAtPXU","outputId":"6373c765-c260-4845-cd28-4d66ed8438c0","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"GE6PccMj7zzt"},"cell_type":"markdown","source":"- There are no missing values present in this dataset\n- All the columns have numrical values, hence we dont have to do encoding for categorical values, in order to perform Linear Regression"},{"metadata":{"id":"BCpU9qXztVkV","outputId":"89f80619-09dc-4f05-a77f-c6a246acf8b1","trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"9PoveRm_TDXE"},"cell_type":"markdown","source":"- There are no null values "},{"metadata":{"id":"-CEuo8aGtdLr","outputId":"c25e91c4-0224-4596-a06a-ac7a90fc740d","trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"id":"P6DHQN9-7xy-"},"cell_type":"markdown","source":"Observations:\n- INDUS, RM, TAX, PTRATIO and LSTAT shows fairly good correlation with MEDV"},{"metadata":{"id":"hYj_FgC3tk-1","outputId":"bf579f80-bc0c-4cb6-fb17-548cc109535e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,9))\nsns.heatmap(data=df.corr().round(2),annot=True,linewidths=0.2,square=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"SNsHguw96cdq"},"cell_type":"markdown","source":"Observations:\n- NOX shows goor corr with INDUS and AGE\n- INDUS shows good corr with LSAT and DIS\n- DIS shows stron corr with INDUS, RM and AGE \n\nHence Multicollinearity exists in this dataset"},{"metadata":{"id":"VI7uPYL28hZw"},"cell_type":"markdown","source":"# Choose 2 features to predict the target\nHere we choose RM and LSTAT as the 2 features"},{"metadata":{"id":"MCP6XyOE6b2c","outputId":"11ded377-13bc-42e6-d292-36e2055d0325","trusted":true},"cell_type":"code","source":"df1 = df[['RM','LSTAT','MEDV']]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"kmA72sip9NFc","outputId":"84b668e2-125c-4352-d364-fd987721cad9","trusted":true},"cell_type":"code","source":"sns.pairplot(data=df1)","execution_count":null,"outputs":[]},{"metadata":{"id":"to_yGnOL9W-n"},"cell_type":"markdown","source":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- LSTAT shows quite a negatively skewed graph\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Position Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- RM and LSTAT, and MEDV and LSTAT have negative linear relationship between them, alongith the presence of few outliers"},{"metadata":{"id":"qPv2iHcb-mFv","outputId":"4c254a5b-6b92-4619-cbc3-197fb36d30be","trusted":true},"cell_type":"code","source":"#description about this data\ndf1.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"swb4ULVC-5ci"},"cell_type":"markdown","source":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV and LSTAT are much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor LSTAT:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- There is a significant difference between the mean and 50% quartile value\n- Hence LSTAT does not have normal distribution"},{"metadata":{"id":"EAfeB2TNABsc","outputId":"ef41c2fc-be62-4d59-f541-8e0189be8580","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"A-qK799iGZIa"},"cell_type":"markdown","source":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers\n"},{"metadata":{"id":"L8IQhwUnP4rX"},"cell_type":"markdown","source":"## REMOVING OUTLIERS"},{"metadata":{"id":"fqUQE5uXGk8v","outputId":"12d92318-b5e9-463a-d23c-523aa4cba573","trusted":true},"cell_type":"code","source":"df2 = df1[~(df1['MEDV']==50)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"WAtrazrSGzO3","outputId":"f77d08d9-126b-4fdb-ea30-12d5c14b1b00","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"KyqkezKnHH6U"},"cell_type":"markdown","source":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50"},{"metadata":{"id":"_Dvzz008CD_Y","outputId":"7880f605-1a4d-4917-9ad8-f55dfffea4e6","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"f2Dk1DcuHqTl"},"cell_type":"markdown","source":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show good Positive Linear Relationship."},{"metadata":{"id":"YM14Xz_tII__","outputId":"abce26f4-7690-4d09-c27f-4e2f6938c345","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['RM']>7.7]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"bMxFM0n-KlYi","outputId":"3946db42-e926-4e94-8c4b-7201e7e2f265","trusted":true},"cell_type":"code","source":"temp_df1 = df2[df1['RM']<4.7]\ntemp_df1.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"QH7RS1qOKH0I","outputId":"204a5afa-870a-4687-9b60-f20856dde049","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']>7.7)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"NBffi_u0M3Wp","outputId":"0ba18d68-63af-44d4-f46a-f285f1fa2b10","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']<4.7)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"DhJVqtL0Uj0T","outputId":"bff9f8a7-bbc4-468e-fcef-7ffb455ab832","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"rN0gvKVcUw5p"},"cell_type":"markdown","source":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7"},{"metadata":{"id":"A_rGDbCdBbq1","outputId":"dff82ff6-064f-4489-99de-806966fd6e8c","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"rp3rLWBwNzCV","outputId":"cc77b743-911a-412c-a2c3-88601f7eab6f","trusted":true},"cell_type":"code","source":"temp_df1 = df2[df1['LSTAT']>31]\ntemp_df1.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"rBGinNT4OFJ6","outputId":"cbad6679-5792-421b-bccc-cadd0d54de74","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"xtRfDmMCVLsP","outputId":"e5509066-aae9-4aa7-f255-ea776db62f64","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"gZJ0eJ9FVVBz"},"cell_type":"markdown","source":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 40 (506-470) rows from out dataset having LSTAT value as >31"},{"metadata":{"id":"sQ302NhZPv12"},"cell_type":"markdown","source":"## SPLITTING THE DATASET"},{"metadata":{"id":"i29u-Uk2PvCK","trusted":true},"cell_type":"code","source":"#Now will split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","execution_count":null,"outputs":[]},{"metadata":{"id":"NouEYZGVQI-G","outputId":"930bd37a-7eb6-4118-cf83-dc62b6277163","trusted":true},"cell_type":"code","source":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"BlJz7IfpQwP1"},"cell_type":"markdown","source":"### FEATURE SCALING using sklearn"},{"metadata":{"id":"tcoW6lYqQLxk","outputId":"d47d71e6-e6d7-48b7-c739-5a5618a6a9e1","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"04dl7GcVQnPo","outputId":"be2b16b0-53d3-45c1-b17f-6e729440acb2","trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"id":"y59U7DgmQn5G","outputId":"1f5859cf-1eb9-4ea6-9bcf-480e9ba6da4c","trusted":true},"cell_type":"code","source":"x_scaled = scaler.transform(x)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"Xkzw8xfcQ2QB","outputId":"168f7f50-0c2b-4c6c-c0e9-3e338b3da314","trusted":true},"cell_type":"code","source":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"raCaGAOuWwq4"},"cell_type":"markdown","source":"- Since we need to add a variable for Bias, we add a new column of 1's in X as the first column.\n"},{"metadata":{"id":"L5j_rusoQ-wY","trusted":true},"cell_type":"code","source":"x=x_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"oLOJBWq_RLoj"},"cell_type":"markdown","source":"### TEST & TRAIN DATASET (80-20)\n> We split the data into Training Set (80% of total data) and Test Set (20% of total data)\n\n\n\n\n\n"},{"metadata":{"id":"gUmf98zTRK-J","outputId":"d3876a86-b63b-4d58-9cd7-a9a3bb9178d3","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ipLbTrP3R3FD","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model","execution_count":null,"outputs":[]},{"metadata":{"id":"wVAzthOyR7xu","outputId":"9b6c9b59-052f-449a-e38f-2ecd9e90e0d9","trusted":true},"cell_type":"code","source":"lin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"oRvzNl7ZSAPT","outputId":"b6f95dca-b1ef-4358-d693-6be3758f4120","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_11 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_12 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_11)\nprint(\"R^2 value: \",test_set_r2_12)","execution_count":null,"outputs":[]},{"metadata":{"id":"G5eWGUkXV3fa"},"cell_type":"markdown","source":"- We know, the higher the R-squared value, the more accurately the regression equation models your data\n- ALso, RMSE measures how accurately the model predicts the response, hence it's an important criterion for fit if the main purpose of the model is prediction.\n- This is a good regression model as the R square score is near 1.0, and the RMSE error is not very large."},{"metadata":{"id":"nTQhFcHKjQ3-"},"cell_type":"markdown","source":"### Scatter plot of predicted vs actual test house prices along with the Regression Line"},{"metadata":{"id":"5VwasYuOSAQ0","outputId":"8de05c0a-fb51-43fe-bacd-ca437263e474","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"bR9U8I8RWCpF"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- But overall, this model fits the data well, as there is fairly small difference between majority of the datapoints and the best fit line"},{"metadata":{"id":"bRrAz_6xrCSd"},"cell_type":"markdown","source":"### TEST & TRAIN DATASET (60-40)\n> We split the data into Training Set (60% of total data) and Test Set (40% of total data)"},{"metadata":{"id":"2jfLtruIrHxX","outputId":"c32f9937-88b2-40f6-a338-5dae7abd3509","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CRDmTyYbrh8D","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model","execution_count":null,"outputs":[]},{"metadata":{"id":"ZlBoLogsrmFl","outputId":"b76c1109-e47b-4fe4-d84a-cc65aa138922","trusted":true},"cell_type":"code","source":"lin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"xgmqYdQmrod9","outputId":"cb5c155c-5574-49aa-b73e-cfaaa6d96be8","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_13 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_14 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_13)\nprint(\"R^2 value: \",test_set_r2_14)","execution_count":null,"outputs":[]},{"metadata":{"id":"pT-fjyRFqvlr"},"cell_type":"markdown","source":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is not very large."},{"metadata":{"id":"42CoMAIDr5Tp"},"cell_type":"markdown","source":"**Scatter plot of predicted vs actual test house prices along with the Regression Line**"},{"metadata":{"id":"n7_ytAQbroqM","outputId":"7f39cb4e-866d-47f9-d216-0d9594f5fdac","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"SQtBGfhRhIl_"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model fits does not really the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"HwyJZ6M4DFXt"},"cell_type":"markdown","source":"# Choose 5 sets of features to predict\n\n```\n- 1st set : RM and TAX\n- 2nd set : LSTAT and PTRATIO\n- 3rd set : RM and PTRATIO\n- 4th set : LSTAT, TAX and PTRATIO\n- 5th set : RM, LSTAT and PTRATIO\n```\n\n"},{"metadata":{"id":"rpkJrU6HXGlP"},"cell_type":"markdown","source":"## 1st set : RM and TAX"},{"metadata":{"id":"UytJP6ylGH_L","outputId":"663dfb49-7093-4c09-bfb2-f454c3dbb9a5","trusted":true},"cell_type":"code","source":"df1 = df[['RM','TAX','MEDV']]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"qg6eyWJveIpj","outputId":"841f095f-7e3d-44a8-e3cd-faa6c8c22c22","trusted":true},"cell_type":"code","source":"sns.pairplot(data=df1)","execution_count":null,"outputs":[]},{"metadata":{"id":"jtNQOCcyeWuR"},"cell_type":"markdown","source":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- TAX does not show normal distribution\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Positive Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- There is no relation between MEDV and TAX"},{"metadata":{"id":"PVJSuc4qetQA","outputId":"cedcf733-6c2d-43d5-e9ca-200c0b900899","trusted":true},"cell_type":"code","source":"df1.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"3I5eQpu_eypb"},"cell_type":"markdown","source":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor TAX:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- There is a significant difference between the mean and 50% quartile value\n- Hence TAX does not have normal distribution"},{"metadata":{"id":"bqEX9ZFmfJqR","outputId":"0dfbf181-dfbc-4671-d439-d8b8453a3f76","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"v1aQjyzxfPXC"},"cell_type":"markdown","source":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers"},{"metadata":{"id":"s6PYVfsQfWq9","outputId":"97d0e351-cb16-4e3e-fa36-36e3c00ec6ba","trusted":true},"cell_type":"code","source":"df2 = df1[~(df1['MEDV']==50)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"tmEkSkjbfbLu","outputId":"5dec8d03-4e9c-4c6a-c824-abb4d0eb63ed","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"uK9p_uY2ffar"},"cell_type":"markdown","source":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50"},{"metadata":{"id":"gnwAP53rfge1","outputId":"14b80289-7ac6-4812-9905-00bf7ca51b62","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"yFylAh_Jfo5f"},"cell_type":"markdown","source":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show fairly good Positive Linear Relationship."},{"metadata":{"id":"fsP10kCgf1d9","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']>7.7)]","execution_count":null,"outputs":[]},{"metadata":{"id":"LU7Nh39Rf2C6","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']<4.7)]","execution_count":null,"outputs":[]},{"metadata":{"id":"hO3NxWJWgH_G","outputId":"e064058d-cfb1-4fd1-c0f4-441c097cf5fa","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"k4Vn0kHOgTj_"},"cell_type":"markdown","source":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7"},{"metadata":{"id":"j_utDLGAgmQJ","outputId":"9e388527-8e88-403f-a420-7b4e57131091","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for TAX\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.TAX)\nplt.title('Box Plot of TAX')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.TAX)\nplt.title('Distribution Plot of TAX')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.TAX,df1.MEDV)\nplt.title('Scatter Plot of TAX vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"nonDhRg9gwkN"},"cell_type":"markdown","source":"Observations:\n- Graph of TAX is NOT normally distributed\n- Though Boxplot does not show any outlier but there are some extreme TAX values in the dataset\n- From the scatter plot we can observe that for these extreme TAX values, and MEDV ranges from low to high.\n"},{"metadata":{"id":"PPol-VjNhBFm","outputId":"7c8994f4-3f59-4e06-fa7f-0d587c2fc4ea","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['TAX']>600]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"mqTFB3uFhHPc"},"cell_type":"markdown","source":"- There are total 123 entries in TAX mostly having value 666\n"},{"metadata":{"id":"Nfg82PfFhSP5","outputId":"5c519db0-d097-4db9-b17f-b8a300842984","trusted":true},"cell_type":"code","source":"temp_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"robyEA0OhgBs"},"cell_type":"markdown","source":"Observations:\n- RM for these entries lies between 4.88 to 7.39\n- MEDV for these entries lies between 14.93 to 29.80.\n- It seems impossible to have such high TAX values for all these houses.\n- These values most likely missing values which were imputed casually by someone\n\nHence, we cannot remove so many values from our dataset"},{"metadata":{"id":"-XGSm3VOh45P","trusted":true},"cell_type":"code","source":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","execution_count":null,"outputs":[]},{"metadata":{"id":"L_tYXgq9idQO","outputId":"100b9b27-e45a-4353-b9c1-876b4da9ad4a","trusted":true},"cell_type":"code","source":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"qRy4mJnfihvL","outputId":"aacbf7bf-0334-44b1-db0e-88a4b195cbfb","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"_ndJHrbdik_o","outputId":"ce6492bd-c270-478e-beaa-f3628cb97a84","trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"id":"SbFpC2jqiocb","outputId":"f4d856e8-cc15-4b38-cbe7-646c52e77166","trusted":true},"cell_type":"code","source":"x_scaled = scaler.transform(x)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"5-PO__1Jirpp","outputId":"f0fde077-5a28-40ff-d944-834e06f97060","trusted":true},"cell_type":"code","source":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"2ud7zQgqiwSm","trusted":true},"cell_type":"code","source":"x=x_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"7cWGsHqCi4CA"},"cell_type":"markdown","source":"### 80-20 Split"},{"metadata":{"id":"GyngCcrIixr9","outputId":"43a85d5b-ec86-4d6a-f798-c9db8cea2277","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"OWbnzJ-VjCrr","outputId":"445977bf-e429-4657-913a-b64f5d721f09","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"5AYKs01mjJMN","outputId":"fb4a235c-0b62-4f7c-c8fc-8c8b4867c42a","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_21 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_22 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_21)\nprint(\"R^2 value: \",test_set_r2_22)","execution_count":null,"outputs":[]},{"metadata":{"id":"Uoe_RyKUkZB9"},"cell_type":"markdown","source":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is not very large."},{"metadata":{"id":"jneE5UYqjmjT","outputId":"8d66adae-356a-44b4-de46-3cd1c99c460d","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"fsoPkopLkjS2"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"4D8fIj3wjvgF"},"cell_type":"markdown","source":"### 60-40 Split"},{"metadata":{"id":"RVDfyF0Tjy25","outputId":"b440c9d6-a339-4861-df89-7360bd28bc8d","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"01w000qcj9aW","outputId":"c0e7cd4d-41f6-4090-f3eb-353796b23212","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"OAa7RpuBkAY6","outputId":"1d7b5129-ae31-4351-ad82-f0520c56e414","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_23 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_24 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_23)\nprint(\"R^2 value: \",test_set_r2_24)","execution_count":null,"outputs":[]},{"metadata":{"id":"TZbrk-CskaQi"},"cell_type":"markdown","source":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is not very large.\n- But the results of 80-20 split are better than this to train the dataset"},{"metadata":{"id":"wq6YZIydkDW4","outputId":"b92f79df-c427-4150-cfb6-1eb6a6a45824","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ssvrD9ZKkkoO"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"ZHYm5IavXXG1"},"cell_type":"markdown","source":"## 2nd set : LSTAT and TAX"},{"metadata":{"id":"O_x2lho7pt_N","outputId":"362236a5-0938-42ad-f6e2-53c7fa76ad9a","trusted":true},"cell_type":"code","source":"df1 = df[['LSTAT','TAX','MEDV']]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Iz28ReihqfIJ","outputId":"cd0c0f6b-c801-4d20-8492-72e5116d47ec","trusted":true},"cell_type":"code","source":"sns.pairplot(data=df1)","execution_count":null,"outputs":[]},{"metadata":{"id":"5kve4F-uqrcG"},"cell_type":"markdown","source":"Observations:\n- LSTAT shows quite a negatively skewed graph\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Negative Linear correlation is present between LSTAT and MEDV. There are a few outliers present near 50\n- There is no relation between MEDV and TAX\n- Normal Distribution is not present in the graph of TAX"},{"metadata":{"id":"gehgZuqCrW4P","outputId":"dce1a228-8038-47dd-999d-c9fa1821530d","trusted":true},"cell_type":"code","source":"df1.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"wHamjoK1rcsV"},"cell_type":"markdown","source":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n\nFor LSTAT & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- The mean and 50% value is nearly equal\n\nFor TAX:\n- There is a significant difference between the mean and 50% quartile value\n- The difference between the min and 50% quartile, and between 50% and max value is almost equal\n- Hence TAX does not have normal distribution"},{"metadata":{"id":"tjOyTTvMsN6K","outputId":"9b3e3884-4d7b-4479-d811-317751ab83ac","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Vu00D5FNsSDO"},"cell_type":"markdown","source":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers"},{"metadata":{"id":"TyAoI7OIsTzX","outputId":"19cc0050-1954-4c96-901b-0180d8b223a7","trusted":true},"cell_type":"code","source":"df2 = df1[~(df1['MEDV']==50)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"WQ7jmy_TsYKc","outputId":"b8947451-9830-419d-e8d4-40de64097d99","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"a6iOfkZCscEw"},"cell_type":"markdown","source":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50"},{"metadata":{"id":"d14f-7k0sqI2","outputId":"6dfc465a-2ac7-4420-dae4-5b42d179e00f","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"I8Ign1ZHxutC"},"cell_type":"markdown","source":"- Web observe that th egraph of LSTAT is negatuvely skewed, with outliers present after approximately 31 value"},{"metadata":{"id":"sQd8fVhksxDl","outputId":"f1e25072-0025-47f5-9098-a35df4930e82","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"5gY0AUQbs23p","outputId":"3359a235-9e8a-4eac-f703-9085e065e7a7","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"82-UIbHns4D_"},"cell_type":"markdown","source":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 23 (506-483) rows from out dataset having LSTAT value as >31"},{"metadata":{"id":"nQuWh87atOlu","outputId":"f177f5d0-a6c8-43ac-8806-0a2e3a7189b8","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for TAX\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.TAX)\nplt.title('Box Plot of TAX')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.TAX)\nplt.title('Distribution Plot of TAX')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.TAX,df1.MEDV)\nplt.title('Scatter Plot of TAX vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"RhVpw_n7tXqO"},"cell_type":"markdown","source":"Observations:\n- Graph of TAX is NOT normally distributed\n- Though Boxplot does not show any outlier but there are some extreme TAX values in the dataset\n- From the scatter plot we can observe that for these extreme TAX values, and MEDV ranges from low to high."},{"metadata":{"id":"RAzIZqKItTEy","outputId":"9f9a4251-2576-4bcc-caf9-e70099375a65","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['TAX']>600]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"4RXI2QQ8totG"},"cell_type":"markdown","source":"- There are total 126 entries in TAX mostly having value 666"},{"metadata":{"id":"P2c08QxXtevi","outputId":"ae7439f2-2a5d-4f4c-88ed-b456fff0d086","trusted":true},"cell_type":"code","source":"temp_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"dGG1N5rXtvgF"},"cell_type":"markdown","source":"Observations:\n- LSTAT for these entries lies between5.29 to 30.81\n- MEDV for these entries lies between 5.00 to 29.80.\n- It seems impossible to have such high TAX values for all these houses.\n- These values most likely missing values which were imputed casually by someone\n\nHence, we cannot remove so many values from our dataset"},{"metadata":{"id":"X9lQuhaJt_M-","trusted":true},"cell_type":"code","source":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","execution_count":null,"outputs":[]},{"metadata":{"id":"HKvLSitbuDG9","outputId":"04471f87-d6d0-4573-9a83-0bff1b136fe0","trusted":true},"cell_type":"code","source":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"7arnOY6kuGZI","outputId":"2dc9fa76-9308-40eb-d911-877e99f3575f","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"ToLl5c7FuKqJ","outputId":"bde87610-5219-4542-ee87-354a436f8883","trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"id":"68c_w464uL4u","outputId":"ec56ae94-20bc-489e-f4b9-5e43d60edde0","trusted":true},"cell_type":"code","source":"x_scaled = scaler.transform(x)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"VD-eZI9EuPg-","outputId":"e9794be3-631e-41ee-a043-e93df5ca532d","trusted":true},"cell_type":"code","source":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"KrQ5sR_LuTPc","trusted":true},"cell_type":"code","source":"x= x_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"E04k4ReLuYsP"},"cell_type":"markdown","source":"### 80-20 Split"},{"metadata":{"id":"aejyePqbugEc","outputId":"a08657c5-10d5-40a6-9af6-190cc4700041","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"uuLiLKXZul_G","outputId":"c1130216-fc30-4748-9fa0-a8f18fe6d294","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"879g8_gAupc9","outputId":"b19dfa65-8fd9-4c9d-f020-412babcab7e9","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_31 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_32 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_31)\nprint(\"R^2 value: \",test_set_r2_32)","execution_count":null,"outputs":[]},{"metadata":{"id":"81LeAH70rABK"},"cell_type":"markdown","source":"- The R square score is not near 1.0\n- The RMSE error is quite large\n- Hence this is not a great regresstion model"},{"metadata":{"id":"xZrw8djLuq5T","outputId":"cd7ad5e4-e2f9-46b4-eeac-83bd954c328a","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"sJphE94Qh9Pe"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"4LZxxeyRub06"},"cell_type":"markdown","source":"### 60-40 Split"},{"metadata":{"id":"DRQI30lluVwd","outputId":"c3666c8a-5498-4ac4-e39d-d328c8c3294f","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"bSpzmZG6u2UW","outputId":"90ea1c41-2577-4328-ba96-ce9fb57c1472","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"nrRnk4dju5bj","outputId":"155966a3-dc14-4eba-b9e1-edaa585f1bb0","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_33 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_34 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_33)\nprint(\"R^2 value: \",test_set_r2_34)","execution_count":null,"outputs":[]},{"metadata":{"id":"LikYkQtirO_f"},"cell_type":"markdown","source":"- The R square score is not near 1.0\n- The RMSE error is quite large\n- Hence this is not a great regression model\n- We also infer that 80-20 split of the dataset showed better results for this set"},{"metadata":{"id":"GF-yJaWOu6vv","outputId":"fe4abd32-59b9-4e31-d0bb-41cbb4dcc600","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"R22oVV0Wh_TE"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"1rCqZtfJf9on"},"cell_type":"markdown","source":"## 3rd set : RM and PTRATIO"},{"metadata":{"id":"ymms9M_Mkv_D","outputId":"15f17074-a57f-47e0-a6e2-b709e7c562ae","trusted":true},"cell_type":"code","source":"df1 = df[['RM','PTRATIO','MEDV']]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Zr8NXjP5k2JW","outputId":"3e6ebeeb-abad-4dfe-c68f-7b5a3b7b2f9e","trusted":true},"cell_type":"code","source":"sns.pairplot(data=df1)","execution_count":null,"outputs":[]},{"metadata":{"id":"tk3Xwtlzk73o"},"cell_type":"markdown","source":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- PTRATIO does not show normal distribution. Graph of PTRATIO is positively skewed with presence of few outliers\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Positive Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- There is no relation between MEDV and PTRATIO"},{"metadata":{"id":"CuI9wmsllHKC","outputId":"29655b66-25b4-4ee8-e0e5-8d912ba81827","trusted":true},"cell_type":"code","source":"df1.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"a2dn9kUilWiT"},"cell_type":"markdown","source":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor PTRATIO:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- The difference between the mean and 50% quartile value is small\n- Hence PTRATIO does not have normal distribution"},{"metadata":{"id":"bBO337MFl4J4","outputId":"ed842b89-d465-496d-e7e2-32c42699021f","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"3AbSqqMUl8fy"},"cell_type":"markdown","source":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers"},{"metadata":{"id":"BJvcvxgimAjn","outputId":"9e597f7f-eaf4-4dac-d488-125087ed5d3e","trusted":true},"cell_type":"code","source":"df2 = df1[~(df1['MEDV']==50)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"z8NF2qiimFqe","outputId":"af0292f6-e6d4-4270-d393-741e2e02bee9","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"pajr2PzDmGL4"},"cell_type":"markdown","source":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50"},{"metadata":{"id":"wdtgVe6XmTbO","outputId":"74c325b1-f428-4fb0-90fa-98dc618ffb50","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Gds3EKuqmVMq"},"cell_type":"markdown","source":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show fairly good Positive Linear Relationship."},{"metadata":{"id":"HRfZZDuomauU","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']>7.7)]","execution_count":null,"outputs":[]},{"metadata":{"id":"cqweG8fzmbOQ","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']<4.7)]","execution_count":null,"outputs":[]},{"metadata":{"id":"CoUXf1FtmkXc","outputId":"b2f57f0c-57d0-4808-88eb-60778d3840ea","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"kgeHH-X5msc6"},"cell_type":"markdown","source":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7"},{"metadata":{"id":"zpKvBH2Smza9","outputId":"b0ab1161-567e-4c3b-f352-7841a06fd573","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for PTRATIO\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.PTRATIO)\nplt.title('Box Plot of PTRATIO')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.PTRATIO)\nplt.title('Distribution Plot of PTRATIO')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.PTRATIO,df1.MEDV)\nplt.title('Scatter Plot of PTRATIO vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"sUfVBjC5nGxi","outputId":"a8fca67c-e287-4dbe-9a91-7e50eb5cb744","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['PTRATIO']<13]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"rP-Cp8o0nnQ5","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['PTRATIO']<13)]","execution_count":null,"outputs":[]},{"metadata":{"id":"yu-6KNlentOv","outputId":"24757c04-13e6-4bcd-d6a5-95676bc939cf","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"OBLCftTNn0y7"},"cell_type":"markdown","source":"- Now the maximum value of PTRATIO column is 22\n- Hence we have deleted 39 (506-467) rows from out dataset having PTRATIO value as < 13"},{"metadata":{"id":"zUXW2aawoHbz","trusted":true},"cell_type":"code","source":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","execution_count":null,"outputs":[]},{"metadata":{"id":"OsaT3s29oLq3","outputId":"9ffae119-53c4-4772-b296-a9789e93366e","trusted":true},"cell_type":"code","source":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"MEo-Zx9aoPkH","outputId":"b00faeb8-8187-40f1-d7b1-75f0eb598ada","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"cUc_yB3FoQeT","outputId":"30554ed9-edcd-4f9f-ca8e-ff22e1976ce5","trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"id":"OnCeSRcXoSAN","outputId":"015b3a80-f645-4899-ce38-d617065694df","trusted":true},"cell_type":"code","source":"x_scaled = scaler.transform(x)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"FiH_X0LYoZeQ","outputId":"cdb04d8f-b331-4949-a418-5a0bd8bbce66","trusted":true},"cell_type":"code","source":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"kuvETo36odPf","trusted":true},"cell_type":"code","source":"x=x_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"2vFHfNrqoeTe"},"cell_type":"markdown","source":"### 80-20 Split"},{"metadata":{"id":"skdKQsFWomGz","outputId":"c9912cc8-5f63-452a-bddc-8f6fec2b515b","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"J8Jr8PRtovHf","outputId":"3f3b1d37-5bf6-41cd-d0c7-fd9c9e8061e3","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"NvUHlRctoxBv","outputId":"50a02e8c-465f-4ae8-feb2-8d91f869ab32","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_41 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_42 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_41)\nprint(\"R^2 value: \",test_set_r2_42)","execution_count":null,"outputs":[]},{"metadata":{"id":"xZeFgyvvrwc5"},"cell_type":"markdown","source":"- The R square score is approx. 0.5 and it's not near 1.0\n- The RMSE error is large\n- Hence this is not a good regression model"},{"metadata":{"id":"kexGyptao5Ty","outputId":"a6264cb2-3a83-4a4b-dc35-44cb6646fccf","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"iz-6cPctRQEY"},"cell_type":"markdown","source":"- We infer that there's positive linear relationship with the regression fit line\n- From the graph, some of the actual value points are above the line, and some are below the regression best fit line.\n- This model does not fit the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"GlfSDTBfoiug"},"cell_type":"markdown","source":"### 60-40 Split"},{"metadata":{"id":"e-jHuysQonAH","outputId":"b84945ca-c295-4e26-91f2-f8bff667f0a6","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"7iCUFtZZpGD8","outputId":"48caadb9-c375-4d26-c923-824ffca66d75","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"c-avK9RBpIpq","outputId":"badf3568-8781-4e3a-97f9-73b0703865aa","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_43 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_44 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_43)\nprint(\"R^2 value: \",test_set_r2_44)","execution_count":null,"outputs":[]},{"metadata":{"id":"TTvMbX1Hr9m_"},"cell_type":"markdown","source":"- The R square score is approx. 0.5 and it's not near 1.0\n- The RMSE error is large\n- Hence this is not a good regression model"},{"metadata":{"id":"zZX2pYm5pJ8c","outputId":"bb8795c4-25e3-4191-ae74-1f5f1c5cc551","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"Bom99KeLiP1s"},"cell_type":"markdown","source":"- We infer that there's positive linear relationship with the regression fit line\n- From the graph, some of the actual value points are above the line, and some are below the regression best fit line.\n- This model does not fit the data well, as there are difference present between many of the datapoints and the best fit line"},{"metadata":{"id":"Wq1yUIH9Xb1E"},"cell_type":"markdown","source":"## 4th set : TAX, LSTAT and PTRATIO"},{"metadata":{"id":"qUxqloHRvvVe","outputId":"bbd3fb5f-b5f9-4946-caef-08fcec6d108d","trusted":true},"cell_type":"code","source":"df1 = df[['TAX','LSTAT','PTRATIO','MEDV']]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"KDbipbgB2Xbq","outputId":"36ef9cf3-9d93-4054-af76-36bbecd57cd1","trusted":true},"cell_type":"code","source":"sns.pairplot(data=df1)","execution_count":null,"outputs":[]},{"metadata":{"id":"YqRcUKha2gMm"},"cell_type":"markdown","source":"Observations:\n- Normal Distribution is not present in the graph of TAX\n- LSTAT shows quite a negatively skewed graph\n- Graph of PTRATIO is positively skewed with presence of few outliers\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Negative Linear correlation is present between LSTAT and MEDV. There are a few outliers present near 50\n- There is no strong relationship between any other pair of features\n"},{"metadata":{"id":"P16M0Y4R2Xn7","outputId":"950f462f-0df6-45cd-b558-7e07daa2fa20","trusted":true},"cell_type":"code","source":"df1.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"AEW2UtAZvZ3i"},"cell_type":"markdown","source":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n- The mean and 50% value is nearly equal in value for LSTAT, PTRATIO & MEDV\n\nFor LSTAT & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n\nFor TAX:\n- There is a significant difference between the mean and 50% quartile value\n- The difference between the min and 50% quartile, and between 50% and max value is almost equal\n- Hence TAX does not have normal distribution\n\nFor PTRATIO:\n- The difference between the min and 50% quartile is greater than, that present between 50% and max value.\n- Hence, the graph of PTRATIO is positively skewed"},{"metadata":{"id":"vHoGAJ6B2Xty","outputId":"653031b5-e0dc-4d03-8d66-c1295512ca4f","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"k_jk8qkmw-uC"},"cell_type":"markdown","source":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers"},{"metadata":{"id":"HlO1Pvgk2X1r","outputId":"b1743c52-f4f6-43f4-80a9-b4187b89920d","trusted":true},"cell_type":"code","source":"df2 = df1[~(df1['MEDV']==50)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"lu8ZVWLz2X8p","outputId":"38af8e71-fa40-451d-b03c-84f9b21d2bd1","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"Vg0pM1sHxIIn"},"cell_type":"markdown","source":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50"},{"metadata":{"id":"49XZxQ2gxIbB","outputId":"b0ee5bfa-04cc-4f91-8aa5-cefd17c6a5c2","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"vO007M0MxkS5"},"cell_type":"markdown","source":"- Web observe that th egraph of LSTAT is negatuvely skewed, with outliers present after approximately 31 value"},{"metadata":{"id":"XJ7V230HxQri","outputId":"9ad19e4b-e9c7-4dc8-99e8-91bf528b6394","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"aC1D_qTlxQwd","outputId":"58f673ba-e6f2-4161-e76f-faa3473a25a8","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"d49D9YZ9xbez"},"cell_type":"markdown","source":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 23 (506-483) rows from out dataset having LSTAT value as >31"},{"metadata":{"id":"7Ux-1n8cxQ2n","outputId":"bfcee765-4101-40dc-b234-89b33bc1b36f","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for TAX\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.TAX)\nplt.title('Box Plot of TAX')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.TAX)\nplt.title('Distribution Plot of TAX')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.TAX,df1.MEDV)\nplt.title('Scatter Plot of TAX vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"cCZcd68wx6s9"},"cell_type":"markdown","source":"Observations:\n- Graph of TAX is NOT normally distributed\n- Though Boxplot does not show any outlier but there are some extreme TAX values in the dataset\n- From the scatter plot we can observe that for these extreme TAX values, and MEDV ranges from low to high."},{"metadata":{"id":"AFeHbH4DxQ8P","outputId":"440bfc61-09ec-46e5-a253-26f83f978309","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['TAX']>600]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"6AAennM7xQ_q","outputId":"8f7ad66e-5292-476c-e105-8a64aad98cda","trusted":true},"cell_type":"code","source":"temp_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"R_q6Dv88yGW_"},"cell_type":"markdown","source":"Observations:\n- almost 126 rows have TAX value as 666\n- LSTAT for these entries lies between5.29 to 30.81\n- MEDV for these entries lies between 5.00 to 29.80\n- It seems impossible to have such high TAX values for all these houses\n- These values most likely missing values which were imputed casually by someone\n\nHence, we cannot remove so many values from our dataset"},{"metadata":{"id":"zWECD6s1yUl1","outputId":"a064af5e-32a6-45c3-ce03-0bd0700cb417","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for PTRATIO\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.PTRATIO)\nplt.title('Box Plot of PTRATIO')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.PTRATIO)\nplt.title('Distribution Plot of PTRATIO')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.PTRATIO,df1.MEDV)\nplt.title('Scatter Plot of PTRATIO vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"k-r5d5DeyZu9","outputId":"2dcd1531-90b3-4e2d-bfa1-bef418d8ad7a","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['PTRATIO']<13]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"YSuwznKpyZyi","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['PTRATIO']<13)]","execution_count":null,"outputs":[]},{"metadata":{"id":"CHX0NxohyZ4b","outputId":"23ac76b8-6925-46f1-d184-d1e8d371f1ce","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"wGfZ-AixzU1m"},"cell_type":"markdown","source":"- Now the maximum value of PTRATIO column is 22\n- Hence we have deleted 39 (506-467) rows from out dataset having PTRATIO value as < 13"},{"metadata":{"id":"MkiecwQ_zQ0n","trusted":true},"cell_type":"code","source":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:3].values\ny = df2.iloc[:,-1:].values","execution_count":null,"outputs":[]},{"metadata":{"id":"GCD6aj6JzQ4I","outputId":"9b938d51-b55a-4f55-85ff-fa6fcfe0f395","trusted":true},"cell_type":"code","source":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"YvlI48mpzQ-H","outputId":"5a42226d-79ba-4596-9981-b046c0a986c5","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"icuo4CixzRCR","outputId":"dddd0b43-3394-4b8a-9280-f1cb0f0502d4","trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"id":"y9iab1axzRFZ","outputId":"40659ef8-098c-4308-9cc3-dd1c87eec72f","trusted":true},"cell_type":"code","source":"x_scaled = scaler.transform(x)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"8pQI69r60PgK","outputId":"d872b126-d675-4942-fea6-98bb0cfa9e1d","trusted":true},"cell_type":"code","source":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"8I_ypT6t0Pnw","trusted":true},"cell_type":"code","source":"x = x_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"gG80qFRO0WLR"},"cell_type":"markdown","source":"### 80-20 Split"},{"metadata":{"id":"0CSxDREE0PrV","outputId":"9bb3c5c5-f782-4be9-f283-3c5c87ec2419","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"HpnFY_Er0fVn","outputId":"ea9713e7-4a12-427a-89a4-a90c3ed60bfa","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"VEYZ8hhP0fa1","outputId":"000b90c3-88f9-4b1b-878f-5f557e8b2670","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_51 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_52 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_51)\nprint(\"R^2 value: \",test_set_r2_52)","execution_count":null,"outputs":[]},{"metadata":{"id":"4wJxkpNAsTSy"},"cell_type":"markdown","source":"- This is not a great regression model as the R square score is near 1.0, and the RMSE error is not quite large."},{"metadata":{"id":"q7fD4xW30uUO","outputId":"c611d30e-dd0a-4c43-c1b2-e53e124788a2","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"U-O2EtdBiZqs"},"cell_type":"markdown","source":"- We infer that there's positive linear relationship with the regression fit line\n- From the graph, some of the actual value points are above the line, and some are below the regression best fit line.\n- This model does not fit the data really well, as there are small differences present between many of the datapoints and the best fit line"},{"metadata":{"id":"g2EDzoKr0ZcO"},"cell_type":"markdown","source":"### 60-40 Split"},{"metadata":{"id":"apV5nGRS0Pva","outputId":"822fff91-7abd-439b-a57e-b3361085e0e1","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"rHLqhFRz1BHF","outputId":"5d4e5ac8-dad4-4c53-dddd-85388c948884","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"nKUlGeIP1CHY","outputId":"7f9cc0d9-4a57-47c4-e018-b903b1c41f3d","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_53 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_54 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_53)\nprint(\"R^2 value: \",test_set_r2_54)","execution_count":null,"outputs":[]},{"metadata":{"id":"eExVqq_IsJNr"},"cell_type":"markdown","source":"- This is not a great regression model as the R square score is near 1.0, and the RMSE error is not quite large.\n- But the results of 80-20 split are better than this to train the dataset"},{"metadata":{"id":"Nm3rIveB1CLw","outputId":"8a756e9f-a85d-44e2-caca-a857b6bebd3a","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"D8GcAVlCXi23"},"cell_type":"markdown","source":"## 5th set : RM, LSTAT and PTRATIO"},{"metadata":{"id":"9au8j6WpR9--","outputId":"081c75d2-50a8-4593-d7c5-5ba0f9fa9127","trusted":true},"cell_type":"code","source":"df1 = df[['RM','LSTAT','PTRATIO','MEDV']]\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"J7UhEruoSEGC","outputId":"6f4a55e2-165e-475f-dba3-30fb53440f46","trusted":true},"cell_type":"code","source":"sns.pairplot(data=df1)","execution_count":null,"outputs":[]},{"metadata":{"id":"vG__dJj4SQUu"},"cell_type":"markdown","source":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- LSTAT shows quite a negatively skewed graph\n- PTRATIO has a positively sked graph with few outliers present towards the ends\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Position Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- RM and LSTAT, and MEDV and LSTAT have negative linear relationship between them, alongith the presence of few outliers\n- Graph of PTRATIO does not show any relationship with RM, LSTAT or MEDV"},{"metadata":{"id":"wP5F_3FqSEPU","outputId":"c040ce39-4a03-4224-f13e-51ae07524938","trusted":true},"cell_type":"code","source":"#description about this data\ndf1.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"fnHjRJjbSx3b"},"cell_type":"markdown","source":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV and LSTAT are much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor LSTAT:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- There is a significant difference between the mean and 50% quartile value\n- Hence LSTAT does not have normal distribution\n\nFor PTRATIO:\n- The difference between the min and 50% quartile is greater than, that present between 50% and max value\n- Hence it has a positively sked graph\n- Here, the mean and 50% values are also approximately same"},{"metadata":{"id":"mpmQ-bFpSEWU","outputId":"3237294d-e88d-4e65-b70e-6b92287185ea","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"LC3aIFSDTYRA"},"cell_type":"markdown","source":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers"},{"metadata":{"id":"a9jippKZSEb5","outputId":"a99b6bed-5935-4dcb-f4bc-a8e02c9b8c66","trusted":true},"cell_type":"code","source":"df2 = df1[~(df1['MEDV']==50)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"a10hQXYfSEgG","outputId":"ed678785-8fa9-489e-d444-80992ed96375","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"6pcQRxgwUCmi"},"cell_type":"markdown","source":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50"},{"metadata":{"id":"cv9BKMBSUC0m","outputId":"b99daa7a-2336-424b-8cbb-6fe31886546d","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"RjNONRnuUQSV"},"cell_type":"markdown","source":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show good Positive Linear Relationship."},{"metadata":{"id":"eisIVeSWUC6T","outputId":"6604518c-7213-4225-c9eb-6a787f138eed","trusted":true},"cell_type":"code","source":"temp_df = df2[df1['RM']>7.7]\ntemp_df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"GPA6GkXwUDD7","outputId":"f9fbeb62-d8a7-4424-df46-b4fd5040dde6","trusted":true},"cell_type":"code","source":"temp_df1 = df2[df1['RM']<4.7]\ntemp_df1.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"9fz4VCZvUDNE","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']>7.7)]","execution_count":null,"outputs":[]},{"metadata":{"id":"_ibFJrS_Ufkn","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['RM']<4.7)]","execution_count":null,"outputs":[]},{"metadata":{"id":"j_89P_FiUfsO","outputId":"d5b9a1ad-1f4b-46a4-c216-c48f322b5baf","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"F-94QI6efASE"},"cell_type":"markdown","source":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7"},{"metadata":{"id":"OtbizRDfUfx0","outputId":"23477bd8-96b4-4af6-fe78-baa6737c6fee","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_ziiapsdUf5T","outputId":"280fc257-fa55-4d4b-cdb4-0a5ee5021369","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","execution_count":null,"outputs":[]},{"metadata":{"id":"9vABUFlQfKVu","outputId":"ce02176a-e0a0-42ef-ae04-a505402332c7","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"o24Vxx8qfPVH"},"cell_type":"markdown","source":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 40 (506-466) rows from out dataset having LSTAT value as >31"},{"metadata":{"id":"yu-Lalh_fKb4","outputId":"fc7ad46a-cb32-4063-b987-7296f70d3746","trusted":true},"cell_type":"code","source":"#Box Plot, Distribution Plot and Scatter Plot for PTRATIO\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.PTRATIO)\nplt.title('Box Plot of PTRATIO')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.PTRATIO)\nplt.title('Distribution Plot of PTRATIO')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.PTRATIO,df1.MEDV)\nplt.title('Scatter Plot of PTRATIO vs MEDV')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"N4xkDqwnfKig","trusted":true},"cell_type":"code","source":"df2 = df2[~(df1['PTRATIO']<13)]","execution_count":null,"outputs":[]},{"metadata":{"id":"z1kL6YP_fmm2","outputId":"3bfff2e1-a48e-487a-a6b6-26f9759fb965","trusted":true},"cell_type":"code","source":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"9G-otYMTfvuu"},"cell_type":"markdown","source":"- Now the maximum value of PTRATIO column is 22\n- Hence we have deleted 43 (506-463) rows from out dataset having PTRATIO value as < 13"},{"metadata":{"id":"1tY7WTpVfmrn","trusted":true},"cell_type":"code","source":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:3].values\ny = df2.iloc[:,-1:].values","execution_count":null,"outputs":[]},{"metadata":{"id":"W6KB-r4afm0q","outputId":"369acc0c-3d8f-424d-feff-6896e630acf8","trusted":true},"cell_type":"code","source":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"bR4IWzgrgHqv","outputId":"aa8b1c5d-ba6b-4e94-bda4-78d10ebab8ff","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"NRjdNYPFgHv7","outputId":"8b59ce52-951c-4e0c-8334-d887e456d899","trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"id":"kyrf5qHogH2J","outputId":"21636bea-c8b5-40d2-b229-ca482c2bc739","trusted":true},"cell_type":"code","source":"x_scaled = scaler.transform(x)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"RszRKFjDgH--","outputId":"5cf04e4e-12aa-4441-abcb-206b9ba7e1c4","trusted":true},"cell_type":"code","source":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"BQE9NjgigVzc","trusted":true},"cell_type":"code","source":"x= x_scaled","execution_count":null,"outputs":[]},{"metadata":{"id":"t7IBaSCdgYvy"},"cell_type":"markdown","source":"### 80-20 Split"},{"metadata":{"id":"nZj1WBCtgV5u","outputId":"9cb65b43-e0a1-4f5a-e19c-69a989270d30","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"v4WmEFrTgjW0","outputId":"51d2d12e-16a8-48b7-bf7c-8c118de50af5","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"mr_et-Z2gjbW","outputId":"15369462-4bb8-4291-f29b-23c48eb3ddf0","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_61 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_62 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_61)\nprint(\"R^2 value: \",test_set_r2_62)","execution_count":null,"outputs":[]},{"metadata":{"id":"o5eappgDsYyI"},"cell_type":"markdown","source":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is comparitively not very large."},{"metadata":{"id":"tW7uvEZJgWA-","outputId":"045f9ec6-c07c-4a9b-b720-f36f0745065e","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"UXS5aAOoisBo"},"cell_type":"markdown","source":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- But overall, this model fits the data well, as there is fairly small difference between majority of the datapoints and the best fit line"},{"metadata":{"id":"aEVhD_hDgdvG"},"cell_type":"markdown","source":"### 60-40 Split"},{"metadata":{"id":"_OTme1MqgWJb","outputId":"5c0db662-1ec6-4372-944d-bd59a8a42e84","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ZhoLcSCngxZx","outputId":"5c21801d-7312-47c5-dcdf-887b43ae79cc","trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","execution_count":null,"outputs":[]},{"metadata":{"id":"UZlNNNQVgxgj","outputId":"e4f8746e-8a43-4820-8f47-d8f260c95569","trusted":true},"cell_type":"code","source":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_63 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_64 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_63)\nprint(\"R^2 value: \",test_set_r2_64)","execution_count":null,"outputs":[]},{"metadata":{"id":"QfTBFnWYsg1G"},"cell_type":"markdown","source":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is comparitively not very large."},{"metadata":{"id":"SdybbuKAgxp7","outputId":"702cf8c2-e3e4-40e3-8668-b3166f8a2d31","trusted":true},"cell_type":"code","source":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","execution_count":null,"outputs":[]},{"metadata":{"id":"gL8Kq8lSiu1p"},"cell_type":"markdown","source":"- We observe that there's positive linear relationship with the regression fit line\n- Some of the actual value points are above the line, and some are below, looking at how the regression line fits in with the scatter plot, \n- But overall, this model fits the data fairly well, as there is small difference between majority of the datapoints and the best fit line"},{"metadata":{"id":"X5WAX3fxXrkp"},"cell_type":"markdown","source":"## CONCLUSION"},{"metadata":{"id":"bND7DSvKkZWO"},"cell_type":"markdown","source":"### Training Set (80% of total data) & Test Set (20% of total data)"},{"metadata":{"id":"mqmlnnL9XuhE","outputId":"491c572c-7332-4c4a-9155-a73fa59e98d8","trusted":true},"cell_type":"code","source":"#For 80-20 Split of the dataset\nmodels = pd.DataFrame({\n    'Model Features': ['RM + LSTAT', 'RM + TAX', 'LSTAT + TAX', 'PTRATIO + RM', 'TAX + LSTAT + PTRATIO', 'PTRATIO + RM + LSTAT'],\n    'RMSE Score': [ test_set_rmse_11 , test_set_rmse_21 , test_set_rmse_31 , test_set_rmse_41 , test_set_rmse_51 , test_set_rmse_61 ],\n    'R-squared Score': [ test_set_r2_12 , test_set_r2_22 , test_set_r2_32 , test_set_r2_42 , test_set_r2_52 , test_set_r2_62]})\nmodels.sort_values(by='RMSE Score', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"ibjfSJTBjv79"},"cell_type":"markdown","source":"- We know that R-squared is a relative measure of fit, RMSE is an absolute measure of fit for a model.\n- RMSE measures how accurately the model predicts the response, thus it is the most important criterion for fit if the main purpose of the model is prediction.\n\n**Hence from the above results, we conclude that for 80-20 Split of the dataset:**\n- The model set using the features *PTRATIO, RM and LSTAT* gives the greatest R-Square Score and the Least RMSE Error Score. Hence this is the **best model**, out of all the sets observed in this experiment.\n- Following this, *RM and LSTAT* give the best results i.e. the second highest R-squared score and the second lowest RMSE score, out of all the sets observed in this experiment.\n- *RM and TAX* is also a good set as it gives good RMSE and R-squared score comparitively to other sets\n- *PTRATIO and RM* does not give good results, as it has a very high RMSE value and a very low R-square score. Hence it would not be a good model for prediction purposes"},{"metadata":{"id":"vcszRZphkpvH"},"cell_type":"markdown","source":"### Training Set (60% of total data) & Test Set (40% of total data)"},{"metadata":{"id":"P2HUcBc1qk1A","outputId":"fbd8ebd1-269e-4746-b809-21d7649ba68b","trusted":true},"cell_type":"code","source":"#For 60-40 Split of the dataset\nmodels = pd.DataFrame({\n    'Model Features': ['RM + LSTAT', 'RM + TAX', 'LSTAT + TAX', 'PTRATIO + RM', 'TAX + LSTAT + PTRATIO', 'PTRATIO + RM + LSTAT'],\n    'RMSE Score': [ test_set_rmse_13 , test_set_rmse_23 , test_set_rmse_33 , test_set_rmse_43 , test_set_rmse_53 , test_set_rmse_63 ],\n    'R-squared Score': [ test_set_r2_14 , test_set_r2_24 , test_set_r2_34 , test_set_r2_44 , test_set_r2_54 , test_set_r2_64]})\nmodels.sort_values(by='RMSE Score', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"f4NL-BkEqxZM"},"cell_type":"markdown","source":"**From the above results, we conclude that for 60-40 Split of the dataset:**\n- The model set using the features *PTRATIO, RM and LSTAT* gives the greatest R-Square Score and the Least RMSE Error. Hence this is the **best model**, out of all the sets observed in this experiment.\n- Following this, *RM and TAX* give good results as it has fairly high R-squared score and low RMSE score, out of all the sets observed in this experiment.\n- *RM and LSTAT* is also a good set as it gives good RMSE and R-squared score comparitively to other sets observed.\n- *PTRATIO and RM* does not give good results, hence it would not be a good model for prediction purposes. This is because it has a very high RMSE value and a very low R-square score."},{"metadata":{"id":"fyZa9iOxpB0S"},"cell_type":"markdown","source":"\n\n---\n\n\n---\n\n\n\n"},{"metadata":{"id":"umuGXeWWoag0"},"cell_type":"markdown","source":" **CONCLUSION:**\n- In this experiment we observe that when the dataset is split in 80:20 ratio, the models give better results than when it is split in 60:40 ratio to train the model on the Machine Learning Algorithm\n- The set of PTRATIO, RM and LSTAT gives the best results for Logistic Regression in both cases, followed by the sets RM+TAX and PM+LSTAT.\n- And the set of PTRATIO and RM gives the worst results in both cases."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}