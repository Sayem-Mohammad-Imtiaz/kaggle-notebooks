{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=df.columns\ncolumns_new=[]\nfor i in columns:\n    columns_new.append(any(df[i].isnull()|df[i].isnull()))\ndf=df.drop(columns[columns_new],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No columns with missing values "},{"metadata":{},"cell_type":"markdown","source":"# Data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"target\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the data is almost balanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.sex,df.target).plot(kind=\"bar\",figsize=(15,6),color=['blue','orange' ],alpha=0.7)\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More prevalence of the desease for woman"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.savefig('heartDiseaseAndAges.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.target==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.target==0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I see some outliers but not a lot of them, we keep them and try the model again without outliers maybe"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n# one hot encode\nencoded1 = pd.DataFrame(to_categorical(df.restecg),columns=['restecg0','restecg1','restecg2'])\nencoded2 = pd.DataFrame(to_categorical(df.cp),columns=['cp0','cp1','cp2','cp3'])\nencoded3 = pd.DataFrame(to_categorical(df.thal),columns=['thal0','thal1','thal2','thal3'])\nencoded4 = pd.DataFrame(to_categorical(df.ca),columns=['ca0','ca1','ca2','ca3','ca4'])\nencoded5 = pd.DataFrame(to_categorical(df.slope),columns=['slope0','slope1','slope2'])\n\ndf = pd.concat([df,encoded1,encoded2,encoded3,encoded4,encoded5],axis=1).drop(['restecg','cp','thal','ca','slope'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train test splinting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(\n    df.drop(['target'], axis=1),\n    df[['target']],\n    test_size=0.3,\n    random_state=41)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in X_train.columns:\n    \n    df_train1 = X_train[(y_train.target==0) & (X_train[column]<np.mean(X_train.loc[y_train.target==0,column])+3*np.std(X_train.loc[y_train.target==0,column]))]\n    df_test1 = X_test[(y_test.target==0) & (X_test[column]<np.mean(X_train.loc[y_train.target==0,column])+3*np.std(X_train.loc[y_train.target==0,column]))]\n    \n    label_train1 = y_train[(y_train.target==0) & (X_train[column]<np.mean(X_train.loc[y_train.target==0,column])+3*np.std(X_train.loc[y_train.target==0,column]))]\n    label_test1 = y_test[(y_test.target==0) & (X_test[column]<np.mean(X_train.loc[y_train.target==0,column])+3*np.std(X_train.loc[y_train.target==0,column]))]\n    \n    df_train2 = X_train[(y_train.target==1) & (X_train[column]<np.mean(X_train.loc[y_train.target==1,column])+3*np.std(X_train.loc[y_train.target==1,column]))]\n    df_test2 = X_test[(y_test.target==1) & (X_test[column]<np.mean(X_train.loc[y_train.target==1,column])+3*np.std(X_train.loc[y_train.target==1,column]))]\n    \n    label_train2 = y_train[(y_train.target==1) & (X_train[column]<np.mean(X_train.loc[y_train.target==1,column])+3*np.std(X_train.loc[y_train.target==1,column]))]\n    label_test2 = y_test[(y_test.target==1) & (X_test[column]<np.mean(X_train.loc[y_train.target==1,column])+3*np.std(X_train.loc[y_train.target==1,column]))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.concat([df_train1,df_train2])\ny_train=pd.concat([label_train1,label_train2])\n\nX_test=pd.concat([df_test1,df_test2])\ny_test=pd.concat([label_test1,label_test2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems that there are no outliers"},{"metadata":{},"cell_type":"markdown","source":"# Looking for correlated features"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatrix = X_train.corr()\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrMatrix, annot=True,ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlated_features = set()\nfor i in range(len(corrMatrix .columns)):\n    for j in range(i):\n        if abs(corrMatrix.iloc[i, j]) > 0.85:\n            colname = corrMatrix.columns[i]\n            correlated_features.add(colname)\nprint(correlated_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is one highly correlated features in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(labels=correlated_features, axis=1, inplace=True)\nX_test.drop(labels=correlated_features, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing features with 0 variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"constant_filter = VarianceThreshold(threshold=0.0)\nconstant_filter.fit(X_train)\nX_train = constant_filter.transform(X_train)\nX_test = constant_filter.transform(X_test)\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one 0 variance features"},{"metadata":{},"cell_type":"markdown","source":"# Scaling the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"mm_scaler = preprocessing.StandardScaler()\nX_train = pd.DataFrame(mm_scaler.fit_transform(X_train))\nX_test=pd.DataFrame(mm_scaler.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(class_weight=\"balanced\",n_estimators=200,random_state = 1)\nrf.fit(X_train, y_train.values.ravel())\ny_pred=rf.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\nprint(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train.values.ravel())\n\ny_pred=nb.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\n\nprint(\"Accuracy of Naive Bayes: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support vector machine model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(X_train, y_train.values.ravel())\n\ny_pred=svm.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\n\nprint(\"Test Accuracy of SVM Algorithm: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# try ro find best k value\nscore = []\n\nfor i in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn.fit(X_train, y_train.values.ravel())\n    score.append(knn.score(X_test, y_test.values.ravel()))\n    \nplt.plot(range(1,20), score)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K neighbors\")\nplt.ylabel(\"Score\")\nplt.show()\n\nacc = max(score)*100\nprint(\"Maximum KNN Score is {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 7)  # n_neighbors means k\nknn.fit(X_train, y_train.values.ravel())    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(max_iter=50)\nlogreg.fit(X_train, y_train.values.ravel())\ny_pred=logreg.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\nprint(\"Test Accuracy of Logistic Regression Algorithm: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\n\n# define the keras model\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the keras model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit the keras model on the dataset\nmodel.fit(X_train, y_train, epochs=100, batch_size=32)\n# evaluate the keras model\n_, accuracy = model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def conf_matrix(matrix,pred):\n    class_names= [0,1]# name  of classes\n    fig, ax = plt.subplots()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names)\n    plt.yticks(tick_marks, class_names)\n    # create heatmap\n    sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n    ax.xaxis.set_label_position(\"top\")\n    plt.tight_layout()\n    plt.title('Confusion matrix', y=1.1)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = rf.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = nb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Suport Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = svm.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = knn.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = model.predict_classes(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{},"cell_type":"markdown","source":"Best model is K neighbors with 88% accuracy precision and recall"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}