{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns={'Residence_type':'residence_type'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converte genero para 0 ou 1\ndf['gender'] = df['gender'].apply({'Male':1, 'Female':0}.get)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converte status de se já foi casado para 0 ou 1\ndf['ever_married'] = df['ever_married'].apply({'Yes':1, 'No':0}.get)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converte o tipo de residência para 0 ou 1\ndf['residence_type'] = df['residence_type'].apply({'Rural':1, 'Urban':0}.get)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# modificando strings\ndf['smoking_status'] = df['smoking_status'].apply(str.lower)\ndf['smoking_status'] = df['smoking_status'].apply(lambda x: x.replace(' ','_'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# modificando strings\ndf['work_type'] = df['work_type'].apply(str.lower)\ndf['work_type'] = df['work_type'].apply(lambda x: x.replace('-','_'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.boxplot(data=df,x=df[\"bmi\"],color='green');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"bmi\"] = df[\"bmi\"].apply(lambda x: 50 if x>50 else x)\ndf[\"bmi\"] = df[\"bmi\"].fillna(28.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Heatmap Correlation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30,20))\nsns.heatmap(df.corr(),annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling The variance in Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"std=StandardScaler()\ncolumns = ['avg_glucose_level','bmi','age']\nscaled = std.fit_transform(df[['avg_glucose_level','bmi','age']])\nscaled = pd.DataFrame(scaled,columns=columns)\ndf=df.drop(columns=columns,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.merge(scaled, left_index=True, right_index=True, how = \"left\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class = df.drop(['id','stroke'], axis=1)\ndf_target = df['stroke']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_class, df_target, test_size=0.3, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# adaboost classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create adaboost classification obj\nab_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, \n                            learning_rate=0.5, random_state=100)\n\n#training via adaboost classficiation model\nab_clf.fit(X_train, y_train)\nprint(\"training....\\n\")\n\n#make prediction using the test set\nab_pred_stroke= ab_clf.predict(X_train)\nprint('prediction: \\n', ab_pred_stroke)\n\nprint('\\nparms: \\n', ab_clf.get_params)\n\n#score\nab_clf_score = ab_clf.score(X_test, y_test)\nprint(\"\\nmean accuracy: %.2f\" % ab_clf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost = GradientBoostingClassifier(random_state=0)\nxgboost.fit(X_train, y_train)\n#== \n#Score \n#== \nxgboost_score = xgboost.score(X_train, y_train)\nxgboost_test = xgboost.score(X_test, y_test)\n#== \n#testing model \n#== \ny_pred = xgboost.predict(X_test)\n#== \n#evaluation\n#== \ncm = confusion_matrix(y_test,y_pred)\nprint('Training Score',xgboost_score)\nprint('Testing Score \\n',xgboost_test)\n\n#=== \n#Confusion Matrix \nplt.figure(figsize=(14,5))\n\nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\");\nprint(accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(random_state=0)\nsvc.fit(X_train, y_train)\n#== \n#Score \n#== \nsvc_score = svc.score(X_train, y_train)\nsvc_test = svc.score(X_test, y_test)\n#== \n#testing model \n#== \ny_pred = svc.predict(X_test)\n#== \n#evaluation\n#== \ncm = confusion_matrix(y_test,y_pred)\nprint('Training Score',svc_score)\nprint('Testing Score \\n',svc_test)\n\nplt.figure(figsize=(14,5))\n\nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\");\nprint(accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestClassifier(n_estimators = 100)\n#== \nforest.fit(X_train, y_train)\n#== \n#Score \n#== \nforest_score = forest.score(X_train, y_train)\nforest_test = forest.score(X_test, y_test)\n#== \n#testing model \n#== \ny_pred = forest.predict(X_test)\n#== \n#evaluation\n#== \ncm = confusion_matrix(y_test,y_pred)\nprint('Training Score',forest_score)\nprint('Testing Score \\n',forest_test)\n\nplt.figure(figsize=(14,5))\n\nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\");\nprint(accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\n#== \n#Score \n#== \nlogistic_score = model.score(X_train, y_train)\nlogistic_test = model.score(X_test, y_test)\n#== \n#testing model \n#== \ny_pred = model.predict(X_test)\n#== \n#evaluation\n#== \ncm = confusion_matrix(y_test,y_pred)\nprint('Training Score',logistic_score)\nprint('Testing Score \\n',logistic_test)\n\nplt.figure(figsize=(14,5))\n\nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\");\nprint(accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost.get_params().keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('classifier' , RandomForestClassifier())])\n\n\nparam_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']},\n    {'classifier' : [RandomForestClassifier()],\n    'classifier__n_estimators' : list(range(10,101,10)),\n    'classifier__max_features' : list(range(6,32,5))},\n    {'classifier' : [SVC()],\n     'classifier__C': [0.1,1, 10, 100], \n     'classifier__gamma': [1,0.1,0.01,0.001],\n     'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n    {'classifier' : [GradientBoostingClassifier()],\n    'classifier__max_depth' : [3,4,5]}\n]\n\n# Create grid search object\n\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1, scoring='recall')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVC(C=100, gamma=0.1, kernel='sigmoid', probability=True)\nmodel.fit(X_train, y_train)\n#== \n#Score \n#== \nlogistic_score = model.score(X_train, y_train)\nlogistic_test = model.score(X_test, y_test)\n#== \n#testing model \n#== \ny_pred = model.predict(X_test)\n#== \n#evaluation\n#== \ncm = confusion_matrix(y_test,y_pred)\nprint('Training Score',logistic_score)\nprint('Testing Score \\n',logistic_test)\n\nplt.figure(figsize=(14,5))\n\nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\");\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Indicies of each class' observations\ni_class0 = np.where(df['stroke'] == 0)[0]\ni_class1 = np.where(df['stroke'] == 1)[0]\n\n# Number of observations in each class\nn_class0 = len(i_class0)\nn_class1 = len(i_class1)\n\n# For every observation of class 0, randomly sample from class 1 without replacement\ni_class0_downsampled = np.random.choice(i_class0, size=n_class1, replace=False)\n\n# Join together class 0's target vector with the downsampled class 1's target vector\ndf_sample = df.iloc[i_class1].append(df.iloc[i_class0_downsampled])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample.stroke.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample_class = df_sample.drop(['id','stroke'], axis=1)\ndf_sample_target = df_sample['stroke']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_sample_class, df_sample_target, test_size=0.3, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('classifier' , RandomForestClassifier())])\n\n\nparam_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']},\n    {'classifier' : [RandomForestClassifier()],\n    'classifier__n_estimators' : list(range(10,101,10)),\n    'classifier__max_features' : list(range(6,32,5))},\n    {'classifier' : [SVC()],\n     'classifier__C': [0.1,1, 10, 100], \n     'classifier__gamma': [1,0.1,0.01,0.001],\n     'classifier__kernel': ['rbf', 'poly', 'sigmoid']},\n    {'classifier' : [GradientBoostingClassifier()],\n    'classifier__max_depth' : [3,4,5]}\n]\n\n# Create grid search object\n\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1, scoring='f1')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(C=0.08858667904100823, penalty='l1', solver='liblinear')\nmodel.fit(X_train, y_train)\n#== \n#Score \n#== \nlogistic_score = model.score(X_train, y_train)\nlogistic_test = model.score(X_test, y_test)\n#== \n#testing model \n#== \ny_pred = model.predict(X_test)\n#== \n#evaluation\n#== \ncm = confusion_matrix(y_test,y_pred)\nprint('Training Score',logistic_score)\nprint('Testing Score \\n',logistic_test)\n\nplt.figure(figsize=(14,5))\n\nconf_matrix = pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"Greens\");\nprint(accuracy_score(y_test,y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'model.pkl'\npickle.dump(model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'std.pkl'\npickle.dump(std, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"std.transform([[30, 23, 20]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict_proba([[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, -1.6815247 , -0.78960167, -1.027359]])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}