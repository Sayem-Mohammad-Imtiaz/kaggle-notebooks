{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\n#from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n#from sklearn.model_selection import train_test_split\nfrom string import punctuation\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization and Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Displays the count of positive and negative reviews in the Dataset\nsns.set(style = \"darkgrid\" , font_scale = 1.2)\nsns.countplot(df.sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum() # Checking for any missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def strip_html(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    return soup.get_text()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing the square brackets using regex\ndef remove_between_square_brackets(text):\n    return re.sub('\\[[^]]*\\]', '', text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing URL's\ndef remove_between_square_brackets(text):\n    return re.sub(r'http\\S+', '', text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the stopwords from text\ndef remove_stopwords(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop and i.strip().lower().isalpha():\n            final_text.append(i.strip().lower())\n    return \" \".join(final_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the noisy text\ndef denoise_text(text):\n    text = strip_html(text)\n    text = remove_between_square_brackets(text)\n    text = remove_stopwords(text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply function on review column\ndf['review'] = df['review'].apply(denoise_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sentiment.replace(\"positive\" , 1 , inplace = True)\ndf.sentiment.replace(\"negative\" , 0 , inplace = True)\ndf.head(7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wordcloud for Positive Text (Label - 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20)) # Positive Review Text\nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.sentiment == 1].review))\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wordcloud for Negative Text (Label - 0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20)) # Negative Review Text\nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.sentiment == 0].review))\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Characters in text"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,8))\ntext_len=df[df['sentiment']==1]['review'].str.len()\nax1.hist(text_len,color='red')\nax1.set_title('Text with Good Reviews')\ntext_len=df[df['sentiment']==0]['review'].str.len()\nax2.hist(text_len,color='green')\nax2.set_title('Text with Bad Reviews')\nfig.suptitle('Characters in texts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Words in texts"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,8))\ntext_len=df[df['sentiment']==1]['review'].str.split().map(lambda x: len(x))\nax1.hist(text_len,color='red')\nax1.set_title('Text with Good Reviews')\ntext_len=df[df['sentiment']==0]['review'].str.split().map(lambda x: len(x))\nax2.hist(text_len,color='green')\nax2.set_title('Text with Bad Reviews')\nfig.suptitle('Words in texts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(20,10))\nword=df[df['sentiment']==1]['review'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('Text with Good Reviews')\nword=df[df['sentiment']==0]['review'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\nax2.set_title('Text with Bad Reviews')\nfig.suptitle('Average word length in each text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_corpus(text):\n    words = []\n    for i in text:\n        for j in i.split():\n            words.append(j.strip())\n    return words\ncorpus = get_corpus(df.review)\ncorpus[:8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ncounter = Counter(corpus)\nmost_common = counter.most_common(10)\nmost_common = dict(most_common)\nmost_common","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_text_ngrams(corpus, n, g):\n    vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common_uni = get_top_text_ngrams(df.review,20,1)\nmost_common_uni = dict(most_common_uni)\ntemp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\ntemp[\"Common_words\"] = list(most_common_uni.keys())\ntemp[\"Count\"] = list(most_common_uni.values())\nfig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common_bi = get_top_text_ngrams(df.review,20,2)\nmost_common_bi = dict(most_common_bi)\ntemp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\ntemp[\"Common_words\"] = list(most_common_bi.keys())\ntemp[\"Count\"] = list(most_common_bi.values())\nfig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Bigrams in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common_tri = get_top_text_ngrams(df.review,20,3)\nmost_common_tri = dict(most_common_tri)\ntemp = pd.DataFrame(columns = [\"Common_words\" , 'Count'])\ntemp[\"Common_words\"] = list(most_common_tri.keys())\ntemp[\"Count\"] = list(most_common_tri.values())\nfig = px.bar(temp, x=\"Count\", y=\"Common_words\", title='Commmon Trigrams in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}