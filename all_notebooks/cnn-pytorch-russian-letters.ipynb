{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CNN PyTorch Russian Letters"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('../input/russian-handwritten-letters/all_letters_info.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"base_path = '../input/russian-handwritten-letters/all_letters_image/all_letters_image/'","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"features = []\nlabels = []\n\nfor i, file in enumerate(df['file'].values):\n    features.append(cv2.resize(cv2.imread(base_path + file), (28, 28)))\n    labels.append(df['label'][i])\n\nfeatures = np.asarray(features)\nlabels = np.asarray(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# normalize\nfeatures = features / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"device = torch.device(\"cuda:0\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"features = torch.from_numpy(features).to(device).type(torch.cuda.FloatTensor)\nlabels = torch.from_numpy(labels).to(device).type(torch.cuda.LongTensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"model = nn.Sequential(nn.Conv2d(28,14,1),\n                      nn.ReLU(),\n                      nn.Dropout2d(0.1),\n                      nn.MaxPool2d(2),\n                      nn.Flatten(),\n                      nn.Linear(196, 124),\n                      nn.Sigmoid(),\n                      nn.Linear(124, 64),\n                      nn.Sigmoid(),\n                      nn.Linear(64, 34),\n                      nn.LogSoftmax(dim=1))\n\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":false},"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=0.42, momentum=0.9)\nloss_fn = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"losses = []","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":false},"cell_type":"code","source":"for e in range(2100):\n    out = model(X_train)\n    loss = loss_fn(out, y_train)\n    losses.append(loss)\n    if(e % 350 == 0):\n        preds_test = model(X_test)\n        loss_test = loss_fn(preds_test, y_test)\n        print('Epoch:{0}, Error-Loss:{1}'.format(e, loss.item()))\n        print('Epoch:{0}, Error-Test-Loss:{1}'.format(e, loss.item()))\n        print('------------------------------------------------------')\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot Loss"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(losses)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}