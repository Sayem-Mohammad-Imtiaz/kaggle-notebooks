{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture \n!pip install pandas\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom fastai import *\nfrom fastai.tabular import *\nimport torch\nimport missingno as msno\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = Path('/kaggle/input/titanic')\ntrpath = path/'train.csv'\ncvpath = path/'test.csv'\n\ndf_train_raw = pd.read_csv(trpath)\ndf_test_raw = pd.read_csv(cvpath)\n\ndf_train = df_train_raw.copy(deep = True)\ndf_test  = df_test_raw.copy(deep = True)\n\ndata_cleaner = [df_train_raw, df_test_raw] #to clean both simultaneously","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(n=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"varnames = list(df_train.columns)\nfor name in varnames:\n    print(name+\": \",type(df_train.loc[1,name]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.isnull().sum(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.corr(method='pearson')['Age'].abs()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Title'] = df_train['Name'].str.split(',',expand = True)[1].str.split('.',expand = True)[0].str.strip()\nvarnames = list(df_train.columns)\nfor name in varnames:\n    print(name+\": \",type(df_train.loc[1,name]))\n    \nprint(list(df_train['Title'].unique()))    \ndf_test['Title'] = df_test['Name'].str.split(',',expand = True)[1].str.split('.',expand = True)[0].str.strip()\ndf_test['Title'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def new_titles(df):\n    new_titles = dict()\n    assert 'Title' in df.columns\n    for key in df['Title'].unique():\n        females = ['Mrs','Miss','Ms','Mlle','Mme','Dona']\n        males = ['Mr','Don']\n        notable = ['Jonkheer','the Countess','Lady','Sir','Major','Col','Capt','Dr','Rev','Notable']\n        titles = [females,males,notable,'Master']\n        newtitles = ['Mrs','Mr','Notable','Master']\n        idx = [key in sublist for sublist in titles]\n        idx = np.where(idx)[0] \n        new_titles[key] = newtitles[idx[0]]\n    return new_titles\n\n\nnew_titles_dict = new_titles(df_train)\ndf_train['Title'] = df_train['Title'].replace(new_titles_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Cabin'][df_train['Cabin'].isnull()]='Missing'\ndf_train['Cabin'] = df_train['Cabin'].str.split(r'(^[A-Z])',expand = True)[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_fill(datasets, mode):\n    assert mode =='median' or mode =='sampling'\n    datasets_cp =[]\n    np.random.seed(2)\n    varnames = ['Age','Fare']\n    for d in datasets:\n        df = d.copy(deep = True)\n        for var in varnames:\n            idx = df[var].isnull()\n            if idx.sum()>0:\n                if mode =='median':\n                    medians = df.groupby('Pclass')[var].median()\n                    for i,v in enumerate(idx):\n                        if v:\n                            df[var][i] = medians[df['Pclass'][i]]\n                else:\n                    g = df[idx==False].groupby('Pclass')[var]\n                    for i,v in enumerate(idx):\n                        if v:\n                            df[var][i] = np.random.choice((g.get_group(df['Pclass'][i])).values.flatten())\n    #Embarked                 \n        idx = df['Embarked'].isnull()\n        g = df[idx==False].groupby('Pclass')['Embarked']\n        for i,v in enumerate(idx):\n            if v:\n                df['Embarked'][i] = np.random.choice((g.get_group(df['Pclass'][i])).values.flatten())                   \n    #Cabin\n        df['Cabin'][df['Cabin'].isnull()]='Missing'\n        df['Cabin'] = df['Cabin'].str.split(r'(^[A-Z])',expand = True)[1]\n        datasets_cp.append(df)\n    return datasets_cp\n\ndata_clean = df_fill(data_cleaner,'median')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_data(datasets):\n        datasets_cp = []\n        for d in datasets:\n            df = d.copy(deep = True)\n            df['Family onboard'] = df['Parch'] + df['SibSp']\n            df['Title'] = df['Name'].str.split(',',expand = True)[1].str.split('.',expand = True)[0].str.strip()\n            new_titles_dict = new_titles(df)\n            df['Title'] = df['Title'].replace(new_titles_dict)\n            df.drop(columns = ['PassengerId','Name','Ticket'],axis = 1, inplace = True)\n            datasets_cp.append(df)\n        return datasets_cp\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,test =prepare_data(df_fill(data_cleaner,mode = 'sampling'))  \nprint(\"Training data\")\nprint(train.isnull().sum())\nprint(\"Test data\")\nprint(test.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def corr_matrix(x,y, quant = None):\n    x_quants = x.quantile(quant) if quant else x.quantile([0, 0.25, 0.5, 0.75, 1])\n    out = np.zeros((x_quants.shape[0]-1,int(y.unique().max()+1)))\n    for i in range(x.shape[0]):\n        comp = x[i]<=x_quants\n        idx = int(next((j for j,compv in enumerate(comp) if compv),None))\n        out[idx-1,int(y[i])]+=1\n    return out.T,x_quants\n\ndef plot_corr_matrix(x,quants,fig, ax, **kwargs):\n    assert x.shape[1] == quants.shape[0]-1\n    cmap = kwargs['cmap'] if kwargs['cmap'] else 'Blues'\n    ax.set_xlabel(kwargs['xlabel'])\n    ax.set_ylabel(kwargs['ylabel'])\n    ticks = np.arange(quants.shape[0])\n    ax.set_xticks(ticks)\n    ax.set_xticklabels(list(quants))\n    if 'xlabel' and 'ylabel' in kwargs.keys():\n        ax.title.set_text(f\"{kwargs['xlabel']} vs {kwargs['ylabel']}\")\n    p = ax.pcolor(x,cmap = cmap)\n    fig.colorbar(p,ax = ax)\n    return fig,ax\n    \n    \ndef gen_corr_matrix(*args,quant = None,cmap = 'YlOrBr'):\n    totalvars = len(args)\n    assert totalvars>1\n    \n    out   = dict()\n    out_q = dict()\n    fig,axs = plt.subplots(1, totalvars-1, squeeze=False)\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.5, hspace=None)\n    fig.figsize=(800, 800) \n    fig.suptitle(\"Correlation Matrix\") if totalvars<3 else fig.suptitle(\"Correlation Matrices\")\n    for i in range(totalvars-1):\n        out[i],out_q[i] = corr_matrix(args[0],args[i+1],quant)\n        plot_corr_matrix(out[i], out_q[i],\n                         fig,\n                         axs[0,i],\n                         cmap = cmap ,\n                         xlabel = args[0].name,\n                         ylabel = args[i+1].name)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = tabular_learner(data, \n                        layers=[1000,500, 200,50, 15],\n                        metrics=accuracy,\n                        emb_drop=0.1\n                       )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.device('cuda')\nlearn.fit_one_cycle(5, 2.5e-2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.export('stage1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.lr_find()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(10, max_lr=slice(2e-4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=slice(5e-2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, *_ = learn.get_preds(DatasetType.Test)\nlabels = np.argmax(predictions, 1)\nsubmission = pd.DataFrame({'PassengerId':df_test['PassengerId'],'Survived':labels})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission-fastai.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}