{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport csv\nimport os\nimport re\n\n# %load_ext rpy2.ipython\n# import rpy2.rinterface\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_stockes = pd.read_csv(\"../input/usstockprices/stocks_price_final.csv\", index_col = 0)\ndf_SP500 = pd.read_csv(\"../input/sp500-symbols/SP500.csv\")\nsymbols = df_SP500['symbol'].tolist()\ncompanies=np.random.choice(symbols, size=500, replace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert matket.cap from string to float\nmapping = dict(K='', M='', B='')\ndf_stockes[\"market.cap\"] = pd.to_numeric(df_stockes['market.cap'].str.strip('$').replace(mapping, regex=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_stockes.head())\nprint(df_stockes.shape)\n#Filter by SP500\ndf_stockes=df_stockes[df_stockes['symbol'].isin(companies)]\ndf_stockes.head()\ndf_stockes.shape\n#df_stock_list = df_stockes[df_stockes[]]\ndf_stock_list = df_stockes[(df_stockes.symbol != 'GOOG') & (df_stockes.symbol != 'FOX') & (df_stockes.symbol != 'UA') & (df_stockes.symbol != 'DISCK') & (df_stockes.symbol != 'NWS')]\nprint(df_stock_list.shape)\n#df_stockes = df_stockes[(df_stockes.symbol != 'GOOG')]\n#df_stockes.shape\n#df_stock_list = df_stockes.head()\n#Filter by Market Cap|\n# df_stockes = df_stockes[df_stockes['market.cap'] > 2.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_close_price = 'adjusted'\ndf_stock_prices = df_stock_list[['symbol','date', col_close_price]]\n# Remove duplicate if any and keep the latest data\ndf_stock_prices = df_stock_prices.drop_duplicates( keep='last')\n# Format the date field\ndf_stock_prices['date'] = pd.to_datetime(df_stock_prices['date'], format='%Y%m%d', errors='ignore')\ndf_stock_prices.set_index(['date','symbol'],inplace=True)\n# Change to wide format. Index is date and Columns are symbols. Values are adjsuted price\ndf_stock_prices=df_stock_prices.unstack()[col_close_price]\ndf_stock_prices.reset_index(inplace=True)\n#Replace Null with adjacent values \ndf_stock_prices.fillna(method='bfill',inplace=True)\ndf_stock_prices.fillna(method='ffill',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate daily log returns\nT = 1 #Daily return\n#Skip first columns which is date\nfor column in df_stock_prices.columns.values.tolist()[1:]:\n#     print(column)\n    df_stock_prices[column] = np.log(df_stock_prices[column]) - np.log(df_stock_prices[column].shift(T))\n\ndf_stock_prices.set_index('date',inplace=True)\ndf_stock_prices.fillna(method='bfill',inplace=True)\ndf_stock_prices.fillna(method='ffill',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot daily log returns\n%matplotlib inline\nfig, ax1 = plt.subplots(figsize=(20, 15))\ndf_stock_prices.plot(ax=ax1, legend=False)\n# plt.ylim([-0.5, 0.5])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_stock_prices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate corr\ndef calculate_corr(df_stock_returns, returns_window, corr_window_size, corr_method):\n    stocks_cross_corr_dict = {}\n    #Calculate mean correlation by window for plot\n    x_days = []\n    y_mean_corr = []        \n#     W = corr_window_size\n    for i in range(returns_window,len(df_stock_returns),corr_window_size):\n        dic_key = i\n        stocks_cross_corr_dict[dic_key]=df_stock_returns.iloc[i:(i+W)].corr(method='pearson')\n        stocks_cross_corr_dict[dic_key].fillna(0,inplace=True)\n        x_days.append(dic_key)\n        y_mean_corr.append(np.mean([abs(j) for j in stocks_cross_corr_dict[dic_key].values.flatten().tolist()]))        \n    return stocks_cross_corr_dict, x_days,y_mean_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot corr for various windows\n%matplotlib inline\n# stocks_cross_corr_dict = {}\n#Time Window width\n#TO DO: try different windows and differnt algorithms\n#t= 21 #21 based on the paper Asset trees and asset graphs in financial markets J.-P. Onnela et all\n# Try window from 1 month to 6 months of trading days\n# 21 days is one month trading days\nstart = 21\nend = 126\nstep = 21;\nplt.figure(figsize=(20, 10))\n#Find corr for the entire time period \n# _, x_days, y_mean_corr = calculate_corr(df_stock_prices,1,len(df_stock_prices), 'pearson')\n# x_days_t = range(0,len(df_stock_prices), 1)\n# y_mean_corr_t = np.empty(len(df_stock_prices))\n# y_mean_corr_t.fill(y_mean_corr[0])\n# plt.plot(x_days_t, y_mean_corr_t)\nfor t in range(start, end, step):\n    x_days = []\n    y_mean_corr = []\n    W = t\n    _, x_days, y_mean_corr = calculate_corr(df_stock_prices,1,W, 'pearson')\n    plt.plot(x_days, y_mean_corr)\n    plt.xlabel('Days')\n    plt.ylabel('Mean Correlation')\n    l = list(range(start, end, step))\n#     l.insert(0, len(df_stock_prices))\n    plt.legend(l, loc='upper left')     \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate corr for the entire period.\nstocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\nstocks_cross_corr[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the Graph with stocks as nodes and corr as edges\nimport networkx as nx\nimport networkx.algorithms.community as nxcom\nimport community\n\nedge_weights = []\ndef build_graph(stocks_cross_corr, threshold):\n    graph_edges = []\n    for x in stocks_cross_corr.keys():\n        for y in stocks_cross_corr[x].keys():\n            #print(x, y) \n            # Filter by absolute value of the corr\n            if abs(stocks_cross_corr[x][y]) > threshold:\n                #if same stock, continue\n                if  x == y:\n                    continue\n                if x < y: #Avoid duplicates, AxAAL vs AALxA\n                    graph_edges.append([x,y,dict(weight=abs(stocks_cross_corr[x][y]))])\n                    edge_weights.append(abs(stocks_cross_corr[x][y]))\n                else:\n                    None\n    \n#   print(len(graph_edges))\n    G = nx.Graph()\n    G.add_edges_from(graph_edges)\n    return G\n#     partition = community.best_partition(G)\n#     modularity = community.modularity(partition, G)\n#     values = [partition.get(node) for node in G.nodes()]\n#     nx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\n#     print(modularity)    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import networkx as nx\nimport networkx.algorithms.community as nxcom\nimport community\n\n\nstocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\nstocks_cross_corr = stocks_cross_corr[1]\n\ncorr_thresholds = np.linspace(0.5, 0.95, 20)\nmodularity_list = []\ncommunity_list = []\nfor cor in corr_thresholds:\n    G = build_graph(stocks_cross_corr, cor)\n    partition = community.best_partition(G)\n    modularity = community.modularity(partition, G)\n    modularity_list.append(modularity)\n    community_list.append(len(G.nodes()))\n    \n\n#\n\n# partition = community.best_partition(G)\n# modularity = community.modularity(partition, G)\n# values = [partition.get(node) for node in G.nodes()]\n# nx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\n# print(modularity)\n# print(\"Total number of Communities=\", len(G.nodes()))\n\n# partition=community.best_partition(G)\n# # Calculating modularity and the total number of communities\n# mod=community.modularity(partition,G)\n# print(\"Modularity: \", mod)\n# print(\"Total number of Communities=\", len(G_comm.nodes()))\n\n# dict_degree_centrality = nx.degree_centrality(G)\n# dict_closeness_centrality = nx.closeness_centrality(G)\n# dict_eigenvector_centrality = nx.eigenvector_centrality(G)\n# print(\"dict_degree_centrality: \", dict_degree_centrality)\n# print(\"dict_closeness_centrality: \", dict_closeness_centrality)\n# print(\"dict_eigenvector_centrality: \", dict_eigenvector_centrality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Louvian\n%matplotlib inline\nstocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\nstocks_cross_corr = stocks_cross_corr[1]\n\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\npartition = community.best_partition(G)\nmodularity = community.modularity(partition, G)\nvalues = [partition.get(node) for node in G.nodes()]\nplt.figure(figsize=(10,10))\nnx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\nprint(modularity)\nprint(\"Total number of Communities=\", len(G.nodes()))\n\ndict_betwenness_centrality = nx.betweenness_centrality(G)\ndict_degree_centrality = nx.degree_centrality(G)\ndict_closeness_centrality = nx.closeness_centrality(G)\ndict_eigenvector_centrality = nx.eigenvector_centrality(G)\nprint(\"dict_degree_centrality: \", dict_degree_centrality)\nprint(\"dict_closeness_centrality: \", dict_closeness_centrality)\nprint(\"dict_eigenvector_centrality: \", dict_eigenvector_centrality)\nprint(\"dict_betweenness_centrality: \", dict_betwenness_centrality)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Portfolio Formula: \nc_dict = dict([(k, [dict_betwenness_centrality[k], dict_eigenvector_centrality[k], dict_degree_centrality[k], dict_closeness_centrality[k] ]) for k in dict_betwenness_centrality])\n#print(c_dict)    \n    \nC_total = {}\nfor key in c_dict: \n    C_total[key] = sum(c_dict[key]) \n        \n\nprint(\"The Centrality total for stocks are:\", C_total)   \n\nnewDict = dict(filter(lambda elem: elem[1] > 0.3, C_total.items()))\nprint(\"Stocks greater than 0.3 centrality are\",newDict)\nprint(len(newDict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_node_community(G, communities):\n    '''Add community to node attributes'''\n    for c, v_c in enumerate(communities):\n        for v in v_c:\n            # Add 1 to save 0 for external edges\n            G.nodes[v]['community'] = c + 1 \n            \ndef set_edge_community(G):\n    '''Find internal edges and add their community to their attributes'''\n    for v, w, in G.edges:\n        if G.nodes[v]['community'] == G.nodes[w]['community']:\n            # Internal edge, mark with community\n            G.edges[v, w]['community'] = G.nodes[v]['community']\n        else:\n            # External edge, mark as 0\n            G.edges[v, w]['community'] = 0\n            \ndef get_color(i, r_off=1, g_off=1, b_off=1):\n    r0, g0, b0 = 0, 0, 0\n    n = 16\n    low, high = 0.1, 0.9\n    span = high - low\n    r = low + span * (((i + r_off) * 3) % n) / (n - 1)\n    g = low + span * (((i + g_off) * 5) % n) / (n - 1)\n    b = low + span * (((i + b_off) * 7) % n) / (n - 1)\n    return (r, g, b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Community detection using Girvan Newman (GN)\nstocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\nstocks_cross_corr = stocks_cross_corr[1]\n\n\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\nresult = nxcom.girvan_newman(G)\ncommunities_gn = next(result)\n# Set node and edge communities\nset_node_community(G, communities_gn)\nset_edge_community(G)\nprint(\"GN Communities: \", len(communities_gn))\n\n# Set community color for nodes\nnode_color = [    \n    get_color(G.nodes[v]['community'])    \n    for v in G.nodes]\n\n# Set community color for internal edgese\nexternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] == 0]\ninternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] > 0]\ninternal_color = [    \n    get_color(G.edges[e]['community'])    \n    for e in internal]\n\nstock_pos = nx.spring_layout(G)\nplt.rcParams.update({'figure.figsize': (15, 15)})\n# Draw external edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_size=0,    \n    edgelist=external, edge_color=\"#333333\", with_labels=False)\n# Draw nodes and internal edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_color=node_color,    \n    edgelist=internal, edge_color=internal_color, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuple(sorted(c) for c in next(communities_gn))\n#print(\"List of GN Community = \", list(communities_gn))\n# for communities in itertools.islice(comp, k):\n#     print(tuple(sorted(c) for c in communities)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Community detection using CNM\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\n\ncommunities_cnm = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True)\n# Set node and edge communities\nset_node_community(G, communities_cnm)\nset_edge_community(G)\nprint(\"CNM Communities: \", len(communities_cnm))\n\n# Set community color for nodes\nnode_color = [    \n    get_color(G.nodes[v]['community'])    \n    for v in G.nodes]\n\n# Set community color for internal edgese\nexternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] == 0]\ninternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] > 0]\ninternal_color = [    \n    get_color(G.edges[e]['community'])    \n    for e in internal]\n\nstock_pos = nx.spring_layout(G)\nplt.rcParams.update({'figure.figsize': (15, 15)})\n# Draw external edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_size=0,    \n    edgelist=external, edge_color=\"#333333\", with_labels=False)\n# Draw nodes and internal edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_color=node_color,    \n    edgelist=internal, edge_color=internal_color, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Community detection using Fluid Communities\n# cor_thresold = 0.6\n# G = build_graph(stocks_cross_corr, cor_thresold)\n# number_of_communities = 10\n# result = nxcom.asyn_fluidc(G, number_of_communities)\n# communities_fluid = next(result)\n# # Set node and edge communities\n# set_node_community(G, communities_fluid)\n# set_edge_community(G)\n# print(\"Fluid Communities: \", len(communities_fluid))\n\n# # Set community color for nodes\n# node_color = [    \n#     get_color(G.nodes[v]['community'])    \n#     for v in G.nodes]\n\n# # Set community color for internal edgese\n# external = [    \n#     (v, w) for v, w in G.edges    \n#     if G.edges[v, w]['community'] == 0]\n# internal = [    \n#     (v, w) for v, w in G.edges    \n#     if G.edges[v, w]['community'] > 0]\n# internal_color = [    \n#     get_color(G.edges[e]['community'])    \n#     for e in internal]\n\n# stock_pos = nx.spring_layout(G)\n# plt.rcParams.update({'figure.figsize': (15, 15)})\n# # Draw external edges\n# nx.draw_networkx(    \n#     G, pos=stock_pos, node_size=0,    \n#     edgelist=external, edge_color=\"#333333\", with_labels=False)\n# # Draw nodes and internal edges\n# nx.draw_networkx(    \n#     G, pos=stock_pos, node_color=node_color,    \n#     edgelist=internal, edge_color=internal_color, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cliques = list(nx.find_cliques(G))\nmax_clique = max(cliques, key=len)\n# Visualize maximum clique\nnode_color = [(0.5, 0.5, 0.5) for v in G.nodes()]\nfor i, v in enumerate(G.nodes()):\n    if v in max_clique:\n        node_color[i] = (0.5, 0.5, 0.9)\nnx.draw_networkx(G, node_color=node_color, pos=stock_pos, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create graph and write it as GraphML\nstocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\nstocks_cross_corr = stocks_cross_corr[1]\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\n\n#sp_500_graph_06.graphml\n#sp_500_graph_08.graphml\n#stocks_2B_graph_06.graphml\n# stocks_2B_graph_08.graphml\nnx.write_graphml(G,'sp_500_graph_06.graphml')\nstocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\nstocks_cross_corr = stocks_cross_corr[1]\ncor_thresold = 0.8\nG = build_graph(stocks_cross_corr, cor_thresold)\n\nnx.write_graphml(G,'sp_500_graph_08.graphml')\n# g = Graph(directed=False)\n# g.add_vertices(len(edges))\n# i = 0\n# for x in edges:\n#     g.vs[i][\"id\"] = x\n#     g.vs[i][\"label\"] = x\n#     i = i + 1\n\n# # g.es[\"weight\"] = weights\n# # g.es[\"label\"] = weights\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import igraph as ig\nfrom tabulate import tabulate\n\nGix08 = ig.read('sp_500_graph_08.graphml',format=\"graphml\")\nGix06 = ig.read('sp_500_graph_06.graphml',format=\"graphml\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Community detection with GN \ndendrogram = Gix06.community_edge_betweenness(directed=False)\noptimal_count = dendrogram.optimal_count\nprint(\"Optimum community count: \", optimal_count)\n# convert it into a flat clustering\nclusters = dendrogram.as_clustering()\n# get the membership vector\nmembership = clusters.membership\nmodularity = clusters.q\nprint(\"Modularity: \", modularity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gix06.es[0]\n# Gix.vs[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"community_list_gn = []\nfor name, membership in zip(Gix06.vs[\"id\"], membership):\n    community_list_gn.append([name, membership])\n#     print(name, membership)\ndf_community_gn = pd.DataFrame(community_list_gn, columns = ['symbol', 'community'])\n# df_community.set_index('symbol',inplace=True)\n# df_community.sort_values(by=['community', 'symbol'], inplace=True)\n# print(df_community)\ndf_community_gn = df_community_gn.groupby('community', as_index=True).agg(lambda x: ', '.join(set(x.astype(str))))\nprint(df_community_gn.to_markdown())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(1)\n\nig.plot(clusters, label=True, mark_groups = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Community detection with CNM \ndendrogram_cnm = Gix06.community_fastgreedy(weights=\"weight\")\noptimal_count_cnm = dendrogram_cnm.optimal_count\nprint(\"CNM Optimum community count: \", optimal_count_cnm)\n# convert it into a flat clustering\nclusters_cnm = dendrogram_cnm.as_clustering()\n# get the membership vector\nmembership_cnm = clusters_cnm.membership\nmodularity_cnm = clusters_cnm.q\nprint(\"Modularity: \", modularity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(1)\n\nig.plot(clusters_cnm, label=True, mark_groups = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"community_list_cnm = []\nfor name, membership in zip(Gix06.vs[\"id\"], membership_cnm):\n    community_list_cnm.append([name, membership])\n#     print(name, membership)\ndf_community_cnm = pd.DataFrame(community_list_cnm, columns = ['symbol', 'community'])\n# df_community_cnm.set_index('symbol',inplace=True)\n# df_community_cnm.sort_values(by=['community', 'symbol'], inplace=True)\n\ndf_community_cnm = df_community_cnm.groupby('community', as_index=True).agg(lambda x: ', '.join(set(x.astype(str))))\nprint(df_community_cnm.to_markdown())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}