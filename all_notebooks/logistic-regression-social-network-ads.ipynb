{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Logistic Regression :\n> Logistic regression is a __classification algorithm__. It is used to predict a binary outcome based on a set of independent variables.\n\n\n### When one should use Logistic Regression ?\n> Like all regression analyses, the logistic regression is a __predictive analysis.__\n> Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables\n\n### Examples :\n> Logistic regression is used to calculate the probability of a binary event occurring, and to deal with issues of classification. For example, predicting if an incoming email is __spam__ or __not spam__, or predicting if a credit card transaction is __fraudulent__ or __not fraudulent__. In a medical context, logistic regression may be used to predict whether a tumor is __benign__ or __malignant__. In marketing, it may be used to __predict__ if a given user (or group of users) will buy a certain product or not. An online education company might use logistic regression to predict whether a student will complete their course on time or not.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:50.524225Z","iopub.execute_input":"2021-08-04T18:16:50.524648Z","iopub.status.idle":"2021-08-04T18:16:50.529514Z","shell.execute_reply.started":"2021-08-04T18:16:50.524612Z","shell.execute_reply":"2021-08-04T18:16:50.528309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/social-network-ads/Social_Network_Ads.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:50.533951Z","iopub.execute_input":"2021-08-04T18:16:50.534622Z","iopub.status.idle":"2021-08-04T18:16:50.557274Z","shell.execute_reply.started":"2021-08-04T18:16:50.534575Z","shell.execute_reply":"2021-08-04T18:16:50.556233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:50.558803Z","iopub.execute_input":"2021-08-04T18:16:50.55937Z","iopub.status.idle":"2021-08-04T18:16:50.570187Z","shell.execute_reply.started":"2021-08-04T18:16:50.559326Z","shell.execute_reply":"2021-08-04T18:16:50.568937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Notes :\n> 1. Purchased is our target variable here.\n> 2. From __Age__ and __EstimatedSalry__ we need to predict that this person will purchase or not.\n> 3. 1 = Purhcased and 0 = Not-purchased \n\n\n> If you observe closely, we can find that the EstimatedSalary for age is not in standard formate, meaning age 19 has salary $50K$ and age 50 has salary of $20K$ which seems to be odd.\n> Therefore we need to standardize our data by __scalling__ using sklearn library.","metadata":{}},{"cell_type":"code","source":"data.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:50.572323Z","iopub.execute_input":"2021-08-04T18:16:50.572777Z","iopub.status.idle":"2021-08-04T18:16:50.586211Z","shell.execute_reply.started":"2021-08-04T18:16:50.572731Z","shell.execute_reply":"2021-08-04T18:16:50.585207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.iloc[:,[0,1]]\n\ny = data.iloc[:,[-1]]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:50.587722Z","iopub.execute_input":"2021-08-04T18:16:50.58817Z","iopub.status.idle":"2021-08-04T18:16:50.601636Z","shell.execute_reply.started":"2021-08-04T18:16:50.588138Z","shell.execute_reply":"2021-08-04T18:16:50.600422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the data into train and test: ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:50.603174Z","iopub.execute_input":"2021-08-04T18:16:50.603742Z","iopub.status.idle":"2021-08-04T18:16:51.630798Z","shell.execute_reply.started":"2021-08-04T18:16:50.603691Z","shell.execute_reply":"2021-08-04T18:16:51.629724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standardize the data :","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:51.632566Z","iopub.execute_input":"2021-08-04T18:16:51.633024Z","iopub.status.idle":"2021-08-04T18:16:51.645364Z","shell.execute_reply.started":"2021-08-04T18:16:51.632974Z","shell.execute_reply":"2021-08-04T18:16:51.643838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression model building :","metadata":{}},{"cell_type":"code","source":"# Fitting the model :\nfrom sklearn.linear_model import LogisticRegression\nlg = LogisticRegression(random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:51.647033Z","iopub.execute_input":"2021-08-04T18:16:51.64735Z","iopub.status.idle":"2021-08-04T18:16:51.744821Z","shell.execute_reply.started":"2021-08-04T18:16:51.647322Z","shell.execute_reply":"2021-08-04T18:16:51.743834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lg.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:51.747379Z","iopub.execute_input":"2021-08-04T18:16:51.747856Z","iopub.status.idle":"2021-08-04T18:16:51.917477Z","shell.execute_reply.started":"2021-08-04T18:16:51.747807Z","shell.execute_reply":"2021-08-04T18:16:51.916638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = lg.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:51.918875Z","iopub.execute_input":"2021-08-04T18:16:51.919381Z","iopub.status.idle":"2021-08-04T18:16:51.923221Z","shell.execute_reply.started":"2021-08-04T18:16:51.919347Z","shell.execute_reply":"2021-08-04T18:16:51.922521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix : ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\n\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:51.925045Z","iopub.execute_input":"2021-08-04T18:16:51.925945Z","iopub.status.idle":"2021-08-04T18:16:51.942315Z","shell.execute_reply.started":"2021-08-04T18:16:51.925862Z","shell.execute_reply":"2021-08-04T18:16:51.94119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note : \n\n1. First diagonal is the accuratly predicted elements / attributes / values.\n2. Second diagonal i.e 3 and 8 are the errors we had in this model.","metadata":{}},{"cell_type":"markdown","source":"# Checking the Score of our model ","metadata":{}},{"cell_type":"code","source":"print('The accuracy is :',accuracy_score(y_test, y_pred)*100)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:16:51.943934Z","iopub.execute_input":"2021-08-04T18:16:51.944404Z","iopub.status.idle":"2021-08-04T18:16:51.95589Z","shell.execute_reply.started":"2021-08-04T18:16:51.94435Z","shell.execute_reply":"2021-08-04T18:16:51.954646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note : \n> 1. Accuracy near 0.80 to 0.90 is said to be good or ideal, hence we can accept this model.\n> 2. Still if we want to increase the accuracy or reduce the amount of errors; for that we can implement various alogithms. and pick the most accurate one.\n> 3. Here further down I'll use __K-Nearest-Neighbors__ to increase the accuracy score.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}