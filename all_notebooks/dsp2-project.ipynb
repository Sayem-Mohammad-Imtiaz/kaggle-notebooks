{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, MaxPool2D, AveragePooling2D, Dense, Dropout, Flatten, Reshape\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_mnist_reduced(mnist, number_of_examples): #number of examples is 1000 in case of train and 100 in case of test\n    mnist_reduced = pd.DataFrame()\n    for i in range(10):\n        mnist_reduced = pd.concat([mnist_reduced, mnist[(mnist.iloc[:, 0] == i).values][0:number_of_examples]], axis = 0)\n    return mnist_reduced.iloc[:, 1:].values.reshape(-1, 28, 28, 1), mnist_reduced.iloc[:, 0].values\n#    return mnist_reduced.iloc[:, 1:].values, mnist_reduced.iloc[:, 0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    train_mnist = pd.read_csv('../input/mnist-original/mnist_train.csv')\n    X_train, y_train = get_mnist_reduced(train_mnist, 1000)\n    test_mnist = pd.read_csv('../input/mnist-original/mnist_test.csv')\n    X_test, y_test = get_mnist_reduced(test_mnist, 100)\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = load_data()\n# print(\"Y_train classes values are:\\n\", y_train.value_counts()) #remove .values from get_mnist_reduced to make this works\n# print(\"Y_test classes values are:\\n\", y_test.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_image(img, label = None):\n    plt.axis('off')\n    plt.imshow(img.reshape(28, 28), cmap = 'gray')\n    if label is not None:\n        plt.title(\"number is \" + str(label))\n\nplot_image(X_train[1100], y_train[1100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_distance(x1, x2):\n    sum = 0\n    for i in range(len(x1)):\n        sum += (x1[i] - x2[i]) ** 2\n    return np.sqrt(sum)\n\n\ndef kmeans(X, k, max_iters):\n    centroids = X[np.random.choice(range(len(X)), k, replace=False)]\n    # centroids = [np.random.uniform(size=len(X[0])) for i in range(k)]\n\n    converged = False\n    current_iter = 0\n\n    while (not converged) and (current_iter < max_iters):\n\n        cluster_list = [[] for i in range(len(centroids))]\n\n        for x in X:  # Go through each data point\n            distances_list = []\n            for c in centroids:\n                distances_list.append(get_distance(c, x))\n            cluster_list[int(np.argmin(distances_list))].append(x)\n\n        cluster_list = list((filter(None, cluster_list)))\n\n        prev_centroids = centroids.copy()\n\n        centroids = []\n\n        for j in range(len(cluster_list)):\n            centroids.append(np.mean(cluster_list[j], axis=0))\n\n        pattern = np.abs(np.sum(prev_centroids) - np.sum(centroids))\n\n        print('K-MEANS: ', int(pattern))\n\n        converged = (pattern == 0)\n\n        current_iter += 1\n\n    return np.array(centroids), [np.std(x) for x in cluster_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RBF:\n\n    def __init__(self, X, y, tX, ty, num_of_classes,\n                 k, std_from_clusters=True):\n        self.X = X\n        self.y = y\n\n        self.tX = tX\n        self.ty = ty\n\n        self.number_of_classes = num_of_classes\n        self.k = k\n        self.std_from_clusters = std_from_clusters\n\n    def convert_to_one_hot(self, x, num_of_classes):\n        arr = np.zeros((len(x), num_of_classes))\n        for i in range(len(x)):\n            c = int(x[i])\n            arr[i][c] = 1\n        return arr\n\n    def get_rbf(self, x, c, s):\n        distance = get_distance(x, c)\n        return 1 / np.exp(-distance / s ** 2)\n\n    def get_rbf_as_list(self, X, centroids, std_list):\n        RBF_list = []\n        for x in X:\n            RBF_list.append([self.get_rbf(x, c, s) for (c, s) in zip(centroids, std_list)])\n        return np.array(RBF_list)\n\n    def fit(self):\n\n        self.centroids, self.std_list = kmeans(self.X, self.k, 1000)\n\n        if not self.std_from_clusters:\n            dMax = np.max([get_distance(c1, c2) for c1 in self.centroids for c2 in self.centroids])\n            self.std_list = np.repeat(dMax / np.sqrt(2 * self.k), self.k)\n\n        RBF_X = self.get_rbf_as_list(self.X, self.centroids, self.std_list)\n\n        self.w = np.linalg.pinv(RBF_X.T @ RBF_X) @ RBF_X.T @ self.convert_to_one_hot(self.y, self.number_of_classes)\n\n        RBF_list_tst = self.get_rbf_as_list(self.tX, self.centroids, self.std_list)\n\n        self.pred_ty = RBF_list_tst @ self.w\n\n        self.pred_ty = np.array([np.argmax(x) for x in self.pred_ty])\n\n        diff = self.pred_ty - self.ty\n\n        print('Accuracy: ', len(np.where(diff == 0)[0]) / len(diff))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RBF_CLASSIFIER = RBF(X_train, y_train,X_test, y_test, num_of_classes=10,\n                     k=1000, std_from_clusters=False)\n\nRBF_CLASSIFIER.fit()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}