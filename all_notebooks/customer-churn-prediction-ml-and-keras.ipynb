{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Description</h1>\n<h2>Context</h2>\n\n<p> Customer churn occurs when customers or subscribers stop doing business with a company or service. Also known as customer attrition, customer churn is a critical metric because it is much less expensive to retain existing customers than it is to acquire new customers – earning business from new customers means working leads all the way through the sales funnel, utilizing your marketing and sales resources throughout the process. Customer retention, on the other hand, is generally more cost-effective, as you have already earned the trust and loyalty of existing customers.  </p>\n\n<h2>Goal</h2>\n<p>\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]]</p>\n\n<h2>Content</h2>\n\n<p>Each row represents a customer; each column contains customer’s attributes described in the column Metadata.\nThe data set includes information about:\n</p>\n\n<ul>\n<li>Customers who left within the last month – the column is called Churn\n<li>Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n<li>Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n<li>Demographic info about customers – gender, age range, and if they have partners and dependents\n</ul>\n<h2>Source:</h2>\n<a href=\"https://www.kaggle.com/blastchar/telco-customer-churn\">https://www.kaggle.com/blastchar/telco-customer-churn</a>\n  "},{"metadata":{},"cell_type":"markdown","source":"This notebook will include 2 tasks (Inicial Data Exploration and Extract, Transform,\tLoad)\n\n<h3>1. Initial Data Exploration</h3>\n<ul>\n<li> Identify quality issues (e.g. missing values, wrong measurements, …)</li>\n<li>Assess feature quality – how relevant is a certain measurement (e.g. use correlation matrix)</li>\n<li>Get an idea on the value distribution of your data using statistical measures and visualizations</li>\n</ul>    \n\n<h3>2. Extract,\tTransform,\tLoad\t(ETL) </h3>\n\n<ul> \n<li>Accessing the data source;</li>\n<li>Transforming data source; </li>\n</ul>\n    "},{"metadata":{},"cell_type":"markdown","source":"<h3>2.1 Extraction</h3> \nThe data set is in csV format. It was updated as an IBM Cloud Object Storage. It was used pandas dataframe to manipulate the data extracted."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\ntelco = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ntelco.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After loading the file, we could notice that some columns are categorical and some are numerical. So, the first step it checks if it has some inconsistent data (missing values, wrong measurements, etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"telco.dtypes","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Chek if there is any column with null values\ntelco.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice total charges are an object type. It might need to be converted to the appropriate type."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"telco.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there is no NaN values."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Get a overview of each column\ntelco.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Get maximum values\ntelco.max()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Get minimum values\ntelco.min()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Checking unique values\ntelco.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>After checking the max, min and unique values, it is possible to see some data inconsistencies. TotalCharges has empty cells. Some columns have three different values but their max and min are 'yes' or 'no'. In this case, these columns might have some ambiguous values that can be replaced by 'yes' or 'no'.</p>\n\n<ul>\n<li> MultipleLines         = 3</li>\n<li> InternetService       = 3</li>\n<li> OnlineSecurity        = 3</li>\n<li> OnlineBackup          = 3</li>\n<li> DeviceProtection      = 3</li>\n<li> TechSupport           = 3</li>\n<li> StreamingTV           = 3</li>\n<li> StreamingMovies       = 3</li>\n<li> Contract              = 3</li>\n</ul>    "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Empty cells in TotalCharges: ', len(telco[telco['TotalCharges']==' ']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before starting some data visualization, it’s necessary to fix some issues and <b>transform</b> the data set (making it easy to manipulate)."},{"metadata":{},"cell_type":"markdown","source":"<h3>2.2 Transform</h3>\n<h3>2.2.1 Transformation: Removing rows with empty cells (Total Charges)</h3>\nFirst, remove rows where TotalCharges column has empty cells."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#number of rows\nnrows_before=len(telco) \n#removing empty cells from TotalCharges (remove associeted rows)\ntelco=telco[telco['TotalCharges']!=' ']\n#Number of rows after remove emptys TotalCharges\nnrows_after=len(telco)\n#Reset inted\ntelco.reset_index(inplace=True)\ntelco.drop('index', axis=1, inplace=True)\n#Lost data\nprint((\"lost data: {0:.3f} %\").format(100*(1-nrows_after/nrows_before)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>2.2.2 Transformation: Converting to float (Total Charges)</h3>\nThe amount of lost data is really small and it will not impact in the model. The next step is to convert TotalCharges to float (considering its format is a string)."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"telco[\"TotalCharges\"] = telco[\"TotalCharges\"].astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"TotalCharges type:\", telco[\"TotalCharges\"].dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another problem pointed out was the ambiguous columns. The next step is to check these columns\n\n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Checking columns with 3 different unique values \ncheck_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingMovies']\nfor c in check_cols:\n    print( c + '=', telco[c].unique())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>2.2.3 Transformation: replace to (yes,no) (SeniorCitizen)</h3>\nThis transformation will just be temporary for some exploratory data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"telco[\"SeniorCitizen\"] = telco[\"SeniorCitizen\"].replace(to_replace=[0, 1], value=['No', 'Yes'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"SeniorCitizen unquies: \", telco[\"SeniorCitizen\"].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>2.2.4 Transformation: Replacing ambiguous values</h3>\n\nAs you can see, No 'Internet Service/No phone service' is equivalent to 'no'. For these cases, they will be replaced. For now, Internet Service column will not be modified."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Replace 'No internet service','No phone service' to 'No'\ntelco.replace(['No internet service','No phone service'],'No', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in check_cols:\n    print( c + '=', telco[c].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing column-only values again:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in telco.columns:\n    print( c + '=', telco[c].unique())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Separation of categorical and numerical columns\ncat_cols = telco.select_dtypes(include='object')\nnum_cols = telco.select_dtypes(exclude='object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>2.3 Exploratory analysis and data visualization </h3>\n<h3>2.3.1 Heatmap - correlation of numerical variables</h3>"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.clustermap(num_cols.corr(),linecolor='white',cmap='coolwarm',annot=True, figsize=(15,15))\nsns.set_context(\"paper\", font_scale=2)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, tenure and Totalcharges have a close correlation. Also, TotalCharges and MonthlyCharge have a relevant correlation."},{"metadata":{},"cell_type":"markdown","source":"<h3>2.3.2 Correlation of numeric variables and Churn distribution</h3>"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.pairplot(telco, hue='Churn', palette='coolwarm', size=5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice the correlation between Total Charges X Tenure and Total Charges X Monthly Charges."},{"metadata":{},"cell_type":"markdown","source":"<h3>2.3.3 Distribution of numeric columns</h3>"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(nrows=1,ncols=3, squeeze=True,figsize=(30, 8))\n\nsns.distplot(telco['MonthlyCharges'], ax=axes[0])\n\nsns.distplot(telco['TotalCharges'],  ax=axes[1])\n\nsns.distplot(telco['tenure'], ax=axes[2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <h3>2.3.4 Checking distribution between numeric columns and Churn</h3>"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#TotalCharges vS  Churn\ng = sns.FacetGrid(telco, hue=\"Churn\", size=8, aspect=2,legend_out=True)\ng = (g.map(sns.distplot, \"TotalCharges\", kde=False).add_legend())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MonthlyCharges vS  Churn\ng = sns.FacetGrid(telco, hue=\"Churn\", size=8, aspect=2,legend_out=True)\ng = (g.map(sns.distplot, \"MonthlyCharges\", kde=False).add_legend())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tenure vS  Churn\ng = sns.FacetGrid(telco, hue=\"Churn\", size=8, aspect=2,legend_out=True)\ng = (g.map(sns.distplot, \"tenure\", kde=False).add_legend())","execution_count":null,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"Note that most of the churn values are in Total Charges <100."},{"metadata":{},"cell_type":"markdown","source":"<h3>2.3.5 Categorical columns comparison</h3>"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"import math\nf, axes = plt.subplots(nrows=math.ceil(len(cat_cols.columns[1:])/2),ncols=2,figsize=(30, 40))\ngraf_count = []\ni=0\nj=0\nfor col in cat_cols.columns[1:]:\n    graf_count.append(sns.countplot(x=col,data=telco, ax=axes[i,j],palette=\"Paired\"))\n    j=j+1\n    if j==2:\n        i=i+1\n        j=0\ngraf_count.append(sns.boxplot(x=\"TotalCharges\", y=\"Churn\", data=telco, whis=np.inf))\nsns.set_context(\"paper\", font_scale=1.5)      \nsns.set_style(\"white\")\nsns.despine()\n\ntotal = float(len(telco)) \nplt.subplots_adjust(bottom=0.1, right=0.8, top=0.9, hspace = 0.5)\n\n\nfor g in graf_count:\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(100*height/total),\n            ha=\"center\") \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"telco.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>3. Feature\tCreation</h3>\n    \n<ul>\n<li>Filling of empty fields based on its value distribution</li>\n<li>Imputed time-series quantization Time series often contain streams with measurements at different timestamps</li>\n<li>Scaling / Normalizing / Centering</li>\n<li>Filtering - Sometimes imputing values doesn’t perform well</li>\n<li>Discretizing - Continuous fields might confuse the model</li>\n</ul>    \n\nLooking again at the tenure, it can be separated into different boxes and create a new category column. In this case, it has been separated by intervals of years:\n\n<ul>\n<li>0-1 year (0-12 months)</li>\n<li>1-2 year (12-24 months)</li>\n<li>2-3 year (24-36 months)</li>\n<li>3-4 year (36-48 months)</li>\n<li>4-5 year (48-60 months)</li>\n<li>5-6 year (60-72 months)</li>\n</ul>    \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tenure to Categorical\ndef tenure_cat(telco) :\n    \n    if telco[\"tenure\"] <= 12 :\n        return \"0-1_year\"\n    elif (telco[\"tenure\"] > 12) & (telco[\"tenure\"] <= 24):\n        return \"1-2_year\"\n    elif (telco[\"tenure\"] > 24) & (telco[\"tenure\"] <= 36):\n        return \"2-3_year\"\n    elif (telco[\"tenure\"] > 36) & (telco[\"tenure\"] <= 48):\n        return \"3-4_year\"\n    elif (telco[\"tenure\"] > 48) & (telco[\"tenure\"] <= 60):\n        return \"4-5_year\"\n    elif telco[\"tenure\"] > 60:\n        return \"5-6_year\"\n\ntelco[\"tenure_years\"] = telco.apply(lambda t:tenure_cat(t), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"telco.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"telco['tenure_years'].value_counts().sort_index().index\nfig = plt.gcf()\nfig.set_size_inches(16, 10)\nsns.set_context(context='paper', font_scale=2)\ng=sns.countplot(x=\"tenure_years\", data=telco, palette=\"magma\", order=telco['tenure_years'].value_counts().sort_index().index)\ntotal = float(len(telco)) \n\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n    height + 3,'{:1.2f}%'.format(100*height/total), ha=\"center\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>3.2 Creating Dummy columns (One-hot-encoding) </h3>\nNext task is create some dummy columns "},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = telco.select_dtypes(include='object')\nnum_cols = telco.select_dtypes(exclude='object')\ncat_cols=cat_cols.drop(\"customerID\", axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"telco=pd.get_dummies(data = telco,columns =  cat_cols.columns, drop_first=True)\ntelco.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"telco.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_context(\"paper\", font_scale=1)  \nsns.clustermap(telco.corr(),linecolor='white',cmap='coolwarm', figsize=(20,15), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>3.3 Normalization</h3>"},{"metadata":{},"cell_type":"markdown","source":"A normalization is applied to the numeric columns (Total Charges, Tenure, Month Charges)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n#Normalize the mesure (numerical columns)\nscale = StandardScaler()\nscale.fit_transform(num_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scale\nscaled_features = scale.transform(num_cols)\n#Create a panda DF with scaled features\ntelco_feat = pd.DataFrame(scaled_features, columns= num_cols.columns)\n#Concat this new DF with Telco DF\ntelco_feat = pd.concat([telco_feat, telco.drop(['tenure','MonthlyCharges','TotalCharges'], axis=1)], axis=1)\n#Move Target columns to the last column position\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Renaming and fixing some columns names"},{"metadata":{"trusted":true},"cell_type":"code","source":"telco_feat['Churn'] = telco_feat['Churn_Yes']\ntelco_feat.drop('Churn_Yes', axis=1, inplace=True)\n\ntelco_feat.rename(columns={'InternetService_Fiber optic':'InternetService_Fiber_Optic',\n                          'PaymentMethod_Credit card (automatic)':'PaymentMethod_Credit_card_Auto',\n                          'PaymentMethod_Electronic check':'PaymentMethod_Electronic_Check',\n                          'PaymentMethod_Mailed check':'PaymentMethod_Mailed_check',\n                           'Contract_One year':'Contract_One_year',\n                           'Contract_Two year':'Contract_Two_year'\n                          }, \n                 inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"telco_feat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"telco_feat.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cheking the correlation between Churn and the other variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nax = fig.add_axes([0,0,1,1])\n\n#Bart plot\ntelco_feat.corr()['Churn'].sort_values(ascending = False).plot(kind='bar', cmap='RdGy', )\n\n#Change font size\nfor item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n             ax.get_xticklabels() + ax.get_yticklabels()):\n    item.set_fontsize(12)\n\nax.axhline(0, color='black')\n    \ntotal=len(telco_feat.corr()['Churn'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4. Model Definition and Training</h3>\n<ul>\n<li>Selecting model performance indicator</li>\n<li>Implementing algorithm</li>\n<li>Appling additional iteration</li>\n<li>Training</li>\n</ul>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"telco=telco_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report,confusion_matrix \n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the dataset in train and test 30% (Test size)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(telco.drop(['customerID','Churn'],axis=1),telco['Churn'],\n                                                    test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_depth=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying GridSearch to find better parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#GridSearch \nparameters = {\n    'n_estimators'      : [100,150,200,250,500],\n    'max_depth'         : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n    'random_state'      : [0],\n}\ngrid_rfc = GridSearchCV(RandomForestClassifier(), parameters, refit=True, verbose=3, scoring='accuracy', cv=5, n_jobs=4) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_rfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RESULTS\nchurn = {'rfc':[grid_rfc.best_params_,grid_rfc.best_score_]}\nprint('Parametros', grid_rfc.best_params_)\nprint('Accuracy', grid_rfc.best_score_)\nprint('Estimator:', grid_rfc.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the best estimator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=9, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['rfc'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cm = pd.DataFrame(cm, index = ['Churn','All'],\n                  columns = ['Churn','All'])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfor i in max_depth:\n    \n    rfc_e = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=i, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)\n    scores = cross_val_score(rfc_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = max_depth[MSE.index(min(MSE))]\nprint(\"The optimal number of Max Depth is:\", optimal_k)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(max_depth, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number of Max Depth')\nplt.ylabel('Misclassification Error')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4.2 KNeighborsClassifier</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nk_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying GridSearch to find better parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'n_neighbors'      : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n    'weights'         : ['uniform','distance'],\n    'metric'      : ['euclidean', 'manhattan'],\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_knn = GridSearchCV(KNeighborsClassifier(), parameters, refit=True, verbose=3, scoring='accuracy', cv=5, n_jobs=4) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RESULTS\nchurn = {'Knn':[grid_knn.best_params_,grid_knn.best_score_]}\nprint('Parametros', grid_knn.best_params_)\nprint('Accuracy', grid_knn.best_score_)\nprint('Estimator:', grid_knn.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the best estimator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n           metric_params=None, n_jobs=1, n_neighbors=24, p=2,\n           weights='uniform')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['Knn'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred)\ndf_cm = pd.DataFrame(cm, index = ['Churn','All'],\n                  columns = ['Churn','All'])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfor i in k_range:\n    \n    knn_e = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n           metric_params=None, n_jobs=1, n_neighbors=i, p=2,\n           weights='uniform')\n    scores = cross_val_score(knn_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = k_range[MSE.index(min(MSE))]\nprint(\"The optimal number of neighbors is:\", optimal_k)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(k_range, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4.3 XGBoosts</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoosts\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying GridSearch to find better parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma = [0, 0.001, 0.01, 0.1,1 , 2, 5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n   'max_depth': [3,4],\n   'n_estimators': [100,150],\n   'nthread': [8],\n   'subsample': [0,0.9, 1.0],\n   'gamma': [0, 0.001, 0.01, 0.1,1 , 2, 5],\n   'min_child_weight': [1, 5, 10]\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_gb = GridSearchCV(XGBClassifier(), param_grid=param_grid, refit=True, verbose=3, scoring='accuracy', n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_gb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RESULTS\nif 'churn' in globals():\n    churn['xgb'] = [grid_gb.best_params_,grid_gb.best_score_]\nelse:\n    churn = {'xgb':[grid_gb.best_params_,grid_gb.best_score_]}\n\nprint('Parametros', grid_gb.best_params_)\nprint('Accuracy', grid_gb.best_score_)\nprint('Estimator:', grid_gb.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the best estimator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n       gamma=2, learning_rate=0.1, max_delta_step=0, max_depth=4,\n       min_child_weight=1, missing=None, n_estimators=100, nthread=8,\n       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['xgb'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred)\ndf_cm = pd.DataFrame(cm, index = ['Churn','All'],\n                  columns = ['Churn','All'])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfor i in gamma:\n    \n    xgb_e = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n       gamma=i, learning_rate=0.1, max_delta_step=0, max_depth=4,\n       min_child_weight=1, missing=None, n_estimators=100, nthread=8,\n       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)\n    scores = cross_val_score(xgb_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = gamma[MSE.index(min(MSE))]\nprint(\"The optimal gamma is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(gamma, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Gamma number')\nplt.ylabel('Misclassification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4.4 Linear Suport Vector Machine</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nC = [0.1, 1, 10, 100,500,1000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying GridSearch to find better parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10, 100,500,1000]}\ngrid_lsvm = GridSearchCV(LinearSVC(),param_grid,refit=True,verbose=3,scoring='accuracy', n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_lsvm.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn['LinearSVC'] = [grid_lsvm.best_params_,grid_lsvm.best_score_]\nprint('Parametros', grid_lsvm.best_params_)\nprint('Accuarcy', grid_lsvm.best_score_)\nprint('Estimator:', grid_lsvm.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc=LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the best estimator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = lsvc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['LinearSVC'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred)\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\nplt.figure(figsize = (15,10))\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfor i in C:\n    \n    lsvc_e = LinearSVC(C=i, class_weight=None, dual=True, fit_intercept=True,\n     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n     verbose=0)\n    scores = cross_val_score(lsvc_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = C[MSE.index(min(MSE))]\nprint(\"The optimal C is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(C, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number os Cs')\nplt.ylabel('Misclassification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4.5 Suport Vector Machine</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying GridSearch to find better parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Csvc = [1,10,100,1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['rbf']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_svc = GridSearchCV(SVC(),param_grid,refit = True, verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_svc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'churn' in globals():\n    churn['SVC'] = [grid_svc.best_params_,grid_svc.best_score_]\nelse:\n    churn = {'SVC':[grid_svc.best_params_,grid_svc.best_score_]}\n \nprint('Parametros', grid_svc.best_params_)\nprint('Accuarcy', grid_svc.best_score_)\nprint('Estimator:', grid_svc.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the best estimator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = svm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['SVC'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred)\nplt.figure(figsize = (15,10))\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\n\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfor i in Csvc:\n    \n    svc_e = SVC(C=i, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n    scores = cross_val_score(svc_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = Csvc[MSE.index(min(MSE))]\nprint(\"The optimal C is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(Csvc, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number os Cs')\nplt.ylabel('Misclassification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4.6 Logistic Regression </h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying GridSearch to find better parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Clog = [0.001,0.01,0.1,1,10,100,1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_values = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_log = GridSearchCV(LogisticRegression(),param_grid=grid_values,refit = True, verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_log.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'churn' in globals():\n    churn['log'] = [grid_log.best_params_,grid_log.best_score_]\nelse:\n    churn = {'log':[grid_log.best_params_,grid_log.best_score_]}\n \nprint('Parametros', grid_log.best_params_)\nprint('Accuarcy', grid_log.best_score_)\nprint('Estimator:', grid_log.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the best estimator:"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_test,pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_test,pred))\nprint('Accuracy', churn['log'][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred)\nplt.figure(figsize = (15,10))\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\n\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\nfor i in Clog:\n    \n    log_e = LogisticRegression(C=i, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n    scores = cross_val_score(log_e, X_train, y_train, cv=5, scoring='accuracy')\n    cv_scores.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal = Clog[MSE.index(min(MSE))]\nprint(\"The optimal C is:\", optimal)\n\n# plot misclassification error vs k\nplt.figure(figsize=(15,10))\nplt.plot(Clog, MSE,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Number os Cs')\nplt.ylabel('Misclassification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import Dense, Dropout\nfrom keras.models import Sequential\nfrom IPython.display import SVG\nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras import losses\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM\n#import pydot\nfrom imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os = SMOTE(random_state = 0,  k_neighbors=10)\n\n#Train set\nX_smote_os,y_smote_os = os.fit_sample(X_train,y_train)\nX_smote_os = pd.DataFrame(data = X_smote_os,columns= telco.drop(['customerID','Churn'], axis=1).columns)\ny_smote_os  = pd.DataFrame(data = y_smote_os,columns=[\"Churn\"])\n\nX_matrix_smote = X_smote_os.as_matrix()\ny_matrix_smote =y_smote_os.as_matrix()\n\n#Test set\nX_smote_os_test,y_smote_os_test = os.fit_sample(X_test,y_test)\nX_smote_os_test = pd.DataFrame(data = X_smote_os_test,columns= telco.drop(['customerID','Churn'], axis=1).columns)\ny_smote_os_test  = pd.DataFrame(data = y_smote_os_test,columns=[\"Churn\"])\n\nX_matrix_smote_test = X_smote_os.as_matrix()\ny_matrix_smote_test =y_smote_os.as_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>4.7 Deep Learning - Model training</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_cols=X_matrix_smote.shape[1]\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(n_cols,), activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(4, activation='softmax'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training the Model:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"history = model.fit(X_matrix_smote, y_matrix_smote, epochs=150, batch_size=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions   = model.predict(X_matrix_smote_test)\nscore = model.evaluate(X_matrix_smote_test, y_matrix_smote_test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking performance:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (predictions > 0.5)\nprint(\"Churn\")\nprint(\"Classification Report\")\nprint(classification_report(y_matrix_smote_test, y_pred))\nprint(\"Confusion Matrix\")\nprint(confusion_matrix(y_matrix_smote_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_matrix_smote_test, y_pred)\nplt.figure(figsize = (15,10))\nsns.set_context(font_scale=2)\ndf_cm = pd.DataFrame(cm, index = ['Churn','No Churn'],\n                  columns = ['No Churn','Churn'])\n\nsns.heatmap(df_cm, annot=True, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(211)\nplt.plot(history.history['acc'], marker='o', markerfacecolor='black', markersize=2)\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n\n# Plot training & validation loss values\nplt.subplot(212)\nplt.plot(history.history['loss'], marker='o', markerfacecolor='black', markersize=2)\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>6. Evaluating Models</h3>\n<ul>\n<li>Performance\tis\tevaluated.</li>\n<li>Metrics\t</li>\n    \n</ul>    "},{"metadata":{},"cell_type":"markdown","source":"<h3>Fucntion to evauluete models (machine learning)</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import plot_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluate(model,train_x,test_x,train_y,test_y,name) :\n    model.fit(train_x,train_y)\n    predictions  = model.predict(test_x)\n    \n    predictions  = model.predict(test_x)\n    accuracy     = accuracy_score(test_y,predictions)\n    recallscore  = recall_score(test_y,predictions)\n    precision    = precision_score(test_y,predictions)\n    auc          = cross_val_score(model,test_x,test_y, scoring='roc_auc').mean()\n    f1score      = f1_score(test_y,predictions) \n        \n    df = pd.DataFrame({\"0_Model\"           :  name,\n                       \"1_Accuracy_score\"  : [accuracy],\n                       \"2_Recall_score\"    : [recallscore],\n                       \"3_Precision\"       : [precision],\n                       \"4_f1_score\"        : [f1score],\n                       \"5_Area_under_curve\": [auc]                  \n                      })\n    \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_models = np.array([rfc, knn, xgb, lr, lsvc, svm])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names=np.array(['RandomForestClassifier', 'KNeighborsClassifier', 'XGBClassifier','LogisticRegression','LinearSVC', 'SVC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame()\ni=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recallscore  = recall_score(y_matrix_smote_test,y_pred)\nprecision    = precision_score(y_matrix_smote_test,y_pred)\nf1score      = f1_score(y_matrix_smote_test,y_pred) \nauc = roc_auc_score(y_matrix_smote_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras_model_result=pd.DataFrame({\"0_Model\"           : 'KerasSequencial',\n                       \"1_Accuracy_score\"  : [score[1]],\n                       \"2_Recall_score\"    : [recallscore],\n                       \"3_Precision\"       : [precision],\n                       \"4_f1_score\"        : [f1score],\n                       \"5_Area_under_curve\": [auc]                  \n                      })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Evaluating machine learning models</h3>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for l in  ml_models:\n    results=results.append(model_evaluate(l ,X_train,X_test,y_train,y_test,names[i]))\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Results</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"results=results.append(keras_model_result).reset_index().drop('index', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def highlight_max(s):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    if s.dtype == 'float64':\n        return ['background-color: yellow' if v else '' for v in is_max]\n    else:\n        return ['background-color: white' if v else '' for v in is_max]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.style.apply(highlight_max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}