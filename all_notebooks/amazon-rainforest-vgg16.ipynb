{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes_df = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ntrain_classes_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/planets-dataset/planet/planet/train-jpg | wc -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_df = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = !ls ../input/planets-dataset/planet/planet/test-jpg | wc -l\ntest2 = !ls ../input/planets-dataset/test-jpg-additional/test-jpg-additional | wc -l\nassert sample_submission_df.shape[0] == float(test1[0])+float(test2[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_number =10\nimg = io.imread('../input/planets-dataset/planet/planet/train-jpg/train_{}.jpg'.format(image_number))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes_df[train_classes_df['image_name'] == 'train_10']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_labels = set()\ndef append_labels(tags):\n    for tag in tags.split():\n        unique_labels.add(tag)\n\ntrain_classes = train_classes_df.copy()\ntrain_classes['tags'].apply(append_labels)\nunique_labels = list(unique_labels)\nprint(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(train_classes['image_name'].unique()) == train_classes.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's do one hot encoding (vectorize) the labels in 'train_classes'\nfor tag in unique_labels:\n    train_classes[tag] = train_classes['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n# adding '.jpg' extension to 'image_name'\ntrain_classes['image_name'] = train_classes['image_name'].apply(lambda x: '{}.jpg'.format(x)) \ntrain_classes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_col = list(train_classes.columns[2:]) # storing the tags column names as a variable\n\n# initializing an image generator with some data augumentation\nimage_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# loading images from dataframe\nX = image_gen.flow_from_dataframe(dataframe=train_classes, \\\n        directory='/kaggle/input/planets-dataset/planet/planet/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(64, 64), class_mode='raw', seed=1, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X is an iterable, It contains 317 batches, each batch contains 128 images and labels because \n#40479 / 128 is 316 remainder 31 each image is of shape (128, 128, 3), each label is of shape (17, )\n\n# let's abitrarily view an image\nx54 = X[0][0][54] # first batch, images, 109th image\ny54 = X[0][1][54] # first batch, labels, 109th label\nprint(\"each image's shape is {}\".format(x54.shape))\nprint(\"each label's shape is {}\".format(y54.shape))\nprint('we have {} batches'.format(len(X)))\nprint('each batch has {} images/labels'.format(X[0][0].shape[0]))\nprint('40479/128 is {:.2F}, so the last batch will have {} images/labels'.format(40479/128, X[316][0].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Conv2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import SGD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fbeta(ytrue , ypred, beta=2, epsilon=1e-4):\n    beta_squarred = beta**2\n\n    ytrue = tf.cast(ytrue, tf.float32)\n    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(0.5)), tf.float32)\n        \n    tp = tf.reduce_sum(ytrue * ypred, axis=1)\n    fp = tf.reduce_sum(ypred, axis=1) - tp\n    fn = tf.reduce_sum(ytrue, axis=1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squarred)*precision*recall / (beta_squarred*precision + recall + epsilon)\n    return fb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_label_acc(ytrue , ypred, epsilon=1e-4):\n    \n    ytrue = tf.cast(ytrue, tf.float32)\n    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(ytrue * ypred, axis=1)\n    fp = tf.reduce_sum(ypred, axis=1) - tp\n    fn = tf.reduce_sum(ytrue, axis=1) - tp\n    \n    ytrue = tf.cast(ytrue, tf.bool)\n    ypred = tf.cast(ypred, tf.bool)\n    \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(ytrue), tf.float32) * tf.cast(tf.logical_not(ypred), tf.float32),\\\n                       axis=1)\n    \n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    in_shape=(64, 64, 3)\n    out_shape=17\n\n    # load mannequin\n\n    mannequin = VGG16(include_top=False, input_shape=in_shape)\n\n    # mark loaded layers as not trainable\n\n    for layer in mannequin.layers:\n        layer.trainable = False\n\n    # enable final vgg block to be trainable\n\n    mannequin.get_layer(\"block5_conv1\").trainable = True\n\n    mannequin.get_layer(\"block5_conv2\").trainable = True\n\n    mannequin.get_layer(\"block5_conv3\").trainable = True\n\n    mannequin.get_layer(\"block5_pool\").trainable = True\n\n    # add new classifier layers\n\n    flat1 = Flatten()(mannequin.layers[-1].output)\n\n    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n\n    output = Dense(out_shape, activation=\"sigmoid\")(class1)\n\n    # outline new mannequin\n\n    mannequin = Model(inputs=mannequin.inputs, outputs=output)\n\n    # compile mannequin\n\n    choose = SGD(lr=0.01, momentum=0.9)\n\n    mannequin.compile(optimizer=choose, loss=\"binary_crossentropy\", metrics=[fbeta, multi_label_acc])\n    \n    return mannequin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_best_check_point = ModelCheckpoint(filepath='best_model.hdf5', monitor='val_fbeta',mode='max', save_best_only=True, save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,validation_split=0.2)\n\n# generating the 80% training image data\ntrain_gen = train_image_gen.flow_from_dataframe(dataframe=train_classes, \\\n        directory='../input/planets-dataset/planet/planet/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(64, 64), class_mode='raw', seed=0, batch_size=64, subset='training')\n\n# generating the 20% validation image data\nval_gen = train_image_gen.flow_from_dataframe(dataframe=train_classes, \\\n        directory='../input/planets-dataset/planet/planet/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(64,64), class_mode='raw', seed=0, batch_size=64, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting step size for training and validation image data\nstep_train_size = int(np.ceil(train_gen.samples / train_gen.batch_size))\nstep_val_size = int(np.ceil(val_gen.samples / train_gen.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"step_train_size+step_val_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nmodel1 = build_model() # building a sequential model for training\n\n# fitting the model\nmodel1.fit(x=train_gen, steps_per_epoch=step_train_size, validation_data=val_gen, validation_steps=step_val_size,epochs=10, callbacks=[save_best_check_point])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# V3 : (vgg16:64,64,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = \"../input/planets-dataset/planet/planet\"\ntrain_data = pd.read_csv(data_path+\"/train_classes.csv\")\ntest_img_path = data_path + \"/test-jpg\"\ntrain_img_path = data_path + \"/train-jpg\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_data['tags'].unique())  # number of categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape # No of Indivials","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_list =[]\n\nfor tag_str in train_data.tags.values:\n    labels =tag_str.split(' ')\n    for label in labels:\n        if label not in label_list:\n            label_list.append(label)\n\nlabel_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label in label_list:\n    train_data[label] =train_data['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n# Display head\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of label instances\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain_data[label_list].sum().sort_values().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndef make_cooccurence_matrix(labels):\n    numeric_df = train_data[labels]; \n    c_matrix = numeric_df.T.dot(numeric_df)\n    sns.heatmap(c_matrix)\n    return c_matrix\n    \n# Compute the co-ocurrence matrix\nmake_cooccurence_matrix(label_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.image import imread\n# load image pixels\nimage = imread(train_img_path+\"/\"+\"train_10002.jpg\")\n\t# plot raw pixel data\nplt.imshow(image)\n    \n# show the figure\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom os import listdir\nfrom numpy import zeros\nfrom numpy import asarray\nfrom numpy import savez_compressed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_tag_mapping(labels_df):\n    \n    labels = set()\n    for i in range(len(labels_df)):\n        # convert spaced separated tags into an array of tags\n        tags = labels_df['tags'][i].split(' ')\n        # add tags to the set of known labels\n        labels.update(tags)\n    # convert set of labels to a list to list\n    labels = list(labels)\n    labels.sort()\n # dict that maps labels to integers, and the reverse\n    labels_map = { labels [i]:i for i in range(len(labels))}\n    inv_labels_map = {i: labels [i] for i in range(len(labels))}\n    return labels_map, inv_labels_map\n\n\n\ndef create_file_mapping(train_data):\n    mapping = dict()\n    for i in range(len(labels_df)):\n        name, tags = train_data['image_name'][i], labels_df['tags'][i]\n        mapping[name] = tags.split(' ')\n        \n    return mapping\n\n\ndef one_hot_encode(tags,mapping):\n    \n    # create empty vector\n    encoding = zeros(len(mapping), dtype='uint8')\n    # mark 1 for each tag in the vector\n    for tag in tags:\n        encoding[mapping[tag]] = 1\n    return encoding\n\n\n\n\ndef load_dataset(path, file_mapping, tag_mapping):\n    photos, targets = list(), list()\n    # enumerate files in the directory\n    for filename in listdir(folder):\n        # load image\n        photo = load_img(path + filename, target_size=(64,64))\n        # convert to numpy array\n        photo = img_to_array(photo, dtype='uint8')\n        # get tags\n        tags = file_mapping[filename[:-4]]\n        # one hot encode tags\n        target = one_hot_encode(tags, tag_mapping)\n        # store\n        photos.append(photo)\n        targets.append(target)\n    X = asarray(photos, dtype='uint8')\n    y = asarray(targets, dtype='uint8')\n    return X, y\n \n    \n    \n \n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = '../input/planets-dataset/planet/planet/train_classes.csv'\nlabels_df = pd.read_csv(filename, encoding='latin1')\n\n# create a mapping of tags to integers\nmapping, inv_mapping = create_tag_mapping(labels_df)\nprint(len(mapping))\nprint(mapping)\n\n# create a mapping of tags to integers\ntag_mapping, _ = create_tag_mapping(labels_df)\n\n# create a mapping of filenames to tag lists\nfile_mapping = create_file_mapping(labels_df)\n\n# load the jpeg images\nfolder = '../input/planets-dataset/planet/planet/train-jpg/'\nX, y = load_dataset(folder, file_mapping, tag_mapping)\nprint(X.shape, y.shape)\n\n# save both arrays to one file in compressed format\nsavez_compressed('planet_data.npz', X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport keras \nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nfrom keras.models import Sequential \nfrom keras.layers import Conv2D,Flatten,MaxPooling2D,Dropout,Dense,BatchNormalization,SpatialDropout2D\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.optimizers import SGD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.load('./planet_data.npz')\nX,y =data['arr_0'],data['arr_1']\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend\n\n\ndef fbeta(y_true, y_pred, beta=2):\n    # clip predictions\n    y_pred = backend.clip(y_pred, 0, 1)\n    # calculate elements\n    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n    # calculate precision\n    p = tp / (tp + fp + backend.epsilon())\n    # calculate recall\n    r = tp / (tp + fn + backend.epsilon())\n    # calculate fbeta, averaged across each class\n    bb = beta ** 2\n    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n    return fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n\ntrain_datagen = ImageDataGenerator(featurewise_center=True, horizontal_flip=True, vertical_flip=True, rotation_range=90)\ntest_datagen = ImageDataGenerator(featurewise_center=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\nprint(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n\ntrain_datagen.mean = [123.68, 116.779, 103.939]\ntest_datagen.mean = [123.68, 116.779, 103.939]\ntrain_datagen.fit(X_train)\ntest_datagen.fit(X_test)\n\ntrain_it = train_datagen.flow(X_train, Y_train, batch_size=128)\n\ntest_it = test_datagen.flow(X_test, Y_test, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    in_shape=(64, 64, 3)\n    out_shape=17\n\n    # load mannequin\n\n    mannequin = VGG16(include_top=False, input_shape=in_shape)\n\n    # mark loaded layers as not trainable\n\n    for layer in mannequin.layers:\n        layer.trainable = False\n\n    # enable final vgg block to be trainable\n\n    mannequin.get_layer(\"block5_conv1\").trainable = True\n\n    mannequin.get_layer(\"block5_conv2\").trainable = True\n\n    mannequin.get_layer(\"block5_conv3\").trainable = True\n\n    mannequin.get_layer(\"block5_pool\").trainable = True\n\n    # add new classifier layers\n\n    flat1 = Flatten()(mannequin.layers[-1].output)\n\n    class1 = Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\")(flat1)\n\n    output = Dense(out_shape, activation=\"sigmoid\")(class1)\n\n    # outline new mannequin\n\n    mannequin = Model(inputs=mannequin.inputs, outputs=output)\n\n    # compile mannequin\n\n    choose = SGD(lr=0.01, momentum=0.9)\n\n    mannequin.compile(optimizer=choose, loss=\"binary_crossentropy\", metrics=[fbeta])\n    \n    return mannequin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n# cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\nsave_best_check_point = ModelCheckpoint(filepath='our_model.hdf5', monitor='val_fbeta', mode='max', save_best_only=True, save_weights_only=True)\n# checkpoint = ModelCheckpoint(filepath='weights/weights.hdf5',monitor='val_fbeta', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n# early = EarlyStopping(monitor='val_fbeta', min_delta=0, patience=20, verbose=1, mode='auto')\n\n# fit model\n# history = full_model.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\nmannequin.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=10,callbacks=[save_best_check_point])\n\n\n# evaluate model\nloss, fbeta = mannequin.evaluate_generator(test_it, steps=len(test_it), verbose=0)\nprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(1, figsize = (8,8)) \n# plt.subplot(211)\n# plt.title('Cross Entropy Loss')\n# plt.plot(history.history['loss'], color='blue', label='train')\n# plt.plot(history.history['val_loss'], color='orange', label='test')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'valid']) \n\n# # plot accuracy\n# plt.subplot(212)\n# plt.title('Fbeta')\n# plt.plot(history.history['fbeta'], color='blue', label='train')\n# plt.plot(history.history['val_fbeta'], color='orange', label='test')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'valid'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = build_model() # building a sequential model for testing\n\n#loading in the weights of the trained model\nmodel2.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = sample_submission_df.copy()\nsample_submission['image_name'] = sample_submission['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1_df = sample_submission.iloc[:40669]['image_name'].reset_index().drop('index', axis=1)\ntest1_df.head()\ntest1_df.shape\n# initializing an image data generator object for the first 40669 images in the sample submission dataframe\ntest_image_gen1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# generating the image data for the first 40669 images in the sample submission dataframe\ntest_gen1 = test_image_gen1.flow_from_dataframe(dataframe=test1_df, directory='../input/planets-dataset/planet/planet/test-jpg/', x_col='image_name', y_col=None, batch_size=128, shuffle=False, class_mode=None, target_size=(64,64))\n\n# setting the step size for the testing set for the first 40669 images in the sample submission dataframe\nstep_test_size1 = int(np.ceil(test_gen1.samples / test_gen1.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen1.reset() # reseting the generator to be sure of avoiding shuffling\npred1 = model2.predict(test_gen1, steps=step_test_size1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file_names1 = test_gen1.filenames # storing the filenames (images names) of the first 40669 images names in \n                                       # the sample submission dataframe as ordered in the prediction as a \n                                       # variable\n\n# converting the predictions of the first 40669 to tag names\npred_tags1 = pd.DataFrame(pred1)\npred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(unique_labels)[x > 0.5]), axis=1)\n\n# converting the predictions of the first 40669 to a dataframe\nresult1 = pd.DataFrame({'image_name': test_file_names1, 'tags': pred_tags1})\nresult1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2_df = sample_submission.iloc[40669:]['image_name'].reset_index().drop('index', axis=1)\ntest2_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_gen2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# generating the image data for the remaining images in the sample submission dataframe\ntest_gen2 = test_image_gen2.flow_from_dataframe(dataframe=test2_df, \\\n            directory='../input/planets-dataset/test-jpg-additional/test-jpg-additional/', x_col='image_name', \\\n            y_col=None, batch_size=128, shuffle=False, class_mode=None, target_size=(64,64))\n\n# setting the step size for the testing set for the remaining images in the sample submission dataframe\nstep_test_size2 = int(np.ceil(test_gen2.samples / test_gen2.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen2.reset() # reseting the generator to be sure of avoiding shuffling\npred2 = model2.predict(test_gen2, steps=step_test_size2, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file_names2 = test_gen2.filenames # storing the filenames (images names) of the remaining images names in \n                                       # the sample submission dataframe as ordered in the prediction as a \n                                       # variable\n\n# converting the predictions of the remaining images to tag names\npred_tags2 = pd.DataFrame(pred2)\npred_tags2 = pred_tags2.apply(lambda x: ' '.join(np.array(unique_labels)[x > 0.5]), axis=1)\n\n# converting the predictions of the remaining to a dataframe\n\nlen(test_file_names2)\nlen(pred_tags2)\nresult2 = pd.DataFrame({'image_name': test_file_names2, 'tags': pred_tags2})\nresult2.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_result = pd.concat([result1, result2]) # concatenate the predictions of the test.jpg and \n                                             # test-additional.jpg into a single dataframe\n\nfinal_result = final_result.reset_index().drop('index', axis=1) # reseting the index of the dataframe so it \n                                                                # matches that of sample submission datafarme\n\nprint(final_result.shape)\nfinal_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert sum(sample_submission['image_name'] == final_result['image_name']) == 61191","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the .jpg extension from 'iamge_name' column\nfinal_result['image_name'] = final_result['image_name'].apply(lambda x: x[:-4])\nfinal_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_result.to_csv('final_submission.csv', index=False) # saving the predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}