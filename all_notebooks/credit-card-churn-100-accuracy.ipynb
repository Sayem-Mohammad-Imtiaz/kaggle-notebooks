{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#File Path\n\nfile_path= '../input/credit-card-customers/BankChurners.csv'\n\ndata = pd.read_csv(file_path, index_col='CLIENTNUM')\n\ndata = data.drop('Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', axis=1)\ndata = data.drop('Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2', axis=1)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n\n# Obtain target and predictors\ny= data['Attrition_Flag']   #target variable\n\n\nX= data # X is same as data\nX = X.drop('Attrition_Flag', axis=1) # remove target column from the data and creates predictors in X\n#X= X.drop('CLIENTNUM', axis=1) #remove CLIENTNUM column from the data\n\n\n#y.head()\n#print(y)\n#print(\"Below is X.head()\")\n#X.head()\n\n# Dividing Data into training data (X_train, y_train) and validation data (X_valid, y_valid)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestClassifier(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dealing with Categorical Data\n\n#Encoding the target variable y\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Make copy to avoid changing original data \nlabel_y_train = y_train.copy()\nlabel_y_valid = y_valid.copy()\n\n# Apply label encoder to y_train and y_valid\n#### label_y_train/valid=1 if 'Existing Customer', else it is 0\nlabel_encoder = LabelEncoder()\nlabel_y_train = label_encoder.fit_transform(y_train) \nlabel_y_valid = label_encoder.transform(y_valid)\n\n#j=0\n#for i in y_train:\n#    if i == \"Existing Customer\":\n#        label_y_train[j]=0\n#        print(label_y_train[j])\n#        j=j+1\n#    else:\n#        label_y_train[j]=1\n#        print(label_y_train[j])\n#        j=j+1\n    \n\n#j=0\n#for i in y_valid:\n#    if j==\"Existing Customer\":\n#        label_y_valid[j]=0\n#        print(label_y_valid[j])\n#        j=j+1\n#    else:\n#        label_y_valid[j]=1\n#        print(label_y_valid[j])\n#        j=j+1\n\n# Get list of categorical variables\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\n#One-Hot encoding\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n\n#y_train.head()\n#print(y_train)\n#print(\"\\nHi\")\n#for i in label_y_train: \n#    print(i)\n#print(\"\\nafter label_y_train\")\n#for i in label_y_valid:\n#    print(i)\n\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dealing with Missing Data\n\nfrom sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(OH_X_valid))\n\n# Imputation removed column names; put them back\nimputed_X_train.columns = OH_X_train.columns\nimputed_X_valid.columns = OH_X_valid.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\n\n# Function for comparing different approaches\nmodel = RandomForestClassifier(n_estimators=100, random_state=0)\nmodel.fit(imputed_X_train, label_y_train)\npreds = model.predict(imputed_X_valid)\nprint(preds)\nprint(label_y_valid)\naccuracy= accuracy_score(label_y_valid, preds)*100\nprint(\"Accuracy is: \", accuracy, \"%\")\n# Save test predictions to file\noutput = pd.DataFrame({'Id': imputed_X_valid.index,\n                       'Attrition prediction': preds,\n                       'actual_y_valid': label_y_valid})\noutput.to_csv('submission.csv', index=False)\nprint(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}