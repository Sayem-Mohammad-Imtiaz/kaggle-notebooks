{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing modules and reading dataset","execution_count":null},{"metadata":{"_uuid":"69f76544-0586-40d3-973b-09dd9b297074","_cell_guid":"d89530e8-46ac-4f5b-9925-e201cd3f57f0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport datetime as dt\nimport seaborn as sns\nimport scipy\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nimport plotly.express as px\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import roc_curve, auc\nfrom textblob import TextBlob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import GridSearchCV\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore') \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9093b184-0c57-474b-9926-8f210b2fb77c","_cell_guid":"0349980f-ae06-4eb4-96c5-80724b233005","trusted":true},"cell_type":"markdown","source":"Read Dataset","execution_count":null},{"metadata":{"_uuid":"fe4cf4aa-c8a5-4fc1-a688-9a30f4253caf","_cell_guid":"f6b42d8d-6c04-4340-b076-92813de7c98e","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv',index_col =[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data[['Review Text','Rating','Class Name','Age']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dd7c79a-c911-4adb-b7c1-a6ceebf2baaf","_cell_guid":"9cfaccac-d2fb-4774-a6d9-8b51e438beba","trusted":true},"cell_type":"code","source":"data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8d32e37-e927-4e50-9ad7-3f2a12fca871","_cell_guid":"38dcc4ec-2ba3-4976-8ebd-537a82e6b31e","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8dfe0f9a-9742-49c5-8462-477b2f4a699b","_cell_guid":"139ba037-ec9c-4c2f-a84b-b0802dc65ac1","trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e30e1c36-dc7b-4b26-bbf2-a38cac01b3dc","_cell_guid":"88355d88-18f3-4e3c-bbc8-6357b6224e33","trusted":true},"cell_type":"markdown","source":"Checking For Missing Values and Handling it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()/len(data)*100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"100bc1e1-33af-4218-89dd-37da6adbde13","_cell_guid":"e0298783-a5f5-4d0d-a5bc-9efbbe9b4477","trusted":true},"cell_type":"markdown","source":"Count rating and recommended IND as recommended IND","execution_count":null},{"metadata":{"_uuid":"d40f1144-da29-4cb9-82f2-4fb7cc2660a4","_cell_guid":"c9900e4c-8062-410d-b2f5-db95195a20c8","trusted":true},"cell_type":"code","source":"data.groupby(['Rating', 'Recommended IND'])['Recommended IND'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The amount of missing values per feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11,4)})\npd.isnull(data).sum().plot(kind='bar')\nplt.ylabel('Number of missing values')\nplt.title('Missing Values per Feature');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The age distribution in data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(data['Age'], color=\"red\", label = \"Age\")\nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Age Distribution in Data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most popular item","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(14, 9))\nplt.xticks(rotation=45)\nplt.xlabel('item ID')\nplt.ylabel('popularity')\nplt.title(\"Top 50 Popular Items\")\ndata['Clothing ID'].value_counts()[:50].plot(kind='bar');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Dropping null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[~data['Review Text'].isnull()]\n\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping Punctuation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def punctuation_removal(messy_str):\n    clean_list = [char for char in messy_str if char not in string.punctuation]\n    clean_str = ''.join(clean_list)\n    return clean_str\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(data, x=\"Age\", y=\"Positive Feedback Count\", facet_row=\"Recommended IND\", facet_col=\"Rating\",trendline=\"ols\",category_orders={\"Rating\": [1,2,3,4,5],'Recommended IND':[0,1]})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word Count and adding new feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvectorizer = CountVectorizer()\n# assign a shorter name for the analyze\n# which tokenizes the string\nanalyzer = vectorizer.build_analyzer()\n\ndef wordcounts(s):\n    c = {}\n    # tokenize the string and continue, if it is not empty\n    if analyzer(s):\n        d = {}\n        # find counts of the vocabularies and transform to array \n        w = vectorizer.fit_transform([s]).toarray()\n        # vocabulary and index (index of w)\n        vc = vectorizer.vocabulary_\n        # items() transforms the dictionary's (word, index) tuple pairs\n        for k,v in vc.items():\n            d[v]=k # d -> index:word \n        for index,i in enumerate(w[0]):\n            c[d[index]] = i # c -> word:count\n    return  c\n\n# add new column to the dataframe\ndata['Word Counts'] = data['Review Text'].apply(wordcounts)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting some words to examine detailed \nselectedwords = ['awesome','great','fantastic','extraordinary','amazing','super',\n                 'magnificent','stunning','impressive','wonderful','breathtaking',\n                 'love','content','pleased','happy','glad','satisfied','lucky',\n                 'shocking','cheerful','wow','sad','unhappy','horrible','regret',\n                 'bad','terrible','annoyed','disappointed','upset','awful','hate']\n\ndef selectedcount(dic,word):\n    if word in dic:\n        return dic[word]\n    else:\n        return 0\n    \ndfwc = data.copy()  \nfor word in selectedwords:\n    dfwc[word] = dfwc['Word Counts'].apply(selectedcount,args=(word,))\n    \nword_sum = dfwc[selectedwords].sum()\nprint('Selected Words')\nprint(word_sum.sort_values(ascending=False).iloc[:5])\n\nprint('\\nClass Names')\nprint(data['Class Name'].fillna(\"Empty\").value_counts().iloc[:5])\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nwc0 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 ).generate_from_frequencies(word_sum)\n\ncn = data['Class Name'].fillna(\" \").value_counts()\nwc1 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 \n                     ).generate_from_frequencies(cn)\n\nax[0].imshow(wc0)\nax[0].set_title('Selected Words\\n',size=25)\nax[0].axis('off')\n\nax[1].imshow(wc1)\nax[1].set_title('Class Names\\n',size=25)\nax[1].axis('off')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Pi chart for polarity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['polarity'] = data['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\nsam = data.loc[data.polarity == 1,['Review Text']].sample(3).values\nnegative = (len(data.loc[data.polarity <0,['Review Text']].values)/len(data))*100\npositive = (len(data.loc[data.polarity >0.5,['Review Text']].values)/len(data))*100\nneutral  = len(data.loc[data.polarity >0 ,['Review Text']].values) - len(data.loc[data.polarity >0.5 ,['Review Text']].values)\nneutral = neutral/len(data)*100\n\nfrom matplotlib import pyplot as plt \nplt.figure(figsize =(10, 7)) \nplt.pie([positive,negative,neutral], labels = ['Positive','Negative','Neutral']) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rating of 4 or higher -> positive, while the ones with \n# Rating of 2 or lower -> negative \n# Rating of 3 -> neutral\ndata = data[data['Rating'] != 3]\ndata['Sentiment'] = data['Rating'] >=4\ndata.head()\n\n# split data\ntrain_data,test_data = train_test_split(data,train_size=0.8,random_state=0)\n# select the columns and \n# prepare data for the models \nX_train = vectorizer.fit_transform(train_data['Review Text'])\ny_train = train_data['Sentiment']\nX_test = vectorizer.transform(test_data['Review Text'])\ny_test = test_data['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start=dt.datetime.now()\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start=dt.datetime.now()\nnb = MultinomialNB()\nnb.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start=dt.datetime.now()\nsvm = SVC()\nsvm.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start=dt.datetime.now()\nnn = MLPClassifier()\nnn.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make graph adding results to data frame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# define a dataframe for the predictions\ndf2 = train_data.copy()\ndf2['Logistic Regression'] = lr.predict(X_train)\ndf2['Naive Bayes'] = nb.predict(X_train)\ndf2['SVM'] = svm.predict(X_train)\ndf2['Neural Network'] = nn.predict(X_train)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Graphs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lr = lr.predict_proba(X_test)[:,1]\nfpr_lr,tpr_lr,_ = roc_curve(y_test,pred_lr)\nroc_auc_lr = auc(fpr_lr,tpr_lr)\n\npred_nb = nb.predict_proba(X_test)[:,1]\nfpr_nb,tpr_nb,_ = roc_curve(y_test.values,pred_nb)\nroc_auc_nb = auc(fpr_nb,tpr_nb)\n\npred_svm = svm.decision_function(X_test)\nfpr_svm,tpr_svm,_ = roc_curve(y_test.values,pred_svm)\nroc_auc_svm = auc(fpr_svm,tpr_svm)\n\npred_nn = nn.predict_proba(X_test)[:,1]\nfpr_nn,tpr_nn,_ = roc_curve(y_test.values,pred_nn)\nroc_auc_nn = auc(fpr_nn,tpr_nn)\n\nf, axes = plt.subplots(2, 2,figsize=(15,10))\naxes[0,0].plot(fpr_lr, tpr_lr, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_lr))\naxes[0,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Logistic Regression')\naxes[0,0].legend(loc='lower right', fontsize=13)\n\naxes[0,1].plot(fpr_nb, tpr_nb, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nb))\naxes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Naive Bayes')\naxes[0,1].legend(loc='lower right', fontsize=13)\n\naxes[1,0].plot(fpr_svm, tpr_svm, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_svm))\naxes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Support Vector Machine')\naxes[1,0].legend(loc='lower right', fontsize=13)\n\naxes[1,1].plot(fpr_nn, tpr_nn, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nn))\naxes[1,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Neural Network')\naxes[1,1].legend(loc='lower right', fontsize=13);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as mt\nprint(\"Logistic Regression\")\nprint(mt.classification_report(y_test, lr.predict(X_test)))\nprint(\"\\n Naive Bayes\")\nprint(mt.classification_report(y_test, nb.predict(X_test)))\nprint(\"\\n Support Vector Machine (SVM)\")\nprint(mt.classification_report(y_test, svm.predict(X_test)))\nprint(\"\\n Neural Network\")\nprint(mt.classification_report(y_test, nn.predict(X_test)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}