{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the necessary libraries\n\nimport warnings\nimport statsmodels.api as sm\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.linear_model import LinearRegression, RANSACRegressor, TheilSenRegressor, Lasso, Ridge, ElasticNet, SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom statsmodels.distributions.empirical_distribution import ECDF\nfrom statsmodels.graphics.tsaplots import plot_acf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/usa-housing/USA_Housing.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rounder = lambda a: [round(x,2) for x in a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Price\"] = rounder(df.Price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"Address\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac = 1).reset_index().drop(\"index\",axis=1) #sampling the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cumulative Distribution Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the cumulative distribution of the data\n\nplt.figure(figsize=(14,10))\nplt.subplot(321)\necdf_1 = ECDF(df[col[0]])\nplt.title(col[0] + \" CDF\")\nplt.plot(ecdf_1.x, ecdf_1.y)\nplt.subplot(322)\necdf_2 = ECDF(df[col[1]])\nplt.title(col[1] + \" CDF\")\nplt.plot(ecdf_2.x, ecdf_2.y)\nplt.subplot(323)\necdf_3 = ECDF(df[col[2]])\nplt.title(col[2] + \" CDF\")\nplt.plot(ecdf_3.x, ecdf_3.y)\nplt.subplot(324)\necdf_4 = ECDF(df[col[3]])\nplt.title(col[3] + \" CDF\")\nplt.plot(ecdf_4.x, ecdf_4.y)\nplt.subplot(325)\necdf_5 = ECDF(df[col[4]])\nplt.title(col[4] + \" CDF\")\nplt.plot(ecdf_5.x, ecdf_5.y)\nplt.subplot(326)\necdf_6 = ECDF(df[col[5]])\nplt.title(col[5] + \" CDF\")\nplt.plot(ecdf_6.x, ecdf_6.y)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outlier Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,2, figsize=(12,8))\naxes_ = [axes_row for axes in ax for axes_row in axes]\n\nfor i, j in enumerate(df.columns):\n    g = sns.boxplot(x = df[j], ax = axes_[i])\n    g.set_title(j)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can some potential outliers present in our data except the Avg. Area Number of Bedrooms. Now we have to decide whether we should ignore this outliers or let it be in our model so before going into any conclusion, we will first investigate these extreme values first to make any conclusion."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(percentiles = [0.001,0.01, 0.1, 0.25, 0.50, 0.75, 0.95, 0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_outliers(data, col):\n    \n    #calculating quantiles\n    q25 = data[col].quantile(q = 0.25)\n    q75 = data[col].quantile(q = 0.75)\n    \n    #calculating inter quantile range\n    iqr = q75-q25\n    \n    #calculating upper_bound and lower_bound\n    lower_bound = q25 - (1.5*iqr)\n    upper_bound = q75 + (1.5*iqr)\n    \n    #filtering out outliers....!!!!!\n    outliers = data[col][(data[col] < lower_bound) | (data[col] > upper_bound)]\n    \n    print(\"**** Printing Outliers Result ****\")\n    \n    print(\"\\nTotal Outliers Present in the Data: %s\"%(len(outliers)))\n    \n    #plotting the line plot result\n    plt.figure(figsize=(10,10))\n    plt.subplot(211)\n    plt.plot(data[col])\n    plt.title(col + \" with Outliers\")\n    plt.scatter(x = outliers.index, y = outliers.values, marker = \"X\", color = 'r', s = 100)\n    \n    #plotting the box plot result\n    plt.subplot(212)\n    plt.title(col + \" After Removing Extreme Values\")\n    filter_data = data[col][~(data[col].isin(outliers))]    \n    sns.boxplot(filter_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_outliers(df, col[5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing the outliers we can see our data become more stables so what we can do instead or removing or imputing we will apply technique called winsorization in which we cap the lower and upper extreme values using quantiles."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats.mstats import winsorize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Winsorization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def apply_winsorize(data, col):\n    winsorize(data[col], limits = [0.005, 0.005], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#performing winsorization using scipy to remove the effect of extreme values\n\nfor i, j in df.items():\n    apply_winsorize(df_copy, i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3,2, figsize=(12,8))\naxes_ = [axes_row for axes in ax for axes_row in axes]\n\nfor i, j in enumerate(df.columns):\n    g = sns.boxplot(x = df_copy[j], ax = axes_[i])\n    g.set_title(j)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_copy.iloc[:, :-1]\ny = df_copy.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(df_copy.corr(), annot = True, fmt = '.2f', cmap = 'viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sklearn Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing Different Regression Algorithms to choose the best one\n\nlr_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"linear_regression\", LinearRegression())])\nrb_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"robust_regression\", RANSACRegressor(random_state = 42))])\nthiel_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"thiel_regressor\", TheilSenRegressor(random_state = 42))])\nridge_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"ridge_regressor\", Ridge(random_state = 42))])\nlasso_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"lasso_regressor\", Lasso(random_state = 42))])\nelastic_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"elastic_net\", ElasticNet(random_state = 42))])\nrandom_forest_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"randomforest_regression\", RandomForestRegressor(random_state = 42))])\nxgboost_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"xgboost_regression\", XGBRegressor())])\nadaboost_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"adaboost_regression\", AdaBoostRegressor(random_state = 42))])\ngradient_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"gradientboost_regression\", GradientBoostingRegressor(random_state = 42))])\nlightgbm_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"lightgbm_regression\", LGBMRegressor(random_state = 42))])\ncatboost_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"catboost_regression\", CatBoostRegressor(random_state = 42, silent = True))])\ndecisiontree_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"decisiontree_regression\", DecisionTreeRegressor(random_state = 42))])\nknn_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"knn_regression\", KNeighborsRegressor())])\nsgc_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"sgd_regression\", SGDRegressor(random_state = 42))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipelines = [lr_pipeline, rb_pipeline, thiel_pipeline, ridge_pipeline, lasso_pipeline,\n            elastic_pipeline, random_forest_pipeline, xgboost_pipeline, adaboost_pipeline, gradient_pipeline, lightgbm_pipeline, catboost_pipeline, decisiontree_pipeline, knn_pipeline, sgc_pipeline]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_dict = {0: \"Linear Regression\", 1: \"Robust\", 2: \"Theil Sen\", 3: \"Ridge\",\n            4: \"Lasso\", 5: \"ElasticNet\", 6: \"RandomForest\", 7: \"XGBoost\",\n             8: \"Adaboost\", 9: \"GradientBoost\", 10: \"LightGBM\", 11: \"CatBoost\", 12: \"Decision Tree\", 13: \"KNN\", 14: \"SGD\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_df = pd.DataFrame(columns = [\"Model\", \"CVScores\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, pipe in enumerate(pipelines):\n    score = cross_val_score(pipe, X, y, cv = 10)\n    print(pipe_dict[i], \": \", score.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the above cross validation, we can see that **Linear Regression**, **Theil Sen Regressor**, **Ridge**, **Lasso**, **Stochastic Gradient Descent** works best among the all. But for our model, we will be going to choose **Linear Regression**, **Ridge** & **Lasso** Regression Models to perform hyperparameter tuning to find the best model among three."},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation - Randomized Search CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_new = Pipeline([(\"scaler\", StandardScaler()), (\"classifier\", LinearRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_params = [\n    {\"classifier\": [LinearRegression()],\n    \"classifier__normalize\": [True, False]},\n    {\"classifier\": [Ridge()],\n     \"classifier__alpha\": np.arange(0.5, 5, 0.25),\n     \"classifier__fit_intercept\": [True, False],\n     \"classifier__normalize\": [True, False],\n     \"classifier__max_iter\": [50, 100, 500, 1000, 2500],\n     \"classifier__tol\": [0.001, 0.01, 0.05, 0.1, 1, 5, 10],\n     \"classifier__solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg,\", \"sag\", \"saga\"]\n    },\n    {\"classifier\": [Lasso()],\n    \"classifier__alpha\": np.arange(0.5, 5, 0.25),\n    \"classifier__fit_intercept\": [True, False],\n    \"classifier__normalize\": [True, False],\n    \"classifier__max_iter\": [50, 100, 500, 1000, 2500],\n    \"classifier__tol\": [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 5, 10],\n    \"classifier__warm_start\": [True, False],\n    \"classifier__positive\": [True, False],\n    \"classifier__selection\": [\"cyclic\", \"random\"]}\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search = RandomizedSearchCV(estimator = pipeline_new, param_distributions = grid_params, scoring = 'neg_mean_absolute_error', n_jobs= -1, cv = 8, verbose = 10, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = random_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_lasso = Pipeline([('scaler', StandardScaler()), ('lasso_reg', Lasso(alpha = 1.25, fit_intercept=True, max_iter=50, normalize=True, tol = 0.0001, warm_start = True, selection = 'cyclic', positive = True))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = pipeline_lasso.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resid = (y_test - predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Diagnosis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_evaluate(true, prediction):\n    mae = mean_absolute_error(true, prediction)\n    mse = mean_squared_error(true, prediction)\n    rmse = np.sqrt(mean_squared_error(true, prediction))\n    r2_square = r2_score(true, prediction)\n\n    print(\"MAE: {}\".format(mae))\n    print(\"MSE: {}\".format(mse))\n    print(\"RMSE: {}\".format(rmse))\n    print(\"R2 Square: {}\".format(r2_square))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_diag(true, prediction):\n    \n    #residuals\n    resid = (true-prediction)\n    \n    #plotting the distplot\n    plt.figure(figsize=(14,8))\n    plt.subplot(221)\n    plt.title(\"Distplot\")\n    sns.distplot(resid)\n    \n    #plotting the residual plot\n    plt.subplot(222)\n    plt.title(\"Residual Plot\")\n    sns.scatterplot(prediction, resid)\n    sns.lineplot([min(prediction), max(prediction)], y = [0,0], linestyle = '--', color = 'r')\n    \n    #plotting the quantile plot\n    ax = plt.subplot(223)\n    plt.title(\"Quantile Plot\")\n    sm.qqplot(resid, line = 'r', ax = ax)\n    \n    #plotting the autocorrelation plot\n    ax2 = plt.subplot(224)\n    plt.title(\"Autocorrelation Plot\")\n    plot_acf(resid, ax = ax2)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_diag(y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_evaluate(y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[\"Predicted Price\"] = predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[\"Original Price\"] = y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[\"Predicted Price\"] = rounder(X_test[\"Predicted Price\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I hope you like this notebook...!!!!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}