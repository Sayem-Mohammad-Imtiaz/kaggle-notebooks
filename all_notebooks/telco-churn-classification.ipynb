{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Init "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#from fastai.structured import *  # Removed from the v1.0 library. Copied the code in the below hidden cell\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# copied from https://github.com/fastai/fastai/blob/master/old/fastai/structured.py\n#from .imports import *\n\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\n\ndef set_plot_sizes(sml, med, big):\n    plt.rc('font', size=sml)          # controls default text sizes\n    plt.rc('axes', titlesize=sml)     # fontsize of the axes title\n    plt.rc('axes', labelsize=med)    # fontsize of the x and y labels\n    plt.rc('xtick', labelsize=sml)    # fontsize of the tick labels\n    plt.rc('ytick', labelsize=sml)    # fontsize of the tick labels\n    plt.rc('legend', fontsize=sml)    # legend fontsize\n    plt.rc('figure', titlesize=big)  # fontsize of the figure title\n\ndef parallel_trees(m, fn, n_jobs=8):\n        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    \"\"\" Draws a representation of a random forest in IPython.\n\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    \"\"\"\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))\n\ndef combine_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n              seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',\n             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\ndef get_sample(df,n):\n    \"\"\" Gets a random sample of n rows from df, without replacement.\n\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    >>> get_sample(df, 2)\n       col1 col2\n    1     2    b\n    2     3    a\n    \"\"\"\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef add_datepart(df, fldname, drop=True, time=False):\n    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n    time: If true time features: Hour, Minute, Second will be added.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, 'A')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    \"\"\"\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n\ndef is_date(x): return np.issubdtype(x.dtype, np.datetime64)\n\ndef train_cats(df):\n    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n    categorical values. This applies the changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category\n    \"\"\"\n    for n,c in df.items():\n        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n\ndef apply_cats(df, trn):\n    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n    a template for the category codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. Any columns of strings will be changed to\n        categorical values. The category codes are determined by trn.\n\n    trn: A pandas dataframe. When creating a category for df, it looks up the\n        what the category's code were in trn and makes those the category codes\n        for df.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category {a : 1, b : 2}\n\n    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n    >>> apply_cats(df2, df)\n\n           col1 col2\n        0     1    b\n        1     2    a\n        2     3    a\n\n    now the type of col is category {a : 1, b : 2}\n    \"\"\"\n    for n,c in df.items():\n        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n\ndef fix_missing(df, col, name, na_dict):\n    \"\"\" Fill missing data in a column of df with the median, and add a {name}_na column\n    which specifies if the data was missing.\n\n    Parameters:\n    -----------\n    df: The data frame that will be changed.\n\n    col: The column of data to fix by filling in missing data.\n\n    name: The name of the new filled column in df.\n\n    na_dict: A dictionary of values to create na's of and the value to insert. If\n        name is not a key of na_dict the median will fill any missing data. Also\n        if name is not a key of na_dict and there is no missing data in col, then\n        no {name}_na column is not created.\n\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df['col1'], 'col1', {})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1     2    2    True\n    2     3    2   False\n\n\n    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df['col2'], 'col2', {})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n\n    >>> df = pd.DataFrame({'col1' : [1, np.NaN, 3], 'col2' : [5, 2, 2]})\n    >>> df\n       col1 col2\n    0     1    5\n    1   nan    2\n    2     3    2\n\n    >>> fix_missing(df, df['col1'], 'col1', {'col1' : 500})\n    >>> df\n       col1 col2 col1_na\n    0     1    5   False\n    1   500    2    True\n    2     3    2   False\n    \"\"\"\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+'_na'] = pd.isnull(col)\n            filler = na_dict[name] if name in na_dict else col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict\n\ndef numericalize(df, col, name, max_n_cat):\n    \"\"\" Changes the column col from a categorical type to it's integer codes.\n\n    Parameters:\n    -----------\n    df: A pandas dataframe. df[name] will be filled with the integer codes from\n        col.\n\n    col: The column you wish to change into the categories.\n    name: The column name you wish to insert into df. This column will hold the\n        integer codes.\n\n    max_n_cat: If col has more categories than max_n_cat it will not change the\n        it to its integer codes. If max_n_cat is None, then col will always be\n        converted.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> numericalize(df, df['col2'], 'col3', None)\n\n       col1 col2 col3\n    0     1    a    1\n    1     2    b    2\n    2     3    a    1\n    \"\"\"\n    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n        df[name] = col.cat.codes+1\n\ndef scale_vars(df, mapper):\n    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper\n\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n\n    y_fld: The name of the response variable\n\n    skip_flds: A list of fields that dropped from df.\n\n    ignore_flds: A list of fields that are ignored during processing.\n\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n\n    preproc_fn: A function that gets applied to df.\n\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n\n    subset: Takes a random subset of size subset from df.\n\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n\n        y: y is the response variable\n\n        nas: returns a dictionary of which nas it created, and the associated median.\n\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    note the type of col2 is string\n\n    >>> train_cats(df)\n    >>> df\n\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n\n    now the type of col2 is category { a : 1, b : 2}\n\n    >>> x, y, nas = proc_df(df, 'col1')\n    >>> x\n\n       col2\n    0     1\n    1     2\n    2     1\n\n    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    \"\"\"\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    else: df = df.copy()\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    else: na_dict = na_dict.copy()\n    na_dict_initial = na_dict.copy()\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if len(na_dict_initial.keys()) > 0:\n        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\ndef set_rf_samples(n):\n    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n    n random rows.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    \"\"\" Undoes the changes produced by set_rf_samples.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n\ndef get_nn_mappers(df, cat_vars, contin_vars):\n    # Replace nulls with 0 for continuous, \"\" for categorical.\n    for v in contin_vars: df[v] = df[v].fillna(df[v].max()+100,)\n    for v in cat_vars: df[v].fillna('#NA#', inplace=True)\n\n    # list of tuples, containing variable and instance of a transformer for that variable\n    # for categoricals, use LabelEncoder to map to integers. For continuous, standardize\n    cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n    contin_maps = [([o], StandardScaler()) for o in contin_vars]\n    return DataFrameMapper(cat_maps).fit(df), DataFrameMapper(contin_maps).fit(df)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_INPUT = \"/kaggle/input/\"\nPATH_WORKING = \"/kaggle/working/\"\nPATH_TMP = \"/tmp/\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Found out that there are ' ' in TotalCharges column, which has to be fixed by skipinitialspace\ndf_raw = pd.read_csv(f'{PATH_INPUT}WA_Fn-UseC_-Telco-Customer-Churn.csv', low_memory=False, skipinitialspace=True)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.dtypes","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"customerID           object\ngender               object\nSeniorCitizen         int64\nPartner              object\nDependents           object\ntenure                int64\nPhoneService         object\nMultipleLines        object\nInternetService      object\nOnlineSecurity       object\nOnlineBackup         object\nDeviceProtection     object\nTechSupport          object\nStreamingTV          object\nStreamingMovies      object\nContract             object\nPaperlessBilling     object\nPaymentMethod        object\nMonthlyCharges      float64\nTotalCharges        float64\nChurn                object\ndtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.describe(include='all')","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"        customerID gender  ...   TotalCharges Churn\ncount         7043   7043  ...    7032.000000  7043\nunique        7043      2  ...            NaN     2\ntop     1374-DMZUI   Male  ...            NaN    No\nfreq             1   3555  ...            NaN  5174\nmean           NaN    NaN  ...    2283.300441   NaN\nstd            NaN    NaN  ...    2266.771362   NaN\nmin            NaN    NaN  ...      18.800000   NaN\n25%            NaN    NaN  ...     401.450000   NaN\n50%            NaN    NaN  ...    1397.475000   NaN\n75%            NaN    NaN  ...    3794.737500   NaN\nmax            NaN    NaN  ...    8684.800000   NaN\n\n[11 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerID</th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>MultipleLines</th>\n      <th>InternetService</th>\n      <th>OnlineSecurity</th>\n      <th>OnlineBackup</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>StreamingTV</th>\n      <th>StreamingMovies</th>\n      <th>Contract</th>\n      <th>PaperlessBilling</th>\n      <th>PaymentMethod</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043.000000</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043.000000</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043</td>\n      <td>7043.000000</td>\n      <td>7032.000000</td>\n      <td>7043</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>7043</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>1374-DMZUI</td>\n      <td>Male</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>3555</td>\n      <td>NaN</td>\n      <td>3641</td>\n      <td>4933</td>\n      <td>NaN</td>\n      <td>6361</td>\n      <td>3390</td>\n      <td>3096</td>\n      <td>3498</td>\n      <td>3088</td>\n      <td>3095</td>\n      <td>3473</td>\n      <td>2810</td>\n      <td>2785</td>\n      <td>3875</td>\n      <td>4171</td>\n      <td>2365</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5174</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.162147</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>32.371149</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>64.761692</td>\n      <td>2283.300441</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.368612</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.559481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30.090047</td>\n      <td>2266.771362</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.250000</td>\n      <td>18.800000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>35.500000</td>\n      <td>401.450000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>70.350000</td>\n      <td>1397.475000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>89.850000</td>\n      <td>3794.737500</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>72.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>118.750000</td>\n      <td>8684.800000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   customerID  gender  SeniorCitizen  ...   MonthlyCharges TotalCharges  Churn\n0  7590-VHVEG  Female              0  ...            29.85        29.85     No\n1  5575-GNVDE    Male              0  ...            56.95      1889.50     No\n2  3668-QPYBK    Male              0  ...            53.85       108.15    Yes\n3  7795-CFOCW    Male              0  ...            42.30      1840.75     No\n4  9237-HQITU  Female              0  ...            70.70       151.65    Yes\n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerID</th>\n      <th>gender</th>\n      <th>SeniorCitizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>tenure</th>\n      <th>PhoneService</th>\n      <th>MultipleLines</th>\n      <th>InternetService</th>\n      <th>OnlineSecurity</th>\n      <th>OnlineBackup</th>\n      <th>DeviceProtection</th>\n      <th>TechSupport</th>\n      <th>StreamingTV</th>\n      <th>StreamingMovies</th>\n      <th>Contract</th>\n      <th>PaperlessBilling</th>\n      <th>PaymentMethod</th>\n      <th>MonthlyCharges</th>\n      <th>TotalCharges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7590-VHVEG</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>1</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5575-GNVDE</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>34</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Mailed check</td>\n      <td>56.95</td>\n      <td>1889.50</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3668-QPYBK</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Mailed check</td>\n      <td>53.85</td>\n      <td>108.15</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7795-CFOCW</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>45</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Bank transfer (automatic)</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9237-HQITU</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>70.70</td>\n      <td>151.65</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check NA\ndf_raw.isnull().sum()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"customerID           0\ngender               0\nSeniorCitizen        0\nPartner              0\nDependents           0\ntenure               0\nPhoneService         0\nMultipleLines        0\nInternetService      0\nOnlineSecurity       0\nOnlineBackup         0\nDeviceProtection     0\nTechSupport          0\nStreamingTV          0\nStreamingMovies      0\nContract             0\nPaperlessBilling     0\nPaymentMethod        0\nMonthlyCharges       0\nTotalCharges        11\nChurn                0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn strings into categories\ntrain_cats(df_raw)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df, y, nas = proc_df(df_raw, 'Churn', skip_flds=['customerID'])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape, y.shape, nas)","execution_count":11,"outputs":[{"output_type":"stream","text":"(7043, 20) (7043,) {'TotalCharges': 1397.475}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_score(m):\n    res = [metrics.f1_score(y_train, m.predict(X_train)), metrics.f1_score(y_valid, m.predict(X_valid))]\n    print(res)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2, stratify=df_raw.Churn)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"((5634, 20), (1409, 20), (5634,), (1409,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestClassifier(n_estimators=100, max_features=0.5, n_jobs=-1, class_weight='balanced')\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":15,"outputs":[{"output_type":"stream","text":"[0.9959973315543695, 0.5427286356821589]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.confusion_matrix(y_valid, m.predict(X_valid)))","execution_count":16,"outputs":[{"output_type":"stream","text":"[[923 112]\n [193 181]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(y_valid, m.predict(X_valid)))","execution_count":17,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86      1035\n           1       0.62      0.48      0.54       374\n\n   micro avg       0.78      0.78      0.78      1409\n   macro avg       0.72      0.69      0.70      1409\nweighted avg       0.77      0.78      0.77      1409\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"fi = rf_feat_importance(m, df)\nfi","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                cols       imp\n17    MonthlyCharges  0.184860\n18      TotalCharges  0.172060\n14          Contract  0.171776\n4             tenure  0.129232\n8     OnlineSecurity  0.055965\n16     PaymentMethod  0.043894\n11       TechSupport  0.040283\n0             gender  0.023946\n15  PaperlessBilling  0.020483\n7    InternetService  0.020455\n9       OnlineBackup  0.019071\n2            Partner  0.018793\n3         Dependents  0.018318\n6      MultipleLines  0.017086\n1      SeniorCitizen  0.016827\n13   StreamingMovies  0.015782\n10  DeviceProtection  0.014899\n12       StreamingTV  0.012373\n5       PhoneService  0.003880\n19   TotalCharges_na  0.000016","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cols</th>\n      <th>imp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17</th>\n      <td>MonthlyCharges</td>\n      <td>0.184860</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>TotalCharges</td>\n      <td>0.172060</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Contract</td>\n      <td>0.171776</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tenure</td>\n      <td>0.129232</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>OnlineSecurity</td>\n      <td>0.055965</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>PaymentMethod</td>\n      <td>0.043894</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>TechSupport</td>\n      <td>0.040283</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>gender</td>\n      <td>0.023946</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>PaperlessBilling</td>\n      <td>0.020483</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>InternetService</td>\n      <td>0.020455</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>OnlineBackup</td>\n      <td>0.019071</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Partner</td>\n      <td>0.018793</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dependents</td>\n      <td>0.018318</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MultipleLines</td>\n      <td>0.017086</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SeniorCitizen</td>\n      <td>0.016827</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>StreamingMovies</td>\n      <td>0.015782</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>DeviceProtection</td>\n      <td>0.014899</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>StreamingTV</td>\n      <td>0.012373</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>PhoneService</td>\n      <td>0.003880</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>TotalCharges_na</td>\n      <td>0.000016</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}