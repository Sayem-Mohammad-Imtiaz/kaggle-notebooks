{"cells":[{"metadata":{"_uuid":"3412e7579b1e6db5c232aeacdda18426a5a820b5"},"cell_type":"markdown","source":"## In this kernel I will try to evaluate some most popular ML classifiers for sentiment classification task.\n\nFirst importing libraries and loading dataset."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/Tweets.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97c398434be29fdbba675e6861235106377afa2c"},"cell_type":"markdown","source":"First of all lets find out if data types are correct."},{"metadata":{"trusted":true,"_uuid":"f45c705b768b63d63adebb37cd727b42843e9399"},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc9049af9a9a566f3848375f93dbecc3e30f73f6"},"cell_type":"markdown","source":"Seems everything is fine. Lets look at NaN values."},{"metadata":{"trusted":true,"_uuid":"625294ebc4dd576a0abf9ddc018aa497720f047f"},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd6384dca9bc18b4b47445a0a2437e8046fec3c0"},"cell_type":"markdown","source":"Not to deal with missing values I will exclude those columns with NaN values and some other fields that I will not use from further analysis."},{"metadata":{"trusted":true,"_uuid":"82cc2042a0a8bdb8b18cd459f030f2b75adc3606"},"cell_type":"code","source":"df = df.drop(['negativereason', \n              'negativereason_confidence', \n              'airline_sentiment_gold', \n              'negativereason_gold', \n              'tweet_coord', \n              'tweet_created', \n              'tweet_location', \n              'user_timezone', \n              'tweet_id',\n              'name',\n              'airline_sentiment_confidence',\n              'retweet_count'], axis=1)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88c845843e25bf429bc3cdaee76fbb5ca5420c17"},"cell_type":"markdown","source":"Now lets look at sentiment type counts."},{"metadata":{"trusted":true,"_uuid":"c8434ef6b58431fc8793c1421fb78b1edf00c595"},"cell_type":"code","source":"df['airline_sentiment'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6037f9879a873ffec564aef1c45e8f6f64be78bd"},"cell_type":"markdown","source":"It seems that dataset is unbalanced with way to much of negative sentiments."},{"metadata":{"_uuid":"8644f225d94c23d5413059e87f1cf4f728a4b2f5"},"cell_type":"markdown","source":"I will convert airline column data to binary categorical and will use TF-IDF for text column. "},{"metadata":{"trusted":true,"_uuid":"250399c33ac03c5cb7c27f23bf6982712c994100"},"cell_type":"code","source":"airline_categorical = pd.get_dummies(df['airline'])\n# df = df.drop(['airline'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"febd7ee143b53d979f1cfaa542490960c4d88806"},"cell_type":"code","source":"df = pd.concat([df, airline_categorical], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0ed684d0d714d3417ed635aee6f315da530c858"},"cell_type":"markdown","source":"Before perform TF-IDF feature extraction from column text, I need to perform some pre-processing like removing stop words and other separators."},{"metadata":{"trusted":true,"_uuid":"c7e945a58dfed2ef8413f46cd5a6b1a61adc8c23"},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\ndf['text'] = df['text'].apply(lambda x: re.sub('[^a-z]', ' ', x.lower()))\ndf['text'] = df['text'].apply(lambda x: re.sub(' +', ' ', x))\ndf['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f9e5f53a5ad226e7889af680152bb5a7a5b329e"},"cell_type":"markdown","source":"Convert sentiment column values to int type."},{"metadata":{"trusted":true,"_uuid":"cd90e23d3f1c996cd002b7bbea7333e53f519e83"},"cell_type":"code","source":"df['target'] = df['airline_sentiment'].apply(lambda x: 0 if x == 'negative' else 1 if x == 'neutral' else 2)\ndf = df.drop(['airline_sentiment'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35ad4a991aff6b42d2b95dc65c8aaec46672bf29"},"cell_type":"markdown","source":"Droping duplicates if exists."},{"metadata":{"trusted":true,"_uuid":"e492aca85d649779c83721e17a109473f6358385"},"cell_type":"code","source":"df = df.drop_duplicates()\ndf = df.reset_index(drop=True)\ndf.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"090d85b328870037c536c0746bfbff2e552f16ee"},"cell_type":"markdown","source":"Performing train/test split."},{"metadata":{"trusted":true,"_uuid":"9382c4ac5cf1c9a9533f58fa55c19abae112e084"},"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.3)\ndf_train = df_train.reset_index(drop=True)\ndf_test = df_test.reset_index(drop=True)\nprint(df_train.shape, df_test.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6629333a981c6607d29865571ff95f13924b2f3"},"cell_type":"markdown","source":"Performing text transformation to features (TF-IDF)."},{"metadata":{"trusted":true,"_uuid":"5da654227f3de61ddb4939f9981df9e5c909064d"},"cell_type":"code","source":"vectorizer = TfidfVectorizer()\ntext_features_train = vectorizer.fit_transform(df_train['text'])\ntext_features_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f20fba1fc3fcc260edd31d907e1095c6407e73d"},"cell_type":"markdown","source":"Adding categorical airline data to generated text features."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"dbfb08e4bd508492971b9f6a69b805fa87a5ed0c"},"cell_type":"code","source":"features_train = np.concatenate([text_features_train.toarray(), df_train[['American', \n                                                                          'Delta', \n                                                                          'Southwest', \n                                                                          'US Airways', \n                                                                          'United', \n                                                                          'Virgin America']].values], axis=1)\nfeatures_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff31d4830672ce616848ac2d021f2f13a3ce5b2e"},"cell_type":"markdown","source":"To reduce dimensionality I will try to use PCA."},{"metadata":{"trusted":true,"_uuid":"8adb3645aee87470d2d89fdb5e9610e90a1eb7a4"},"cell_type":"code","source":"pca = PCA(n_components=2)\nfeatures_train = pca.fit_transform(features_train)\nfeatures_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cda60294673da2c0035ddf9783b213c9fa45adc"},"cell_type":"code","source":"df_features_train = pd.DataFrame(features_train)\ndf_features_train = pd.concat([df_features_train, df_train[['target']]], axis=1, ignore_index=True)\ndf_features_train.columns = ['pca_1', 'pca_2', 'target']\ndf_features_train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a4f9cb302a66a872a9cabd94718cc86ea888ac2"},"cell_type":"markdown","source":"Lets plot scatter plot and look how data are distributed."},{"metadata":{"trusted":true,"_uuid":"dd1fd69917fe7f73656a183e297ed59a1c708745"},"cell_type":"code","source":"cmap = {0: 'red', 1: 'blue', 2: 'green'}\ndf_features_train.plot(kind='scatter', x='pca_1', y='pca_2', c=[cmap.get(t, 'black') for t in df_features_train['target']])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a7435e2c59112bf2b21ceff084248aaf7fb07d3"},"cell_type":"markdown","source":"Lets define classifiers that will be evaluated for this task."},{"metadata":{"trusted":true,"_uuid":"7b0fb4be66852c5e7a62b936db91dfcd1785f60d"},"cell_type":"code","source":"Classifiers = [\n    KNeighborsClassifier(3),\n    KNeighborsClassifier(5),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200),\n    AdaBoostClassifier(),\n    GaussianNB()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c900dea69a1ea44b2933c28b454c6816512222c1"},"cell_type":"markdown","source":"Performing models training and evaluating."},{"metadata":{"trusted":true,"_uuid":"ce10a0ac363f36e88473c83dcc9e6f17c26ef0d2"},"cell_type":"code","source":"text_features_test = vectorizer.transform(df_test['text'])\nfeatures_test = np.concatenate([text_features_test.toarray(), df_test[['American', \n                                                                       'Delta', \n                                                                       'Southwest', \n                                                                       'US Airways', \n                                                                       'United', \n                                                                       'Virgin America']].values], axis=1)\nfeatures_test = pca.transform(features_test)\ndf_features_test = pd.DataFrame(features_test)\ndf_features_test = pd.concat([df_features_test, df_test[['target']]], axis=1, ignore_index=True)\ndf_features_test.columns = ['pca_1', 'pca_2', 'target']\ndf_features_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc0683029c589d4437427bdce395d24416558f3f","scrolled":true},"cell_type":"code","source":"for c in Classifiers:\n    fit = c.fit(df_features_train[['pca_1', 'pca_2']], df_features_train[['target']])\n    pred = fit.predict(df_features_test[['pca_1', 'pca_2']])\n\n    accuracy = accuracy_score(pred, df_features_test[['target']])\n\n    print('Accuracy of ' + c.__class__.__name__ + 'is ' + str(accuracy))  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39b424b3b620d82ce7e1e4c3db97204a6074c92f"},"cell_type":"markdown","source":"Results are not good, lets try using not binary categorical airline features but  int."},{"metadata":{"trusted":true,"_uuid":"4d823be017cf6452f9980824dd10c31e0abeb9cc","scrolled":true},"cell_type":"code","source":"df_train['airline'] = df_train['airline'].apply(lambda x: 1 if x == 'American' else 2 if x == 'Delta' else 3 if x =='Southwest' else 4 if x == 'US Airways' else 5 if x == 'United' else 6 if x == 'Virgin America' else 0)\ndf_test['airline'] = df_test['airline'].apply(lambda x: 1 if x == 'American' else 2 if x == 'Delta' else 3 if x =='Southwest' else 4 if x == 'US Airways' else 5 if x == 'United' else 6 if x == 'Virgin America' else 0)\n\nvectorizer = TfidfVectorizer()\ntext_features_train = vectorizer.fit_transform(df_train['text'])\n\nfeatures_train = np.concatenate([text_features_train.toarray(), df_train[['airline']].values], axis=1)\n\npca = PCA(n_components=2)\nfeatures_train = pca.fit_transform(features_train)\n\ndf_features_train = pd.DataFrame(features_train)\ndf_features_train = pd.concat([df_features_train, df_train[['target']]], axis=1, ignore_index=True)\ndf_features_train.columns = ['pca_1', 'pca_2', 'target']\ndf_features_train.describe(include='all')\n\ntext_features_test = vectorizer.transform(df_test['text'])\nfeatures_test = np.concatenate([text_features_test.toarray(), df_test[[ 'airline']].values], axis=1)\n\nfeatures_test = pca.transform(features_test)\ndf_features_test = pd.DataFrame(features_test)\ndf_features_test = pd.concat([df_features_test, df_test[['target']]], axis=1, ignore_index=True)\ndf_features_test.columns = ['pca_1', 'pca_2', 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db44d880d2f38312d9b385b069259fb2cb720088"},"cell_type":"code","source":"for c in Classifiers:\n    fit = c.fit(df_features_train[['pca_1', 'pca_2']], df_features_train[['target']])\n    pred = fit.predict(df_features_test[['pca_1', 'pca_2']])\n\n    accuracy = accuracy_score(pred, df_features_test[['target']])\n\n    print('Accuracy of ' + c.__class__.__name__ + 'is ' + str(accuracy)) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02e37f607f4b9d9d41440a4bbf6b633e4e6ee0b6"},"cell_type":"markdown","source":"As we can see accuracy is not so high. Need to spend more time on feature enginearing and classifiers hyperparameter tunning in order to increase accuracy."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}