{"cells":[{"metadata":{},"cell_type":"markdown","source":"# SPAM MESSAGE CLASSIFICATION \n![](https://appliedmachinelearning.files.wordpress.com/2017/01/spam-filter.png?w=620)\nClassifiying messages into spam or not spam by natural language processing using deep  learning\nthe below model is able to attain accuracy around 98.6% in classification"},{"metadata":{},"cell_type":"markdown","source":"# load and read the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing libaries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set_style(\"darkgrid\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',encoding='latin1')\nsms = sms.iloc[:,[0,1]]\nsms.columns = [\"label\", \"message\"]\nsms.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n"},{"metadata":{},"cell_type":"markdown","source":"Lets find  the number of spam message and ham messages in the dataset using visualization.747 spam messages are found out of 5572 messages"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_Class=pd.value_counts(sms[\"label\"], sort= True)\ncount_Class.plot(kind = 'bar',color = [\"green\",\"red\"])\nplt.title('Bar Plot')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#747 spam messages  are there\nsms.groupby('label').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets add another coloumn length for storing the length of each message .It will help us to find the lengths of the messages as well as we can compare the length of spam and ham by vizualisation techinques"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets add length coloumn to the data\nsms['length'] = sms['message'].apply(len)\nsms.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = plt.figure(dpi = 120)\nax = plt.axes()\nsms['length'].plot(bins=50, kind='hist',ax=ax,color = 'indigo')\nax.set(xlabel = 'Message Length Class',ylabel = 'Frequency',title = 'Length Distribution');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# comparison of spam and ham messages   \nplt.figure(figsize=(12, 8))\n\nsms[sms.label=='ham'].length.plot(bins=35, kind='hist', color='green', \n                                       label='Ham messages', alpha=0.6)\nsms[sms.label=='spam'].length.plot(kind='hist', color='red', \n                                       label='Spam messages', alpha=0.6)\nplt.legend()\nplt.xlabel(\"Message Length\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets visualize the most commen words used in both spam and ham messages"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\ncount1 = Counter(\" \".join(sms[sms['label']=='ham'][\"message\"]).split()).most_common(20)\ndf1 = pd.DataFrame.from_dict(count1)\ndf1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\ncount2 = Counter(\" \".join(sms[sms['label']=='spam'][\"message\"]).split()).most_common(20)\ndf2 = pd.DataFrame.from_dict(count2)\ndf2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.plot.bar(legend = False,color=\"black\")\ny_pos = np.arange(len(df1[\"words in non-spam\"]))\nplt.xticks(y_pos, df1[\"words in non-spam\"])\nplt.title('More frequent words in non-spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()\n\n\ndf2.plot.bar(legend = False, color = 'blue')\ny_pos = np.arange(len(df2[\"words in spam\"]))\nplt.xticks(y_pos, df2[\"words in spam\"])\nplt.title('More frequent words in spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"randomaly checking a message in the dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#randomaly checking a message\nsms[sms.length == 200].message.iloc[0]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Text preproccessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libaries required\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.layers import Embedding, LSTM, Dropout, Dense\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 400\noov_tok = \"<OOV>\"\nmax_length = 250\nembedding_dim = 16\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replacing the catogorical values in such a way that spam as 1 and ham as 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"encode = ({'ham': 0, 'spam': 1} )\n#new dataset with replaced values\nsms = sms.replace(encode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX = sms['message']\nY = sms['label']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(X)\n# convert to sequence of integers\nX = tokenizer.texts_to_sequences(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)\ny = np.array(Y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nX = pad_sequences(X, maxlen=max_length)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" spliting the data as training and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=7)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 30\nhistory = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test,y_test), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.evaluate(X_test, y_test)\n# extract those\nloss = result[0]\naccuracy = result[1]\n\n\nprint(f\"[+] Accuracy: {accuracy*100:.2f}%\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import sequence\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predictions(txts):\n    txts = tokenizer.texts_to_sequences(txts)\n    txts = sequence.pad_sequences(txts, maxlen=max_length)\n    preds = model.predict(txts)\n    if(preds[0] > 0.5):\n        print(\"SPAM MESSAGE\")\n        \n    else:\n        print('NOT SPAM')\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets check 2 messages one is a spam and the other one is not spam "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spam message\ntxts=[\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005\"]\n\nget_predictions(txts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#not Spam\ntxts = [\"Hi man, I was wondering if we can meet tomorrow.\"]\nget_predictions(txts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Our model is succesfully classifying the messages into 2 classes\n# Thanks for reading my notebook .If you like my work,please upvote it !"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}