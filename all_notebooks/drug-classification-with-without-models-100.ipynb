{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Modules and Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport warnings\n\n#Suppressing all warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/drug-classification/drug200.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reviewing Data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.pie(df,names='Drug', title='Drug Distribution',width=600, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replacing 'DrugY' with 'drugY' to preserve consistency"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Drug'].replace('DrugY', 'drugY', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Models to classify 'Drug'"},{"metadata":{},"cell_type":"markdown","source":"Replacing Categorical Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copying df to avoid manipulating original data\ndf2 = df.copy()\n\ndf2['Sex'].replace({'M', 'F'},{1, 0}, inplace=True)\ndf2['BP'].replace({'HIGH', 'LOW', 'NORMAL'},{1, -1, 0}, inplace=True)\ndf2['Cholesterol'].replace({'HIGH', 'NORMAL'},{1, 0}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting data into test and train sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df2.drop(['Drug'], axis=1)\ny = df2['Drug']\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=10000)\nlr.fit(x_train,y_train)\np1=lr.predict(x_test)\ns1=accuracy_score(y_test,p1)\nprint(\"Linear Regression Success Rate :\", \"{:.2f}%\".format(100*s1))\nplot_confusion_matrix(lr, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Booster Classifier"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc=GradientBoostingClassifier()\ngbc.fit(x_train,y_train)\np2=gbc.predict(x_test)\ns2=accuracy_score(y_test,p2)\nprint(\"Gradient Booster Classifier Success Rate :\", \"{:.2f}%\".format(100*s2))\nplot_confusion_matrix(gbc, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(x_train,y_train)\np3=rfc.predict(x_test)\ns3=accuracy_score(y_test,p3)\nprint(\"Random Forest Classifier Success Rate :\", \"{:.2f}%\".format(100*s3))\nplot_confusion_matrix(rfc, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC()\nsvm.fit(x_train,y_train)\np4=svm.predict(x_test)\ns4=accuracy_score(y_test,p4)\nprint(\"Support Vector Machine Success Rate :\", \"{:.2f}%\".format(100*s4))\nplot_confusion_matrix(svm, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K Nearest Neighbor"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nscorelist=[]\nfor i in range(1,21):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    p5=knn.predict(x_test)\n    s5=accuracy_score(y_test,p5)\n    scorelist.append(round(100*s5, 2))\nprint(\"K Nearest Neighbors Top 5 Success Rates:\")\nprint(sorted(scorelist)[:-6:-1])\nplot_confusion_matrix(knn, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extra Gradient Booster Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom bayes_opt import BayesianOptimization\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\n\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\n\nxgb = XGBClassifier(learning_rate=0.01, n_estimators=1000, objective='binary:logistic')\n\nskf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 0)\n\ngrid = GridSearchCV(estimator=xgb, param_grid=params, n_jobs=4, \n                    cv=skf.split(x_train,y_train), verbose=0 )\n\ngrid.fit(x_train,y_train,early_stopping_rounds=20,eval_set=[(x_test, y_test)])\np2x = grid.best_estimator_.predict(x_test)\ns2x=accuracy_score(y_test,p2x)\nplot_confusion_matrix(grid.best_estimator_, x_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Extra Gradient Booster Classifier Success Rate :\", \"{:.2f}%\".format(100*s2x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The data size is small enough to classify 'Drug' without using models"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df['Drug']\nx = df.drop('Drug', axis=1)\n\npred = []\nfor index, row in x.iterrows():\n    if row['Na_to_K'] > 15:\n        pred.append('drugY')\n    elif row['BP']=='HIGH' and row['Age'] <= 50:\n        pred.append('drugA')\n    elif row['BP']=='HIGH' and row['Age'] >50:\n        pred.append('drugB')\n    elif row['BP']=='LOW' and row['Cholesterol']=='HIGH':\n        pred.append('drugC')\n    else:\n        pred.append('drugX')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(target, pred)*100,'%', sep='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The above logic was derived by pure observation of raw data by filtering it in Excel."},{"metadata":{},"cell_type":"markdown","source":"Hope this notebooks helped someone. Thoughts appreciated."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}