{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv',encoding = \"ISO-8859-1\")\ndf.dropna(axis=0,inplace=True)\n#df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y=df.iloc[:,5]\nY=pd.get_dummies(Y)\n#Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df['OriginalTweet']\nX=np.array(X)\n#X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.text import one_hot\nlem=WordNetLemmatizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfor i,sent in enumerate(X):\n  #print(i)\n  #sent=re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",sent)\n\n  sent=sent.lower()\n  sent=re.sub('https:\\/\\/\\S+','',sent)\n  sent=re.sub('@\\S+','',sent)\n  sent=re.sub('&[a-zA-Z]+;','',sent)\n  sent=re.sub('#\\S+','',sent)\n  sent=re.sub('[^a-zA-Z0-9]',' ',sent)\n  sent=sent.split()\n  wds=''\n  for word in sent:\n    #if word not in stopwords.words('english'):\n      word=lem.lemmatize(word)\n      wds+=' '\n      wds+=word\n  X[i]=wds\n#X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntokenizer=Tokenizer(num_words=100000)\ntokenizer.fit_on_texts(X)\ndic=tokenizer.word_index\n#print(dic)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=tokenizer.texts_to_sequences(X)\n#X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nX_train=pad_sequences(X_train,maxlen=100,padding='pre')\n#X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfl=open('../input/glove6b/glove.6B.300d.txt',encoding='utf-8')\nGlvDic={}\nfor line in fl:\n  lst=line.split()\n  wrd=lst[0]\n  ary=np.array(lst[1:])\n  GlvDic[wrd]=ary\n  #print(GlvDic[wrd])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mat=np.zeros((100000,300))\nfor key,i in dic.items():\n  vec=GlvDic.get(key)\n  if vec is not None:\n    mat[i]=vec\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Bidirectional","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(100000,300,input_length=300))\nmodel.add(Bidirectional(LSTM(500)))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(5,activation='softmax'))\nmodel.layers[0].set_weights([mat])\n#model.layers[0].trainable=False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,Y,validation_split=.2,epochs=20,batch_size=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}