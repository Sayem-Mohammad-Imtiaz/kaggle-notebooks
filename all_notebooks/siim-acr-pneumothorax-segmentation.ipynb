{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydicom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom glob import glob\nimport pydicom\nfrom matplotlib import pyplot as plt\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#reading all dcm files into train and text\ntrain = sorted(glob(\"../input/siim-acr-pneumothorax-segmentation-data/dicom-images-train/*/*/*.dcm\"))\nprint(\"train files: \", len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = pydicom.read_file(train[0]).pixel_array\nplt.imshow(img, cmap='bone')\n\ndata = pydicom.dcmread(train[0])\nprint(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/siim-acr-pneumothorax-segmentation-data/train-rle.csv',index_col='ImageId')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, width, height):\n    mask= np.zeros(width* height)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        mask[current_position:current_position+lengths[index]] = 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fns = train[:5000]\nim_height = 1024\nim_width = 1024\nim_chan = 1\n# Get train images and masks\nX_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.bool)\nprint('Getting train images and masks ... ')\n\nfor n, _id in tqdm_notebook(enumerate(train_fns), total=len(train_fns)):\n    dataset = pydicom.read_file(_id)\n    X_train[n] = np.expand_dims(dataset.pixel_array, axis=2)\n    try:\n        if '-1' in df.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n            Y_train[n] = np.zeros((1024, 1024, 1))\n        else:\n            if type(df.loc[_id.split('/')[-1][:-4],' EncodedPixels']) == str:\n                Y_train[n] = np.expand_dims(rle2mask(df.loc[_id.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n            else:\n                Y_train[n] = np.zeros((1024, 1024, 1))\n                for x in df.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n                    Y_train[n] =  Y_train[n] + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n    except KeyError:\n        print(f\"Key {_id.split('/')[-1][:-4]} without mask, assuming healthy patient.\")\n        Y_train[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_height = 128\nim_width = 128\nX_train = X_train.reshape((-1, im_height, im_width, 1))\nY_train = Y_train.reshape((-1, im_height, im_width, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((128,128,1))\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\ndrop4 = Dropout(0.5)(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)                                    \ndrop5 = Dropout(0.5)(conv5)\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\nmerge6 = concatenate([drop4,up6], axis = 3)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\nmerge7 = concatenate([conv3,up7], axis = 3)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\nmerge8 = concatenate([conv2,up8], axis = 3)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\nmerge9 = concatenate([conv1,up9], axis = 3)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\nconv10 = Conv2D(1, (1,1), padding='same')(conv9)\noutput_layer = Activation('sigmoid')(conv10)\n     \nmodel = Model(input = inputs, output = output_layer)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, Y_train, validation_split=.2, batch_size=128, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"i try to make my own genertor but when run the fit cell the note book restart "},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import Sequence\nfrom skimage.transform import resize\nclass generator(Sequence):\n    \n    def __init__(self,filenames,dataframe,batch_size=32, image_size=256, shuffle=True):\n        self.filenames = filenames\n        self.dataframe=df\n        self.batch_size = batch_size\n        self.image_size = image_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        \n    def __load__(self, filename):\n        # load dicom file as numpy array\n        img = pydicom.dcmread(filename).pixel_array\n        img = np.expand_dims(img, 2)\n        try:\n            if '-1' in df.loc[filename.split('/')[-1][:-4],' EncodedPixels']:\n                y = np.zeros((1024, 1024, 1))\n            else:\n                if type(df.loc[filename.split('/')[-1][:-4],' EncodedPixels']) == str:\n                    y = np.expand_dims(rle2mask(df.loc[filename.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n                else:\n                    y = np.zeros((1024, 1024, 1))\n                    for x in df.loc[filename.split('/')[-1][:-4],' EncodedPixels']:\n                        y =  y + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n        except KeyError:\n            y = np.zeros((1024, 1024, 1))  \n        return img, y\n        \n    def __getitem__(self, index):\n        # select batch\n        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n        items = [self.__load__(filename) for filename in filenames]\n        imgs, y = zip(*items)\n        imgs = np.array(imgs)\n        imgs=imgs.reshape(-1,256, 256,1)  \n        y = np.array(y)\n        y= y.reshape(-1,256, 256,1)  \n        return imgs, y\n         \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.filenames)\n        \n    def __len__(self):\n        return int(len(self.filenames) / self.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata= train[2000:]\ntestdata= train[:2000]\nprint(len(traindata))\nprint(len(testdata))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = generator(traindata,\n                      df, batch_size=32,\n                      image_size=256, shuffle=True)\nvalid_gen = generator(testdata, \n                      df, batch_size=32, \n                      image_size=256, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((256,256,1))\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\ndrop4 = Dropout(0.5)(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)                                    \ndrop5 = Dropout(0.5)(conv5)\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\nmerge6 = concatenate([drop4,up6], axis = 3)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\nmerge7 = concatenate([conv3,up7], axis = 3)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\nmerge8 = concatenate([conv2,up8], axis = 3)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\nmerge9 = concatenate([conv1,up9], axis = 3)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\nconv10 = Conv2D(1, (1,1), padding='same')(conv9)\noutput_layer = Activation('sigmoid')(conv10)\n     \nmodel = Model(input = inputs, output = output_layer)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_loss', verbose=1,\n    save_best_only=True, mode='auto', period=1)\nmodel.fit_generator(train_gen,validation_data=valid_gen,epochs=10,callbacks=[checkpoint])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}