{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"hr_data = pd.read_csv('../input/human-resource/HR_comma_sep.csv')\nhr_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we should probably rename this to something more intuitive like 'department'\nhr_data['sales'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr_data['department'] = hr_data['sales']\nhr_data.drop('sales', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot an understanding of the categorical features\n\nsns.set_style('darkgrid')\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,7))\nfig.tight_layout()\nsns.countplot(x='salary', hue='left', data=hr_data, ax=ax1, palette='bright')\nax1.set_xticklabels(ax1.get_xticklabels(), fontsize=12);\nsns.countplot(x='department', hue='left', data=hr_data, ax=ax2, palette='bright')\nax2.set_xticklabels(ax2.get_xticklabels(), fontsize=12, rotation=45);\nax2.set_ylabel(' ');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hr_num_data = hr_data[['satisfaction_level', 'last_evaluation', 'number_project',\n                       'average_montly_hours', 'time_spend_company', 'Work_accident',\n                       'left', 'promotion_last_5years']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's get an understanding of the numerical features for employees who left the company\n\nleft_nums = hr_num_data[hr_num_data.left==1]\n\nleft_nums.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# source: https://stackoverflow.com/questions/29432629/plot-correlation-matrix-using-pandas\n\ndef CorrelationMatrix(df):\n    f = plt.figure(figsize=(8, 10))\n    plt.matshow(df.corr(), fignum=f.number)\n    plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=90)\n    plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n    cb = plt.colorbar()\n    cb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CorrelationMatrix(hr_num_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_recall_fscore_support, precision_recall_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_categorical = hr_data[['department', 'salary']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode values\nX_categorical = pd.concat([pd.get_dummies(X_categorical['department']), \n                           pd.get_dummies(X_categorical['salary'])], axis=1)\nX_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale values\ny = hr_num_data['left']\n\nhr_data_to_scale = hr_num_data.drop(['left', 'Work_accident'], axis=1)\n\nscaler = StandardScaler()\n\nX_numerical = pd.DataFrame(scaler.fit_transform(hr_data_to_scale), columns=hr_data_to_scale.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Work_accident is binary and needn't be scaled\n\nX = pd.concat([X_categorical, X_numerical, hr_num_data['Work_accident']], axis=1)\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1867)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Baseline models\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, y_train)\n\nlr_preds = logreg.predict(X_test)\n\nlr_results = pd.DataFrame(precision_recall_fscore_support(y_test, lr_preds)).T\nlr_results.rename(index={0:'LR_0', 1:'LR_1'},\n                  columns={0:'Precision', 1:'Recall', \n                                 2:'F-Score', 3:'Support'}, inplace=True)\n\n\nrandfor = RandomForestClassifier()\n\nrandfor.fit(X_train, y_train)\n\nrf_preds = randfor.predict(X_test)\n\nrf_results = pd.DataFrame(precision_recall_fscore_support(y_test, rf_preds)).T\nrf_results.rename(index={0:'RF_0', 1:'RF_1'},\n                  columns={0:'Precision', 1:'Recall', \n                                 2:'F-Score', 3:'Support'}, inplace=True)\nbaseline_results = pd.concat([lr_results, rf_results], axis=0)\nbaseline_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_prec, l_rec, _ = precision_recall_curve(y_test, lr_preds)\nr_prec, r_rec, _ = precision_recall_curve(y_test, rf_preds)\n\nplt.figure(figsize=(10, 5))\nplt.plot(l_prec, l_rec, label='LogisticRegression')\nplt.plot(r_prec, r_rec, label='RandomForest')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\n\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Findings\n\nRandom Forest outperformed the LogisticRegression model significantly, and it carries the advantage of providing feature_importances from the prediction. If we plot these, we can see that **employee satisfaction level, number of projects, time spent with the company, average monthly hours, and the performance at the last evaluation** all influenced whether the model would predict an employee as staying, or leaving the company.\n\nDepartments, and various salary levels were not considered as heavily in the prediction process.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_names = X.columns\nimportances = randfor.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure(figsize=(10,5))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [feat_names[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}