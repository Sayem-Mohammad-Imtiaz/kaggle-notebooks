{"cells":[{"metadata":{"_uuid":"35b8a558-d36f-4c20-9528-31f8bf3a095b","_cell_guid":"392e096d-c2db-4697-b76f-81d1abbb3332","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fccdbcbd-66e9-4c49-bfb6-84bab6099b24","_cell_guid":"ddbee0c7-6962-4802-b6dc-727e2487591f","trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/reddit-selfposts/subreddit_info.csv', delimiter=',',usecols=['subreddit','category_1', 'category_2']).set_index(\"subreddit\")\ndf1.dataframeName = 'subreddit_info.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0721f93b-2ed6-4bf2-960f-24482ee911d8","_cell_guid":"7e3f51ae-059b-478d-8625-2d3990b24f88","trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5735b751-a763-4786-bc89-703efbf65ae5","_cell_guid":"53874a15-7332-452d-82f8-0eb88f4abf8a","trusted":true},"cell_type":"code","source":"df2 = pd.read_csv('../input/reddit-selfposts/rspct.tsv', delimiter='\\t').set_index(\"subreddit\")\ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ad51a69-0a4a-4e4a-81a4-525d27f13d9e","_cell_guid":"7711e0d8-db2e-4250-9fe7-c0f0479bd64e","trusted":true},"cell_type":"code","source":"df2 = df2.join(df1).drop([\"id\"],axis=1)\ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4c6f80b-43d8-499e-a664-5fe859f12a4e","_cell_guid":"9b36f7c7-599b-494a-82fa-d520ad1d5226","trusted":true},"cell_type":"code","source":"print(df2.category_1.value_counts())\ncategories_of_interest=['health', 'profession', 'software', 'electronics', 'music', 'sports', 'sex/relationships'\n                        , 'hobby', 'geo', 'crypto', 'company/website', 'other', 'anime/manga', 'drugs', 'writing/stories'\n                        , 'arts', 'programming', 'autos', 'advice/question', 'education', 'animals', 'social_group'\n                        , 'politics/viewpoint', 'food/drink', 'card_game', 'stem', 'hardware/tools', 'religion/supernatural'\n                        , 'parenting', 'books',]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3502a03b-6e34-4f4c-b48d-3f32411cfb06","_cell_guid":"dc146317-80c7-4fce-996d-b88a885ce685","trusted":true},"cell_type":"code","source":"subset_df=df2.loc[df2.category_1.isin(categories_of_interest), ['category_1','category_2','title','selftext']]\nsubset_df.columns = ['category_1','category_2','title','text']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04b517bf-b933-402e-875d-631a57ae2b1b","_cell_guid":"45c251b4-8e78-4560-b56a-602a27796ae2","trusted":true},"cell_type":"code","source":"subset_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac952576-2266-4e1b-9c2b-8e5eb2e78f9d","_cell_guid":"977ba8cd-74f0-462f-84fc-f0684d2faaab","trusted":true},"cell_type":"code","source":"\ndata_columns = ['title','text',]\nY_columns = ['category_1','category_2',]\n\nfrom bs4 import BeautifulSoup\nimport regex\n\ndef preprocess_dataframe(input_df,data_columns,Y_columns):\n\n    df = input_df.loc[:,Y_columns]\n\n    df['text'] = input_df[data_columns].apply(lambda x: ' '.join(x.map(str)), axis=1)\n    df['text'] = df['text'].apply( lambda x: BeautifulSoup(str(x),'html.parser').get_text())\n\n    pattern = regex.compile('[\\W\\d_]+', regex.UNICODE)\n    df['text'] = df['text'].apply( lambda x: pattern.sub(' ',str(x)))\n    return df\n\ndf = preprocess_dataframe(subset_df,data_columns,Y_columns)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c44de871-c36d-47e7-aeb8-edbe02bbe9d0","_cell_guid":"1c11c9db-a696-4114-8e17-c37f8b771482","trusted":true},"cell_type":"code","source":"df_train = df.iloc[:600000,:]\ndf_valid = df.iloc[600000:,:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d82be2ba-d682-47d2-97c0-53780a391511","_cell_guid":"b0c529e9-c6ae-4ba8-8757-16d823f50a6f","trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bbda180-dcd0-4c5f-8ec1-d884e0cf43b1","_cell_guid":"c9302164-1559-412e-a0c3-6fbbd3026808","trusted":true},"cell_type":"code","source":"df_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we need the class labels encoded into integers for functions in the pipeline\nfrom sklearn.preprocessing import OrdinalEncoder\noe = OrdinalEncoder()\n\n# fit on both, because otherwise we cannot do validation. The actual encoding doesn't play a role in learning.\noe.fit( pd.concat([df_train[Y_columns], df_valid[Y_columns]]).values.reshape(-1, 2)) \nY_train = oe.transform(df_train[Y_columns].values.reshape(-1, 2))\nY_valid = oe.transform(df_valid[Y_columns].values.reshape(-1, 2))\nprint('Y training shape', Y_train.shape, Y_train.dtype)\nprint('Y validation shape', Y_valid.shape, Y_valid.dtype)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaec1425-c32e-4f78-b535-2104af64e1ae","_cell_guid":"94ea003f-f773-4fce-ae9e-d625901e7e16","trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nlanguage_stop_words = stopwords.words('english')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df=2) #ngram_range=(1,2)\n\nimport numpy as np\n\n#https://stackoverflow.com/a/55742601/4634344\nvectorizer.fit(df_train['text'].apply(lambda x: np.str_(x)))\nX_train = vectorizer.transform(df_train['text'].apply(lambda x: np.str_(x)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8e2ed90-6ff2-41f1-b7b8-323c70a3542b","_cell_guid":"3b08751a-3653-4e79-af2c-7d9ec3a5bc68","trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c03d114b-5b1e-4801-9f45-bb1f39d1d38c","_cell_guid":"b17f8492-ae63-4f43-9461-4150e803ea2a","trusted":true},"cell_type":"code","source":"X_valid = vectorizer.transform(df_valid['text'].apply(lambda x: np.str_(x)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f589a395-887b-43d2-aeff-e0f4bf1d10de","_cell_guid":"cd20e05c-6f96-4462-bb26-2611b84a246b","trusted":true},"cell_type":"code","source":"X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03f47c67-c337-4a0f-9074-1692eb77be74","_cell_guid":"afc58c54-5980-4628-bf67-9c60c1892ba7","trusted":true},"cell_type":"code","source":"print('X training shape', X_train.shape, X_train.dtype)\nprint('X validation shape', X_valid.shape, X_valid.dtype)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fda9c156-1d29-4a28-9f35-9e4a3438eef9","_cell_guid":"3b3b5068-7c6f-4344-b8f8-53d64e1b761f","trusted":true},"cell_type":"code","source":"from sklearn.multioutput import ClassifierChain\nfrom sklearn.linear_model import SGDClassifier\n\nclf=ClassifierChain(SGDClassifier(random_state=0, class_weight='balanced', n_jobs=-1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76a852bd-2c8a-48f3-bf7f-75e2bf65865e","_cell_guid":"72667918-48fd-424b-8949-b57e01f1f0f0","trusted":true},"cell_type":"code","source":"from sklearn.metrics import jaccard_score, f1_score, make_scorer\n\ndef concat_categories(Y):\n  return np.apply_along_axis(lambda a: str(a[0]) + '-' + str(a[1]), 1, Y)\n\n# score for predicting category_1\ndef js_0(y,y_pred, **kwargs):\n  return jaccard_score(y[:,0], y_pred[:,0], average='micro')\n# score for predicting category_2\ndef js_1(y,y_pred, **kwargs):\n  return jaccard_score(y[:,1], y_pred[:,1], average='micro')\ndef f1_0(y,y_pred, **kwargs):\n  return f1_score(y[:,0], y_pred[:,0], average='micro')\ndef f1_1(y,y_pred, **kwargs):\n  return f1_score(y[:,1], y_pred[:,1], average='micro')\n# score for predicting 'category_1-category_2' (concatenated strings)\ndef js_01(y,y_pred, **kwargs):\n  return jaccard_score(concat_categories(y), concat_categories(y_pred), average='micro')\ndef f1_01(y,y_pred, **kwargs):\n  return f1_score(concat_categories(y), concat_categories(y_pred), average='micro')\n\njs_0_scorer = make_scorer(score_func=js_0, greater_is_better=True, needs_proba=False, needs_threshold=False)\njs_1_scorer = make_scorer(score_func=js_1, greater_is_better=True, needs_proba=False, needs_threshold=False)\njs_01_scorer = make_scorer(score_func=js_01, greater_is_better=True, needs_proba=False, needs_threshold=False)\nf1_0_scorer = make_scorer(score_func=f1_0, greater_is_better=True, needs_proba=False, needs_threshold=False)\nf1_1_scorer = make_scorer(score_func=f1_1, greater_is_better=True, needs_proba=False, needs_threshold=False)\nf1_01_scorer = make_scorer(score_func=f1_01, greater_is_better=True, needs_proba=False, needs_threshold=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"629c114b-94e2-41eb-8981-320a33449d73","_cell_guid":"c65b847f-5270-4040-aaa1-69b495f31743","trusted":true},"cell_type":"code","source":"clf.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5cfcd9b-a977-4312-ad5b-8721962ca304","_cell_guid":"cd38bbfb-484e-40d4-b1fe-687f35f91f76","trusted":true},"cell_type":"code","source":"Y_pred = clf.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f81372ec-f62a-444e-b60d-93e89757f8ba","_cell_guid":"bd9c9786-bab4-44ed-92dd-c2e3d85cf3ef","trusted":true},"cell_type":"code","source":"print('For both Level 1 and Level 2  concatenated:\\n\\tF1 micro (=accuracy): {}'.format(f1_01(Y_valid,Y_pred).round(3)))\nprint('Just the Level 1:\\n\\tF1 micro (=accuracy): {}'.format(f1_0(Y_valid,Y_pred).round(3)))\nprint('Just the Level 2:\\n\\tF1 micro (=accuracy): {}'.format(f1_1(Y_valid,Y_pred).round(3)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}