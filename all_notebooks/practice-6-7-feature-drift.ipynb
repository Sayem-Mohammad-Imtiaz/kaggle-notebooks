{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/applied-ml-microcourse-telco-churn'\ndata = pd.read_csv('{}/usage_drift.csv'.format(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_distributions(t):\n    plt.figure()\n    plt.hist(data['MeanMonthlyUsage_t{}'.format(t)], bins=20, alpha=0.5)\n    plt.hist(data['MeanMonthlyUsage'], bins=20, alpha=0.5)\n    plt.title('Usage Histogram: Original vs t{}'.format(t))\n    plt.xlim([0, 20000])\n\n\nfor t in [1, 2, 3, 4]:\n    plot_distributions(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function taken from this github link:\n# https://github.com/mwburke/population-stability-index/blob/master/psi.py\n\ndef calculate_psi(expected, actual, buckettype='bins', buckets=10, axis=0):\n    '''Calculate the PSI (population stability index) across all variables\n    Args:\n       expected: numpy matrix of original values\n       actual: numpy matrix of new values, same size as expected\n       buckettype: type of strategy for creating buckets, bins splits into even splits, quantiles splits into quantile buckets\n       buckets: number of quantiles to use in bucketing variables\n       axis: axis by which variables are defined, 0 for vertical, 1 for horizontal\n    Returns:\n       psi_values: ndarray of psi values for each variable\n    Author:\n       Matthew Burke\n       github.com/mwburke\n       worksofchart.com\n    '''\n\n    def psi(expected_array, actual_array, buckets):\n        '''Calculate the PSI for a single variable\n        Args:\n           expected_array: numpy array of original values\n           actual_array: numpy array of new values, same size as expected\n           buckets: number of percentile ranges to bucket the values into\n        Returns:\n           psi_value: calculated PSI value\n        '''\n\n        def scale_range (input, min, max):\n            input += -(np.min(input))\n            input /= np.max(input) / (max - min)\n            input += min\n            return input\n\n\n        breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n\n        if buckettype == 'bins':\n            breakpoints = scale_range(breakpoints, np.min(expected_array), np.max(expected_array))\n        elif buckettype == 'quantiles':\n            breakpoints = np.stack([np.percentile(expected_array, b) for b in breakpoints])\n            \n\n        expected_percents = np.histogram(expected_array, breakpoints)[0] / len(expected_array)\n        actual_percents = np.histogram(actual_array, breakpoints)[0] / len(actual_array)\n\n        def sub_psi(e_perc, a_perc):\n            '''Calculate the actual PSI value from comparing the values.\n               Update the actual value to a very small number if equal to zero\n            '''\n            if a_perc == 0:\n                a_perc = 0.0001\n            if e_perc == 0:\n                e_perc = 0.0001\n\n            value = (e_perc - a_perc) * np.log(e_perc / a_perc)\n            return(value)\n\n        psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n\n        return(psi_value)\n\n    if len(expected.shape) == 1:\n        psi_values = np.empty(len(expected.shape))\n    else:\n        psi_values = np.empty(expected.shape[axis])\n\n    for i in range(0, len(psi_values)):\n        if len(psi_values) == 1:\n            psi_values = psi(expected, actual, buckets)\n        elif axis == 0:\n            psi_values[i] = psi(expected[:,i], actual[:,i], buckets)\n        elif axis == 1:\n            psi_values[i] = psi(expected[i,:], actual[i,:], buckets)\n\n    return(psi_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for t in [1, 2, 3, 4]:\n    psi = calculate_psi(data['MeanMonthlyUsage'], data['MeanMonthlyUsage_t{}'.format(t)], buckettype='quantiles', buckets=20)\n    print('PSI for sample {} is {}'.format(\n        t,\n        round(psi, 4)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}