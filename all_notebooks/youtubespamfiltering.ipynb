{"cells":[{"metadata":{"_uuid":"8edd2af85a328ab13a4ac6910d9995bbedc94238"},"cell_type":"markdown","source":" **Youtube Video Comments -  Spam Filtering **"},{"metadata":{"_uuid":"fd2fcae5d70f5398a7d59e772b817dda16aa56f0"},"cell_type":"markdown","source":"In this kernel we will use various machine learning models to see which performs the best for the comments on each of the videos. I have implemented the solution based on the research paper [TubeSpam: Comment Spam Filtering on YouTube](http://www.dt.fee.unicamp.br/~tiago//papers/TCA_ICMLA15.pdf) where each file was considered as a single dataset and the performance of classifiers on each was optimized and compared. "},{"metadata":{"_uuid":"345a1bed2ece9c821cf4d891972a02a2e5af8204"},"cell_type":"markdown","source":"I have used the following models for comparison:\n1.  Logistic Regression Classifier\n1.  Naive - Bayes Classifier\n1.  Suppot Vector Classifer\n1.  K Neighbors Classifier\n1.  Decision Tree Classifier\n1.  Random Forest Classifier\n1.  XGBoost Classifier"},{"metadata":{"_uuid":"c7246d62f03930b7306586123d3eb2aba5c3fef1"},"cell_type":"markdown","source":"**Steps:**\nThe steps involved are divided into two parts: 1) Data pre-processing using NLP techniques 2) Applying Machine Learning on the processed data\n\n**Data Pre-processing/NLP\n\n1) Reading the CSV file and Converting into TSV \n    - To accomodate dataset with comma within comments\n    - TSV is better document type for this problem as its tab separated \n2) Cleaning the data\n    - Remove all charaters except alphabets a-z & A-Z\n    - Convert everything to lower keys\n    - Split each comment row into list of words\n    - Apply Stemming - From Wiki (https://en.wikipedia.org/wiki/Stemming), stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root formâ€”generally a written word form. The stem need not be identical to the morphological root of the word; it is usually sufficient that related words map to the same stem, even if this stem is not in itself a valid root. \n    - Joining all the words back to a list of words called Corpus. Corpus is a large collection of texts. It is a body of written or spoken material upon which a linguistic analysis is based. Read more about Corpus [here](http://language.worldofcomputing.net/linguistics/introduction/what-is-corpus.html)\n3) Creating the Bag of Words model\n    - The bag-of-words model is a way of representing text data when modeling text with machine learning algorithms. \n    - It is used for feature extraction in natural language processing\n    - What we get is a sparse matrix with each unique words in the Corpus as column headers and frequency of each of those words in corresponding rows(comments) of dataset as cell values\n4) Splitting the dataset (bag of words model) into train and test set\n5) Optimization:  Finding the best configurations for all Classifier models, for each dataset using GridSearchCV\n6) Fitting each classifier to our dataset and predicting the test result\n7) Evaluation: Comparing the selected metrics across all classifiers to find the best classifier for each dataset"},{"metadata":{"_uuid":"36e490f2b6785ddb423d5b230c532c3aa625e778"},"cell_type":"markdown","source":"**Evaluation Metrics**\n\nFor evaluating Youtube Comment Spam Filtering model, Accuracy, Spam Catch Rate, Blocked Ham Rate and Matthews Coefficient have been used, to compare between classifier models. A Blocked ham(non-spam email) is more expensive than a non-caught spam (spam email), hence a balance between spam caught rate and blocked ham is required to better evaluate the model. \nFormulas for the metrics are as follows:\n1. Accuracy : (TP+TN)/(TP+TN+FP+FN)\n1. Spam Caught Rate: TP/ (TP+FP)\n1. Blocked Ham Rate: TN / (TN + FN)\n1. Matthews Coefficient: : A coefficient of +1 represents a perfect prediction, 0 an average random prediction and -1 an inverse prediction.\n\nWe will also plot the ROC curve to better understand the choice of classifier. AUC-ROC curve tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s."},{"metadata":{"_uuid":"4c3b9faa2d9a849c9354582fb2b577570d664bee"},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"bdf83bd5d5bab799b4ffa6b5a472cbfd64cd0caa","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sys,csv,os\nimport seaborn as sns\n#NLP libraries\nimport re\nimport nltk #importing the tools (list of irrelevant words) which has to be removed\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\n# Text Processing\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# Data Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Metrics\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict, cross_validate, RandomizedSearchCV, learning_curve\nfrom sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report, make_scorer, fbeta_score, matthews_corrcoef\n\n# Visualization\nfrom matplotlib.pyplot import cm\nfrom funcsigs import signature\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bfd72a311f2cdffc988135459b1f109f7bd1a42"},"cell_type":"markdown","source":"#### Initializing list of Classifier dictionaries"},{"metadata":{"_uuid":"45819007d8b8e0a32a929fb8a105bcc6e84b2fb0","trusted":true},"cell_type":"code","source":"# Classifier Details\nclassifiers = [\n{\n    'label': 'Logistic Regression Classifier',\n    'model': LogisticRegression(),\n    'parameters': {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 0.5, 1, 10]},\n    'g_cv' : 10\n    \n},\n{\n    'label': 'Naive- Bayes Classifier',\n    'model': GaussianNB(),\n    'parameters': {},\n    'g_cv' : 10\n    \n},\n{\n    'label': 'Support Vector Classifier',\n    'model': SVC(),\n    'parameters': {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n    'g_cv' : 10\n},\n{\n    'label': 'K-Nearest Neighbor',\n    'model': KNeighborsClassifier(),\n    'parameters':{\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n    'g_cv' : 10\n},\n{\n    'label': 'Decision Tree Classifier',\n    'model': DecisionTreeClassifier(),\n    'parameters': {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))},\n    'g_cv' : 10\n    \n},\n{\n    'label': 'Random Forest Classifier',\n    'model': RandomForestClassifier(),\n    'parameters': { 'n_estimators': [10,100,300,500],\n                   \"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))},\n    'g_cv' : 5    \n },\n\n{\n    'label': 'XGBoost Classifier',\n    'model': XGBClassifier(),\n    'parameters': { 'learning_rate': [0.01], 'n_estimators':[100,500],\n                   'gamma': [0.5, 1, 1.5], 'subsample': [0.6, 0.8, 1.0], \n                   'colsample_bytree': [0.6, 0.8, 1.0], 'max_depth': [2]},\n    'g_cv' : 2\n    \n}\n]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64d6770b1d1219e31d258755074a2a71be4fb9e1"},"cell_type":"markdown","source":"Function to convert CSV to TSV"},{"metadata":{"_uuid":"9f991e8c4f2d48a4da5ec801efc3dadfdb70585c","trusted":true},"cell_type":"code","source":"#Converting csv to tsv\ndef convert_to_tsv(csv_file, tsv_file):\n    \"\"\"\n    Converts a comma-separated file to tab_separated file\n    \n    Args:    \n        csv_file: path to csv_file\n        tsv_file: path to new tsv_file\n\n    Returns:    \n        tsv_file: path to new tsv_file\n    \n    \"\"\"           \n    csv.writer(open(tsv_file, \n                    'w+',\n                    encoding=\"utf-8\"),\n    delimiter='\\t').writerows(csv.reader(open(csv_file,\n                              encoding=\"utf8\")))\n    return tsv_file","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81bdd7db8c5d68728ec82d693cb324ee14d645b6"},"cell_type":"markdown","source":"Function to clean the input file and create corpus"},{"metadata":{"_uuid":"09a7d4e0f63344d2182874842be878c790c2821f","trusted":true},"cell_type":"code","source":"def create_corpus(dataset):\n    \"\"\"Creates corpus from the input dataset\n    \n    Args:\n        Dataset: Input data as pandas Dataframe\n        \n    Returns:\n        corpus: List of preprocessed input data\n        \n    \"\"\"\n    corpus = [] \n    for i in range(0,len(dataset)):\n        #remove all characters except a-z, removed charac will be replaced by space\n        comment = re.sub(pattern = '[^a-zA-Z]',repl = ' ' , string = dataset['CONTENT'][i]) \n        \n        #to lower case\n        comment = comment.lower() \n        \n        #splitting each  comment sentence into list of words\n        comment = comment.split() \n        \n        #Stemming \n        ps = PorterStemmer()\n        comment = [ps.stem(word) for word in comment if not word in set(stopwords.words('english'))] \n        \n        #Joining the words back \n        comment =' '.join(comment)\n        corpus.append(comment)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"109e166aac4f526a98a5573f5d6123b4a7d0ff39"},"cell_type":"markdown","source":"Function to create the Bag of Words model from corpus"},{"metadata":{"_uuid":"dd0b34bfe9d892f9e09e16bdbc60d7d649c25e84","trusted":true},"cell_type":"code","source":"def bag_of_words(corpus):\n    \"\"\"Creating Bag of Words Model\n    \n    Creates bag of words using CountVectorizer, which is a sparse matrix\n    with all the words from corpus. Each cell will contain its own frequency\n    in the corresponding comment.\n    \n    Args:\n        corpus, a list containing processed input dataset\n        \n    Returns:\n        The sparse matrix (bag of words) X and labels y\n    \n    \"\"\"   \n    # tokenizer\n    cv = CountVectorizer()\n    X = cv.fit_transform(corpus).toarray() \n    \n    # re-initializing to add max_features so that we can filter out irrelevant words which has very less frequency\n    cv = CountVectorizer(max_features = (X.shape[1] - 50))\n    X = cv.fit_transform(corpus).toarray() \n    y = dataset.iloc[:,-1].values\n\n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c834c4902da3dabd7865eae3ab0e4362d12c835"},"cell_type":"markdown","source":"Function to find the optimized Classifiers - Using GridSearchCV"},{"metadata":{"_uuid":"f6fd79cd0c46d6019bcf62b04581575e4aa1f755","trusted":true},"cell_type":"code","source":"def best_estimator(classifiers, X_train, y_train, filename):\n    \"\"\"Finding the best estimator \n    \n    Uses GridSearchCV to search for the best parameters for all\n    the classifiers used to find the best optimized classifier\n    \n    Args: \n        classifiers: List of classifier dictionaries with names and parameter details\n                \n        X_train: X values of training data\n        \n        y_train: Actual labels of training data\n        \n        filename: String\n        Name of Youtube accounts whose comments are being classified\n        \n    Returns:\n        best_estimator: Dictionary of classifiers parameters, optimized for each dataset\n    \n    \"\"\"\n    \n    scoring = {'acc': 'accuracy',\n               'AUC': 'roc_auc',\n              'prec_macro': 'precision_macro',\n               'rec_micro': 'recall_micro',\n               'f1_score': 'f1_micro'}\n    best_estimators = dict()\n    best_scores_df = pd.DataFrame()\n     \n    for c in classifiers:\n            classifier = c['model']\n            label = c['label']\n            print('\\n\\n Optimized ', label, 'for ', filename)\n            print('---------------------------------------')\n            \n            #print('%s Best Values' % (c['label']))\n            grid_search = GridSearchCV(estimator = classifier,\n                       param_grid = c['parameters'],\n                       scoring = scoring,\n                       refit='acc',\n                       cv = c['g_cv'],\n                       return_train_score=True,\n                       verbose =1)\n            if label == 'Random Forest Classifier':\n                grid_search.fit(X_train, y_train, sample_weight = None)\n            else:\n                grid_search.fit(X_train, y_train)\n            results = grid_search.cv_results_\n            print('\\n')\n            #print('Best Accuracy Score: ',round(grid_search.best_score_*100,2),'%')\n            print('Best Parameters: ',grid_search.best_params_)\n            \n            best_estimators[label] = grid_search.best_estimator_\n            \n            data = [[label, round(grid_search.best_score_*100,2)]]\n            df2 = pd.DataFrame(data, columns = ['Classifier','Accuracy']) \n            best_scores_df = best_scores_df.append(df2)\n            \n            #best_scores[label] = round(grid_search.best_score_*100,2)\n            \n            print('\\n')\n            for key,scorer in scoring.items():\n                #print('{} scores:\\n '.format(scorer))\n                for sample in ('train','test'):\n                    sample_score_mean = round(results['mean_%s_%s' % (sample, key)].mean()*100,2)\n                    sample_score_std = round(results['std_%s_%s' % (sample, key)].mean()*100,2)\n                    if(sample == 'train'):\n                        to_print = 'Training'\n                    else:\n                        to_print = 'Validation'\n                    print(to_print,' ',scorer,' : ',sample_score_mean, '% (+/-)', sample_score_std,'%')\n                print('\\n')\n                   \n            print('-----------------------------------------')\n                \n    print('Comparing the Best Cross-Validated Accuracy between Classifiers')\n    best_scores_df\n    #print('\\t'.join(['{0}{1} % \\n'.format(k, v) for k,v in best_scores.items()]))\n    return best_estimators","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcbbb3ce44e4960074b88f69603f7a2d78a58ae8","trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n                     \n    \"\"\"Generate a simple plot of the test and training learning curve.\n    \n    Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n\n    Args:\n        estimator: object type that implements the \"fit\" and \"predict\" methods\n            An object of that type which is cloned for each validation.\n\n        title: string\n            Title for the chart.\n\n        X: array-like, shape (n_samples, n_features)\n            Training vector, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        y: array-like, shape (n_samples) or (n_samples, n_features), optional\n            Target relative to X for classification or regression;\n            None for unsupervised learning.\n\n        ylim: tuple, shape (ymin, ymax), optional\n            Defines minimum and maximum yvalues plotted.\n\n        cv: int, cross-validation generator or an iterable, optional\n            Determines the cross-validation splitting strategy.\n\n        n_jobs: int or None, optional (default=None)\n            Number of jobs to run in parallel.\n           \n        train_sizes: array-like, shape (n_ticks,), dtype float or int\n            Relative or absolute numbers of training examples that will be used to\n            generate the learning curve. \n            \n    Returns:\n        plt: an object of the generated plot\n    \n    \"\"\"\n\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d04dbf01f23ac106b7aa8a1c4a392fe9f23f4dd1"},"cell_type":"markdown","source":"> * Fit Classifier and Predict Values"},{"metadata":{"_uuid":"9369b81579d1b4378bd2ff20def52e13113e879b","trusted":true},"cell_type":"code","source":"def simple_fit_predict(classifiers, best_estimators, X_train, X_test, y_train, y_test, filename):\n    \"\"\"Fit the train data to classifier and predict on test data\n    \n    Args:\n        classifiers: List of classifier dictionaries with names and parameter details\n                \n        best_estimators: Dictionary of classifier names and optimized parameters\n        \n        X_train: X values of training data\n        \n        X_test: X values of test data\n        \n        y_train: y values of train daa\n        \n        y_test: y values of test data\n        \n        filename: String\n        Name of Youtube accounts whose comments are being classified    \n        \n    Returns:\n        y_preds: Predicted values for test input\n    \n    \"\"\"\n    print('Validation Scores:\\n')\n    y_preds = dict()\n    for key, model in best_estimators.items():\n        #classifier = c\n        label = model.__class__.__name__\n        if label == 'Random Forest Classifier':\n            model.fit(X_train, y_train, weight = None)\n        else:\n            model.fit(X_train, y_train)    \n        train_predictions = model.predict(X_train)\n        test_predictions = model.predict(X_test)\n        y_preds[label] = test_predictions\n        \n        print('Predicting test data for ', filename,': Using ',label)\n        print('\\n')\n        print('Precision:')\n        print('Training score: ',round(precision_score(train_predictions,y_train)*100,2),'%', '\\t Testing score: ',  round(precision_score(test_predictions,y_test)*100,2),'%')\n        print('Recall:')\n        print('Training score: ',round(recall_score(train_predictions,y_train)*100,2),'%', '\\t Testing score: ',  round(recall_score(test_predictions,y_test)*100,2),'%')\n        print('F1 Score:')\n        print('Training score: ',round(f1_score(train_predictions,y_train)*100,2),'%', '\\t Testing score: ',  round(f1_score(test_predictions,y_test)*100,2),'%')\n        print('Accuracy:')\n        print('Training score: ',round(accuracy_score(train_predictions,y_train)*100,2),'%', '\\t Testing score: ',  round(accuracy_score(test_predictions,y_test)*100,2),'%')\n        print('==========================================')\n        print('\\n')\n    return y_preds","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34bc94541f46261932e52ee5fec0c9fb349abd51"},"cell_type":"markdown","source":"Function to create ROC Curves"},{"metadata":{"_uuid":"11728ebadf3ac5f80ba956fddf75de651738cbc4","trusted":true},"cell_type":"code","source":"def roc_curves(classifiers, best_estimators, X_test, y_test, filename):\n    \"\"\"Plot ROC Curves\n\n    Reference: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n    \n    Displays the Receiver Operating Characteristic (ROC) curve for the classifiers\n    \n    Args: \n        classifiers: List of classifier dictionaries with names and parameter details\n                \n        best_estimators: Dictionary of classifier names and optimized parameters\n        \n        X_test: X values of test data\n        \n        y_test: y values of test data\n        \n        filename: String\n        Name of Youtube accounts whose comments are being classified  \n\n    Returns:\n        plt: An object of the plot\n        \n    \"\"\"\n    color=iter(cm.rainbow(np.linspace(0,15,100)))\n    for key, model in best_estimators.items():\n        y_pred = model.predict(X_test) # predict the test data\n        # Compute False postive rate, and True positive rate\n        if hasattr(model, \"decision_function\"):\n            y_pred = model.decision_function(X_test)\n        else:\n            y_pred = model.predict_proba(X_test)[:, 1]\n        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n        # Calculate Area under the curve to display on the plot\n        auc = roc_auc_score(y_test,y_pred)\n        # Now, plot the computed values\n        plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (model.__class__.__name__, auc))\n    \n    # Custom settings for the plot \n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('1-Specificity(False Positive Rate)')\n    plt.ylabel('Sensitivity(True Positive Rate)')\n    plt.title('Receiver Operating Characteristic - '+ filename)\n    plt.legend(loc=\"lower right\")\n    plt.show()               ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f22e3c960c491a63bffd064779f440ecd6d80d4a","trusted":true},"cell_type":"code","source":"def get_confusion_matrix_values(y_test, y_pred):\n    \"\"\"Creates confusion matrix\n    \n    Args:\n        y_test: y values of test data\n        \n        y_pred: Predicted y values\n        \n    Returns: \n        Array of confusion matrix values\n    \n    \"\"\"\n    cm = confusion_matrix(y_test, y_pred)\n    return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"689b67acfbf339adc5a8b8aa06cbd862c5eae7ca"},"cell_type":"markdown","source":"Function to prepare the Performance Comparison between Classifiers"},{"metadata":{"_uuid":"fd958727fcf8e0ff93cd41d901761d8f8927ee0e","trusted":true},"cell_type":"code","source":"def performance_comparison(best_estimators, y_preds, y_test, filename):\n    \"\"\"Preparing evaluation metrics for all data - classifier combinations\n    \n    Args: \n        classifiers: List of classifier dictionaries with names and parameter details\n        \n        best_estimators: Dictionary of classifier names and optimized parameters\n        \n        X_test : X values of test data\n        \n        y_test : y values of test data\n        \n        filename : String\n        Name of Youtube accounts whose comments are being classified \n        \n    Returns:\n        df: Dataframe of evaluation metrics of all classifiers for each dataset    \n    \n    \"\"\"\n    df = pd.DataFrame()\n    df1=[]\n    for key, y_pred in y_preds.items():\n        label = key\n        \n        TN, FP, FN, TP = get_confusion_matrix_values(y_test, y_pred)\n        \n        precision = round(TP/ (TP + FP)*100,2)\n        recall = round(TP / (TP + FN)*100,2)\n        accuracy = round((TP+TN)/(TP+TN+FP+FN)*100,2)\n        spam_caught_rate = round(TP/ (TP+FP)*100,2)\n        blocked_ham = round(FN / (TN + FN)*100,2)\n        matthews_coefficient = round(matthews_corrcoef(y_test, y_pred)*100,2) \n        f1_score = round(2 * precision * recall/(precision + recall),2)\n        \n        data = [[label, accuracy, spam_caught_rate, blocked_ham, matthews_coefficient, f1_score]]\n        df2 = pd.DataFrame(data, columns = ['Classifier','Accuracy','Spam_Caught_Rate', 'Blocked_Ham','Matthews_Coefficient', 'F1 Score']) \n        df1.append(df2)\n        \n    df = pd.concat(df1,ignore_index = True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1c6ba051ce2d808b37f1e8c0f650c0f212652fd","trusted":true},"cell_type":"code","source":"#Data Input\nbase_dir = '../input/'\ndata_files = [os.path.join(base_dir,f) for f in os.listdir(base_dir)] \nfiles = os.listdir(base_dir)\ninput_dir = './ directory'\n#os.mkdir(input_dir)\n\ndf = pd.DataFrame()\ndf_all = pd.DataFrame()\ndf_list =[]\nfor csv_file,file in zip(data_files, files):\n    filename, file_extension = os.path.splitext(file)\n    tsv_file = input_dir+ filename + '_input.tsv'\n    \n    print('PROCESSING DATASET.........', filename)\n    print('===========================================================\\n')\n        \n    #convert csv files to tsv format\n    input_file = convert_to_tsv(csv_file, tsv_file)\n    \n    if filename == 'Youtube04-Eminem':\n        dataset = pd.read_csv(input_file,delimiter = '\\t', skiprows = range(270,276), quoting = 3)\n        #skipping content with nan values\n    else:\n        #Reading the tsvfile ignoring quotes\n        dataset = pd.read_csv(input_file,delimiter = '\\t', quoting = 3)\n    #Viewing the columns\n    print(dataset.head())\n\n#APPLYING NLP\n    print('APPLYING NLP ON .........', filename)\n    print('===========================================================\\n')\n       \n    #Cleaning texts \n    corpus = create_corpus(dataset)\n    \n    X,y = bag_of_words(corpus)\n\n#DATA PRE-PROCESSING FOR CLASSIFICATION\n    # Splitting the dataset into the Training set and Test set\n    print('SPLITTING INTO TRAIN AND TEST.........', filename)\n    print('===========================================================\\n')\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    \n#OPTIMIZING PARAMETERS FOR CLASSIFIERS\n    #Find the best hyper parameters using GridSearchCV method\n    print('OPTIMIZATION OF CLASSIFIERS THROUGH GRIDSEARCHCV FOR ', filename)\n    print('===========================================================\\n')\n       \n    best_estimators = best_estimator(classifiers, X_train, y_train, filename)\n\n#FIT & PREDICT DATA TO THE BEST VERSION OF CLASSIFIERS\n    #Simple fit_predict to see how each classifier performs\n    print('FITTING THE BEST CLASSIFIER AND PREDICTING TEST SET RESULT FOR ', filename)\n    print('===========================================================\\n')\n       \n    y_preds = simple_fit_predict(classifiers,best_estimators, X_train, X_test, y_train, y_test, filename)\n        \n#EVALUATING CLASSIFIERS\n    \n    #Classification report\n    #report(best_estimators, X_test, y_test)\n\n    #SPAM DETECTION PERFORMANCE COMPARISON OF CLASSIFIERS\n    print('PERFORMANCE COMPARISON OF CLASSIFIERS FOR ', filename)\n    print('===========================================================\\n')\n       \n    df = performance_comparison(best_estimators, y_preds, y_test, filename)\n    print(df.head(8))\n    \n    df_list.append(df)\n    print('===========================================================')\n    \n    #Plot ROC curves\n    roc_curves(classifiers, best_estimators, X_test, y_test, filename)    \n\ndf_all = pd.concat(df_list, ignore_index = True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae274b2d426dbc9325fa6e5de7eb4ed97d392adc","trusted":true},"cell_type":"code","source":"def highlight_max(s):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c72b485f2a11b5afa7475dcba603156c29235d3","trusted":true},"cell_type":"code","source":"from tabulate import tabulate\nprint('======================================\\n')\nprint('FINAL PERFORMANCE COMPARISON GRID\\n')\nprint('======================================\\n')\nheaders = ['Classifier','Accuracy','Spam Caught','Blocked Ham','Mathews Coeff','F1 Score']\n[print(\"Dataset Name: \",f,\"\\n\\n\",tabulate(x, headers = headers, tablefmt='psql', numalign=\"right\",floatfmt=\".2f\"),\"\\n\\n\") for f,x in zip(files,df_list)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performance on Youtube01-Psy: XGBoost Classifier performed the best for all metrics, followed by SVC and Logistic Regression. Three classifiers (Random Forest, SVC and XGBoost were able to bring the Blocked Ham to 0%.\n\nPerformance on Youtube02-KatyPerry: Both SVC and Logistic Regression performed the best for all evaluation metrics, including Blocked Ham and Matthew's Coefficient.\n\nPerformance on Youtube03-LMFAO: Logistic Regression stood out by performing the best across all metrics, followed by SVC and Random Forest.\n\nPerformance on Youtube04-Eminem: Logistic Regression performed the best, followed equally by SVC, Decision Tree and XGBoost.\n\nPerformance on Youtube05-Shakira: For this data, no one classifier performed the best. Gaussian Naive Bayes had the lowest Blocked Ham, but it sacrificed Matthews Coefficient and Spam Caught rate. Here, comparitively SVC did the best overall, even though it had 11.54% Blocked Ham.\n\nOverall, Logisitic Regression was the best classifier considering all datasets."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}