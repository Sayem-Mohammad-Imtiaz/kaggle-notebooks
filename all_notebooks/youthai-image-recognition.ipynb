{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MNIST数据集"},{"metadata":{},"cell_type":"markdown","source":"首先我们读取MNIST数据集"},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nx_train = np.array(mnist_train.iloc[:, 1:]).reshape(-1, 28, 28)\ny_train = np.array(mnist_train.iloc[:, 0])\nx_test = np.array(mnist_test.iloc[:, 1:]).reshape(-1, 28, 28)\ny_test = np.array(mnist_test.iloc[:, 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"从x_train和y_train的形状可以看到训练数据中包含了60000个数据点，其中输入x是60000张28x28=784像素组成的图像，由于MNIST数据集是灰度图，所以每个像素仅由一个数字表示；输出y是60000个数字，代表了每一张图像对应的数字几。测试数据x_test和y_test中则包含了10000个数据点。"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 5, figsize=(10, 4)) # 新建一个包含10张子图2行5列的画布\naxes = axes.flatten() # axes中存储了每一个子图\nfor i in range(10): # 循环10次（画10张图）\n    axes[i].imshow(x_train[i], cmap=\"gray_r\") # 将x_train的第i张图画在第i个子图上，这里我们用cmap=\"gray_r\"即反灰度图，数字越大颜色越黑，数字越小颜色越白 \n    axes[i].set_xticks([]) # 移除图像的x轴刻度\n    axes[i].set_yticks([]) # 移除图像的y轴刻度\nplt.tight_layout() # 采用更美观的布局方式\nplt.show() # 显示图片","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"接下来对于0到9每一个数字，我们使用下列代码画出10张对应的手写数字图片。"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(10, 10, figsize=(20, 20)) # 新建一个包含100张子图的10行10列的画布\nfor i in range(10): # 对于每一个数字i\n    indice = np.where(y_train == i)[0] #找到标签为数字i的图像下标\n    for j in range(10): # 输出前10张图片\n        axes[i][j].imshow(x_train[indice[j]], cmap=\"gray_r\")\n        axes[i][j].set_xticks([])\n        axes[i][j].set_yticks([])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可以看到MNIST数据集中包含了笔画轻重各异、书写风格不同的图片。数据集中的数据多样性很重要，计算机“见过”的数据越多，分类就能越准确。直观上理解，若计算机“见过”的都是右撇子写的数字，这时新来了一张图片是由左撇子书写的，因为左撇子写的数字与右撇子会有一些差异，那么它大概率会识别错误；反之如果计算机曾经“见过”左撇子写的数字，它识别正确的可能性就会提升。"},{"metadata":{},"cell_type":"markdown","source":"# CIFAR-10"},{"metadata":{},"cell_type":"markdown","source":"首先我们先进行一些处理，把CIFAR-10数据集准备好"},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"from os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\ndatasets_dir = join(cache_dir, 'datasets') # /cifar-10-batches-py\nif not exists(datasets_dir):\n    makedirs(datasets_dir)\n    \n!cp ../input/cifar10-python/cifar-10-python.tar.gz ~/.keras/datasets/\n!ln -s  ~/.keras/datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz\n!tar xzvf ~/.keras/datasets/cifar-10-python.tar.gz -C ~/.keras/datasets/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"我们使用keras的cifar10模块下载CIFAR-10数据集，数据集已经被分为训练数据与测试数据，分别包含了输入x（即图像）和输出y（即对应的物体）。我们将四个数据集的形状打印出来。"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CIFAR-10数据集中包含了50000个训练数据与10000个测试数据。可以看到与MNIST数据集不同，CIFAR-10数据集中的图片是RGB格式的彩色图片，每张图片大小为32*32*3，即每张图片含有32*32=1024个像素点，而每个像素点由3个数字组成，分别代表红色、绿色、蓝色通道。输出y依然由一个数字表示，0到9这10个数字分别代表10类物体。\n\n> 0：飞机，1：汽车，2：鸟，3：猫，4：鹿，5：狗，6：青蛙，7：马，8：船，9：卡车"},{"metadata":{},"cell_type":"markdown","source":"我们使用matplotlib库将训练数据中的前十张图像画出来。"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 5, figsize=(10, 4)) # 新建一个包含10张子图2行5列的画布\naxes = axes.flatten() # axes中存储了每一个子图\nfor i in range(10): # 循环10次（画10张图）\n    axes[i].imshow(x_train[i]) # 将x_train的第i张图画在第i个子图上\n    axes[i].set_xticks([]) # 移除图像的x轴刻度\n    axes[i].set_yticks([]) # 移除图像的y轴刻度\nplt.tight_layout() # 采用更美观的布局方式\nplt.show() # 显示图片","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"与前一节中MNIST相似，我们对于每一类物体，画出10张图片。"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(10, 10, figsize=(20, 20)) # 新建一个包含100张子图的10行10列的画布\nfor i in range(10): # 对于每一类物体\n    indice = np.where(y_train == i)[0] #找到标签为i的图像下标\n    for j in range(10): # 输出前10张图片\n        axes[i][j].imshow(x_train[indice[j]], cmap=\"gray_r\")\n        axes[i][j].set_xticks([])\n        axes[i][j].set_yticks([])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可以看到CIFAR-10数据集中的每一类物体，都包含形状、颜色、拍摄角度不同的图片，并且图片中还含有一些不相关的元素。[todo]"},{"metadata":{},"cell_type":"markdown","source":"# K近邻算法进行手写数字分类"},{"metadata":{},"cell_type":"markdown","source":"首先，我们导入一些必要的库\n- KNeighborsClassifier：sklearn库中提供的K近邻算法类\n- mnist： keras库中包含的一个方便我们下载MNIST数据集的类\n- pyplot：python中最常用的画图工具\n- numpy：python中用于处理各种数值计算的库"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom keras.datasets import mnist\nfrom matplotlib import pyplot as plt\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在前面我们学习了加载了MNIST数据集。注意原本的输入数据是二维的图像，我们使用reshape函数将二维的图像展开成一维的向量，方便后续使用欧式距离计算相似度。"},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nx_train = np.array(mnist_train.iloc[:, 1:]).reshape(-1, 28, 28)\ny_train = np.array(mnist_train.iloc[:, 0])\nx_test = np.array(mnist_test.iloc[:, 1:]).reshape(-1, 28, 28)\ny_test = np.array(mnist_test.iloc[:, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train = x_train.shape[0] # 训练数据数量\nn_test = x_test.shape[0] # 测试数据数量\nprint(\"原输入数据的形状\")\nprint(x_train.shape)\nprint(x_test.shape)\n\n# 使用reshape方法将图像展开成向量\nx_train = x_train.reshape(n_train, -1) \nx_test = x_test.reshape(n_test, -1)\nprint(\"reshape后输入数据的数据形状\")\nprint(x_train.shape)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可以看到reshape后的训练数据的输入变成了60000个28*28=784维的向量"},{"metadata":{},"cell_type":"markdown","source":"接下来我们调用sklearn中的K近邻算法，K近邻算法会接受一个参数 n_neighbors，也就是查看邻居的个数K。我们先尝试将k设为5，即每次寻找最近的5个邻居。"},{"metadata":{"trusted":true},"cell_type":"code","source":"k = 5\nknc = KNeighborsClassifier(n_neighbors=k)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"接下来我们使用手写数字数据来训练这个K近邻分类器，sklearn库提供了一个非常方便的函数 fit ，它接收两个参数 X 和 y， 分别输入数据和对应的标签。我们把x_train和y_train作为参数传给 fit 函数，即完成了K近邻分类器的训练（训练过程需要花一些时间）。"},{"metadata":{"trusted":true},"cell_type":"code","source":"knc.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"训练完毕！我们使用predict方法对测试集中的10000个数据进行分类，并将分类结果其存到y_predict中（预测也需要花一些时间）。"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = knc.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"将我们的分类结果y_predict与真实的类别y_test进行一一对比，统计分类正确的个数并计算分类准确度。"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = np.sum(y_predict == y_test) / n_test\nprint(\"准确度为 %f\" % accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可以看到我们仅仅用了不到10行代码，就得到了一个分类准确度为96.88%的手写数字分类器！怎么样？是不是没有想象中那么复杂？在机器学习领域，有非常多个人和组织，会将已有的算法实现，打包成一个个库，降低其他人使用算法的门槛。找到并使用这些工具，是每个对机器学习感兴趣的人必备的技能。"},{"metadata":{},"cell_type":"markdown","source":"10000张图像中，我们分错了322张，让我们看看哪些图像分类错误了。"},{"metadata":{"trusted":true},"cell_type":"code","source":"indice = np.random.choice(np.where(y_predict != y_test)[0], size=10) # 随机选择10张分类错误的图像\nfig, axes = plt.subplots(2, 5, figsize=(10, 4))\naxes = axes.flatten()\nfor i, idx in enumerate(indice):\n    axes[i].imshow(x_test[idx].reshape(28, 28), cmap=\"gray_r\")\n    axes[i].set_xticks([])\n    axes[i].set_yticks([])\n    axes[i].set_title(\"y_predict: %d\\ny_test: %d\" % (y_predict[idx], y_test[idx]))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"y_predict是K近邻算法的分类结果，y_test是正确分类。可以看到我们分类错误的基本都是一些歪歪扭扭，与正常写法有较大差异的案例。"},{"metadata":{},"cell_type":"markdown","source":"# 卷积神经网络"},{"metadata":{},"cell_type":"markdown","source":"首先我们导入一些必要的库，我们主要会用到keras库。\n- mnist： keras库中包含的一个方便我们下载MNIST数据集的类\n- Sequential: keras线性模型框架，可以理解为积木的模板\n- 神经网络中的一些常用层\n    - Dense: 全连接层\n    - Flatten: 平铺层（二维转一维）\n    - Conv2D: 二维卷积层\n    - MaxPooling2D: 二维池化层"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"我们还是先导入MNIST数据集。但是为了能让卷积神经网络训练，我们还需要对数据做一些预处理和变换。首先我们将对输入数据做一个形状变换，原先的每一个输入数据是一个28x28的矩阵，但是一般情况下图像是一个三维的张量，也就是对于矩阵中的每一个元素，都有多个数字组成。比如一张彩色的RGB图，矩阵中的每个元素就有3个数字，也就形成了一个28x28x3的张量。而由于MNIST数据集是灰度图，所以我们将输入的每张图片reshape成28x28x1的张量。还有一点需要注意的是，原本的输入数据中每个像素是一个0-255的整数，但是对于神经网络的输入，我们一般希望将输入转化到0-1左右的较小的数字，所以我们将输入数据除以255。另外对于输出数据，我们不再简单的用一个数字来表示。正如在2.3中说到的，对于多分类问题，我们往往采用独热编码作为输出。keras提供了一个方面的函数to_categorical来完成这个变换。"},{"metadata":{"trusted":true},"cell_type":"code","source":"mnist_train = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\")\nmnist_test = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")\nx_train = np.array(mnist_train.iloc[:, 1:]).reshape(-1, 28, 28)\ny_train = np.array(mnist_train.iloc[:, 0])\nx_test = np.array(mnist_test.iloc[:, 1:]).reshape(-1, 28, 28)\ny_test = np.array(mnist_test.iloc[:, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"width, height = x_train.shape[1], x_train.shape[2]\nn_train = x_train.shape[0]\nn_test = x_test.shape[0]\n\nx_train = x_train.reshape(n_train, width, height, 1)\nx_test = x_test.reshape(n_test, width, height, 1)\nprint(\"reshape后的输入形状\")\nprint(x_train.shape)\nprint(x_test.shape)\n\ny_train = keras.utils.to_categorical(y_train)\ny_test = keras.utils.to_categorical(y_test)\nprint(\"独热化后的输出形状\")\nprint(y_train.shape)\nprint(y_test.shape)\n\nprint(\"处理前的最大值为%f\" % x_train.max())\nx_train = x_train / 255\nx_test = x_test / 255\nprint(\"处理后的最大值为%f\" % x_train.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"处理完数据后，我们接下来开始搭建模型，我们使用keras中的线性（Sequential）模型。在线性模型中，我们可以使用add函数，一层层地添加神经网络层。这里我们搭建一个基础的卷积神经网络，该网络的架构如下。\n- 二维卷积层，32个5*5的卷积核，使用relu作为激活函数\n- 最大池化层，2*2大小的池化核\n- 二维卷积层，32个3*3的卷积核，使用relu作为激活函数\n- 最大池化层，2*2大小的池化核\n- 平铺层，将二维矩阵转为一维向量\n- 全连接层，隐藏层数量为256，使用relu作为激活函数\n- 全连接层，隐藏层数量为10，使用softmax作为激活函数，输出每个分类的概率"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (5, 5), activation=\"relu\", input_shape=(width, height, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(10, activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"keras提供了summary函数，方便查看模型每一层的结构，以及参数个数。"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"搭建完卷积神经网络后，我们定义一个优化器，用来找到使损失函数最小的权重，这里我们使用Adam优化器。\n最后我们使用多分类的交叉熵作为损失函数，使用准确率作为度量指标，并完成模型的搭建。"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"keras提供了fit函数来进行训练，将训练的输入与输出x_train,y_train传给fit函数，指定批量大小为32，训练轮数为10轮。\n\n一切就绪！开始训练（这会花上一些时间）"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"训练完毕！我们使用测试数据对训练好的模型进行测试。"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test)\nprint(\"损失为%f\" % score[0])\nprint(\"准确度为%F\" % score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"我们简单的卷积神经网络在测试数据上取得了99.09%的准确度！"},{"metadata":{},"cell_type":"markdown","source":"# 图像增强"},{"metadata":{},"cell_type":"markdown","source":"有一种观点认为神经网络是靠数据喂出来的，如果能够增加训练数据，提供海量数据进行训练，则能够有效提升算法的准确率，因为这样可以避免过拟合，从而可以进一步增大、加深网络结构。而当训练数据有限时，可以通过一些变换从已有的训练数据集中生成一些新的数据，以快速地扩充训练数据。这种方法被成为“数据增强”。\n\n对图像数据进行变换的方式有很多，最常用的包括：\n\n- 旋转图像\n- 平移图像\n- 水平或竖直翻转图像"},{"metadata":{},"cell_type":"markdown","source":"keras提供了ImageDataGenerator模块方便我们进行图像数据增强，仅需几行代码就可以完成。我们使用cifar-10数据集做例子，对原始数据进行数据增强。"},{"metadata":{},"cell_type":"markdown","source":"首先导入一些必要的库\n\n- cifar10： keras库中包含的一个方便我们加载CIFAR-10数据集的类\n- ImageDataGenerator：keras中用于进行图像数据增强的类\n- pyplot：python中最常用的画图工具"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"加载cifar10数据集"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = cifar10.load_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"在ImageDataGenerator中定义图像增强的方式，这里我们采取了下列几种方式\n\n- rotation_range=30，随机旋转不超过30度\n- horizontal_flip=True, 随机进行水平翻转\n- vertical_flip=True, 随机进行竖直反转\n- width_shift_range=5, 随机进行不超过5像素的水平平移\n- height_shift_range=5, 随机进行不超过5像素的竖直平移"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=30,\n    horizontal_flip=True,\n    vertical_flip=True,\n    width_shift_range=5,\n    height_shift_range=5\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"我们选取训练集中的一张卡车的图片，用这个ImageDataGenerator对图像进行五次随机变换并将它们画出来。"},{"metadata":{"trusted":true},"cell_type":"code","source":"origin_image = x_train[1] # 选取原图\n\n# 将原图画出来\nplt.imshow(origin_image) \nplt.show()\n\n# 对图像作五次随机变换并画出来\nfig, ax = plt.subplots(1, 5, figsize=(15, 3))\nax = ax.flatten()\nfor i in range(5):\n    ax[i].imshow(datagen.random_transform(origin_image)) # 使用datagen对图像作随机变换\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"要使用图像增强后的数据代替原数据进行训练也非常简单，只需要更改一行代码。回想在上一节中，我们使用model.fit函数指定训练数据对模型进行训练。"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, batch_size=32, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"如果我们希望启用图像增强，keras提供了一个fit_generator函数，用法如下。"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), epochs=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"fit_generator接收的第一个参数是datagen.flow(x_train, y_train, batch_size=32), 这句话的意思是使用定义好的datagen对原始的输入数据进行变换，生成新的训练数据，每批次生成32个。其他的步骤没有变化，我们就可以像之前一样训练模型了。不要忘记在训练模型之前需要对数据进行预处理。"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = keras.utils.to_categorical(y_train)\ny_test = keras.utils.to_categorical(y_test)\nx_train = x_train / 255\nx_test = x_test / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"除了上面提到的几种变换方式，keras还提供了亮度变换、缩放等其他变换，另外还可以自己编写变换函数，对图片进行自定义的变化。"},{"metadata":{},"cell_type":"markdown","source":"## 样例图片生成"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(origin_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_image = datagen.apply_transform(origin_image, {\n    \"theta\": 30\n})\nplt.imshow(transformed_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_image = datagen.apply_transform(origin_image, {\n    \"tx\": 5,\n    \"ty\": 5\n})\nplt.imshow(transformed_image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_image = datagen.apply_transform(origin_image, {\n    \"flip_vertical\": True\n})\nplt.imshow(transformed_image)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}