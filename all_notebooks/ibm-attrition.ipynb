{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n%config InlineBackend.figure_format ='retina'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv')\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Y true, enconding it to binary\ny = pd.DataFrame(np.zeros(shape=(df.shape[0], 1)))\ny[ df['Attrition']=='No'] = 0\ny[ df['Attrition']=='Yes'] = 1\nprint(y.shape)\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.copy()\ndf2 = df2.drop('Attrition', axis=1) # df only X variables, y is target\ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe() # shows only numerical variables statistics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df.describe().columns\nprint(type(cols))\ncols # column names of numerical variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = df[cols].copy() # training sub dataset 1, only numerical variables, copy() to prevent memory miss-assignment\nprint(x1.shape)\nx1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x2 = df.copy() # training sub dataset 2, only dummied-categorical variables, copy() to prevent memory miss-assignment\nx2 = x2.drop(x1.columns, axis=1)\nprint(x2.columns, x2.shape)\nx2 = pd.get_dummies(x2) # dummify-ing categ vars\nprint(x2.shape)\nx2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# joining x1 and x2 training datasets\nx = x1.join(x2)\nprint(x.shape)\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Base model\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=123)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yte_pred = logreg.predict(X_test)\nprint(yte_pred.shape)\nprint('yte_pred.mean():', yte_pred.mean())\nprint('y_test.values.mean():', y_test.values.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.classification_report(y_test, yte_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.confusion_matrix(y_test, yte_pred))\nprint('Accuracy:', metrics.accuracy_score(y_test, yte_pred))\n#print('Accuracy:', (952+89)/X_train.shape[0])\nprint('Precision:', metrics.precision_score(y_test, yte_pred))\n#print('Precision:', (952)/(952+110)) # this is the one that I ned to fix...\nprint('Recall:', metrics.recall_score(y_test, yte_pred))\n#print('Recall:', 89/(89+110))\nprint('F1:', metrics.f1_score(y_test, yte_pred))\n#print('F1:', 2 * metrics.precision_score(y_train, y_pred) * metrics.recall_score(y_train, y_pred) / (metrics.precision_score(y_train, y_pred) + metrics.recall_score(y_train, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: interpret metrics\n\n# Accuracy is all correct predictions over all predictions\n\n# Precision is \n\n# Recall is 44 / 48 = ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nyte_pred = nb.predict(X_test)\nprint(metrics.confusion_matrix(y_test, yte_pred))\nprint('Accuracy:', metrics.accuracy_score(y_test, yte_pred))\nprint('Precision:', metrics.precision_score(y_test, yte_pred))\nprint('Recall:', metrics.recall_score(y_test, yte_pred))\nprint('F1:', metrics.f1_score(y_test, yte_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nyte_pred = rf.predict(X_test)\nprint(metrics.confusion_matrix(y_test, yte_pred))\nprint('Accuracy:', metrics.accuracy_score(y_test, yte_pred))\nprint('Precision:', metrics.precision_score(y_test, yte_pred))\nprint('Recall:', metrics.recall_score(y_test, yte_pred))\nprint('F1:', metrics.f1_score(y_test, yte_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perfect test fit with ensemble method!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\nyte_pred = dt.predict(X_test)\nprint(metrics.confusion_matrix(y_test, yte_pred))\nprint('Accuracy:', metrics.accuracy_score(y_test, yte_pred))\nprint('Precision:', metrics.precision_score(y_test, yte_pred))\nprint('Recall:', metrics.recall_score(y_test, yte_pred))\nprint('F1:', metrics.f1_score(y_test, yte_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# also with simple desicion tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\nrc = RidgeClassifier(alpha=100)\nrc.fit(X_train, y_train)\nyte_pred = rc.predict(X_test)\nprint(metrics.confusion_matrix(y_test, yte_pred))\nprint('Accuracy:', metrics.accuracy_score(y_test, yte_pred))\nprint('Precision:', metrics.precision_score(y_test, yte_pred))\nprint('Recall:', metrics.recall_score(y_test, yte_pred))\nprint('F1:', metrics.f1_score(y_test, yte_pred))\nprint(rc.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}