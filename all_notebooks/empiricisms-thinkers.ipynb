{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-06T14:53:37.283202Z","iopub.execute_input":"2021-07-06T14:53:37.28358Z","iopub.status.idle":"2021-07-06T14:53:37.295539Z","shell.execute_reply.started":"2021-07-06T14:53:37.283546Z","shell.execute_reply":"2021-07-06T14:53:37.294394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import chi2","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:52:19.563128Z","iopub.execute_input":"2021-07-06T14:52:19.563477Z","iopub.status.idle":"2021-07-06T14:52:20.940908Z","shell.execute_reply.started":"2021-07-06T14:52:19.563449Z","shell.execute_reply":"2021-07-06T14:52:20.939632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv(\"../input/empiricisms-thinkers/Empiricism_works_corpus.csv\")\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:30:44.27266Z","iopub.execute_input":"2021-07-06T14:30:44.273018Z","iopub.status.idle":"2021-07-06T14:30:44.419068Z","shell.execute_reply.started":"2021-07-06T14:30:44.272988Z","shell.execute_reply":"2021-07-06T14:30:44.418106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dataset[['authors', 'book_title','text_clean']].copy()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:30:46.099327Z","iopub.execute_input":"2021-07-06T14:30:46.099701Z","iopub.status.idle":"2021-07-06T14:30:46.125098Z","shell.execute_reply.started":"2021-07-06T14:30:46.099669Z","shell.execute_reply":"2021-07-06T14:30:46.12403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(dataset.authors.unique()).values","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:30:47.872345Z","iopub.execute_input":"2021-07-06T14:30:47.872885Z","iopub.status.idle":"2021-07-06T14:30:47.879419Z","shell.execute_reply.started":"2021-07-06T14:30:47.872837Z","shell.execute_reply":"2021-07-06T14:30:47.878447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word clouds","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\n\nplt.figure(figsize=(40,25))\nsubset = df[df['authors']=='John Locke']\ntext = subset.text_clean.values\ncloud1=WordCloud(background_color='pink',colormap=\"Dark2\",collocations=False,width=2500,height=1800\n                ).generate(\" \".join(text))\n\nplt.subplot(1,3,1)\nplt.axis('off')\nplt.title(\"John Locke\",fontsize=40)\nplt.imshow(cloud1)\n\nsubset = df[df['authors']=='David Hume']\ntext = subset.text_clean.values\ncloud2=WordCloud(background_color='pink',colormap=\"Dark2\",collocations=False,width=2500,height=1800\n                       ).generate(\" \".join(text))\nplt.subplot(1,3,2)\nplt.axis('off')\nplt.title(\"David Hume\",fontsize=40)\nplt.imshow(cloud2)\n\nsubset = df[df['authors']=='George Berkeley']\ntext = subset.text_clean.values\ncloud3=WordCloud(background_color='pink',colormap=\"Dark2\",collocations=False,width=2500,height=1800\n                       ).generate(\" \".join(text))\nplt.subplot(1,3,3)\nplt.axis('off')\nplt.title(\"George Berkeley\",fontsize=40)\nplt.imshow(cloud3)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:48:06.408203Z","iopub.execute_input":"2021-07-06T14:48:06.408547Z","iopub.status.idle":"2021-07-06T14:48:39.213529Z","shell.execute_reply.started":"2021-07-06T14:48:06.408519Z","shell.execute_reply":"2021-07-06T14:48:39.209133Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ncnt=Counter()\n\nfor text in df['text_clean'].values:\n    for word in text.split():\n        cnt[word]+=1\n        \ncnt.most_common(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:46:57.678834Z","iopub.execute_input":"2021-07-06T14:46:57.679202Z","iopub.status.idle":"2021-07-06T14:46:57.849802Z","shell.execute_reply.started":"2021-07-06T14:46:57.679173Z","shell.execute_reply":"2021-07-06T14:46:57.848843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\ndef remove_freqwords(text):\n    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n\ndf[\"text_clean\"] = df[\"text_clean\"].apply(lambda text: remove_freqwords(text))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:47:57.11555Z","iopub.execute_input":"2021-07-06T14:47:57.115935Z","iopub.status.idle":"2021-07-06T14:47:57.205849Z","shell.execute_reply.started":"2021-07-06T14:47:57.1159Z","shell.execute_reply":"2021-07-06T14:47:57.205004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word clouds without frequent words","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\n\nplt.figure(figsize=(40,25))\nsubset = df[df['authors']=='John Locke']\ntext = subset.text_clean.values\ncloud1=WordCloud(background_color='pink',colormap=\"Dark2\",collocations=False,width=2500,height=1800\n                ).generate(\" \".join(text))\n\nplt.subplot(1,3,1)\nplt.axis('off')\nplt.title(\"John Locke\",fontsize=40)\nplt.imshow(cloud1)\n\nsubset = df[df['authors']=='David Hume']\ntext = subset.text_clean.values\ncloud2=WordCloud(background_color='pink',colormap=\"Dark2\",collocations=False,width=2500,height=1800\n                       ).generate(\" \".join(text))\nplt.subplot(1,3,2)\nplt.axis('off')\nplt.title(\"David Hume\",fontsize=40)\nplt.imshow(cloud2)\n\nsubset = df[df['authors']=='George Berkeley']\ntext = subset.text_clean.values\ncloud3=WordCloud(background_color='pink',colormap=\"Dark2\",collocations=False,width=2500,height=1800\n                       ).generate(\" \".join(text))\nplt.subplot(1,3,3)\nplt.axis('off')\nplt.title(\"George Berkeley\",fontsize=40)\nplt.imshow(cloud3)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['authors_id'] = df['authors'].factorize()[0]\nauthors_id_df = df[['authors', 'authors_id']].drop_duplicates()\n\nauthors_to_id = dict(authors_id_df.values)\nid_to_authors = dict(authors_id_df[['authors_id', 'authors']].values)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:40.255208Z","iopub.execute_input":"2021-07-06T14:51:40.255665Z","iopub.status.idle":"2021-07-06T14:51:40.288963Z","shell.execute_reply.started":"2021-07-06T14:51:40.255629Z","shell.execute_reply":"2021-07-06T14:51:40.287893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Term frequency","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n                        ngram_range=(1, 2), \n                        stop_words='english')\n\nfeatures = tfidf.fit_transform(df.text_clean).toarray()\n\nlabels = df.authors_id\n\nprint(\"Each of the %d text is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:52:23.991659Z","iopub.execute_input":"2021-07-06T14:52:23.992041Z","iopub.status.idle":"2021-07-06T14:52:24.821811Z","shell.execute_reply.started":"2021-07-06T14:52:23.992005Z","shell.execute_reply":"2021-07-06T14:52:24.821027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 3\nfor authors, authors_id in sorted(authors_to_id.items()):\n  features_chi2 = chi2(features, labels == authors_id)\n  indices = np.argsort(features_chi2[0])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n  print(\"\\n==> %s:\" %(authors))\n  print(\"  * Most Correlated Unigrams are: %s\" %(', '.join(unigrams[-N:])))\n  print(\"  * Most Correlated Bigrams are: %s\" %(', '.join(bigrams[-N:])))","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:53:50.057221Z","iopub.execute_input":"2021-07-06T14:53:50.057795Z","iopub.status.idle":"2021-07-06T14:53:50.098505Z","shell.execute_reply.started":"2021-07-06T14:53:50.057746Z","shell.execute_reply":"2021-07-06T14:53:50.097722Z"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]}]}