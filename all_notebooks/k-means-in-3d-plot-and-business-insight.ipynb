{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Project Overview\nOnline retail is a Kaggle data set</a> which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered online-only retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\n## Our Goal\nWe will conduct a RFM analysis on the company's customers and thus better understand our customers' buying preference.\n\n#### The steps are broadly divided into:\n\n1. [Step 1: Reading and Understanding Data](#1)\n1. [Step 2: Data Cleaning](#2)\n1. [Step 3: Data Preparation](#3)\n1. [Step 4: Building K-Means Model](#4)\n1. [Step 5: Business Insight](#5)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This notebook is based on the work of Manish Kumar's [Kaggle kernel](https://www.kaggle.com/hellbuoy/online-retail-k-means-hierarchical-clustering). He has done a great job in the organization of the whole kernel. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If this Notebook helps you get a better understanding of K-Means clustering and unsupervised learning, please give me a <font color=\"orange\"><b>UPVOTE</b></font>. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n## Step 1 : Reading and Understanding Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import required libraries for dataframe and visualization\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\n# import required libraries for clustering\nimport sklearn\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ndata = pd.read_csv('../input/online-retail-customer-clustering/OnlineRetail.csv',encoding=\"ISO-8859-1\")\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data description\nprint(data.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n## Step 2 : Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate missing values % in original data\ndata_null = round(100 * (data.isnull().sum()) / len(data), 2)\nprint(data_null)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with missing values\ndata = data.dropna()\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change data type of Customer Id; they are not numeric in essence\ndata['CustomerID'] = data['CustomerID'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n## Step 3 : Data Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### We are going to analysis the Customers based on below 3 factors:\n- R (Recency): Number of days since last purchase\n- F (Frequency): Number of transactions\n- M (Monetary): Total spending by customers (revenue)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Calculate recency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Attribute : Recency\n# Reformat datetime\ndata['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], format='%d-%m-%Y %H:%M')\nprint(data['InvoiceDate'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the difference between most recent date and transaction date\ndata['Diff'] = max(data['InvoiceDate']) - data['InvoiceDate']\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute last transaction date to get the recency of customers\nrfm_r = data.groupby('CustomerID', as_index=False)['Diff'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract number of days only\nrfm_r['Diff'] = rfm_r['Diff'].dt.days\nrfm_r.columns = ['CustomerID', 'Recency']\nprint(rfm_r.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate frequency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Attribute : Frequency\nrfm_f = data.groupby('CustomerID', as_index=False)['InvoiceNo'].count()\nrfm_f.columns = ['CustomerID', 'Frequency']\nprint(rfm_f.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate amount (monetary)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Attribute : Monetary\ndata['Amount'] = data['Quantity'] * data['UnitPrice']\nrfm_m = data.groupby('CustomerID', as_index=False)['Amount'].sum()\nrfm_m.columns = ['CustomerID', 'Amount']\nprint(rfm_m.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine R, F, M\nrfm = pd.concat((rfm_r['Recency'], rfm_f['Frequency'], rfm_m['Amount']), axis=1)\nprint(rfm.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove negative amounts (excluding goods refund)\nrfm = rfm[rfm.Amount > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardize data\nfrom sklearn.preprocessing import StandardScaler\n\n# Store original column names and data\nkeys = rfm.keys()\nrfm_unscaled = rfm\n\n# Scale rfm\nscaler = StandardScaler()\nrfm = scaler.fit_transform(rfm)\nrfm = pd.DataFrame(rfm, columns=keys)\nprint(rfm.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We remove outliers that are outside 3-sigma range, as part of data preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove values outside mean +/- 3 std range\nfor key in rfm.keys():\n    mean = np.mean(rfm[key])\n    std = np.std(rfm[key])\n    rfm = rfm[np.abs(rfm[key] - mean) / std <= 3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n## Step 4 : Building K-Means Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### K-Means Clustering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.<br>\n\nThe algorithm works as follows:\n\n1. Randomly initialize k points as the center of clustering (\"centroid\")\n2. Categorize each data point to the closest centroid\n3. For each centroid, update its coordinate to be the average of all points categorized to it. \n3. Repeat step 2&3 for a given number of iterations and use the centroid location with the lowest error (sum of distance from all data points in a cluster to the cluster centroid), as the optimal choice of centroid location and final output. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Finding the Optimal Number of Clusters","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Elbow Curve to get the right number of Clusters\nA fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw elbow curve to find optimal K value\n# 2 <= i <= 10\ninertia = {}\nfor i in range(2, 11):\n    kmeans = KMeans(n_clusters=i, max_iter=1000)\n    kmeans.fit(rfm)\n    inertia[i] = kmeans.inertia_\n\nfor k, v in inertia.items():\n    print(str(k), ': ', str(v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot for each K value\nplt.subplots()\nplt.plot(list(inertia.values()), 'b+-')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The elbow curve is close to a linear function after K value of 3, which indicates that adding more centroids may not result in better clustering outcomes. Therefore, K should be set to 3 according to the elbow curve.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"However, just looking at the elbow curve above can only give us an imprecise estimation of K value. To have more comfort in the K value of 3 that we have selected, we can do a Silhouette analysis.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Silhouette Analysis\n\n$$\\text{silhouette score}=\\frac{p-q}{max(p,q)}$$\n\n$p$ is the mean distance to the points in the nearest cluster that the data point is not a part of\n\n$q$ is the mean intra-cluster distance to all the points in its own cluster.\n\n* The value of the silhouette score range lies between -1 to 1. \n\n* A score closer to 1 indicates that the data point is very similar to other data points in the cluster, \n\n* A score closer to -1 indicates that the data point is not similar to the data points in its cluster.\n\n**Rule: Higher score is better.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Silhouette analysis\nfor num_clusters in range(2,10):\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=1000)\n    kmeans.fit(rfm)\n    cluster_labels = kmeans.labels_\n    \n    silhouette_avg = silhouette_score(rfm, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1:.4f}\".format(num_clusters, silhouette_avg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although K=2 is the number of K with the highest score, from the perspective of business and for easier interpretation, we continue to adopt 3 as the K value. \nYou will see how K=3 works out in the later sections of this article.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final model with k=3\nkmeans = KMeans(n_clusters=3, max_iter=1000)\nkmeans.fit(rfm)\nprint(kmeans.labels_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign label\nrfm['Cluster_Id'] = kmeans.labels_\nprint(rfm.head())\nprint(rfm.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These box plots show our algorithm actually works quite well in that there is only small overlap between clusters, which means none of three clusters is redundant.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can also draw scatter plots with colored clusters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot\nplt.subplots()\nplt.scatter(x=rfm['Recency'], y=rfm['Amount'], c=rfm['Cluster_Id'], alpha=0.4)\nplt.xlabel('Recency')\nplt.ylabel('Amount')\nplt.title(\"Clustering: Recency vs Amount\")\n\nplt.subplots()\nplt.scatter(x=rfm['Frequency'], y=rfm['Amount'], c=rfm['Cluster_Id'], alpha=0.4)\nplt.xlabel('Frequency')\nplt.ylabel('Amount')\nplt.title(\"Clustering: Frequency vs Amount\")\n\nplt.subplots()\nplt.scatter(x=rfm['Frequency'], y=rfm['Recency'], c=rfm['Cluster_Id'], alpha=0.4)\nplt.xlabel('Frequency')\nplt.ylabel('Recency')\nplt.title(\"Clustering: Frequency vs Recency\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, these 2D plots may not be intutive enough for you guys. So, why not draw a 3D plot to visualize which group our customers belong to, after we computing three variables of R, F, and M? ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create 3D scatter plot\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(xs=rfm['Recency'], ys=rfm['Frequency'], zs=rfm['Amount'], c=rfm['Cluster_Id'])\n\nplt.title('RFM Clustering')\nax.set_xlabel('Recency')\nax.set_ylabel('Frequency')\nax.set_zlabel('Amount')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Qualitative Analysis of Clustering Result\nThis 3D scatter graph clearly shows that our K-Means clustering algorithm has successfully segmented all customers into three distinct categories:\n\n* Category 1: \n\nColor: green\n\nNumber: quite a lot\n\nPurchase frequency: low\n\nAmount of spending: low\n\nRecency: vary\n\n* Category 2:\n\nColor: purple\n\nNumber: many\n\nPurchase frequency: low to mid\n\nAmount of spending: low to mid\n\nRecency: low\n\n\n* Category 3:\n\nColor: yellow\n\nNumber: few\n\nPurchase frequency: vary\n\nAmount of spending: high\n\nRecency: low\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n## Step 5 : Business Insight","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We have already learned that a small number of large customers have contributed a great portion of sale revenue, and it is worth our time and some further coding to explore our customer structure in terms of three clusters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Restore rfm\nrfm = rfm_unscaled\nprint(rfm.head())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove values outside mean +/- 3 std range\nfor key in rfm.keys():\n    mean = np.mean(rfm[key])\n    std = np.std(rfm[key])\n    rfm = rfm[np.abs(rfm[key] - mean) / std <= 3]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Refit model with k=3 to unscaled rfm\nkmeans = KMeans(n_clusters=3, max_iter=1000)\nkmeans.fit(rfm)\nprint(kmeans.labels_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign label\nrfm['Cluster_Id'] = kmeans.labels_\nprint(rfm.head())\nprint(rfm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new data frame for cluster analysis\ncluster_sale = rfm.groupby('Cluster_Id', as_index=False)['Amount'].sum()\ncluster_sale.columns = ['ClusterId', 'Revenue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the number of customers by their cluster id\ncluster_sale['CustomerCount'] = rfm['Cluster_Id'].value_counts()\ncluster_sale['Customer%'] = cluster_sale['CustomerCount'] / sum(cluster_sale['CustomerCount'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the average recency of customers\ncluster_sale['MeanRecency'] = rfm.groupby('Cluster_Id', as_index=False)['Recency'].mean()['Recency']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the number of transactions done by clusters\ncluster_sale['TransactionCount'] = rfm.groupby('Cluster_Id', as_index=False)['Frequency'].sum()['Frequency']\ncluster_sale['Transaction%'] = cluster_sale['TransactionCount'] / sum(cluster_sale['TransactionCount'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the average number of times customers do shopping\ncluster_sale['MeanFrequency'] = cluster_sale['TransactionCount'] / cluster_sale['CustomerCount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the percentage of total revenue by clusters\ncluster_sale['Revenue%'] = cluster_sale['Revenue'] / sum(cluster_sale['Revenue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate average revenue per transaction\ncluster_sale['ARPT'] = cluster_sale['Revenue'] / cluster_sale['TransactionCount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate average revenue per customer\ncluster_sale['ARPC'] = cluster_sale['Revenue'] / cluster_sale['CustomerCount']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reorganize columns for easier reading\ncluster_sale = cluster_sale[\n    ['ClusterId', 'CustomerCount', 'Customer%', 'MeanRecency', 'MeanFrequency', 'Revenue', 'Revenue%',\n     'TransactionCount', 'Transaction%', 'ARPT', 'ARPC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cluster_sale.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Interpretation of result\n\n**Cluster 0 are mostly one-time, infrequent customers**\n\n1. They are the great majority of customers (83%) but only contribute slightly more than 40% of total revenue. Their transaction amount per invoice is quite low, at 13 dollars.\n\n2. On average, the last time they shop online is about 102 days ago. \n\n3. They only shop occasionally in that during the period studied, a typical class-0 customer places about 50 orders in total.\n\n**Cluster 1 are general customers**\n\n1. They are about 14% of all customers and the second largest source of income (40%)\n\n2. Average recency is about 30 days ago. \n\n3. They shop often with average 210 orders per person.\n\n**Cluster 2 are frequent, high-value customers/wholesalers**\n\n1. There are only 93 cluster-2 customers who makes up just 2% of total customers and 9% of total transactions, but more than 18% of total revenue come from them. \n\n2. They also love shopping and spend much more in total. Their average purchase amount per transaction is about 36 dollars, which is the highest among all three customer groups. Their mean total spending amount is more than 11,500 dollars. \n\n3. They buy quite often with 17 days mean recency. They shop almost every day: an average class-2 customer shop 321 times in the past year. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If this Notebook helps you get a better understanding of K-Means clustering and unsupervised learning, please give me a <font color=\"orange\"><b>UPVOTE</b></font>. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}