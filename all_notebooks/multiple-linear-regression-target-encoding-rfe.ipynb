{"cells":[{"metadata":{},"cell_type":"markdown","source":"#Multiple Linear Regression using RFE, Statsmodels and Mean Target Encoding\n## Problem Statement\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts. \n<br>\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\n- Which variables are significant in predicting the price of a car\n- How well those variables describe the price of a car\n<br>\nBased on various market surveys, the consulting firm has gathered a large dataset of different types of cars across the Americal market."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary modules for data analysis and data visualization. \nimport pandas as pd\nimport numpy as np\n\n# Some visualization libraries\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n## Some other snippit of codes to get the setting right \n%matplotlib inline \nimport warnings ## importing warnings library. \nwarnings.filterwarnings('ignore') ## Ignore warning","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the data\ncar = pd.read_csv(\"../input/CarPrice_Assignment.csv\")\ncar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking basic details\ncar.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"car.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **As we can see, this dataset does not contain any missing value**"},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking for duplicated rows\ncar[car.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see we dont have any duplicate record."},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing car_ID column as it is insignificant \ncar.drop('car_ID', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Extracting car company name from CarName column\ncar['CarName'] = car['CarName'].apply(lambda x: x.split()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking the slpit and data quality issues\ncar['CarName'].value_counts().index.sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Here we can see various data quality issues \n  - mazda is written as `maxda`\n  - nissan is written as `Nissan`\n  - porsche is written as `porcshce`\n  - toyota is written as `toyouta`\n  - for volkswagen we have `vokswagen` and `vw`\n\n**We will correct the names one by one**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#replacing car names with correct ones\ncar['CarName'] = car['CarName'].replace('maxda','mazda')\ncar['CarName'] = car['CarName'].replace('Nissan','nissan')\ncar['CarName'] = car['CarName'].replace('porcshce','porsche')\ncar['CarName'] = car['CarName'].replace('toyouta','toyota')\ncar['CarName'] = car['CarName'].replace('vokswagen','volkswagen')\ncar['CarName'] = car['CarName'].replace('vw','volkswagen')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking the car names again\ncar['CarName'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see we have unique car names"},{"metadata":{"trusted":false},"cell_type":"code","source":"#renaming Carname column to companyname\ncar = car.rename(columns={'CarName':'CompanyName'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking distribution of price column\nsns.distplot(car['price'], bins=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Derived Metrics"},{"metadata":{},"cell_type":"markdown","source":"symboling : Its assigned insurance risk rating, A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.(Categorical) \t\t\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"#creating symbol function and applying it of symboling column\ndef symbol(x):\n    if x >= -3 & x <= -1:\n        return 'No Risk'\n    elif x>=0 and x <= 1:\n        return 'Low Risk'\n    else:\n        return 'High Risk'\ncar['symboling'] = car['symboling'].apply(symbol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"car.symboling.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creating fuel economy metric\ncar['fueleconomy'] = (0.55 * car['citympg']) + (0.45 * car['highwaympg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing citympg and highwaympg cols as their effect is considered in fueleconomy\ncar.drop(['citympg','highwaympg'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"car.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#recognising categorical and numerical features\ncat_features = car.dtypes[car.dtypes == 'object'].index\nprint('No of categorical fetures:',len(cat_features),'\\n')\nprint(cat_features)\nprint('*'*100)\n\nnum_features = car.dtypes[car.dtypes != 'object'].index\nprint('No of numerical fetures:',len(num_features),'\\n')\nprint(num_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"car[cat_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"car[num_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking stats of numerical features\ncar[num_features].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{},"cell_type":"markdown","source":"### EDA on numerical variables"},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking correlation of all numerical variables\nplt.figure(figsize=(10,8),dpi=100)\nsns.heatmap(car[num_features].corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above heatmap, **wheelbase, carlength, carwidth, curbweight, enginesize & horsepower** are highly positivily correlated with `price`"},{"metadata":{},"cell_type":"markdown","source":"**fuel economy** is highly negatively correlated"},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking the distribution of highly correlated numerical features with price variable\ncols = ['wheelbase','carlength', 'carwidth', 'curbweight', 'enginesize','horsepower']\nplt.figure(figsize=(20,4), dpi=100)\ni = 1\nfor col in cols:\n    plt.subplot(1,6,i)\n    #sns.distplot(car['price'])\n    sns.distplot(car[col])\n    i = i+1\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All these features follows nearly normal distribution"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#visualising all the numerical features against price column\n\nnr_rows = 5\nnr_cols = 3\nfrom scipy import stats\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*3.5,nr_rows*3),dpi=200)\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        i = r*nr_cols+c\n        if i < len(num_features):\n            sns.regplot(car[num_features[i]], car['price'], ax = axs[r][c])\n            stp = stats.pearsonr(car[num_features[i]], car['price'])\n            str_title = \"r = \" + \"{0:.3f}\".format(stp[0]) + \"      \" \"p = \" + \"{0:.3f}\".format(stp[1])\n            axs[r][c].set_title(str_title,fontsize=11)\n            \nplt.tight_layout()    \nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph, we can make the following inferences:\n- **stroke, compressionratio and peakrpm** have very low correlation with price variable\n- All these variables have high p value (> 0.05), we can say that they will be insignificant in our model building process, so we will remove them"},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing these columns\ncar.drop(['carheight','stroke','compressionratio','peakrpm'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA on Categorical Variables"},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking unique value counts of categorical features\ncar[cat_features].nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#eda on categorical columns\ncols = ['fueltype','aspiration', 'doornumber','enginelocation','drivewheel']\ni = 1\nplt.figure(figsize=(17,8),dpi=100)\nfor col in cols:\n    plt.subplot(1,len(cols),i)\n    car[col].value_counts().plot.pie(autopct='%1.0f%%', startangle=90, shadow = True,colors = sns.color_palette('Paired'))\n    i = i+1\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can easily draw following points :\n - Most number of cars runs on gasoline in America\n - Standard aspiration is preferred over turbo aspiration\n - There is only 1% cars which are having engine at rear position\n - People prefer front wheel derive cars"},{"metadata":{"trusted":false},"cell_type":"code","source":"#dropping engine location as it is highly imbalanced\ncar.drop('enginelocation',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#making countplot for all below categorical variables\ncols = ['symboling','carbody', 'enginetype', 'fuelsystem']\nnr_rows = 2\nnr_cols = 2\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*6.5,nr_rows*3),dpi=100)\n\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        i = r*nr_cols+c\n        if i < len(cols):\n            sns.countplot(car[cols[i]], ax = axs[r][c])\n            \nplt.tight_layout()    \nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some useful points:\n - Cars with Low risk rating are more in number\n - people prefer Sedan and Hatchback cars\n - 4 cylinder OHC(Over head cam) type engine is more poplular in America"},{"metadata":{"trusted":false},"cell_type":"code","source":"#visualising carname feature\nplt.figure(figsize=(10,4),dpi=100)\nsns.countplot(car['CompanyName'])\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets visaualize effect of categorical variables on price"},{"metadata":{"trusted":false},"cell_type":"code","source":"li_cat_feats = list(car.dtypes[car.dtypes=='object'].index)\nnr_rows = 5\nnr_cols = 2\nfig, axs = plt.subplots(nr_rows, nr_cols, figsize=(nr_cols*6,nr_rows*3),dpi=200)\nfor r in range(0,nr_rows):\n    for c in range(0,nr_cols):  \n        i = r*nr_cols+c\n        if i < len(li_cat_feats):\n            sns.boxplot(x=li_cat_feats[i], y='price', data=car, ax = axs[r][c])\nplt.tight_layout()    \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can draw following points from the above graphs:\n - Price of car does not depend much on Doornumber of car\n - Price of car does depend on number brand name in the car <br>\nExcept doornumber , price of car depends on every other feature"},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing doornumber from the dataset\ncar.drop('doornumber',axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Encoding of categorical variables"},{"metadata":{},"cell_type":"markdown","source":"We will use one-hot code encoding for this assignment."},{"metadata":{"trusted":false},"cell_type":"code","source":"cat_features = car.dtypes[car.dtypes == 'object'].index","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"car[cat_features].nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creating function for targe encoding\n#credits : https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\ndef calc_smooth_mean(df, by, on, m):\n    # Compute the global mean\n    mean = df[on].mean()\n\n    # Compute the number of values and the mean of each group\n    agg = df.groupby(by)[on].agg(['count', 'mean'])\n    counts = agg['count']\n    means = agg['mean']\n\n    # Compute the \"smoothed\" means\n    smooth = (counts * means + m * mean) / (counts + m)\n\n    # Replace each value by the according smoothed mean\n    return df[by].map(smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#performing target encoding with weight of 100\nfor col in cat_features:\n    car[col] = calc_smooth_mean(car,by=col, on='price', m=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train-Test split"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train, df_test = train_test_split(car, test_size=0.3, random_state=42)\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature scaling"},{"metadata":{},"cell_type":"markdown","source":"Here we will scale full dataframe using MinMax scaler"},{"metadata":{"trusted":false},"cell_type":"code","source":"cols = df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#importing minmax scaler from sklearn.preprocessing and scaling the training dataframe\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf_train[cols] = scaler.fit_transform(df_train[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#transforming the test data set\ndf_test[cols] = scaler.transform(df_test[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking minmax scaling\ndf_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking correlation of train dataframe \nplt.figure(figsize=(15,15),dpi=100)\nsns.heatmap(df_train.corr(), cmap='RdYlBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#creating function for VIF\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\ndef vif(X_train):\n    vif = pd.DataFrame()\n    vif['Features'] = X_train.columns\n    vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return vif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model building"},{"metadata":{"trusted":false},"cell_type":"code","source":"#creating X and y variables\ny_train = df_train.pop('price')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#feature selection using RFE\n#In this case we are have 57 features , lets select 20 features from the data using RFE and then we will \n# remove statistical insignificant variables one by one\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train,y_train)\n\nrfe = RFE(lr,10)\nrfe.fit(X_train,y_train)\n\nprint(list(zip(X_train.columns,rfe.support_,rfe.ranking_)))\nprint('*'*100)\ncols_rfe = X_train.columns[rfe.support_]\nprint('Features with RFE support:')\nprint(cols_rfe)\nprint('*'*100)\nprint('Features without RFE support:')\ncols_not_rfe = X_train.columns[~rfe.support_]\nprint(cols_not_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#taking cols with RFE support\nX_train = X_train[cols_rfe]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking VIF\nvif(X_train).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing carlength as it is having VIF\nX_train.drop('carlength', axis=1, inplace=True)\nvif(X_train).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing curbweight as it is having high VIF\nX_train.drop('curbweight', axis=1, inplace=True)\nvif(X_train).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing carwidth as it is having high VIF\nX_train.drop('carwidth', axis=1, inplace=True)\nvif(X_train).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing enginesize as it is having high VIF\nX_train.drop('enginesize', axis=1, inplace=True)\nvif(X_train).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets start building model and we will remove other statistically insignificant variables based on p-value and vif"},{"metadata":{"trusted":false},"cell_type":"code","source":"#importing statsmodel\nimport statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Building the first model\nX_train_lr = sm.add_constant(X_train)\nlr_1 = sm.OLS(y_train,X_train_lr).fit()\nprint(lr_1.summary())\nprint(vif(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing enginetype as it is having p-value  and building 2nd model\nX_train.drop('enginetype', axis=1, inplace=True)\nX_train_lr = sm.add_constant(X_train)\nlr_2 = sm.OLS(y_train,X_train_lr).fit()\nprint(lr_2.summary())\nprint(vif(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#removing wheelbase as it is having high VIF building 3rd model\nX_train.drop('wheelbase', axis=1, inplace=True)\nX_train_lr = sm.add_constant(X_train)\nlr_3 = sm.OLS(y_train,X_train_lr).fit()\nprint(lr_3.summary())\nprint(vif(X_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see our model have all the variables having VIF less than 5 and all the p-values less than 0.05, so we can say that our model is good."},{"metadata":{},"cell_type":"markdown","source":"## Residual Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"#calculating residuals\ny_train_pred = lr_3.predict(X_train_lr)\nresiduals = y_train-y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#plotting residuals\nplt.figure(dpi=100)\nsns.distplot(residuals)\nplt.xlabel('Residuals')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking mean of residuals\nnp.mean(residuals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see , residuals are normally distributed and have a mean of zero"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#scatterplot of resuduals v/s fitted values\nplt.figure(figsize=(16,5),dpi=100)\nplt.subplot(121)\nplt.scatter(y_train_pred,residuals)\nplt.xlabel('Fitted Values')\nplt.ylabel('Residuals')\n\nplt.subplot(122)\nplt.scatter(y_train,residuals)\nplt.xlabel('Training Values')\nplt.ylabel('Residuals')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are not having any pattern of residuals with either fitted value or training values "},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(dpi=100)\nsns.regplot(y_train_pred,residuals)\nplt.xlabel('Fitted Values')\nplt.ylabel('Residuals')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above graphs residuals does not have any pattern with fitted and training values, so we can say that our model is good."},{"metadata":{},"cell_type":"markdown","source":"## Making predictions"},{"metadata":{"trusted":false},"cell_type":"code","source":"#checking the test data\ndf_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#creating X and y for test dataframe\ny_test = df_test.pop('price')\nX_test = df_test\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#predicting test values\nX_test = X_test[X_train.columns]\nX_test = sm.add_constant(X_test)\ny_test_pred = lr_3.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#scatterplot of y_test and y_test_pred\nplt.scatter(y_test_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we have almost linear relationship, so we can say that our model is good."},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#importing necessary libraries and methods\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n#calculating r2_score \nr2_score(y_test,y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see r2-score of test set is `0.865` against r2-score of `0.884` and adjusted-r2 score of `0.881` of training data set"},{"metadata":{"trusted":false},"cell_type":"code","source":"#calculating mean squared error for test set\nmean_squared_error(y_test,y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#calculating mean squared error for traning set\nmean_squared_error(y_train,y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank You for visiting the kernel : )"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"165px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"oldHeight":220.12,"position":{"height":"241.4px","left":"674.8px","right":"20px","top":"58px","width":"350px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"varInspector_section_display":"block","window_display":false}},"nbformat":4,"nbformat_minor":1}