{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import r2_score\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nprint(\"Done\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/zomato-bangalore-restaurants/zomato.csv') #for regressors\ndf1 = pd.read_csv('/kaggle/input/zomato-bangalore-restaurants/zomato.csv') #for recommendation ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RESTAURANT RECOMMENDATION \n'''\nThis code uses the zomato dataset to recommend a restaurant similar to what you give as an input(your liking). \nIt uses a content based filtering of other reviews and then sorts them (highest to lowest.)\n\n'''\n\n#Preprocessing- reasonong in the second dataset\n\n#The recommendation algorithm does not need these features\nzomato=df1.drop(['url','dish_liked','phone'],axis=1) \n\n#Remove duplicates, null values, convert object data to analysable form,rename columns,\nzomato.duplicated().sum()\nzomato.drop_duplicates(inplace=True)\nzomato.isnull().sum()\nzomato.dropna(how='any',inplace=True)\nzomato = zomato.rename(columns={'approx_cost(for two people)':'price','listed_in(type)':'type', 'listed_in(city)':'city'})\nzomato['price'] = zomato['price'].astype(str) #Changing the price a to string\nzomato['price'] = zomato['price'].apply(lambda x: x.replace(',','')) \nzomato['price'] = zomato['price'].astype(float)\nzomato = zomato.loc[zomato.rate !='NEW']\nzomato = zomato.loc[zomato.rate !='-'].reset_index(drop=True)\nremove_slash = lambda x: x.replace('/5', '')\nzomato.rate = zomato.rate.apply(remove_slash).str.strip().astype('float')\nzomato.name = zomato.name.apply(lambda x:x.title())\nzomato.online_order.replace(('Yes','No'),(True, False),inplace=True)\nzomato.book_table.replace(('Yes','No'),(True, False),inplace=True)\n\n#Mean Rating\nrestaurants = list(zomato['name'].unique())\nzomato['Mean Rating'] = 0\n\nfor i in range(len(restaurants)):\n    zomato['Mean Rating'][zomato['name'] == restaurants[i]] = zomato['rate'][zomato['name'] == restaurants[i]].mean()\n    \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (1,5))\nzomato[['Mean Rating']] = scaler.fit_transform(zomato[['Mean Rating']]).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lower Casing\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].str.lower()\n\n# Removing of puctuation\nimport string\npunct = string.punctuation\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', punct))\n\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_punctuation(text))\n\n# Removing commonly used words(stop words)\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_stopwords(text))\n\n## Removal of URLS\ndef remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_urls(text))\n\nzomato[['reviews_list', 'cuisines']].sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #RESTAURANT NAMES:\nrestaurant_names = list(zomato['name'].unique())\ndef get_top_words(column, top_nu_of_words, nu_of_word):\n    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n    bag_of_words = vec.fit_transform(column)\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:top_nu_of_words]\n    \nzomato=zomato.drop(['address','rest_type', 'type', 'menu_item', 'votes'],axis=1)\nimport pandas\n\n# Draw a random sample(half of the data)\ndf_percent = zomato.sample(frac=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_percent.set_index('name', inplace=True)\nindices = pd.Series(df_percent.index)\n\n# Creating tf-idf matrix\n'''\nTerm Frequency-Inverse Document Frequency(TF-IDF) vectorization gives a matrix. It is used to transform text into \na meaningful representation of numbers and assess meaning of the words so it can be used for a \nmachine learning algorithm\n'''\ntfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df_percent['reviews_list'])\n\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recommendation algorithm\ndef recommend(name, cosine_similarities = cosine_similarities):\n    \n    # Create a list to put top restaurants\n    recommend_restaurant = []\n    \n    # Find the index of the hotel entered\n    idx = indices[indices == name].index[0]\n    \n    # Find the restaurants with a similar cosine-sim value and order them from bigges number\n    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)\n    \n    # Extract top 30 restaurant indexes with a similar cosine-sim value\n    top30_indexes = list(score_series.iloc[0:31].index)\n    \n    # Names of the top 30 restaurants\n    for each in top30_indexes:\n        recommend_restaurant.append(list(df_percent.index)[each])\n    \n    # Creating the new data set to show similar restaurants\n    df_new = pd.DataFrame(columns=['cuisines', 'Mean Rating', 'price'])\n    \n    # Create the top 30 similar restaurants with some of their columns\n    for each in recommend_restaurant:\n        df_new = df_new.append(pd.DataFrame(df_percent[['cuisines','Mean Rating', 'price']][df_percent.index == each].sample()))\n    \n    # Drop the same named restaurants and sort only the top 10 by the highest rating\n    df_new = df_new.drop_duplicates(subset=['cuisines','Mean Rating', 'price'], keep=False)\n    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)\n    \n    print('We recommend these %s restaurants because you liked %s : ' % (str(len(df_new)), name))\n    \n    return df_new\nrecommend('Pizza Hut')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n''' Column description\n\n1. url : contains the url of the restaurant in the zomato website\n2. address : contains the address of the restaurant in Bengaluru\n3. name : contains the name of the restaurant\n4. online_order : whether online ordering is available in the restaurant or not\n5. book_table : table book option available or not\n6. rate : contains the overall rating of the restaurant out of 5\n7. votes : contains total number of rating for the restaurant as of the above mentioned date\n8. phone : contains the phone number of the restaurant\n9. location : contains the neighborhood in which the restaurant is located\n10. rest_type : restaurant type\n11. dish_liked : dishes people liked in the restaurant\n12. cuisines : food styles, separated by comma\n13. cost_two : contains the approximate cost for meal for two people\n14. reviews_list : list of tuples containing reviews for the restaurant, each tuple\n15. menu_item : contains list of menus available in the restaurant\n16. service_type : type of meal\n17. serve_to : contains the neighborhood in which the restaurant is listed\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PREPROCESSING\n#null values, cleaning, data type conversions(object to analysable format), renaming, etc\n\n# Checking for missing values\npd.DataFrame(round(df.isnull().sum()/df.shape[0] * 100,3), columns = ['Missing'])\n#Therefore,column dish_liked has more tha 50% of the missing data. If we drop the data we would lose 50% of the data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#droping some columns- url, address, phone\ndf.drop(['url', 'address', 'phone'], axis=1, inplace = True)\n\n#Renaming few columns \ndf.rename(columns = {\"approx_cost(for two people)\" : \"cost_two\", \"listed_in(type)\" : \"service_type\", \"listed_in(city)\" : \"serve_to\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the cost_two variaible into integer \ndf.cost_two = df.cost_two.astype(str)\ndf.cost_two = df.cost_two.apply(lambda x : x.replace(',','')).astype(float)\n#the \",\"(comma, example 1,600) inbetween numbers must be removed before conversion\n\ndf.rate.unique() #to check what values need to be removed \n\n#\"NEW\" and \"-\" must be replaced and the '/5'must be removed before conversion\ndf['rate'] = df.rate.replace('NEW', np.NaN)\ndf['rate'] = df.rate.replace('-', np.NaN)\ndf.rate = df.rate.astype(str)\ndf.rate = df.rate.apply(lambda x : x.replace('/5','')).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#VISUALIZATION\n\nplt.rcParams['figure.figsize'] = 16,8\nsns.countplot(df['rate'], palette='Set2')\nplt.title(\"Count plot of the ratings\")\nplt.xticks()\nplt.show()\n#Ratings is normally distributed with 3.4-4.2 stars being the most common ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#box plot comparisons \n\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nsns.boxplot(x='book_table', y='cost_two', data=df.loc[df['book_table'].isin(df['book_table'].value_counts().head(10).index)]);\nplt.title('Online booking(0-No 1-Yes) vs Cost');\n#This shows that mean cost for two people is higher in restaurants with online booking facility","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nsns.boxplot(x='online_order', y='cost_two', data=df.loc[df['online_order'].isin(df['online_order'].value_counts().head(10).index)]);\nplt.title('Online ordering(0-No 1-Yes) vs Cost');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nsns.boxplot(x='cost_two', y='rate', data=df.loc[df['cost_two'].isin(df['cost_two'].value_counts().head(10).index)]);\nplt.title('Cost vs Rating');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding how many people order online \n\ntrace = go.Pie(labels = ['Online_orders', 'No_online_orders'], values = df['online_order'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['pink','teal'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of order variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n#From the pie chart it can be seen that people order online more than going out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the locations with the most number of retaurants \n\ndf.location.value_counts().nlargest(10).plot(kind='barh',color='teal')\nplt.title(\"Number of restaurants by location\")\nplt.xlabel(\"Restaurant counts\")\nplt.show()\n#From the barchart it can be seen that BTM has the most number of restaurants","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Restaurants serving in\n\ndf.serve_to.value_counts().nlargest(10).plot(kind = 'barh', color = 'teal')\nplt.title(\"Number of restaurants listed in a location\")\nplt.xlabel(\"Count\")\nplt.legend()\nplt.show()\n#Most restaurants deliver to BTM and different blocks of Koramangala","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = df['rate'], hue = df['online_order'], palette= 'Set2')\nplt.title(\"Distribution of restaurant rating over online order facility\")\nplt.show()\n#This plot shows that rating clearly depends on the online ordering facility provision, restaurants with online facilities have a higher rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dish_liked.value_counts().nlargest(20).plot(kind = 'barh',color='teal')\nplt.show()\n#Biriyani is the most liked dish","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rest_type.value_counts().nlargest(20).plot(kind = 'barh',color='teal')\nplt.title(\"Restaurant type\")\nplt.xlabel(\"Count\")\nplt.legend()\nplt.show()\n#Quick bites are the most popular type ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.name.value_counts().nlargest(20).plot(kind = 'barh',color='teal')\nplt.legend()\nplt.show()\n#Cafe coffee day is the most popular restaurant in Bangalore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.countplot(x = df['online_order'], hue = df['rate'], palette= 'Set2')\nplt.title(\"Distribution of restaurant rating over table booking facility\")\nplt.show()\n#The distribution below clearly shows that ratings depend on online table booking facility. The restaurants with the online reservation facility have a higher rating","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a pie chart for online orders\n\ntrace = go.Pie(labels = ['Table_booking_available', 'No_table_booking_available'], values = df['book_table'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['pink','teal'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of order variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n#87.5% of the restaurants have online table booking(reservation) facilities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = 14,7\nplt.subplot(1,2,1)\n\ndf.name.value_counts().head().plot(kind = 'barh', color = sns.color_palette(\"hls\", 5))\nplt.xlabel(\"Number Of Restaurants\")\nplt.title(\"Biggest Restaurant Chain (Top 5)\")\n\nplt.subplot(1,2,2)\n\ndf[df['rate'] >= 4.5]['name'].value_counts().nlargest(5).plot(kind = 'barh', color = sns.color_palette(\"Paired\"))\nplt.xlabel(\"Number Of Restaurants\")\nplt.title(\"Biggest Restaurant Chain (Top 5) - Rating more than 4.5\")\nplt.tight_layout()\n'''\nThe bigger chained restaurants in Bangalore do not necessarily have the highest rating. Cafe coffee day has almost \n100 cafes while truffles has just over 40. Truffles has a higher rating than cafe coffee day\nTherefore, quality over quantity\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing the NaN values in rate feature\ndf['rate'] = df['rate'].fillna(df['rate'].mean())\n\n#Ratings is normally distributed as seen below\nsns.distplot(df['rate'], color = 'teal')\nplt.title('Rating Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing the NaN values for the cost_two feature with mean value\ndf['cost_two'] = df['cost_two'].fillna(df['cost_two'].mean())\n\n# cost for two is normally distriuted as seen below\nsns.distplot(df['cost_two'], color = 'teal')\nplt.title('Rating Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorical to numeric type for analysis\n\ndf['online_order']= pd.get_dummies(df['online_order'], drop_first=True)\ndf['book_table'] = pd.get_dummies(df['book_table'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding on rest_type\n\nget_dummies_rest_type = pd.get_dummies(df.rest_type)\nget_dummies_rest_type.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding on location\n\nget_dummies_location = pd.get_dummies(df.location)\nget_dummies_location.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding on type\n\nget_dummies_service_type = pd.get_dummies(df.service_type)\nget_dummies_service_type.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatinating the dataframes\nfinal_df = pd.concat([df,get_dummies_rest_type,get_dummies_service_type, get_dummies_location], axis = 1)\nfinal_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop name, rest_type, location, cuisines, dish_liked, reviews_list\nfinal_df = final_df.drop([\"name\",\"rest_type\",\"location\", 'cuisines', 'dish_liked', 'reviews_list'],axis = 1)\n#drop menu_item, service_type, serve_to\nfinal_df = final_df.drop([\"menu_item\",\"service_type\",\"serve_to\"],axis = 1)\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the features into independent and dependent variables\n\nx = final_df.drop(['rate'], axis = 1) #independent\n\ny = final_df['rate'] #dependent\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesRegressor\n\nmodel = ExtraTreesRegressor()\nmodel.fit(x,y)\n#Extra Tree Regressor is used for finding importance(related to output) score for each feature(column)\n#Select 10 most relevant features and use them to train the model more accurately\nprint(model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualization of top 10 features' importance\n#Higher the value, higher the relevance\nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(10).plot(kind='barh',color='teal')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThe data is split into two sets- one for training the model and one for testing it. \nWe use 2 models- Linear Regression and Decision Tree Regressor \n'''\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.30) #30% split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LINEAR REGRESSION \n\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\n\nlr.fit(x_train, y_train)\n\nlr_pred = lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nR-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model\n'''\nprint('LINEAR REGRESSION\\n')\n\nr2 = r2_score(y_test,lr_pred)\nprint('R-Squared Score: ',r2*100)\n#ERRORS\n#mean absolute error(MAE) , mean absolute percentage error(MAPE), accuracy\n\nlr_errors = abs(lr_pred - y_test)\nprint('Mean Absolute Error:', round(np.mean(lr_pred), 2), 'degrees')\nmape = 100 * (lr_errors / y_test)\nlr_accuracy = 100 - np.mean(mape)\nprint('Accuracy :', round(lr_accuracy, 2), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the errors, normally distributed as seen below \nsns.distplot(y_test-lr_pred,color='y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the Random forest values predicated Rating\n\nplt.figure(figsize=(12,7))\n\nplt.scatter(y_test,x_test.iloc[:,2],color=\"black\")\nplt.title(\"True rate vs Predicted rate, Linear regression\",size=20,pad=15)\nplt.xlabel('Rating',size = 15)\nplt.ylabel('Frequency',size = 15)\nplt.scatter(lr_pred,x_test.iloc[:,2],color=\"yellow\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DECISION TREE REGRESSOR\n\nfrom sklearn.tree import DecisionTreeRegressor\n\ndtree = DecisionTreeRegressor(criterion='mse')\ndtree.fit(x_train, y_train)\ndtree_pred = dtree.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('DECISION TREE REGRESSOR \\n')\n\nr2 = r2_score(y_test,dtree_pred)\nprint('R-Square Score: ',r2*100)\n\n#ERRORS\n#absolute errors, accuracy\ndtree_errors = abs(dtree_pred - y_test)\nprint('Mean Absolute Error:', round(np.mean(dtree_pred), 2), 'degrees.')\nmape = 100 * (dtree_errors / y_test)\ndtree_accuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(dtree_accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the errors\nsns.distplot(y_test-dtree_pred,color='y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the Random forest values predicated Rating\n\nplt.figure(figsize=(12,7))\n\nplt.scatter(y_test,x_test.iloc[:,2],color=\"black\")\nplt.title(\"True rate vs Predicted rate, Decision Tree Regressor\",size=20,pad=15)\nplt.xlabel('Rating',size = 15)\nplt.ylabel('Frequency',size = 15)\nplt.scatter(dtree_pred,x_test.iloc[:,2],color=\"yellow\")\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}