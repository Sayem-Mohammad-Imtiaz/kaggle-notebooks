{"cells":[{"metadata":{"trusted":true,"_uuid":"c5958ca3a918c8405b2d4f7e880dae4b8be38ca3"},"cell_type":"code","source":"# Import the necessary libraries \nimport numpy as np\nimport pandas as pd # Dataframe Management\nimport matplotlib.pyplot as plt \nimport seaborn as sns # Visualization\nfrom sklearn.model_selection import train_test_split \nimport pickle # Model Serialization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a69a8c4db4a78ddc09953dcea26a9c7b4be54c05"},"cell_type":"code","source":"# Load Data\ndf = pd.read_csv('../input/dataset/spam_or_ham.csv', delimiter=',', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b1ffe03fd2dd391d9329221577eb96b8e31234d"},"cell_type":"code","source":"# Exploratory Analysis\n# View Dataset, top 10 Text Messages\ndf.head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d824842b651ec2abfb6217991338a62f06d8386d"},"cell_type":"code","source":"# Check Distribution - Not Balanced Data\nsns.countplot(df.Label)\nplt.xlabel('Label')\nplt.title('Number of ham and spam messages')\n# 20% Spam Data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4343e1d232cd069df6dfed786c03280c1bc0e40"},"cell_type":"code","source":"# Word Cloud - Install From Terminal\n# conda install -c conda-forge wordcloud (if Anaconda is installed)\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud \n\n# spam and ham words\nspam_words = ' '.join(list(df[df['Label'] == 'spam']['Text']))\nham_words = ' '.join(list(df[df['Label'] == 'ham']['Text']))\n\n# Create Word Clouds \nspam_wc = WordCloud(width = 512, height = 512, colormap = 'plasma').generate(spam_words)\nham_wc = WordCloud(width = 512, height = 512, colormap = 'ocean').generate(ham_words)\n\n# Plot Word Clouds\n# SPAM\nplt.figure(figsize = (10,8), facecolor = 'r')\nplt.imshow(spam_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()\n\n# HAM \nplt.figure(figsize = (10,8), facecolor = 'g')\nplt.imshow(ham_wc)\nplt.axis('off')\nplt.tight_layout(pad = 0)\nplt.show()\n\n# In Spam Messages word FREE occurs very oftenly\n# In Ham Messages words 'OK', 'will', 'got' occur often and corrupted words ('gt' or 'lt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4c2820b9dd37a057df86d6d14e340ebd578752c"},"cell_type":"code","source":"# Split Data Set into Train and Test\n# Train 70%\n# Test  30%\n# random_state setup means same values every time split is perfomed \nX_train, X_test, Y_train, Y_test = train_test_split(df.Text, df.Label, test_size=0.3, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f1777a477ae8bd0df1940f88d54ae142ae4736"},"cell_type":"code","source":"# https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB # Naive Bayes\nfrom sklearn.svm import LinearSVC, SVC # Support Vector Machine\nfrom sklearn.ensemble import RandomForestClassifier # Random Forest\nimport time\n\n# Python Function\ndef models(list_sentences_train, list_sentences_test, train_labels, test_labels):\n    t0 = time.time() # start time\n    \n    # Pipeline \n    model = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))), \n                      ('tfidf', TfidfTransformer(use_idf=False)),\n                      ('clf', MultinomialNB())]) # Naive Bayes\n    #                  ('clf', SVC(kernel='linear', probability=True))]) # Linear SVM with probability\n    #                  ('clf', RandomForestClassifier())]) # Random Forest\n\n    # Train Model\n    model.fit(list_sentences_train, train_labels) \n    \n    duration = time.time() - t0 # end time\n    print(\"Training done in %.3fs \" % duration)\n\n    # Model Accuracy\n    print('Model final score: %.3f' % model.score(list_sentences_test, test_labels))\n    return model\n\n# Train, Evaluate and Save Model\nmodel_std_NLP = models(X_train, X_test, Y_train, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e42eaa7bfb8da4cf7da0e605966f8cefd17fe3be"},"cell_type":"code","source":"# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\nfrom sklearn.metrics import confusion_matrix # Library to Compute Confusion Matrix\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    # classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f34b5e96fad719285c69a6fca5f42c23d6b1e04"},"cell_type":"code","source":"np.set_printoptions(precision=2)\n\n# Predictions with model\nY_pred = model_std_NLP.predict(X_test)\nclass_names = np.array(['ham', 'spam'])\n\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, Y_pred, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, Y_pred, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"489821f3ffbfe5080ec0c566f53ca7d8285742ed"},"cell_type":"code","source":"# Save to file in the current working directory\npkl_filename = \"pickle_model.pkl\"  \nwith open(pkl_filename, 'wb') as file:  \n    pickle.dump(model_std_NLP, file)\n\n# Load from file\nwith open(pkl_filename, 'rb') as file:  \n    pickle_model = pickle.load(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ebffe11b1a9a0d4b7ec16d0dff060d663ce6e50"},"cell_type":"code","source":"test_text_spam = ['Urgent! call 09066350750 from your landline. Your complimentary 4* Ibiza Holiday or 10,000 cash await collection SAE T&Cs PO BOX 434 SK3 8WP 150 ppm 18+ ']\ntest_text_ham = ['Good. No swimsuit allowed :)']\n\n# Predict Category and Probability\n# Spam\nprint(model_std_NLP.predict(test_text_spam)) \nprint(model_std_NLP.predict_proba(test_text_spam)) \n\n# Ham\nprint(model_std_NLP.predict(test_text_ham)) \nprint(model_std_NLP.predict_proba(test_text_ham)) \n\n# More Test Examples\n# Ham - 0\n# Good. No swimsuit allowed :)\n# Wish i were with you now!\n# Im sorry bout last nite it wasnÃ¥Ãt ur fault it was me, spouse it was pmt or sumthin! U 4give me? I think u shldxxxx\n\n# Spam - 1\n# Urgent! call 09066350750 from your landline. Your complimentary 4* Ibiza Holiday or 10,000 cash await collection SAE T&Cs PO BOX 434 SK3 8WP 150 ppm 18+ \n# +123 Congratulations - in this week's competition draw u have won the Ã¥Â£1450 prize to claim just call 09050002311 b4280703. T&Cs/stop SMS 08718727868. Over 18 only 150ppm\n# Double mins and txts 4 6months FREE Bluetooth on Orange. Available on Sony, Nokia Motorola phones. Call MobileUpd8 on 08000839402 or call2optout/N9DX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9971513ce4390480cd79e8a46a1c7690ed5cd48"},"cell_type":"code","source":"# Test Pickle Model\nprint(pickle_model.predict(test_text_spam)) # Predict Category\nprint(pickle_model.predict_proba(test_text_spam)) # Predict Probability","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"825114281a7921bdb72ca7a80f1afd1cd4d0c50e"},"cell_type":"code","source":"# Import Keras Libraries\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"400b1d66bf05209f42cd0af91dbdd6b51dd91f7e"},"cell_type":"code","source":"le = LabelEncoder()            # Create Label Encoder\nY = le.fit_transform(df.Label) # Set Labels (ham, spam) -> (0, 1)\nY = Y.reshape(-1,1)            # Change (0, 1) -> (-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a764ded4a444abb39993cf0e649e6a52a385f842"},"cell_type":"code","source":"# Split Data Set into Train and Test\n# Train 70%\n# Test  30%\n# random_state setup means same values every time split is perfomed \nX_train, X_test, Y_train, Y_test = train_test_split(df.Text, Y, test_size=0.3, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"423f77fdeddbf5169915a04e879362232f93323b"},"cell_type":"code","source":"# Tokenize the data and convert the text to sequences\n# Add padding to ensure that all the sequences have the same shape\n# There are many ways of taking the max_len and here an arbitrary length of 150 is chosen\nmax_words = 1000\nmax_len = 150\n\n# Split Sentences into Tokens \ntok = Tokenizer(num_words = max_words) \ntok.fit_on_texts(X_train) \n\n# Transform sequence of senteces in sequence of integers\nsequences = tok.texts_to_sequences(X_train)\n# Create Input to Neural Network\nsequences_matrix = sequence.pad_sequences(sequences, maxlen = max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7bc277d823414c7a20c2fa76fca9948459e748f"},"cell_type":"code","source":"# Raw Textual Data\nprint(X_train[1])\n# After Tokenization\nprint(sequences[1])\n# Matrix with Tokens (Proper Input to Neural Network)\nprint(sequences_matrix[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e605dd633486cb7d7ae7dc96a9d13674228586e7"},"cell_type":"code","source":"# Define RNN - Recursive Neural Network\ndef RNN():\n    inputs = Input(name = 'inputs', shape = [max_len])\n    layer = Embedding(max_words, 50, input_length = max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256, name = 'FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.5)(layer)\n    layer = Dense(1, name = 'out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs = inputs, outputs = layer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a46c21658c00cc85cc81944ac92836a6a26dd15e"},"cell_type":"code","source":"# Create Model\nmodel = RNN()\nmodel.summary() # About RNN ...\nmodel.compile(loss = 'binary_crossentropy', optimizer = RMSprop(), metrics=['accuracy']) # Finalize Neural Network","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31d0dc76496809af026b2e2ec3889586b5f49c32"},"cell_type":"code","source":"# Train Neural Network\nhistory = model.fit(sequences_matrix, Y_train, batch_size=128, epochs=10,\n          validation_split=0.2, callbacks = [EarlyStopping(monitor='val_loss', min_delta=0.0001)])\n\n# Batch Size ?\n# Epochs ?\n# Validation Set ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a89fa12683f29fd52ec60662d7d63a4075e2a92b"},"cell_type":"code","source":"# Process the test set data\ntest_sequences = tok.texts_to_sequences(X_test)\n# Prepare Test Input for Neural Network\ntest_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen = max_len)\n\n# Evaluate the model on the test set\n\naccr = model.evaluate(test_sequences_matrix, Y_test)\n\n# Check Neural Network Accuracy\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e9b4acc4f206b930d9ab59a9640615796ff269e"},"cell_type":"code","source":"# Setup precision of floating point number\nnp.set_printoptions(precision=2)\n\n# Predictions with keras model\nY_pred = model.predict(test_sequences_matrix)\nclass_names = np.array(['ham', 'spam'])\n\n# Based on Threshold (e.g. 0,9) change output from Neural Network\nY_pred = (Y_pred > 0.05).astype(int)\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(Y_test, Y_pred, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(Y_test, Y_pred, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4666b5a3676e1a85b268d2a304ed097126afc032"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}