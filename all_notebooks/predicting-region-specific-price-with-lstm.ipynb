{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"> ## Get that Avo Toast.  \n***It's not like you can afford a home in the Bay anyway.***"},{"metadata":{},"cell_type":"markdown","source":"This is my third attempt at avocado price prediction. My first attempt was using fb prophet, second attempt was using regression, and both methods did not work. Fbprophet only worked for univariate dataset, but I wanted to use the region variable as well. And the regression models could not predict future dates.  \nIt seems like for multivariate time series data, I would need a more complex model like neural networks. Hence I am trying LSTM this time. Let's see if third time will be a charm.  \n\n*This is also my first Kaggle/data science project and any criticism/feedback is welcomed :) *\n"},{"metadata":{},"cell_type":"markdown","source":"### Goal\nPredict the region-specific avocado price based on total volume and historical average price.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport math, time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/avocado.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Unnamed: 0'], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ndf.loc[:,'Total Volume':'XLarge Bags']= scaler.fit_transform(df.loc[:,'Total Volume':'XLarge Bags'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalizing the volume columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['type']=df['type'].replace('conventional', 0)\ndf['type']=df['type'].replace('organic', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label encoding and one-hot encoding the categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"region_ohe = OneHotEncoder(categories = \"auto\", handle_unknown = \"ignore\")\nX_encoded = region_ohe.fit_transform(df['region'].values.reshape(-1,1)).toarray()\nX_encoded = pd.DataFrame(X_encoded, columns = [str(int(i)) for i in range(X_encoded.shape[1])])\nX = df.drop(['year', 'region'], 1)\ndff = pd.concat([X, X_encoded], axis = 1)\n#moving AveragePrice to the last column\ndff['Price']=dff.AveragePrice\ndff.drop(['AveragePrice'], 1, inplace=True)\ndff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff=dff.set_index('Date')\ndff.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the date column as index."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(df.corr(),cmap='coolwarm',annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like the quantities are highly correlated between each other, but not very much with the average price... This is not good since the variables should be independent. I should just keep one and drop the others, I will keep Total Volume."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = dff.drop(dff.loc[:,'4046': 'XLarge Bags'], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(df, seq_len):\n    amount_of_features = len(df.columns) # 5\n    data = df.as_matrix() \n    sequence_length = seq_len + 1 # index starting from 0\n    result = []\n    \n    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n        result.append(data[index: index + sequence_length]) # index : index + 22days\n    \n    result = np.array(result)\n    print(result.shape)\n    row = round(0.9 * result.shape[0]) # 90% split\n    print(\"row: \", row)\n    train = result[:int(row), :] # 90% date, all features \n    #print(train.shape)\n    \n    x_train = train[:, :-1] \n    y_train = train[:, -1][:,-1]\n    \n    x_test = result[int(row):, :-1] \n    y_test = result[int(row):, -1][:,-1]\n\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n\n    return [x_train, y_train, x_test, y_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"window = 10\nX_train, y_train, X_test, y_test = load_data(df2, window)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(layers):\n    d = 0.3\n    model = Sequential()\n    \n    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n    model.add(Dropout(d))\n        \n    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n    model.add(Dropout(d))\n        \n    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n    \n    # adam = keras.optimizers.Adam(decay=0.2)\n        \n    start = time.time()\n    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n    print(\"Compilation Time : \", time.time() - start)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model([57,window,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=100,epochs=50,validation_split=0.1,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff=[]\nratio=[]\np = model.predict(X_test)\nprint (p.shape)\n# for each data index in test data\nfor u in range(len(y_test)):\n    # pr = prediction day u\n    pr = p[u][0]\n    # (y_test day u / pr) - 1\n    ratio.append((y_test[u]/pr)-1)\n    diff.append(abs(y_test[u]- pr))\n    # print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n    # Last day prediction\nprint(p[-1]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_score(model, X_train, y_train, X_test, y_test):\n    trainScore = model.evaluate(X_train, y_train, verbose=0)\n    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n\n    testScore = model.evaluate(X_test, y_test, verbose=0)\n    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n    return trainScore[0], testScore[0]\n\n\nmodel_score(model, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt2\nplt2.figure(figsize=(14,6))\nplt2.plot(p,color='red', label='Prediction')\nplt2.plot(y_test,color='blue', label='Actual')\nplt2.legend(loc='best')\nplt2.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"From the model score and the plot, it seems like the model is doing a pretty good job. But I'm not confident at all since I cannot justify all the parameters that I'm using (sequence length, batch size, units, number of layers, etc.)... I'm sure there is a lot of room for optimization, but I think (hope) that the overall structure of the model is right at least? "},{"metadata":{},"cell_type":"markdown","source":"### Now let's try predicting the price of a new/future date."},{"metadata":{},"cell_type":"markdown","source":"I will go through a series of clunky steps to get the user's input into the right shape for the model.\nI'm aware that I might be taking a lot of detours and unecessary steps here... would love to know if there's a better alternative."},{"metadata":{"trusted":true},"cell_type":"code","source":"regiondict = {}\nfor key, value in enumerate(df.region.unique()):\n    regiondict[key] = value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def OHE_region (region): #region is a string   \n    #get the region number as mapped in the dict\n    regionnum = list(regiondict.keys())[list(regiondict.values()).index(region)]   \n    #create regionnum columns of 0, concat one column of 1 at index regionnum, then concat 53-regionnum columns of 0.\n    before_df = pd.DataFrame(0.0, index=range(1), columns = list(range(regionnum)))\n    after_df = pd.DataFrame(0.0, index=range(1), columns = list(range(regionnum+1, 54)))\n    new_df = pd.DataFrame(1.0, index=range(1), columns = [str(regionnum)])\n    OHE_df = pd.concat([before_df, new_df, after_df], axis=1) \n    return OHE_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OHE_region('Tampa')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_dict = {'Date': '2019-08-12', 'Total Volume': dff['Total Volume'].mean(), 'type': 0}\nX_df = pd.DataFrame([X_dict])\nnew_X = pd.DataFrame(X_df, columns=X_dict.keys()) #hacky/dumb way of making sure that the columns in the df maintain the same order as in the dict.\nencoded_region = OHE_region('Houston')\nnew_X = pd.concat([new_X, encoded_region], axis=1)\nnew_X=new_X.set_index('Date')\nprint(new_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#new_X=new_X.reshape(1,1,56)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.predict(new_X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### stuck - TBC. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}