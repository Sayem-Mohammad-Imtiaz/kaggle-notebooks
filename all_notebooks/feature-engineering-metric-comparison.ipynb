{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"234c05c6-7717-19a6-5199-568e3eab261c"},"source":"Hi, friends.\n\nLet's study how the creation of simple binary features can impact the generalization of logistic regression when evaluated with several metrics: log-loss, AUC, F1-score, and accuracy. By ten-fold cross-validation, we'll see that these custom features improve the mean AUC across folds. Then, given more training data, all scores tend to improve consistently when evaluated on unseen data. \n\nYou can find the complete code for this project on my GitHub: <br>\nhttps://github.com/Justin-Le/predicting-diabetes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc0cda3d-6c8f-0d35-2a29-77db16ac7faa"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Import Seaborn for plotting\n# and ignore all warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nplt.style.use('ggplot')\n\ndata = pd.read_csv('../input/diabetes.csv')\ndata.shape\ndata.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"d1800bab-0660-d82c-f150-6b2a108693a6"},"source":"First, let's consider pairwise relationships between raw features by inspecting their scatterplots. The FacetGrid function in Seaborn allows us to easily color-code the two classes, which helps us to quickly identify regions of interest for feature engineering.\n\nAs an example, the first plot leads us to (naively) suspect that individuals who have an insulin-level greater than or equal to 400 tend to be at risk of diabetes (blue). This clue leads us to a potential custom feature: insulin_geq_400. We'll continue this process of naive inspection for the remaining features, too."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f8f2428-c0d0-7099-92f9-aa29ca29184a"},"outputs":[],"source":"grid = sns.FacetGrid(data, hue='Outcome')\ngrid.map(plt.scatter, 'Glucose', 'Insulin')\ngrid.add_legend()\nplt.show()\n\n# High risk: insulin_geq_400"},{"cell_type":"markdown","metadata":{"_cell_guid":"a809bca1-2fd3-9259-2e19-620bd74b2a6a"},"source":"Already, we see some zero-values that may need to be imputed later on. Is it possible for a person to have an insulin-level of zero? Similarly, the plot below suggests that some people have a body-mass index of zero, which we suspect is meaningless."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bcbfbd3-234c-6e87-f88a-b3fd75fbf8e0"},"outputs":[],"source":"grid = sns.FacetGrid(data, hue='Outcome')\ngrid.map(plt.scatter, 'Glucose', 'BMI')\ngrid.add_legend()\nplt.show()\n\n# High risk: BMI_geq_48"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f6689ad-5461-bb1c-deb9-8c405c22323e"},"outputs":[],"source":"grid = sns.FacetGrid(data, hue='Outcome')\ngrid.map(plt.scatter, 'Glucose', 'DiabetesPedigreeFunction')\ngrid.add_legend()\nplt.show()\n\n# High risk: pedigree_geq_1\n\n# From all scatterplots\n# High risk: glucose_geq_170"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"260b64d5-d329-9545-d054-6024b31caceb"},"outputs":[],"source":"grid = sns.FacetGrid(data, hue='Outcome')\ngrid.map(plt.scatter, 'BloodPressure', 'SkinThickness')\ngrid.add_legend()\nplt.show()\n\n# High risk: blood_geq_92"},{"cell_type":"markdown","metadata":{"_cell_guid":"74a2009a-4651-51ca-71cf-27a99934b6b7"},"source":"Perhaps histograms would be more appropriate for examining these next few features, as they each have only a few discrete values."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e349da8a-4d93-944b-277a-3edc590793b1"},"outputs":[],"source":"n_bins = data.Pregnancies.max() - data.Pregnancies.min()\ngrid = sns.FacetGrid(data, row='Outcome')\ngrid.map(plt.hist, 'Pregnancies', bins=np.arange(0, n_bins)-0.5)\nplt.show()\n\n# Low risk: preg_1_or_2"},{"cell_type":"markdown","metadata":{"_cell_guid":"a977066f-810a-73ef-dc4e-c670451f919b"},"source":"As mentioned in the forums by our friend Hugues Fontenelle, it's certainly reasonable for an individual to have zero pregnancies, so we won't impute this value."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8c68c07-8c0b-68a8-17e3-c74bc9ce30c2"},"outputs":[],"source":"n_bins = data.Age.max() - data.Age.min()\ngrid = sns.FacetGrid(data, row='Outcome')\ngrid.map(plt.hist, 'Age', bins=np.arange(20, n_bins)-0.5)\nplt.show()\n\n# Low risk: age_leq_28\n# High risk: age_52_or_53"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"feb59f79-2643-13eb-414e-2c8d33f28ae2"},"outputs":[],"source":"data = data[data.SkinThickness != 0]\nn_bins = data.SkinThickness.max() - data.SkinThickness.min()\ngrid = sns.FacetGrid(data, row='Outcome')\ngrid.map(plt.hist, 'SkinThickness', bins=np.arange(n_bins)-0.5)\nplt.show()\n\n# Low risk: st_10_to_23"},{"cell_type":"markdown","metadata":{"_cell_guid":"ff7de973-3c39-8219-6f3f-5c9fb7decbac"},"source":"Before we test the custom features that were suggested from these plots, let's see how logistic regression and XGBoost perform when cross-validated on the raw data. Then, we'll see how they generalize to the isolated testing set when given the complete training set to learn from."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee35ce00-b4d1-4c6a-72bc-8cee6de209e6"},"outputs":[],"source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, roc_auc_score, f1_score, accuracy_score\n\nX = data.ix[:, :-1]\ny = data.ix[:, -1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Instantiate logistic regression\nclf = LogisticRegression()\n\n#Cross-validate logistic regression\nprint(\"\\nLogistic regression results for 10-fold cross-validation:\\n\")\nscores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\nprint((\"Accuracies:\\n %s\\n\\n\" +\n       \"Best accuracy on held-out data: %.4f\\n\\n\" +\n       \"Mean accuracy on held-out data: %.4f\\n\\n\") % (str(scores), scores.max(), scores.mean()))\nscores = cross_val_score(clf, X_train, y_train, cv=10, scoring='roc_auc')\nprint((\"AUC:\\n %s\\n\\n\" +\n       \"Best AUC on held-out data: %.4f\\n\\n\" + \n       \"Mean AUC on held-out data: %.4f\\n\\n\") % (str(scores), scores.max(), scores.mean()))\n\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\n\nprint(\"=\"*80)\nprint(\"\\nLogistic regression performance on unseen data:\")\nprint(\"\\nlog-loss: %.4f\" % log_loss(y_test, pred))\nprint(\"\\nAUC: %.4f\" % roc_auc_score(y_test, pred))\nprint(\"\\nF1 score: %.4f\" % f1_score(y_test, pred))\nprint(\"\\nAccuracy: %.4f\" % accuracy_score(y_test, pred))\nprint(\"=\"*80)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9f64befd-b971-8aac-c07d-48f4f6c0f946"},"source":"Let's see if we can improve these scores by creating new features and imputing some bad ones."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cddec752-7831-8919-c68e-29a79629684e"},"outputs":[],"source":"######################################## \n# Create binary features\n######################################## \n\n# Insulin >= 400\nX['insulin_geq_400'] = np.where(X['Insulin'] >= 400, 1, 0)\n\n# BMI >= 48\nX['bmi_geq_48'] = np.where(X['BMI'] >= 48, 1, 0)\n\n# Diabetes Pedigree Function >= 1\nX['pedigree_geq_1'] = np.where(X['DiabetesPedigreeFunction'] >= 1.0, 1, 0)\n\n# Glucose >= 170\nX['glucose_geq_170'] = np.where(X['Glucose'] >= 170, 1, 0)\n\n# Blood Pressure >= 92\nX['blood_geq_92'] = np.where(X['BloodPressure'] >= 92, 1, 0)\n\n# One or two pregnancies\nX['preg_1_or_2'] = np.where(X['Pregnancies'] == 1, 1, 0) +\\\n                      np.where(X['Pregnancies'] == 2, 1, 0)\n\n# Age <= 28\nX['age_leq_28'] = np.where(X['Age'] <= 28, 1, 0)\n\n# Age is 52 or 53\nX['age_52_or_53'] = np.where(X['Age'] == 52, 1, 0) +\\\n                       np.where(X['Age'] == 53, 1, 0)\n\n# 10 <= Skin Thickness >= 23\nX['skin_10_to_23'] = np.where(X['SkinThickness'] >= 10, 1, 0) -\\\n                        np.where(X['SkinThickness'] > 23, 1, 0)\n\nX.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a9f93de2-403a-d028-c1b9-2dd0a96f3546"},"source":"Certainly, there's potential for more intricate features, but we'll only consider these naive binary ones for now.\n\nBefore imputing, let's isolate training and testing sets."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"def1ad15-76ae-9094-89d7-218c4b335f4d"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\n# Isolate a training set for CV.\n# Testing set won't be touched until CV is complete.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\n# Note that the train/test split *must* be done before any imputation.\n# If we impute values before isolating the training set,\n# then values from the testing set might \n# influence the imputed values in the training set.\n# See Abu-Mostafa's \"Learning from Data\" to read more about this issue,\n# sometimes referred to as \"data snooping\"."},{"cell_type":"markdown","metadata":{"_cell_guid":"475190c5-fdaa-1fc2-c512-9b3201f2f1b7"},"source":"We'll now impute the meaningless zeros in the dataset by replacing them with random Gaussian values localized near the respective sample means. Again, this step must be done separately for training and testing sets, and we'll see why in a moment."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a2eb656-265b-e218-7982-84732e153c42"},"outputs":[],"source":"normals = [0]*3\nvariables = ['Glucose', 'SkinThickness', 'BMI']\n\n# Generate imputation values with Gaussian randomness.\nfor n, v in zip(range(len(normals)), variables):\n    # Shift the mean up to account for skewness caused by zeros.\n    v_mean = X_train[v].mean()*1.5\n\n    # Use surrogate deviation.\n    # (Sometimes I get strange values when using .std(). Why?)\n    v_std = v_mean*0.1\n\n    normals[n] = np.random.normal(loc = v_mean, scale = v_std)\n\nprint(\"Imputing zeros in Glucose, SkinThickness, and BMI with\")\nprint(\"%f, %f, and %f\" % (normals[0], normals[1], normals[2]))\n\n# Impute.\nX_train = X_train.replace(to_replace = {'Glucose': {0: normals[0]}, \n                                  'SkinThickness': {0: normals[1]}, \n                                  'BMI': {0: normals[2]}})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79421b59-6030-403a-a822-2b11c5dffe07"},"outputs":[],"source":"normals = [0]*3\nvariables = ['Glucose', 'SkinThickness', 'BMI']\n\n# Generate imputation values with Gaussian randomness.\nfor n, v in zip(range(len(normals)), variables):\n    # Shift the mean up to account for skewness caused by zeros.\n    v_mean = X_test[v].mean()*1.5\n\n    # Use surrogate deviation.\n    # (Sometimes I get strange values when using .std(). Why?)\n    v_std = v_mean*0.1\n\n    normals[n] = np.random.normal(loc = v_mean, scale = v_std)\n\nprint(\"Imputing zeros in Glucose, SkinThickness, and BMI with\")\nprint(\"%f, %f, and %f\" % (normals[0], normals[1], normals[2]))\n\n# Impute.\nX_test = X_test.replace(to_replace = {'Glucose': {0: normals[0]}, \n                                  'SkinThickness': {0: normals[1]}, \n                                  'BMI': {0: normals[2]}})"},{"cell_type":"markdown","metadata":{"_cell_guid":"063b422c-56cf-55c5-706c-eb3f6eeaaed3"},"source":"Notice how the imputing values are very different in the training set than they are in the testing set. If we had imputed before the train/test split, then information from the testing set would have significantly influenced our imputation of the training set. Let's try to avoid this kind of information leakage, as it could hinder generalization. For more on this issue, please see Abu-Mostafa's \"Learning from Data\", an excellent book that formally discusses generalization in the theory of statistical learning.\n\nAlso notice that we haven't imputed insulin-levels for now, since there are too many observations that would be affected, and we'd possibly require a more sophisticated imputation strategy to avoid causing a significant skew in the sample distribution."},{"cell_type":"markdown","metadata":{"_cell_guid":"eaacb181-9ca0-a112-17b6-793fe29f77f3"},"source":"To see the impact of the custom features, we'll first cross-validate using only the training data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc67edac-e7cf-5cc8-f79e-1df5edbeccba"},"outputs":[],"source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, roc_auc_score, f1_score, accuracy_score\n\n# Instantiate logistic regression\nclf = LogisticRegression()\n\n#Cross-validate logistic regression\nprint(\"\\nLogistic regression results for 10-fold cross-validation:\\n\")\nscores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\nprint((\"Accuracies:\\n %s\\n\\n\" +\n       \"Best accuracy on held-out data: %.4f\\n\\n\" +\n       \"Mean accuracy on held-out data: %.4f\\n\\n\") % (str(scores), scores.max(), scores.mean()))\nscores = cross_val_score(clf, X_train, y_train, cv=10, scoring='roc_auc')\nprint((\"AUC:\\n %s\\n\\n\" +\n       \"Best AUC on held-out data: %.4f\\n\\n\" + \n       \"Mean AUC on held-out data: %.4f\\n\\n\") % (str(scores), scores.max(), scores.mean()))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1d6e6f3c-d702-9c23-5823-5f80669fc309"},"source":"Compare the above results to the performance on raw data. The mean AUC increased from 81 to 84%, while the peak scores fell slightly.\n\nNow, we'll see how these features help the model to generalize to the isolated testing set after being given access to the complete training set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d6d13ec-feb5-dd35-2a47-f34484c4da11"},"outputs":[],"source":"clf.fit(X_train, y_train)\npred = clf.predict(X_test)\n\nprint(\"=\"*80)\nprint(\"\\nLogistic regression performance on unseen data:\")\nprint(\"\\nlog-loss: %.4f\" % log_loss(y_test, pred))\nprint(\"\\nAUC: %.4f\" % roc_auc_score(y_test, pred))\nprint(\"\\nF1 score: %.4f\" % f1_score(y_test, pred))\nprint(\"\\nAccuracy: %.4f\" % accuracy_score(y_test, pred))\nprint(\"=\"*80)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ac953672-bfef-a156-8304-160465fbe7b4"},"source":" - Log-loss decreased from 8.24 to 6.65.\n - AUC increased from 70 to 75%.\n - F1-score increased from 59 to 67%.\n - Accuracy increased from 76 to 80%.\n\nAll of the scores improved for this particular train/test split.\n\nWe can change the random seed of the split and see if this performance is consistent with other random splits. (The results are similar with seeds 5 and 10.)\n\nOn that note, I'd like to give a big thanks to Hugues Fontenelle for reminding all of us about the \"luckiness\" of splits. Be sure to check out his notebook, as well.\n\nBest wishes, everyone."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}