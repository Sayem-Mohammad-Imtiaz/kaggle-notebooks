{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/ruruamour/sample-code2-augmentation  \nこのサンプルコードでは少し精度が伸びましたがまだまだ判定精度を上げることができます。  \nこのNotebookでは転移学習という手法を使って簡単に高精度な機械学習モデルを作成します。  \n\n（The above sample code shows a slight increase in accuracy, but the accuracy can still be improved.    \nThis Notebook uses a technique called transfer learning to easily create a highly accurate machine learning model.  ）"},{"metadata":{},"cell_type":"markdown","source":"# 調整パラメータ - Config\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"resize_w = 256  # 画像のリサイズ幅を指定\nresize_h = 256  # 画像のリサイズ高さを指定\nchannel = 3  # 画像のカラーチャンネルを指定\n\ntest_size_rate = 0.100 # データセットをTrain/Testに分割する際の、Test dataの比率（0.0〜1.0）\n\nepochs = 200  # 学習回数を指定\nn_batch = 8  # 一度にまとめて学習するデータ数。\n             # 値が大きいと学習が安定し早く進むが、大きすぎると各データの特徴が平均化されるため逆に学習が進まない。\n             # (GPU計算速度の関係で2のn乗を指定するのがおすすめ)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 前準備 - Preprocess code"},{"metadata":{},"cell_type":"markdown","source":"## Preprocess1. 画像処理関数定義 - Image Processing Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n# 画像が大きいと計算が遅いため、リサイズ縮小\ndef resize(tmp_image):\n    return cv2.resize(tmp_image , (resize_h, resize_w))\n\n# 4次元配列化()　\ndef to_4d(tmp_image):\n    return tmp_image.reshape(1, resize_h, resize_w, channel)   \n\n# 256段階の色調を0.0~1.0にする\ndef normalize(tmp_image):\n    return tmp_image / 255.0\n\ndef adjust(img, alpha=1.0, beta=0.0):\n    # 積和演算を行う。\n    dst = alpha * img + beta\n    return np.clip(dst, 0.0, 255.0)\n\n# 画像の前処理付きロード\ndef load_preprocessed_image(image_filepath):\n    tmp_image = cv2.imread(image_filepath)\n    tmp_image = resize(tmp_image)\n    tmp_image = adjust(tmp_image, 1.3, 40)    \n    tmp_image = normalize(tmp_image)\n    tmp_image = to_4d(tmp_image)\n\n    return tmp_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess2. 画像とラベルのロード - Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nroot_dir = \"/kaggle/input/mj1-anomaly-images-detection-challenge/\"\ntrain_csv_filepath = root_dir + \"train.csv\"\n\n# ファイルの読み込み\ntrain_df = pd.read_csv(train_csv_filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.utils import np_utils\n\nimages = None\nfor fn in train_df['filename']:\n    image_filepath = root_dir + 'train/' + fn\n    tmp_image = load_preprocessed_image(image_filepath)\n    if (images is None):\n        images = tmp_image\n    else:\n        images = np.vstack((images, tmp_image))\n\nanomaly_flags = np.array([flag for flag in train_df['anomaly']])\nanomaly_flags = np_utils.to_categorical(anomaly_flags, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess3. Train/Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=test_size_rate, random_state=0)\n\nfor train_index, test_index in sss.split(images, anomaly_flags):\n    X_train = images[train_index]\n    y_train = anomaly_flags[train_index]\n    X_test = images[test_index]\n    y_test = anomaly_flags[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess4. Over Sampling (不均衡な学習データ数を揃える処理）"},{"metadata":{"trusted":true},"cell_type":"code","source":"# over-samplingを試します。\n\ntmp = pd.DataFrame(y_train[:, 1]).value_counts().values\nprint(tmp)\nlabel_ok_num = tmp[0]\nlabel_ng_num = tmp[1]\n\nwhile(label_ok_num != label_ng_num):\n    rand_index = np.random.randint(0, len(y_train))\n\n    label_is_ng = (y_train[rand_index, 1] == 1.0)\n    if label_is_ng:\n        X_train = np.vstack((X_train, [X_train[rand_index]]))\n        y_train = np.vstack((y_train, [y_train[rand_index]]))\n        label_ng_num += 1\n    print(label_ng_num, end='\\r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess5. Augmantation (画像をランダムに変化させて、学習データにバリエーションをもたせる）"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=360)\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ■-- 転移学習(Transfer Learning)\n\n転移学習は大まかにいうと、「すでに学習済みのオープンな高精度なモデルを流用して、簡単に自分の目的の学習モデルを作る方法」です。  \n\n学習モデルには「1.入力データの特徴を捉える層」と「2.出力結果を推定する層」があり、  \n1の層をそのままにして2の層を自分の目的に合うように差し替えることで転移学習を実現します.  \n\n具体的には  \na. すでに学習済みのオープンな高精度なモデルを用意  \nb. 学習しないようにパラメータ設定  \nc. aの下に「2.出力結果を推定する層」を追加  \nを行います。\n\n---\n\nTransfer learning is, roughly speaking, \"a way to easily create a learning model for your own purposes by appropriating an open, highly accurate model that has already been trained.  \n\nA learning model has two layers: 1. a layer that captures the characteristics of the input data, and 2. a layer that estimates the output results.  \nTransfer learning can be achieved by leaving the first layer as it is and replacing the second layer with the one that suits your purpose.  \n\nSpecifically  \n**a. Prepare an accurate open model that has already been trained.  \nb. Set the parameters so that it does not learn.  \nc. Add \"2. Estimating the output result layer\" under a. ** \n"},{"metadata":{},"cell_type":"markdown","source":"## ※注\n\n学習済モデルのダウンロード  \n> base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(  \n\nの実行時にエラーになる場合があります。  \n\nその場合は、このNoteBook の Internet 設定をオンにすることで、問題が解消されます。  \n詳細は下記のリンクをご確認ください。  \n\nhttps://stackoverflow.com/questions/47378542/kaggle-could-not-download-resnet50-pretrained-model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n# a. すでに学習済みのオープンな高精度なモデルを用意\n# a. Prepare an accurate open model that has already been trained.  \nbase_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n    weights='imagenet',\n    include_top=False,\n    pooling='avg'\n)\n\n# b. 学習しないようにパラメータ設定 \n# b. Set the parameters so that it does not learn.  \nbase_model.trainable = False\n\n# c. aの下に「2.出力結果を推定する層」を追加\n# c. Add \"2. Estimating the output result layer\" under a. \nmodel = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.Dense(1024, activation='relu'), \n    tf.keras.layers.Dense(128, activation='relu'),        \n    tf.keras.layers.Dense(2, activation='softmax')\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Total params: 3,701,186  \n> Trainable params: 1,443,202  \n> Non-trainable params: 2,257,984  \n\nという結果になります。  \nimagenetという汎用的な大規模画像データセットの学習済みモデルを使用しており、様々な画像の特徴が抜き出せるようになっています。  \n転移学習をすることで、「1.入力データの特徴を捉える層」に必要だった2,257,984個のパラメータを学習する手間が省けました。\n\n--- \n\n\nThe results are shown above.\n\nWe have used imagenet, a general-purpose trained model of a large image dataset, which allows us to extract features from various images.  \nBy using transfer learning, we saved the time and effort of learning the 2,257,984 parameters required."},{"metadata":{},"cell_type":"markdown","source":"## 学習〜判定〜結果出力まで。"},{"metadata":{},"cell_type":"markdown","source":"## 学習 - Learning Process"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(datagen.flow(X_train, y_train, batch_size=n_batch),\n                    steps_per_epoch=len(X_train) / n_batch,\n                    epochs=epochs,\n                    validation_data=(X_test, y_test))\n\ntrain_score = model.evaluate(X_train, y_train, verbose=0)\ntest_score = model.evaluate(X_test, y_test, verbose=0)\nprint('Train Loss:{0:.3f}'.format(train_score[0]))\nprint('Train accuracy:{0:.3}'.format(train_score[1]))\nprint('Test Loss:{0:.3f}'.format(test_score[0]))\nprint('Test accuracy:{0:.3}'.format(test_score[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 判定"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nfrom pathlib import Path\n\ntest_images = None\ntest_filenames = None\nfor test_filepath in glob.glob('/kaggle/input/mj1-anomaly-images-detection-challenge/test/*.png'):\n    tmp_image = load_preprocessed_image(test_filepath)\n    if (test_images is None):\n        test_images = tmp_image\n        test_filenames = [Path(test_filepath).name]\n    else:\n        test_images = np.vstack((test_images, tmp_image))\n        test_filenames.append(Path(test_filepath).name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_predict = model.predict(test_images)\nresult_predict = np.argmax(result_predict, axis=1)\nresult_predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 結果をcsvで出力"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_filepath = \"/kaggle/input/mj1-anomaly-images-detection-challenge/sample_submit.csv\"\nsubmit_df = pd.read_csv(submit_filepath, index_col=0)\n\nfor i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\n    \nsubmit_df.to_csv('result_submit.csv')\nsubmit_df[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\nsubmit_df.to_csv('result_submit.csv')\nprint(submit_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}