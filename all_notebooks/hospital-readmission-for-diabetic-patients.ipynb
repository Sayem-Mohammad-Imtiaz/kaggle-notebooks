{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing required packages","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n%config Completer.use_jedi = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/diabetes-readmission-dataset/dataset_diabetes/diabetic_data.csv\")\ndf.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target column\n\ndf.groupby('readmitted').size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.loc[~df.discharge_disposition_id.isin([11, 13, 14, 19, 20, 21])]\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['OUTPUT_LABEL'] = (df.readmitted == '<30').astype('int')\ndf[['OUTPUT_LABEL']].sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for calculating prevalance of population that is readmitted within 30 days\n\ndef cal_prevalance(y_actual):\n    return (sum(y_actual)/len(y_actual))\n\nprint(f\"Prevalance : {round(cal_prevalance(df.OUTPUT_LABEL.values)*100, 3)} %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing '?' with NAN\ndf = df.replace('?', np.nan)\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Collecting Numerical columns\nnum_cols = [\n    'time_in_hospital', 'num_lab_procedures',\n    'num_procedures', 'num_medications',\n    'number_outpatient', 'number_emergency',\n    'number_inpatient', 'number_diagnoses'\n]\nprint('ColName              NullCount')\nprint('=============================')\ndf[num_cols].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Collecting categorical columns\ncat_cols = [\n    'race', 'gender', \n    'max_glu_serum', 'A1Cresult',\n    'metformin', 'repaglinide', \n    'nateglinide', 'chlorpropamide',\n    'glimepiride', 'acetohexamide',\n    'glipizide', 'glyburide',\n    'tolbutamide', 'pioglitazone',\n    'rosiglitazone', 'acarbose',\n    'miglitol', 'troglitazone',\n    'tolazamide', 'insulin',\n    'glyburide-metformin', 'glipizide-metformin',\n    'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n    'metformin-pioglitazone', 'change',\n    'diabetesMed','payer_code'\n]\n\nprint('ColName                    NullCount')\nprint('======================================')\ndf[cat_cols].isnull().sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['race'] = df['race'].fillna('UNK')\ndf['paper_code'] = df['payer_code'].fillna('UNK')\ndf['medical_specialty'] = df['medical_specialty'].fillna('UNK')\n\nprint(f\"# medical specialty : {df.medical_specialty.nunique()}\")\ndf.groupby('medical_specialty').size().sort_values(ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_10 = [\n    'UNK','InternalMedicine',\n    'Emergency/Trauma', 'Family/GeneralPractice',\n    'Cardiology', 'Surgery-General' , \n    'Nephrology', 'Orthopedics',\n    'Orthopedics-Reconstructive', 'Radiologist'\n]\n\ndf['med_spec'] = df['medical_specialty'].copy()\ndf.loc[~df.med_spec.isin(top_10), 'med_spec'] = 'Other'\n\ndf.groupby('med_spec').size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_cat_num = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n\ndf[cols_cat_num] = df[cols_cat_num].astype('str')\ndf_cat = pd.get_dummies(df[cat_cols + cols_cat_num + ['med_spec']], drop_first = True)\n\ndf_cat.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df, df_cat], axis = 1)\n\n# To keep track of the categorical columns\ncols_all_cat = list(df_cat.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using 'age' and 'weight'\n\ndf[['age', 'weight']].sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('age').size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_id = {'[0-10)':0, \n          '[10-20)':10, \n          '[20-30)':20, \n          '[30-40)':30, \n          '[40-50)':40, \n          '[50-60)':50,\n          '[60-70)':60, \n          '[70-80)':70, \n          '[80-90)':80, \n          '[90-100)':90}\ndf['age_group'] = df.age.replace(age_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since 'weight' has lots of NAN values, it is better to use it as whether the paitent_ID has enrolled his/her weight or not\ndf[\"has_weight\"] = df.weight.notnull().astype('int')\n\nextra_cols = [\"age_group\", \"has_weight\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upto this we have created \n\n* Numerical features : 8\n* Categorical features : 132\n* Extra features : 2","metadata":{}},{"cell_type":"code","source":"cols2use = num_cols + cols_all_cat + extra_cols\ndf_data = df[cols2use + ['OUTPUT_LABEL']]  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Training, Validation, Test Sets\n","metadata":{}},{"cell_type":"code","source":"cols2use = [\n    'number_inpatient',\n    'discharge_disposition_id_22',\n    'number_emergency',\n    'number_diagnoses',\n    'num_medications',\n    'time_in_hospital',\n    'num_lab_procedures',\n    'insulin_No',\n    'age_group',\n    'number_outpatient',\n    'discharge_disposition_id_3',\n    'num_procedures',\n]\n\ndf_data = df[cols2use + ['OUTPUT_LABEL']] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split 70:15:15, type = Stratify\n# Shuffling the dataset with random state 42\n\ndf_data = df_data.sample(n = len(df_data), random_state = 42)\ndf_data = df_data.reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_valid_test = df_data.sample(frac = 0.3, random_state = 42)\ndf_test = df_valid_test.sample(frac = 0.3, random_state = 42)\ndf_valid = df_valid_test.drop(df_test.index)\ndf_train_all = df_data.drop(df_valid_test.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test prevalence(n = %d):%.3f'%(len(df_test),cal_prevalance(df_test.OUTPUT_LABEL.values)))\nprint('Valid prevalence(n = %d):%.3f'%(len(df_valid),cal_prevalance(df_valid.OUTPUT_LABEL.values)))\nprint('Train all prevalence(n = %d):%.3f'%(len(df_train_all), cal_prevalance(df_train_all.OUTPUT_LABEL.values)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the training data into positive and negative\nrows_pos = df_train_all.OUTPUT_LABEL == 1\ndf_train_pos = df_train_all.loc[rows_pos]\ndf_train_neg = df_train_all.loc[~rows_pos]\n\n# merge the balanced data\ndf_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n\n# shuffle the order of training samples \ndf_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n\nprint('Train balanced prevalence(n = %d):%.3f'%(len(df_train), cal_prevalance(df_train.OUTPUT_LABEL.values)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train[cols2use].values\nX_train_all = df_train_all[cols2use].values\nX_valid = df_valid[cols2use].values\n\ny_train = df_train['OUTPUT_LABEL'].values\ny_valid = df_valid['OUTPUT_LABEL'].values\n\nprint('Training All shapes:',X_train_all.shape)\nprint('Training shapes:',X_train.shape, y_train.shape)\nprint('Validation shapes:',X_valid.shape, y_valid.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nimport pickle\n\nss = StandardScaler()\nss.fit(X_train_all)\n\nscalerfile = 'StndSclr.sav'\npickle.dump(ss, open(scalerfile, 'wb'))\n\n# load it back\nss = pickle.load(open(scalerfile, 'rb'))\n\nX_train_tf = ss.transform(X_train)\nX_valid_tf = ss.transform(X_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building and testing models","metadata":{}},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating helper functions\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n\ndef calc_specificity(y_actual, y_pred, thresh):\n    # calculates specificity\n    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n\ndef print_report(y_actual, y_pred, thresh):\n    \n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    precision = precision_score(y_actual, (y_pred > thresh))\n    specificity = calc_specificity(y_actual, y_pred, thresh)\n    print('AUC:%.3f'%auc)\n    print('accuracy:%.3f'%accuracy)\n    print('recall:%.3f'%recall)\n    print('precision:%.3f'%precision)\n    print('specificity:%.3f'%specificity)\n    print('prevalence:%.3f'%cal_prevalance(y_actual))\n    print(' ')\n    return auc, accuracy, recall, precision, specificity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresh = 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors = 100)\nknn.fit(X_train_tf, y_train)\n\ny_train_preds = knn.predict_proba(X_train_tf)[:,1]\ny_valid_preds = knn.predict_proba(X_valid_tf)[:,1]\n\nprint('KNN')\nprint('Training:')\nknn_train_auc, knn_train_accuracy, knn_train_recall, \\\nknn_train_precision, knn_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nknn_valid_auc, knn_valid_accuracy, knn_valid_recall, \\\nknn_valid_precision, knn_valid_specificity = print_report(y_valid,y_valid_preds, thresh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(random_state = 42)\nlr.fit(X_train_tf, y_train)\n\ny_train_preds = lr.predict_proba(X_train_tf)[:,1]\ny_valid_preds = lr.predict_proba(X_valid_tf)[:,1]\n\nprint('Logistic Regression')\nprint('Training:')\nlr_train_auc, lr_train_accuracy, lr_train_recall, \\\n    lr_train_precision, lr_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nlr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n    lr_valid_precision, lr_valid_specificity = print_report(y_valid,y_valid_preds, thresh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Navie Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(X_train_tf, y_train)\n\ny_train_preds = nb.predict_proba(X_train_tf)[:,1]\ny_valid_preds = nb.predict_proba(X_valid_tf)[:,1]\n\nprint('Naive Bayes')\nprint('Training:')\nnb_train_auc, nb_train_accuracy, nb_train_recall, nb_train_precision, nb_train_specificity =print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nnb_valid_auc, nb_valid_accuracy, nb_valid_recall, nb_valid_precision, nb_valid_specificity = print_report(y_valid,y_valid_preds, thresh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(max_depth = 10, random_state = 42)\ntree.fit(X_train_tf, y_train)\n\ny_train_preds = tree.predict_proba(X_train_tf)[:,1]\ny_valid_preds = tree.predict_proba(X_valid_tf)[:,1]\n\nprint('Decision Tree')\nprint('Training:')\ntree_train_auc, tree_train_accuracy, tree_train_recall, tree_train_precision, tree_train_specificity =print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\ntree_valid_auc, tree_valid_accuracy, tree_valid_recall, tree_valid_precision, tree_valid_specificity = print_report(y_valid,y_valid_preds, thresh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest Classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier(max_depth = 6, random_state = 42)\nrf.fit(X_train_tf, y_train)\n\ny_train_preds = rf.predict_proba(X_train_tf)[:,1]\ny_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n\nprint('Random Forest')\nprint('Training:')\nrf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity =print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nrf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, rf_valid_specificity = print_report(y_valid,y_valid_preds, thresh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_results = pd.DataFrame({'classifier':['KNN','KNN','LR','LR','NB','NB','DT','DT','RF','RF',],\n                           'data_set':['train','valid']*5,\n                          'auc':[knn_train_auc, knn_valid_auc,lr_train_auc,lr_valid_auc,nb_train_auc,nb_valid_auc,tree_train_auc,tree_valid_auc,rf_train_auc,rf_valid_auc,],\n                          'accuracy':[knn_train_accuracy, knn_valid_accuracy,lr_train_accuracy,lr_valid_accuracy,nb_train_accuracy,nb_valid_accuracy,tree_train_accuracy,tree_valid_accuracy,rf_train_accuracy,rf_valid_accuracy,],\n                          'recall':[knn_train_recall, knn_valid_recall,lr_train_recall,lr_valid_recall,nb_train_recall,nb_valid_recall,tree_train_recall,tree_valid_recall,rf_train_recall,rf_valid_recall,],\n                          'precision':[knn_train_precision, knn_valid_precision,lr_train_precision,lr_valid_precision,nb_train_precision,nb_valid_precision,tree_train_precision,tree_valid_precision,rf_train_precision,rf_valid_precision,],\n                          'specificity':[knn_train_specificity, knn_valid_specificity,lr_train_specificity,lr_valid_specificity,nb_train_specificity,nb_valid_specificity,tree_train_specificity,tree_valid_specificity,rf_train_specificity,rf_valid_specificity,]})\n\ndf_results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"darkgrid\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18, 7))\nax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=df_results)\nax.set_xlabel('Classifier',fontsize = 15)\nax.set_ylabel('AUC', fontsize = 15)\nax.tick_params(labelsize=15)\n\n# Put the legend out of the figure\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\nplt.show()\nplt.savefig(\"Model Comparision.jpeg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train/test splits.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"AUC\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = 'roc_auc')\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"b\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"b\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title = \"Learning Curves (Random Forest)\"\n# Cross validation with 5 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\nestimator = RandomForestClassifier(max_depth = 6, random_state = 42)\nplot_learning_curve(estimator, title, X_train_tf, y_train, ylim=(0.2, 1.01), cv=cv, n_jobs=4)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"markdown","source":"### LR","metadata":{}},{"cell_type":"code","source":"feature_importances = pd.DataFrame(lr.coef_[0],\n                                   index = cols2use,\n                                    columns=['importance']).sort_values('importance',\n                                                                        ascending=False)\n\nfeature_importances.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 12\nylocs = np.arange(num)\n# get the feature importance for top num and sort in reverse order\nvalues_to_plot = feature_importances.iloc[:num].values.ravel()[::-1]\nfeature_labels = list(feature_importances.iloc[:num].index)[::-1]\n\nplt.figure(num=None, figsize=(8, 15), dpi=80, facecolor='w', edgecolor='k');\nplt.barh(ylocs, values_to_plot, align = 'center')\nplt.ylabel('Features')\nplt.xlabel('Importance Score')\nplt.title('Positive Feature Importance Score - Logistic Regression')\nplt.yticks(ylocs, feature_labels)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values_to_plot = feature_importances.iloc[-num:].values.ravel()\nfeature_labels = list(feature_importances.iloc[-num:].index)\n\nplt.figure(num=None, figsize=(8, 15), dpi=80, facecolor='w', edgecolor='k');\nplt.barh(ylocs, values_to_plot, align = 'center')\nplt.ylabel('Features')\nplt.xlabel('Importance Score')\nplt.title('Negative Feature Importance Score - Logistic Regression')\nplt.yticks(ylocs, feature_labels)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RFC","metadata":{}},{"cell_type":"code","source":"feature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = cols2use,\n                                    columns=['importance']).sort_values('importance',\n                                                                        ascending=False)\n\nfeature_importances.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 12\nylocs = np.arange(num)\n# get the feature importance for top num and sort in reverse order\nvalues_to_plot = feature_importances.iloc[:num].values.ravel()[::-1]\nfeature_labels = list(feature_importances.iloc[:num].index)[::-1]\n\nplt.figure(num=None, figsize=(8, 15), dpi=80, facecolor='w', edgecolor='k');\nplt.barh(ylocs, values_to_plot, align = 'center')\nplt.ylabel('Features')\nplt.xlabel('Importance Score')\nplt.title('Feature Importance Score - Random Forest')\nplt.yticks(ylocs, feature_labels)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances[:12]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_features = [\n    'number_inpatient',\n    'discharge_disposition_id_22',\n    'number_emergency',\n    'number_diagnoses',\n    'num_medications',\n    'time_in_hospital',\n    'num_lab_procedures',\n    'insulin_No',\n    'age_group',\n    'number_outpatient',\n    'discharge_disposition_id_3',\n    'num_procedures',\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparamet Tuning","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# number of trees\nn_estimators = range(200,1000,200)\n# maximum number of features to use at each split\nmax_features = ['auto','sqrt']\n# maximum depth of the tree\nmax_depth = range(1,10,1)\n# minimum number of samples to split a node\nmin_samples_split = range(2,10,2)\n# criterion for evaluating a split\ncriterion = ['gini','entropy']\n\n# random grid\n\nrandom_grid = {'n_estimators':n_estimators,\n              'max_features':max_features,\n              'max_depth':max_depth,\n              'min_samples_split':min_samples_split,\n              'criterion':criterion}\n\nprint(random_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import make_scorer, roc_auc_score\nauc_scoring = make_scorer(roc_auc_score)\n\n# create the randomized search cross-validation\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                               n_iter = 20, cv = 2, scoring=auc_scoring,\n                               verbose = 1, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the random search model (this will take a few minutes)\nt1 = time.time()\nrf_random.fit(X_train_tf, y_train)\nt2 = time.time()\nprint(t2-t1)\n\nrf_random.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_preds = rf.predict_proba(X_train_tf)[:,1]\ny_valid_preds = rf.predict_proba(X_valid_tf)[:,1]\n\nprint('Baseline Random Forest')\nrf_train_auc_base = roc_auc_score(y_train, y_train_preds)\nrf_valid_auc_base = roc_auc_score(y_valid, y_valid_preds)\n\nprint('Training AUC:%.3f'%(rf_train_auc_base))\nprint('Validation AUC:%.3f'%(rf_valid_auc_base))\n\nprint('Optimized Random Forest')\ny_train_preds_random = rf_random.best_estimator_.predict_proba(X_train_tf)[:,1]\ny_valid_preds_random = rf_random.best_estimator_.predict_proba(X_valid_tf)[:,1]\n\nrf_train_auc = roc_auc_score(y_train, y_train_preds_random)\nrf_valid_auc = roc_auc_score(y_valid, y_valid_preds_random)\n\nprint('Training AUC:%.3f'%(rf_train_auc))\nprint('Validation AUC:%.3f'%(rf_valid_auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Downloading Model","metadata":{}},{"cell_type":"code","source":"pickle.dump(rf_random.best_estimator_, open('reAdmissionDiabeticsModel.pkl', 'wb'),protocol = 4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"X_test = df_test[cols2use].values\ny_test = df_test['OUTPUT_LABEL'].values\n\nscaler = pickle.load(open('./StndSclr.sav', 'rb'))\nX_test_tf = scaler.transform(X_test)\n\nbest_model = pickle.load(open('./reAdmissionDiabeticsModel.pkl','rb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[cols2use]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_preds = best_model.predict_proba(X_train_tf)[:,1]\ny_valid_preds = best_model.predict_proba(X_valid_tf)[:,1]\ny_test_preds = best_model.predict_proba(X_test_tf)[:,1]\n\nthresh = 0.5\n\nprint('Training:')\ntrain_auc, train_accuracy, train_recall, train_precision, train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nvalid_auc, valid_accuracy, valid_recall, valid_precision, valid_specificity = print_report(y_valid,y_valid_preds, thresh)\nprint('Test:')\ntest_auc, test_accuracy, test_recall, test_precision, test_specificity = print_report(y_test,y_test_preds, thresh)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve \n\nfpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_preds)\nauc_train = roc_auc_score(y_train, y_train_preds)\n\nfpr_valid, tpr_valid, thresholds_valid = roc_curve(y_valid, y_valid_preds)\nauc_valid = roc_auc_score(y_valid, y_valid_preds)\n\nfpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_preds)\nauc_test = roc_auc_score(y_test, y_test_preds)\n\nplt.figure(figsize = (20, 7))\nplt.plot(fpr_train, tpr_train, 'r-',label ='Train AUC:%.3f'%auc_train)\nplt.plot(fpr_valid, tpr_valid, 'b-',label ='Valid AUC:%.3f'%auc_valid)\nplt.plot(fpr_test, tpr_test, 'g-',label ='Test AUC:%.3f'%auc_test)\nplt.plot([0,1],[0,1],'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols2use","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vals = []\nfor v in range(len(cols2use)):\n    vals.append([])\nvals","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict(zip(cols2use, vals))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(cols2use)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_tf[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}