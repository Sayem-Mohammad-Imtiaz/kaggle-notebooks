{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"review_df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nreview_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_word(word):\n    word = word.lower().strip()\n    return word\n\ndef get_tokens(sentence):\n    tokens = [normalize_word(token) for token in sentence.split(' ') if token ]\n    return [token for token in tokens if token]\n\nvocab = []\nall_reviews = review_df.review.to_list()\nvocab = []\nfor review in all_reviews:\n    vocab.extend(get_tokens(review))\nvocab = list(set(vocab))\nprint('total vocab:', len(vocab))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2index = {}\nfor index, word in enumerate(vocab):\n    word2index[word] = index\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data = []\nfor review in all_reviews:\n    tokens = get_tokens(review)\n    sentence2index = []\n    for token in tokens:\n        sentence2index.append(word2index[token])\n    input_data.append(sentence2index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_data = []\nlabels = review_df.sentiment.to_list()\ntarget_data = [1 if label == 'positive' else 0 for label in labels]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('input data length:', len(input_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\n\ndef sigmoid(x):\n    return 1/(1 + np.exp(-x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nalpha, iterations = (0.01, 2)\nhidden_size = 100\n\nweights_0_1 = 0.2 * np.random.random((len(vocab), hidden_size)) - 0.1\nweights_1_2 = 0.2 * np.random.random((hidden_size, 1)) - 0.1\n\ncorrect, total = (0, 0)\nfor iteration in range(iterations):\n    for i in range(len(input_data) -1000):\n        x,y = (input_data[i], target_data[i])\n        \n        #embed + sigmoid\n        layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n        \n        #linear + softmax\n        layer_2 = sigmoid(np.dot(layer_1, weights_1_2))\n        \n        layer_2_delta = layer_2 - y\n        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n        \n        weights_0_1[x] -= layer_1_delta * alpha\n        weights_1_2 -= np.outer(layer_1, layer_2_delta) * alpha\n        \n        if np.abs(layer_2_delta) < 0.5:\n            correct += 1\n        total += 1\n        \n#         print(i)\n        if (i%10) == 9:\n            progress = str(i/float(len(input_data) - 1000) * 100)\n            sys.stdout.write('\\rIter:'+str(iteration)\\\n                        +' Progress:'+ str(progress)\\\n                        +'% Training Accuracy:'\\\n                        + str(correct/float(total) * 100)[0:5] + '%'\n                            )\n#     break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct, total = (0, 0)\nfor i in range(len(input_data)-1000,len(input_data)):\n    x, y = (input_data[i], target_data[i])\n    \n    layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n    layer_2 = sigmoid(np.dot(layer_1, weights_1_2))\n    if(np.abs(layer_2 - y) < 0.5):\n        correct += 1\n    total += 1\nprint(\"Test Accuracy:\" + str(correct / float(total))) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nimport math\n\ndef get_word_similarity(target_word):\n    target_index = word2index[target_word]\n    scores = Counter()\n    for word, index in word2index.items():\n        raw_difference = weights_0_1[index] - weights_0_1[target_index]\n        sqrt_difference = raw_difference**2\n        scores[word] = -math.sqrt(sum(sqrt_difference))\n    return scores.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_word_similarity('beautiful')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_word_similarity('terrible')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_word_similarity('cool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}