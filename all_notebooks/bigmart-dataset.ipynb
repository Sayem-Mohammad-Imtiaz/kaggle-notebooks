{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/bigmart-sales-data/Train.csv\")\npred_df = pd.read_csv(\"../input/bigmart-sales-data/Test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ohe(df, col):\n    label_encoder = LabelEncoder()\n    label_encoded = label_encoder.fit_transform(df[col]).reshape(-1, 1)\n    one_hot_encoder = OneHotEncoder(sparse = False)\n    column_names = [col + \"_\" + str(i) for i in label_encoder.classes_]\n    one_hot_encoded = one_hot_encoder.fit_transform(label_encoded)\n    return pd.DataFrame(one_hot_encoded, columns = column_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def standarize(df):\n    standard_scaler = StandardScaler()\n    return standard_scaler.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data(df):\n    # Delete this feature because it has a big percentage of missing values\n    # del df[\"Outlet_Size\"]\n    df[\"Outlet_Identifier\"] = df[\"Outlet_Identifier\"].astype(\"category\")\n    df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].astype(\"category\")\n    df[\"Item_Type\"] = df[\"Item_Type\"].astype(\"category\")\n    df[\"Outlet_Location_Type\"] = df[\"Outlet_Location_Type\"].astype(\"category\")\n    df[\"Outlet_Type\"] = df[\"Outlet_Type\"].astype(\"category\")\n    df[\"Outlet_Establishment_Year\"] = df[\"Outlet_Establishment_Year\"].astype(\"category\")\n    ###################################################\n    os = df[[\"Outlet_Type\", \"Outlet_Size\"]].groupby(\"Outlet_Type\").apply(lambda x:x.mode())\n    miss_bool = df['Outlet_Size'].isnull()\n    df.loc[miss_bool,'Outlet_Size'] = df.loc[miss_bool,'Outlet_Type'].apply(lambda x: os.loc[x][\"Outlet_Size\"][0])\n    df[\"Outlet_Size\"] = df[\"Outlet_Size\"].astype(\"category\")\n    #################################################\n    # Replace the missing values with the mean each item identifier\n    im = df[[\"Item_Identifier\", \"Item_Weight\"]].groupby(\"Item_Identifier\").mean()\n    miss_bool = df['Item_Weight'].isnull() \n    df.loc[miss_bool,'Item_Weight'] = df.loc[miss_bool,'Item_Identifier'].apply(lambda x: im.loc[x])\n    df[\"Item_Weight\"].fillna(df[\"Item_Weight\"].mean(), inplace = True)\n    ###############################################\n    # Replace 0 item visibility with the mean of the item visibility of each item\n    iv = df[[\"Item_Identifier\", \"Item_Visibility\"]].groupby(\"Item_Identifier\").mean()\n    miss_bool = df['Item_Visibility'] == 0\n    df.loc[miss_bool, \"Item_Visibility\"] = df.loc[miss_bool, \"Item_Identifier\"].apply(lambda x: iv.loc[x])\n    ######################################################\n    df[\"Item_Visibility_MeanRatio\"] = df.apply(lambda x: x[\"Item_Visibility\"]/ iv.loc[x[\"Item_Identifier\"]],axis = 1)\n    ##################################################\n    #df[\"Item_Identifier\"] = df[\"Item_Identifier\"].astype(\"category\")\n    del df[\"Item_Identifier\"]\n    categorical_df = df.select_dtypes(include = \"category\")\n    for column in categorical_df.columns:\n        temp = ohe(df, column)\n        del df[column]\n        df = pd.concat([df, temp], axis = 1)\n    # Standardization\n    # df = standarize(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(df):\n    model = Sequential()\n    #model.add(Dense(1024,input_dim = df.shape[1], activation = \"relu\"))\n    model.add(Dense(512, input_dim = df.shape[1], activation = \"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(128, activation = \"relu\"))\n    model.add(Dropout(0.05))\n    model.add(Dense(64, activation = \"relu\"))\n    model.add(Dense(32, activation = \"relu\"))\n    model.add(Dense(16, activation = \"relu\"))\n    model.add(Dense(8, activation = \"relu\"))\n    model.add(Dense(1, activation = \"linear\"))\n    model.compile(loss = \"mean_squared_error\" , optimizer = \"adam\", metrics = [\"mean_squared_error\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = train_df[\"Item_Outlet_Sales\"]\ndel train_df[\"Item_Outlet_Sales\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = process_data(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = get_model(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = KerasRegressor(build_fn= lambda : get_model(train_df), epochs = 30, batch_size = 32, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = cross_val_score(estimator, train_df, train_target, scoring=\"neg_mean_squared_error\", cv = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model.fit(train_df, train_target, epochs = 30, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"identifiers = pred_df[[\"Item_Identifier\", \"Outlet_Identifier\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = process_data(pred_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = my_model.predict(pred_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.concat([identifiers, pd.DataFrame(pred, columns=[\"Item_Outlet_Sales\"])], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df[\"Item_Outlet_Sales\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df[\"Item_Outlet_Sales\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df[\"Item_Identifier\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Item_Type\"] = df[\"Item_Type\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outlet_Identifier\"] = df[\"Outlet_Identifier\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete this feature because it has a big percentage of missing values\ndel df[\"Outlet_Size\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outlet_Location_Type\"] = df[\"Outlet_Location_Type\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outlet_Type\"] = df[\"Outlet_Type\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace the missing values with the mode of the feature\ndf[\"Item_Weight\"] = df[\"Item_Weight\"].fillna(df[\"Item_Weight\"].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outlet_Establishment_Year\"] = df[\"Outlet_Establishment_Year\"].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_df = df.select_dtypes(include = \"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ohe(df, col):\n    label_encoder = LabelEncoder()\n    label_encoded = label_encoder.fit_transform(df[col]).reshape(-1, 1)\n    one_hot_encoder = OneHotEncoder(sparse = False)\n    column_names = [col + \"_\" + str(i) for i in label_encoder.classes_]\n    one_hot_encoded = one_hot_encoder.fit_transform(label_encoded)\n    return pd.DataFrame(one_hot_encoded, columns = column_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in categorical_df.columns:\n    temp = ohe(df, column)\n    del df[column]\n    df = pd.concat([df, temp], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    model = Sequential()\n    model.add(Dense(512,input_dim = df.shape[1], activation = \"relu\"))\n    model.add(Dense(256,  activation = \"relu\"))\n    model.add(Dense(128, activation = \"relu\"))\n    model.add(Dense(64, activation = \"relu\"))\n    model.add(Dense(32, activation = \"relu\"))\n    model.add(Dense(16, activation = \"relu\"))\n    model.add(Dense(8, activation = \"relu\"))\n    model.add(Dense(1, activation = \"linear\"))\n    model.compile(loss = \"mean_squared_error\" , optimizer = \"adam\", metrics = [\"mean_squared_error\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = KerasRegressor(build_fn=get_model, epochs = 30, batch_size = 32, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = cross_val_score(estimator, df.values, target.values, scoring = \"neg_mean_squared_error\", cv = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = get_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model.fit(df.values, target.values, epochs = 30, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = to_predict.groupby(by = [\"Item_Identifier\", \"Outlet_Identifier\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(to_predict[\"Item_Identifier\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_predict.shape[0] - x.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(x[\"Item_Identifier\"] == \"FDW58\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}