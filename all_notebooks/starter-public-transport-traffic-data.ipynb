{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 2 csv files in the current version of the dataset:\n"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's check 1st file: /kaggle/input/Regularities_by_liaisons_Trains_France.csv"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# Regularities_by_liaisons_Trains_France.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('/kaggle/input/Regularities_by_liaisons_Trains_France.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'Regularities_by_liaisons_Trains_France.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a quick look at what the data looks like:"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df1.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's check 2nd file: /kaggle/input/Travel_titles_validations_in_Paris_and_suburbs.csv"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# Travel_titles_validations_in_Paris_and_suburbs.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf2 = pd.read_csv('/kaggle/input/Travel_titles_validations_in_Paris_and_suburbs.csv', delimiter=',', nrows = nRowsRead)\ndf2.dataframeName = 'Travel_titles_validations_in_Paris_and_suburbs.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a quick look at what the data looks like:"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df2.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check the third file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import\n\nfrom geopandas.tools import geocode\nimport pandas as pd\nimport geopandas as gpd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly = gpd.read_file('/kaggle/input/Station_shapefiles.shp', SHAPE_RESTORE_SHX='YES')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's merge with df2\n\ndf2.merge(poly, how='left', right_on='id_refa_ld', left_on='ID_REFA_LDA')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have the means of transport associated with each station (station_ty) and its polygon. We have also a second name column wich gives a more precise information."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}