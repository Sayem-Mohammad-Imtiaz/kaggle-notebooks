{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Version note","metadata":{}},{"cell_type":"markdown","source":"# Setup for Notebook","metadata":{}},{"cell_type":"markdown","source":"## Import libaries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport os\nfrom sklearn.model_selection import GroupKFold\nimport cv2\nimport PIL.Image as Image\n\nprint('Setup Completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Global value","metadata":{}},{"cell_type":"code","source":"iou_thr = 0.5\nskip_box_thr = 0.03\nsigma = 0.1\n\niou_thr_large = 0.4\nskip_box_thr_large = 0.03\nsigma = 0.1\n\nclass_large = [0, 1, 3, 4, 12]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Global function","metadata":{}},{"cell_type":"code","source":"def Preprocessing(input_path, output_path):\n    #Example image\n    #Read image\n    img = cv2.imread(input_path)\n    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    #Histogram Equlization\n    # create a CLAHE object\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    cl1 = clahe.apply(gray_image)\n    img_f = cv2.cvtColor(cl1, cv2.COLOR_GRAY2BGR)\n    \n    #Normalization\n    norm_img = np.zeros((800,800))\n    n_img = cv2.normalize(img_f,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    \n    final_image = Image.fromarray(n_img)\n    final_image.save(output_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{}},{"cell_type":"code","source":"#Define folder path (Custom)\nTEST_DIR = '/kaggle/input/vinbigdata-640pixel/test_vin.csv'\n#Read csv\ntest_df = pd.read_csv(TEST_DIR)\ndisplay(test_df.head())\nimage_ids = test_df.image_id.unique()\nprint(f'Number of tets image: {len(image_ids)} ')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Image path\ninput_path = '/kaggle/input/vinbigdata-640pixel/Test'\noutput_path = '/kaggle/working/testimage'\nos.makedirs('/kaggle/working/testimage', exist_ok = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"for idx in tqdm(image_ids, total = len(image_ids)):\n    origin_image_path = os.path.join(input_path,idx+'.jpg')\n    output_image_path = os.path.join(output_path, idx +\".jpg\")\n    Preprocessing(origin_image_path, output_image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Yolov5 Predict","metadata":{}},{"cell_type":"code","source":"#cloning yolov5 model\n!git clone https://github.com/ultralytics/yolov5\n\n#cloning NVIDIA/apex to speed up the process\n!git clone https://github.com/NVIDIA/apex.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom IPython.display import Image, clear_output  # to display images\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv yolov5/* ./\n!pip install -r requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source /kaggle/working/data/images/zidane.jpg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename='/kaggle/working/runs/detect/exp/zidane.jpg', width=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ensemble-boxes\nfrom ensemble_boxes import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimage_id_list = []\nlabel_id_list = []\nconf_id_list = []\nx_id_list = []\ny_id_list = []\nw_id_list = []\nh_id_list = []\nfold_list = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fold 0","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights /kaggle/input/weight/best_fold0.pt --img 640 --conf 0.01 --iou 0.5 --source /kaggle/working/testimage --save-txt --save-conf --augment","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor file_path in tqdm(glob('runs/detect/exp2/labels/*txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w = test_df[test_df.image_id == image_id].width.values[0]\n    h = test_df[test_df.image_id == image_id].height.values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    for i in range(len(data)):\n        image_id_list.append(image_id)\n        label_id_list.append(data[i,0])\n        conf_id_list.append(data[i,1])\n        x_id_list.append(data[i,2])\n        y_id_list.append(data[i,3])\n        w_id_list.append(data[i,4])\n        h_id_list.append(data[i,5])\n        fold_list.append(0)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fold 1","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights /kaggle/input/weight/best_fold1.pt --img 640 --conf 0.01 --iou 0.5 --source /kaggle/working/testimage --save-txt --save-conf --augment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file_path in tqdm(glob('runs/detect/exp3/labels/*txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w = test_df[test_df.image_id == image_id].width.values[0]\n    h = test_df[test_df.image_id == image_id].height.values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    for i in range(len(data)):\n        image_id_list.append(image_id)\n        label_id_list.append(data[i,0])\n        conf_id_list.append(data[i,1])\n        x_id_list.append(data[i,2])\n        y_id_list.append(data[i,3])\n        w_id_list.append(data[i,4])\n        h_id_list.append(data[i,5])\n        fold_list.append(1)\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fold 2","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights /kaggle/input/weight/best_fold2.pt --img 640 --conf 0.01 --iou 0.5 --source /kaggle/working/testimage --save-txt --save-conf --augment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file_path in tqdm(glob('runs/detect/exp4/labels/*txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w = test_df[test_df.image_id == image_id].width.values[0]\n    h = test_df[test_df.image_id == image_id].height.values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    for i in range(len(data)):\n        image_id_list.append(image_id)\n        label_id_list.append(data[i,0])\n        conf_id_list.append(data[i,1])\n        x_id_list.append(data[i,2])\n        y_id_list.append(data[i,3])\n        w_id_list.append(data[i,4])\n        h_id_list.append(data[i,5])\n        fold_list.append(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fold 3","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights /kaggle/input/weight/best_fold3.pt --img 640 --conf 0.01 --iou 0.5 --source /kaggle/working/testimage --save-txt --save-conf --augment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file_path in tqdm(glob('runs/detect/exp5/labels/*txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w = test_df[test_df.image_id == image_id].width.values[0]\n    h = test_df[test_df.image_id == image_id].height.values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    for i in range(len(data)):\n        image_id_list.append(image_id)\n        label_id_list.append(data[i,0])\n        conf_id_list.append(data[i,1])\n        x_id_list.append(data[i,2])\n        y_id_list.append(data[i,3])\n        w_id_list.append(data[i,4])\n        h_id_list.append(data[i,5])\n        fold_list.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fold 4","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights /kaggle/input/weight/best_fold4.pt --img 640 --conf 0.01 --iou 0.5 --source /kaggle/working/testimage --save-txt --save-conf --augment","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for file_path in tqdm(glob('runs/detect/exp6/labels/*txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w = test_df[test_df.image_id == image_id].width.values[0]\n    h = test_df[test_df.image_id == image_id].height.values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    for i in range(len(data)):\n        image_id_list.append(image_id)\n        label_id_list.append(data[i,0])\n        conf_id_list.append(data[i,1])\n        x_id_list.append(data[i,2])\n        y_id_list.append(data[i,3])\n        w_id_list.append(data[i,4])\n        h_id_list.append(data[i,5])\n        fold_list.append(4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns =['image_id', 'label', 'conf', 'x_mid', 'y_mid', 'w', 'h','fold']\nsubmit_df = pd.DataFrame(list(zip(image_id_list, label_id_list,conf_id_list,x_id_list,y_id_list,w_id_list,h_id_list,fold_list)),\n               columns =columns)\ndisplay(submit_df.tail())\nprint(submit_df.shape)\ncsv_path = os.path.join('/kaggle/working','result_vin'+'.csv')\nsubmit_df.to_csv(csv_path,index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number image of Fold 0: ')\nprint(len(submit_df[submit_df['fold']==1].image_id.unique()))\nprint('Number image of Fold 1: ')\nprint(len(submit_df[submit_df['fold']==1].image_id.unique()))\nprint('Number image of Fold 2: ')\nprint(len(submit_df[submit_df['fold']==2].image_id.unique()))\nprint('Number image of Fold 3: ')\nprint(len(submit_df[submit_df['fold']==3].image_id.unique()))\nprint('Number image of Fold 4: ')\nprint(len(submit_df[submit_df['fold']==4].image_id.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nfor image_id in tqdm(image_ids, total=len(image_ids)):\n    data = submit_df[submit_df[\"image_id\"] == image_id]\n    data = data.reset_index(drop=True)\n    annotations = {}\n    weights = []\n    for idx, row in data.iterrows():\n        fold_id = row['fold']\n        if fold_id not in annotations:\n            annotations[fold_id] = {\n                \"boxes_list\": [],\n                \"scores_list\": [],\n                \"labels_list\": [],\n                \"boxes_list_large\": [],\n                \"scores_list_large\": [],\n                \"labels_list_large\": [],\n            }\n            weights.append(1.0)\n        x_mid = row['x_mid']\n        y_mid = row['y_mid']\n        w = row['w']\n        h = row['h']\n        x1 = x_mid - w/2\n        y1 = y_mid - h/2\n        x2 = x_mid + w/2\n        y2 = y_mid + h/2\n        if row[\"label\"] in class_large:\n            annotations[fold_id][\"boxes_list_large\"].append([x1, y1, x2, y2])\n            annotations[fold_id][\"scores_list_large\"].append(row['conf'])\n            annotations[fold_id][\"labels_list_large\"].append(row[\"label\"])\n        else:\n            annotations[fold_id][\"boxes_list\"].append([x1, y1, x2, y2])\n            annotations[fold_id][\"scores_list\"].append(row['conf'])\n            annotations[fold_id][\"labels_list\"].append(row[\"label\"])\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n    boxes_list_large = []\n    scores_list_large = []\n    labels_list_large = []\n    for annotator in annotations.keys():\n        boxes_list.append(annotations[annotator][\"boxes_list\"])\n        scores_list.append(annotations[annotator][\"scores_list\"])\n        labels_list.append(annotations[annotator][\"labels_list\"])\n        boxes_list_large.append(annotations[annotator][\"boxes_list_large\"])\n        scores_list_large.append(annotations[annotator][\"scores_list_large\"])\n        labels_list_large.append(annotations[annotator][\"labels_list_large\"])\n    boxes, scores, labels = weighted_boxes_fusion(\n        boxes_list,\n        scores_list,\n        labels_list,\n        weights=weights,\n        iou_thr=iou_thr,\n        skip_box_thr=skip_box_thr\n    )\n    boxes_large, scores_large, labels_large = weighted_boxes_fusion(\n        boxes_list_large,\n        scores_list_large,\n        labels_list_large,\n        weights=weights,\n        iou_thr=iou_thr_large,\n        skip_box_thr=skip_box_thr_large\n    )\n    for idx, box in enumerate(boxes):\n        results.append({\n            \"image_id\": image_id,\n            \"class_id\": int(labels[idx]),\n            \"conf\": scores[idx],\n            \"x_min\": box[0],\n            \"y_min\": box[1],\n            \"x_max\": box[2],\n            \"y_max\": box[3],\n        })\n    for idx, box in enumerate(boxes_large):\n        results.append({\n            \"image_id\": image_id,\n            \"class_id\": int(labels_large[idx]),\n            \"conf\": scores_large[idx],\n            \"x_min\": box[0],\n            \"y_min\": box[1],\n            \"x_max\": box[2],\n            \"y_max\": box[3],\n        })\nFinal_df = pd.DataFrame(results)\ndisplay(Final_df.head())\nprint(f'Size of Final_df Dataframe: {Final_df.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = submit_df[submit_df[\"image_id\"] == '002a34c58c5b758217ed1f584ccbcfe9']\ndisplay(k)\np = Final_df[Final_df[\"image_id\"] == '002a34c58c5b758217ed1f584ccbcfe9']\ndisplay(p)\nprint(len(Final_df.class_id.unique()))\nprint(len(Final_df.image_id.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_path = os.path.join('/kaggle/working','result_vin'+'.csv')\nFinal_df.to_csv(csv_path,index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}