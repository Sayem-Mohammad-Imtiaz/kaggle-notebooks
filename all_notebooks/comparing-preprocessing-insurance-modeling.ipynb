{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e30a1e92495a95249c937f2d355bf6a69dcf5f96"},"cell_type":"code","source":"df = pd.read_csv('../input/insurance.csv')\nx = df.copy()\nprint(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f79afa302d70e79292e2be3cd4fc275af571c34d"},"cell_type":"code","source":"#Checking for null values\n\nl = list(x.isnull().sum())\nprint(x.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3de756e8c809e27b176c1c4dfd2d436c74f630a8"},"cell_type":"markdown","source":"**Here we are comparing the LabelEncoder Pre - Processing type with Get-dummies preprocessing method for Medical Insurance Dataset **"},{"metadata":{"trusted":true,"_uuid":"3553145304210f9f949cbc158b595da356695a14"},"cell_type":"code","source":"#Data pre- processing process for Type 1 Data\n\ntemp = pd.get_dummies(x['sex'],prefix = 'sex')\ndel x['sex']\nx = pd.concat([x,temp], axis = 1)\n\ntemp = pd.get_dummies(x['smoker'],prefix = 'smoker')\ndel x['smoker']\nx = pd.concat([x,temp], axis = 1)\n\ntemp = pd.get_dummies(x['region'],prefix = 'region')\ndel x['region']\nx = pd.concat([x,temp], axis = 1)\n\nt = x['charges'].copy()\ndel x['charges']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"470029b6e49ff9267db9af8f0d4952d3eb02dbd3"},"cell_type":"code","source":"#Deleting the columns which having 95% of zeros which will not effect the model accuracy\n\nv = x.copy()\nvar = list(v.columns)\n\nfor i in range(0,12):\n    count = 0\n    for j in range(0,1339):\n        l = list(x[var[i]])\n        count = l.count(0)\n    if(count > 1275 or (j - count) > 63):\n        del v[var[i]]\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57e9f61e9b0ef88eaaf65cce5bf03db0731b373d"},"cell_type":"code","source":"# checking correlation for data preprocessed using get_dummies method  for Type 1 Data\n\ncorr = v.corr()\nsm.graphics.plot_corr(corr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31fff1588ed862f40657038069d1f8cc2e7c08df"},"cell_type":"code","source":"#Removing highly correlated variable from the dataset for Type 1 Data\n\nX = v.copy()\nvar2 = list(X.columns)\nthresh = 5\nfor i in np.arange(0,len(var2)):\n    vif = [variance_inflation_factor(X[var2].values, ix) for ix in range(x[var2].shape[1])]\n    maxloc = vif.index(max(vif))\n    if max(vif) > thresh:\n        x1 = var2[maxloc]\n        del X[x1]\n        var2 = list(X.columns)\n    else:\n        break\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c74cd0ace24571509d8f87792597ee661e66e715"},"cell_type":"code","source":"# checking correlation for Type 1 Data after removing unwanted columns\ncorr = X.corr()\nsm.graphics.plot_corr(corr)\nplt.show()\nprint(var2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60060352e839b3a64d990b9120fb60fab572c900"},"cell_type":"code","source":"#Data pre- processing process for Type 2 Data using Labelencoder\n\nf = df.copy()\ndel f['charges']\nlb = LabelEncoder()\nf['sex'] = lb.fit_transform(f['sex'])\nf['smoker'] = lb.fit_transform(f['smoker'])\nf['region'] = lb.fit_transform(f['region'])\nprint(f.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a87162b8b638b088206393b54078cb578e4d5d94"},"cell_type":"code","source":"#checking corrleation for data pre-processed using Type 2 Data Label encoder\n\ncorr = f.corr()\nsm.graphics.plot_corr(corr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69d8690826c5ee329b419618cb122af7dfa407a8"},"cell_type":"code","source":"#Splitting data in to Train and test for modeling purpose using type 1 data\n\nx_train1,x_test1,y_train1,y_test1 = train_test_split(v,t, test_size = 0.2,random_state = 1)\nprint(np.shape(x_train1),np.shape(x_test1),np.shape(y_train1),np.shape(y_test1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfde66e32205d7b228f8b17cde2f2a84c7cfdae8"},"cell_type":"code","source":"#Splitting data in to Train and test for modeling purpose using type 2 data\n\nx_train2,x_test2,y_train2,y_test2 = train_test_split(f,t, test_size = 0.2,random_state = 1)\nprint(np.shape(x_train2),np.shape(x_test2),np.shape(y_train2),np.shape(y_test2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e37aae13827c55b0c82f01b873177c9749017cb1"},"cell_type":"code","source":"#Model creation using type 1 data\n\nlr1 = LinearRegression()\nlr1.fit(x_train1,y_train1)\n\nde1 = DecisionTreeRegressor()\nde1.fit(x_train1,y_train1)\n\nre1 = RandomForestRegressor(max_leaf_nodes=20,n_estimators = 100)\nre1.fit(x_train1,y_train1)\n\nsr1 = SVR(kernel = 'linear', C = 100000, degree = 2, gamma = 'auto')\nsr1.fit(x_train1,y_train1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1424629d75dc63d65f52c42223460f22a5411494"},"cell_type":"code","source":"#Model creation using type 2 data\n\nlr2 = LinearRegression()\nlr2.fit(x_train2,y_train2)\n\nde2 = DecisionTreeRegressor( max_depth = 15)\nde2.fit(x_train2,y_train2)\n\nre2 = RandomForestRegressor(max_leaf_nodes=20,n_estimators = 100)\nre2.fit(x_train2,y_train2)\n\nsr2 = SVR(kernel = 'linear', C = 100000, degree = 2, gamma = 'auto')\nsr2.fit(x_train2,y_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e196ba6810a5f065c165e9068264b8ee403d8eb7"},"cell_type":"code","source":"print('------Linear Regression--Type 1 Data---')\nprint('Training score : ', r2_score(lr1.predict(x_train1),y_train1))\nprint('Testing score : ', r2_score(lr1.predict(x_test1),y_test1))\n\nprint('------Linear Regression--Type 2 Data---')\nprint('Training score : ', r2_score(lr2.predict(x_train2),y_train2))\nprint('Testing score : ', r2_score(lr2.predict(x_test2),y_test2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d384365095ebc09e07930bb075b9ea08b4834cc0"},"cell_type":"code","source":"print('------Decision Tree Regression--Type 1 Data---')\nprint('Training score : ', r2_score(de1.predict(x_train1),y_train1))\nprint('Testing score : ', r2_score(de1.predict(x_test1),y_test1))\n\nprint('------Decision Tree Regression--Type 2 Data---')\nprint('Training score : ', r2_score(de2.predict(x_train2),y_train2))\nprint('Testing score : ', r2_score(de2.predict(x_test2),y_test2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f835868f1ce2145058dbe515519e638b8bc986d"},"cell_type":"code","source":"print('------Random Forest Regression--Type 1 Data---')\nprint('Training score : ', r2_score(re1.predict(x_train1),y_train1))\nprint('Testing score : ', r2_score(re1.predict(x_test1),y_test1))\n\nprint('------Random Forest Regression--Type 2 Data---')\nprint('Training score : ', r2_score(re2.predict(x_train2),y_train2))\nprint('Testing score : ', r2_score(re2.predict(x_test2),y_test2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7a03b2dd032dd6a654a600a749d846557cda4dc"},"cell_type":"code","source":"print('------Support vector Regression---Type 1 Data--')\nprint('Training score : ', r2_score(sr1.predict(x_train1),y_train1))\nprint('Testing score : ', r2_score(sr1.predict(x_test1),y_test1))\n\nprint('------Support vector Regression---Type 2 Data--')\nprint('Training score : ', r2_score(sr2.predict(x_train2),y_train2))\nprint('Testing score : ', r2_score(sr2.predict(x_test2),y_test2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e3ffbc1431d3849c73e7ea9b92fc30d747e7c4b"},"cell_type":"markdown","source":"***By considering above result,  Type 2 data (pre-processed using LabelEncoder Method) suits good for  this data set.\nRandom Forest Regression Algorithm suits good for this data set Modeling.***"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}