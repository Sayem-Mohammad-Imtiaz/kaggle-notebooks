{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare pytest for unit testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ipytest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pytest\nimport ipytest\n\nipytest.autoconfig()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_grouped=pd.read_csv('../input/corona-virus-report/full_grouped.csv')\n\nonly_death = full_grouped[['Date', 'Country/Region', 'New deaths']]\nonly_death = only_death[only_death['Country/Region'] == 'United Kingdom']\nonly_death = only_death[['Date', 'New deaths']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check that all dates and New deaths in dataset are valid"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%run_pytest[clean]\n\ndef test_valid_dates():\n    assert((pd.to_datetime(only_death['Date']).isnull() == True).any() == False)\n    \ndef test_valid_new_deaths():\n    assert((only_death['New deaths'].isnull() == True).any() == False)\n    assert((only_death['New deaths'] < 0).any() == False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDataset = only_death.sample(frac=0.8,random_state=0)\ntestDataset = only_death.drop(trainDataset.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\ntrainInput = pd.Series([datetime.datetime.strptime(\n    d, '%Y-%m-%d') for d in trainDataset['Date']])\nstart_date = trainInput.min()\ntrainInput = pd.Series(\n    [(d - start_date) / datetime.timedelta(days=1) for d in trainInput])\ntrainTarget = trainDataset['New deaths']\ntestInput = pd.Series(\n    [(datetime.datetime.strptime(d, '%Y-%m-%d') - start_date) /\n     datetime.timedelta(days=1) for d in testDataset['Date']]\n)\ntestTarget = testDataset['New deaths']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n      keras.layers.Dense(1, use_bias=True, input_shape=(1,))\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = keras.optimizers.Adam(\n    learning_rate=0.01, beta_1=0.9, beta_2=0.99, epsilon=1e-05, amsgrad=False,\n    name='Adam')\n  \n# Model compiling settings\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['mae','mse'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"n_idle_epochs = 100\nearlyStopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=n_idle_epochs, min_delta=0.01\n)\n\nn_epochs = 200\nhistory = model.fit(\n    trainInput, trainTarget, batch_size=10,\n    epochs=n_epochs, validation_split=0.1, verbose=1, callbacks=[earlyStopping]\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# The fit model returns the history object for each Keras model\n# Let's explore what is inside history\nprint('keys:', history.history.keys())\n\n# Returning the desired values for plotting and turn to numpy array\nmae = np.asarray(history.history['mae'])\nval_mae = np.asarray(history.history['val_mae'])\n\n# Creating the data frame\nnum_values = (len(mae))\nvalues = np.zeros((num_values,2), dtype=float)\nvalues[:,0] = mae\nvalues[:,1] = val_mae\n\n# Using pandas to frame the data\nsteps = pd.RangeIndex(start=0,stop=num_values)\ndata = pd.DataFrame(values, steps, columns=[\"training-mae\", \"val-mae\"])\n\n# Plotting\nplt.figure(figsize=(20,10))\nplt.plot(data['training-mae'], label='train')\nplt.plot(data['val-mae'], label='validation')\nplt.title('Training and validation loss', fontsize=18)\nplt.ylabel('Loss', fontsize=18)\nplt.xlabel('Epoch', fontsize=18)\nplt.legend(prop={'size': 18})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(testInput).flatten()\nmetric = keras.metrics.MeanAbsoluteError()\nmetric.update_state(predictions, testTarget)\nmetric.result().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\nlayer = model.get_layer('dense')\nw1,w0 = layer.get_weights()\nw1 = float(w1[0])\nw0 = float(w0[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pd.to_datetime(only_death['Date']),\n         only_death['New deaths'], 'g', label=\"real\")\nonly_death['Linear'] = (pd.to_datetime(\n    only_death['Date']) - start_date) / datetime.timedelta(days=1) * w1 + w0\nplt.plot(pd.to_datetime(\n    only_death['Date']), only_death['Linear'], 'b', marker='.', label=\"linear\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Polynomial regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\nfrom keras.layers import Input, Dense\nfrom keras.optimizers import Adam\n\ntrX, trY = pd.to_datetime(only_death['Date']), only_death['New deaths']\ntrX = (trX - trX.min()) / datetime.timedelta(days = 1)\ntrX, trY = trX/trX.max(), trY/trY.max()\n\n\ntrs, models = [], []\nns = [3, 5, 10, 15]\nfor n in ns:\n    poly = PolynomialFeatures(n)\n\n\n    trX_expanded = np.expand_dims(trX, axis=1)\n    trX_expanded = poly.fit_transform(trX_expanded)\n    \n    graph = tf.Graph()\n    inp = Input((n+1)) \n\n    out = Dense(1)(inp)\n    model = keras.Model(inputs=inp, outputs=out)\n    model.compile(optimizer=Adam(lr=1e-3), loss=\"mean_squared_error\")\n\n    model.fit(trX_expanded, trY, epochs=500)\n    models.append(model)\n    trs.append(trX_expanded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nplt.plot(pd.to_datetime(only_death['Date']),\n         only_death['New deaths'], 'g', label=\"real\")\n\ncolors = ['violet', 'blue', 'yellow', 'orange']\ndates = pd.to_datetime(only_death['Date'])\n\npolynomial_predictions = []\nfor m, n, trX_expanded, c in zip(models, ns, trs, colors):\n    polynomial_predictions.append(\n        m.predict(trX_expanded) * only_death['New deaths'].max())\n    plt.plot(dates, polynomial_predictions[-1], c, label=f'polynomial {n}')\nplt.plot(pd.to_datetime(\n    only_death['Date']), only_death['Linear'], 'cyan', marker='.', label=\"linear\")\nplt.ylabel('New deaths', fontsize=18)\nplt.xlabel('Date', fontsize=18)\nplt.legend(prop={'size': 18})\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Long short-term memory (LSTM)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nrcParams['figure.figsize'] = 16, 10\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cases_by_date(data, country):\n    if country not in np.unique(data['Country/Region']):\n        return\n    data = data[data['Country/Region'] == country][['New deaths']]\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = only_death['Date']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pd.to_datetime(dates),\n         only_death['New deaths'], label='Deaths by date')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"res = np.array(only_death['New deaths']).flatten()\ndates = np.array(dates).flatten()\ndf = pd.DataFrame(dict(dead=res), index=dates, columns=['dead'])\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(df) * 0.8) \ntest_size = len(df) - train_size\ntrain, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(X, y, time_steps=1):\n    Xs, ys = [], []\n    for i in range(len(X) - time_steps):\n        v = X.iloc[i:(i + time_steps)].values\n        Xs.append(v)        \n        ys.append(y.iloc[i + time_steps])\n    return np.array(Xs), np.array(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_steps = 1\n\n# reshape to [samples, time_steps, n_features]\nprint(train.iloc[: time_steps].values)\nprint(train.iloc[: time_steps])\nX_train, y_train = create_dataset(train, train.dead, time_steps)\nX_test, y_test = create_dataset(test, test.dead, time_steps)\nprint(train)\nprint(X_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(keras.layers.LSTM(128, input_shape=(\n    X_train.shape[1], X_train.shape[2])))\nmodel.add(keras.layers.Dense(1))\nmodel.compile(loss='mean_squared_error',\n              optimizer=keras.optimizers.Adam(0.001))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    X_train, y_train, \n    epochs=100, \n    batch_size=1, \n    validation_split=0.1, \n    verbose=1, \n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training and validation loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='validation')\nplt.title('Training and validation loss', fontsize=18)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test predicted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%run_pytest[clean]\n\ndef test_predict():\n    assert ((y_pred < 0).any() == False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pd.to_datetime(dates[:len(y_train)]), y_train, 'g', label=\"previous\")\nplt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_test, marker='.', label=\"true\")\nplt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train) + len(y_test)]), y_pred, 'r', label=\"prediction\")\nplt.title('Prediction on the background of previous values')\nplt.ylabel('New deaths')\nplt.xlabel('Date')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_test, 'magenta', marker='.', label=\"true\")\nplt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_pred, 'r', label=\"prediction\")\nfor m, n, trX_expanded, c in zip(models, ns, trs, colors):\n    plt.plot(\n        pd.to_datetime(\n            dates[len(y_train):len(y_train)+len(y_test)]\n        ),\n        m.predict(trX_expanded)[len(y_train):len(\n            y_train)+len(y_test)] * only_death['New deaths'].max(),\n        c,\n        linestyle=':',\n        label=f'polynomial {n}')\nplt.plot(\n    pd.to_datetime(dates[len(y_train):len(y_train) +\n                         len(y_test)]),\n    only_death['Linear'][len(y_train):len(y_train)+len(y_test)],\n    'cyan',\n    linestyle=':',\n    label='linear'\n)\n\nplt.title('Prediction against the true values')\nplt.ylabel('New deaths')\nplt.xlabel('Date')\nplt.xticks(rotation=40)\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models MAE comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"metric = keras.metrics.MeanAbsoluteError()\nmetric.update_state(y_pred, y_test)\n# only_death['Linear'][len(y_train):len(y_train)+len(y_test)]\nprint(F'LSTM MAE: {metric.result():.2f}')\nmetric.update_state(only_death['Linear'][len(\n    y_train):len(y_train)+len(y_test)], y_test)\nprint(F'Linear regression MAE: {metric.result():.2f}')\n\ngraph = tf.Graph()\nfor m, n, trX_expanded, pred in zip(models, ns, trs, polynomial_predictions):\n    metric.update_state(np.array(pred).flatten()[\n                        len(y_train):len(y_train)+len(y_test)], y_test)\n    print('Polynomial {} regression MAE {:.2f}'\n          .format(n, metric.result()\n                  )\n          )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Relation between steps count and prediction accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(df) * 0.8) \ntest_size = len(df) - train_size\ntrain, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_steps = [2, 3, 4, 5, 10]\n\n# reshape to [samples, time_steps, n_features]\ntrain_list, test_list = [], []\n\nfor t in time_steps:\n    X_train, y_train = create_dataset(train, train.dead, t)\n    X_test, y_test = create_dataset(test, test.dead, t)\n    train_list.append((X_train, y_train))\n    test_list.append((X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\n\nfor X_train, y_train in train_list:\n    model = keras.Sequential()\n    model.add(keras.layers.LSTM(128, input_shape=(\n    X_train.shape[1], X_train.shape[2])))\n    model.add(keras.layers.Dense(1))\n    model.compile(loss='mean_squared_error',\n              optimizer=keras.optimizers.Adam(0.001))\n\n    model.fit(\n        X_train, y_train, \n        epochs=100, \n        batch_size=1, \n        validation_split=0.1, \n        verbose=1, \n        shuffle=False\n    )\n    \n    y_pred = model.predict(X_test)\n    predictions.append(y_pred)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), y_test, 'magenta', marker='.', label=\"true\")\n\nfor p, c, s in zip(predictions, colors + ['black'], time_steps):\n    plt.plot(pd.to_datetime(dates[len(y_train):len(\n    y_train)+len(y_test)]), p, c, linestyle=':', label=f'steps {s}')\n\nplt.title('Predictions comparison')\nplt.ylabel('New deaths')\nplt.xlabel('Date')\nplt.xticks(rotation=40)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph = tf.Graph()\n\nfor p, step in zip(predictions, time_steps):\n    metric.update_state(np.array(p).flatten(), y_test)\n    print('Step {} LSTM MAE {:.2f}'\n          .format(step, metric.result()\n                  )\n          )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}