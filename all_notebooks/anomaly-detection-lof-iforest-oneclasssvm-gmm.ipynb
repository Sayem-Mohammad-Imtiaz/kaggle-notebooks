{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/nab/realKnownCause/realKnownCause/ec2_request_latency_system_failure.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're looking at the CPU usage data from a server in Amazon's East Coast datacenter.\n\n25% of the values are below 43, 50% are below 45 and 75% are below 46. We can see that the maximum value is 99"},{"metadata":{"trusted":true},"cell_type":"code","source":"#changing timestamp to datetime value\n\ndf['timestamp']=pd.to_datetime(df['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting values\n\nimport plotly.express as px\n\npx.line(df,x='timestamp',y='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see 3 clear outliers from this graph. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hour']=df['timestamp'].dt.hour\npx.box(df,x='hour',y='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lot of outliers are present at 3 AM."},{"metadata":{"trusted":true},"cell_type":"code","source":"px.histogram(df['value'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import OneClassSVM\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use EM (Excess Mass) score to evaluate the performance of unsupervised anomaly detection.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import auc\n\n#Source:https://github.com/ngoix/EMMV_benchmarks/blob/master/em.py\n\ndef em(t, t_max, volume_support, s_unif, s_X, n_generated):\n    EM_t = np.zeros(t.shape[0])\n    n_samples = s_X.shape[0]\n    s_X_unique = np.unique(s_X)\n    EM_t[0] = 1.\n    for u in s_X_unique:\n        # if (s_unif >= u).sum() > n_generated / 1000:\n        EM_t = np.maximum(EM_t, 1. / n_samples * (s_X > u).sum() -\n                          t * (s_unif > u).sum() / n_generated\n                          * volume_support)\n    amax = np.argmax(EM_t <= t_max) + 1\n    if amax == 1:\n        print(\"failed to achieve t_max\")\n        amax = -1\n    AUC = auc(t[:amax], EM_t[:amax])\n    return AUC, EM_t, amax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters of the algorithm:\nn_generated = 100000\nt_max = 0.9\n\nlim_inf = df['value'].values.min(axis=0)\nlim_sup = df['value'].values.max(axis=0)\nvolume_support = (lim_sup - lim_inf).prod()\nt = np.arange(0, 100 / volume_support, 0.01 / volume_support)\nunif = np.random.uniform(lim_inf, lim_sup,size=(n_generated, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One Class SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"one_svm=OneClassSVM()\none_svm_result=one_svm.fit_predict(df['value'].values.reshape(-1,1))\none_svm_result_df=pd.DataFrame()\none_svm_result_df['timestamp']=df['timestamp']\none_svm_result_df['value'] = df['value']\n\n#Inliers are labeled 1, while outliers are labeled -1.\none_svm_result_df['anomaly']  = [1 if i==-1 else 0 for i in one_svm_result]\ns_X_ocsvm = one_svm.decision_function(df['value'].values.reshape(-1,1)).reshape(1, -1)[0]\ns_unif_ocsvm = one_svm.decision_function(unif).reshape(1, -1)[0]\nauc_ocsvm, em_ocsvm, amax_ocsvm = em(t, t_max, volume_support,s_unif_ocsvm, s_X_ocsvm, n_generated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will store the EM values for all the models in a list\n\nem_values=[]\nmodel_name=[]\nem_values.append(em_ocsvm.mean())\nmodel_name.append(\"One Clas SVM\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_svm_result_df['anomaly'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=one_svm_result_df['timestamp'], y=one_svm_result_df['value'],\n                    mode='lines',\n                    name='lines'))\n\na=one_svm_result_df[one_svm_result_df['anomaly']==1]\n\nfig.add_trace(go.Scatter(x=a.timestamp, y=a.value,\n                    mode='markers',\n                    name='markers'))\n\nfig.update_layout(title='Anomaly detection using One Class SVM')\nfig.show(\"notebook\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_svm_result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like One Class SVM did not do a good job\n\n### Isolation Forest\n\nWe can compute anomaly score of the input samples using the \"decision_function\". The anomaly score is derived from the the average path lengths of the samples in the model.\n\n* The lower, the more abnormal.\n* Negative scores represent outliers, positive scores represent inliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"iso=IsolationForest()\niso_result=iso.fit_predict(df['value'].values.reshape(-1,1))\niso_result_df=pd.DataFrame()\niso_result_df['timestamp']=df['timestamp']\niso_result_df['value'] = df['value']\n\n#Inliers are labeled 1, while outliers are labeled -1.\niso_result_df['anomaly']  = [1 if i==-1 else 0 for i in iso_result]\ns_X_iso = iso.decision_function(df['value'].values.reshape(-1,1)).reshape(1, -1)[0]\ns_unif_iso = iso.decision_function(unif).reshape(1, -1)[0]\nauc_iso, em_iso, amax_iso = em(t, t_max, volume_support,s_unif_iso, s_X_iso, n_generated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"em_values.append(em_iso.mean())\nmodel_name.append(\"Isolation Forest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iso_result_df['anomaly'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=iso_result_df['timestamp'], y=iso_result_df['value'],\n                    mode='lines',\n                    name='lines'))\n\na=iso_result_df[iso_result_df['anomaly']==1]\n\nfig.add_trace(go.Scatter(x=a.timestamp, y=a.value,\n                    mode='markers',\n                    name='markers'))\n\nfig.update_layout(title='Anomaly detection using Isolation Forest')\nfig.show(\"notebook\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"iForest seems to have done a good job.\n\n### Local Outlier Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"lof=LocalOutlierFactor(novelty=True)\nlof.fit(df['value'].values.reshape(-1,1))\nlof_result=lof.predict(df['value'].values.reshape(-1,1))\nlof_result_df=pd.DataFrame()\nlof_result_df['timestamp']=df['timestamp']\nlof_result_df['value'] = df['value']\n\n#Inliers are labeled 1, while outliers are labeled -1.\nlof_result_df['anomaly']  = [1 if i==-1 else 0 for i in lof_result]\n\n#decision_function is not available when novelty=False. If we make novelty=True, then fit_predict\n#is not available\n\n\"\"\"\nThe decision_function method is also defined from the scoring function, \nin such a way that negative values are outliers and non-negative ones are inliers.\n\"\"\"\ns_X_lof = lof.decision_function(df['value'].values.reshape(-1,1))\ns_unif_lof = lof.decision_function(unif).reshape(1, -1)\nauc_lof, em_lof, amax_lof = em(t, t_max, volume_support,s_unif_lof, s_X_lof, n_generated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"em_values.append(em_lof.mean())\nmodel_name.append(\"LOF\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lof_result_df['anomaly'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=lof_result_df['timestamp'], y=lof_result_df['value'],\n                    mode='lines',\n                    name='lines'))\n\na=lof_result_df[lof_result_df['anomaly']==1]\n\nfig.add_trace(go.Scatter(x=a.timestamp, y=a.value,\n                    mode='markers',\n                    name='markers'))\n\nfig.update_layout(title='Anomaly detection using LOF')\nfig.show(\"notebook\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GMM\n\nSource: [Link to Github](https://github.com/rhasanbd/Anomaly-Detection-LOF-IsolationForest-FactMCD-GMM/blob/master/Anomaly%20Detection-LOF-IsolationForest-FastMCD-GMM.ipynb)\n\nTo determine whether a data point is an anomaly we need to compute the log-likelihood of the given data.\n\nWe use the \"score\" method of GMM to compute the per-sample average log-likelihood of the data.\n\nThen, compare the likelihood values with the density threshold.\n\nwe identify the outliers using the first percentile lowest density as the threshold. I.e., approximately 1% of the instances will be flagged as anomalies."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\ngm = GaussianMixture(random_state=0)\ngm.fit(df['value'].values.reshape(-1,1))\n\ndensities = gm.score_samples(df['value'].values.reshape(-1,1))\ndensity_threshold = np.percentile(densities, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gm_result= [-1 if i<density_threshold else 0 for i in densities]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gm_result_df=pd.DataFrame()\ngm_result_df['timestamp']=df['timestamp']\ngm_result_df['value'] = df['value']\n\ngm_result_df['anomaly']  = [1 if i==-1 else 0 for i in gm_result]\ns_X_gm = gm.score_samples(df['value'].values.reshape(-1,1)).reshape(1, -1)[0]\ns_unif_gm = gm.score_samples(unif).reshape(1, -1)[0]\nauc_gm, em_gm, amax_gm = em(t, t_max, volume_support,s_unif_gm, s_X_gm, n_generated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gm_result_df['anomaly'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"em_values.append(em_gm.mean())\nmodel_name.append(\"GMM\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=gm_result_df['timestamp'], y=gm_result_df['value'],\n                    mode='lines',\n                    name='lines'))\n\na=gm_result_df[gm_result_df['anomaly']==1]\n\nfig.add_trace(go.Scatter(x=a.timestamp, y=a.value,\n                    mode='markers',\n                    name='markers'))\n\nfig.update_layout(title='Anomaly detection using GMM')\nfig.show(\"notebook\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_result={}\n\nfinal_result={'Model Name':model_name,'EM Value':em_values}\nfinal_result_df=pd.DataFrame(final_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_result_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Higher EM value corresponds to a better model. In this case, Isolation Forest has performed the best followed by GMM. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}