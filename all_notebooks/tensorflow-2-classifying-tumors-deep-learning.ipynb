{"cells":[{"metadata":{"_cell_guid":"d7031c91-50c2-409e-8f8a-f52ccdb34820","_uuid":"2e6eed6a8fa69909229718941411f9192efc917b"},"cell_type":"markdown","source":"## Using Tensorflow for Classification: ##\n\nTensorflow is Deep Learning Framework from Google. It has become quite popular in recent years and help in putting Neural Network Architecture together\n\nThis kernel is about doing a classification task using Tensorflow. This example uses a DNNClassifier for performing Binary Classification. The data used is **Breast Cancer data from Wisconsin.** This has 32 Columns and 569 rows.\n\nThe classifier used is DNNClassifier.\n "},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas.api.types as ptypes\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"df_wisconsin = pd.read_csv('../input/data.csv')\ndf_wisconsin.columns = df_wisconsin.columns.str.replace('\\s+', '_')  # Replacing column names by _ whereever space id found\nlen(df_wisconsin.columns)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"627bc6c2-d15b-4425-8c5e-07e62c82a492","_uuid":"3f25e7e48ec7f5d6e9c49a89605e0da266608540"},"cell_type":"markdown","source":"**Determining numeric columns from the dataset.**\nFollowing is a strategy to find out which are numeric columns. This is done because, later on when building feature columns, this information will be required."},{"metadata":{"_cell_guid":"30f60ab4-24c1-4292-b643-a75082f21936","collapsed":true,"_uuid":"f181ace31f305b2eb038bb6b4f2d262237ef49ac","trusted":false},"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_wisconsin_numeric = df_wisconsin.select_dtypes(include=numerics) # exclude is another keyword.\n# Looking at the columns of the dataset\nlen(df_wisconsin_numeric.columns)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"616c699b-a855-461d-adab-8f8177f963b6","_uuid":"52f83f358b173f020420321744180d246f9112ee"},"cell_type":"markdown","source":"We observe that there is difference of only one column, which is the **diagnosis** column. This will also be the response or target column. Out of these 32 columns, *id* and *Unnamed:_32* will be ignored.\n\nNumeric columns are for further consideration are:\n\n'radius_mean',\n'texture_mean', \n'perimeter_mean',\n'area_mean',\n'smoothness_mean',\n'compactness_mean', \n'concavity_mean',\n'concave points_mean', \n'symmetry_mean',\n'fractal_dimension_mean',\n'radius_se',\n 'texture_se', \n'perimeter_se', \n 'area_se',\n 'smoothness_se',\n 'compactness_se',\n  'concavity_se',\n  'concave points_se',\n  'symmetry_se',\n  'fractal_dimension_se', \n  'radius_worst',\n  'texture_worst',\n  'perimeter_worst',\n  'area_worst', \n   'smoothness_worst',\n  'compactness_worst', \n   'concavity_worst', \n   'concave points_worst',\n   'symmetry_worst', \n   'fractal_dimension_worst'\n   \n   \n   Above mentioned numeric columns will be normalized."},{"metadata":{"_cell_guid":"3f4c583b-7dc2-49a8-b848-1f4d0aa02168","_uuid":"a20a8acd2b6cb8820e307c531ddbec6ba01cc9b8"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"32fdc3f7-477e-4e97-8ad1-19b8ac00ea13","collapsed":true,"_uuid":"da6257d2928f7eadd39fe8f1a904148a7e4665d7","trusted":false},"cell_type":"code","source":"normalize_columns = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave_points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"82876b89-8087-4821-af55-2b2288219417","_uuid":"127ee59d7b243d6fe918a31e3a8eb55aa8ca5bc6"},"cell_type":"markdown","source":"We observe that Diagnosis is the column which we need to predict on unseen data. \nData seems to be pretty well balanced and possible values are **Benign** and **Malignant**."},{"metadata":{"_cell_guid":"22ca73dc-c7c8-4d86-82a9-b6bcb075feeb","collapsed":true,"_uuid":"b0300324c2123e719f4cba53602c65f3c6d0bb0f","trusted":false},"cell_type":"code","source":"x_values = df_wisconsin.drop(['diagnosis','id','Unnamed:_32'],axis=1) # Getting Predictors\ny_val = df_wisconsin['diagnosis'] # getting response","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9ce3516b-0cb1-4c18-8f72-7c70eceefb6b","collapsed":true,"_uuid":"6ba8475cd9b1cebf55661203f3340c888d6150bb","trusted":false},"cell_type":"code","source":"x_values.head() # Examining x_values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9df31515-128f-4f7c-87f3-26c7ec8e9358","collapsed":true,"_uuid":"97eaf08987c71f786ebe3115c517cf609e409d38","trusted":false},"cell_type":"code","source":"y_val.value_counts() # Checking if the classes are balanced. Seems pretty good.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"248f3325-8d3a-4adc-92b7-9bb0151088b6","collapsed":true,"_uuid":"cd975656eda95021824d276cbf9b8a8b23e17c3b","trusted":false},"cell_type":"code","source":"# Converting Labels to integer form. 'B' and 'M; are represented as 0,1. Since Tensorflow does not accept categorical variables in text form, we are converting to integers.\ndef label_numeric(label):\n    if (label == 'B'):\n        return(0)\n    else:\n        return(1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e95244bc-225b-4374-9392-a9ba899375c8","collapsed":true,"_uuid":"9e57388a24a1ad9059056e0bd73ae4d737ad54bd","trusted":false},"cell_type":"code","source":"y_val_numeric =y_val.apply(label_numeric)\ny_val_numeric.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"03ea8b9d-c309-46f3-91b4-1931cabc9982","_uuid":"e43b213f19d36b44227691db349414a716a632df"},"cell_type":"markdown","source":"A quick check above confirms that things are happening as per the expectation."},{"metadata":{"_cell_guid":"a5406d92-f3be-41cf-99de-b5e51b571255","_uuid":"72e897534a3d23626a3fac714d57cefdf680dd0a"},"cell_type":"markdown","source":"## Performing Training and Testing split ##\nPreparing data for model building and checking. 10 percent of data is kept aside for validation purposes. We will also be performing scaling of data using sklearn's *MinMaxScaler*."},{"metadata":{"_cell_guid":"70612546-fa9d-419a-b7a2-5188e3e537ee","collapsed":true,"_uuid":"a88c75bfc7656b564e78d3bdee77fe24a779487a","trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x_values,y_val_numeric,test_size=0.1,random_state=1234)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)\n#X_train.head()\n# Have a look at the before and after scaling step to understand what transformation has been done to the data.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"00bd434e-8c36-482c-8ca9-d425c5f178de","collapsed":true,"_uuid":"9270179e735c58305eb615f4f1194a962f50d3f9","trusted":false},"cell_type":"code","source":"# Similarly, scaling is performed on test data as well.\nX_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e2e3169b-973b-4309-889f-3ae53b759703","_uuid":"d74a8b422c260fdf3c333e4f99adee969ad3a1a4"},"cell_type":"markdown","source":"### Building feature columns for Tensorflow framework ###\nTensorflow expects feature columns to be built using its api calls. Following is a lengthy way of creating them. Later on, an efficient mechanism is also used. Following is retained as it makes the understanding easier."},{"metadata":{"_cell_guid":"c92542b7-127f-43c6-a802-5828ab72cc7b","collapsed":true,"_uuid":"a31cc088e446101c3beead720d497aa3cbdb2eb9","trusted":false},"cell_type":"code","source":"# Now we have 30 features which will be built in tensorflow framewor. Tensorflow requires these features to be defined as feature columns.\nfc_radius_mean = tf.feature_column.numeric_column('radius_mean')\nfc_texture_mean = tf.feature_column.numeric_column('texture_mean')\nfc_perimeter_mean = tf.feature_column.numeric_column('perimeter_mean')\nfc_area_mean = tf.feature_column.numeric_column('area_mean')\nfc_smoothness_mean = tf.feature_column.numeric_column('smoothness_mean')\nfc_compactness_mean = tf.feature_column.numeric_column('compactness_mean')\nfc_concavity_mean = tf.feature_column.numeric_column('concavity_mean')\nfc_concave_points_mean = tf.feature_column.numeric_column('concave points_mean')\nfc_symmetry_mean = tf.feature_column.numeric_column('symmetry_mean')\nfc_fractal_dimension_mean = tf.feature_column.numeric_column('fractal_dimension_mean')\nfc_radius_se = tf.feature_column.numeric_column('radius_se')\nfc_texture_se = tf.feature_column.numeric_column('texture_se')\nfc_perimeter_se = tf.feature_column.numeric_column('perimeter_se')\nfc_area_se = tf.feature_column.numeric_column('area_se')\nfc_smoothness_se = tf.feature_column.numeric_column('smoothness_se')\nfc_compactness_se = tf.feature_column.numeric_column('compactness_se')\nfc_concavity_se = tf.feature_column.numeric_column('concavity_se')\nfc_concave_points_se = tf.feature_column.numeric_column('concave points_se')\nfc_symmetry_se = tf.feature_column.numeric_column('symmetry_se')\nfc_fractal_dimension_se = tf.feature_column.numeric_column('fractal_dimension_se')\nfc_radius_worst = tf.feature_column.numeric_column('radius_worst')\nfc_texture_worst = tf.feature_column.numeric_column('texture_worst')\nfc_perimeter_worst = tf.feature_column.numeric_column('perimeter_worst')\nfc_area_worst = tf.feature_column.numeric_column('area_worst')\nfc_smoothness_worst = tf.feature_column.numeric_column('smoothness_worst')\nfc_compactness_worst = tf.feature_column.numeric_column('compactness_worst')\nfc_concavity_worst = tf.feature_column.numeric_column('concavity_worst')\nfc_concave_points_worst = tf.feature_column.numeric_column('concave points_worst')\nfc_symmetry_worst = tf.feature_column.numeric_column('symmetry_worst')\nfc_fractal_dimension_worst = tf.feature_column.numeric_column('fractal_dimension_worst')\n#feat_cols = [fc_radius_mean, ..., fc_concave_points_worst, fc_symmetry_worst]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"779a3b23-cefd-410f-bc7c-156cb6b3e170","collapsed":true,"_uuid":"bf7466556fcff2ab3204320afe0846b49f7dc19b","trusted":false},"cell_type":"code","source":"# Efficient way of building feature columns. \n# Please notice that Categorical Columns and Numerical Columns are treated differently.\nfeat_cols = []\ndf = X_train\nfor col in df.columns:\n  if ptypes.is_string_dtype(df[col]): #is_string_dtype is pandas function\n    feat_cols.append(tf.feature_column.categorical_column_with_hash_bucket(col, \n        hash_bucket_size= len(df[col].unique())))\n\n  elif ptypes.is_numeric_dtype(df[col]): #is_numeric_dtype is pandas function\n    feat_cols.append(tf.feature_column.numeric_column(col))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7943319e-96ca-4f41-baa7-2b36ed64cfcb","collapsed":true,"_uuid":"7b8c33584e52be6acc26f34ba03c5823dcd212f3"},"cell_type":"markdown","source":"Having a look at the Feature Columns as below:"},{"metadata":{"_cell_guid":"b4a88175-e58c-40b1-8cb4-57681600bc39","collapsed":true,"_uuid":"cbc5e5a74417e4264d74fa7b54816724b5eeca50","trusted":false},"cell_type":"code","source":"print(feat_cols)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ed7e8138-0af3-4f56-a4d5-de1309260a0b","_uuid":"1c90c79a6bd82c94ce337ddea26a82a010d4e161"},"cell_type":"markdown","source":"### Choosing Classification model, input function and training steps. ###\n*  Classification model -  tf.estimator.DNNClassifier is chosen as the model for training the data.\n*  Input function - Since we have loaded data using Pandas input function, we will use pandas_input_fn. Tensorflow also provides numpy based input function.\n*  epocs and steps - Since these terms are used frequently, it is important to understand the difference between them.\n    Following explanation is taken from Stackoverflow:\n    \n>     In the neural network terminology:\n>         one epoch = one forward pass and one backward pass of all the training examples\n>         batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n>         number of iterations = number of passes, each pass using [batch size] number of examples. To be clear, one pass = one forward pass + one backward pass (we do not count the forward pass and backward pass as two different passes)."},{"metadata":{"_cell_guid":"c82d7335-72fb-4f8c-bd00-8621bf387dd1","collapsed":true,"_uuid":"6bf1434dae4b7469261911186044a25bf1b502a2","trusted":false},"cell_type":"code","source":"classifier = tf.estimator.DNNClassifier(\n        feature_columns=feat_cols,\n        # Two hidden layers of 20 nodes each.\n        hidden_units=[20, 20],\n        # The model must choose between 2 classes.\n        n_classes=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7743658b-e6bb-45d4-af10-96968fce5ebc","collapsed":true,"_uuid":"17181ee96501b1b25acba19b72fd82de958f1c5c","trusted":false},"cell_type":"code","source":"input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=500, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4a788ffc-15df-41d8-bd54-955421f2d0df","_uuid":"b3c551cda25c964ba83d237df25d9cf63d06517e"},"cell_type":"markdown","source":"### Now it is time to train the Classifier ###"},{"metadata":{"_cell_guid":"fb25790a-d81e-48b6-b1c2-bb35a24c0180","collapsed":true,"_uuid":"b721fe3c362763f68450f0abf8c071c0c2bb55b4","trusted":false},"cell_type":"code","source":"classifier.train(input_fn=input_func, steps=10000)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ee1e7ef-aeb7-450c-a67a-05548e8bbcf9","collapsed":true,"_uuid":"6fa5317a3715051c16be103d7c656b76a7fd65e6"},"cell_type":"markdown","source":"Creating an input function for prediction, will be applied on test data. Please note that shuffle parameter is set to False here."},{"metadata":{"_cell_guid":"02a594cf-3d04-40d0-991c-08539be4215c","collapsed":true,"_uuid":"f0f6050d033a60a987c3138a781cfbb35aaa5d13","trusted":false},"cell_type":"code","source":"pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False) # Shuffle should be set as false as we are interested in comparing with actual results.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2384e90d-587c-4172-ae0f-c90bf339f4e7","collapsed":true,"_uuid":"aafebc0176ba8c9c069e39c32da5be121b31a4c6","trusted":false},"cell_type":"code","source":"# Prediction is done here now.\npredictions = list(classifier.predict(input_fn=pred_fn))\npredictions[0]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e5755ee6-a4ff-47a7-a323-9a36407c0c23","_uuid":"c08923850bb77c090ee9f9abf5adcb7403080bde"},"cell_type":"markdown","source":"Since prediction API outputs a number of information, we are taking the required stuff here which is class_ids."},{"metadata":{"_cell_guid":"2364fd7d-f367-4ee3-9bb4-8e3243effe31","collapsed":true,"_uuid":"d2bc20429c916188e05e409a6ad388d6cd6c4c35","trusted":false},"cell_type":"code","source":"final_preds = []\nfor pred in predictions:\n    #info = \"{} {} {}\".format(pred['class_ids'][0], pred['probabilities'][0] , pred['probabilities'][1])\n    final_preds.append(pred['class_ids'][0])\n    #final_preds.append(info)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7fa96f74-1877-4164-8089-ad08be654b18","_uuid":"4554613410d0ccd9dd54bdedd9347084ef0c6b9e"},"cell_type":"markdown","source":"### Evaluating model performance ###\nOnce we have prediction data available with us, we can now compare with the 10% data we have kept aside. As we have kept aside the unseen data, we can be reasonably confident that our model has not overfit. This is important step in machine learning to not to use evaluation data for training a model.\nWe have used classification report, accuracy and confusion matrix to evaluate the model performance."},{"metadata":{"_cell_guid":"245ca76b-df5f-4ecc-ac03-473010d7a20e","collapsed":true,"_uuid":"ccf7ecc4ef74ca087ff5ff168e646b767891bfef","trusted":false},"cell_type":"code","source":"print(classification_report(y_test,final_preds))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddb75319-14fd-4f12-98c9-60d331f15e53","collapsed":true,"_uuid":"df672c79ec7b27e76976e05a465d71ed3b2ca70b","trusted":false},"cell_type":"code","source":"print(confusion_matrix(y_test,final_preds))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c3f3b913-c890-473a-9724-3df2480381bb","collapsed":true,"_uuid":"c9fd382cbbe9509e79bf227970556396e2ccf3ae","trusted":false},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,final_preds, normalize=True, sample_weight=None)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e8308b72-ad00-48fd-8e9e-38b19072408c","collapsed":true,"_uuid":"19e592b77e35d556a08819668f2cb9335ecc043c"},"cell_type":"markdown","source":"We see that out of 57 observations, only 1 is misclassified. This concludes this article of using Tensorflow for classification. ** Happy Model Building! #**\n\n*Note: This has been a good experience using Tensorflow for NN. Hope you liked!*"}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}