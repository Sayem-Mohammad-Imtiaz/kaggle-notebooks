{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 线性回归"},{"metadata":{},"cell_type":"markdown","source":"导入numpy、matplotlib库"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np # 导入numpy库\nimport matplotlib.pyplot as plt # 导入matplotlib库","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"生成需要拟合的线性数据"},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.array([1, 2, 3])\ny = 2 * x + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"第一步：确定模型，定义一个一次函数(即只有一个参数的线性函数)作为预测函数\n\n线性模型 y = wx + b\n\n需要学习的参数是 w 和 b，初始化都为 0"},{"metadata":{},"cell_type":"markdown","source":"### todo1:画出数据点"},{"metadata":{"trusted":false},"cell_type":"code","source":"???","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"定义预测函数"},{"metadata":{"trusted":false},"cell_type":"code","source":"w = 0\nb = 0\ndef predict(x):\n    return w * x + b","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"第二步：定义损失函数，衡量预测值与真实值之间的误差\n\n求该线性回归模型的损失函数，这里使用均方误差除以2，即 $\\frac{1}{2N}\\sum_{i=1}^N{(y\\_predict-y)^2}$"},{"metadata":{},"cell_type":"markdown","source":"### todo2:根据给出的损失函数的公式，写出该损失函数"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_predict = predict(x)\n\ndef MSE(y_predict, y):\n    return ??? # 提示：np.mean的作用就是求平均，这里是把所有的平方差加起来求平均","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"输出当前 w 和 b 下损失函数的值，并尝试不同的 w 和 b"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"MSE(predict(x), y)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### todo3：将循环内更新梯度的部分补全"},{"metadata":{"trusted":false},"cell_type":"code","source":"w = 0\nb = 0\nlearning_rate = .01               \nloss_list = []                    \nfor i in range(50):\n    d_w = (y - predict(x)) @ -x   \n    d_b = np.sum(predict(x) - y)  \n    ???      # 更新w(为了降低loss则减去梯度，增加loss则加上梯度)\n    ???      # 更新b    \n    loss = MSE(predict(x), y)     \n    loss_list.append(loss)        \n    print(\"w: %.4f, b: %.4f, loss: %.4f\" % (w, b, loss))      # 输出更新后的w,b以及loss            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可视化loss每一步变化"},{"metadata":{"trusted":false},"cell_type":"code","source":"???","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 梯度下降"},{"metadata":{},"cell_type":"markdown","source":"### todo4：尝试用梯度下降法对不同的损失函数进行优化，写出目标函数的梯度，尝试不同的初始化参数和学习率"},{"metadata":{},"cell_type":"markdown","source":"定义损失函数并画出"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np # 导入numpy库\nimport matplotlib.pyplot as plt # 导入matplotlib库\n\ndef f(x):                    # 目标(损失)函数               \n    return x ** 4 + x ** 3 - 20 * x ** 2 + x + 1\n\ndef d(x):                    # 梯度 d(x) \n    return ???  \n\nx = np.linspace(-5, 5, 101)  # 画出损失函数                \ny = f(x)\nplt.plot(x, y)\nplt.title(\"loss\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可视化梯度下降过程"},{"metadata":{"trusted":false},"cell_type":"code","source":"from IPython.display import display, clear_output             \nx_start = -2             \nlearning_rate = 0.1      \nstep = 10                \nfor i in range(step):\n    x_start = x_start - learning_rate * d(x_start)         \n    plt.title(\"x: %.4f, y: %.4f\" % (x_start, f(x_start)))  \n    plt.plot(x, y)                                         \n    plt.plot(x_start, f(x_start), 'ro')                     \n    plt.show()\n    clear_output(wait=True)                                \n    plt.pause(0.5)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 思考：刚刚的一次线性函数能否可以将这两类点分开"},{"metadata":{},"cell_type":"markdown","source":"## Keras 搭建 MLP(多层感知机/神经网络)"},{"metadata":{},"cell_type":"markdown","source":"首先我们导入一些必要的库，我们主要会用到keras库。\n- Sequential: keras线性模型框架，可以理解为积木的模板\n- 神经网络中的一些常用层\n    - Dense: 全连接层\n    - Activation：激活层\n    - Flatten: 平铺层（二维转一维）\n    - Dropout：随机失活层\n- 优化器optimizers：优化网络参数"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"from keras.models import Sequential                               \nfrom keras.layers import Dense, Activation, Flatten, Dropout      \nfrom keras.optimizers import SGD                                  \n\nimport numpy as np \nimport matplotlib.pyplot as plt ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型构建"},{"metadata":{"trusted":false},"cell_type":"code","source":"x = np.array([\n    [0, 0],\n    [0, 1],\n    [1, 0],\n    [1, 1]\n])\ny = np.array([1, 0, 0, 1])\n\nmodel = Sequential()                            \nmodel.add(Dense(2))                   \nmodel.add(Activation('sigmoid'))      \nmodel.add(Dense(1))                   \nmodel.add(Activation('sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"编译模型"},{"metadata":{},"cell_type":"markdown","source":"搭建完卷积神经网络后，我们定义一个优化器，用来找到使损失函数最小的权重，这里我们使用SGD优化器。\n最后我们使用二分类的交叉熵作为损失函数，使用准确率作为度量指标，并完成模型的搭建。"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.compile(optimizer = SGD(lr = 1),      \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型训练"},{"metadata":{},"cell_type":"markdown","source":"keras提供了fit函数来进行训练，将训练的输入与输出x,y传给fit函数，指定训练轮数为500轮。"},{"metadata":{"trusted":false},"cell_type":"code","source":"history = model.fit(x, y, epochs=500)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型训练过程可视化"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(history.history[\"loss\"])       \nplt.plot(history.history[\"accuracy\"])        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"输出模型每层权重"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"for layer in model.layers:        \n    print(layer.get_weights())    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### todo5：画出这个 MLP，并标出这些权重是如何对应的（哪条边上的权重）"},{"metadata":{},"cell_type":"markdown","source":"# 用 MLP 识别 MNIST 数据集"},{"metadata":{},"cell_type":"markdown","source":"数据读取 (*这里数据读取时，需要注意路径名是否正确，当添加多个数据集时，input会为每一个数据集建一个文件夹*)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd                                                  \nimport numpy as np  \nmnist_dir = \"../input/youthaiimageclassification/\"\nmnist_train = pd.read_csv(mnist_dir + \"mnist_train.csv\")   \nmnist_test = pd.read_csv(mnist_dir + \"mnist_test.csv\")          \nx_train = np.array(mnist_train.iloc[:, 1:]).reshape(-1, 28, 28)      \ny_train = np.array(mnist_train.iloc[:, 0])                           \nx_test = np.array(mnist_test.iloc[:, 1:]).reshape(-1, 28, 28)        \ny_test = np.array(mnist_test.iloc[:, 0])                             \n\nnum_classes = 10  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"从x_train和y_train的形状可以看到训练数据中包含了60000个数据点，其中输入x是60000张28x28=784像素组成的图像，由于MNIST数据集是灰度图，所以每个像素仅由一个数字表示；输出y是60000个数字，代表了每一张图像对应的数字几。测试数据x_test和y_test中则包含了10000个数据点。"},{"metadata":{},"cell_type":"markdown","source":"数据预处理"},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import Sequential                               \nfrom keras.layers import Dense, Activation, Flatten, Dropout      \nfrom keras.optimizers import SGD                                  \nimport matplotlib.pyplot as plt \nfrom keras.utils import to_categorical\n\nx_train = x_train / 255       \nx_test = x_test / 255          \ny_train = to_categorical(y_train, num_classes)  \ny_test = to_categorical(y_test, num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"原本的输入数据中每个像素是0-255的整数，但是对于神经网络的输入，我们一般希望将输入转化到0-1左右的较小的数字，所以我们将输入数据除以255。另外对于输出数据，我们不再简单的用一个数字来表示。对于多分类问题，我们往往采用独热编码作为输出。keras提供了一个方便的函数to_categorical来完成这个变换。"},{"metadata":{},"cell_type":"markdown","source":"模型构建"},{"metadata":{"trusted":false},"cell_type":"code","source":"model = Sequential()                           \nmodel.add(Flatten(input_shape = (28, 28)))     \nmodel.add(Dense(20, activation = 'relu'))      \nmodel.add(Dense(20, activation = 'relu'))      \nmodel.add(Dense(num_classes, activation = 'softmax')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model = Sequential()                           \nmodel.add(Flatten(input_shape = (28, 28)))     \nmodel.add(Dense(512, activation = 'relu'))     \nmodel.add(Dropout(0.2))                        \nmodel.add(Dense(512, activation = 'relu'))     \nmodel.add(Dropout(0.2))                        \nmodel.add(Dense(num_classes, activation = 'softmax')) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型各层详细信息可视化"},{"metadata":{},"cell_type":"markdown","source":"keras提供了summary函数，方便查看模型每一层的结构，以及参数个数。"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.summary()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型编译"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',   \n              optimizer=\"rmsprop\",               \n              metrics=['accuracy'])              ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型训练、评估"},{"metadata":{"trusted":false},"cell_type":"code","source":"batch_size = 32        \nepochs = 5             \nhistory = model.fit(x_train, y_train, \n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,   \n                    validation_data=(x_test, y_test))  \nscore = model.evaluate(x_test, y_test, verbose=0)      \nprint('Test loss:', score[0])     \nprint('Test accuracy:', score[1]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型预测"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.predict(x_test[0:1]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 用卷积神经网络 CNN 识别 CIFAR-10 数据集"},{"metadata":{},"cell_type":"markdown","source":"模型构建"},{"metadata":{},"cell_type":"markdown","source":"首先我们导入一些必要的库，我们主要会用到keras库。\n- Sequential: keras线性模型框架，可以理解为积木的模板\n- 卷积神经网络中的一些常用层\n    - Dense: 全连接层\n    - Flatten: 平铺层（二维转一维）\n    - Conv2D: 二维卷积层\n    - MaxPooling2D: 二维池化层"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"../input/youthaiimageclassification/cifar10.pkl\", \"rb\") as f:\n    (x_train, y_train), (x_test, y_test) = pickle.load(f)\n\n    \nfrom keras.models import Sequential                               \nfrom keras.layers import Dense, Activation, Flatten, Dropout      \nfrom keras.optimizers import SGD                                 \nimport matplotlib.pyplot as plt \nfrom keras.utils import to_categorical\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\n# 数据预处理\n???  # 训练数据归一化\n???  # 测试数据归一化\nnum_classes = 10         # 数据一共有10类\n???  # 将训练数据的标签独热编码\n???  # 将测试数据的标签独热编码 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型搭建"},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D  \n\nmodel = Sequential()\nmodel.add(Conv2D(16, (5, 5), padding='same',    \n                 input_shape=x_train.shape[1:]))\nmodel.add(Activation('relu'))                   \nmodel.add(Conv2D(32, (5, 5)))                   \nmodel.add(Activation('sigmoid'))                \nmodel.add(MaxPooling2D(pool_size=(2, 2)))      \nmodel.add(Dropout(0.25))                       \n\nmodel.add(Conv2D(64, (5, 5), padding='same'))   \nmodel.add(Activation('relu'))                   \nmodel.add(MaxPooling2D(pool_size=(2, 2)))       \nmodel.add(Dropout(0.25))                        \n\nmodel.add(Flatten())\nmodel.add(Dense(100))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\n# 模型编译\nmodel.compile(loss='categorical_crossentropy',  \n              optimizer=\"adam\",                 \n              metrics=['accuracy'])             ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"模型训练"},{"metadata":{"trusted":false},"cell_type":"code","source":"'''\nbatch_size = 32               \nepochs = 5                    \nhistory = model.fit(x_train, y_train,                  \n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,                                     \n                    validation_data=(x_test, y_test))   \nscore = model.evaluate(x_test, y_test, verbose=0)       \nprint('Test loss:', score[0])                           \nprint('Test accuracy:', score[1])                       \n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### todo6:自己搭建一个卷积神经网络进行 CIFAR-10 数据集识别"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":4}