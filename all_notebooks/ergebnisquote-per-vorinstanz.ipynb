{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Verfahrensergebnisse pro Vorinstanz\n\nstrafrechtliche (6B) und strafprozessuale (1B) Bundesgerichtsurteile\n\nvon 1.1.2011 bis 30.5.2021\n\n*Die Auswertung basiert auf einer Grundlage, die nicht frei von Fehlern ist!*\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"}},{"cell_type":"code","source":"import pandas as pd\n\njahre = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\nkammern = ['1B', '6B']\n\ndef urteilsdatenframe_erstellen(kammern, jahre):\n    df_list = []\n    for i in range(len(kammern)):\n        for y in range(len(jahre)):\n            df = pd.read_csv('/kaggle/input/bger6b2018/'+ kammern[i] + '_' + str(jahre[y]) + '.csv')\n            df = df.drop(columns=['Unnamed: 0'])\n            df_list.append(df)\n    big_list = pd.concat(df_list)\n    return big_list\n\nalle = urteilsdatenframe_erstellen(kammern, jahre)\n\n# Urteil mit falschem Datum korrigieren\nalle.loc[alle.Verfahrensnummer == '6B_844/2018', 'Urteilsdatum'] = '13.09.2019'\n\nalle['Urteilsdatum'] = pd.to_datetime(alle['Urteilsdatum'], errors='coerce', format='%d.%m.%Y')\n\nmax_dt = alle[\"Urteilsdatum\"].max().strftime('%d.%m.%Y')\nmax_dt_nr = alle.loc[alle[\"Urteilsdatum\"] == max_dt, 'Verfahrensnummer']\n\nprint(f'Auswertung von insgesamt '+ str(alle.shape[0]) + ' online veröffentlichten Urteilen. Das jüngste Urteil datiert vom ' + str(max_dt) + ' (' + str(max_dt_nr.values) + ').')\n ","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:15.807264Z","iopub.execute_input":"2021-05-30T10:22:15.807697Z","iopub.status.idle":"2021-05-30T10:22:16.951493Z","shell.execute_reply.started":"2021-05-30T10:22:15.807655Z","shell.execute_reply":"2021-05-30T10:22:16.950836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datenbereinigung","metadata":{}},{"cell_type":"markdown","source":"Korrektur von **Vorinstanzen**","metadata":{}},{"cell_type":"code","source":"vorinstanz_error = alle[alle['Vorinstanz'].str.contains(\"#\")]\nprint(f'Bei ' + str(vorinstanz_error.shape[0]) + ' Urteilen konnte der Auswertungsalgorithmus die Vorinstanz nicht eruieren und gab eine Fehlermeldung zurück. Diese Lücken werden in der Folge mit einem verifizierten Korrekturdatensatz korrigert.')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:16.952765Z","iopub.execute_input":"2021-05-30T10:22:16.953086Z","iopub.status.idle":"2021-05-30T10:22:16.974587Z","shell.execute_reply.started":"2021-05-30T10:22:16.953059Z","shell.execute_reply":"2021-05-30T10:22:16.973965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vorinstanzkorrektur(pfad=f'/kaggle/input/bger6b2018/val_sets/straf/vorinstanzkorrektur.csv'):\n    try:\n        korr_vor = pd.read_csv(pfad)\n        print(f'Von {pfad} wurden {korr_vor.shape[0]} Vorinstanzkorrekturen eingelesen.')\n        korrekturcount = 0\n        for i in range(korr_vor.shape[0]):\n            urteilsnummer = korr_vor.iloc[i, 1]\n            if urteilsnummer in alle['Verfahrensnummer'].unique():\n                korrekturcount += 1\n                vorinstanz = korr_vor.iloc[i, 2]\n                alle.loc[alle.Verfahrensnummer == urteilsnummer, 'Vorinstanz'] = vorinstanz\n            else:\n                pass\n        print(f'Im Zieldatenframe wurden bei {korrekturcount} Urteilen die Vorinstanz korrigiert')\n    except FileNotFoundError:\n        print(f'Pfad {pfad} existiert nicht, daher erfolgte keine Vorinstanzkorrektur')\n        pass\n\nvorinstanzkorrektur()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:16.975638Z","iopub.execute_input":"2021-05-30T10:22:16.975992Z","iopub.status.idle":"2021-05-30T10:22:18.163051Z","shell.execute_reply.started":"2021-05-30T10:22:16.975965Z","shell.execute_reply":"2021-05-30T10:22:18.161938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vorinstanz_error = alle[alle['Vorinstanz'].str.contains(\"#\")]\nif vorinstanz_error.shape[0] > 0:\n    print(f'Es verbleiben ' + str(vorinstanz_error.shape[0]) + ' Urteile mit einem Vorinstanz-Auswertungsfehler. Die sind neu hinzugekommen und wurden noch nicht händisch korrigiert.')\nelse:\n    print('Es verbleiben keine Urteile mehr im Datensatz, in welchem keine Vorinstanz festgelegt ist.')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:18.164271Z","iopub.execute_input":"2021-05-30T10:22:18.164498Z","iopub.status.idle":"2021-05-30T10:22:18.187813Z","shell.execute_reply.started":"2021-05-30T10:22:18.164472Z","shell.execute_reply":"2021-05-30T10:22:18.186476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Im folgenden werden Urteile, bei denen der Auswertungsalgorithmus nicht ein fehlerhaftes, aber merkwürdiges Vorinstanzresultat ergab, händisch korrigert. Eine Liste mit verbliebenen fehlerhaft erfassten oder seltenen Vorinstanzen, die bei der folgenden Auswertung nicht berücksichtigt wurden, finden sich ganz am Ende.","metadata":{}},{"cell_type":"code","source":"# Regex-Ersetzungen\nalle = alle.replace(r'(?<=Anklagekammer des Kantons St. Gallen).*', '', regex=True)\nalle = alle.replace(r'Anklagekammer.*Gallen', 'Anklagekammer des Kantons St. Gallen', regex=True)\nalle = alle.replace(r'(?<=Anklagekammer des Kantons Thurgau).*', '', regex=True)\nalle = alle.replace(r'(?<=Anklagekammer des Kantons Waadt).*', '', regex=True)\nalle = alle.replace(r'(?<=Appellationsgericht des Kantons Basel-Stadt).*', '', regex=True)\nalle = alle.replace(r'(?<=Appellationsgerichtpr).*', 'aesidentIn des Kantons Basel-Stadt', regex=True)\n#alle = alle.replace(r'Cour de cassation pénale', 'Tribunal cantonal du canton de Vaud', regex=True)\n#alle = alle.replace(r'Tribunal cantonal', \"Tribunal d'accusation du Tribunal cantonal du canton de Vaud\", regex=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:18.190271Z","iopub.execute_input":"2021-05-30T10:22:18.190585Z","iopub.status.idle":"2021-05-30T10:22:20.448992Z","shell.execute_reply.started":"2021-05-30T10:22:18.190549Z","shell.execute_reply":"2021-05-30T10:22:20.447995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Korrektur von **Ergebnissen**","metadata":{}},{"cell_type":"code","source":"ergebnis_error = alle[alle['Verfahrensergebnis'].str.contains('#')]\nfehlerzahl = ergebnis_error.shape[0]\nprint(f'Bei {fehlerzahl} Urteilen konnte der Auswertungsalgorithmus das Ergebnis nicht feststellen und gab eine Fehlermeldung zurück. Die betreffenden Urteile werden in der Folge (teilweise) mit einem verifizierten Korrekturdatensatz korrigiert.')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:20.450857Z","iopub.execute_input":"2021-05-30T10:22:20.451214Z","iopub.status.idle":"2021-05-30T10:22:20.473578Z","shell.execute_reply.started":"2021-05-30T10:22:20.451171Z","shell.execute_reply":"2021-05-30T10:22:20.472444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ergebniskorrektur(pfad='/kaggle/input/bger6b2018/val_sets/straf/ergebniskorrektur.csv'):\n    try:\n        korr_erg = pd.read_csv(pfad)\n        print(f'Von {pfad} wurden {korr_erg.shape[0]} Ergebniskorrekturen eingelesen.')\n        korrekturcount = 0\n        for i in range(korr_erg.shape[0]):\n            urteilsnummer = korr_erg.iloc[i, 1]\n            if urteilsnummer in alle['Verfahrensnummer'].unique():\n                korrekturcount += 1\n                ergebnis = korr_erg.iloc[i, 2]\n                alle.loc[alle.Verfahrensnummer == urteilsnummer, 'Verfahrensergebnis'] = ergebnis\n            else:\n                pass\n        print(f'Im Zieldatenframe wurden bei {korrekturcount} Urteilen das Verfahrensergebnis korrigiert')\n    except FileNotFoundError:\n        print(f'Pfad {pfad} existiert nicht, daher erfolgte keine Ergebniskorrektur')\n        pass\n    \nergebniskorrektur()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:20.475165Z","iopub.execute_input":"2021-05-30T10:22:20.475495Z","iopub.status.idle":"2021-05-30T10:22:23.191123Z","shell.execute_reply.started":"2021-05-30T10:22:20.475463Z","shell.execute_reply":"2021-05-30T10:22:23.190192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ergebnis_error = alle[alle['Verfahrensergebnis'].str.contains('#')]\nfehlerzahl = ergebnis_error.shape[0]\nif fehlerzahl > 0:\n    print(f'Es verbleiben {fehlerzahl} Urteile mit einem bei welchen der Ergebnis-Auswertungsalgorithmus einen Fehler zurückgegeben hat.')\nelse: \n    print('Es verbleiben keine Urteile mehr im Datensatz, in welchem kein Verfahrensergebnis festgelegt ist.')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:23.192541Z","iopub.execute_input":"2021-05-30T10:22:23.192863Z","iopub.status.idle":"2021-05-30T10:22:23.2138Z","shell.execute_reply.started":"2021-05-30T10:22:23.192821Z","shell.execute_reply":"2021-05-30T10:22:23.212648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Es folgt eine Fehlerquoten-Evaluation**\n\nDer Auswertungsalgorithmus interpretiert die Ergebnisse teilweise falsch (z.B. ein gutgeheissenes UR-Gesuch wird fälschlicherweise als Gutheissung der Beschwerde interpretiert). Um die Fehlerquote hochzurechnen werden in der Folge menschlich verifizierte Samples mit dem durch den Algorithmus errechneten Verfahrensergebnissen abgeglichen und die Übereinstimmungsquote eruiert, womit die Fehlerquote des gesamten Datensatzes abgeschätzt werden kann.","metadata":{}},{"cell_type":"code","source":"rechtsbereich = 'straf'\n\ndef fehlerquoten_evaluation(val_set_folderpath=f'/kaggle/input/bger6b2018/val_sets/{rechtsbereich}', print_details=False):\n    #print('fehlerquoten_evaluation(): ')\n    count_dict = dict()\n    fehlerquote_dict = dict()\n    for val_set in ['de_val_set', 'fr_val_set', 'it_val_set']:\n        filepath = f'{val_set_folderpath}/{val_set}.csv'\n        try:\n            val_df = pd.read_csv(filepath)\n            #print(f' Von {filepath} insgesamt {str(val_df.shape[0])} evaluierte Verfahrensergebnisse eingelesen.')\n            val_df = pd.merge(alle, val_df, on='Verfahrensnummer', how='inner')\n            if val_set == 'de_val_set':\n                sprache = 'deutschen'\n            elif val_set == 'fr_val_set':\n                sprache = 'französischen'\n            else:\n                sprache = 'italienischen'\n            print(f'In diesem Datenset können insgesamt {val_df.shape[0]} Ergebnisse von {sprache} Urteilen kontrolliert werden.')\n            count_dict[val_set] = val_df.shape[0]\n            matches = 0\n            dismatches = 0\n            for row in range(val_df.shape[0]):\n                if val_df.iloc[row]['Verfahrensergebnis'] == val_df.iloc[row]['Ergebnis']:\n                    matches += 1\n                else:\n                    dismatches += 1\n                    if print_details:\n                        print(f' -> Beim Urteil {val_df.iloc[row][\"Verfahrensnummer\"]} hat der Algorithmus '\n                              f'fälschlicherweise auf \"{val_df.iloc[row][\"Verfahrensergebnis\"]}\" erkannt, das '\n                              f'korrekte Ergebnis wäre: \"{val_df.iloc[row][\"Ergebnis\"]}\".')\n\n            fehlerquote = dismatches/(matches+dismatches)*100\n            print(f' Die Fehlerquote im {sprache} Evaluationsset beträgt {str(fehlerquote)}%')\n            fehlerquote_dict[val_set] = fehlerquote/100\n        except FileNotFoundError:\n            print(f' {filepath} existiert nicht')\n    count_list = list(count_dict.values())\n    fehlerquoten_list = list(fehlerquote_dict.values())\n    count_fehlerquote_tuple = list(zip(count_list, fehlerquoten_list))\n    gesamtcount = sum(count_list)\n    print(f'Insgesamt wurde das Ergebnis des Auswertungslogarithmus bei {gesamtcount} verifizierten Urteilen überprüft')\n    gewichtete_fehlerquoten = [tup[0]*tup[1]/gesamtcount for tup in count_fehlerquote_tuple]\n    gesamtfehlerquote = sum(gewichtete_fehlerquoten)\n    print(f' Dabei wurde eine Fehlerquote von {round(gesamtfehlerquote*100, 2)}% festgestellt.')\n     \nfehlerquoten_evaluation(print_details=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:23.215194Z","iopub.execute_input":"2021-05-30T10:22:23.215443Z","iopub.status.idle":"2021-05-30T10:22:23.440038Z","shell.execute_reply.started":"2021-05-30T10:22:23.215417Z","shell.execute_reply":"2021-05-30T10:22:23.439172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gutheissungsquoten im interkantonalen Vergleich (alle strafrechtlichen Bundesgerichtsurteile ab 2011)","metadata":{}},{"cell_type":"code","source":"counted = alle.groupby([\"Vorinstanz\", \"Verfahrensergebnis\"]).count()\ncounted = counted.reset_index()\n\n# ZMG-Vorinstanzen ausfiltern, \"|\" bedeutet oder\ncounted = counted[counted['Vorinstanz'].str.contains('ZMG|mesures|Bezirksgericht|undefiniert')==False]\n\npivot = counted.pivot(values=\"Verfahrensnummer\", index=\"Vorinstanz\", columns=\"Verfahrensergebnis\")\npivot[\"Total\"] = pivot.sum(axis=1)\npivot = pivot.fillna(0)\npivot[\"% gut\"] = (pivot[\"Gutheissung\"]+pivot[\"teilweise Gutheissung\"])/pivot[\"Total\"]*100\npivot[\"% gut-mat\"] = (pivot[\"Gutheissung\"]+pivot[\"teilweise Gutheissung\"])/(pivot[\"Total\"]-pivot[\"Nichteintreten\"]-pivot[\"Gegenstandslosigkeit\"])*100\nfiltered = pivot[pivot[\"Total\"] > 19]\nsortiert = filtered.sort_values(\"% gut-mat\", ascending=False)\n# Spaltennamen kürzen\nsortiert = sortiert.rename(columns={\"Abweisung\": \"abw\", \"Gegenstandslosigkeit\": \"gglos\", \"Gutheissung\": \"gut\", \"Nichteintreten\": \"nee\", \"teilweise Gutheissung\": \"tlwgut\", \"Total\": \"tot\"})\n# Spaltennamen neu einordnen\nsortiert = sortiert[['tot', 'gut', 'tlwgut','abw', 'nee', 'gglos', '% gut', '% gut-mat']]\nsortiert['tot-mat'] = sortiert['tot'] - sortiert['nee'] - sortiert['gglos']\nsortiert['tot-gut'] = sortiert['gut'] + sortiert['tlwgut']\nsortiert = sortiert[['tot', 'tot-mat', 'tot-gut', 'gut', 'tlwgut', 'abw', 'nee', 'gglos', '% gut', '% gut-mat']]\n\n#funktion um Spalten hervorzuheben:\ndef highlight_cols(x):\n    #copy df to new - original data are not changed\n    df = x.copy()\n    #select all values to default value - none\n    df.loc[:,:] = ''\n    #overwrite values lightyellow color\n    df[['tot']] = 'font-weight: bold'\n    #overwrite values lightyellow color\n    df[['gut', 'tlwgut', 'tot-gut']] = 'background-color: lightgreen'\n    #overwrite values lightyellow color\n    df[['tot-gut']] = 'font-weight: bold; background-color: lightgreen'\n    #overwrite values lightred color\n    df[['abw', 'nee', 'gglos']] = 'background-color: lightyellow'\n    #return color df\n    return df      \n\nsortiert = sortiert.fillna(0)\nsortiert.style.background_gradient(subset=['% gut', '% gut-mat'], cmap='Blues')\\\n.apply(highlight_cols, axis=None)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:23.441188Z","iopub.execute_input":"2021-05-30T10:22:23.441418Z","iopub.status.idle":"2021-05-30T10:22:23.892817Z","shell.execute_reply.started":"2021-05-30T10:22:23.441391Z","shell.execute_reply":"2021-05-30T10:22:23.892158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n## Graph erstellen\nplt.figure(figsize=[14, 4.8])\nax1 = plt.subplot()\nax1.set_xticks(range(len(sortiert['% gut-mat'])))\nax1.set_xticklabels(sortiert.index.to_list(), rotation='vertical')\nplt.bar(range(len(sortiert['% gut-mat'])), sortiert['% gut-mat'].to_list())\nplt.title('Gutheissungsquote pro Vorinstanz in Prozent im Verhältnis zu allen materiell beurteilten Fällen (Gutheissungen und Abweisungen)')\nplt.ylabel('%')\nplt.xlabel('Vorinstanz')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:23.894069Z","iopub.execute_input":"2021-05-30T10:22:23.894578Z","iopub.status.idle":"2021-05-30T10:22:24.327873Z","shell.execute_reply.started":"2021-05-30T10:22:23.894545Z","shell.execute_reply":"2021-05-30T10:22:24.327234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Liste aller verbliebenen Vorinstanzen-Ergebnisse des Auswertungsalgorithmus (nach Datenbereinigung)**","metadata":{}},{"cell_type":"code","source":"err_count = alle.groupby(['Vorinstanz']).Verfahrensnummer.count().reset_index().rename(columns={'Verfahrensnummer': 'tot'}).set_index('Vorinstanz')\npd.set_option('display.max_rows', 1000)\nerr_count.head(1000).sort_values('tot')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T10:22:24.32937Z","iopub.execute_input":"2021-05-30T10:22:24.329805Z","iopub.status.idle":"2021-05-30T10:22:24.38417Z","shell.execute_reply.started":"2021-05-30T10:22:24.329775Z","shell.execute_reply":"2021-05-30T10:22:24.383459Z"},"trusted":true},"execution_count":null,"outputs":[]}]}