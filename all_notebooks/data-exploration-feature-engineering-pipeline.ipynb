{"cells":[{"metadata":{"colab_type":"text","id":"HTMsnUnJt6jD"},"cell_type":"markdown","source":"# Data exploration + pipeline for ingredients one hot encodings\n\n# Import data\n \nCurently I'm considering only *ingredients*, *nutrition* and free features like *n_ingredients* and *n_steps* for exploration and one hot encodings. "},{"metadata":{"colab":{},"colab_type":"code","id":"EgaDEj5HrX9e","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nr_recipes = pd.read_csv('../input/food-com-recipes-and-user-interactions/RAW_recipes.csv')\ntest = pd.read_csv('../input/food-com-recipes-and-user-interactions/interactions_test.csv')\ntrain = pd.read_csv('../input/food-com-recipes-and-user-interactions/interactions_train.csv')\nvalidation = pd.read_csv('../input/food-com-recipes-and-user-interactions/interactions_validation.csv')","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"IEdfuutxt3mw"},"cell_type":"markdown","source":"In the following I will get required data about recipes and interactions, merge train and validation data sets as we use later cross-validation, calculate the average rating per recipe in train/test/validate, and join recipes data with rating data. "},{"metadata":{"colab":{},"colab_type":"code","id":"BsXw6YCHteME","trusted":true},"cell_type":"code","source":"r_recipes = r_recipes[['id', 'ingredients', 'nutrition', 'n_steps', 'n_ingredients']]\nr_recipes.columns = ['recipe_id', 'ingredients', 'nutrition', 'n_steps', 'n_ingredients']\nr_recipes = r_recipes.set_index('recipe_id')\n\ntrain = pd.concat([train[['user_id', 'recipe_id', 'rating']], validation[['user_id', 'recipe_id', 'rating']]], axis = 0)\n\ntrain_rating = pd.DataFrame(train.groupby(['recipe_id']).mean()['rating'])\ntest_rating = pd.DataFrame(test.groupby(['recipe_id']).mean()['rating'])\n\nrecipes_rating_train = r_recipes.join(train_rating, how = 'inner')\nrecipes_rating_test = r_recipes.join(test_rating, how = 'inner')\n\nrecipes_rating_train['rating'] = recipes_rating_train['rating'].apply(lambda x: round(x))\nrecipes_rating_test['rating'] = recipes_rating_test['rating'].apply(lambda x: round(x))\n\ntrain_test = pd.concat([recipes_rating_train[0:round(recipes_rating_train.shape[0]*0.3)], recipes_rating_test[0:round(recipes_rating_test.shape[0]*0.3)]])","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"EG1qF0fK4EGX"},"cell_type":"markdown","source":"# Some data exploration\n\nTo continue with prediction of ratings I will check for missing values, dublicates, look for outliers and imbalances. "},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"colab_type":"code","id":"zyHRrT133Lgi","outputId":"2e8cfd2c-b6d2-41a8-ceee-abcda4e508ac","trusted":true},"cell_type":"code","source":"def avoidRowsWithMissValues(df):\n  if(df.isnull().values.any()): \n    columns = df.columns\n    for column in columns: \n      df[df[column].isnull()] = \"\"\n      df[df[column]=='NaN'] = \"\"\n      df[pd.isna(df[column])] = \"\"\n  return df\n\nrecipes_rating_train = avoidRowsWithMissValues(recipes_rating_train)\nrecipes_rating_test = avoidRowsWithMissValues(recipes_rating_test)\n\n\nrecipes_rating_train.drop_duplicates()\nrecipes_rating_test.drop_duplicates()\n\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"R68C80tAEyeq"},"cell_type":"markdown","source":"#### Ratings distribution \n\nMost of recipes are rated with 5 in both set. So we need later to take care about imbalanced classes. Class 4 appears more often in test class. \n"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"7PtiuARuFMHr","outputId":"35e81353-054f-4c82-a98e-806f1ceaae10","trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_train['rating'])\nax.set_xticks(np.arange(0,6))\nax.set_xlabel('Ratings in train set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"1V3xOi7_FR5y","outputId":"67389272-f2cc-429f-bb22-e5ffefa9025d","trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_test['rating'])\nax.set_xticks(np.arange(0,6))\nax.set_xlabel('Ratings in test set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"xgsv0SgHAuwn"},"cell_type":"markdown","source":"#### Number of ingredients\nIs similarly distributed in train and test sets and do not include critical outliers.\n"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"0d-3h6Da_KPx","outputId":"690e6fc7-5109-4311-d8f0-78ef522d5092","trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_train['n_ingredients'])\nax.set_xticks(np.arange(0,20))\nax.set_xlabel('Number of ingredients per recipe in train set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"vD-uWIdw_m6v","outputId":"998540aa-1713-4123-8b35-b395544ba50d","trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_test['n_ingredients'])\nax.set_xticks(np.arange(0,20))\nax.set_xlabel('Number of ingredients per recipe in test set')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"wpPhjn59BHH9"},"cell_type":"markdown","source":"#### Number of steps per recipe \nThe distribution of steps in train and test sets are similar. Some of recipes in both sets have unsualy many steps (> 22). The number of such recipes are similarly distributed in test and train sets and the rating disctribution of outliers corresponds to general rating distribution.  "},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"QBh_4vHt_yQw","outputId":"2716773f-491c-4083-901c-bfc36a45a667","trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_train['n_steps'])\nax.set_xticks(np.arange(0,40, 2))\nax.set_xlabel('Number of steps per recipe')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"WvY4qJrV_4oM","outputId":"2588355b-079c-45ad-ba6e-1f1fe308d963","trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_test['n_steps'])\nax.set_xticks(np.arange(0,40, 2))\nax.set_xlabel('Number of steps per recipe')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"colab_type":"code","id":"rtyRsyZGBwmK","outputId":"bf93b144-9c99-40c6-a8ff-2bb92f8420ea","trusted":true},"cell_type":"code","source":"recipes_rating_train[recipes_rating_train['n_steps'] > 22]['rating'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"colab_type":"code","id":"q_YAOQ84ErF0","outputId":"cbb580d3-fe7b-42c4-a2eb-076bb4cec60b","trusted":true},"cell_type":"code","source":"recipes_rating_test[recipes_rating_test['n_steps'] > 22]['rating'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"0uOAXumFGcMH"},"cell_type":"markdown","source":"# Feature engineering\n\nFollowing I will choose a bunch of features to be ready to run classification algorithms. Firstly I check correlations and transform ingredients and nutrition values into a suitable format. With the help of CountVectorizer all ingredients are added to a vocabulary. So each recipe ingredients will be represented by onehot-encodings. Nutrition data will be as well separated into different columns. \n\nFor deployment it is better when all the transformations with the input data are done in a pipeline. For this purpose i created Scikit Learn -designed transformers that will transform the current and future input data. But the input data is expected to be in particular format like includes *recipe_id* and other required columns."},{"metadata":{"colab":{},"colab_type":"code","id":"4RNryzh2INsB","trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef strToList(list_l, splitSymbol):\n    list_l = list_l.split(splitSymbol)\n    temp = list()\n    for l in list_l: \n        l = l.replace(\"[\",'').replace(\"]\",'').replace(\"'\", '').replace(\" \", '')\n        temp.append(l)\n    return temp\n\nclass ingredientsToList(BaseEstimator, TransformerMixin): \n    def __init__(self, columns = []):\n        self.columns = columns\n    def fit(self, X):\n        return self\n    def transform(self, X): \n      for column in self.columns:\n        X[column] = X[column].apply(lambda x : strToList(x, ','))\n      return X\n    \nclass ingredientsToOneHot(BaseEstimator, TransformerMixin): \n    def __init__(self, columns = []):\n        self.columns = columns\n    def fit(self, X):\n        return self\n    def transform(self, X): \n        cv = CountVectorizer(analyzer=lambda x: x)\n        for column in self.columns:\n            test = cv.fit_transform(X[column].to_list())\n            test_columns = [x for x in cv.get_feature_names()]\n            X = X.join(pd.DataFrame(test.toarray(), columns = test_columns, index = X.index))\n            #X = X.join(pd.DataFrame(test.toarray(), index = X.index))\n        return X\n\nclass nutritionDataIntoCol(BaseEstimator, TransformerMixin): \n    def fit(self, X):\n        return self\n\n    def transform(self, X): \n      nutrition_X = pd.DataFrame(X['nutrition'].to_list(), columns = ['calories', 'total fat', 'sugar_nutrition', 'sodium', 'protein', 'saturated fat', 'carbohydrates'], index = X.index)\n      \n      nutrition_X_col = nutrition_X.columns\n      for col in nutrition_X_col: \n        nutrition_X[col] = nutrition_X[col].apply(lambda x: float(x))\n\n      X = X.join(nutrition_X)\n      return X\n\nclass getFeatureColumns(BaseEstimator, TransformerMixin): \n    def fit(self, X):\n        return self\n    def transform(self, X):\n        col = list(X.columns)\n        for c in ['ingredients', 'nutrition', 'n_steps', 'n_ingredients']:\n            col.remove(c)\n        return X[col]","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"colab_type":"code","id":"HgIG18NyIXxW","outputId":"bf3a4abd-9092-4809-c4af-89eb4b033afe","trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npip = Pipeline([\n    ('ingredientsToList', ingredientsToList(columns = ['ingredients', 'nutrition'])), \n    ('ingredientToOneHotColumns', ingredientsToOneHot(columns = ['ingredients'])),\n    ('nutritionData', nutritionDataIntoCol()), \n    ('getFeatureColumns', getFeatureColumns())\n])\nall_withFeatures = pip.transform(train_test)\nall_withFeatures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean RAM\nHere I remove some of variables that are not required any more. It allows to conduct further memory-consuming experiments."},{"metadata":{"trusted":true},"cell_type":"code","source":"del r_recipes\ndel train\ndel train_rating\ndel train_test\ndel recipes_rating_train\ndel recipes_rating_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Avoid rare ingredients\nThe idea here is to avoid ingredients that appear rarely in recipes. Since they can disturb models while looking for the fit. So I consider further ingredients that appear at least in 1% of recipes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"col = list(all_withFeatures.columns)\nfor column in ['rating', 'calories', 'total fat', 'sugar_nutrition', 'sodium', 'protein',\n       'saturated fat', 'carbohydrates']:\n    col.remove(column)\nsum_ingredients = pd.DataFrame(all_withFeatures[col].sum(axis = 0)/all_withFeatures.shape[0])\n\nsns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = sum_ingredients.values*100)\nax.set_xticks(np.arange(0,10, 2))\nax.set_xlabel('Number of time an ingredient was used')\nplt.show()\n\nsum_freq_ingred_index = list(sum_ingredients[sum_ingredients[0]>0.01].index)","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"food.com.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}