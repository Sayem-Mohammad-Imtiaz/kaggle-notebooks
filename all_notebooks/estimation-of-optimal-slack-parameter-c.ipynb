{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2b7a0453-f863-b11d-b353-f49bdb1c231a"},"source":"The following code runs a number of simulation using different values of the slack parameter C in a support vector machine. The aim is to identify the value of C, that has the best predictive value. Different values of C ranging from 0.001 to 100 are used. The data set is split in to three sets, in order to un-bias the final estimator of accuracy. Hence, the value of C with the best average performance is used to find the model's predictive power in an out-of-sample data set. All this is done twice: once using a Linear Kernel and once using a Gaussian Kernel ('rbf'). Everything is summarized in a nice plot in the end.\n\nI have one  conceptual problem.:\n\nThe out-of-sample predictive power of my best Gaussian Kernel is devastating (blue star in the plot). I tried several things, it is not a coding issue. Why is that performance of the best(!) C in the out-of-sample data set so bad? (The performance for the Linear Kernel deteriorates only slightly).\n\nAny feedback is welcome!\n\nThanks, \nJan"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ed22544-6af2-8398-7d30-449f7cd084db"},"outputs":[],"source":"import numpy as np\nimport math\nfrom sklearn import preprocessing, svm\nimport pandas as pd\nfrom math import sqrt\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.cross_validation import  train_test_split\n\n\n\ndf =  pd.read_csv('../input/data.csv', header=0)\ndf[df.columns[1]] = df[df.columns[1]].map( {'B': 0, 'M': 1} ).astype(int)\n\ndf = df[list(df.columns[:13])] \ndf.replace('?', -99999, inplace=True)\ndf.drop(['id'], 1, inplace=True)\n\nX = np.array(df.drop(['diagnosis'], 1))\ny = np.array(df['diagnosis'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea3603d0-e653-63c6-45b4-5a29ae12ce5a"},"outputs":[],"source":"#Now I split the set the first time and use \nX_train_CV, X_test_CV, y_train_CV, y_test_CV = train_test_split(X, y, test_size=0.2)\n\nreduced_X=X_train_CV\nreduced_y=y_train_CV\n\n#List of C-values and other stuff\nC_values=[math.pow(10,x/20) for x in range(-60,30)]\nopt_dict_lin={}\nopt_dict_gauss={}\nC_dependent_acc=[]\n\nnumber_of_simulations=30    #Adjust at will!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92563812-5ee6-b54d-482a-3b791f8c3fea"},"outputs":[],"source":"C_dependent_acc_lin=[]\nyerr=[]\nfor i in range(len(C_values)):\n\n    accuracies = []\n    for i1 in range(number_of_simulations):\n\n        X = preprocessing.scale(reduced_X)\n        X_train, X_test, y_train, y_test = train_test_split(X, reduced_y, test_size=0.2)\n\n        clf=svm.SVC(C=C_values[i],kernel='linear')\n        clf.fit(X_train,y_train)\n\n        predictions = clf.predict(X_test)\n        accuracy=metrics.accuracy_score(y_test, predictions)\n\n        #accuracy=clf.score(X_test,y_test)\n        accuracies.append(accuracy)\n\n    mean_acc=(sum(accuracies)/len(accuracies))\n    standard_error=np.std(accuracies)/sqrt(len(accuracies))\n    C_dependent_acc_lin.append(mean_acc)\n    yerr.append(standard_error)\n    opt_dict_lin[mean_acc]=[C_values[i]]\n\nnorms=sorted([n for n in opt_dict_lin])\nopt_choice_lin=opt_dict_lin[norms[-1]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0141710b-db60-4fd3-bac3-79ce098f29de"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"327d2dbb-5785-4aaa-afdc-d456c8fda0c2"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ef35241-da86-c30f-f2a3-939ef4fa2203"},"outputs":[],"source":"#Out of sample estimation of accuracy\n#Note: If I try preprocessing my data using\n#X_train_CV = preprocessing.scale(X_train_CV)\n#,the performance is screwed up. Why is that?\n\nclf = svm.SVC(C=opt_choice_lin[0], kernel='linear')\nclf.fit(X_train_CV, y_train_CV)\n\n\npredictions = clf.predict(X_test)\naccuracy=metrics.accuracy_score(y_test, predictions)\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1e14ec7-3161-aa20-4eef-146af6a46b36"},"outputs":[],"source":"\n#Now, everything is repeated, only using a Gaussian Kernel instead of a Linear one.\n\nC_dependent_acc=[]\nyerr1=[]\nfor i in range(len(C_values)):\n\n    accuracies = []\n    for i1 in range(number_of_simulations):\n\n\n        X = preprocessing.scale(reduced_X)\n        X_train, X_test, y_train, y_test = train_test_split(X, reduced_y, test_size=0.2)\n\n        clf=svm.SVC(C=C_values[i],kernel='rbf')\n        clf.fit(X_train,y_train)\n\n        predictions = clf.predict(X_test)\n        accuracy=metrics.accuracy_score(y_test, predictions)\n        accuracies.append(accuracy)\n\n    mean_acc=(sum(accuracies)/len(accuracies))\n    standard_error=np.std(accuracies)/sqrt(len(accuracies))\n    C_dependent_acc.append(mean_acc)\n    yerr1.append(standard_error)\n    opt_dict_gauss[mean_acc] = [C_values[i]]\n\nnorms = sorted([n for n in opt_dict_gauss])\nprint(norms)\nopt_choice_gauss = opt_dict_gauss[norms[-1]]\n\n#Testing of optimal value at new data\nX = preprocessing.scale(X_train_CV)\n\nclf = svm.SVC(C=opt_choice_gauss[0], kernel='rbf')\nclf.fit(X, y_train_CV)\n\npredictions = clf.predict(X_test)\naccuracy1=metrics.accuracy_score(y_test, predictions)\n\n#Things are plotted using a log scale\nax = plt.subplot(111)\nax.set_xscale(\"log\")\nplt.errorbar(C_values,C_dependent_acc_lin,yerr=yerr,color='b',label='Linear Kernel')\nplt.errorbar(C_values,C_dependent_acc,yerr=yerr1,color='r',label='Gaussian Kernel')\n\nplt.scatter(opt_choice_gauss[0],accuracy1,marker='*',s=100,color='r',label='Accuracy of best C of Gaussian kernel on new data')\nplt.scatter(opt_choice_lin[0],accuracy,marker='*',s=100,color='b',label='Accuracy of best C of Linear kernel on new data')\nplt.xlabel(\"Log of Slack Parameter 'C'\")\nplt.ylabel(\"Accuracy\")\n#plt.legend(loc='lower right')\nprint('Accuracy of best C (',opt_choice_gauss[0],') at new data with Gaussian kernel:', accuracy1)\nprint('Accuracy of best C (',opt_choice_lin[0],') at new data with linear kernel:', accuracy)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f71ac4e4-4128-9bf9-7206-77dcd14e20ad"},"outputs":[],"source":"print('Accuracy of best C (',opt_choice_lin[0],') at new data with linear kernel:', accuracy)\nprint('Accuracy of best C (',opt_choice_gauss[0],') at new data with Gaussian kernel:', accuracy1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d62c2815-8d19-ae40-653d-5f90d9001eb0"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}