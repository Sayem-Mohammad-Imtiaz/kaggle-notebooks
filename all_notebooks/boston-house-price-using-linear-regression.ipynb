{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory # ref https://www.kaggle.com/vikrishnan/house-sales-price-using-regression\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndata_df=pd.read_csv('/kaggle/input/boston-house-prices/housing.csv', header=None, delim_whitespace=True, names=column_names) #, delimiter=r\"\\s+\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summarize Data from Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.duplicated().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.hist(bins=12,figsize=(12,10),grid=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CRIM per capita: crime rate by town\n\nZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n\nINDUS: proportion of non-retail business acres per town\n\nCHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n\nNOX: nitric oxides concentration (parts per 10 million)\n\nRM: average number of rooms per dwelling\n\nAGE: proportion of owner-occupied units built prior to 1940\n\nDIS: weighted distances to five Boston employment centres\n\nRAD: index of accessibility to radial highways\n\nTAX: full-value property-tax rate per 10,000usd\n\nPTRATIO: pupil-teacher ratio by town\n\nB: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n\nLSTAT: % lower status of the population\n\nMEDV--> our resident value target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data_df['MEDV']\nX=data_df.drop('MEDV',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.distplot(y, hist=True);\nfig = plt.figure()\nres = stats.probplot(y, plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error\n\nresults = []\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n\npipeLR=Pipeline([('scaler', StandardScaler()), ('LR', LinearRegression())])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(pipeLR, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n\npipeLR.fit(X_train, y_train)\n\n# this is the scaled LR\nprint(\"Score for scaledLR: \", pipeLR.score(X_test, y_test))\n# the mean result (10 data) of negative mean squared error\nprint(\"Score for scaledLR using cross_val_score: \", cv_results.mean())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ideal of cross_val_score using neg_mean_squared_error scoring is zero. It means that the total error of all data on the regression line is as stated above."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nsklearn.metrics.SCORERS.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeLASSO=Pipeline([('scaler', StandardScaler()), ('LASSO', Lasso())])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(pipeLASSO, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n\npipeLASSO.fit(X_train, y_train)\n\n# this is the scaled LR\nprint(\"Score for scaledLASSO: \", pipeLASSO.score(X_test, y_test))\n# the mean result (10 data) of negative mean squared error\nprint(\"Score for scaledLASSO using cross_val_score: \", cv_results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeEN=Pipeline([('scaler', StandardScaler()), ('ElasticNet', ElasticNet())])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(pipeEN, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n\npipeEN.fit(X_train, y_train)\n\n# this is the scaled LR\nprint(\"Score for pipeEN: \", pipeEN.score(X_test, y_test))\n# the mean result (10 data) of negative mean squared error\nprint(\"Score for pipeEN using cross_val_score: \", cv_results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeKNNReg=Pipeline([('scaler', StandardScaler()), ('KNeighborsRegressor', KNeighborsRegressor())])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(pipeKNNReg, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n\npipeKNNReg.fit(X_train, y_train)\n\n# this is the scaled LR\nprint(\"Score for pipeKNNReg: \", pipeKNNReg.score(X_test, y_test))\n# the mean result (10 data) of negative mean squared error\nprint(\"Score for pipeKNNReg using cross_val_score: \", cv_results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeGBM=Pipeline([('scaler', StandardScaler()), ('GradientBoostingRegressor', GradientBoostingRegressor())])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(pipeGBM, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n\npipeGBM.fit(X_train, y_train)\n\n# this is the scaled LR\nprint(\"Score for pipeGBM: \", pipeGBM.score(X_test, y_test))\n# the mean result (10 data) of negative mean squared error\nprint(\"Score for pipeGBM using cross_val_score: \", cv_results.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GBM is good for this model. Now we are ready to use the model for data test"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeGBM=Pipeline([('scaler', StandardScaler()), ('GradientBoostingRegressor', GradientBoostingRegressor(random_state=0, n_estimators=400))])\n\n# the benefit of using K-Fold is that we could calculate the cross validation value using some of the methods of scoring \nkfold = KFold(n_splits=10, shuffle=True, random_state=0)\ncv_results = cross_val_score(pipeGBM, X_train, y_train, cv=kfold, scoring='neg_mean_squared_error')\n\npipeGBM.fit(X_train, y_train)\n\n#scaler = StandardScaler().fit(X_train)\n\n#X_test_scaled=scaler.transform(X_test)\n\npredictions = pipeGBM.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mean_squared_error(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df=pd.DataFrame({\"Original Price of House\": y_test, \"Prediction Price of House\": predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}