{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"400966af-72cd-d1ac-7520-c18c850f59a2"},"source":"In this notebook I search for the best classifier and its parameters for tweets multi-class classifications based on authorship attributes (char analyzer and word analyzer with stems ) SVC with linear kernel takes too much time to run today and the kernel is killed."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9242b05-8556-5229-e3da-da453ccda0af"},"outputs":[],"source":"import pandas as pd\nfrom pandas import Series,DataFrame\nimport numpy as np"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4931abf3-141e-afea-559c-01560cde768c"},"outputs":[],"source":"#data\ndf=pd.read_csv('../input/AllTweets.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c543c07-e26f-4228-5acf-bbdcf8c7ef89"},"outputs":[],"source":"pd.DataFrame(df.groupby('author').size().rename('counts')).sort_values('counts', ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"81a893de-edfb-159f-5059-65779054a592"},"outputs":[],"source":"import random\nfrom sklearn.model_selection import train_test_split\n#1000 random sample rows for each author\ndf_new=pd.DataFrame()\ntwts_train=pd.DataFrame()\ntwts_test=pd.DataFrame()\nauthor_train=pd.DataFrame()\nauthor_test=pd.DataFrame()\nfor a in df.author.unique():\n    rows = random.sample(list(df[df['author']==a].index), 1000)\n    df_temp = df.ix[rows]\n    df_new=df_new.append(df_temp,ignore_index=True)    \n    X_train, X_test, Y_train, Y_test = train_test_split(df_temp.ix[:,['text']], df_temp.ix[:,['author']], test_size=0.2, random_state=42)\n    twts_train=twts_train.append(X_train, verify_integrity=False)\n    twts_test=twts_test.append(X_test, verify_integrity=False)\n    author_train=author_train.append(Y_train, verify_integrity=False)\n    author_test=author_test.append(Y_test, verify_integrity=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7def55a5-e597-b7c6-71f0-18d5f978b189"},"source":"Train set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"236a0f8f-3e91-23cd-8883-0a3ade730438"},"outputs":[],"source":"print (len(twts_train),len(author_train))"},{"cell_type":"markdown","metadata":{"_cell_guid":"3ac1ccff-ab8e-314e-c23b-43eb5a3c9381"},"source":"Test set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7057861-fcb0-54cd-63ea-4323e4f4c79e"},"outputs":[],"source":"print(len(twts_test),len(author_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fd35bab-22c8-1771-2f27-a30434a69a7f"},"outputs":[],"source":"from nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\ndef text_process(text):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Tokenizes and removes punctuation\n    3. Stems\n    4. Returns a list of the cleaned text\n    \"\"\"\n\n    # tokenizing\n    tokenizer = RegexpTokenizer(r'\\w+')\n    text_processed=tokenizer.tokenize(text)\n    \n    \n    # steming\n    porter_stemmer = PorterStemmer()\n    \n    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n    \n\n    return text_processed"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"641896ba-81fa-9a7b-b3d6-a3487dcb7f24"},"outputs":[],"source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"277b05bb-1ef6-1d4f-ab3d-0e16811834e5"},"outputs":[],"source":"ScoreSummaryByModel = list()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3cef9c81-e97b-955f-5e1e-1b6037ad571e"},"outputs":[],"source":"def PredictionEvaluation(author_test_b,author_predicted_b,target_names,comment):\n    Accuracy=accuracy_score(author_test_b,author_predicted_b)\n    #print (Accuracy)\n    Recall=recall_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n    #print (Recall)\n    Precision=precision_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n    #print (Precision)\n    F1=f1_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n    #print (F1)\n    ScoreSummaryByModel.append([Accuracy,Recall,Precision,F1,comment])\n    print(classification_report(author_test_b, author_predicted_b, target_names=target_names))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"55f9396e-235f-d9f6-2735-bb2e9df87a74"},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport itertools"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33fd02cf-7ca6-9cb4-4c67-03624d8b11e0"},"outputs":[],"source":"#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac725c81-8966-8bc9-7104-888bdec7905f"},"outputs":[],"source":"ScoreSummaryByModelParams=list()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1fdc617e-6678-0672-6e3e-dae4f51022c7"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelBinarizer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65ba7ad4-87be-ccd1-858c-fa873544782b"},"outputs":[],"source":"def ModelParamsEvaluation (f_union,model,params,comment):\n    pipeline = Pipeline([\n    # Extract the text & text_coded\n    # Use FeatureUnion to combine the features from different vectorizers\n    ('union', f_union),\n    # Use a  classifier on the combined features\n    ('clf', model)\n    ])\n    grid_search = GridSearchCV(estimator=pipeline, param_grid=params, verbose=1)\n    grid_search.fit(twts_train['text'], author_train['author'])\n    author_predicted = grid_search.predict(twts_test['text'])\n    lb = LabelBinarizer()\n    author_test_b = lb.fit_transform(author_test['author'])\n    author_predicted_b  = lb.fit_transform(author_predicted)\n    #best score\n    print(\"Best score: %0.3f\" % grid_search.best_score_)\n    print(\"Best parameters set:\")\n    best_parameters = grid_search.best_estimator_.get_params()\n    author_names=grid_search.best_estimator_.named_steps['clf'].classes_\n\n    for param_name in sorted(params.keys()):\n        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n        ScoreSummaryByModelParams.append([comment,grid_search.best_score_,\"\\t%s: %r\" % (param_name, best_parameters[param_name])]) \n    return (author_predicted,author_predicted_b,author_test_b,author_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4d048d1-9119-0e05-53f2-97fa80836fb4"},"outputs":[],"source":"f2_union=FeatureUnion(\n        transformer_list=[\n            # Pipeline for pulling char features  from the text\n            ('char', Pipeline([\n                ('tfidf',     TfidfVectorizer(analyzer='char',ngram_range=(3, 3))),\n            ])),\n            # Pipeline for pulling stememd word features from the text\n            ('text', Pipeline([\n                ('tfidf',    TfidfVectorizer(analyzer='word',tokenizer= text_process,ngram_range=(1, 1))),\n            ])),        \n\n        ],\n\n    )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7112f9f-9016-34e8-6787-abb3e15a384e"},"outputs":[],"source":"from sklearn.svm import LinearSVC\n#LinearSVC\np = {'clf__C': (1,0.1,0.01,0.001,0.0001)}\n(author_predicted,author_predicted_b, author_test_b,author_names)=ModelParamsEvaluation(f2_union,LinearSVC(),p,'LinearSVC')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"727657e9-04cb-9b50-e705-aaa6b54d4587"},"outputs":[],"source":"PredictionEvaluation(author_predicted_b, author_test_b,author_names,'LinearSVC')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c797434-c174-7a7d-4243-ad6a002aa440"},"outputs":[],"source":"plot_confusion_matrix(confusion_matrix(author_test['author'], author_predicted), author_names,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9a6fc0e-018d-ca1e-1c55-33608d3b5480"},"outputs":[],"source":"author_predicted=pd.DataFrame(author_predicted,columns=['predicted'])\ndf_wrong_result = pd.concat([twts_test.reset_index(),author_test.reset_index(),author_predicted], axis=1)\ndf_wrong_result.drop('index', axis=1, inplace=True)\ndf_wrong_result=df_wrong_result[df_wrong_result['author']!=df_wrong_result['predicted']]\ndf_wrong_result.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8134a1f0-ced3-e491-d0c5-01389b557a40"},"outputs":[],"source":"df_wrong_result[df_wrong_result['predicted']=='KimKardashian'].head(20)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b5375578-4326-cfa5-689a-4ca3de84de5f"},"outputs":[],"source":"#from sklearn.svm import SVC\n#p = {'clf__C': (1,0.1,0.01,0.001,0.0001)}\n#(author_predicted,author_predicted_b, author_test_b,author_names)=ModelParamsEvaluation(f2_union,SVC(kernel='linear'),p,'SVC, linear kernel')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"190236ec-d669-2de0-8e64-c7cbdf108b76"},"outputs":[],"source":"##PredictionEvaluation(author_predicted_b, author_test_b,author_names,'SVC, linear kernel')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"919db189-9223-d1ee-2094-f68c5956ad04"},"outputs":[],"source":"#plot_confusion_matrix(confusion_matrix(author_test['author'], author_predicted), author_names,\n#                          title='Confusion matrix',\n#                         cmap=plt.cm.Blues)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1441313-a916-424e-ca23-d44504249954"},"outputs":[],"source":"from sklearn.linear_model import SGDClassifier\np = {'clf__alpha': (0.01,0.001,0.0001,0.00001, 0.000001),\n    'clf__penalty': ('l1','l2', 'elasticnet')}\n(author_predicted,author_predicted_b, author_test_b,author_names)=ModelParamsEvaluation (f2_union,SGDClassifier(),p,'SGD Classifier')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb621ab8-27c2-6f12-4f68-520c1c2407a0"},"outputs":[],"source":"PredictionEvaluation(author_predicted_b, author_test_b,author_names,'SGD Classifier')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19ad78b5-b5dd-0ef4-45dc-e1179d8fc31f"},"outputs":[],"source":"plot_confusion_matrix(confusion_matrix(author_test['author'], author_predicted), author_names,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ecc6a82-c821-b9d1-8cf1-3f313dbeecb9"},"outputs":[],"source":"from sklearn.naive_bayes import BernoulliNB\np = {'clf__alpha': (1,0.1,0.01,0.001,0.0001,0)}\n(author_predicted,author_predicted_b, author_test_b,author_names)=ModelParamsEvaluation(f2_union,BernoulliNB(),p,'Bernoulli Naive Bayes')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2d5a500b-280e-b146-38f4-d43f923d597d"},"outputs":[],"source":"PredictionEvaluation(author_predicted_b, author_test_b,author_names,'Bernoulli Naive Bayes')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"362cdb3c-c03a-43ea-b684-9fe31435e8cd"},"outputs":[],"source":"plot_confusion_matrix(confusion_matrix(author_test['author'], author_predicted), author_names,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6adac267-ac47-99f6-0109-a3b19fb7dc14"},"source":"The best method is LinearSVC(C=1). \nSVC with the linear kernel shows worse result then LinearSVC. This is also different from binary classification. LinearSVC uses \"one-vs-rest\" (default) and SVC uses \"one-vs-one\" for multi-class. And SGDClassifier uses \"one-vs-all\" for multi-class classification"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0851ffc8-f1cb-38f8-9c4f-e613dd00e571"},"outputs":[],"source":"df_ScoreSummaryByModelParams=DataFrame(ScoreSummaryByModelParams,columns=['Method','BestScore','BestParameter'])\ndf_ScoreSummaryByModelParams.sort_values(['BestScore'],ascending=False,inplace=True)\ndf_ScoreSummaryByModelParams"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95216b43-e105-e1c7-52d2-e68c5e0fbd06"},"outputs":[],"source":"df_ScoreSummaryByModel=DataFrame(ScoreSummaryByModel,columns=['Precision','Accuracy','Recall','F1','Comment'])\ndf_ScoreSummaryByModel.sort_values(['F1'],ascending=False,inplace=True)\ndf_ScoreSummaryByModel"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}