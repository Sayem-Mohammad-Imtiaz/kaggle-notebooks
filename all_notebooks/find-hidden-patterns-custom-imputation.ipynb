{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data, test_size=0.2, random_state=42)\nX_train = train.drop('Outcome', axis=1)\ny_train = train['Outcome']\nX_test = test.drop('Outcome', axis=1)\ny_test = test['Outcome']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How do the features interact with each other?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nscatter_matrix(train, figsize=(20,16))\nplt.savefig('interactions.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot(x='Insulin', y='Age', style='o');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a Custom Imputer \nAs we can see, some numerical feature interaction reveal these weird streaks at 0. In most cases, these are probably just missing values and thus we should use an imputer to get rid of them. Therefore, I will use a simple RandomForestRefressor to replace the zeros by meaningful values.\n\n(TODO: does a better evaluation lead to (a drastically) better performance of the final model? I will have to test it)\n\nLet's create one pipeline for categorical variables, one pipeline for regular numerical variables and one pipeline for numerical columns with these weird zero-streaks."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.base import TransformerMixin\n\n\nclass ZeroImputer(TransformerMixin):\n    \"\"\"\n    A Transformer for sklearn Pipelines. \n    Replaces zeroes with predicted values.\n    Each Column is treated individually.\n    \"\"\" \n    def __init__(self, col_names):\n        self.col_names = col_names\n        self.models_fitted = [0]*len(col_names)\n        \n    def fit(self, X, y = None):\n        for i,col in enumerate(self.col_names):\n            temp = X[X[col] != 0]\n            X_impute = temp.drop([col], axis=1)\n            y_impute = temp[col]\n            rfr = RandomForestRegressor(random_state=42)\n            rfr_fitted = rfr.fit(X_impute, y_impute)\n            self.models_fitted[i] = rfr_fitted \n        return self\n    \n    def transform(self, X):\n        for i,col in enumerate(self.col_names):\n            temp = X[X[col] == 0]\n            X_impute = temp.drop([col], axis=1)\n            if len(X_impute) > 0:\n                preds_impute = self.models_fitted[i].predict(X_impute)\n                missing = X.loc[X[col] == 0,:][col] \n                X.loc[X[col] == 0,[col]] = preds_impute.reshape(-1,1)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['Pregnancies']\nnum_cols_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\nnum_cols = ['DiabetesPedigreeFunction', 'Age']\nall_cols = X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.compose import ColumnTransformer \n\n\n\nnum_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n\nnum_zeros_pipeline = Pipeline([('imputer', ZeroImputer(col_names=num_cols_zeros))])\n                         \ncat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent'))])\n\npreprocess_pipeline = ColumnTransformer([('cat', cat_pipeline, cat_cols),\n                                         ('num_zero', num_zeros_pipeline, num_cols_zeros),\n                                        ('num', num_pipeline, num_cols)])\n\n\n# This preprocessing-pipeline \n# will be integrated in the full pipeline later on.\n# just for the scatter matrix:\npreprocessed = pd.DataFrame(preprocess_pipeline.fit_transform(X_train))\npreprocessed.columns = all_cols\nscatter_matrix(preprocessed, figsize=(20,16));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got rid of the weird zero-streaks =). But we should still perform some further transformations on our data.\nLet's expand our preprocessing pipeline!"},{"metadata":{},"cell_type":"markdown","source":"# Create a custom Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nnum_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')),\n                        ('scaler', StandardScaler())])\n\nnum_zeros_pipeline = Pipeline([('imputer', ZeroImputer(col_names=num_cols_zeros)),\n                              ('scaler', StandardScaler())])\n                         \ncat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                         ('binning', KBinsDiscretizer(encode='onehot-dense'))])\n\npreprocess_pipeline = ColumnTransformer([('cat', cat_pipeline, cat_cols),\n                                         ('num_zero', num_zeros_pipeline, num_cols_zeros),\n                                        ('num', num_pipeline, num_cols)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train or load the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV \n\nn_estimators_range = np.arange(start=5, stop=400, step=25)\nmax_features_range = np.arange(start=1, stop=5)\nn_bins_range = np.arange(start=2, stop=4)\nrfc = RandomForestClassifier(random_state=42)\n\npipe_base = Pipeline([\n    ('preprocessing', preprocess_pipeline),\n    ('forest', rfc)\n])\n\npipe_base_params = [{'forest__n_estimators': n_estimators_range, \n                     'forest__max_features': max_features_range,\n                    'preprocessing__cat__binning__n_bins': n_bins_range}]\n\ngscv = GridSearchCV(pipe_base, pipe_base_params, cv=5, scoring='f1')\ngscv.fit(X_train, y_train)\npipe_base = gscv.best_estimator_\n\n#load the baseline pipe, run, if you don't want to \n#train the same model over and over again..\n'''with open('pipe_base.pkl',mode='rb') as load_model:\n    pipe_base = joblib.load(load_model)'''\n\n\n\npipe_base_preds = pipe_base.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's evaluate the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(pipe_base_preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score \naccuracy_score(pipe_base_preds, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dump the model\nRun this code if you created a model and you want to store it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('pipe_base.pkl',mode='wb') as load_model:\n    joblib.dump(pipe_base,load_model)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}