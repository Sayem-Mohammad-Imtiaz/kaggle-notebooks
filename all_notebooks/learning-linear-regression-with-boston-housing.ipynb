{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Learning Linear Regression ##\nIn this notebook I am going to try to understand what goes on behind the scenes of linear regression using numpy and pandas <br>\nI am going to load in the Boston Housing dataset and go from there"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# import numpy and pandas\n# also import warnings and ignore them to keep notebook clean\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\") # ignores warnings\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading in the dataset and peeking at the first five rows\ndata = pd.read_csv('../input/BostonHousing.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking some time here to play with some Pandas methods\n#data.index # shows range of indices\n#data.to_numpy() # returns df as a matrix\n#data.describe() # some summary statistics. Notice the counts are all equal so there are no missing values--clean\n#data.info() # gives us some more information and count and datatypes\n#data.T # switches columns with rows\n#data.sort_index(axis=1, ascending = False)# sorts the dataset by the index of each row\n#data[\"tax\"] # returns a single column (series)\n#data[0:3] # row slicing\n#data[\"tax\"][3] # locate a specific value in column. Also can be done with data['tax'].loc[3]\n#data.loc[:, [\"tax\",\"nox\"]] # returns all the rows of two features\n#data.isnull().sum() the first checks for missing values, the second sums them up","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create empty list for coefficients\ncoefficients = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating helper functions to make model more viewable\ndef reshape_X(X):\n    return X.reshape(-1,1) # numpy.reshape returns the m x n matrix of the arguments in this case","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The second helper matrix concatenates a feature of ones to the matrix\ndef concatenate_ones(X):\n    ones = np.ones(shape=X.shape[0]).reshape(-1,1) # np.ones() creates an array of ones\n    return np.concatenate((ones, X), 1) # concatenate basically appends the newly created vector of ones","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating our function to fit the training data\ndef fit(X,y):\n    global coefficients\n    if len(X.shape) == 1:\n        X = reshape_X(X)\n    X = concatenate_ones(X)\n    coefficients = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose()).dot(y) # math to obtain coeff ie. slope\n    print(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a predict function to predict coefficient(??)\ndef predict(entry):\n    b0 = coefficients[0] #initial slope\n    other_betas = coefficients[1:] \n    prediction = b0 # initial prediction\n    \n    for xi, bi in zip(entry, other_betas): \n        # we avoid declaring two for loops by assigning xi to entry and bi to coef.\n        # zip function creates a tuple out of the entry and other_betas\n        prediction += (bi * xi)\n    return prediction\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training ###\nTo train the model, we will fit the dataset without the median value feature (because that is what we are trying to predict) and test how accurate it is in predicting the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(\"medv\", axis=1).values # drops the medv column from the data\ny = data[\"medv\"].values # setting our target equal to the values we just dropped","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First I am going to run OLS (ordinary least squares regression) on the model, then do a train-test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"fit(X,y) # fits our dataset with the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict(X[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So my prediction for the first median value is 30. Let's see for the whole dataset!"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor row in X:\n    predictions.append(predict(row))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    \"Actual\": y,\n    \"Predicted\": predictions\n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try using scikit for linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing matplotlib for graphs \nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_regressor = LinearRegression()\nlinear_regressor.fit(X,y)\nY_pred = linear_regressor.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(predictions, y)\nplt.plot(predictions, Y_pred, color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some things to figure out: how to properly format pyplot, other ML models I can use, figuring out train-test split"},{"metadata":{},"cell_type":"markdown","source":"### References ###\nInspiration for this primarily comes from: https://towardsdatascience.com/multiple-linear-regression-from-scratch-in-numpy-36a3e8ac8014 <br>\n***Additional Resources*** <br>\nhttps://towardsdatascience.com/linear-regression-in-6-lines-of-python-5e1d0cd05b8d <br>\nhttps://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html <br>\nhttps://docs.scipy.org/doc/numpy/ <br>\nhttps://www.markdownguide.org/basic-syntax"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}