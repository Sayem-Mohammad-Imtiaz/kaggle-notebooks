{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nimport pandas as pd\nimport numpy as np\nimport os, sys, gc \nfrom plotnine import *\nimport plotnine\n\nfrom tqdm import tqdm_notebook\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nimport matplotlib as mpl\nfrom matplotlib import rc\nimport re\nfrom matplotlib.ticker import PercentFormatter\nimport datetime\nfrom math import log # IDF 계산을 위해","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/t-academy-recommendation/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.read_json : json 형태의 파일을 dataframe 형태로 불러오는 코드 \nmagazine = pd.read_json(path + 'magazine.json', lines=True) # lines = True : Read the file as a json object per line.\nmetadata = pd.read_json(path + 'metadata.json', lines=True)\nusers = pd.read_json(path + 'users.json', lines=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%%time \nimport itertools\nfrom itertools import chain\nimport glob\nimport os \n\ndef chainer(s):\n    return list(itertools.chain.from_iterable(s))\n\nread_rowwise = pd.read_csv(path + \"read_rowwise.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime \n\nmetadata['reg_datetime'] = metadata['reg_ts'].apply(lambda x : datetime.fromtimestamp(x/1000.0))\nmetadata.loc[metadata['reg_datetime'] == metadata['reg_datetime'].min(), 'reg_datetime'] = datetime(2090, 12, 31)\nmetadata['reg_dt'] = metadata['reg_datetime'].dt.date\nmetadata['type'] = metadata['magazine_id'].apply(lambda x : '개인' if x == 0.0 else '매거진')\nmetadata['reg_dt'] = pd.to_datetime(metadata['reg_dt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_rowwise = read_rowwise.merge(metadata[['id', 'reg_dt']], how='left', left_on='article_id', right_on='id')\nread_rowwise = read_rowwise[read_rowwise['article_id'] != '']\n\n# 사용자가 읽은 글의 목록들을 저장 \nread_total = pd.DataFrame(read_rowwise.groupby(['user_id'])['article_id'].unique()).reset_index()\nread_total.columns = ['user_id', 'article_list']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 콘텐츠 기반의 추천시스템\n- Model의 단어를 이용한 방식\n- TF-IDF 형식\n    - index : 문서의 아이디 \n    - column : 단어 \n\n하지만, 문서가 총 64만개로 너무 많고 data.0의 파일을 읽어보면 단어 또한 너무 많아서 사용하기가 어려운 상황\n\n### 해결방식\n위와 같은 문제를 해결하기 위해서 해당 대회의 1등팀인 NAFMA팀은 글의 키워드를 활용해서 Embedding을 구성 \n- 참고자료 : https://github.com/JungoKim/brunch_nafma","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nmetadata = metadata[metadata['keyword_list'].notnull()].reset_index()\nmetadata = metadata[metadata['reg_dt'] >= '2019-01-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_total = pd.DataFrame(read_rowwise.groupby(['article_id'])['user_id'].unique()).reset_index()\nuser_total.columns = ['article_id', 'user_list']\n\nuser_total['user_len'] = user_total['user_list'].apply(lambda x: len(x))\ncold_article = user_total[user_total['user_len'] <= 20]['article_id'].unique()\nmetadata = metadata[~metadata['id'].isin(cold_article)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"article2idx = {}\nfor i, l in enumerate(metadata['id'].unique()):\n    article2idx[l] = i\n    \nidx2article = {i: item for item, i in article2idx.items()}\narticleidx = metadata['articleidx'] = metadata['id'].apply(lambda x: article2idx[x]).values","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import scipy\n\ndocs = metadata['keyword_list'].apply(lambda x: ' '.join(x)).values\ntfidv = TfidfVectorizer(use_idf=True, smooth_idf=False, norm=None).fit(docs)\ntfidv_df = scipy.sparse.csr_matrix(tfidv.transform(docs))\ntfidv_df = tfidv_df.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tfidv_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"popular_rec_model = read_rowwise['article_id'].value_counts().index[0:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del read_rowwise\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터가 Sparse 형태인 것을 확인할 수 있음","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n\n# 메모리 문제 발생 \ncos_sim = cosine_similarity(tfidv_df, tfidv_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid = pd.read_csv(path + '/predict/dev.users', header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ntop_n = 100\nwith open('./recommend.txt', 'w') as f:\n    for user in tqdm_notebook(valid[0].values):\n        seen = chainer(read_total[read_total['user_id'] == user]['article_list'])\n        for seen_id in seen:\n            # 2019년도 이전에 읽어서 혹은 메타데이터에 글이 없어서 유사도 계산이 안된 글\n            cos_sim_sum = np.zeros(len(cos_sim))\n            try:\n                cos_sim_sum += cos_sim[article2idx[seen_id]]\n            except:\n                pass\n\n        recs = []\n        for rec in cos_sim_sum.argsort()[-(top_n+100):][::-1]:\n            if (idx2article[rec] not in seen) & (len(recs) < 100):\n                recs.append(idx2article[rec])\n\n        f.write('%s %s\\n' % (user, ' '.join(recs[0:100])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://github.com/choco9966/T-academy-Recommendation/blob/master/figure/Contents_Based_Score.PNG?raw=true)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}