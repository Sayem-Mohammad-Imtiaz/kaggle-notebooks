{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cc_apps = pd.read_csv('../input/uci-credit-approval/crx.csv', header=None)\ncc_apps.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print summary statistics\ncc_apps_description = cc_apps.describe()\nprint(cc_apps_description)\n\nprint(\"\\n\")\n\n# Print DataFrame information\ncc_apps_info = cc_apps.info()\nprint(cc_apps_info)\n\nprint(\"\\n\")\n\n# Inspect missing values in the dataset\ncc_apps.tail(17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Handling Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import numpy\nimport numpy as np\n\n# Inspect missing values in the dataset\nprint(cc_apps.tail(17))\n\n# Replace the '?'s with NaN\ncc_apps = cc_apps.replace(to_replace='?',value=np.nan)\n\n# Inspect the missing values again\ncc_apps.tail(17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute the missing values with mean imputation\ncc_apps.fillna(cc_apps.mean(), inplace=True)\n\n# Count the number of NaNs in the dataset to verify\ncc_apps.isnull().count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print summary statistics\ncc_apps_description = cc_apps.describe()\nprint(cc_apps_description)\n\nprint(\"\\n\")\n\n# Print DataFrame information\ncc_apps_info = cc_apps.info()\nprint(cc_apps_info)\n\nprint(\"\\n\")\n\n# Inspect missing values in the dataset\ncc_apps.tail(17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import numpy\nimport numpy as np\n\n# Inspect missing values in the dataset\nprint(cc_apps.tail(17))\n\n# Replace the '?'s with NaN\ncc_apps = cc_apps.replace(to_replace='?',value=np.nan)\n\n# Inspect the missing values again\ncc_apps.tail(17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute the missing values with mean imputation\ncc_apps.fillna(cc_apps.mean(), inplace=True)\n\n# Count the number of NaNs in the dataset to verify\ncc_apps.isnull().count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cc_apps.columns:\n    # Check if the column is of object type\n    if cc_apps[col].dtypes == 'object':\n        # Impute with the most frequent value\n        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# Instantiate LabelEncoder\nle = LabelEncoder()\n\n# Iterate over all the values of each column and extract their dtypes\nfor col in cc_apps.columns:\n    # Compare if the dtype is object\n    if cc_apps[col].dtypes=='object':\n    # Use LabelEncoder to do the numeric transformation\n        cc_apps[col]=le.fit_transform(cc_apps[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\ncc_apps = cc_apps.drop([11, 13], axis=1)\ncc_apps = cc_apps.values\n\n# Segregate features and labels into separate variables\nX,y = cc_apps[:,0:12] , cc_apps[:,13]\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                y,\n                                test_size=0.33,\n                                random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Instantiate MinMaxScaler and use it to rescale X_train and X_test\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n# Instantiate a LogisticRegression classifier with default parameter values\nlogreg = LogisticRegression()\n\n# Fit logreg to the train set\nlogreg.fit(rescaledX_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\n# Use logreg to predict instances from the test set and store it\ny_pred = logreg.predict(rescaledX_test)\n\n# Get the accuracy score of logreg model and print it\nprint(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test,y_pred))\n\n# Print the confusion matrix of the logreg model\nprint(confusion_matrix(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gridsearch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n# Define the grid of values for tol and max_iter\ntol = [0.01,0.001,0.0001]\nmax_iter = [100,150,200]\n\n# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\nparam_grid = dict(tol=tol, max_iter=max_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate GridSearchCV with the required parameters\ngrid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n\n# Use scaler to rescale X and assign it to rescaledX\nrescaledX = scaler.fit_transform(X)\n\n# Fit data to grid_model\ngrid_model_result = grid_model.fit(rescaledX, y)\n\n# Summarize results\nbest_score, best_params = grid_model_result.best_score_,grid_model_result.best_params_\nprint(\"Best: %f using %s\" % (best_score, best_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}