{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"___\n# Iris Dataset Project\n\nWelcome to your Support Vector Machine Project! Just follow along with the notebook and instructions below. We will be analyzing the famous iris data set!\n\n## The Data\n \nThe Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by Sir Ronald Fisher in the 1936 as an example of discriminant analysis. \n\nThe data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor), so 150 total samples. Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n\nHere's a picture of the three different Iris types:","metadata":{}},{"cell_type":"code","source":"# The Iris Setosa\nfrom IPython.display import Image\nurl = 'http://upload.wikimedia.org/wikipedia/commons/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg'\nImage(url,width=300, height=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The Iris Versicolor\nfrom IPython.display import Image\nurl = 'http://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg'\nImage(url,width=300, height=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The Iris Virginica\nfrom IPython.display import Image\nurl = 'http://upload.wikimedia.org/wikipedia/commons/9/9f/Iris_virginica.jpg'\nImage(url,width=300, height=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The iris dataset contains measurements for 150 iris flowers from three different species.\n\nThe three classes in the Iris dataset:\n\n    Iris-setosa (n=50)\n    Iris-versicolor (n=50)\n    Iris-virginica (n=50)\n\nThe four features of the Iris dataset:\n\n    sepal length in cm\n    sepal width in cm\n    petal length in cm\n    petal width in cm\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\niris = pd.read_csv(\"/kaggle/input/iris-flower-dataset/IRIS.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the data and get started!\n\n## Exploratory Data Analysis\n\nTime to put your data viz skills to the test! Try to recreate the following plots, make sure to import the libraries you'll need!\n\n**Import some libraries you think you'll need.**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Create a pairplot of the data set. Which flower species seems to be the most separable?**","metadata":{}},{"cell_type":"code","source":"# Setosa is the most separable. \nsns.pairplot(iris,hue='species',palette='Dark2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create a kde plot of sepal_length versus sepal width for setosa species of flower.**","metadata":{}},{"cell_type":"code","source":"iris['species'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"setosa = iris[iris['species']=='Iris-setosa']\nsns.kdeplot( setosa['sepal_width'], setosa['sepal_length'],\n                 cmap=\"plasma\", shade=True, shade_lowest=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Test Split\n\n** Split your data into a training set and a testing set.**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = iris.drop('species',axis=1)\ny = iris['species']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train a Model\n\nNow its time to train a Support Vector Machine Classifier. \n\n**Call the SVC() model from sklearn and fit the model to the training data.**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_model = SVC()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_model.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation\n\n**Now get predictions from the model and create a confusion matrix and a classification report.**","metadata":{}},{"cell_type":"code","source":"predictions = svc_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow! You should have noticed that the model was pretty good! Let's see if we can tune the parameters to try to get even better (unlikely, and you probably would be satisfied with these results in real like because the data set is quite small, but I just want you to practice using GridSearch.","metadata":{}},{"cell_type":"markdown","source":"## Gridsearch Practice\n\n** Import GridsearchCV from SciKit Learn.**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create a dictionary called param_grid and fill out some parameters for C and gamma.**","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Create a GridSearchCV object and fit it to the training data.**","metadata":{}},{"cell_type":"code","source":"grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\ngrid.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"** Now take that grid model and create some predictions using the test set and create classification reports and confusion matrices for them. Were you able to improve?**","metadata":{}},{"cell_type":"code","source":"grid_predictions = grid.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,grid_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,grid_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You should have done about the same or exactly the same, this makes sense, there is basically just one point that is too noisey to grab, which makes sense, we don't want to have an overfit model that would be able to grab that.","metadata":{}}]}