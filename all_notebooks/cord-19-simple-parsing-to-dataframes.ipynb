{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Parsing the initial CORD-19 Data\n\n- Create separate dataframes for each paper dataset\n- Create an aggregated overall dataframe "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The json data structure\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import walk\nfor (dirpath, dirnames, filenames) in walk('/kaggle/input'):\n    print('Directory path: ', dirpath, 'Folder name: ', dirnames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/5d3612cd95331a2f0c43ef9d03ce583b5ff8c995.json', 'r') as f:\n    test = json.load(f)\ntest.keys()\n# test['paper_id']\n# test['metadata']['title']\n# test['metadata']['authors'][0]['first', 'middle', 'last', 'suffix', 'affiliation', 'email']\n# test['metadata']['authors'][0]['affiliation']['laboratory', 'institution', 'location']\n# test['metadata']['authors'][0]['affiliation']['location']['addrLine', 'postCode', 'region', 'settlement', 'country']\n# test['abstract'][0]['text', 'cite_spans', 'ref_spans', 'section']\n# test['body_text'][0]['text', 'cite_spans', 'ref_spans', 'section']\n# test['bib_entries']['BIBREF0', 'BIBREF2', '...']['ref_id', 'title', 'authors', 'year', 'venue', 'volume', 'issn', 'pages', 'other_ids']\n# test['ref_entries']['FIGREF0', 'FIGREF1', '...'][]'text', 'latex', 'type']\n# test['back_matter']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define utilities for parsing the data. \n\nDo not parse into lists or dicts, better to use strings with delimiters for later reading from csv. Pipe | delimited in this case."},{"metadata":{"trusted":true},"cell_type":"code","source":"def affiliation_parsing(x: dict) -> str:\n    \"\"\"Parse affiliation into string.\"\"\"\n    current = []\n    for key in ['laboratory', 'institution']:\n        if x['affiliation'].get(key):  # could also use try, except\n            current.append(x['affiliation'][key])\n        else:\n            current.append('')\n    for key in ['addrLine', 'settlement', 'region', 'country', 'postCode']:\n        if x['affiliation'].get('location'):\n            if x['affiliation']['location'].get(key):\n                current.append(x['affiliation']['location'][key])\n        else:\n            current.append('')\n    return ', '.join(current)\n\n\ndef cite_parsing(x: list, key: str) -> list:\n    \"\"\"Parse references into lists for delimiting.\"\"\"\n    cites = [i[key] if i else '' for i in x]\n    output = []\n    for i in cites:\n        if i:\n            output.append(','.join([j['ref_id'] if j['ref_id'] else '' for j in i]))\n        else:\n            output.append('')\n    return '|'.join(output)\n\n\ndef extract_key(x: list, key:str) -> str:\n    if x:\n        return ['|'.join(i[key] if i[key] else '' for i in x)]\n    return ''\n\nextract_func = lambda x, func: ['|'.join(func(i) for i in x)]\nformat_authors = lambda x: f\"{x['first']} {x['last']}\"\nformat_full_authors = lambda x: f\"{x['first']} {''.join(x['middle'])} {x['last']} {x['suffix']}\"\nformat_abstract = lambda x: \"{}\\n {}\".format(x['section'], x['text'])\nall_keys = lambda x, key: '|'.join(i[key] for i in x.values())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parse all jsons into dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"for path in ['biorxiv_medrxiv', 'comm_use_subset', 'custom_license', 'noncomm_use_subset']:\n    json_files = [file for file in os.listdir(f'/kaggle/input/CORD-19-research-challenge/{path}/{path}') if file.endswith('.json')]\n    df_list = []\n\n    for js in json_files:\n        with open(os.path.join(f'/kaggle/input/CORD-19-research-challenge/{path}/{path}', js)) as json_file:\n            paper = json.load(json_file)\n            print(path, js)\n        paper_df = pd.DataFrame({\n            'paper_id': paper['paper_id'],\n            'title': paper['metadata']['title'],\n            'authors': extract_func(paper['metadata']['authors'], format_authors),\n            'full_authors': extract_func(paper['metadata']['authors'], format_full_authors),\n            'affiliations': extract_func(paper['metadata']['authors'], affiliation_parsing),\n            'emails': extract_key(paper['metadata']['authors'], 'email'),\n            'abstract': extract_func(paper['abstract'], format_abstract),\n            'abstract_cite_spans': cite_parsing(paper['abstract'], 'cite_spans'),\n            'abstract_ref_spans': cite_parsing(paper['abstract'], 'ref_spans'),\n            'body': extract_func(paper['body_text'], format_abstract),\n            'body_cite_spans': cite_parsing(paper['body_text'], 'cite_spans'),\n            'body_ref_spans': cite_parsing(paper['body_text'], 'ref_spans'),\n            'bib_titles': all_keys(paper['bib_entries'], 'title'),\n            'ref_captions': all_keys(paper['ref_entries'], 'text'),\n            'back_matter': extract_key(paper['back_matter'], 'text')\n        })\n        df_list.append(paper_df)\n    temp_df = pd.concat(df_list)\n    temp_df.to_csv(f'/kaggle/working/{path}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create stacked dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_list = []\nfor path in ['biorxiv_medrxiv', 'comm_use_subset', 'custom_license', 'noncomm_use_subset']:\n    temp_df = pd.read_csv(f'/kaggle/working/{path}.csv')\n    temp_df['dataset'] = path\n    df_list.append(temp_df)\n    \naggregate_df = pd.concat(df_list)\naggregate_df.to_csv(f'/kaggle/working/all_datasets.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aggregate_df  # view the aggregated data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Download the csvs and use them to create an exploration kernel"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}