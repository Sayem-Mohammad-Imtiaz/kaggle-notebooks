{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Imports\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import ensemble\nfrom sklearn import svm\nimport time\nimport random\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nimport math\nimport matplotlib.ticker as plticker\nimport matplotlib.patches as mpatches\nimport matplotlib.lines as mlines\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics \nfrom sklearn.ensemble import AdaBoostClassifier\nimport matplotlib.cm as cm\nfrom matplotlib.colors import Normalize\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import FastICA\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.decomposition import FactorAnalysis\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npos_outcome_var = \"won\"\nneg_outcome_var = \"lost\"\ndata_frames = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        file_path = os.path.join(dirname, filename)\n        data_frames.append(pd.read_csv(file_path))\nbig_frame = pd.concat(data_frames, ignore_index=True)\nbig_frame.info()\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in big_frame:\n#     print (\"col is \", col, \" unique values:  \",big_frame[col].unique())\n#     print (\"#####\")\n#eval_df = pd.DataFrame(data={\"model\":[], \"recall\":[], \"accuracy\":[], \"precision\":[], \"training_time\": []})\neval_df = pd.DataFrame(columns=[\"model\", \"recall\", \"accuracy\", \"precision\"])\nbig_frame = big_frame.drop(columns=[\"tourney_id\",\"tourney_name\", \"draw_size\", \"tourney_date\", \"match_num\", \"winner_id\", \"winner_seed\", \"tourney_level\", \"winner_ioc\",\\\n                                    \"winner_rank_points\", \"winner_entry\",\"winner_name\", \"loser_id\", \"loser_seed\", \"loser_rank_points\", \"loser_entry\", \"loser_ioc\",\\\n                                    \"score\", \"round\", \"loser_name\", \"minutes\",\"surface\", \"winner_hand\", \"winner_ht\", \"winner_age\", \"winner_rank\", \"loser_hand\", \"loser_ht\",\\\n                                    \"loser_age\", \"loser_rank\" ])\nbig_frame = big_frame.dropna()\nbig_frame.info()\n#big_frame[\"surface\"].value_counts()\n# filtered_df = big_frame[(big_frame.surface == \"Hard\")] # | (big_frame.surface == \"Clay\" )] #\"Clay\", \"Grass\", \"Carpet\"])]\nfiltered_df = big_frame[(big_frame.best_of == 3)]\nbig_frame.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"filtered_df[\"best_of\"].value_counts()\nw\nw_ace        44451 non-null float64\nw_df         44451 non-null float64\nw_svpt       44451 non-null float64\nw_1stIn      44451 non-null float64\nw_1stWon     44451 non-null float64\nw_2ndWon     44451 non-null float64\nw_SvGms      44451 non-null float64\nw_bpSaved    44451 non-null float64\nw_bpFaced    44451 non-null float64\nl_ace        44451 non-null float64\nl_df         44451 non-null float64\nl_svpt       44451 non-null float64\nl_1stIn      44451 non-null float64\nl_1stWon     44451 non-null float64\nl_2ndWon     44451 non-null float64\nl_SvGms      44451 non-null float64\nl_bpSaved    44451 non-null float64\nl_bpFaced    44451 non-null float64\n\"\"\"\nlost_df = filtered_df[['l_ace', 'l_df', 'l_svpt','l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_bpSaved', 'l_bpFaced']]\nwon_df = filtered_df[['w_ace', 'w_df', 'w_svpt', 'w_1stIn', 'w_1stWon', 'w_2ndWon','w_SvGms', 'w_bpSaved', 'w_bpFaced']]\nlost_df = lost_df.rename(columns={'l_ace':'ace', 'l_df':'df', 'l_svpt':'svpt','l_1stIn':'1stIn', 'l_1stWon':'1stWon', 'l_2ndWon':'2ndWon', \\\n                                  'l_SvGms':'SvGms', 'l_bpSaved':'bpSaved', 'l_bpFaced':'bpFaced'})\nwon_df = won_df.rename(columns={'w_ace':'ace', 'w_df':'df', 'w_svpt':'svpt','w_1stIn':'1stIn', 'w_1stWon':'1stWon', 'w_2ndWon':'2ndWon',\\\n                                'w_SvGms':'SvGms', 'w_bpSaved':'bpSaved', 'w_bpFaced':'bpFaced'})\n\nall_players = pd.concat(data_frames, ignore_index=True)\nwon_df[pos_outcome_var] = won_df['svpt']**0\nlost_df[pos_outcome_var] = lost_df['svpt']*0\n\nbig_df = pd.concat([won_df, lost_df], ignore_index=True)\nbig_df = big_df.sample(frac=0.02, random_state=1)\nbig_df = big_df.drop(columns=['svpt'])\nbig_df.info\nbig_df = big_df.reset_index()\n\n# lost_df[\"ace_pct\"] = filtered_df.apply(lambda x: x.l_ace / x.l_svpt)\n# won_df[\"ace_pct\"] = filtered_df.apply(lambda x: x.w_ace / x.w_svpt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# util functions\n\ndef eval_for_conclusion(model_id, clf, test_x, test_y):\n    y_pred = clf.predict(test_x)\n    print(classification_report(test_y, y_pred))\n    print(confusion_matrix(test_y, y_pred))\n    accuracy = metrics.accuracy_score(test_y, y_pred)\n    precision = metrics.precision_score(test_y, y_pred)\n    recall = metrics.recall_score(test_y, y_pred)\n    print(\"Final {0} model accuracy:\".format(model_id), accuracy)\n    print(\"Final {0} model precision:\".format(model_id), precision) \n    print(\"Final {0} model recall:\".format(model_id), recall) \n    return {\"model\":model_id, \"recall\":recall, \"accuracy\":accuracy, \"precision\":precision}\n\ndef split_test_train(train_size, all_data):\n    msk = np.random.rand(len(all_data)) < train_size\n    train_df = all_data[msk]\n    test_df = all_data[~msk]\n    train_y = train_df[\"won\"]\n    train_x = train_df.drop(\"won\", axis=1)\n    test_y = test_df[\"won\"]\n    test_x  = test_df.drop(\"won\", axis=1)\n    return (train_x, train_y, test_x, test_y)\n\ndef cross_validate(all_data, model):\n    depth = []\n    all_y = all_data[\"won\"]\n    all_x  = all_data.drop(\"won\", axis=1)\n    for i in range(2,10):\n        # Perform n-fold cross validation \n        scores = cross_val_score(estimator=model, X=all_x, y=all_y, cv=i, n_jobs=4)\n        # print(\"i scores for cv: \", scores)\n        depth.append((i,scores.mean()))\n    # print(depth)\n    return depth\n    \ndef train_and_test(all_data, model):\n    test_scores = []\n    train_scores = []\n    times = []\n    for i in range(1,10):\n        (train_x, train_y, test_x, test_y) = split_test_train(0.1 * i, big_df)\n        #print(\"len test: \", len(test_x), \", len train: \", len(train_x))\n        start = time.time()\n        #TODO iterations\n        model.fit(train_x, train_y)\n        end = time.time()\n        times.append(end - start)\n        pred_test_y = model.predict(test_x) # TODO add wallclock time\n        test_score = round(model.score(test_x, test_y) * 100, 2)\n        pred_train_y = model.predict(train_x)\n        train_score = round(model.score(train_x, train_y) * 100, 2)\n        test_scores.append(test_score)\n        train_scores.append(train_score)\n    return (test_scores, train_scores, times)\n\ndef plot_data(x_vars, x_label, all_y_vars, y_var_labels, y_label, title, y_bounds=None):\n    colors = ['red','orange','black','green','blue','violet']\n    plt.rcParams[\"figure.figsize\"] = (4,3)\n\n    i = 0\n    for y_var in all_y_vars:\n#         if i == 2: # don't plot when i = 1 for cv\n#             x_vars = x_vars[1:]\n        plt.plot(x_vars, y_var, 'o-', color=colors[i % 6], label=y_var_labels[i])\n        i += 1\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    if y_bounds != None:\n        plt.ylim(y_bounds)\n    leg = plt.legend();\n    plt.show()\n\ndef evaluate_model(all_data, model, model_id):\n    (test_scores, train_scores, times) = train_and_test(all_data, model)\n    cv_scores = cross_validate(all_data, model)\n    print(\"{0} train timings (seconds): {1}\".format(model_id, times))\n    print(\"{0} test set scores: {1} \".format(model_id, test_scores))\n    print(\"{0} train set scores: {1}\".format(model_id, train_scores))\n    print(\"{0} cross validation set scores: {1}\".format(model_id, cv_scores))\n    plot_data([x * 10 for x in range(1,10)], \"Percentage of data in training set\", [test_scores, train_scores],\\\n              [\"test_scores\", \"train_scores\"], \"Accuracy\", \"{0} Accuracy Over Train/Test Split\".format(model_id), (50,103))\n    plot_data([x[0] for x in cv_scores], \"Number of folds\", [[x[1] for x in cv_scores]],\n             [\"cross_validation_accuracy\"], \"Accuracy\", \"{0} Accuracy Over Different Cross Validation Values of K\".format(model_id), (0.3,1))\n    plot_data([x * 10 for x in range(1,10)], \"Percentage of data in training set\", [times],\n             [\"times\"], \"Train time in Seconds\", \"{0} Time Spent Training Over Train/Test Split\".format(model_id))\n    return (test_scores, train_scores, times, cv_scores)\n\ndef plot_grid_search(grid_results, plotting_func, title, x_label, y_label, grid_size, model_handles):\n    plt.rcParams[\"figure.figsize\"] = grid_size\n    means = grid_results.cv_results_['mean_test_score']\n    stds = grid_results.cv_results_['std_test_score']\n    params = grid_results.cv_results_['params']\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.subplots\n    ax = plt.subplot()\n    for mean, std, params in zip(means, stds, params):\n        #print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n        plotting_func(mean, params, plt, ax)\n    if handles: plt.legend(handles=model_handles)\n    plt.show()\n\n\n#def grid_search(model, params, x_train, y_train, x_test, y_test):\n    \n\n#TODO come up with graphing function that takes in two arrays of test and train and plots them","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_k_means(x_data, start=1, end=50):\n    ssds = []\n    binary_labels = []\n    n_iter = []\n    binary_k_means = None\n    print(x_data)\n    for k in range(start, end + 1):\n        k_means = KMeans(n_clusters=k, random_state=0).fit(x_data)\n        ssds.append(k_means.inertia_)\n        n_iter.append(k_means.n_iter_)\n        if k == 2:\n            binary_labels = k_means.labels_\n            binary_k_means = k_means\n    return (ssds, binary_labels, binary_k_means, n_iter)\n\ndef match_won_to_clusters(all_data, EM):\n    cluster_counts = [{pos_outcome_var: 0, neg_outcome_var: 0},\n    {pos_outcome_var: 0, neg_outcome_var: 0}]\n    #cluster_id = pd.DataFrame(columns=['Cluster_ID'])\n    cluster_col = np.zeros(len(all_data))\n    cluster_rows = [set(), set()]\n    for i,row in all_data.iterrows():\n        cluster_idx = EM.predict(row.drop(pos_outcome_var).values.reshape(1, -1))[0]\n        key_to_increment = pos_outcome_var if all_data.iloc[i,:][pos_outcome_var] else neg_outcome_var\n        cluster_col[i] = cluster_idx\n        cluster_counts[cluster_idx][key_to_increment] += 1\n        cluster_rows[cluster_idx].add(i)\n    print(\"len cluster rows 0: \", len(cluster_rows[0]))\n    print(\"len cluster rows 1: \", len(cluster_rows[1]))\n\n    cluster_analysis = [\n        big_df[big_df.index.isin(cluster_rows[0])], \n        big_df[big_df.index.isin(cluster_rows[1])]\n    ]\n        \n    return (cluster_counts, cluster_col, cluster_analysis)\ndef plot_cluster_accuracy(data, title=\"Tennis SSD over K for KMC\", print_default=True,\\\n                          x_label=\"Number of Clusters (k)\", y_label=\"Sum of Squared Distances\"):\n    plt.rcParams[\"figure.figsize\"] = (6,4)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.plot(range(1, len(data) + 1), data, '-o')\n    if print_default:\n        default_y = [data[0] / float(i) for i in range(1,len(data) + 1)]\n        plt.plot(range(1, len(data) + 1), default_y, color=\"orange\")\n    plt.show()\n    \ndef k_means_helper(x_reduced, big_df, outcome_var=\"won\"):\n    (ssds, binary_labels, binary_k_means, n_iter) = \\\n    compute_k_means(x_reduced)\n    reduced_with_labels = pd.DataFrame(data=x_reduced, columns=[\"component1\", \"component2\"])\n    reduced_with_labels.insert(2,outcome_var, big_df[outcome_var], True)\n    cluster_counts, cluster_col, cluster_samples = match_won_to_clusters(reduced_with_labels, binary_k_means)\n    reduced_with_labels.insert(2,\"ClusterId\", cluster_col, True)\n    return {\n        \"reduced_with_labels\": reduced_with_labels,\n        \"cluster_counts\": cluster_counts,\n        \"log_likelihoods\": log_likelihoods, \n        \"binary_weights\": binary_weights,\n        \"ssds\": ssds,\n        \"n_iter\": n_iter,\n        \"binary_k_means\": binary_k_means,\n        \"cluster_samples\": cluster_samples\n    }\n    \n\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_y = big_df[pos_outcome_var]\nall_x  = big_df.drop(pos_outcome_var, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(ssds, binary_labels, binary_k_means, n_iter) = compute_k_means(all_x)\n(cluster_counts_k_means, cluster_col_k_means, cluster_analysis_k_means) = match_won_to_clusters(big_df, binary_k_means)\n#print(cluster_counts)\n\nplot_cluster_accuracy(ssds)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_analysis_k_means[0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_analysis_k_means[1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_EM(x_data, start=1, end=50):\n    binary_weights = []\n    log_likelihoods = []\n    n_iter = []\n    binary_EM = None\n    for k in range(start, end + 1):\n        EM = GaussianMixture(n_components=k, random_state=22).fit(x_data)\n        log_likelihoods.append(EM.lower_bound_)\n        n_iter.append(EM.n_iter_)\n        if k == 2:\n            binary_EM = EM\n            binary_weights = EM.weights_\n            \n    return (log_likelihoods, binary_weights, n_iter, binary_EM)\n\ndef get_cluster_samples(cluster_rows):\n    cluster_dfs = [\n        big_df[big_df.index.isin(cluster_rows[0])], \n        big_df[big_df.index.isin(cluster_rows[1])]\n    ]\n    print(\"cluster_0\")\n    cluster_dfs[0].sample(n=30, random_state=1).describe()\n    print(\"cluster_0\")\n    cluster_dfs[1].sample(n=30, random_state=1).describe()\n    return cluster_dfs\n    \ndef match_outcome_to_clusters_EM(all_data, EM):\n    cluster_counts = [{pos_outcome_var: 0, neg_outcome_var: 0},\n    {pos_outcome_var: 0, neg_outcome_var: 0}]\n    #cluster_id = pd.DataFrame(columns=['Cluster_ID'])\n    cluster_col = np.zeros(len(all_data))\n    cluster_rows = [set(), set()]\n    for i,row in all_data.iterrows():\n        cluster_idx = EM.predict(row.drop(pos_outcome_var).values.reshape(1, -1))[0]\n        key_to_increment = pos_outcome_var if all_data.iloc[i,:][pos_outcome_var] else neg_outcome_var\n        cluster_col[i] = cluster_idx\n        cluster_counts[cluster_idx][key_to_increment] += 1\n        cluster_rows[cluster_idx].add(i)\n    print(\"len cluster rows 0: \", len(cluster_rows[0]))\n    print(\"len cluster rows 1: \", len(cluster_rows[1]))\n\n    cluster_analysis = [\n        big_df[big_df.index.isin(cluster_rows[0])], \n        big_df[big_df.index.isin(cluster_rows[1])]\n    ]\n        \n    return (cluster_counts, cluster_col, cluster_analysis)\n\ndef EM_helper(x_reduced, big_df, outcome_var=\"won\"):\n    (log_likelihoods, binary_weights, n_iter, binary_EM) = \\\n    compute_EM(x_reduced)\n    reduced_with_labels = pd.DataFrame(data=x_reduced, columns=[\"component1\", \"component2\"])\n    reduced_with_labels.insert(2,outcome_var, big_df[outcome_var], True)\n    cluster_counts, cluster_col, cluster_samples = match_won_to_clusters(reduced_with_labels, binary_EM)\n    reduced_with_labels.insert(2,\"ClusterId\", cluster_col, True)\n    return {\n        \"reduced_with_labels\": reduced_with_labels,\n        \"cluster_counts\": cluster_counts,\n        \"log_likelihoods\": log_likelihoods, \n        \"binary_weights\": binary_weights, \n        \"n_iter\": n_iter,\n        \"binary_EM\": binary_EM,\n        \"cluster_samples\": cluster_samples\n    }\n    \n\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(log_likelihoods, binary_weights, n_iter, binary_EM) = compute_EM(all_x)\nprint(\"log_likelihoods: \", log_likelihoods)\nprint(\"binary_weights: \", binary_weights)\nprint(\"n_iter: \", n_iter)\n(cluster_counts_EM, cluster_col, cluster_analysis_em) = match_won_to_clusters(big_df, binary_EM)\nplot_cluster_accuracy(log_likelihoods, title=\"Tennis EM Log Likelihoods\", print_default=False, y_label= \"log_likelihoods\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For PCA, what is the distribution of eigenvalues? \npca_first = PCA(n_components=6)\npca_first.fit(all_x)\npca_first.fit(all_x)\nplt.xlabel(\"component number\")\nplt.ylabel(\"captured variance ratio\")\nplt.title(\"Tennis PCA component explanatory power\")\nplt.bar(np.arange(1, 7), pca_first.explained_variance_ratio_)\nprint(pca_first.explained_variance_ratio_)\npca = PCA(n_components=2)\npca.fit(all_x)\nprint(pca.explained_variance_ratio_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_reduced_pca = pca.fit_transform(all_x)\npca_k_means_info = k_means_helper(x_reduced_pca, big_df)\nplot_cluster_accuracy(pca_k_means_info[\"ssds\"], \"Tennis PCA k means\")\npca_EM_info = EM_helper(x_reduced_pca, big_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_k_means_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_k_means_info[\"cluster_samples\"][1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_EM_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_EM_info[\"cluster_samples\"][1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how kurtotic are the distributions? \n#Do the projection axes for ICA seem to capture anything \"meaningful\"?\n#did you get the same clusters as before? Different clusters? Why? Why not?\nica = FastICA(n_components=2)\nx_reduced_ica = ica.fit_transform(all_x)\n\nica_k_means_info = k_means_helper(x_reduced_ica, big_df)\nplot_cluster_accuracy(ica_k_means_info[\"ssds\"], \"Tennis ICA k means\")\n\nica_EM_info = EM_helper(x_reduced_ica, big_df)\nprint(ica_EM_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ica_k_means_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ica_k_means_info[\"cluster_samples\"][1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ica_EM_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ica_EM_info[\"cluster_samples\"][1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assuming you only generate k projections (i.e., you do dimensionality reduction), how well is the data reconstructed by the randomized projections? \n#Do the clusters change every time?\nr_p = GaussianRandomProjection(n_components=2)\nx_reduced_r_p = r_p.fit_transform(all_x)\n\nr_p_k_means_info = k_means_helper(x_reduced_r_p, big_df)\nplot_cluster_accuracy(r_p_k_means_info[\"ssds\"], \"Tennis RP k means\")\n\nr_p_EM_info = EM_helper(x_reduced_r_p, big_df)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r_p_k_means_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r_p_k_means_info[\"cluster_samples\"][1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r_p_EM_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r_p_EM_info[\"cluster_samples\"][1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_a = FactorAnalysis(n_components=2,random_state=3)\nx_reduced_f_a = f_a .fit_transform(all_x)\n\nf_a_k_means_info = k_means_helper(x_reduced_f_a, big_df)\nplot_cluster_accuracy(f_a_k_means_info[\"ssds\"], \"Tennis Factor Analysis k means\")\n\n\nf_a_EM_info = EM_helper(x_reduced_f_a, big_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_a_k_means_info[\"cluster_samples\"][0].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_a_k_means_info[\"cluster_samples\"][1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_a_EM_info[\"cluster_samples\"][0].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_a_EM_info[\"cluster_samples\"][1].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# util functions\n\ndef eval_for_conclusion(model_id, clf, test_x, test_y):\n    y_pred = clf.predict(test_x)\n    print(classification_report(test_y, y_pred))\n    print(confusion_matrix(test_y, y_pred))\n    accuracy = metrics.accuracy_score(test_y, y_pred)\n    precision = metrics.precision_score(test_y, y_pred)\n    recall = metrics.recall_score(test_y, y_pred)\n    print(\"Final {0} model accuracy:\".format(model_id), accuracy)\n    print(\"Final {0} model precision:\".format(model_id), precision) \n    print(\"Final {0} model recall:\".format(model_id), recall) \n    return {\"model\":model_id, \"recall\":recall, \"accuracy\":accuracy, \"precision\":precision}\n\n \ndef split_test_train(train_size, all_data):\n    msk = np.random.rand(len(all_data)) < train_size\n    train_df = all_data[msk]\n    test_df = all_data[~msk]\n    train_y = train_df[pos_outcome_var]\n    train_x = train_df.drop(pos_outcome_var, axis=1)\n    test_y = test_df[pos_outcome_var]\n    test_x  = test_df.drop(pos_outcome_var, axis=1)\n    return (train_x, train_y, test_x, test_y)\n\ndef cross_validate(all_data, model):\n    depth = []\n    all_y = all_data[pos_outcome_var]\n    all_x  = all_data.drop(pos_outcome_var, axis=1)\n    # Perform k-fold cross validation \n    scores = cross_val_score(estimator=model, X=all_x, y=all_y, cv=5, n_jobs=4)\n    depth.append((i,scores.mean()))\n    return depth\n    \ndef train_and_test(all_data, model):\n    test_scores = []\n    train_scores = []\n    times = []\n    for i in range(1,10):\n        (train_x, train_y, test_x, test_y) = split_test_train(0.1 * i, big_df)\n        #print(\"len test: \", len(test_x), \", len train: \", len(train_x))\n        start = time.time()\n        #TODO iterations\n        model.fit(train_x, train_y)\n        end = time.time()\n        times.append(end - start)\n        pred_test_y = model.predict(test_x) # TODO add wallclock time\n        test_score = round(model.score(test_x, test_y) * 100, 2)\n        pred_train_y = model.predict(train_x)\n        train_score = round(model.score(train_x, train_y) * 100, 2)\n        test_scores.append(test_score)\n        train_scores.append(train_score)\n    return (test_scores, train_scores, times)\n\ndef plot_data(x_vars, x_label, all_y_vars, y_var_labels, y_label, title, y_bounds=None):\n    plt.rcParams[\"figure.figsize\"] = (4,3)\n    colors = ['red','orange','black','green','blue','violet']\n    i = 0\n    for y_var in all_y_vars:\n#         if i == 2: # don't plot when i = 1 for cv\n#             x_vars = x_vars[1:]\n        plt.plot(x_vars, y_var, 'o-', color=colors[i % 6], label=y_var_labels[i])\n        i += 1\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    if y_bounds != None:\n        plt.ylim(y_bounds)\n    leg = plt.legend();\n    plt.show()\n\ndef evaluate_model(all_data, model, model_id):\n    (test_scores, train_scores, times) = train_and_test(all_data, model)\n    print(\"{0} train timings (seconds): {1}\".format(model_id, times))\n    print(\"{0} test set scores: {1} \".format(model_id, test_scores))\n    print(\"{0} train set scores: {1}\".format(model_id, train_scores))\n    plot_data([x * 10 for x in range(1,10)], \"Percentage of data in training set\", [test_scores, train_scores],\\\n              [\"test_scores\", \"train_scores\"], \"Accuracy\", \"{0} Accuracy Over Train/Test Split\".format(model_id), (50,105))\n    plot_data([x * 10 for x in range(1,10)], \"Percentage of data in training set\", [times],\n             [\"times\"], \"Train time in Seconds\", \"{0} Time Spent Training Over Train/Test Split\".format(model_id))\n    return (test_scores, train_scores, times)\n\ndef plot_grid_search(grid_results, plotting_func, title, x_label, y_label, grid_size, model_handles):\n    means = grid_results.cv_results_['mean_test_score']\n    stds = grid_results.cv_results_['std_test_score']\n    params = grid_results.cv_results_['params']\n    plt.rcParams[\"figure.figsize\"] = grid_size\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.title(title)\n    plt.subplots\n    ax = plt.subplot()\n    \n    for mean, std, params in zip(means, stds, params):\n        #print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n        plotting_func(mean, params, plt, ax)\n    if model_handles: plt.legend(handles=model_handles)\n    plt.show()\n\n\n#def grid_search(model, params, x_train, y_train, x_test, y_test):\n    \n\n#TODO come up with graphing function that takes in two arrays of test and train and plots them","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(x_reduced_pca, neural_net_classifier, \"Tennis NN PCA\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(x_reduced_ica, neural_net_classifier, \"Tennis NN ICA\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(x_reduced_r_p, neural_net_classifier, \"Tennis NN Randomized Projections\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(x_reduced_f_a, neural_net_classifier, \"Tennis NN Factor Analysis\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(pca_EM_info[\"reduced_with_labels\"], neural_net_classifier, \"Tennis NN PCA with labels\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(ica_EM_info[\"reduced_with_labels\"], neural_net_classifier, \"Tennis NN ICA with labels\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(r_p_EM_info[\"reduced_with_labels\"], neural_net_classifier, \\\n               \"Tennis NN Randomized Projections with labels\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neural_net_classifier = MLPClassifier(max_iter=10000) #, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# tried with6,3 and works great. Other dimensions are horrible\nevaluate_model(f_a_EM_info[\"reduced_with_labels\"], neural_net_classifier, \\\n               \"Tennis NN Factor Analysis with labels\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# neural_net_classifier = MLPClassifier(max_iter=10000, alpha=0.01, hidden_layer_sizes=(6, 3), random_state=1)\n# # tried with6,3 and works great. Other dimensions are horrible\n# (nn_test_scores, nn_train_scores, nn_cv_scores) = evaluate_model(big_df, neural_net_classifier, \"NeuralNet baseline model\")\n# optimal_test_split = nn_test_scores.index(max(nn_test_scores)) * 0.1\n# optimal_test_split = max(optimal_test_split, 0.7)\n\n# print(\"max index for means was: \", optimal_test_split * 10)\n\n\nmlp = MLPClassifier(max_iter=10000)\n#     'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n#     'activation': ['tanh', 'relu'],\n#     'solver': ['sgd', 'adam'],\n#     'learning_rate': ['constant','adaptive'],\nparameter_space = {\n    'activation': ['tanh', 'relu'],\n    'alpha': [0.0001, 0.0005, 0.01, 0.05, 0.1],\n    \"hidden_layer_sizes\": [(3,), (5,), (7,)]\n    \n}\n\nnn_grid_clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n(nn_train_x, nn_train_y, nn_test_x, nn_test_y) = split_test_train(0.8, big_df)\nnn_grid_clf.fit(nn_train_x, nn_train_y)\n# Best paramete set\nprint('Best parameters found:\\n', nn_grid_clf.best_params_)\n\n# All results\nnn_means = nn_grid_clf.cv_results_['mean_test_score']\nnn_stds = nn_grid_clf.cv_results_['std_test_score']\nnn_params = nn_grid_clf.cv_results_['params']\n\nfor mean, std, params in zip(nn_means, nn_stds, nn_params):\n    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\nprint(\"best params \", nn_grid_clf.best_params_)\nnn_grid_score = nn_grid_clf.score(nn_test_x,nn_test_y)\nprint(\"nn grid search model score: \", nn_grid_score)\n\n\n# mlp = MLPClassifier(max_iter=10000, hidden_layer_sizes=(6, 3), alpha=clf.best_params_[\"alpha\"], activation=clf.best_params_[\"activation\"])\n# mlp.fit(nn_train_x, nn_train_y)\n# nn_test_score = round(mlp.score(nn_test_x, nn_test_y) * 100, 2)\n# print(\"nn grid search model score: \", nn_test_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All results\n# nn_means = nn_grid_clf.cv_results_['mean_test_score']\n# nn_stds = nn_grid_clf.cv_results_['std_test_score']\n# nn_params = nn_grid_clf.cv_results_['params']\n\n# for mean, std, params in zip(nn_means, nn_stds, nn_params):\n#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n# print(\"best params \", nn_grid_clf.best_params_)\n\n\ndef plotting_func_nn(mean, params, plt, ax):\n    x_var = \"alpha\"\n    tick_spacing = 0.1\n    layer_colors = {\"(3,)\":\"orange\", \"(5,)\":\"red\", \"(7,)\":\"black\"}\n    activation_labels = {\"tanh\": \"o\", \"relu\":\"s\"}\n    #print(params[\"hidden_layer_sizes\"])\n    layer_color_idx = str(params[\"hidden_layer_sizes\"])\n    activation_idx = params[\"activation\"]\n    ax.plot(math.log(params[x_var],10), mean, activation_labels[activation_idx], color=layer_colors[layer_color_idx])\n    x_loc = plticker.MultipleLocator(base=1.0) # this locator puts ticks at regular intervals\n    ax.xaxis.set_major_locator(x_loc)\n    y_loc = plticker.MultipleLocator(base=0.005) # this locator puts ticks at regular intervals\n    ax.yaxis.set_major_locator(y_loc)\nred_patch = mpatches.Patch(color='orange', label='(3,) layer')\norange_patch = mpatches.Patch(color='red', label='(5,) layer')\nblack_patch = mpatches.Patch(color='black', label='(7,) layer')\ntanh = mlines.Line2D([], [],marker='o',\n                         label='tanh')\nrelu = mlines.Line2D([], [],marker='s',\n                         label='relu')\nhandles = [tanh, relu, red_patch, orange_patch, black_patch]\n\nplot_grid_search(nn_grid_clf, plotting_func_nn, \"Tennis NN accuracy as a function of log(alpha Param)\", \"log(alpha)\", \"accuracy\",(5,7), handles)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_df = pd.DataFrame(columns=[\"model\", \"recall\", \"accuracy\", \"precision\"])\neval_df = eval_df.append(eval_for_conclusion(\"Tennis Neural Network\", nn_grid_clf, nn_test_x, nn_test_y), ignore_index=True)\neval_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_k_means_info[\"reduced_with_labels\"].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}