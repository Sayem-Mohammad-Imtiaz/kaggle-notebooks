{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport matplotlib.animation as animation\nfrom sklearn.model_selection import train_test_split\nfrom osgeo import gdal\nfrom IPython.display import HTML\nfrom base64 import b64encode\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as mpatches\nfrom matplotlib import colors ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Settings","metadata":{}},{"cell_type":"code","source":"dataset = '../input/land-use-land-cover-time-series/time_series.csv'\n\nclasse_info = {\n  'not identified':           {'value':0, 'color': '#000000'},\n  'soybean':                  {'value':1, 'color': '#ffe32e'},\n  'maize':                    {'value':2, 'color': '#FF0000'},\n  'cotton':                   {'value':3, 'color': '#0000FF'},\n  'coffee':                   {'value':4, 'color': '#75781f'},\n  'beans':                    {'value':5, 'color': '#e5eb34'},\n  'wheat':                    {'value':6, 'color': '#ff24e5'},\n  'sorghum':                  {'value':7, 'color': '#a80a96'},\n  'millet':                   {'value':8, 'color': '#fa73eb'},\n  'eucalyptus':               {'value':9, 'color': '#c75e0e'},\n  'pasture':                  {'value':10, 'color': '#fff68f'},\n  'hay':                      {'value':11, 'color': '#c9cf91'},\n  'grass':                    {'value':12, 'color': '#12e362'},\n  'crotalari':                {'value':13, 'color': '#12e362'},\n  'maize+crotalari':          {'value':14, 'color': '#f77159'},\n  'cerrado':                  {'value':15, 'color': '#5e2e10'},\n  'conversion area':          {'value':16, 'color': '#12e0e3'},\n  'uncultivated soil':        {'value':17, 'color': '#a9b0b0'},\n  'ncc':                      {'value':18, 'color': '#12e362'},\n  'brachiaria':               {'value':19, 'color': '#12e362'},\n}\n\nclasses = {x : y.get('value') for x, y in classe_info.items()}\n\nclasse_colors = [y.get('color') for x, y in classe_info.items()]\n\nfeatures = ['red', 'nir', 'swir']\nn_features = len(features)\n\nsequence_size = 30\n\nmodel_dir = './logs'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(dataset)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['class_name'] = df.apply(lambda row: list(classes.keys())[list(classes.values()).index(row['class'])], axis = 1) \ndf['date'] = pd.to_datetime(df['date'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot time series","metadata":{}},{"cell_type":"code","source":"points = df.id.unique()\n\nfor point in points[:7]:\n    point_df = df[df['id'] == point]\n    point_df = point_df.sort_values(by=['date'])\n    ax = point_df.plot(x='date', y=features, figsize=(20, 5))\n\n    axes1 = plt.gca()\n    axes2 = axes1.twiny()\n    \n    class_names = point_df['class_name'].tolist()\n    axes2.set_xticks(np.arange(len(class_names)))\n    axes2.set_xticklabels(class_names, rotation=50, fontsize=12, minor=False)\n\n    axes1.set_ylabel(\"Features\")\n    axes1.set_xlabel(\"Image Date\")\n    axes2.set_xlabel(\"Land Use/Land Cover\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare datasets","metadata":{}},{"cell_type":"code","source":"X = []\ny = []\n\nfor point in points:\n    point_df = df[df['id'] == point]\n    point_df = point_df.sort_values(by=['date'])\n    \n    x_values = point_df[features].to_numpy()\n    y_values = point_df['class'].tolist()\n\n    x_values = tf.keras.preprocessing.sequence.pad_sequences([x_values], \n                                                             maxlen=sequence_size, dtype='float32')[0]\n    y_values = tf.keras.preprocessing.sequence.pad_sequences([y_values], \n                                                             maxlen=sequence_size, \n                                                             value=classes.get('not identified'), dtype='float32')[0]\n    \n    X.append(x_values)\n    \n    labels = []\n    for y_value in y_values:\n        values = np.zeros(len(classes))\n        np.put(values, [y_value], [1])\n        labels.append(values)\n        \n    y.append(labels)\n    \nX = np.array(X)\ny = np.array(y)\n\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split dataset in train, validation and test sets","metadata":{}},{"cell_type":"code","source":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\nX_validation, X_test, y_validation, y_test = train_test_split(X_validation, y_validation, test_size=0.5)\n\nprint(\"Train: \", len(X_train), \"\\nValidation: \", len(X_validation), \"\\nTest:\", len(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create LSTM model","metadata":{}},{"cell_type":"code","source":"def LSTM(n_classes, sequence_size, n_features):\n    model = tf.keras.models.Sequential()\n\n    model.add(tf.keras.layers.LSTM(200, input_shape=(sequence_size, n_features)))\n    \n    model.add(tf.keras.layers.RepeatVector(sequence_size))\n    \n    model.add(tf.keras.layers.LSTM(200, activation='relu', return_sequences=True))\n    \n    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation='relu')))\n\n    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_classes)))\n    \n    model.add(tf.keras.layers.Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    return model\n              \nmodel = LSTM(n_classes=len(classes), sequence_size=sequence_size, n_features=n_features)\n              \nmodel.summary()\n\ntf.keras.utils.plot_model(model, show_shapes=True, to_file='/kaggle/working/model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create callbacks","metadata":{}},{"cell_type":"code","source":"checkpoint_path = \"{dir}/model.ckpt\".format(dir=model_dir)\n\nlatest = tf.train.latest_checkpoint(model_dir)\n\nif latest:\n    model.load_weights(latest)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True)\n\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', \n                                            baseline=None, restore_best_weights=True)\n\ncallbacks = [cp_callback, es_callback]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"epochs = 100\nbatch_size = 128\n\nhistory = model.fit(x=X_train, y=y_train, \n          validation_data=(X_validation, y_validation),\n          epochs=epochs, batch_size=batch_size, callbacks=callbacks, use_multiprocessing=False, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot training and validation loss","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2,1, figsize=(15, 10))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate model","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test, batch_size=128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict image","metadata":{}},{"cell_type":"markdown","source":"### Load image","metadata":{}},{"cell_type":"code","source":"image_path = '../input/land-use-land-cover-time-series/image_2019-10-01_2020-10-01.tif'\npredicted_path = './predicted_2019-10-01_2020-10-01.tif'\ndata_source = gdal.Open(image_path)\nimage = data_source.ReadAsArray()\nimage.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reshape image","metadata":{}},{"cell_type":"code","source":"flat_image = image.reshape(image.shape[0],\n                           image.shape[1] * image.shape[2])\n\nflat_image = flat_image.transpose()\n\nflat_image = flat_image.reshape((flat_image.shape[0],\n                                 int(flat_image.shape[1] / n_features), n_features))\n\nflat_image = np.array(flat_image).astype(float)\n\nflat_image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pad time series","metadata":{}},{"cell_type":"code","source":"padded_image = tf.keras.preprocessing.sequence.pad_sequences(flat_image, maxlen=sequence_size, dtype='float32')\n\npadded_image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reescale time series values. From 0-10000 to 0-1","metadata":{}},{"cell_type":"code","source":"rescaled_image = padded_image / 10000.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict time series","metadata":{}},{"cell_type":"code","source":"flat_predicted = model.predict(rescaled_image, batch_size=1024)\nflat_predicted.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_labels = np.argmax(flat_predicted, axis=2)\nflat_predicted.shape, '-->', flat_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flat_labels.shape, flat_image.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_flat_labels = flat_labels[:,-flat_image.shape[1]:]\nvalid_flat_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_image = valid_flat_labels.reshape((image.shape[1], image.shape[2], valid_flat_labels.shape[-1]))\npredicted_image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_image = predicted_image[:, :, predicted_image.shape[-1] - image.shape[0]:]\npredicted_image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save results\ndriver = data_source.GetDriver()\noutput_dataset = driver.Create(predicted_path,\n                               predicted_image.shape[1],\n                               predicted_image.shape[0],\n                               predicted_image.shape[-1],\n                               gdal.GDT_Byte,\n                               ['COMPRESS=DEFLATE'])\noutput_dataset.SetGeoTransform(data_source.GetGeoTransform())\noutput_dataset.SetProjection(data_source.GetProjection())\n\nfor band_id in range(predicted_image.shape[-1]):\n    band_data = predicted_image[:, : , band_id]        \n    output_dataset.GetRasterBand(band_id + 1).WriteArray(band_data, 0, 0)\noutput_dataset.FlushCache()\ndel output_dataset\nprint(\"Completed!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load predicted image","metadata":{}},{"cell_type":"code","source":"data_source = gdal.Open(predicted_path)\nimage = data_source.ReadAsArray()\nimage.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot predicted image","metadata":{}},{"cell_type":"code","source":"def play(filename):\n    html = ''\n    video = open(filename,'rb').read()\n    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n    return HTML(html)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 10))\n\nims = []\n\ncmap = colors.ListedColormap(classe_colors) \n\nfor band in image:\n    im = ax.imshow(band, vmin=0, vmax=len(classe_colors)-1, cmap=cmap, animated=True)\n    ims.append([im])\n\nani = animation.ArtistAnimation(fig, ims, interval=1000, blit=True, repeat_delay=1000)\n\npatches = list(map(lambda item: mpatches.Patch(color=item[1].get('color'), label=item[0]), classe_info.items() ))\nplt.legend(handles=patches, loc='center left', bbox_to_anchor=(1, 0.5))\n    \n\noutput = '/kaggle/working/predicted.mp4'\n\nani.save(output)\n\nplay(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}