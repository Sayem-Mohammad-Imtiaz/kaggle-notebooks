{"cells":[{"metadata":{"_uuid":"bc11c6ca9008f1ba9a80a1f5319e1b93302a5209","_cell_guid":"c2e90b6a-3d39-45ca-9e35-ffeb73684854","trusted":true},"cell_type":"code","source":"#Straight forward neural network\nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nimport os\n\ndef ingest():\n    data = pd.read_csv('../input/tweets-16m/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-1\", header = None)\n    data.drop([1,2,3,4], axis=1, inplace=True)\n    data.columns = ['sentiment', 'text']\n    data = data[data.sentiment.isnull() == False]\n    data = data[data['text'].isnull() == False]\n    data.sentiment = data.sentiment.apply(lambda x: 'positive' if x == 4 else 'negative')\n    data.reset_index(inplace=True)\n    data.drop('index', axis=1, inplace=True)\n    print ('dataset loaded with shape', data.shape)    \n    return data\n\ndata = ingest()\nvectorizer = TfidfVectorizer(ngram_range = (1,2))\ntfidf_word_freq = vectorizer.fit_transform(tqdm(data.text))\ninput_data = tfidf_word_freq\nn_features = input_data.shape[1]\ntarget = pd.get_dummies(data.sentiment)\n#NN model\nmodel = Sequential()\nmodel.add(Dense(100, activation = 'relu', input_shape = (n_features,)))\nmodel.add(Dense(50, activation = 'relu'))\nmodel.add(Dense(50, activation = 'relu'))\nmodel.add(Dense(2, activation = 'softmax'))\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\nearly_stopping = EarlyStopping(patience = 3)\nmodel.fit(input_data, target, callbacks = [early_stopping], validation_split = 0.2)\n#Save model\nmodel.save('Sentiment_analysis_module.HD5')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f60cc6f8-3ddb-44a7-8ca9-11e6d0622915","collapsed":true,"_uuid":"0253f309f2c3469f7c53bb490b546cb5512e1b02","trusted":false},"cell_type":"code","source":"import pandas as pd # provide sql-like data manipulation tools. very handy.\npd.options.mode.chained_assignment = None\nimport numpy as np # high dimensional vector computing library.\nfrom copy import deepcopy\nfrom string import punctuation\nfrom random import shuffle\n\nimport gensim\nfrom gensim.models.word2vec import Word2Vec # the word2vec model gensim class\nfrom gensim.models.doc2vec import LabeledSentence\n\nfrom tqdm import tqdm\ntqdm.pandas(desc=\"progress-bar\")\n\nfrom nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\ntokenizer = TweetTokenizer()\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f4a91ae-0063-4b9d-9e33-db6bbd23fba1","collapsed":true,"_uuid":"79d9e78d4086dac400ffe8c7e31c7953975af55d","trusted":false},"cell_type":"code","source":"#Straight forward neural network\nimport numpy as np \nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nimport os\n\ndata1 = pd.read_csv('../input/twitter-airline-sentiment/Tweets.csv')[['airline_sentiment', 'text']]\ndata1.columns = ['sentiment', 'text']\ndata2 = pd.read_csv('../input/twitter-sentiment-analysis-with-textblob/twitter_data_2.csv')[['Tweet_text', 'Class']]\ndata2.columns = ['text', 'sentiment']\ndata2.sentiment = data2.sentiment.apply(lambda x: x.lower())\ndata = pd.concat([data1, data2])\n\nvectorizer = TfidfVectorizer(ngram_range = (1,2))\ntfidf_word_freq = vectorizer.fit_transform(data.text)\ninput_data = tfidf_word_freq\ntarget = pd.get_dummies(data.sentiment)\n#NN model\nmodel = Sequential()\nmodel.add(Dense(300, activation = 'relu', input_shape = (172685,)))\nmodel.add(Dense(300, activation = 'relu'))\nmodel.add(Dense(300, activation = 'relu'))\nmodel.add(Dense(300, activation = 'relu'))\n#model.add(Dense(200, activation = 'relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(130, activation = 'relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(130, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50, activation = 'relu'))\nmodel.add(Dense(3, activation = 'softmax'))\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\nearly_stopping = EarlyStopping(patience = 3)\n#model.fit(input_data, target, callbacks = [early_stopping])\n#Save model\n#model.save('Sentiment_analysis_module_2.HD5')\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"481bc8c3-6880-4779-803a-a7739a36ee2c","collapsed":true,"_uuid":"12c7a0a6923e71198a19ed348439d64e1e9977a3","trusted":false},"cell_type":"code","source":"#Straight forward Neural network prediction on test set\nimport os\nimport numpy as np \nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport keras\nfrom sqlalchemy import create_engine\ndata1 = pd.read_csv('../input/twitter-airline-sentiment/Tweets.csv')[['airline_sentiment', 'text']]\ndata1.columns = ['sentiment', 'text']\ndata2 = pd.read_csv('../input/twitter-sentiment-analysis-with-textblob/twitter_data_2.csv')[['Tweet_text', 'Class']]\ndata2.columns = ['text', 'sentiment']\ndata2.sentiment = data2.sentiment.apply(lambda x: x.lower())\ndata = pd.concat([data1, data2])\ndata_test = pd.read_csv('../input/twitter-sentiment-analysis/twitter_data_1.csv')\n#Vectorizer\nvectorizer = TfidfVectorizer(ngram_range = (1,2))\ntfidf_word_freq = vectorizer.fit(data.text)\ninput_data = vectorizer.transform(data_test.dropna().Tweet_text)\nmodel = keras.models.load_model('Sentiment_analysis_module_2.HD5')\npreds = model.predict(input_data)\ndef get_index(row):\n    x = max(row)\n    if x == row[0]:\n        return 0;\n    if x == row[1]:\n        return 1;\n    return 2\n\nresult_set = ['negative', 'neutral', 'positive']\ncount = 0\nfor row in range(len(preds)):\n    if (result_set[get_index(preds[row])] == data_test.Class[row].lower()):\n        count+=1\nprint('Accuracy on test set using NN: ', count/len(preds))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3c74a8c6-cef7-470e-8035-7d56563e2835","collapsed":true,"_uuid":"9426550c49d64a462c5d4f7fb987528c70009348","trusted":false},"cell_type":"code","source":"#Straight forward Neural network prediction on test set\nimport os\nimport numpy as np \nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport keras\nfrom sqlalchemy import create_engine\ndata = pd.read_csv('../input/twitter-airline-sentiment/Tweets.csv')\n#Databse connection and fetch\nengine = create_engine('../input/twitter-airline-sentiment/database.sqlite')\ncon = engine.connect()\nrs = con.execute('select airline_sentiment, text from Tweets')\ndata_test = pd.DataFrame(rs.fetchall())\ndata_test.columns = rs.keys()\n#Vectorizer\nvectorizer = TfidfVectorizer(ngram_range = (1,2))\ntfidf_word_freq = vectorizer.fit(data.text)\ninput_data = vectorizer.transform(data_test.text)\nmodel = keras.models.load_model('Sentiment_analysis_module_2.HD5')\npreds = model.predict(input_data)\ndef get_index(row):\n    x = max(row)\n    if x == row[0]:\n        return 0;\n    if x == row[1]:\n        return 1;\n    return 2\n\nresult_set = ['negative', 'neutral', 'positive']\ncount = 0\nfor row in range(len(preds)):\n    if (result_set[get_index(preds[row])] == data_test.airline_sentiment[row]):\n        count+=1\nprint('Accuracy on test set using NN: ', count/len(preds))","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}