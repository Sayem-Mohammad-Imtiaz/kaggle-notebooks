{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import precision_recall_fscore_support\nimport matplotlib.pyplot as plt\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Questions.csv', encoding='ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['all_text'] = df['Title'] + ' ' + df['Body']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bad_question(score):\n    if score < 0:\n        return 1\n    else:\n        return 0\n\ndf['bad_question'] = df['Score'].apply(lambda x: bad_question(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_questions = df[['all_text', 'bad_question']]\ntrain, test = train_test_split(df_questions, test_size=0.05, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bad = train.loc[train['bad_question'] == 1]\ntrain_good = train.loc[train['bad_question'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fix severe class imbalance in training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_bad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_good)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"good_sample = train_good.sample(frac=0.05)\ntrain = good_sample.append(train_bad)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean text"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['all_text'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['all_text'] = df['all_text'].apply(lambda x: re.sub('(\\<code\\>.*?<\\/code\\>)', '', x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['all_text'] = df['all_text'].apply(lambda x: re.sub('<[^>]+>', '', x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['all_text'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Try using tfidf features\n#### https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(train['all_text'])\nX_train_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nX_train_tfidf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_counts = count_vect.transform(test['all_text'])\nX_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators = 5, n_jobs = -1, verbose=1, class_weight=\"balanced\")\n#clf = MLPClassifier(hidden_layer_sizes = (10, 10), verbose=True, early_stopping=True)\nclf.fit(X_train_tfidf, train['bad_question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test_tfidf)\ny_pred_train = clf.predict(X_train_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_recall_fscore_support(train['bad_question'], y_pred_train, average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_recall_fscore_support(test['bad_question'], y_pred, average='macro')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Try using RNN\n#### https://www.tensorflow.org/alpha/tutorials/sequences/text_classification_rnn\n#### https://www.kaggle.com/kredy10/simple-lstm-for-text-classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train['all_text']\ny_train = train['bad_question']\nX_test = test['all_text']\ny_test = test['bad_question']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_words = 2000\nmax_len = 150\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RNN():\n    inputs = Input(name='inputs',shape=[max_len])\n    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n    layer = LSTM(64)(layer)\n    layer = Dense(256,name='FC1')(layer)\n    layer = Activation('relu')(layer)\n    layer = Dropout(0.9)(layer)\n    layer = Dense(1,name='out_layer')(layer)\n    layer = Activation('sigmoid')(layer)\n    model = Model(inputs=inputs,outputs=layer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RNN()\nmodel.summary()\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"history = model.fit(sequences_matrix,y_train,batch_size=128,epochs=20,\n          validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sequences = tok.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"y_hat = model.predict(test_sequences_matrix, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat[y_hat > 0.5] = 1\ny_hat[y_hat <= 0.5] = 0\nprecision_recall_fscore_support(y_test, y_hat, average='macro')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spacy\n\n#### https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\nfrom sklearn.base import TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom nltk.corpus import stopwords\nfrom sklearn.svm import LinearSVC\nimport string\nimport re\nimport spacy\nspacy.load('en')\nfrom spacy.lang.en import English\nparser = English()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))\nSYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\"]\n\nclass CleanTextTransformer(TransformerMixin):\n    def transform(self, X, **transform_params):\n        return [cleanText(text) for text in X]\n    def fit(self, X, y=None, **fit_params):\n        return self\n\ndef get_params(self, deep=True):\n        return {}\n    \ndef cleanText(text):\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n    text = text.lower()\n    return text\n\ndef tokenizeText(sample):\n    tokens = parser(sample)\n    lemmas = []\n    for tok in tokens:\n        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n    tokens = lemmas\n    tokens = [tok for tok in tokens if tok not in STOPLIST]\n    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n    return tokens\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n\nclf = LinearSVC()\n\npipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pipe.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision_recall_fscore_support(y_test, y_pred, average='macro')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}