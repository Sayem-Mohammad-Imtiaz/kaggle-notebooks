{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\npd.set_option('display.max_columns',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will first check for nan values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see there are no nan values present in the dataset."},{"metadata":{},"cell_type":"markdown","source":"We will extract all the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [feature for feature in df.columns if feature!= 'target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividing it into Discrete and Continous."},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_feature = [ feature for feature in features if len(df[feature].unique()) < 10 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will go for count plot for understanding insight of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in dis_feature:\n    sns.countplot(x=feature,data=df,hue='target')\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above,\n\n            1 : cp,ca,slope,thal are playing important role with respect to target.\n            2 : fbs has 50-50% probability. so,it is weak to predict the target"},{"metadata":{},"cell_type":"markdown","source":"Relationship of every feature with respect to target."},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in dis_feature:\n    df.groupby(feature)['target'].mean().plot()\n    plt.xlabel(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As, they are not in perfect relationship, we will bring it to monotonic relationship with the help of target guided encoding. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in dis_feature:\n    mean = df.groupby(feature)['target'].mean()\n    index = mean.sort_values().index\n    ordered_labels = { k:i for i,k in enumerate(index,0) }\n    df[feature] = df[feature].map(ordered_labels)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in dis_feature:\n    df.groupby(feature)['target'].mean().plot()\n    plt.xlabel(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, all the features are now in monotonic relationship. "},{"metadata":{},"cell_type":"markdown","source":"Extracting Continous features."},{"metadata":{"trusted":true},"cell_type":"code","source":"con_feature = [ feature for feature in features if feature not in dis_feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"con_feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First and foremost we will check histogram of each feature. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in con_feature:\n    df[feature].hist(bins=10)\n    plt.xlabel(feature)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above all the features, oldpeak is highly skewed.\n\nThe 1/3 rd of oldpeak are 0(zeros). so,we will use it as it is."},{"metadata":{},"cell_type":"markdown","source":"According to above histograms, there we will be very few outliers."},{"metadata":{},"cell_type":"markdown","source":"Now, we will check for outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in con_feature:\n    sns.boxplot(x=feature,data=df)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As predicted there are very few outliers."},{"metadata":{},"cell_type":"markdown","source":"For Feature selection, we are using SelectKbest and chi2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selectk = SelectKBest(score_func=chi2,k=9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scores = selectk.fit(df.drop('target',axis=1),df['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scores.scores_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores = pd.DataFrame(feature_scores.scores_)\ndf_features = pd.DataFrame(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_scores = pd.concat([df_features,df_scores],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_scores.columns = ['features','scores']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_scores.sort_values(by='scores',ascending=False,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As I already discussed in Feature engneering cp,thal are more correlated with target."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many features with correlation more than 0.4."},{"metadata":{},"cell_type":"markdown","source":"Extracting those features which scored more than 18."},{"metadata":{"trusted":true},"cell_type":"code","source":"Best_features = features_scores[features_scores['scores']>18]['features'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Best_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are using Ensemble technique because it does not over fit. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(model,df[Best_features],df['target'],cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see we have got 82% accuracy.\n"},{"metadata":{},"cell_type":"markdown","source":"We will tune the parameters of Random Forest to improve further accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators' : list(np.arange(10,101,1)),\n    'max_depth' :  list(np.arange(3,30,1)),\n    'min_samples_leaf' :  list(np.arange(1,10,1)),\n    'min_samples_split' :  list(np.arange(1,10,1))\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search = RandomizedSearchCV(model,param_distributions=params,n_jobs=-1,n_iter=10,scoring='f1_macro',cv=5,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(df[Best_features],df['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=22, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=4, min_samples_split=7,\n                       min_weight_fraction_leaf=0.0, n_estimators=41,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(model,df[Best_features],df['target'],cv=10).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see,Hyper Parameter tuninig improved accuracy to 84%"},{"metadata":{},"cell_type":"markdown","source":"#### I hope you learned some new things..."},{"metadata":{},"cell_type":"markdown","source":"#### Thank You."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}