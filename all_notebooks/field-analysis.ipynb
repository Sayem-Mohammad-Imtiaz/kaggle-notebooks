{"cells":[{"metadata":{"_cell_guid":"62525925-a0f6-47a6-a4bd-5d1333554c21","_uuid":"d9c3a94f0626814acb32ab335adc912947a23483"},"source":"# Naukri Lisitngs\n### Dataset available at Kaggle - https://www.kaggle.com/PromptCloudHQ/jobs-on-naukricom\n#### Created by 'Nishchal Gaba' (nishgaba9@gmail.com)(October 2017)\n#### GitHub: https://github.com/nishgaba-ai/Kaggle/Datasets/\n#### NOTE: The extensive analysis for some fields such as 'Job Description' might require techniques of Natural Language Processing (NLP) as they are not deemed necessary currently for this kernel version as well as the analysis of the trends in job payrates and postings","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"1dc921d83710161fb5ad009fbad1f369d9aabb79","_cell_guid":"2b894784-2627-425f-b65a-c722f4e1de72"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"57f6b2fe5cd63753b9a3a8d0d210f797c474441c","_cell_guid":"23a0e4e9-5bce-49be-ad16-5b01456a5095"},"source":"# Import files\n# NOTE: Some of the imported packages are not used, they are just used as usual imports\nimport os\nimport sys\nimport numpy as np\nimport matplotlib as plt\nimport tensorflow as tf\nimport time\nimport random\nimport math\nimport pandas as pd\nimport sklearn\nfrom scipy import misc\nimport glob\nimport pickle\nimport re\n%matplotlib inline\nplt.pyplot.style.use('ggplot')","cell_type":"code"},{"metadata":{"_cell_guid":"4e6a5d81-6e5a-498f-9d19-bab9e8e14357","_uuid":"2d4122383e71cc307c344cd37d74b8efda2b7046"},"source":"### * Importing the dataset","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"8c5abfb9-bc46-41fd-8409-7057c66a1b7d","_uuid":"c5b3995a67f54692b4784ce504951ce8de82b156"},"source":"dataSet = pd.read_csv('../input/naukri_com-job_sample.csv')","cell_type":"code"},{"metadata":{"_cell_guid":"07fb5d50-4bc9-4704-a069-3410d6e4ffaf","_uuid":"c60bca8dfac55c2e07e3b45eeca36f1e9d75c199"},"source":"### * An overview of the dataset","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"4d0bfc03-7e51-4454-a58f-4532fdeb911b","_uuid":"bd4cacd7a8549a3ea6a0b259de2ae86458cdc352"},"source":"# Dataset headers or column names\nheads = list(dataSet)\nprint(\"Number of columns : \"+str(len(heads)))\ndataSet.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"b766d6b3-2959-443d-a537-544a8dd0deb4","_uuid":"ab87a1cd3a6b679bbe488c824b9957cf5f484abf","collapsed":true},"source":"# Dissecting the dataset\n#This dataset has following fields: (Ref: https://www.kaggle.com/PromptCloudHQ/jobs-on-naukricom)\n\n#    company\n#    education\n#    experience\n#    industry\n#    job description\n#    jobid\n#    joblocation_address\n#    job title\n#    number of positions\n#    pay rate\n#    postdate\n#    site_name\n#    skills\n#    uniq_id","cell_type":"code"},{"metadata":{"_cell_guid":"2d35d793-c7a9-4ed5-babc-5e8dca30d61f","_uuid":"17c955976c7a4b6e4f900da7fdf0a42428744fa8"},"source":"### * Need for preprocessing","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_uuid":"023aa4d21ae79f8c2e7effb3d41720b9008bd506","_cell_guid":"0dcff244-e0b2-4474-abfa-8791c7ef3ea5"},"source":"# When we try to do Pattern Recognition or Corelation Analysis, we have to consider what fields to use in them\n# Also what kind of changes we have to make in a field for it to be used to in the data analysis\n# Some fields might require parsing to convert the human language into a statistical value or even a category\n\n# NOTE:\n### We will be looking at each field individually to understand the techniques for data processing\n### This will help to learn how a particular type of data is turned into an input for Machine Learning Algorithms","cell_type":"code"},{"metadata":{"_cell_guid":"408b98e0-7f81-421b-8858-929417ab55e1","_uuid":"71a7a44b9616929d53ed16a8b67c25199d60618c"},"source":"#### Field 1 - Company Name","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"0100078e-0839-4aad-9a47-24a39aac86a0","_uuid":"65a86965dc30da0649b0214f1d22b732812e0f8b"},"source":"# Field-1\n# Company Name\nprint(heads[0])\nprint(type(heads[0]))\n\n# An example name looks like\nprint(dataSet[heads[0]][0])\n\n\n# Suggested Use:\n### We can use it for individual company analytics as there is no industry mentioned for the company as well\n### To classify it into some kind of sector e.g. Steel Sector, IT Sector\n### Hence, for Analysis of trends in payrates, or salaries based on experience, this field can be skipped\n### Principal Component Analysis (PCA) is used for the dimensionality-reduction in statistics, but as this field is a string\n### We either have to declare numerical counterparts for such fields before including them in statistical analysis\n### or We can do company wise analysis as mentioned earlier\n\n# If you check out some data mining books, such data without any order is  'categorical' data","cell_type":"code"},{"metadata":{"_cell_guid":"a7ab92b3-3fb7-4b39-97e6-b97092cec395","_uuid":"9fe2d4e3a7c14f1a8c3879226faacd063e0a98ac"},"source":"#### Field 2 - Education","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"0699da0d-5c59-49a7-936c-08d05124c9c8","_uuid":"2710072d6fb754696fbdd9f4a60c5aa5ce737cca"},"source":"# Field-2\n# Education\nprint(heads[1])\nprint(type(heads[1]))\n\n# An example name looks like\nprint(dataSet[heads[1]][0])\n\n\n# Suggested Use:\n### This is a string as well, but this needs to be 'parsed' into different skills and can be useful for the dataset\n### Education skills for Under Graduate(UG) and Post Graduate(PG) can help form a trend analysis to see\n### which skills have the highest pay, or are in demand\n### This would be a 'categorical' data as well,\n### Because, e.g. Jobs for Computers and Media Technology may be different but they don't bear a rank among themselves\n\n\n# We take 'any' as a catergory as well, but its semantic meaning implies to the requirements mentioned in the particular job post\n# Parsing the data to extract the skills for both UG and PG\n# 'UG' and 'PG' are both followed by ':' which makes it a good first candidate for splitting between the Two parts of strings\n# As they are different levels of qualification\n\n# NOTE: The Analysis and preprocessing for this field will be released in the upcoming kernel very soon","cell_type":"code"},{"metadata":{"_cell_guid":"83ca688b-d327-441e-89a2-2ce6a8b91acc","_uuid":"4ec602116888d029bdfcbe1cb6889a840caadd07"},"source":"#### Field 3 - Experience","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7db8a228-4106-4c30-8926-cca725c00390","_uuid":"22c165d588a10c51385176f6a0b15ffd67521046"},"source":"# Field-3\n# Experience\nprint(heads[2])\nprint(type(heads[2]))\n\n# An example name looks like\nprint(\"\\nBefore Processing: \")\nprint(dataSet[heads[2]][10])\n\n# We process this field and now get the splits based on \"-\" and replace everything not a digit\nexp = []\nfor i in range(len(dataSet)):\n    exp.append(((str(dataSet[heads[2]][i])).replace(\" \",\"\")).split(\"-\"))\n    \nfor i in range(len(exp)):\n    for j in range(len(exp[i])):\n        exp[i][j] = re.sub(r'[^0-9]','',exp[i][j])\n# An Example after processing\nprint(\"\\nAfter Processing: \")\nprint(exp[10])","cell_type":"code"},{"metadata":{"_cell_guid":"ae327ea1-2925-40dd-8f03-2ac076dcffa7","_uuid":"1101a7b448d0404d7048fce95cba14d0ae08b1c4"},"source":"#### Field 4 - Industry","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"9150d318-66c8-4e97-827c-497ae42cbb3e","_uuid":"5d7a515cb0d28252676ed4f40e36321d6dabd235"},"source":"# Field-4\n# Industry\nprint(heads[3])\nprint(type(heads[3]))\n\n# An example name looks like\nprint(dataSet[heads[3]][0])\n\n# Storing the Industries for different jobs, splitting with \"/\" and \" \" and removing all spaces using 'replace', otherwise they would occur in the list\n### NOTE: The dataSet in this field had one object being recognized as float, hence we have to str() the field\n### inspite of it being a 'str' type field, we will be able to filter out that number when we try to see,\n### the categories of industries involved, as we will produce different industries and their number of occurences\nIndustry=[]\nfor i in range(len(dataSet)):\n    Industry.append(((str(dataSet[heads[3]][i])).replace(\" \",\"\")).split(\"/\"))\nprint(len(Industry))\n\n# an example of how the industries currently look like\nprint(Industry[10])","cell_type":"code"},{"metadata":{"_cell_guid":"4a3a5989-3ef2-4454-963b-edd7e6c90388","_uuid":"3e11971e9d612a61eb40b3321df070a18816020b"},"source":"#### Field 5 - Job Description","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"c11f77bb-4bb4-4b1b-9608-cbebf7353083","_uuid":"08cd48c5047a79c7a307d6e65f7bdad77f8f9281"},"source":"# Field-5\n# Job Description\nprint(heads[4])\nprint(type(heads[4]))\n\n# An example name looks like\nprint(dataSet[heads[4]][0])\n\n# This is a whole description about the job post,which may have relevant information\n# By first look ,  : - == > , may seem like a separator for parsing, but if we look closely, the field description before it is \n# mixed with the next field name, e.g. Knowledge Job Requirement : - == > System or Laptop Type of job: - == > Full Time or Part time\n# Here, Job Requirement seems like a possible field and Type of Job, but they are both together\n# To clean the data, we would require the NLP(Natural Language Processing) after initial cleaning\n# which may be implemented in the upcoming versions of this kernel","cell_type":"code"},{"metadata":{"_cell_guid":"338ed216-f40b-4fc3-9b76-1e2e25122c09","_uuid":"260f4b8784ad86baf5964445ef2271fd472e661f"},"source":"#### Field 6 - Job Id","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f4829cfa-5e5c-4db7-9c73-91d1358c627c","_uuid":"4d8d5308df32b8600da8a3554d590fafc822a681"},"source":"# Field-6\n# Job Id\nprint(heads[5])\nprint(type(heads[5]))\n\n# An example name looks like\nprint(dataSet[heads[5]][0])\n\n# Job Id is useful to search for the job using this number, but for analysis, it can serve the same purpose, as locating\n# a particular job column\n# An example of finding the index of a job based on the 'jobid' and this index can be used in other columns to find this record\n# Although we know the index would be one, but may be due to duplicacy in data, with some different field values for only one or two columns\n# The jobs would not be seen as identical by duplicacy removal programs everytime, and hence it may be more than 1 index too\n# So we safely turn it into a list so that there is no disurption in the running of the program\nidx = dataSet.jobid[dataSet.jobid == 210516002263].index.tolist()\nprint(idx)","cell_type":"code"},{"metadata":{"_cell_guid":"bd2af363-3b1c-4f9e-bd8f-8094110fd1ed","_uuid":"c3c1b927f4454c1d1cf7c7fff62f18b4d2d2667e"},"source":"#### Field 7 - Job Location Address","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f638f46c-1da7-440d-911c-7bebb6e6f56e","_uuid":"35a9d2b91df1740f829b522c48c86b5c9a1907bb"},"source":"# Field-7\n# Job Location Address\nprint(heads[6])\nprint(type(heads[6]))\n\n# An example name looks like\nprint(dataSet[heads[6]][0])\nprint(dataSet[heads[6]][10]) # It can contain multiple locations too, so we have to use the splitting again using ','\n\n# Locations list\nLocations=[]\nfor i in range(len(dataSet)):\n    Locations.append(((str(dataSet[heads[6]][i])).replace(\" \",\"\")).split(\",\"))\nprint(len(Locations))\n# An Example of Locations list\nprint(Locations[10])","cell_type":"code"},{"metadata":{"_cell_guid":"10c7cc7c-327a-4cd2-8bb8-39f2f37d064b","_uuid":"26e4d818e87dc35bd83aadef2a7683b357882d46"},"source":"#### Field 8 - Job title","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"0b9c4b03-9c5c-4533-abb4-25e3f3170799","_uuid":"6f465298a4aeff7e4afbd0bc03f2b5717eda169e"},"source":"# Field-8\n# Job Title\nprint(heads[7])\nprint(type(heads[7]))\n\n# An example name looks like\nprint(dataSet[heads[7]][0])\nprint(dataSet[heads[7]][200])\n\n# Another field, requiring cleaning and understanding the structure, hence skipped for current analysis\n### As can be seen in the two examples printed, it varies heavily on the job poster and sometimes is full of information\n### not belonging to this field\n### e.g. Day Shift is the type of Job, and it is mentioned twice in this example as dayshift, Day Shift","cell_type":"code"},{"metadata":{"_cell_guid":"b4df17c0-a1ec-4bec-9fd4-a2847fa191e0","_uuid":"328db1265cd1402b2be421a03352f0ea4bf4096e"},"source":"#### Field 9 - Number of Positions","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"596fef07-663e-4abf-8dac-54252a73bf58","_uuid":"0dc56b6a14ba9836af8150a33b6bec34ed8476ec"},"source":"# Field-9\n# Number of Positions\nprint(heads[8])\nprint(type(heads[8]))\n\n# An example name looks like\nprint(dataSet[heads[8]][0])\n\n\n# Number of disclosed job postings\n# Although the class is string, when passed to np.nansum, it will be parsed to its equivalent float value\n# nansum treats NaN as zero\nprint(\"Number of Disclosed Positions: \"+str(np.nansum(dataSet['numberofpositions'])))","cell_type":"code"},{"metadata":{"_cell_guid":"b0355404-8a28-4192-abc6-a7ddfaa38479","_uuid":"77158bc4770f85ac1448003e01c82569671f2cc9"},"source":"#### Field 10 - Pay Rate","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e5c36749-cf44-40ab-b218-350337bc7041","_uuid":"68ba2056684f7de135ce5a2bb8a77ef5772ccd9d"},"source":"# Field-10\n# Pay Rate\nprint(heads[9])\nprint(type(heads[9]))\n\n# An example name looks like\nprint(dataSet[heads[9]][0])\n\n# Lets split the salaries first with '-' later, we can replace everything except numbers with \"\"\npayrates=[]\nfor i in range(len(dataSet)):\n    payrates.append(((str(dataSet[heads[9]][i]))).split(\"-\"))\n\nprint(len(payrates))\n# An Example of payrates list\nprint(\"\\nBefore Processing: \")\nprint(payrates[0])\nprint(payrates[10])\n\n# Checking if the string has a digit, because some categories are \"Not Disclosed by Recruiter\"\n# If we process the strings for numbers these will cause problems\n# Hence, we will run one more loop to clean it, we could have done it in the previous loop too,\n# But to demonstrate the problems such as the example having '2,25,000 P.A' as one of the values\n# We will clean it in another loop, where we will replace all values except for digits in a string \n# having at least one digit by \"\" which will remove whitespaces and \",\" and \"P.A\" or any other strings\nfor i in range(len(payrates)):\n    for j in range(len(payrates[i])):\n        payrates[i][j] = re.sub(r'[^0-9]','',payrates[i][j])\n# An Example after processing\nprint(\"\\nAfter Processing: \")\nprint(payrates[0])\nprint(payrates[10])","cell_type":"code"},{"metadata":{"_cell_guid":"429f2ef2-fbf5-4a55-8e36-dc1b58d390e0","_uuid":"bb68ba347d5b6603e5f87f05939e25fe5c9790c1"},"source":"#### Field 11 - Post Date","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"921ba755-2fa3-4e10-9045-3d8ebb364d3a","_uuid":"00d9dbcb0eab62b297f6d961b174410fb73962c6"},"source":"# Field-11\n# Post Date\nprint(heads[10])\nprint(type(heads[10]))\n\n# An example name looks like\nprint(dataSet[heads[10]][40])\n\n# We can split this field using \" \" and keep the first element as it is the one containing date\n# The values seem timestamped and hence in a uniform format\ndates=[]\nfor i in range(len(dataSet)):\n    dates.append(str(dataSet[heads[10]][i]).split(\" \")[0])\n    \n# An example of dates, some examples may have 'nan' as well which was found during analysis\nprint(dates[0])\n\n# nan value existing in dates\nprint(max(dates))","cell_type":"code"},{"metadata":{"_cell_guid":"ba5ab74f-1ee4-4ec2-b0a9-b12c5504de1f","_uuid":"e8ba5708348919b01232911317f054f5e82dbced"},"source":"#### Field 12 - Site Name","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"b9a68de6-d35e-4c85-aca6-b52af9e0d165","_uuid":"ba96696829605654011dbf2542a8f3bbc7d48f71"},"source":"# Field-12\n# Site Name\nprint(heads[11])\nprint(type(heads[11]))\n\n# A lot of values in this field were nan(Not a Number)\n# An example name looks like\nprint(dataSet[heads[11]][90])","cell_type":"code"},{"metadata":{"_cell_guid":"e5e8497f-de10-4016-9ada-42bc5fcd7392","_uuid":"38aa4661e1ea0416290ac6c53e5634fc7b61b294"},"source":"#### Field 13 - Skills","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"059cda99-9d64-49fe-8893-e06d74676b52","_uuid":"11932c24e074b2f086b7c21b92f8c7fc9c120723"},"source":"# Field-13\n# Skills\nprint(heads[12])\nprint(type(heads[12]))\n\n# An example name looks like\nprint(dataSet[heads[12]][100])","cell_type":"code"},{"metadata":{"_cell_guid":"4befcf20-f446-4860-a4dd-f6f71e1ca738","_uuid":"2aefdab975a9e9b20a44488afccef4270408eb37"},"source":"#### Field 14 - Unique Id","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e1b0c517-bff7-42c9-81a3-c4cfc94a464e","_uuid":"7d1334c677ca08cd3e723819cf20ec963db09c18"},"source":"# Field-14\n# Unique Id\nprint(heads[13])\nprint(type(heads[13]))\n\n# An example name looks like\nprint(dataSet[heads[13]][0])\n# This can be used in a similar manner to the 'jobid' field","cell_type":"code"},{"metadata":{"_cell_guid":"ab555263-54f0-462b-ad71-bceeff9ea9c8","_uuid":"060935d9c637f08ae572cba48d4a388a4ea8936d"},"source":"# This analysis can be used accordinly in the required projects as deep insight is given in for each field with initial cleaning where required","cell_type":"markdown"}],"nbformat":4,"nbformat_minor":1,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.3","mimetype":"text/x-python"}}}