{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Advance Regression Case Study on Housing Data Using Lasso and Ridge\n\nA US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. The data is provided in the CSV file below.\n\n \n\nThe company is looking at prospective properties to buy to enter the market. You are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n\n \n\nThe company wants to know:\n\n- Which variables are significant in predicting the price of a house, and\n\n- How well those variables describe the price of a house."},{"metadata":{},"cell_type":"markdown","source":"### Data Understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model, metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\n\nimport os\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the dataset\n\nhousing= pd.read_csv('../input/house-prices-data/train.csv')\n\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary of the dataset:\n\nprint(housing.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Outlier Treatment\nWe will check for the outliers, if any then we will discard it."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.describe(percentiles=[.25, .5, .75, .90, .95, .99])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will manually pick a number of variables which appears to have high outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#SalePrice\n\nplt.boxplot(housing['SalePrice'])\nQ1 = housing['SalePrice'].quantile(0.1)\nQ3 = housing['SalePrice'].quantile(0.9)\nIQR = Q3 - Q1\nhousing = housing[(housing['SalePrice'] >= Q1 - 1.5*IQR) & \n                      (housing['SalePrice'] <= Q3 + 1.5*IQR)]\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lot Area\nplt.boxplot(housing['LotArea'])\nQ1 = housing['LotArea'].quantile(0.1)\nQ3 = housing['LotArea'].quantile(0.9)\nIQR = Q3 - Q1\nhousing = housing[(housing['LotArea'] >= Q1 - 1.5*IQR) & \n                      (housing['LotArea'] <= Q3 + 1.5*IQR)]\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MiscVal\n\nplt.boxplot(housing['MiscVal'])\nQ1 = housing['MiscVal'].quantile(0.1)\nQ3 = housing['MiscVal'].quantile(0.9)\nIQR = Q3 - Q1\nhousing = housing[(housing['MiscVal'] >= Q1 - 1.5*IQR) & \n                      (housing['MiscVal'] <= Q3 + 1.5*IQR)]\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LotFrontage\nplt.boxplot(housing['LotFrontage'])\nQ1 = housing['LotFrontage'].quantile(0.1)\nQ3 = housing['LotFrontage'].quantile(0.9)\nIQR = Q3 - Q1\nhousing = housing[(housing['LotFrontage'] >= Q1 - 1.5*IQR) & \n                      (housing['LotFrontage'] <= Q3 + 1.5*IQR)]\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MasVnrArea\nplt.boxplot(housing['MasVnrArea'])\nQ1 = housing['MasVnrArea'].quantile(0.1)\nQ3 = housing['MasVnrArea'].quantile(0.9)\nIQR = Q3 - Q1\nhousing = housing[(housing['MasVnrArea'] >= Q1 - 1.5*IQR) & \n                      (housing['MasVnrArea'] <= Q3 + 1.5*IQR)]\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No we will look into the corelation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation matrix\ncor = housing.corr()\ncor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"#### Firstly let check percentage of missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the percentage of missing values\nmissing = round(100*(housing.isnull().sum()/len(housing.Id)), 2)\nmissing.loc[missing > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lets remove all the columns with more than 70% missing values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_with_missing_values = list(missing[missing >= 70].index)\n\nlen(columns_with_missing_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### There were **4 columns** with more than 70% values as missing. Removing such columns as these columns clearly add noise and wont help in analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = housing.drop(columns_with_missing_values,axis=1)\nhousing.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Treating Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#NA in FireplaceQu column means No Fireplace, so we will replace NA by it.\nhousing['FireplaceQu'].fillna('No Fireplace', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['MasVnrArea'].fillna(0, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['LotFrontage'].fillna(0, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NA in GarageType, GarageFinish, GarageQual, GarageCond columns mean No Garage, so we will replace NA by it.\n\nhousing['GarageType'].fillna('No Garage', inplace=True) \nhousing['GarageFinish'].fillna('No Garage', inplace=True) \nhousing['GarageQual'].fillna('No Garage', inplace=True) \nhousing['GarageCond'].fillna('No Garage', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting year to number of years\nhousing['YearBuilt'] = 2020 - housing['YearBuilt']\nhousing['YearRemodAdd'] = 2020 - housing['YearRemodAdd']\nhousing['GarageYrBlt'] = 2020 - housing['GarageYrBlt']\nhousing['YrSold'] = 2020 - housing['YrSold']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting from int type to object to treat the variables as categorical variables\n\nhousing['MSSubClass'] = housing['MSSubClass'].astype('object')\nhousing['OverallQual'] = housing['OverallQual'].astype('object')\nhousing['OverallCond'] = housing['OverallCond'].astype('object')\nhousing['BsmtFullBath'] = housing['BsmtFullBath'].astype('object')\nhousing['BsmtHalfBath'] = housing['BsmtHalfBath'].astype('object')\nhousing['FullBath'] = housing['FullBath'].astype('object')\nhousing['HalfBath'] = housing['HalfBath'].astype('object')\nhousing['BedroomAbvGr'] = housing['BedroomAbvGr'].astype('object')\nhousing['KitchenAbvGr'] = housing['KitchenAbvGr'].astype('object')\nhousing['TotRmsAbvGrd'] = housing['TotRmsAbvGrd'].astype('object')\nhousing['Fireplaces'] = housing['Fireplaces'].astype('object')\nhousing['GarageCars'] = housing['GarageCars'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we will check for any NAN values if any, if the count is less, we will remove them directly."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mapping of variables"},{"metadata":{},"cell_type":"markdown","source":"#### We will map the necessary categorical variables "},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of variables to map\n\nvarlist1 =  ['Street']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Pave': 1, \"Grvl\": 0})\n\n# Applying the function to the Lead list\nhousing[varlist1] = housing[varlist1].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CentralAir\n\nvarlist2 =  ['CentralAir']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Y': 1, \"N\": 0})\n\n# Applying the function to the Lead list\nhousing[varlist2] = housing[varlist2].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Utilities\n\nvarlist3 =  ['Utilities']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'AllPub': 1, \"NoSeWa\": 0})\n\n# Applying the function to the Lead list\nhousing[varlist3] = housing[varlist3].apply(binary_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing['Utilities']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will dropping Id column as it is of no use in our analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns= ['Id']\nhousing= housing.drop(drop_columns,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.isnan(housing.any())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dummy variables for categorical variables\n\n# subset all categorical variables\nhouse_categorical = housing.select_dtypes(include=['object'])\nhouse_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert into dummies\nhouse_dummies = pd.get_dummies(house_categorical, drop_first=True)\nhouse_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop categorical variables \nhousing = housing.drop(list(house_categorical.columns), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concat dummy variables with X\nhousing = pd.concat([housing, house_dummies], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the Data into Training and Testing Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(housing, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Rescaling the Features \n\nWe will use MinMax scaling."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\nnum_vars = ['LotFrontage','YearBuilt','YearRemodAdd','LotArea', 'TotalBsmtSF', 'GrLivArea',\n           'MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GarageYrBlt',\n            'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MoSold','YrSold','SalePrice'\n           ]\n\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dividing into X and Y sets for the model building"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train.pop('SalePrice')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test Split-\ny_test = df_test.pop('SalePrice')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying RFE in order to reduce the count to 30 most important predictor variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 50\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 30)             # running RFE\nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RFE Support columns\ncol = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Not RFE support columns\n\nX_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying Ridge and Lasso"},{"metadata":{},"cell_type":"markdown","source":"### Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of alphas to tune\nparams = {'alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5,1.0, 5.0, 10.0, 100]}\n\n\nridge = Ridge()\n\n# cross validation\nfolds = 5\nmodel_cv = GridSearchCV(estimator = ridge, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \nmodel_cv.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the value of optimum number of parameters\nprint(model_cv.best_params_)\nprint(model_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We got alpha value as 5.0 for Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results = cv_results[cv_results['param_alpha']<=200]\ncv_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('int32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.ylabel('Negative Mean Absolute Error')\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = 5.0\nridge = Ridge(alpha=alpha)\n\nridge.fit(X_train, y_train)\nridge.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets predict the R-squared value of test and train data\ny_train_pred = ridge.predict(X_train)\nprint('RSquare- '+str(metrics.r2_score(y_true=y_train, y_pred=y_train_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LASSO"},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso = Lasso()\n\n# cross validation\nmodel_cv = GridSearchCV(estimator = lasso, \n                        param_grid = params, \n                        scoring= 'neg_mean_absolute_error', \n                        cv = folds, \n                        return_train_score=True,\n                        verbose = 1)            \n\nmodel_cv.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting mean test and train scoes with alpha \ncv_results['param_alpha'] = cv_results['param_alpha'].astype('float32')\n\n# plotting\nplt.plot(cv_results['param_alpha'], cv_results['mean_train_score'])\nplt.plot(cv_results['param_alpha'], cv_results['mean_test_score'])\nplt.xlabel('alpha')\nplt.xscale('log')\nplt.ylabel('Negative Mean Absolute Error')\n\nplt.title(\"Negative Mean Absolute Error and alpha\")\nplt.legend(['train score', 'test score'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the value of optimum number of parameters\nprint(model_cv.best_params_)\nprint(model_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = 0.001\n\nlasso = Lasso(alpha=alpha)\n        \nlasso.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets predict the R-squared value of test and train data\ny_train_pred = lasso.predict(X_train)\nprint('RSquare- ' +str(metrics.r2_score(y_true=y_train, y_pred=y_train_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = 0.001\n\nlasso = Lasso(alpha=alpha)\n        \nlasso.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results= pd.DataFrame.from_dict(model_cv.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results= results.sort_values(['param_alpha'])\nalphas= np.array(params['alpha'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[['param_alpha','mean_train_score','mean_test_score']]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}