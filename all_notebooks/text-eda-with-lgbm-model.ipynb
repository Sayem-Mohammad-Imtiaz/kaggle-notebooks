{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nimport re\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport string\nfrom sklearn.utils import resample\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"trainData = pd.read_csv(\"/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calMissingData(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\n\ndef fillNa(df):\n    for col in df.columns:\n        df[col] = df[col].fillna(\"\")\n    return df  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(calMissingData(trainData).head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData['Category'] = trainData['Category'].map(dict(spam=1, ham=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData[trainData['Category']==1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(trainData['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"down_sampled_0 = resample(trainData[trainData.Category==0],replace=True,n_samples=1000,random_state=27)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData_sampled =  pd.concat([down_sampled_0,trainData[trainData.Category!=0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(trainData_sampled['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = nltk.corpus.stopwords.words('english')\nps = nltk.PorterStemmer()\nSIA = SentimentIntensityAnalyzer()\n\ndef count_words(text):\n    return len(str(text).split())\n\ndef body_len(text):\n    return len(str(text))\n\ndef avg_word_len(text):\n    if(len(str(text)) - text.count(\" \")>0):\n        return len(str(text))/len(str(text).split())\n    return 0\n\ndef count_stop_words(text):\n    return len([w for w in str(text).lower().split() if w in stopwords])\n\ndef count_punct(text):\n    count = sum([1 for char in text if char in string.punctuation])\n    if len(text)>0:\n        return round(count/(len(text) - text.count(\" \")), 3)*100\n    else:\n        return 0\n    \ndef clean_text(text):\n    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n    tokens = re.split('\\W+', text)\n    text = [ps.stem(word) for word in tokens if word not in stopwords]\n    return text\n\ndef count_title_words(text):\n    return len([w for w in str(text).replace(\"I\",'i').replace(\"A\",\"a\").split() if w.istitle() == True])\n\ndef sentimentScore(text):\n    return SIA.polarity_scores(str(text))['compound']\n\ndef count_nouns(text):\n    nouns = ['NN','NNS','NNP','NNPS']\n    c = Counter(tup[1] for tup in nltk.pos_tag(i for i in clean_text(text) if i))\n    return sum(v for k, v in c.items() if k in nouns)\n\ndef count_pronouns(text):\n    pronouns = ['PRP','PRP$','WP','WP$']\n    c = Counter(tup[1] for tup in nltk.pos_tag(i for i in clean_text(text) if i))\n    return sum(v for k, v in c.items() if k in pronouns)\n    \ndef count_verbs(text):\n    verbs = ['VB','VBD','VBG','VBN','VBP','VBZ']\n    c = Counter(tup[1] for tup in nltk.pos_tag(i for i in clean_text(text) if i))\n    return sum(v for k, v in c.items() if k in verbs)\n\ndef count_adverbs(text):\n    adverbs = ['RB','RBR','RBS','WRB']\n    c = Counter(tup[1] for tup in nltk.pos_tag(i for i in clean_text(text) if i))\n    return sum(v for k, v in c.items() if k in adverbs)\n\ndef count_adj(text):\n    adjectives = ['JJ','JJR','JJS']\n    c = Counter(tup[1] for tup in nltk.pos_tag(i for i in clean_text(text) if i))\n    return sum(v for k, v in c.items() if k in adjectives)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData_sampled['count_words'] = trainData_sampled['Message'].apply(lambda x: count_words(x))\ntrainData_sampled['body_len'] = trainData_sampled['Message'].apply(lambda x: body_len(x))\ntrainData_sampled['avg_word_len'] = trainData_sampled['Message'].apply(lambda x: avg_word_len(x))\ntrainData_sampled['count_stop_words'] = trainData_sampled['Message'].apply(lambda x: count_stop_words(x))\ntrainData_sampled['punct%'] = trainData_sampled['Message'].apply(lambda x: count_punct(x))\ntrainData_sampled['count_title_words'] = trainData_sampled['Message'].apply(lambda x: count_title_words(x))\ntrainData_sampled['text_sentiment'] = trainData_sampled['Message'].apply(lambda x:sentimentScore(x))\ntrainData_sampled['count_nouns'] = trainData_sampled['Message'].apply(lambda x: count_nouns(x))\ntrainData_sampled['count_pronouns'] = trainData_sampled['Message'].apply(lambda x: count_pronouns(x))\ntrainData_sampled['count_verbs'] = trainData_sampled['Message'].apply(lambda x: count_verbs(x))\ntrainData_sampled['count_adverbs'] = trainData_sampled['Message'].apply(lambda x: count_adverbs(x))\ntrainData_sampled['count_adj'] = trainData_sampled['Message'].apply(lambda x: count_adj(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bar_chart_from_dataframe(dataframe1,key_column,columns_to_be_plotted):\n    import pandas as pd\n    test_df1 = dataframe1.groupby(key_column).sum()\n    test_df2 = pd.DataFrame()\n    for column in columns_to_be_plotted:\n        test_df2[column] = round(test_df1[column]/ test_df1[column].sum()*100,2)\n    test_df2 = test_df2.T \n    ax = test_df2.plot(kind='bar', stacked=True, figsize =(10,5),legend = 'reverse',title = '% usage for each target')\n    for p in ax.patches:\n        a = p.get_x()+0.4\n        ax.annotate(str(p.get_height()), (a, p.get_y()), xytext=(5, 10), textcoords='offset points')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_chart_from_dataframe(trainData_sampled,'Category',['count_words','body_len','avg_word_len','count_stop_words','punct%','count_title_words','text_sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(trainData_sampled.drop(['Category'],axis=1), trainData_sampled['Category'], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''skiping ngram first case'''\ntfidf_vect = TfidfVectorizer(analyzer=clean_text)\ntfidf_vect_fit = tfidf_vect.fit(X_train['Message'])\n\ntfidf_train = tfidf_vect_fit.transform(X_train['Message'])\ntfidf_test = tfidf_vect_fit.transform(X_test['Message'])\n\nX_train_vect = pd.concat([X_train.drop(['Message'],axis=1).reset_index(drop=True), \n           pd.DataFrame(tfidf_train.toarray())], axis=1)\nX_test_vect = pd.concat([X_test.drop(['Message'],axis=1).reset_index(drop=True), \n           pd.DataFrame(tfidf_test.toarray())], axis=1)\n\nX_train_vect.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train_vect)\nX_train_vect = scaler.transform(X_train_vect)\nX_test_vect = scaler.transform(X_test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import precision_recall_fscore_support as score\nimport time\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train_vect, y_train)\nlgb_eval = lgb.Dataset(X_test_vect, y_test, reference=lgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# specify your configurations as a dict\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'multiclass',\n    'num_class':3,\n    'metric': 'multi_logloss',\n    'num_leaves': 10,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 5,\n    'verbose': 0,\n    'lambda_l2': 0.5\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=300,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=10)\nend = time.time()\nfit_time = (end - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred = gbm.predict(X_test_vect, num_iteration=gbm.best_iteration)\n\npredictions = []\nfor x in y_pred:\n    predictions.append(np.argmax(x))\n\naccuracy_score(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}