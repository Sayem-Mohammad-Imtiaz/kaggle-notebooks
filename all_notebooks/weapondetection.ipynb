{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport os\nimport numpy as np \nimport cv2\nfrom keras.preprocessing import image \nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom skimage.segmentation import mark_boundaries ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reducing the image value under 1\ndef get_image_value(path, dim): \n    '''Load image and convert into arrey '''\n    img = image.load_img(path, target_size = dim)\n    img = image.img_to_array(img)\n    return img/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_paths, dim): \n    '''Get list of image path and convert into numpy array'''\n    final_array = []\n    from tqdm import tqdm\n    for path in tqdm(img_paths):\n        img = get_image_value(path, dim)\n        final_array.append(img)\n    final_array = np.array(final_array)  \n    return final_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tts():\n    '''This function will create a train test split'''  \n   \n    DIM =  (150,150)\n    np.random.seed(10)        \n    pistol_paths = [f'../input/guns-ar/Separated/Separated/FinalImages/Pistol/{i}' for i in os.listdir('../input/guns-ar/Separated/Separated/FinalImages/Pistol')] \n    pistol_labels = [1 for i in range(len(pistol_paths))]\n    rifle_paths = [f'../input/guns-ar/Separated/Separated/FinalImages/Rifle/{i}' for i in os.listdir('../input/guns-ar/Separated/Separated/FinalImages/Rifle')] \n    rifle_labels = [2 for i in range(len(rifle_paths))]    \n    neg_paths = [f'../input/guns-ar/Separated/Separated/FinalImages/NoWeapon/{i}' for i in os.listdir('../input/guns-ar/Separated/Separated/FinalImages/NoWeapon')]\n    np.random.shuffle(neg_paths)\n    neg_paths = neg_paths[:len(pistol_paths)- 500]\n    neg_labels = [0 for i in range(len(neg_paths))]\n\n    np.random.shuffle(pistol_paths)\n    pistol_paths = pistol_paths[:len(rifle_paths)+150]\n    neg_paths = neg_paths[:len(rifle_paths)+150]\n\n    pistol_labels = [1 for i in range(len(pistol_paths))]\n    rifle_labels = [2 for i in range(len(rifle_paths))]\n    neg_labels = [0 for i in range(len(neg_paths))]\n    paths = pistol_paths + rifle_paths + neg_paths\n    labels = pistol_labels + rifle_labels + neg_labels\n    x_train, x_test, y_train, y_test = train_test_split(paths, labels, stratify = labels, train_size = .90, random_state = 10)\n\n    new_x_train = get_img_array(x_train, DIM)\n    new_x_test = get_img_array(x_test, DIM)\n    \n    print('Train Value Counts')\n    print(pd.Series(y_train).value_counts())\n    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n    print('Test Value Counts')\n    print(pd.Series(y_test).value_counts())\n    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n    print('X Train Shape')\n    print(new_x_train.shape)\n    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n    print('X Test Shape')\n    print(new_x_test.shape)\n    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n\n    y_train = np.array(y_train)\n    y_test = np.array(y_test)\n    y_test = to_categorical(y_test)\n    y_train = to_categorical(y_train)\n    tts = (new_x_train, new_x_test, y_train, y_test)\n    return tts\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the images to varibles\nx_train, x_test, y_train, y_test = get_tts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Flatten \nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport pickle\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport cv2\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_conv_model(dim = (150,150, 3)):\n    '''This function will create and compile a CNN given the input dimension'''\n    inp_shape = dim\n    act = 'relu'\n    drop = .25\n    kernal_reg = regularizers.l1(.001)\n    optimizer = Adam(lr = .0001)    \n    model = Sequential() \n    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n                     kernel_regularizer = kernal_reg,\n                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n                     kernel_initializer = 'he_uniform',padding = 'same'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n                     kernel_initializer = 'he_uniform',padding = 'same'))\n    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n                     kernel_initializer = 'he_uniform',padding = 'same'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))  \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(drop))\n    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n    model.compile(loss = 'categorical_crossentropy', \n                  optimizer = optimizer, \n                  # comment experimental_steps_per_execution if not using Tpu\n                  experimental_steps_per_execution = 50, \n                  metrics = ['accuracy'])\n    return model ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TPU Initialization\n\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(resolver)\n# This is the TPU initialization code that has to be at the beginning.\ntf.tpu.experimental.initialize_tpu_system(resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\nstrategy = tf.distribute.TPUStrategy(resolver)\n@tf.function\ndef matmul_fn(x, y):\n  z = tf.matmul(x, y)\n  return z\n\na = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\nb = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\nz = strategy.run(matmul_fn, args=(a, b))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#prevents overfitting and saves models every time the validation loss improves\nearly_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\nmodel_checkpoint = ModelCheckpoint('ModelWeights.h5', verbose = 1, save_best_only=True,\n                                  monitor = 'val_loss')\nlr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\nepochs = 1000\nbatch_size = 32\nmodel = get_conv_model()\nmodel_history = model.fit(x_train, y_train, batch_size = batch_size, \n                          epochs = epochs, \n                          callbacks = [early_stopping, model_checkpoint, lr_plat], \n                          validation_data = (x_test, y_test), \n                          verbose= 1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}