{"cells":[{"metadata":{"_uuid":"e3195135a8a04dc00763d7111df7a159ccec6e2e"},"cell_type":"markdown","source":"#                                         Incidents Text Analytics   "},{"metadata":{"trusted":true,"_uuid":"031efca7c6327e4f647fd78ddedf11ea2e15beca"},"cell_type":"code","source":"### Download required packages\n\n# import nltk\n# nltk.download('gutenberg')\n# nltk.download('genesis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d04bb99b0add58a651facad81011921048b42a13"},"cell_type":"code","source":"##### Imporing Libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n## Importing Textblob package\nfrom textblob import TextBlob\n\n# Importing CountVectorizer for sparse matrix/ngrams frequencies\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n## Import datetime\nimport datetime as dt\n\n\nimport nltk.compat\nimport itertools\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30cb14878afdc5b27f2a3becf7804b479160ef44"},"cell_type":"markdown","source":"### 1. Basic Feature Extraction\n"},{"metadata":{"trusted":true,"_uuid":"07efbee761e56186abe301bcc8fc5dfcb2a5cc09"},"cell_type":"code","source":"#### Checking on encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bed0351592963f9b93533508a9d15fdd19359916"},"cell_type":"code","source":"import chardet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7af15512c96810ffdcc534ba7eca3307007c7d26"},"cell_type":"code","source":"##### Read the data file\nfilepath = \"../input/ebi-finance-and-qlikview-incidents-data/Incident_2017_18_Final.csv\"\n\n\n## Checking the encoding factor\nwith open(filepath,\"rb\") as mydata:\n    result = chardet.detect(mydata.read(1000000))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb029a0b17cfa306acf21a4176beded4e8c94f7b"},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dfc7a5716ab86ce1f3d012eb7184fba991e9538"},"cell_type":"code","source":"##### Read the data file\nfilepath = \"../input/ebi-finance-and-qlikview-incidents-data/Incident_2017_18_Final.csv\"\ntrain_incidents = pd.read_csv(filepath,encoding=\"Windows-1252\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6af7c163d3c0ebbe5417c3deea87986320af714f"},"cell_type":"markdown","source":"##### 1.1 Number of words"},{"metadata":{"_uuid":"585803583b15829aad35785f682332c6cecc1e00"},"cell_type":"markdown","source":"Note: The basic intuition behind this is that generally, the negative sentiments contain a lesser amount of words than the positive ones."},{"metadata":{"trusted":true,"_uuid":"c0aa26552c02ab2552f4e2dc697f57954083880c"},"cell_type":"code","source":"train_incidents[\"short_description_nwords\"] = train_incidents[\"short_description\"].apply(lambda x: len(str(x).split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02809a565a1564f170da67a1967bd5faec911620"},"cell_type":"markdown","source":"Top 5 texts with more number of words"},{"metadata":{"trusted":true,"_uuid":"3c5932ee089e44d579f9c5e9b9e4f10042ac2673"},"cell_type":"code","source":"\ntrain_incidents[[\"short_description\",\"short_description_nwords\"]].sort_values(by = \"short_description_nwords\",ascending = True).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd3d2459affe8af7b7060d873ad6398d91c8eaec"},"cell_type":"markdown","source":"Top 5 texts with least number of words"},{"metadata":{"trusted":true,"_uuid":"2ad3162c07a20fb0c8061e74aefb4c37410626b9"},"cell_type":"code","source":"\n\ntrain_incidents[[\"short_description\",\"short_description_nwords\"]].sort_values(by = \"short_description_nwords\",ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34fa1a5c19e5a6f8fb6dd17f8816202ff2d05fbe"},"cell_type":"markdown","source":"##### 1.2 Number of characters"},{"metadata":{"trusted":true,"_uuid":"d05e7bfbdeeb0307626e6d2520bdf9e8ea56b768"},"cell_type":"code","source":"train_incidents[\"short_description_nchars\"] = train_incidents[\"short_description\"].str.len()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"135bc303fbee553961c0683b1a62b1dbf707935f"},"cell_type":"markdown","source":"Top 5 texts with more number of charecters"},{"metadata":{"trusted":true,"_uuid":"812f1687dc65dcf80a6645b3d124c2571e63b9b6"},"cell_type":"code","source":"\ntrain_incidents[[\"short_description\",\"short_description_nchars\"]].sort_values(by = \"short_description_nchars\",ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5aef587882292294d0e641da8b46cd06b42b7e2"},"cell_type":"markdown","source":"5 texts with least number of charecters"},{"metadata":{"trusted":true,"_uuid":"4ef731ae0053e618be800e5cf8247f121641e666"},"cell_type":"code","source":"\ntrain_incidents[[\"short_description\",\"short_description_nchars\"]].sort_values(by = \"short_description_nchars\",ascending = True).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"844ea09fe11c9521a3b1de0865838518ce1559ac"},"cell_type":"markdown","source":"##### 1.3 Average word length"},{"metadata":{"trusted":true,"_uuid":"030f50bd35ff125f4e73208ab77d10c81ee7375e"},"cell_type":"code","source":"#sum of words/total words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e7200f4444e9599d7931c27911bb9e6c537aa58"},"cell_type":"code","source":"def ave_word_len(sentence):\n    words  = sentence.split(\" \")\n    return ((sum((len(word) for word in words))/len(words)))\n\ntrain_incidents[\"short_description_avg_word_len\"] = train_incidents[\"short_description\"].apply(ave_word_len)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"daf7c6da00320678caa2cf29fc1aca91494b8c67"},"cell_type":"markdown","source":"least avg number of word len"},{"metadata":{"trusted":true,"_uuid":"d81e7130e998e6ac2a6d640104ff40fb3d006b09"},"cell_type":"code","source":"train_incidents[[\"short_description\",\"short_description_avg_word_len\"]].sort_values(by = \"short_description_avg_word_len\",ascending = True).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07ea85895d9de271d22687b635d339cb99aacdf3"},"cell_type":"markdown","source":"###### 1.4 Number of stop words"},{"metadata":{"trusted":true,"_uuid":"9eca50439fa7bbccfd291c5419edeb7b969d3d18"},"cell_type":"code","source":"## Importing stop words from nltk.corpus\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"649958f8a70cb2b71357fef424db2492bc1c7dfb"},"cell_type":"code","source":"stop = stopwords.words(\"english\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bc570850f0f51760f655f40bfd9cef3da2c66cf"},"cell_type":"code","source":"train_incidents[\"short_description_nstopwords\"] = train_incidents[\"short_description\"].apply(lambda word: len([x for x in word.split(\" \") if x in stop]))\ntrain_incidents[[\"short_description\",\"short_description_nstopwords\"]].sort_values(by = \"short_description_nstopwords\",ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d09fde2c9a54fbe31c14033cdaeab8ca5289d122"},"cell_type":"markdown","source":"##### 1.5 Number of numerics"},{"metadata":{"trusted":true,"_uuid":"c48a2b3ca138d1029564d86622e7219479622c1c"},"cell_type":"code","source":"train_incidents[\"short_description_ndigits\"] = train_incidents[\"short_description\"].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n\ntrain_incidents[[\"short_description\",\"short_description_ndigits\"]].sort_values(by = \"short_description_ndigits\",ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed3dbb6cd72d0ad84d23ebe7371b4530804669dd"},"cell_type":"markdown","source":"##### 1.6 Number of upper case words"},{"metadata":{"trusted":true,"_uuid":"c164acc8e6ccdffd0bce51c1661e9f877317a393"},"cell_type":"code","source":"train_incidents[\"short_description_nupper\"] = train_incidents[\"short_description\"].apply((lambda word: len([x for x in word.split() if x.isupper()])))\ntrain_incidents[[\"short_description\",\"short_description_nupper\"]].sort_values(by = \"short_description_nupper\",ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09e0cb3d4347a26f183cce969955a5d8623eba43"},"cell_type":"markdown","source":"### 2. Basic Pre-processing\n"},{"metadata":{"_uuid":"5dcfb9a703fe03eda132051c056e3a2e7c887543"},"cell_type":"markdown","source":"###### 2.1 Lower case"},{"metadata":{"_uuid":"2bc8643129e91959848dbd4746f93e1fd6d2f35d"},"cell_type":"markdown","source":"The first pre-processing step which we will do is transform our tweets into lower case. This avoids having multiple copies of the same words. For example, while calculating the word count, ‘Analytics’ and ‘analytics’ will be taken as different words."},{"metadata":{"trusted":true,"_uuid":"b70524118dd099381302b0d31a03def73d0bef29"},"cell_type":"code","source":"train_incidents[\"short_description\"] = train_incidents[\"short_description\"].apply(lambda x: x.lower())\ntrain_incidents[\"short_description\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a51985a2acaeaff18ee4b1f4c8b9a109b124fc6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a87332bf2e52485c076a3360a4fc19d35d394ae"},"cell_type":"markdown","source":"###### Converging similar words eg: Qlik to Qlikview"},{"metadata":{"trusted":true,"_uuid":"c78284475e441092ac7fa5e967d6eb71a93f4981"},"cell_type":"code","source":"train_incidents[\"short_description\"] = train_incidents[\"short_description\"].str.replace(\"qlik view\",\"qlikview\")\ntrain_incidents[\"short_description\"] = train_incidents[\"short_description\"].str.replace(\"qv\",\"qlikview\")\ntrain_incidents[\"short_description\"] = train_incidents[\"short_description\"].str.replace(\"wrongly\",\"wrong\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fe3a429f48969bc6290021b1e43d5d8d348d87d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bfe290bb7d807c2439a0f92c354d17d77e680ac"},"cell_type":"markdown","source":"###### 2.2 Removing Punctuation"},{"metadata":{"_uuid":"1367887d3cae3bd8a5648d9837a5f5b920070993"},"cell_type":"markdown","source":"The next step is to remove punctuation, as it doesn’t add any extra information while treating text data. Therefore removing all instances of it will help us reduce the size of the training data."},{"metadata":{"trusted":true,"_uuid":"c39888c06ba4f59b86e4fbc1d680393d7f178be4"},"cell_type":"code","source":"train_incidents[\"short_description\"] = train_incidents[\"short_description\"].str.replace(\"[^\\w\\s]\",\"\")\ntrain_incidents[\"short_description\"].tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5182eaab688039a69bcbdb1aa3b69154f948a3b2"},"cell_type":"markdown","source":"###### 2.3 Removal of Stop Words"},{"metadata":{"trusted":true,"_uuid":"1eb35006b409d773960c423ff4bca2ff9db06407"},"cell_type":"code","source":"train_incidents[\"short_description\"] = train_incidents[\"short_description\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24a38fb446b578500cb4a76b560596c849375fba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8797827b9b57cf88aa4f396a82da3b4b9e92f51a"},"cell_type":"markdown","source":"###### 2.4  Lemmatization\n\n\nLemmatization is a more effective option than stemming because it converts the word into its root word, rather than just stripping the suffices. It makes use of the vocabulary and does a morphological analysis to obtain the root word. Therefore, we usually prefer using lemmatization over stemming."},{"metadata":{"trusted":true,"_uuid":"fd5683e661f0290ce8df827130e670c86a171d82"},"cell_type":"code","source":"from textblob import Word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d829fbe6a95fbaf2838df35767bdc9147a112ed"},"cell_type":"code","source":"train_incidents[\"short_description\"] = train_incidents[\"short_description\"].apply(lambda x: \" \".join([Word(myword).lemmatize() for myword in x.split()])  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0d62674d474020783418920c70fb7b032cfed69"},"cell_type":"code","source":"train_incidents[\"short_description\"].head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36fb6da5d533d3b557c1b7cb0069027c444f093a"},"cell_type":"raw","source":""},{"metadata":{"_uuid":"247f8d3705ae4f4a1a543704b640a6c884bfdf7c"},"cell_type":"markdown","source":"###### 2.5 Common word  -- Currently we are not removing as the frequent words are useful to perform further analysis"},{"metadata":{"_uuid":"97713cc6bfa748444aac0af3b67ab4a598e24d3e"},"cell_type":"markdown","source":"Previously, we just removed commonly occurring words in a general sense. We can also remove commonly occurring words from our text data First, let’s check the 10 most frequently occurring words in our text data then take call to remove or retain."},{"metadata":{"trusted":true,"_uuid":"f5fabe0a1ae07758fd60462754e2ebfcdc1c882e"},"cell_type":"code","source":"### Most frequent words in short description\nShort_description_most_freq_words = pd.Series(\" \".join(train_incidents[\"short_description\"]).split()).value_counts()\nShort_description_most_freq_words.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f173a2285eb65eecc9e6feea9790a1fddc0f34c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49023b45c1fb5ecbf198eded1e79da49d8b141b5"},"cell_type":"code","source":"### Least frequent words in short description\nshort_description_least_freq_words =  pd.Series(\" \".join(train_incidents[\"short_description\"]).split()).value_counts().sort_values(ascending = True)\nshort_description_least_freq_words.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7edde8f67bc3bf547b4055f078ed09248bbc27f"},"cell_type":"markdown","source":"###### 2.6 Spelling Correction\n"},{"metadata":{"_uuid":"6accd3ea2f946ad4440da0be13a0d1fba314f0ae"},"cell_type":"markdown","source":"##### [TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.]"},{"metadata":{"_uuid":"34a98f1c83029ac89dceca78eb735269dcf5635c"},"cell_type":"markdown","source":"spelling correction is a useful pre-processing step because this also will help us in reducing multiple copies of words.\nFor example, “Analytics” and “analytcs” will be treated as different words even if they are used in the same sense."},{"metadata":{"trusted":true,"_uuid":"b9d06b51add25ad7cef0798f36afab54b22d08e5"},"cell_type":"code","source":"## Correction for top 10 sentences\n##  train_incidents[\"short_description\"] = train_incidents[\"short_description\"].apply(lambda x: str(TextBlob(x).correct()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2ced85310f66645b0e0ab9ab53669f77af88821"},"cell_type":"markdown","source":"\n###### 2.6 Tokenization"},{"metadata":{"_uuid":"28acfb66a2c5881846f533de626298eb73e3a4ed"},"cell_type":"markdown","source":"\n\n##### Method 1"},{"metadata":{"_uuid":"dacc3a4f636e4ccd6564ef90a741a4dd3fa02567"},"cell_type":"markdown","source":"Tokenization refers to dividing the text into a sequence of words or sentences. In our example, we have used the textblob library to first transform INCIDENT texts into a blob and then converted them into a series of words."},{"metadata":{"trusted":true,"_uuid":"1ad9dd359d59627e324d3747cc88dde30d848218"},"cell_type":"code","source":"TextBlob(train_incidents[\"short_description\"][1]).words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2de07b542b5337c12dc6eb178a6af0c016ae0a2"},"cell_type":"code","source":"train_incidents[\"short_description\"][1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78977ee166ac8c6e2303990baa0fccd7709e71c9"},"cell_type":"markdown","source":"Applying Tokenization to short description text:"},{"metadata":{"trusted":true,"_uuid":"441e4bc3d7cf83af193c8987154b8ffd61b364d9"},"cell_type":"code","source":"train_incidents[\"short_description_tokens\"] =  train_incidents[\"short_description\"].apply(lambda x: TextBlob(x).words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0100549bf36b568521206821d19f8e1e98253c36"},"cell_type":"code","source":"train_incidents[\"short_description_tokens\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46e38d1606e01eda945974b94f41495271b218fc"},"cell_type":"markdown","source":"###### Method 2"},{"metadata":{"trusted":true,"_uuid":"ed8198ce9fab2a59a02af4cdb396d40314b2a03b"},"cell_type":"code","source":"from nltk import word_tokenize,sent_tokenize","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"de336c98dd9d32c8d4de12e223dcb4b25a46b49c"},"cell_type":"code","source":"train_incidents[\"short_description\"].apply(lambda x: word_tokenize(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77d16be54a596af5a3493a78edcfa489153e6552"},"cell_type":"markdown","source":"###### 2.7 Stemming"},{"metadata":{"_uuid":"d8b75e2f9dd9cd77e0c33163341541b3cf66eaa5"},"cell_type":"markdown","source":"Stemming refers to the removal of suffices, like “ing”, “ly”, “s”, etc. by a simple rule-based approach. For this purpose, we will use PorterStemmer from the NLTK library."},{"metadata":{"trusted":true,"_uuid":"40dd3d16a8000afeea60fa33a6e27351b62919fd"},"cell_type":"code","source":"from nltk.stem import PorterStemmer\n\nst = PorterStemmer()\n\ntrain_incidents[\"short_description\"][:5].apply(lambda words: \" \".join([st.stem(word) for word in words.split()]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccf29fae0ff55dcbeb3dd361859b998965ef65e9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d4718300c3ff872795dcf532f9c0903d8846f1d"},"cell_type":"markdown","source":"#### Handling Date fields\n"},{"metadata":{"_uuid":"5d2e758a95bb95a73ddbf633665629dd5571d687"},"cell_type":"markdown","source":"Converting string date objects to timestamps- Required to extract dates and time"},{"metadata":{"trusted":true,"_uuid":"6c34b3bb7ea8d7086d25a0d0d77d43ba59c9c9c6"},"cell_type":"code","source":"train_incidents[\"sys_created_on\"] = (pd.to_datetime(train_incidents[\"sys_created_on\"],format='%d/%m/%Y %H:%M'))\ntrain_incidents[\"sys_updated_on\"] = (pd.to_datetime(train_incidents[\"sys_updated_on\"],format='%d/%m/%Y %H:%M'))\ntrain_incidents[\"opened_at\"] = (pd.to_datetime(train_incidents[\"opened_at\"],format='%d/%m/%Y %H:%M'))\ntrain_incidents[\"resolved_at\"] = (pd.to_datetime(train_incidents[\"resolved_at\"],format='%d/%m/%Y %H:%M'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a9d66939d3a59c0389894a8a28b7e706719604d"},"cell_type":"code","source":"### Extracting dates from datetime object\ntrain_incidents[\"opened_at_date\"] = train_incidents[\"opened_at\"].dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ee5b374c123b938b7c9bab80eb355e740eff1b0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2b311cd2e91e22aa0df77cafdf54332658ec440"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83a40f0a4ebb9687a577ba2273065e27cdc3b1b7"},"cell_type":"markdown","source":"### Creating group by objects"},{"metadata":{"trusted":true,"_uuid":"062039b54d2f8e4176c6939747a5238272aa469f"},"cell_type":"code","source":"## Creating Category GROUPBY Object\nincidents_category = train_incidents.groupby(\"category\")\n## Creating sub Category GROUPBY Object\nincidents_incident_subcategory = train_incidents.groupby(\"incident_subcategory\")\n## Creating priority GROUPBY Object\nincidents_priority= train_incidents.groupby(\"priority\")\n## Creating priority GROUPBY Object\nincidents_urgency= train_incidents.groupby(\"urgency\")\n## Creating re-open GROUPBY Object\nincidents_reopen_count= train_incidents.groupby(\"reopen_count\")\n## Creating made_sla GROUPBY Object\nincidents_made_sla= train_incidents.groupby(\"made_sla\")\n## Creating incident type GROUPBY Object\nincidents_type= train_incidents.groupby(\"incident_type\")\n\n\n## Creating impact GROUPBY Object\nincidents_impact= train_incidents.groupby(\"impact\")\n\n## Creating Escalations GROUPBY Object\nincidents_escalation= train_incidents.groupby(\"escalation\")\n\n## Creating E2E resolution met Object\nincidents_e2e_resolution_met= train_incidents.groupby(\"e2e_resolution_met\")\n\n## Creating location Object\nincidents_location = train_incidents.groupby(\"current_location\")\n\n## Creating location Object\nincidents_country = train_incidents.groupby(\"country\")\n\n## Creating contact type Object\nincidents_contact_type = train_incidents.groupby(\"contact_type\")\n\n## Creating affected user Object\nincidents_affected_user = train_incidents.groupby(\"affected_user\")\n\n## Creating assigned group Object\nincidents_assignment_group = train_incidents.groupby(\"assignment_group\")\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"952ad7c60278df7a71f38f91ce25e2421325077f"},"cell_type":"markdown","source":"##  3. Extract Featuring  - Advanced Text Analytics"},{"metadata":{"trusted":true,"_uuid":"c7a045327c745b025312a153c06f232547b71a91"},"cell_type":"code","source":"### Analyzing top 20 frequent words\n\n\nsd_freq_plot = Short_description_most_freq_words.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Number Of Words\")\n\nplt.style.use(\"ggplot\")\nsd_freq_plot.set_xlabel(\"Frequency\")\nsd_freq_plot.set_ylabel(\"Terms\")\n\ntotals = []\nfor i in sd_freq_plot.patches:\n    totals.append(i.get_width())\n\nfor i in sd_freq_plot.patches:\n    sd_freq_plot.text(i.get_width()+.3,i.get_y()+0.1,str(i.get_width()),fontsize = 8,color= 'black')\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1aa98ec414b7e4f19aef5259e068382788172eb9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"331a3a690e0c85a22a6072e0cd07577f5aba7b7e"},"cell_type":"markdown","source":"* ##### 3.1. N-Grams"},{"metadata":{"trusted":true,"_uuid":"67d025193c9f0bc4d8d2e6c5a11c9f6d575ff751"},"cell_type":"code","source":"### Lets generate bigrams and store it in a bi_grams variable\n### train_incidents[\"bi_grams\"] = train_incidents[\"short_description\"].apply(lambda x: TextBlob(x).ngrams(2))\n### train_incidents[\"bi_grams\"].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b58262a2a0dbeb3e4927300e0538cf7af3cc111"},"cell_type":"code","source":"### Lets generate trigrams and store it in a tri_grams variable\n### train_incidents[\"tri_grams\"] = train_incidents[\"short_description\"].apply(lambda x: TextBlob(x).ngrams(3))\n### train_incidents[\"tri_grams\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00576496985f66d7016627663944c7903f9863bd"},"cell_type":"code","source":"bigrams = TextBlob(\" \".join(train_incidents[\"short_description\"])).ngrams(2)\n#bigrams = pd.Series(bigrams).apply(lambda x: list(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"138d8dd02523a367b74a69d5e1a5f0f6d4bcdb79"},"cell_type":"markdown","source":"### Bi-Gram Frequency for Text - \"Short Description\""},{"metadata":{"trusted":true,"_uuid":"a3b5bbd5e41c94052f7c60424012223937ff793f"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(train_incidents[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\nbi_grams_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n    ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7d3ba5f20dc30ea5b1b99d5d5307351df194dc58"},"cell_type":"code","source":"bi_grams_df.sort_values(by = \"frequency\",ascending=False).head(20)\n\n#grams_df[grams_df.index.str.contains(\"reconciliation\")]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74b6c1183bc2bab9c63455ea80b6363acfb7039e"},"cell_type":"markdown","source":"#### Bi Grams Data Visualization"},{"metadata":{"trusted":true,"_uuid":"93269fc2cb65e888e35d99494aba5a9a5100b175"},"cell_type":"code","source":"### Analyzing top 20 frequent BI Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\",)\nplt.ylabel(\"Terms\")\ntop20_bigrams = bi_grams_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop20_bigrams.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Bi Grams\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25934fedc06afe8269af4a7a3c05b05078a64665"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"738045e689660a0b284e12fce60c43d575dfa2b4"},"cell_type":"markdown","source":"##### What are the most frequent words combined with word \"Issue\""},{"metadata":{"trusted":true,"_uuid":"584fe4acbe2af074ce50dac1fa8f9a6e43da3826"},"cell_type":"code","source":"train_incidents_word_issue = train_incidents[train_incidents[\"short_description\"].str.contains(\"issue\")]\n\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue qlikview\",\"qliview issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue data\",\"data issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue mrh\",\"mrh issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue dashboard\",\"dashboard issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue access\",\"access issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue query\",\"query issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue ebi\",\"ebi issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue report\",\"report issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue hr\",\"hr issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue mrh2\",\"mrh2 issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue master\",\"master issue\")\ntrain_incidents_word_issue[\"short_description\"] = train_incidents_word_issue[\"short_description\"].str.replace(\"issue file\",\"file issue\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb945f438be3e62aa9bc6ac7524375006883acad"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(train_incidents_word_issue[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\nbi_grams_issue_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"704e6aeda01c6cedddcdc3e5c013e32701a78019"},"cell_type":"code","source":"bi_grams_issue_df[bi_grams_issue_df.index.str.contains(\"issue\")].sort_values(by = \"frequency\",ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c408c1208669fb3fcb585179b81394fc30d6b23"},"cell_type":"markdown","source":"###### Bi Grams Data Visualization-- words containing issue"},{"metadata":{"trusted":true,"_uuid":"3e1d3e412061445bfadf3cc782a5b92d6048fba7"},"cell_type":"code","source":"### Analyzing top 20 frequent BI Gram words- word containing issue\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Terms\")\nplt.title(\"Top 10 Frequent Bi Grams contains word \"\"issue\"\"\")\ntop20_bigrams_issue = bi_grams_issue_df[\"frequency\"].sort_values(ascending = False)\n\ntop20_bigrams_issue_plot = top20_bigrams_issue[top20_bigrams_issue.index.str.contains(\"issue\")].head(10).sort_values(ascending = True).plot(kind=\"barh\")\n\ntotals = []\nfor i in top20_bigrams_issue_plot.patches:\n    totals.append(i.get_width())\n\nfor i in top20_bigrams_issue_plot.patches:\n    top20_bigrams_issue_plot.text(i.get_width()+.3,i.get_y()+0.1,str(i.get_width()),fontsize = 10,color= 'black')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5d3c1666e8f775808ed31202d620b396ec27189"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff68cdb5e95604ec56e1b2e1c8fc7b5b2b13737b"},"cell_type":"markdown","source":"#### Finding out the patterns between word \"data issues\" with other attributes:"},{"metadata":{"trusted":true,"_uuid":"0194b85c58f1685e3e74c1281b062844dd70c1a5"},"cell_type":"code","source":"train_incidents_word_issue.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bd1e78900c930bef0e727d12bec259e750c2111"},"cell_type":"code","source":"train_incidents_word_issue[\"data_issue_count\"] = \"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7140afce62163c0f7057cda92142734f9b037101"},"cell_type":"code","source":"\nword_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nfor each in (train_incidents_word_issue[\"short_description\"].index):\n    text_issue_list = [train_incidents_word_issue[\"short_description\"][each]]\n    sparse_matrix = word_vectorizer.fit_transform(text_issue_list)\n    frequencies = sum(sparse_matrix).toarray()[0]\n    bi_grams_issue_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n    train_incidents_word_issue[\"data_issue_count\"][each] = bi_grams_issue_df[bi_grams_issue_df.index.str.contains(\"^data issue$\")][\"frequency\"].sum()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"930e4f357f8e1d0ab65cbe79b4660246ef13aa1f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3da594266597e9948135d5dc410aab314f6314a9"},"cell_type":"code","source":"### Occurance of Word \"data issue\" in \"short description\" VS categories\nissue_category_groupby = train_incidents_word_issue.groupby(by=\"category\")\nissue_category_groupby[\"data_issue_count\"].sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c37281e9c58f774d5e106ea6be248e853e446259"},"cell_type":"code","source":"### Word \"data issue\" in \"short description\" VS sub categories\nissue_subcategory_groupby = train_incidents_word_issue.groupby(by=\"incident_subcategory\")\nissue_subcategory_groupby[\"data_issue_count\"].sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"626d1d801541af1d6409f5fd17aa5e8d06a7cf60"},"cell_type":"code","source":"### Word \"data issue\" in \"short description\" VS impact\nissue_impact_groupby = train_incidents_word_issue.groupby(by=\"impact\")\nissue_impact_plot= issue_impact_groupby[\"data_issue_count\"].sum()\nissue_impact_plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f8c95101bbc38d5880e8f50901af94a56a6486e"},"cell_type":"code","source":"### Word \"data issue\" in \"short description\" VS source\nissue_assignment_groupby = train_incidents_word_issue.groupby(by=\"assignment_group\")\nissue_assignment_freq= issue_assignment_groupby[\"data_issue_count\"].sum()\nissue_assignment_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ae3fb432634c1be01a75a904bb6bb37922467d"},"cell_type":"code","source":"### Word \"data issue\" in \"short description\" VS location\nissue_location_groupby = train_incidents_word_issue.groupby(by=\"current_location\")\nissue_location_freq= issue_location_groupby[\"data_issue_count\"].sum()\nissue_location_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5de6bb336492a131ac1134c6e759158a4b96cb8b"},"cell_type":"code","source":"### Word \"data issue\" in \"short description\" VS Contact type\nissue_contact_type_groupby = train_incidents_word_issue.groupby(by=\"contact_type\")\nissue_contact_type_freq= issue_contact_type_groupby[\"data_issue_count\"].sum()\nissue_contact_type_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43b7482a540d70637da813f4f65ab96687fa9899"},"cell_type":"code","source":"### Word \"data issue\" in \"short description\" VS Syngenta location\nissue_syn_loc_groupby = train_incidents_word_issue.groupby(by=\"syngenta_location\")\nissue_syn_loc_freq= issue_syn_loc_groupby[\"data_issue_count\"].sum()\nissue_syn_loc_freq.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6405fd832c4cc259a31733f8a38e8ffebdbb005d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0de3cbc3700a00ec5431a4591ee9b463bf0ad968"},"cell_type":"code","source":"train_incidents_word_issue[\"top10_issue_count\"] = \"\"\n\nword_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nfor each in (train_incidents_word_issue[\"short_description\"].index):\n    text_issue_list = [train_incidents_word_issue[\"short_description\"][each]]\n    sparse_matrix = word_vectorizer.fit_transform(text_issue_list)\n    frequencies = sum(sparse_matrix).toarray()[0]\n    bi_grams_top_10_issue_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n    train_incidents_word_issue[\"top10_issue_count\"][each] = bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^data issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^dashboard issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^query issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^mapping issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^access issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^mrh issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^file issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^ebi issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^report issue$\")][\"frequency\"].sum() + bi_grams_top_10_issue_df[bi_grams_top_10_issue_df.index.str.contains(\"^qlikview issue$\")][\"frequency\"].sum()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41ec87f56cd4149e5b121f1ebfdf6649c8e7a6dc"},"cell_type":"code","source":"issue_impact_groupby[\"top10_issue_count\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cab0acda5ab96eee467b35972b22a74f081add2c"},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.title(\"Top 10 issues VS tickets Priority\")\nplt.ylabel(\"Top 10 Issues\")\nplt.xlabel(\"Tickets Priority\")\nissue_priority_groupby = train_incidents_word_issue.groupby(\"priority\")\nissue_priority_groupby[\"top10_issue_count\"].sum().plot(kind = \"bar\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fe010af0b4c3bfbd06d74212be9cd3eccbebc0e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"694da458e92c79d828aad8b4fef161b0b3d804a9"},"cell_type":"code","source":"train_incidents_word_issue[\"opened_at_date\"].head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d091cdb4f2f7f1b9a547379451ad4e1f9c700fb"},"cell_type":"code","source":"train_incidents_word_issue[\"opened_at_year\"] = train_incidents_word_issue[\"opened_at\"].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b7514631d587e55d5b93d72419aef24ff4228a5"},"cell_type":"code","source":"# Top 10 data issues VS ticket Opened Year Analysis\nplt.style.use(\"ggplot\")\nplt.title(\"Top 10 data issues VS ticket Opened Year Analysis\")\nplt.ylabel(\"Top 10 Issues\")\nissue_opened_at_year_grpby = train_incidents_word_issue.groupby(\"opened_at_year\")\nissue_opened_at_year_grpby[\"top10_issue_count\"].sum().plot(kind =\"bar\")\nplt.xlabel(\"Tickets Opened at Year\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b916dd0754f84074681b359bacb35b994adec5f9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d15b6aae763c0d965be130146caa3a01b4a80852"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"416410e1cd4be1df6f8a4ef6930bccaeb839554a"},"cell_type":"markdown","source":"### Tri-Gram Frequency for Text - \"Short Description\""},{"metadata":{"trusted":true,"_uuid":"3f26de07cb6cf3fc4e1670d7ca426e0593c30ade"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(3,3), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(train_incidents[\"short_description\"])\n#sparse_matrix = word_vectorizer.fit_transform(train_incidents[\"short_description_tokens\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\ntri_grams_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cd535de4d14176adb5a151cfc2b711ff15ef48a"},"cell_type":"code","source":"tri_grams_df.sort_values(by = \"frequency\",ascending=False).head(20)\n\n##grams_df[grams_df.index.str.contains(\"reconciliation\")]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f33189d58b394eac08471400e6dbc17307a3e4a9"},"cell_type":"markdown","source":"#### Tri Grams Data Visualization"},{"metadata":{"trusted":true,"_uuid":"a688befc62fdd89bb945cb15455267cad18de2ac"},"cell_type":"code","source":"### Analyzing top 20 frequent Tri Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Terms\",)\nplt.ylabel(\"Frequency\")\ntrigrams_short_description = tri_grams_df[\"frequency\"].sort_values(ascending = False)\ntop20_trigrams = tri_grams_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop5_trigrams_plot =  top20_trigrams.head(5).sort_values(ascending = False).plot(kind=\"bar\",title = \"Top 5 Frequent Tri Grams\")\ntop5_trigrams_plot\nplt.xticks(rotation=75)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1edec7e882ebcb0a1d28248077f31d5823686114"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8443a8b5dd36ed4e4c80b8a6e41f6ee0bd1b2d13"},"cell_type":"code","source":"#### Find N grams for category - incident\n\nword_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(incidents_category.get_group(\"Incident\")[\"short_description\"])\nfrequencies_Incident_cate = sum(sparse_matrix).toarray()[0]\ngrams_df_incident_cate = pd.DataFrame(frequencies_Incident_cate, index=word_vectorizer.get_feature_names(), columns=['Incident_category_frequency'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1226c19f3a6acb5e52e2473652c5d1753c13da6"},"cell_type":"code","source":"grams_df_incident_cate.sort_values(by = \"Incident_category_frequency\",ascending= False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8642807c6cfa12e3ca0c42f0d2cb53dad732c93c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"af8ca72a3cbd4ce30d8ab541091cd97a7c86eefc"},"cell_type":"code","source":"#### Find N grams for category - Request\n\nword_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(incidents_category.get_group(\"Request\")[\"short_description\"])\nfrequencies_Request_cate = sum(sparse_matrix).toarray()[0]\ngrams_df_Request_cate = pd.DataFrame(frequencies_Request_cate, index=word_vectorizer.get_feature_names(), columns=['Request_category_frequency'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"c1e8347f6ed3efca5d32dc13ee198fd4b5ce95f6"},"cell_type":"code","source":"grams_df_Request_cate.sort_values(by = \"Request_category_frequency\",ascending= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"031bb2fec5fa94562385e8defe7897d778e1c948"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35baac18e22d867bf8bef1c6c3459c1a699805ae"},"cell_type":"markdown","source":"#### Plotting bi grams of Categories \"Request\" vs \"Incidents\""},{"metadata":{"trusted":true,"_uuid":"e0af66e3107766059abcb2372865c781a145946d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c45ca9196da35118a89b06b2d06974f3dafeb9a"},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\",)\nplt.ylabel(\"Bi Grams\")\ngrams_Request_cate = grams_df_Request_cate[\"Request_category_frequency\"].sort_values(ascending = False).head(20)\ngrams_Request_cate.sort_values(ascending = True).plot(kind=\"barh\",title = \"Request Category - Top 20 Frequent Number Of Words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3be4a9d00fed2d6bf63d0fbe991c4ac9e03c2e54"},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\",)\nplt.ylabel(\"Bi Grams\")\ngrams_df_incident_cate = grams_df_incident_cate[\"Incident_category_frequency\"].sort_values(ascending = False).head(20)\ngrams_df_incident_cate.sort_values(ascending = True).plot(kind=\"barh\",title = \"Incident Category - Top 20 Frequent Number Of Words\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0cfd43aa6988205c0e5221e97a44a3b69a0ed05"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c2d0bb571606e34de33ae05b356c7a727951cce"},"cell_type":"markdown","source":"#### Occurances of Term \"Report\" in Incidents text variable \"short description\" Vs variable \"Category\" Analysis"},{"metadata":{"trusted":true,"_uuid":"d11b3d2b82fccc2a6cb641bc62a2279f2dc03f6e"},"cell_type":"code","source":"train_incidents[\"short_desc_report_count\"]  = train_incidents[\"short_description_tokens\"].apply(lambda x: list(x).count(\"report\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79212dbad27765ab3f6311c90c83ad3c1f91fd06"},"cell_type":"code","source":"incidents_category[\"short_desc_report_count\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98025a2b8f61f53f36f11daa0a5f7fdb4c13c012"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9134c5832b1557185c9aa65373c7ea4548946bfc"},"cell_type":"markdown","source":"#### Occurances of Term \"Authorization\" in Incidents text variable \"short description\" Vs variable \"Category\" Analysis"},{"metadata":{"trusted":true,"_uuid":"e38fb12c09aa1a64d95a6b9588abe076976cd83b"},"cell_type":"code","source":"train_incidents[\"short_desc_authorization_count\"] = train_incidents[\"short_description_tokens\"].apply(lambda x: list(x).count(\"authorization\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ecc0ada4bb9be88624ad4374f29e3cd7144ac03"},"cell_type":"code","source":"incidents_category[\"short_desc_authorization_count\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bc3f15cd1c8108e10bdd5bd9877190cc4c6ba94"},"cell_type":"markdown","source":"#### Occurances of Term \"Authorization\" in Incidents text variable \"short description\" Vs variable \"Escalation\" Analysis"},{"metadata":{"trusted":true,"_uuid":"4e7c6a6d7ba4c7975e02cef56812c065b585f570"},"cell_type":"code","source":"incidents_escalation[\"short_desc_authorization_count\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c88f182c14fdf9904c95952c37e3e4ae88471b2"},"cell_type":"code","source":"incidents_type[\"short_desc_authorization_count\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3106edfa1dae28bcc84964078ab69b6377fcc3ed"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55522422443c18793e5effa3f9dcdacf8ff8ae4c"},"cell_type":"markdown","source":"## Lexical dispersion plot"},{"metadata":{"trusted":true,"_uuid":"db0a00976e3209c73fd20a9d5b6bc43eb540c444"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"23a77b207eb2b1a1cd4247a4eb2da07e43f7a97c"},"cell_type":"code","source":"train_incidents_sorted_opened_at_df  = train_incidents.sort_values(by = \"opened_at\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d6588ceb45ee2553bb8355eca499950920fcac3"},"cell_type":"code","source":"train_incidents_sorted_opened_at_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f89c3981bc8b0350f224c23289faf23f7281c4a"},"cell_type":"code","source":"\n#nltk.download('inaugural')\n#nltk.download('nps_chat')\n#nltk.download('webtext')\n#nltk.download('treebank')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e2024374a4dabad4ea4ec15c6e7ff786e973b75"},"cell_type":"markdown","source":"##### This is the plot of a word vs the offset of the word in the text corpus.\nThe y-axis represents the word. Each word has a strip representing entire text in terms of offset, and a mark on the strip indicates the occurrence of the word at that offset, a strip is an x-axis. \n\nSo if you observe the plot below the terms \"ebi\",\"reload\" occur more often at the 2nd half the incidents and words like \"authorization\" and some words have somewhat uniform distribution in the middle. \n"},{"metadata":{"trusted":true,"_uuid":"417b5b20dd7e25ad221a30c5c04f44dc3e24a4fa"},"cell_type":"code","source":"short_desc_tokens_series = train_incidents[\"short_description_tokens\"].apply(lambda x: list(x))\nshort_desc_tokens_series = short_desc_tokens_series.tolist()\nshort_desc_tokens_series\n\n#short_desc_tokens_list = list(itertools.chain.from_iterable(short_desc_tokens_series))   \n#short_desc_tokens_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef53ac8552088689079ca28e35c8987ff7c1c1b0"},"cell_type":"code","source":"\nshort_desc_tokens_series = train_incidents[\"short_description_tokens\"].apply(lambda x: list(x))\nshort_desc_tokens_series = short_desc_tokens_series.tolist()\nshort_desc_tokens_series\n\nshort_desc_tokens_list = list(itertools.chain.from_iterable(short_desc_tokens_series))   \nshort_desc_tokens_list\n\nplt.figure(figsize=(16,5))\n## Make the list as NLTK object\nshort_desc_tokens_list = nltk.Text(short_desc_tokens_list)\n\ntopics = ['authorization', 'access', 'reload',\"qlikview\",\"mismatch\",\"reconciliation\",\"ebi\",\"mapping\",\"report\"]\nshort_desc_tokens_list.dispersion_plot(topics)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd50af86fab09407cdfa0f4a5366e40fd7716052"},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5cfc75c73914f68b93e7031f361c0f6870a179e"},"cell_type":"markdown","source":"### \"Short description\" token VS \"Opened at\" time series analysis"},{"metadata":{"trusted":true,"_uuid":"e62e163a6b2aa6d5a32d3b0aaf02609e51b225e8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"19c59f6872d08c74b7bbbdfd757ce13a58a7e590"},"cell_type":"code","source":"###\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# datetime parser\nfilepath2 = \"../input/it-incidents-tokens-vs-date-fields-data/short_description_token_vs_open_at_dates.csv\"\n\nwith open(filepath2,'rb') as filep:\n    result2 = chardet.detect(filep.read(1000000))\n    result2\n\nresult2\n\nsd_token_timeseries = pd.read_csv(filepath2,encoding=\"Windows-1252\")\n\nsd_token_timeseries[\"Opened_at\"] = (pd.to_datetime(sd_token_timeseries[\"Opened_at\"],format = '%d/%m/%Y'))\n## Delete duplicates value of all the rows\nsd_token_timeseries = sd_token_timeseries.drop_duplicates()\n\nsd_token_timeseries.head\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96496a9912cb6437cf7212020423b4d33ef61364"},"cell_type":"code","source":"### Filter the tokens data containing selected tokens to analyze with open dates\n#selected_tokens_mask = sd_token_timeseries[\"Short_desc_tokens\"].str.contains(\"access|reload\",regex = True)\n\n#sd_token_timeseries[\"Short_desc_selected_tokens\"] = np.where(selected_tokens_mask,sd_token_timeseries[\"Short_desc_tokens\"])\n\nsd_token_timeseries[\"Short_desc_selected_tokens\"] = sd_token_timeseries[\"Short_desc_tokens\"].str.extract(\"(\"+'authorization|reload|mismatch|reconciliation|access|qlikview|ebi|query|report|mapping'+\")\",expand = False)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"aa9502b7a9e7e411a2bdb78d0a15aa4d4f816245"},"cell_type":"code","source":"sd_token_timeseries_updated = sd_token_timeseries.dropna()\nsd_token_timeseries_updated.drop_duplicates(subset=[\"Opened_at\",\"Short_desc_selected_tokens\"],keep=\"first\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a299cb5953d77e7e47f6c50c6d540e3e13b7a84c"},"cell_type":"code","source":"# set size of figure\nplt.figure(figsize=(16,10))\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='Short_desc_selected_tokens',x='Opened_at', data=sd_token_timeseries_updated,\n orient='h', marker='^', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50,size= 15)\nplt.yticks(size= 15)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Tokens VS tickets Open Date - Time Series Analysis\",size= 30)\nplt.ylabel(\"Issues\",size = 20)\nplt.xlabel(\"Tickets Opened at\",size = 20)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd64d20c9b67a5d4865aa62d64eaf319a2462901"},"cell_type":"markdown","source":"\n\n###### Tickets Opened at VS incident_sub category -- DIspersion Analysis"},{"metadata":{"trusted":true,"_uuid":"8c209a65759b3bb028799841fa6f998e33b58c60"},"cell_type":"code","source":"# set size of figure\nplt.figure(figsize=(16,10))\n\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='incident_subcategory',x='opened_at', data=train_incidents,\n orient='h', marker='X', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Incident Sub-Category VS tickets Open Date - Time Series Analysis\")\nplt.ylabel(\"Sub category\")\nplt.xlabel(\"Tickets Opened at\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc1da8ce068148c4283b8539c88e61512b5552c7"},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cb5f824d92aace73464a42c9211172fc70e39d5"},"cell_type":"markdown","source":"\n\n###### Tickets Opened at VS Priority -- DIspersion Analysis"},{"metadata":{"trusted":true,"_uuid":"66fc988b384dbb885d2d2e2ee287d4f13b53d13b"},"cell_type":"code","source":"# set size of figure\n\nplt.figure(figsize=(16,10))\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='priority',x='opened_at', data=train_incidents,\n orient='h', marker='X', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Incident Priority VS tickets Open Date - Time Series Analysis\")\nplt.ylabel(\"Priority\")\nplt.xlabel(\"Tickets Opened at\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1990b1c6815a94b9496c1dcb0253315bfb7355c0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9186a966349a78b7b67b4fcd061eec5c341bc929"},"cell_type":"markdown","source":"###### Tickets Opened at VS Close status -- DIspersion Analysis"},{"metadata":{"trusted":true,"_uuid":"baaae40d399aa5be800c4efc8114374a8b15e425","scrolled":true},"cell_type":"code","source":"# set size of figure\n\nplt.figure(figsize=(16,10))\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='close_code',x='opened_at', data=train_incidents,\n orient='h', marker='X', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Ticket closure status VS tickets Open Date - Time Series Analysis\")\nplt.ylabel(\"Tickets Closure Status\")\nplt.xlabel(\"Tickets Opened at\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30fe6a39d118b01f09cb24607af8693b0f5785d9"},"cell_type":"markdown","source":"###  Time Series Analysis on Bi grams and Tri Grams"},{"metadata":{"trusted":true,"_uuid":"87367bd89f97178a2815f4883d063cda7b21fe08","scrolled":false},"cell_type":"code","source":"train_incidents[\"selected_bi_grams_text\"] = train_incidents[\"short_description\"].str.extract(\"(\"+'net sale|ebi report|mrh report|sale report|qlikview dashboard|sale broadcast|tp tool|daily sale|mrh query|demand review|access request|review dashboard|data issue|edwh ebi|edwh report|complaint valid|sale data|fr qlikview|3rd party|incorrect data'+\")\",expand = False)\ntrain_incidents[\"selected_bi_grams_text\"].head()\ntrain_incidents[\"selected_bi_grams_text\"] = train_incidents[\"selected_bi_grams_text\"].apply(lambda x: str(x))\n#train_incidents[\"selected_bi_grams_text\"].str.replace(np.nan,\"\",regex= True)\ntrain_incidents.selected_bi_grams_text.fillna(\"\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b097189a801fe1c920f4eedd9d614fb132f3475e"},"cell_type":"code","source":"train_incidents[\"top_20_bi_grams_list\"] = \" \"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f733bd63aa48e6a7e5b37dd269a1a2de4f1018c0"},"cell_type":"code","source":" \nword_vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",stop_words=None,ngram_range=(2,2), analyzer='word')\nfor each in (train_incidents[\"selected_bi_grams_text\"].index):\n    if (train_incidents[\"selected_bi_grams_text\"][each] != 'nan'):\n        text_list = [train_incidents[\"selected_bi_grams_text\"][each]]\n        sparse_matrix = word_vectorizer.fit_transform(text_list)\n        df11 = pd.DataFrame(word_vectorizer.get_feature_names(), columns=['bi_grams'])\n        train_incidents[\"top_20_bi_grams_list\"][each] = list(df11.bi_grams)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9b0935ac2b7ba9f276a9e8c2fa964e65ce76dda9"},"cell_type":"code","source":"## Lets check the format of the data\ntrain_incidents[\"top_20_bi_grams_list\"].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2b7478803caefaa624186d3e9a4ee7f17872d9","scrolled":true},"cell_type":"code","source":"bi_grams_date_df =  train_incidents[[\"opened_at_date\",\"top_20_bi_grams_list\"]]\n#bi_grams_date_df[\"top20_bi_grams_list\"].apply(lambda x: str(x))\nbi_grams_date_df[\"top_20_bi_grams_list\"] = bi_grams_date_df[\"top_20_bi_grams_list\"].apply(lambda x: \"\".join(x))\n#bi_grams_date_df[bi_grams_date_df.isnull]\nbi_grams_date_df = bi_grams_date_df[bi_grams_date_df[\"top_20_bi_grams_list\"] != \" \"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c22a81e95fbb631b55af76d73ba75e397a79c3"},"cell_type":"code","source":"\n# set size of figure\nplt.figure(figsize=(16,10))\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='top_20_bi_grams_list',x='opened_at_date', data=bi_grams_date_df,\n orient='h', marker='^', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50,size= 15)\nplt.yticks(size= 15)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Bi Grams VS Tickets Open Date - Time Series Analysis\",size= 30)\nplt.ylabel(\"Bi Grams\",size = 20)\nplt.xlabel(\"Tickets Opened at\",size = 20)\nplt.show()\n\n### Its observed majority of the bigrams piled up during 2018 compare to 2017 and few terms like demand review,FR Qlikview are not seen in 2017 at all","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6802c463f83cf6d03630f119e12c1f01ac393ad"},"cell_type":"markdown","source":"## Tri grams- time series analysis"},{"metadata":{"trusted":true,"_uuid":"87367bd89f97178a2815f4883d063cda7b21fe08","scrolled":false},"cell_type":"code","source":"train_incidents[\"selected_tri_grams_text\"] = train_incidents[\"short_description\"].str.extract(\"(\"+'net sale broadcast|demand review dashboard|global edwh ebi|hr master file|3rd party net|daily sale report|party net sale|manual file upload|ea field crop|file upload qlikview|crop manual file|apac ea field|field crop manual|qlikview demand review|global qlikview demand|qlik demand dashboard|demand dashboard refresh|incident apac ea|related qlik demand|wd activity related'+\")\",expand = False)\ntrain_incidents[\"selected_tri_grams_text\"].head()\ntrain_incidents[\"selected_tri_grams_text\"] = train_incidents[\"selected_tri_grams_text\"].apply(lambda x: str(x))\ntrain_incidents.selected_tri_grams_text.fillna(\"\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b097189a801fe1c920f4eedd9d614fb132f3475e"},"cell_type":"code","source":"train_incidents[\"top_20_tri_grams_list\"] = \" \"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f733bd63aa48e6a7e5b37dd269a1a2de4f1018c0"},"cell_type":"code","source":" \nword_vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",stop_words=None,ngram_range=(3,3), analyzer='word')\nfor each in (train_incidents[\"selected_tri_grams_text\"].index):\n    if (train_incidents[\"selected_tri_grams_text\"][each] != 'nan'):\n        text_list = [train_incidents[\"selected_tri_grams_text\"][each]]\n        sparse_matrix = word_vectorizer.fit_transform(text_list)\n        df12 = pd.DataFrame(word_vectorizer.get_feature_names(), columns=['tri_grams'])\n        train_incidents[\"top_20_tri_grams_list\"][each] = list(df12.tri_grams)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9b0935ac2b7ba9f276a9e8c2fa964e65ce76dda9"},"cell_type":"code","source":"## Lets check the format of the data\ntrain_incidents[\"top_20_tri_grams_list\"].tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2b7478803caefaa624186d3e9a4ee7f17872d9"},"cell_type":"code","source":"tri_grams_date_df =  train_incidents[[\"opened_at_date\",\"top_20_tri_grams_list\"]]\ntri_grams_date_df[\"top_20_tri_grams_list\"] = tri_grams_date_df[\"top_20_tri_grams_list\"].apply(lambda x: \"\".join(x))\ntri_grams_date_df = tri_grams_date_df[tri_grams_date_df[\"top_20_tri_grams_list\"] != \" \"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c22a81e95fbb631b55af76d73ba75e397a79c3"},"cell_type":"code","source":"\n# set size of figure\nplt.figure(figsize=(16,10))\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='top_20_tri_grams_list',x='opened_at_date', data=tri_grams_date_df,\n orient='h', marker='^', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50,size= 15)\nplt.yticks(size= 15)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Tri Grams VS Tickets Open Date - Time Series Analysis\",size= 30)\nplt.ylabel(\"Tri Grams\",size = 20)\nplt.xlabel(\"Tickets Opened at\",size = 20)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbc15f2ad3b58755b9eb8c9775ebb44fbad00bc7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b0aef95c5aa5fcf9ee4955f2c3d1ee96ca33a3a"},"cell_type":"markdown","source":"#### Lets analyze the time series of all the incidents contains word 'issue'. So, we will use the extracted text contains word issues and see the time series pattern."},{"metadata":{"trusted":true,"_uuid":"87367bd89f97178a2815f4883d063cda7b21fe08","scrolled":false},"cell_type":"code","source":"train_incidents[\"bi_grams_contains_issue\"] = train_incidents[\"short_description\"].str.extract(\"(\"+'data issue|dashboard issue|mapping issue|query issue|access issue|mrh issue|file issue|ebi issue|report issue|mrh2 issue'+\")\",expand = False)\ntrain_incidents[\"bi_grams_contains_issue\"].head()\ntrain_incidents[\"bi_grams_contains_issue\"] = train_incidents[\"bi_grams_contains_issue\"].apply(lambda x: str(x))\ntrain_incidents.bi_grams_contains_issue.fillna(\"\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b097189a801fe1c920f4eedd9d614fb132f3475e"},"cell_type":"code","source":"train_incidents[\"top_10_bi_grams_issue_list\"] = \" \"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f733bd63aa48e6a7e5b37dd269a1a2de4f1018c0"},"cell_type":"code","source":" \nword_vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",stop_words=None,ngram_range=(2,2), analyzer='word')\nfor each in (train_incidents[\"bi_grams_contains_issue\"].index):\n    if (train_incidents[\"bi_grams_contains_issue\"][each] != 'nan'):\n        text_list = [train_incidents[\"bi_grams_contains_issue\"][each]]\n        sparse_matrix = word_vectorizer.fit_transform(text_list)\n        df13 = pd.DataFrame(word_vectorizer.get_feature_names(), columns=['bi_grams_contains_issues'])\n        train_incidents[\"top_10_bi_grams_issue_list\"][each] = list(df13.bi_grams_contains_issues)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9b0935ac2b7ba9f276a9e8c2fa964e65ce76dda9"},"cell_type":"code","source":"## Lets check the format of the data\ntrain_incidents[\"top_10_bi_grams_issue_list\"][2274]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2b7478803caefaa624186d3e9a4ee7f17872d9"},"cell_type":"code","source":"bi_grams_issue_date_df =  train_incidents[[\"opened_at_date\",\"top_10_bi_grams_issue_list\"]]\nbi_grams_issue_date_df[\"top_10_bi_grams_issue_list\"] = bi_grams_issue_date_df[\"top_10_bi_grams_issue_list\"].apply(lambda x: \"\".join(x))\nbi_grams_issue_date_df = bi_grams_issue_date_df[bi_grams_issue_date_df[\"top_10_bi_grams_issue_list\"] != \" \"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c22a81e95fbb631b55af76d73ba75e397a79c3"},"cell_type":"code","source":"\n# set size of figure\nplt.figure(figsize=(16,10))\n\n# use horizontal stripplot with x marker size of 5\nsns.stripplot(y='top_10_bi_grams_issue_list',x='opened_at_date', data=bi_grams_issue_date_df,\n orient='h', marker='^', color='navy', size=4)\n# rotate x tick labels\nplt.xticks(rotation=50,size= 15)\nplt.yticks(size= 15)\n# remover borders of plot\nplt.style.use(\"ggplot\")\nplt.tight_layout()\nplt.title(\"Bi Grams contains word 'Issue' VS Tickets Open Date - Time Series Analysis\",size= 30)\nplt.ylabel(\"Issue Bi Grams\",size = 20)\nplt.xlabel(\"Tickets Opened at\",size = 20)\nplt.show()\n\n### Its observed data issues count were low in 2018 compared to 2017.However,report and mrh2 issue are occured more in 2018","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"020278a1bb9b6ad42966f4eb238e0282d20970c8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9438c6ccdac4b3268729feb273c22d85b6239617"},"cell_type":"markdown","source":"# Sentiment Analysis"},{"metadata":{"trusted":true,"_uuid":"8797c47cbc7169d511086c2524751344b3fe668a"},"cell_type":"code","source":"train_incidents[\"sentiments\"] = train_incidents[\"short_description\"].apply(lambda x: TextBlob(x).sentiment[0])\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"39f4c2861d0d96e4cb52a66aba66383b0d39993f"},"cell_type":"code","source":"train_incidents[[\"short_description\",\"sentiments\",\"short_description_tokens\"]].sort_values(by = \"sentiments\",ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b4dde1ad6759bc3fc1f345f7246d3f3b416e0c9"},"cell_type":"code","source":"incidents_impact[\"sentiments\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06b88bed37652261b5b95375a9e6d439fbfbd320"},"cell_type":"code","source":"incidents_impact[\"sentiments\"].sum().plot(kind= \"bar\")\nplt.title(\"Sentiment Polarity VS Incident Impact\")\nplt.xlabel(\"Impact\")\nplt.ylabel(\"Polarity\")\nplt.xticks(rotation = \"0.5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57da067e54a3d9817bf02e31cc48026ba7d8cbbc"},"cell_type":"code","source":"incidents_category[\"sentiments\"].sum().sort_values(ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"133397e5b3c08842d37d6e42497e6fca0f4b2b03"},"cell_type":"code","source":"incidents_incident_subcategory[\"sentiments\"].sum().sort_values(ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92a4cad0c779b55234dd6ef2714dcbef3a4deed"},"cell_type":"code","source":"incidents_assignment_group[\"sentiments\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"156b36480462b6308ac1a9f290c5fd8c7cad4c41"},"cell_type":"code","source":"incidents_assignment_group[\"sentiments\"].sum().plot(kind =\"bar\",color= [\"pink\",\"brown\"])\nplt.title(\"Application Wise Sentiment Polarity Analysis\")\nplt.xlabel(\"Application\")\nplt.ylabel(\"Polarity\")\nplt.xticks(rotation = \"0.5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13750801246eb7beac94bd5d6dd71ebbb799ccb2"},"cell_type":"code","source":"## Defining sentiment type based on polarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8a53ec14f220b0026adcc1ed253f937cc79b2a3"},"cell_type":"code","source":"def sentiment_type(value):\n    if value >= 0.5:\n        return \"Positive\"\n    elif value <= -0.5:\n        return \"Negitive\"\n    else:\n        return \"Neutral\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"043629f08b70700d1c31c903403d9de68778546b"},"cell_type":"code","source":"train_incidents[\"sentiment_types\"] = train_incidents[\"sentiments\"].apply(sentiment_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c32e8ef6d7aa13dfedf735c1757a22e9eb2d3a8"},"cell_type":"code","source":"train_incidents[\"sentiment_types\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df436d60a75208129db2e2afacb1fcb6957974a0"},"cell_type":"code","source":"train_incidents[\"sentiment_types\"].value_counts().plot(kind = \"bar\",color = [\"blue\",\"red\",\"green\"])\nplt.title(\"Sentiment types classification frequency\")\nplt.xlabel(\"Sentiment Types\")\nplt.ylabel(\"Frequency\")\nplt.xticks(rotation = \"0.5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c6966e7fb67702f4abc69546ecd11e5fa25dd20"},"cell_type":"code","source":"#### Sentiment types Vs incident category analysis ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65fba5c9448855438972d27f508cbfc5a2aee73f"},"cell_type":"code","source":"incident_cate_senti_type_grpby = train_incidents.groupby([\"category\",\"sentiment_types\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27747f136d480ba1f280d9152aaefb7c0a80a0e5"},"cell_type":"code","source":"df_ramdom = incident_cate_senti_type_grpby[\"number\"].count().to_frame(name = \"count\")\n\ndf_ramdom.unstack(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1da7586c89f3e40d1972fb0aa2a4c0dd5c997a8c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00bf64015aec273f6366bebcf425353c12a52c41"},"cell_type":"markdown","source":"##### Extracting sentiment words and analyzing those words with other categorical variables"},{"metadata":{"trusted":true,"_uuid":"673792ac0586820a62d1743a472818bde3d007cb"},"cell_type":"code","source":"# Importing SentimentIntensityAnalyzer  --- Method 2 -- in which we can calculate sentiment polarity\n# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n# sia = SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3999afc3f5466edb2f5dd093bf5b22fd160ff33b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be9e2b69f94ea6a56c915a24672920054158c58c"},"cell_type":"code","source":"## Function to hold positive sentiments and its words\ndef sentiment_type_words_fun_positive(words):\n    mysentilist = []\n    for word in words.split(\" \"):\n        if (TextBlob(word).sentiment[0]) >= 0.5:\n            mysentilist.append(word)\n    return mysentilist    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e86472217cd90e7dd2062b4ac6b75b77be71c9b2"},"cell_type":"code","source":"## Function to hold negitive sentiments and its words\ndef sentiment_type_words_fun_negitive(words):\n    mysentilist = []\n    for word in words.split(\" \"):\n        if (TextBlob(word).sentiment[0]) <= -0.5:\n            mysentilist.append(word)\n    return mysentilist    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff637c396e641177d8e1a27b75c12ee5f12e132"},"cell_type":"code","source":"## Function to hold neutral sentiments and its words\ndef sentiment_type_words_fun_neutral(words):\n    mysentilist = []\n    for word in words.split(\" \"):\n        if ((TextBlob(word).sentiment[0]) > -0.5 and (TextBlob(word).sentiment[0]) < 0.5):\n            mysentilist.append(word)\n    return mysentilist    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2558094cd274e77a0e988140346f8151cfb6e3a2"},"cell_type":"code","source":"### List of all postive sentimental words found in text \"short description\"\ntrain_incidents[\"sentiment_types_postive_words\"] = train_incidents[\"short_description\"].apply(sentiment_type_words_fun_positive)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c65ca30a5ea017e7d0af81a0051f3a522c6eeef1"},"cell_type":"code","source":"postive_senti_df = pd.DataFrame(train_incidents[\"sentiment_types_postive_words\"].apply(lambda x: \"\".join(x)).value_counts())\npostive_senti_df[postive_senti_df[\"sentiment_types_postive_words\"] != 2271].plot(kind = \"bar\",color = \"green\")\nplt.title(\"Most observed Positive words\")\nplt.xlabel(\"Positive Words\")\nplt.ylabel(\"Frequency\")\nplt.xticks(rotation = \"0.5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d433cee13676bae8d7ef23c7b21c2325dfeb2a2e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fd796d6a966398258104c7fb0caaf5e97772ec5"},"cell_type":"code","source":"### List of all negitive sentimental words found in text \"short description\"\ntrain_incidents[\"sentiment_types_negitive_words\"] = train_incidents[\"short_description\"].apply(sentiment_type_words_fun_negitive)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8f001428440987dd53b8f7acea047a19848768e"},"cell_type":"code","source":"negitive_df = pd.DataFrame((train_incidents[\"sentiment_types_negitive_words\"].apply(lambda x: \"\".join(x))).value_counts())\nnegitive_df[negitive_df[\"sentiment_types_negitive_words\"] != 2199].head(5).plot(kind = \"bar\")\nplt.title(\"Most observed negitive words\")\nplt.xlabel(\"Negitive Words\")\nplt.ylabel(\"Frequency\")\nplt.xticks(rotation = \"0.5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3af45905dc295cabb4f9733e2bd3d0e345dd1267"},"cell_type":"markdown","source":"#### Lets  check for bigrams / trigrams with the negative words and undiscovered patterns"},{"metadata":{"trusted":true,"_uuid":"9f381eeddfeb2e423aa4535d1a076363f7d5dc68"},"cell_type":"code","source":"mask1 = (train_incidents[\"sentiment_types\"] == \"Negitive\")\n\nnegitive_sentiment_data_df = train_incidents[[\"short_description\",\"sentiments\",\"sentiment_types_negitive_words\"]][mask1].sort_values(by = \"sentiments\",ascending = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0be209280f8f6a255dedfee426eb8f6aac7b9e6"},"cell_type":"code","source":"## Collecting top 5 negitive words into a list\ntop5_negitive_words_list = negitive_df.index[1:6]\ntop5_negitive_words_list = list(top5_negitive_words_list)\ntop5_negitive_words_list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cba7fc5753a8e8a0a0676c81d6e410cd9812f21f"},"cell_type":"code","source":"negitive_sentiment_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce55a09f30e0358f4b9b8b39c512fab6f59fcc1d"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(negitive_sentiment_data_df[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\nbi_grams_negitive_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ced99a107bcbabeed531d4851cea70136c955ae"},"cell_type":"code","source":"#### Bi grams of Negitive Sentiment Words\nbi_grams_negitive_df = bi_grams_negitive_df[bi_grams_negitive_df.index.str.contains(\"wrong|unable|failed|bad|inconvenient\")].sort_values(by = \"frequency\",ascending= False).head(20)\nbi_grams_negitive_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57920f2f014c4415fd5c2cc698666a194c6bb2fa"},"cell_type":"code","source":"### Analyzing top 20 frequent Negitive BI Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Negitive Bi Grams\")\ntop20_negitive_bigrams = bi_grams_negitive_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop20_negitive_bigrams.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Negitive Bi Grams\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df86d2c3d2b8d9c262d1a024bc7326e17ba7a614"},"cell_type":"code","source":"####### Negitive Sentiment Trigrams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34cc34d6045e7a997e058aa5d2618f4c77a25afa"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(3,3), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(negitive_sentiment_data_df[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\ntri_grams_negitive_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n\n\n#### tri grams of Negitive Sentiment Words\ntri_grams_negitive_df = tri_grams_negitive_df[tri_grams_negitive_df.index.str.contains(\"wrong|unable|failed|bad|inconvenient\")].sort_values(by = \"frequency\",ascending= False).head(20)\ntri_grams_negitive_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57920f2f014c4415fd5c2cc698666a194c6bb2fa"},"cell_type":"code","source":"### Analyzing top 20 frequent Negitive TRI Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Negitive Tri Grams\")\ntop20_negitive_trigrams = tri_grams_negitive_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop20_negitive_trigrams.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Negitive Tri Grams\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3213b566bd266241c00f33bdf76954f94b0795f4"},"cell_type":"code","source":"## SInce Tri grams above seems like have common grams revolving aroung top negitive words, \n## so higher grams would make sense to check any patterns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df86d2c3d2b8d9c262d1a024bc7326e17ba7a614"},"cell_type":"markdown","source":"## sentences involving top 20 negitive words"},{"metadata":{"trusted":true,"_uuid":"34cc34d6045e7a997e058aa5d2618f4c77a25afa"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(4,4), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(negitive_sentiment_data_df[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\nnegitive_sentences_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n\n\n#### tri grams of Negitive Sentiment Words\nnegitive_sentences_df = negitive_sentences_df[negitive_sentences_df.index.str.contains(\"wrong|unable|failed|bad|inconvenient\")].sort_values(by = \"frequency\",ascending= False).head(20)\nnegitive_sentences_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57920f2f014c4415fd5c2cc698666a194c6bb2fa","scrolled":true},"cell_type":"code","source":"### Analyzing top 20 frequent Negitive TRI Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Negitive Tri Grams\")\ntop20_negitive_trigrams = tri_grams_negitive_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop20_negitive_trigrams.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Negitive Tri Grams\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3af45905dc295cabb4f9733e2bd3d0e345dd1267"},"cell_type":"markdown","source":"#### Lets  check for bigrams / trigrams with the postive words and undiscovered patterns"},{"metadata":{"trusted":true,"_uuid":"9f381eeddfeb2e423aa4535d1a076363f7d5dc68"},"cell_type":"code","source":"mask1 = (train_incidents[\"sentiment_types\"] == \"Positive\")\n\npositive_sentiment_data_df = train_incidents[[\"short_description\",\"sentiments\",\"sentiment_types_postive_words\"]][mask1].sort_values(by = \"sentiments\",ascending = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cba7fc5753a8e8a0a0676c81d6e410cd9812f21f"},"cell_type":"code","source":"positive_sentiment_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce55a09f30e0358f4b9b8b39c512fab6f59fcc1d"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(2,2), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(positive_sentiment_data_df[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\nbi_grams_positive_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ced99a107bcbabeed531d4851cea70136c955ae"},"cell_type":"code","source":"#### Bi grams of positive Sentiment Words\nbi_grams_positive_df = bi_grams_positive_df[bi_grams_positive_df.index.str.contains(\"able|latest|good|successful|many|best|sure\")].sort_values(by = \"frequency\",ascending= False).head(20)\nbi_grams_positive_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57920f2f014c4415fd5c2cc698666a194c6bb2fa"},"cell_type":"code","source":"### Analyzing top 20 frequent Negitive BI Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Positive Bi Grams\")\ntop20_positive_bigrams = bi_grams_positive_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop20_positive_bigrams.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Positive Bi Grams\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df86d2c3d2b8d9c262d1a024bc7326e17ba7a614"},"cell_type":"code","source":"####### Negitive Sentiment Trigrams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34cc34d6045e7a997e058aa5d2618f4c77a25afa"},"cell_type":"code","source":"word_vectorizer = CountVectorizer(ngram_range=(3,3), analyzer='word')\nsparse_matrix = word_vectorizer.fit_transform(positive_sentiment_data_df[\"short_description\"])\nfrequencies = sum(sparse_matrix).toarray()[0]\ntri_grams_positive_df = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n\n\n''#### tri grams of Positive Sentiment Words\ntri_grams_positive_df = tri_grams_positive_df[tri_grams_positive_df.index.str.contains(\"able|latest|good|successful|many|best|sure\")].sort_values(by = \"frequency\",ascending= False).head(20)\ntri_grams_positive_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57920f2f014c4415fd5c2cc698666a194c6bb2fa"},"cell_type":"code","source":"### Analyzing top 20 frequent Positive TRI Gram words\n\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Positive Tri Grams\")\ntop20_positive_trigrams = tri_grams_positive_df[\"frequency\"].sort_values(ascending = False).head(20)\n\ntop20_positive_trigrams.head(20).sort_values(ascending = True).plot(kind=\"barh\",title = \"Top 20 Frequent Positive Tri Grams\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0552d125a82bcad735695f734ff851e622b620d3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2dc6bda29fd508d6cebe64f72c8cdf5c31317df"},"cell_type":"code","source":"# Lets analyze the correlation between top 20 bi/tri grams and the sentiment data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6fce478c992b2fa569a457711f7db6ebda76c13"},"cell_type":"code","source":"train_incidents[\"top_20_bi_grams_list\"] = train_incidents[\"top_20_bi_grams_list\"].apply(lambda x: \"\".join(x))\ntop20_bigrams_sentiment_sum = train_incidents[[\"top_20_bi_grams_list\",\"sentiments\"]]\ntop20_bigrams_sentiment_grpby = top20_bigrams_sentiment_sum.groupby(by = \"top_20_bi_grams_list\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"996f05a29897db0ad1023a2faa0740815f2bbfb7"},"cell_type":"code","source":"## Sentiments VS Bi grams\ntop20_bigrams_sentiment_series = (top20_bigrams_sentiment_grpby[\"sentiments\"].sum()).sort_values(na_position= \"last\")\ntop20_bigrams_sentiment_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49676b56eb03861d9c28eb2944e787495d12d791"},"cell_type":"code","source":"top20_bigrams_sentiment_df = pd.DataFrame(top20_bigrams_sentiment_series.values,top20_bigrams_sentiment_series.index)\ntop20_bigrams_sentiment_df = top20_bigrams_sentiment_df[top20_bigrams_sentiment_df.index != \" \"]\ntop20_bigrams_sentiment_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"fd69472b264e543c125293dce12115d016e7f6e4"},"cell_type":"code","source":"\n#plt.title(\"Top 20 Bi Grams VS Sentiment Correlation\")\ntop20_bigrams_sentiment_df.sort_values(by = 0,ascending = True).plot(kind=\"bar\",title = \"Top 20 Bi Grams VS Sentiment Plot\")\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Bi Grams\")\nplt.ylabel(\"Sentiment Polarity\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"741657abb2d43fb452c6bded909403c946bbb5d7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6fce478c992b2fa569a457711f7db6ebda76c13"},"cell_type":"code","source":"train_incidents[\"top_20_tri_grams_list\"] = train_incidents[\"top_20_tri_grams_list\"].apply(lambda x: \"\".join(x))\ntop20_trigrams_sentiment_sum = train_incidents[[\"top_20_tri_grams_list\",\"sentiments\"]]\ntop20_trigrams_sentiment_sum_grpby = top20_trigrams_sentiment_sum.groupby(by = \"top_20_tri_grams_list\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"996f05a29897db0ad1023a2faa0740815f2bbfb7","scrolled":true},"cell_type":"code","source":"## Sentiments VS Tri grams\ntop20_trigrams_sentiment_series = (top20_trigrams_sentiment_sum_grpby[\"sentiments\"].sum()).sort_values(na_position= \"last\")\ntop20_trigrams_sentiment_series\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67a8b67527111bd6c00a8c4fb453d56c9e0ad0eb"},"cell_type":"code","source":"top20_trigrams_sentiment_df = pd.DataFrame(top20_trigrams_sentiment_series.values,top20_trigrams_sentiment_series.index)\ntop20_trigrams_sentiment_df = top20_trigrams_sentiment_df[top20_trigrams_sentiment_df.index != \" \"]\ntop20_trigrams_sentiment_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c11f84c651659ecf9c62c26ed7bbed85de944769"},"cell_type":"code","source":"#plt.title(\"Top 20 Bi Grams VS Sentiment Correlation\")\ntop20_trigrams_sentiment_df.sort_values(by = 0,ascending = True).plot(kind=\"bar\",title = \"Top 20 Tri Grams VS Sentiment Plot\")\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Tri Grams\")\nplt.ylabel(\"Sentiment Polarity\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf26710dd411fdea6a9bd290b96bb7843e5145d5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6d1a8c82df2bf58db5867f9bc47b9b121581697"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79d04a7625e60cdee4245abb69762869f0b09a4c"},"cell_type":"markdown","source":"## Lets check the patterns between sentiments created and other attributes"},{"metadata":{"trusted":true,"_uuid":"f9d636941b209e65ed0788077b15b42d16ce2ae0"},"cell_type":"code","source":"#incidents_category VS sentiments\n\nincidents_category[\"sentiments\"].sum().sort_values()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63afe0b03c69210f1e018c2555c3a9ad7be4fdd4"},"cell_type":"code","source":"## incidents_incident_subcategory vs sentiments\nincidents_incident_subcategory[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ae28ee665fff0a037884fcef1a81c1274b47a61"},"cell_type":"code","source":"##incidents_priority vs sentiments\nincidents_priority[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"376f27cbd088c70472b4d8535e9ecf6d9cac5299"},"cell_type":"code","source":"#incidents_urgency vs sentiments\nincidents_urgency[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e060e821b6ec87f38462fe102603fd0d05a1452e"},"cell_type":"code","source":"#incidents_made_sla vs sentiments\nincidents_made_sla[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70dd9e4a47cc7f29f59d72e71751f9deef62f1c8"},"cell_type":"code","source":"#incidents_type vs sentiments\nincidents_type[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33c109722017f13c1e6c66326b682c7b152c707b"},"cell_type":"code","source":"#incidents_impact vs sentiments\nincidents_impact[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"048897943f5f47098ee6c01f0d2668f08bfe0023"},"cell_type":"code","source":"#incidents_escalation vs sentiments\nincidents_escalation[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86c2058995c053a312fca4d0bbf8b63c45608c31"},"cell_type":"code","source":"#incidents_e2e_resolution_met vs sentiments\nincidents_e2e_resolution_met[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6943b949ef209f3f459b1cc8180a9f52e842d5d"},"cell_type":"code","source":"#incidents_location vs sentiments\nincidents_location[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ae4c9e19218897701fd87b63c4ec3506fe83642"},"cell_type":"code","source":"#incidents_country vs sentiments\ncountry_sentiments_series = incidents_country[\"sentiments\"].sum().sort_values()\ncountry_sentiments_series\n##create a dataframe of country series\ncountry_sentiments_df = pd.DataFrame(country_sentiments_series.values,country_sentiments_series.index)\ncountry_sentiments_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19f69ab297144f9fc98574957d1311b6aaa175d3"},"cell_type":"code","source":"#plt.title(\"Top 20 Bi Grams VS Sentiment Correlation\")\ncountry_sentiments_df.sort_values(by = 0,ascending = True).plot(kind=\"bar\",title = \"Country VS Sentiment Plot\")\nplt.style.use(\"ggplot\")\nplt.xlabel(\"Countries\")\nplt.ylabel(\"Sentiment Polarity\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03634ee4f26b9e8c6436a8c42c9396d77b2e3795"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b212c5d94439aa12180a7061bd7d9873bea7549a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"403e4faa0c7b2011aba3f94fed17fa14e4849f46"},"cell_type":"code","source":"#incidents_contact_type vs sentiments\nincidents_contact_type[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e346b5712a1aa57f764deb1f9ef209aefc7958f8"},"cell_type":"code","source":"#incidents_affected_user vs sentiments\nincidents_affected_user[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e704999903e5bd4f8988378a93dcd30ba2479c4b"},"cell_type":"code","source":"#incidents_assignment_group vs sentiments\nincidents_assignment_group[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d80fdc0a2b62f4038f6a12f33d47b11eea37b6fc"},"cell_type":"code","source":"close_code_grpby = train_incidents.groupby(\"close_code\")\nclose_code_grpby[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2825a21f711290b7cf3a15db625b213e1db8a053"},"cell_type":"code","source":"resolved_by_grpby = train_incidents.groupby(\"resolved_by\")\nresolved_by_grpby[\"sentiments\"].sum().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dc42f95c512de80545096a21a6326585e1e62fc"},"cell_type":"markdown","source":"### Finding Correlations between numeric variables"},{"metadata":{"trusted":true,"_uuid":"4a8fb80b56ed81aaba72adf919661f6edb0931bc"},"cell_type":"code","source":"from scipy.stats import linregress\n\n### Lets check the correlation between infosys_e2e_resolution_duration and sentiments \nlinregress(train_incidents[\"infosys_e2e_resolution_duration\"],train_incidents[\"sentiments\"])\n# Correlation coefficient - 0.07(on positive side but very minimal correlation, hence can rule out the correlation\n# between these 2 variables) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68e284a5dbf3757b0ab33d35fa476555492aa713"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcc8e0b046273e4ad9be8d1e4c80d911851a3992"},"cell_type":"code","source":"\n### Lets check the correlation between infosys_e2e_response_duration and sentiments \nlinregress(train_incidents[\"infosys_e2e_response_duration\"],train_incidents[\"sentiments\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2847e1c29ea47591300f583194b1152861478edc"},"cell_type":"code","source":"\n### Lets check the correlation between e2e_response_duration and sentiments \nlinregress(train_incidents[\"e2e_response_duration\"],train_incidents[\"sentiments\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cd9cce75f336224f53dee818eaeef62e9e66ced","scrolled":true},"cell_type":"code","source":"\n### Lets check the correlation between e2e_resolution_duration and sentiments \nlinregress(train_incidents[\"e2e_resolution_duration\"],train_incidents[\"sentiments\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7099de2a582a02d83838ee9bd3aeeb4db55572f1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e37d1d09e8861e2e12a65bcb1a0c3c18779c41c6"},"cell_type":"markdown","source":"### Correlation matrix"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"de3986287717f7585b699dc1ef6f887d9b1b47f4"},"cell_type":"code","source":"### Extract numeric cols without null data\ntrain_incidents.dtypes == \"int64\" \nint_float_cols = train_incidents.dtypes[(train_incidents.isna().sum() != 2301) & ((train_incidents.dtypes == \"int64\") | (train_incidents.dtypes == \"float64\"))].index\ntrain_incidents[int_float_cols].head(5)\n\n## Selecting only required numeric cols for correlation plot\n\nnumeric_cols_selected = train_incidents[[\"reopen_count\",\"reassignment_count\",\"infosys_e2e_response_duration\",\"infosys_e2e_resolution_duration\",\"followup_counter\",\"e2e_response_duration\",\"e2e_resolution_duration\",\"calendar_duration\",\"business_duration\",\"sentiments\"]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"2f740e7df7d3c32898a1209495e90ee9e0ecf6d9"},"cell_type":"code","source":"pd.plotting.scatter_matrix(numeric_cols_selected,alpha = 0.8,figsize=(25, 25))\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caa21a4b251c3c875ecb6b393fc47b2905fca820"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52f64e713a60c3c78bdf1689e2c7980166c6580f"},"cell_type":"markdown","source":"\n\n### Check the overall turnaround times and check the sentiment correlation with the turnaround times"},{"metadata":{"trusted":true,"_uuid":"d3461668495400f953511617835f7ad04e37ef6a"},"cell_type":"code","source":"train_incidents[\"issue_turnaround_time_hours\"] = (train_incidents[\"resolved_at\"] - train_incidents[\"opened_at\"]).astype('timedelta64[h]')\n## Impute missing values with mean \ntrain_incidents[\"issue_turnaround_time_hours\"][train_incidents[\"issue_turnaround_time_hours\"].isna() == True] = train_incidents[\"issue_turnaround_time_hours\"].mean(skipna= True)\n\ntrain_incidents[\"issue_turnaround_time_days\"] = (train_incidents[\"resolved_at\"].dt.date - train_incidents[\"opened_at\"].dt.date)\ntrain_incidents[\"issue_turnaround_time_days\"] = pd.to_numeric(train_incidents[\"issue_turnaround_time_days\"].dt.days)\n## Impute missing values with mean \ntrain_incidents[\"issue_turnaround_time_days\"][train_incidents[\"issue_turnaround_time_days\"].isna() == True] = train_incidents[\"issue_turnaround_time_days\"].mean(skipna= True)\n\ntrain_incidents[\"issue_turnaround_time_days\"].head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c9bec1f376bb79fe1b26760c88d8a19792e4506"},"cell_type":"markdown","source":"## Check the correlation plot between turnaround times and sentiments"},{"metadata":{"trusted":true,"_uuid":"9465b558f10a715ce200cf9ccc5ca1ca6d4c0467"},"cell_type":"code","source":"### Lets check the correlation between turenaround time and sentiments \nlinregress(train_incidents[\"issue_turnaround_time_days\"],train_incidents[\"sentiments\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de715433a4ca14c46e6a010036a1e7058965d6ff"},"cell_type":"code","source":"##  Incidents with high turnaround times have more negative sentiment polarity score. \n##  As we you can see in above plot, majority of turnaround times have sentiment polarity scores < -0.10.\n\ntrain_incidents.plot.scatter(\"issue_turnaround_time_days\",\"sentiments\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b66b48f9a27f0a8cd005433b22d77950c083bbe"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0201e61bf606c7e7262c28b1c95f24d7ac248ebb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a02757b9bf3a0fd15843372d9f054cd06e5c3f3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48c3c505b6215daea088f90d10e03c1e198dadba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39080d574329fe7ca57fb93e1e5d76b27cc0dc16"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f3e8d0b4947cea71bad91615f34fe9b586d610"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cab5a147d7b20dafd2ac560889e5a5d9b5194d2c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}