{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ntrain_path, test_path = \"../input/titanic/train.csv\", \"../input/titanic/test.csv\"\ntrain_df = pd.read_csv(train_path)\ntest_df  = pd.read_csv(test_path)\ntrain_df.info()\n\n# merge train test dataset and assign y\nmain_df = pd.concat([train_df,test_df])\ny = train_df.Survived","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(main_df.groupby(\"Pclass\".split()).agg([\"count\",\"sum\",\"mean\"])[\"Age\"])\ntemp_mean = main_df.groupby(\"Pclass\".split()).agg([\"count\",\"sum\",\"mean\"])[\"Age\"][\"mean\"].tolist()\n\ndef fill_age(cols, mean_list):\n    pclass, age = cols[0], cols[1]\n    if pd.isnull(age):\n        for i in range(1,4):\n            if pclass == i:\n                age = mean_list[i-1]\n    else:\n        age = cols[1]\n    return age\n\nmain_df.Age = main_df[\"Pclass Age\".split()].apply(fill_age, axis=1, args=(temp_mean,))\ntrain_df.Age = train_df[\"Pclass Age\".split()].apply(fill_age, axis=1, args=(temp_mean,))\ntest_df.Age = test_df[\"Pclass Age\".split()].apply(fill_age, axis=1, args=(temp_mean,))\n\ndef trans_age(age):\n    temp=None\n    if age <= 2:\n        temp = 1\n    elif 2 < age <= 12:\n        temp = 2\n    elif 12 < age <= 18:\n        temp = 3\n    elif 18 < age <= 40:\n        temp = 4\n    elif 40 < age <= 60:\n        temp = 5\n    else:\n        temp = 6\n    return temp\n\nmain_df[\"agegroup\"] = main_df.Age.apply(trans_age)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df[\"last_name\"] = main_df.Name.apply(lambda x: x.split(\",\")[0])\nmain_df[\"title_name\"] = main_df.Name.apply(lambda x: x.split(\",\")[1].split(\".\")[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fillna Fare by get mean of groupby(pclass, agegroup)\n# print(main_df.groupby(\"Pclass agegroup\".split()).agg(\"count sum mean\".split())[\"Fare\"])\n# print(main_df[main_df.Fare.isnull()])\ntemp = main_df.groupby(\"Pclass agegroup\".split()).agg(\"mean\",)[\"Fare\"]\ntemp = {temp.index[i]: t for i, t in enumerate(temp)}\ndef fill_fare(cols, temp):\n    if pd.isnull(cols[2]):\n        for k,v in temp.items():\n            if (cols[0], cols[1]) == k:\n                return temp[k]\n    else:\n        return cols[2]\nmain_df.Fare = main_df[\"Pclass agegroup Fare\".split()].apply(fill_fare, axis=1, args=(temp,))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df.last_name.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df[\"family_size\"] = main_df.SibSp + main_df.Parch + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cabin_list = sorted(list(set(\" \".join(main_df.Cabin[main_df.Cabin.isnull()==False].tolist()).split())))\n# cabin_list\n# for col in cabin_list:\n#     main_df[col] = 0\n# indexes = main_df[main_df.Cabin.isnull()==False].index\n# for i in indexes:\n#     value = main_df.iloc[i].Cabin\n#     if pd.isnull(value):\n#         pass\n#     elif type(value)==str:\n#         value=value.split()\n#         if len(value)>1:\n#             for s in value:\n#                 main_df.loc[i,s] = 1\n#         else:\n#             main_df.loc[i,value] =1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df = pd.concat([main_df.drop([\"Sex\"],axis=1),pd.get_dummies(main_df.Sex, drop_first=True)],axis=1)\nmain_df = pd.concat([main_df.drop([\"Embarked\"],axis=1),pd.get_dummies(main_df.Embarked)],axis=1)\nmain_df = main_df.drop([\"Name\",\"Cabin\"],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\"cnull\":main_df.isnull().sum()})\ndf[df.cnull>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in \"title_name last_name Ticket\".split():\n    main_df[i] = main_df[i].astype(\"category\").cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df.columns[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\"cnull\":main_df.isnull().sum()})\ndf[df.cnull>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nX = main_df[:len(train_df)].drop([\"Survived\"],axis=1)\ny = main_df[:len(train_df)].Survived\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(X_train,y_train)\nprint(classification_report(model.predict(X_test).round(),y_test))\nprint(pd.DataFrame({\"ori\":model.predict(X_test), \"round\":model.predict(X_test).round(), \"y\":y_test}))\npred = confusion_matrix(model.predict(X_test).round().astype(\"int\"),y_test)\nprint(\"Accuracy\",sum(pred)[0]/(sum(pred)[0]+sum(pred)[1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df = main_df.drop([\"Survived\"],axis=1)\nmodel = RandomForestRegressor(n_estimators=100, random_state=1)\nmodel.fit(X,y)\nsubmit = pd.DataFrame({\"PassengerId\":main_df[len(train_df):].PassengerId, \"Survived\":model.predict(main_df[len(train_df):]).round()})\nsubmit.Survived = submit.Survived.astype(\"int\")\nsubmit.to_csv(\"submissionJavier_Vallejos.csv\",index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat([main_df[:len(train_df)].Fare, train_df.Fare],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}