{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.gminsights.com/assets/img/all-terrain-vehicle-atv-market-pressrelease.png)gminsights.com"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\nimport os\nimport cv2\nimport sys\nfrom pylab import rcParams\nfrom PIL import Image\nfrom tqdm import tqdm\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes by Junyi Ng https://www.kaggle.com/junyingsg/step-by-step-guide-to-denoising-your-labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seed everything for reproducible results\nimport random\nfrom numpy.random import seed\nfrom tensorflow.random import set_seed\n\nseed_value = 42\nrandom.seed(seed_value)\nseed(seed_value)\nset_seed(seed_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy) #shortens training time by 2x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gps = pd.read_csv(\"../input/offroad-terrain-dataset-for-autonomous-vehicles/SensorData/2020-10-02-10-17-05/gps.csv\")\ngps.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/offroad-terrain-dataset-for-autonomous-vehicles/ImageLabels/tsm_1_labels.csv\")\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_train = pd.read_csv(\"../input/offroad-terrain-dataset-for-autonomous-vehicles/ImageLabels/tsm_2_labels.csv\")\ndf2_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#df_train[\"tsm1_original\"] = df_train[\"tsm1_original\"].astype(str) #convert to str as we want to use cross entropy loss later\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Image Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\nimage_size=300\n\ninput_shape = (image_size, image_size, 3)\ntarget_size = (image_size, image_size)\nimg_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomCrop(image_size, image_size),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n        tf.keras.layers.experimental.preprocessing.RandomContrast(0.2)\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/offroad-terrain-dataset-for-autonomous-vehicles/Images/Images/2020-09-24/\"\nfiles = df_train[\"image\"].tolist()\nfile = random.choice(files)\nimage = Image.open(\"../input/offroad-terrain-dataset-for-autonomous-vehicles/Images/Images/2020-09-24/969904752s168ms.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Augmentation helps the model generalize better. What images can look like after augmentation."},{"metadata":{"trusted":true},"cell_type":"code","source":"image = tf.expand_dims(np.array(image), 0)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    augmented_image = img_augmentation(image)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_image[0])\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train[\"tsm1_original\"] = df_train[\"tsm1_original\"].astype(str) #convert to str as we want to use cross entropy loss later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DataGenerator(train_set, val_set):\n    \n    train_datagen = ImageDataGenerator().flow_from_dataframe(\n                  dataframe = train_set,\n                  directory='../input/offroad-terrain-dataset-for-autonomous-vehicles/Images/Images/',\n                  x_col='image',\n                  y_col='tsm1_original',\n                  target_size=target_size,\n                  batch_size=batch_size,\n                  shuffle=True,\n                  class_mode='sparse',\n                  seed=seed_value)\n\n    val_datagen = ImageDataGenerator().flow_from_dataframe(\n                dataframe = val_set,\n                directory='../input/offroad-terrain-dataset-for-autonomous-vehicles/Images/Images/',\n                x_col='image',\n                y_col='tsm1_original',\n                target_size=target_size,\n                batch_size=batch_size,\n                shuffle=False,\n                class_mode='sparse',\n                seed=seed_value)\n    \n    return train_datagen, val_datagen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 3\ntotal_steps = (int(len(df_train)*0.8/batch_size)+1)*epochs\n\nlr = tf.keras.experimental.CosineDecay(initial_learning_rate=1e-3, decay_steps=total_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n\n    # Rebuild top\n    inputs = Input(shape=input_shape)\n    base = base_model(inputs)\n    pooling = GlobalAveragePooling2D()(base)\n    outputs = Dense(5, activation=\"softmax\", dtype='float32')(pooling) #necessary for mixed-precision training to work properly\n\n    # Compile\n    model = Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"fold_number = 1\nn_splits = 5\noof_accuracy = []\n\ntf.keras.backend.clear_session()\nskf = StratifiedKFold(n_splits=n_splits, random_state=None)\nfor train_index, val_index in skf.split(df_train[\"image\"], df_train[\"tsm1_original\"]):\n    train_set = df_train.loc[train_index]\n    val_set = df_train.loc[val_index]\n    train_datagen, val_datagen = DataGenerator(train_set, val_set)\n    model = build_model()\n    print(\"Training fold no.: \" + str(fold_number+1))\n\n    model_name = \"effnetb0 \"\n    fold_name = \"fold.h5\"\n    filepath = model_name + str(fold_number+1) + fold_name\n    callbacks = [ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True)]\n\n    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n    oof_accuracy.append(max(history.history[\"val_accuracy\"]))\n    fold_number += 1\n    if fold_number == n_splits:\n        print(\"Training finished!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#ValueError: Asked to retrieve element 0, but the Sequence has length 0"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar√≠lia Prata, @mpwolke Was here' )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}