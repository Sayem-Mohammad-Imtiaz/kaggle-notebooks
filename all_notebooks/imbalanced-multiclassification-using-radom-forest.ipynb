{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nnp.random.seed(0)\nimport sklearn.model_selection\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/residential-power-usage-3years-data-timeseries/power_usage_2016_to_2020.csv')\ndf1 = pd.read_csv('/kaggle/input/residential-power-usage-3years-data-timeseries/weather_2016_2020_daily.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['StartDate'] = pd.to_datetime(df['StartDate'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year'] = df['StartDate'].dt.year\ndf['month'] = df['StartDate'].dt.month\ndf['week'] = df['StartDate'].dt.week\ndf['day'] = df['StartDate'].dt.day\ndf['hour'] = df['StartDate'].dt.hour\n#df['minute'] = df['StartDate'].dt.minute\n#df['seconds']= df['StartDate'].dt.second","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('StartDate',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('notes',axis=1)\ny=df['notes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(),y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding of Target Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('notes',axis=1)\ny=df['notes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ny_true = pd.Series(le.fit_transform(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['notes'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize distribution\ncounter = Counter(y_true)\nfor k,v in counter.items():\n    per = v / len(y_true) * 100\n    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n# plot the distribution\nplt.bar(counter.keys(), counter.values())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the above plot it is clear that the data is imbalanced."},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classification"},{"metadata":{},"cell_type":"markdown","source":"Random Forest is an ensemble of decision trees. The single decision tree is very sensitive to data variations. It can easily overfit to noise in the data. The Random Forest with only one tree will overfit to data as well because it is the same as a single decision tree. When we add trees to the Random Forest then the tendency to overfitting should decrease (thanks to bagging and random feature selection). However, the generalization error will not go to zero. The variance of generalization error will approach to zero with more trees added but the bias will not! It is a useful feature, which tells us that the more trees in the RF the better"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.4, random_state=1,stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two important things I want to point out in the code above. First is that I set a random_state; this ensures that if I have to rerun my code, I’ll get the exact same train-test split, so my results won’t change\nThe second thing I want to point out is stratify=y. This tells train_test_split to make sure that the training and test datasets contain examples of each class in the same proportions as in the original dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Encoding the labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ny_train = pd.Series(le.fit_transform(y_train))\ny_test = pd.Series(le.fit_transform(y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Evaluate Model with cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate a model\ndef evaluate_model(X, y, model):\n\t# define evaluation procedure\n\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n\t# evaluate model\n\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n\treturn scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the reference model\nmodel = RandomForestClassifier()\n# evaluate the model\nscores = evaluate_model(X_train, y_train, model)\n# summarize performance\nprint('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions for the test set\nmodel.fit(X_train, y_train)\ny_pred_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View accuracy score\naccuracy_score(y_test, y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy from cross validation and general accuracy arethe same.This model has an accuracy score of 99.95% on the test data. That seems pretty impressive, but remember that accuracy is not a great measure of classifier performance when the classes are imbalanced"},{"metadata":{},"cell_type":"markdown","source":"### Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View confusion matrix for test data and predictions\nconfusion_matrix(y_test, y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This confusion matrix would be a lot easier to read if it had some labels and even a color scale to help us spot the biggest and smallest values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get and reshape confusion matrix data\nmatrix = confusion_matrix(y_test, y_pred_test)\nmatrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n\n# Build the plot\nplt.figure(figsize=(16,7))\nsns.set(font_scale=1.4)\nsns.heatmap(matrix, annot=True, annot_kws={'size':10},\n            cmap=plt.cm.Greens, linewidths=0.2)\n\n# Add labels to the plot\nclass_names = ['weekday', 'weekend', 'COVID_lockdown', \n               'vacation']\ntick_marks = np.arange(len(class_names))\ntick_marks2 = tick_marks + 0.5\nplt.xticks(tick_marks, class_names, rotation=25)\nplt.yticks(tick_marks2, class_names, rotation=0)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix for Random Forest Model')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it’s easy to see that our classifier struggled at predicting the weekend label"},{"metadata":{},"cell_type":"markdown","source":"### Classification report"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the classification report for test data and predictions\nprint(classification_report(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Balancing Data for Classification"},{"metadata":{},"cell_type":"markdown","source":"The purpose is to avoid SMOTE.\nSMOTE is not very good for high dimensionality data\nOverlapping of classes may happen and can introduce more noise to the data.\nSo, to skip this problem, we can assign weights for the class manually with the ‘class_weight’ parameter.\nBelow processes do the same"},{"metadata":{},"cell_type":"markdown","source":"### Sklearn Utils"},{"metadata":{},"cell_type":"markdown","source":"We can get class weights using sklearn to compute the class weight. By adding those weight to the minority classes while training the model, can help the performance while classifying the classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weight = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_list = [0,1,2,3]\nzip_iterator = zip(class_list, class_weight)\na_dictionary = dict(zip_iterator)\nprint(a_dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the reference model\nmodel = RandomForestClassifier(class_weight = a_dictionary)\n# evaluate the model\nscores = evaluate_model(X_train, y_train, model)\n# summarize performance\nprint('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions for the test set\nmodel.fit(X_train, y_train)\ny_pred_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View accuracy score\naccuracy_score(y_test, y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Counts to Length Ratio:"},{"metadata":{},"cell_type":"markdown","source":"Dividing the no. of counts of each class with the no. of rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = y_true.value_counts()/len(y_true)\nclass_list = [0,1,2,3]\nzip_iterator = zip(class_list, weights)\na_dictionary = dict(zip_iterator)\nprint(a_dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the reference model\nmodel = RandomForestClassifier(class_weight = a_dictionary)\n# evaluate the model\nscores = evaluate_model(X_train, y_train, model)\n# summarize performance\nprint('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions for the test set\nmodel.fit(X_train, y_train)\ny_pred_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View accuracy score\naccuracy_score(y_test, y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Smoothen Weights Technique"},{"metadata":{},"cell_type":"markdown","source":"This is one of the preferable methods of choosing weights.\nlabels_dict is the dictionary object contains counts of each class.\nThe log function smooths the weights for the imbalanced class."},{"metadata":{"trusted":true},"cell_type":"code","source":"mu=0.15\n# random labels_dict\nlabels_dict = y_true.value_counts().to_dict()\ntotal = sum(labels_dict.values())\nkeys = labels_dict.keys()\nweight = dict()\nweight\n\nfor i in keys:\n    score = np.log(mu*total/float(labels_dict[i]))\n    weight[i] = score if score > 1 else 1\n    \nweight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the reference model\nmodel = RandomForestClassifier(class_weight = weight)\n# evaluate the model\nscores = evaluate_model(X_train, y_train, model)\n# summarize performance\nprint('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions for the test set\nmodel.fit(X_train, y_train)\ny_pred_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View accuracy score\naccuracy_score(y_test, y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}