{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Problem Statement:\nThe Insurance company that provides health insurance to its customers are now planning to provide vehicle insurance. The company wants to know how many of its customers would be interested in vehicle insurance. \n\n##### EDA:\nPerform EDA to extract valuable insights from the data. \n\n##### Feature Engineering: \nPerform feature engineering to check which columns play a very important role in model building and try to come up with new features which makes a difference in building the model. \n\n##### Modelling:\nBuild a model to come up with a probability score which tells the chances of a person opting for vehicle insurance\n    \n##### Note:\n<b><p> I am still working on the model. Feel free to drop by later for more updates. </p></b>\nConsider upvoting if you like my work and if you have any suggestions please drop it in comments. I will take a look at it and work on it. \n     \nThank you!!!","metadata":{}},{"cell_type":"code","source":"## Importing libraries\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the dataset\ntrain_df = pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv')\ntest_df = pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"## Checking the number of features and instances\ntrain_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Check for missing values\ntrain_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can infer from above that there are no missing values. ","metadata":{}},{"cell_type":"code","source":"## Looking at columns\ntrain_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df[\"Region_Code\"].unique())\nprint(train_df[\"Policy_Sales_Channel\"].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Segregating columns\nnumerical_columns = [\"Age\",\"Region_Code\", \"Annual_Premium\", \"Policy_Sales_Channel\", \"Vintage\"]\ncategorical_columns = [\"Gender\",\"Driving_License\", 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[numerical_columns].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Checking if the data is skewed. ","metadata":{}},{"cell_type":"code","source":"### Checking if the data is skewed. \nsns.countplot(x = train_df[\"Response\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot we can see that the data is skewed. Going forward, we need to implement techniques like random sampling or SMOT analysis to fix this issue. ","metadata":{}},{"cell_type":"markdown","source":"##### Gender participation","metadata":{}},{"cell_type":"code","source":"### Gender participation\nsns.countplot(x = train_df[\"Gender\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Gender distribution based on response","metadata":{}},{"cell_type":"code","source":"### Gender distribution based on response\nfig, axis = plt.subplots(1, 2, figsize = (14, 5))\n\nsns.countplot(ax = axis[0], x = train_df[train_df[\"Response\"] == 1][\"Gender\"])\naxis[0].set_title(\"When they subscribe to vehicle insurence\")\n\nsns.countplot(ax = axis[1], x = train_df[train_df[\"Response\"] == 0][\"Gender\"])\naxis[1].set_title(\"When they do-not subscribe to vehicle insurence\")\n\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above we can see that Male tend to subscribe to vehicle insurence more than female. Therefore we can assume that gender plays an important role in model building. ","metadata":{}},{"cell_type":"markdown","source":"##### Analysing Driving liscense","metadata":{}},{"cell_type":"code","source":"### Analysing Driving liscense\ntemp = train_df.groupby([\"Gender\"]).count()[\"Driving_License\"].to_frame().reset_index()\nprint(temp)\nsns.barplot(x = temp[\"Gender\"], y = temp[\"Driving_License\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Customer previously insured","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = train_df[\"Previously_Insured\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data with respect to customer previously insured is almost equally distributed. ","metadata":{}},{"cell_type":"markdown","source":"##### Analysis Vehicle age","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = train_df[\"Vehicle_Age\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This doesnt tell much about data so I need to check how many opted for insurence with respect to above 3 groups","metadata":{}},{"cell_type":"code","source":"temp = train_df.groupby([\"Vehicle_Age\",\"Response\"]).count()[\"id\"].to_frame().reset_index()\ntemp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above output doesnt help much as the dataset is highly skewed and number of people without insurence is much higher than the ones with insurence. To make actual sense of the response vs vehicle age, sampling the dataset is required","metadata":{}},{"cell_type":"markdown","source":"##### Plotting the count for each group when people have opted for insurence","metadata":{}},{"cell_type":"code","source":"sns.catplot(x = \"Vehicle_Age\", y=\"id\", col=\"Response\", data=temp[temp[\"Response\"] == 1], kind=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph we can observe that people tend to take insurence when the age of the vehicle is between 1-2 years. This might be a important factor when building the model. \n\nBut before coming to this conclusion, we need to check the data to see how many records fall under the above 3 groups. If the data for vehicles age between 1-2 years is more than the others then we cant come to the above conclusion. ","metadata":{}},{"cell_type":"markdown","source":"##### Analysing Vehicle Age","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = train_df[\"Vehicle_Age\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Counting number of damaged vehicle","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = train_df[\"Vehicle_Damage\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above barplot we can see that equal number of records have damaged and non-damaged vehicles. ","metadata":{}},{"cell_type":"markdown","source":"##### Analysing the response of the customers when they have damaged vehicles","metadata":{}},{"cell_type":"code","source":"temp = train_df.groupby([\"Vehicle_Damage\",\"Response\"]).count()['id'].to_frame().reset_index()\ntemp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x=\"Vehicle_Damage\", y=\"id\", col = \"Response\", data = temp[temp[\"Response\"] == 1], kind = \"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above we can see that most people who opted for the insurence have damaged there vehicle previously.","metadata":{}},{"cell_type":"markdown","source":"##### Analysisng Annual Premium ","metadata":{}},{"cell_type":"code","source":"sns.histplot(x = train_df[\"Annual_Premium\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"##### Correlation plot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,10))\nplt.title(\"Correlation Plot\")\nsns.heatmap(train_df.corr(), linewidth = 5, annot = True, square = True, annot_kws={'size': 10}, cmap=\"YlGnBu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot we can see correlation among each features. If two features are highly correlated, we can eleminate one of them because they tend to overfit the data and we also need to make sure to consider all the features that highly correlate with the output so that they help in better prediction. ","metadata":{}},{"cell_type":"markdown","source":"##### Converting the data into 0-1 encodings","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Reading Continuous and Categorical data\ncont = [\"Age\", \"Vintage\", \"Annual_Premium\"]\ncat = [\"Gender\", \"Driving_License\", \"Region_Code\", \"Previously_Insured\", \"Vehicle_Age\", \"Vehicle_Damage\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.get_dummies(train_df,drop_first = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you observe above, get_dummies only apply for categorical features where number of category is more than 2. If number of categories are two then they will be converted to 0 and 1 and also note that column names will be renamed. ","metadata":{}},{"cell_type":"code","source":"train.columns\ntrain.columns = ['id', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured',\n       'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response',\n       'Gender_Male', 'Vehicle_Age__1_Year', 'Vehicle_Age_2_Years',\n       'Vehicle_Damage_Yes']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modelling","metadata":{}},{"cell_type":"markdown","source":"##### Random Sampling the data","metadata":{}},{"cell_type":"code","source":"# Getting the records which have the value as 1 for response\ntrain_1 = train[train[\"Response\"] == 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_1))\n\n# Getting the records which have value as 0 fro response\ntrain_0 = train[train[\"Response\"] == 0]\n\nprint(len(train_0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Getting random samples of train_0 for modelling\ntrain_00 = train_0.sample(n = len(train_1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_00)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Appending the two dataframes to have equal number of records when response = 1 and 0\ntrain_sampled = train_1.append(train_00)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_sampled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Scalling the data","metadata":{}},{"cell_type":"code","source":"train_sampled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sampled = train_sampled.drop([\"id\"], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sampled.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sampled.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Spitting the dataset into features and target variable\nX = train_sampled[['Age', 'Driving_License', 'Region_Code', 'Previously_Insured',\n       'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Gender_Male', 'Vehicle_Age__1_Year', 'Vehicle_Age_2_Years',\n       'Vehicle_Damage_Yes']]\ny = train_sampled[[\"Response\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Printing the first 3 rows of X\nX.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## printing the first 3 rows of y\ny.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Declaring the standard scaler and transforming the dataset \nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Displaying the first 3 rows \nX_scaled[:3]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Train_Test_Split","metadata":{}},{"cell_type":"code","source":" X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Building an ANN Model using PyTorch","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}