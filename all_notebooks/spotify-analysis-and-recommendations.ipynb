{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spotify Dataset 1922 - 2021","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we first analyse the data and do some basic visualisations before we perform a time series analysis of the artists popularity over the years.\nFollowing that, we start working on the recommendation model where we used content based filtering.","metadata":{}},{"cell_type":"markdown","source":"> Before we start, I would like to ackloedge that I am learning myself and I took inspiration from sources at Stack Overflow, Kaggle and articles on Towards Data Science. Moreover, I referred to code from other contributors on this kaggle dataset like Darkstar Dream and Florian Heiny. ","metadata":{}},{"cell_type":"markdown","source":"The imports I am using for the data analysis and visualisations:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nfrom datetime import date\nfrom datetime import datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nartist_df = pd.read_csv('/kaggle/input/spotify-dataset-19212020-160k-tracks/artists.csv')\ntracks_df = pd.read_csv('/kaggle/input/spotify-dataset-19212020-160k-tracks//tracks.csv')\nwith open(\"/kaggle/input/spotify-dataset-19212020-160k-tracks//dict_artists.json\", encoding='utf-8', errors='ignore') as json_data:\n     data = json.load(json_data, strict=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tracks_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's convert all the dates to datetime objects for easier comprehension in the future.","metadata":{}},{"cell_type":"code","source":"df = tracks_df.copy()\n\ndf['release_date'] = pd.to_datetime(df['release_date'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation matrix of all the variables in the dataset tracks_df","metadata":{}},{"cell_type":"code","source":"corr = df.corr()\nplt.figure(figsize=(20,8))\nsns.heatmap(corr, vmax=1, vmin=-1, center=0,linewidth=.5,square=True, annot = True, annot_kws = {'size':8},fmt='.1f', cmap='BrBG_r')\nplt.title('Correlation')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation matrix of the important variables in the dataset tracks_df","metadata":{}},{"cell_type":"code","source":"corr = df[[\"acousticness\",\"danceability\",\"energy\", \"instrumentalness\", \n           \"liveness\",\"tempo\", \"valence\", \"loudness\", \"speechiness\"]]\n\nplt.figure(figsize=(10,10))\nsns.heatmap(corr.corr(), annot=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we create a new column for year for ease in visualisations.","metadata":{}},{"cell_type":"code","source":"df['year'] = df.apply(lambda row: row.release_date.year, axis = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Time Series Analysis of the artists","metadata":{}},{"cell_type":"code","source":"year_avg = df[[\"acousticness\",\"danceability\",\"energy\", \"instrumentalness\", \n               \"liveness\",\"tempo\", \"valence\", \"loudness\", \"speechiness\", \"year\"]].\\\ngroupby(\"year\").mean().sort_values(by=\"year\").reset_index()\n\n# year_avg.head()\nplt.figure(figsize=(14,8))\nplt.title(\"Song Trends Over Time\", fontdict={\"fontsize\": 15})\n\nlines = [\"acousticness\",\"danceability\",\"energy\", \n         \"instrumentalness\", \"liveness\", \"valence\", \"speechiness\"]\n\nfor line in lines:\n    ax = sns.lineplot(x='year', y=line, data=year_avg)\n    \n    \nplt.ylabel(\"value\")\nplt.legend(lines)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recommendation Model","metadata":{}},{"cell_type":"markdown","source":"We now use content based filtering to build the recommendation model. We will use the package from sklearn.\nAlso, we remove the id column since we don't need that for the recommendation","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\nartist_df.drop(['id'], axis=1, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, we remove all the rows with empty genres since they will not help with the recommendation.\nSecondly, we remove data from the dataset due to less computational power. If you do not want to do this, you only need to use the first line of code from the segment","metadata":{}},{"cell_type":"code","source":"artist_df = artist_df[artist_df['genres'] != '[]']\n# Remove data due to less computational power\nartist_df = artist_df.sort_values(by=['popularity'], ascending=False)\nl = len(artist_df)/15\nartist_df = artist_df[:round(l)]\nartist_df = artist_df.reset_index(drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"artist_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\ntfidf_matrix = model.fit_transform(artist_df['genres'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = pd.Series(artist_df.index, index=artist_df['name'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = {}\nfor idx, row in artist_df.iterrows():\n    similar_indices = cosine_similarities[idx].argsort()[:-100:-1] \n    similar_items = [(cosine_similarities[idx][i], artist_df['name'][i]) for i in similar_indices] \n    results[row['name']] = similar_items[1:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _recommend(item_id, num):\n    recs = results[item_id][:num]   \n    preds = {}\n    for pair in recs:\n        preds[pair[1]] = pair[0]\n    return preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_recommend('Drake', 5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _recommend_multiple(artists, num=10):\n    dict_similar = {}\n    for artist, weight in artists.items():\n        dict_similar[artist] = _recommend(artist, num)\n    artists_all = []\n    for artist, similar_artists in dict_similar.items():\n        artists_all.append(list(similar_artists.keys()))\n    artists_unique = np.unique(artists_all).tolist()\n    artists_dict = {artist: 0 for artist in artists_unique}\n    for artist, similar_artists in dict_similar.items():\n        for similar_artist, score in similar_artists.items():\n            artists_dict[similar_artist] += artists[artist] * score\n    return list({k: v for k, v in sorted(artists_dict.items(), key=lambda item: item[1], reverse=True) if k not in artists}.keys())[0:num]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_recommend_multiple({\"Drake\": 10, \"Queen\": 8}, 5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}