{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Linear Regression Model"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we will explain with examples, one of the basics algorithms in Machine Learning. (Linear regression)"},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function definitions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def computeCost(X,y,thetas):\n    m = X.shape[0]\n    h = X.dot(thetas)\n    J = (h-y).T.dot((h-y))/(2*m)\n    return(J)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def computeGradientDescendWithCost(X, y, alpha, iterations):\n    m = X.shape[0]\n    n = X.shape[1]\n    thetas = np.zeros(X.shape[1])\n    vCosts = np.zeros(iterations)\n    vThetas = np.zeros((iterations, n))\n    for it in range(iterations):\n        h = X.dot(thetas)\n        thetas -= (alpha/m)*X.T.dot(h-y)\n        vCosts[it] = computeCost(X,y,thetas)\n        vThetas[it] = thetas\n    return(vCosts, vThetas, thetas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read first dataset using pandas"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../../kaggle/input/housingprices/ex1data1.txt\", header=None, names=['population','profit'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot graph using plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = {\n    'data': [{\n        'type': 'scatter',\n        'x': df['population'],\n        'y': df['profit'],\n        'mode': 'markers'\n    }],\n    'layout':{\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'Population'},\n        'yaxis': {'title': 'Profit'},\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define X's (input variables), y's (target variable), learning rate and number of iterations"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array([np.ones(df.shape[0]), df['population']]).T\ny = np.array(df['profit'])\nalpha = 0.01\niterations = 2000\nprint(\"Number of rows: {}\". format(X.shape[0]))\nprint(\"Number of theta parameters: {}\". format(X.shape[1]))\nprint(\"Learning rate used: {}\".format(alpha))\nprint(\"Number of iterations: {}\".format(iterations))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Execute gradient descend to get theta parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"vCosts, vThetas, thetas = computeGradientDescendWithCost(X, y, alpha, iterations)\nprint(\"Cost at first iteration = {}\".format(vCosts[0]))\nprint(\"Theta parameters at first iteration = {}\".format(vThetas[0]))\nprint(\"Cost at last iteration = {}\".format(vCosts[iterations-1]))\nprint(\"Theta parameters at last iteration = {}\".format(vThetas[iterations-1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction of one point"},{"metadata":{"trusted":true},"cell_type":"code","source":"point = np.array([1, 16])\nprediction = thetas.dot(point)\nprediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot hypothesis function (line)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = {\n    'data': \n    [{\n        'type': 'scatter',\n        'x': X[:,1],\n        'y': y,\n        'name': 'training set',\n        'mode': 'markers'\n    },\n    {\n        'type': 'scatter',\n        'x': X[:,1],\n        'y': X.dot(thetas),\n        'name': 'hypothesis',\n        'mode': 'lines'   \n    },\n    {\n        'type': 'scatter',\n        'x': [point[1]],\n        'y': [prediction],\n        'name': 'prediction',\n        'mode': 'markers'   \n    }\n    ],\n    'layout':\n    {\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'Population'},\n        'yaxis': {'title': 'Profit'},\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot cost vs number of iterations"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = {\n    'data': \n    [{\n        'type': 'scatter',\n        'x': np.arange(iterations),\n        'y': vCosts,\n        'name': 'training set',\n        'mode': 'lines'\n    }],\n    'layout':\n    {\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'Iterations'},\n        'yaxis': {'title': 'Cost'}\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot cost vs theta parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"delta = 0.1\nth0 = np.arange(-10.0, 10.0, delta)\nth1 = np.arange(-1.0, 4.0, delta)\ntheta0, theta1 = np.meshgrid(th0, th1)\ncostes = np.zeros(theta0.shape)\n\nfor i in range(theta0.shape[0]):\n    for j in range(theta0.shape[1]):\n        costes[i,j]=computeCost(X,y,[theta0[i,j],theta1[i][j]])\n\nfig = {\n    'data': \n    [{\n        'type': 'contour',\n        'z': costes,\n        'x': th0,\n        'y': th1,\n        'contours':{'start':0, 'end':700, 'size':25, 'showlabels': True, 'labelfont':{'size':12, 'color':'white'}}\n    }],\n    'layout':\n    {\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'theta0'},\n        'yaxis': {'title': 'theta1'}\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read second dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../../kaggle/input/housingprices/ex1data2.txt', header=None, names=['size', 'bedrooms', 'price'])\ntarget = 'price'\nvariables = [var for var in data.columns if var != target]\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"vMu = np.array([np.mean(data[var]) for var in variables])\nvSigma = np.array([np.std(data[var]) for var in variables])\n\ndf = pd.DataFrame()\ni=0\nfor col in variables:\n    df[col] = (data[col]-vMu[i])/vSigma[i]\n    i += 1\ndf[target] = data[target]/1000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definitions and execution of gradient descend (1 variable)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array([np.ones(df.shape[0]), df['size']]).T\ny = np.array(df['price'])\nprint(X.shape[0])\nprint(X.shape[1])\n\nalpha = 0.01\niterations = 2000\n\nvCosts, vThetas, thetas = computeGradientDescendWithCost(X, y, alpha, iterations)\nprint(vCosts[0])\nprint(vThetas[0])\nprint(vCosts[iterations-1])\nprint(vThetas[iterations-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction of one point"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_point = np.array([1.0, 1750.0])\npoint = raw_point\npoint[1] = (point[1]-vMu[0])/vSigma[0]\nprediction = thetas.dot(point)\nprint(point)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot hypothesis function(line)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = {\n    'data': \n    [{\n        'type': 'scatter',\n        'x': X[:,1],\n        'y': y,\n        'name': 'training set',\n        'mode': 'markers'\n    },\n    {\n        'type': 'scatter',\n        'x': X[:,1],\n        'y': X.dot(thetas),\n        'name': 'hypothesis',\n        'mode': 'lines'   \n    },\n    {\n        'type': 'scatter',\n        'x': [point[1]],\n        'y': [prediction],\n        'name': 'prediction',\n        'mode': 'markers'   \n    }    ],\n    'layout':\n    {\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'Size'},\n        'yaxis': {'title': 'Price'},\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot cost vs number of iterations"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = {\n    'data': \n    [{\n        'type': 'scatter',\n        'x': np.arange(iterations),\n        'y': vCosts,\n        'name': 'training set',\n        'mode': 'lines'\n    }],\n    'layout':\n    {\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'Iterations'},\n        'yaxis': {'title': 'Cost'}\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot cost vs theta parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"delta = 1\nth0 = np.arange(300.0, 400.0, delta)\nth1 = np.arange(90.0, 120.0, delta)\ntheta0, theta1 = np.meshgrid(th0, th1)\ncostes = np.zeros(theta0.shape)\n\nfor i in range(theta0.shape[0]):\n    for j in range(theta0.shape[1]):\n        costes[i,j]=computeCost(X,y,[theta0[i,j],theta1[i][j]])\n\nfig = {\n    'data': \n    [{\n        'type': 'contour',\n        'z': costes,\n        'x': th0,\n        'y': th1,\n        'contours':{'start':1000, 'end':7000, 'size':50, 'showlabels': True, 'labelfont':{'size':12, 'color':'white'}}\n    }],\n    'layout':\n    {\n        'title': 'LinearRegression',\n        'xaxis': {'title': 'theta0'},\n        'yaxis': {'title': 'theta1'}\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Definitions and execution of gradient descend (2 variables)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array([np.ones(df.shape[0]), df['size'], df['bedrooms']]).T\ny = np.array(df['price'])\nprint(X.shape[0])\nprint(X.shape[1])\n\nalpha = 0.01\niterations = 5000\n\nvCosts, vThetas, thetas = computeGradientDescendWithCost(X, y, alpha, iterations)\nprint(vCosts[0])\nprint(vThetas[0])\nprint(vCosts[iterations-1])\nprint(vThetas[iterations-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resolve exercice using Sklearn library"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nX = df[['size','bedrooms']].values\ny = df['price'].values\n\nmodel_lr = LinearRegression()\nmodel_lr.fit(X,y)\n\nprint(\"La ordenada al origen es: \" + str(model_lr.intercept_))\nprint(\"Las coeficientes theta son: \" + str(model_lr.coef_))\n\npoint = np.array([[1650, 3]])\nprediction = model_lr.predict(point)\nprint(\"La prediccion del punto \" + str(point)+ \" es: \" + str(prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}