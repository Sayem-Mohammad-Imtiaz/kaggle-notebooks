{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Background\n\nNOAA’s National Centers for Environmental Information (NCEI) hosts and provides access to one of the most significant archives on earth, with comprehensive oceanic, atmospheric, and geophysical data. From the depths of the ocean to the surface of the sun and from million-year-old ice core records to near-real-time satellite images, NCEI is the Nation’s leading authority for environmental information.\n\nThe five \"fundamental activities\" of NOAA are:\n\n- Monitoring and observing Earth systems with instruments and data collection networks.\n- Understanding and describing Earth systems through research and analysis of that data.\n- Assessing and predicting the changes of these systems over time.\n- Engaging, advising, and informing the public and partner organizations with important information.\n- Managing resources for the betterment of society, economy and environment.\n\nDetails of NOAA - https://en.wikipedia.org/wiki/National_Oceanic_and_Atmospheric_Administration"},{"metadata":{},"cell_type":"markdown","source":"### History"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nfrom IPython.display import IFrame\n\nHTML('<iframe width=\"560\" height=\"315\" src=\"//www.youtube.com/embed/nBnCsMYm2yQ\" frameborder=\"0\" allowfullscreen></iframe>')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data definition and collection\n\n#### GHCN \n- The Global Historical Climatology Network (GHCN) is an integrated database of climate summaries from land surface stations across the globe. \n- GHCN-Daily contains records from over 100,000 stations in 180 countries and territories.\n- The data are obtained from more than 20 sources. Some data are more than 175 years old.\n- NCEI provides numerous daily variables, including maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about one half of the stations \n  report precipitation only\n  \n##### Data description\nhttps://www.ncdc.noaa.gov/ghcn-daily-description\n\n##### Collection\nThe data can be collected from S3 buckets. Here I collected it beforehand and put into aws-data folder for 2019.  \nFor detail information the link is as below:  \nhttps://docs.opendata.aws/noaa-ghcn-pds/readme.html  \nQuestion for data quality should be addressed at noaa.bdp@noaa.gov."},{"metadata":{},"cell_type":"markdown","source":"### Exploration of data retreived from station\n#### Summary of Date format\nID = 11 character station identification code. Please see ghcnd-stations section below for an explantation  \nYEAR/MONTH/DAY = 8 character date in YYYYMMDD format (e.g. 19860529 = May 29, 1986)  \nELEMENT = 4 character indicator of element type  \nDATA VALUE = 5 character data value for ELEMENT  \nM-FLAG = 1 character Measurement Flag  \nQ-FLAG = 1 character Quality Flag  \nS-FLAG = 1 character Source Flag  \nOBS-TIME = 4-character time of observation in hour-minute format (i.e. 0700 =7:00 am)  \n\nThe fields are comma delimited and each row represents one station-day. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"station_df = pd.read_csv(\"/kaggle/input/aws-open-source-weather-transaction-and-metadata/2019.csv\", header = 1, \\\n                 names = ['station_code', 'w_date', 'element_type', 'element_value', 'measurement_flag', 'quality_flag', \\\n                          'source_flag', 'obs_time'], \\\n                delimiter = ',')\nstation_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Retreive unique element_types\n\nThe five core elements are:  \nPRCP = Precipitation (tenths of mm)  \nSNOW = Snowfall (mm)  \nSNWD = Snow depth (mm)  \nTMAX = Maximum temperature (tenths of degrees C)  \nTMIN = Minimum temperature (tenths of degrees C)  "},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_statuion = station_df['element_type'].unique()\nunique_statuion","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_statuion.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for number of observations per day"},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df['w_date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_grp_dt = station_df.groupby('w_date').count().sort_values(by = 'station_code', ascending = False)\ndf_grp_dt['station_code'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Aditional attributes\n### M-flag i.e. measurement flag  \nMFLAG is the measurement flag. There are ten possible values:  \nBlank = no measurement information applicable  \nB = precipitation total formed from two 12-hour totals  \nD = precipitation total formed from four six-hour totals  \nH = represents highest or lowest hourly temperature (TMAX or TMIN) or the average of hourly values (TAVG)  \nK = converted from knots  \nL = temperature appears to be lagged with respect to reported hour of observation  \nO = converted from oktas  \nP = identified as “missing presumed zero” in DSI 3200 and 3206  \nT = trace of precipitation, snowfall, or snow depth  \nW = converted from 16-point WBAN code (for wind direction) "},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df[station_df.measurement_flag == 'T'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q-flag i.e. quality flag  \nQ-FLAG is the measurement quality flag. here are fourteen possible values:  \nBlank = did not fail any quality assurance check  \nD = failed duplicate check  \nG = failed gap check  \nI = failed internal consistency check  \nK = failed streak/frequent-value check  \nL = failed check on length of multiday period  \nM = failed mega consistency check  \nN = failed naught check  \nO = failed climatological outlier check  \nR = failed lagged range check  \nS = failed spatial consistency check  \nT = failed temporal consistency check  \nW = temperature too warm for snow  \nX = failed bounds check  \nZ = flagged as a result of an official Datzilla Investigation "},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df[station_df.quality_flag == 'W'].head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### S-flag i.e. source flag\n\nS-FLAG is the source flag for the observation. There are twenty nine possible values (including blank, upper and lower case letters):\n\nBlank = No source (i.e., data value missing)  \n0 = U.S. Cooperative Summary of the Day (NCDC DSI-3200)  \n6 = CDMP Cooperative Summary of the Day (NCDC DSI-3206)  \n7 = U.S. Cooperative Summary of the Day – Transmitted via WxCoder3 (NCDC SI-3207)  \nA = U.S. Automated Surface Observing System (ASOS) real-time data (since January 1, 2006)  \na = Australian data from the Australian Bureau of Meteorology  \nB = U.S. ASOS data for October 2000-December 2005 (NCDC DSI-3211)  \nb = Belarus update  \nC = Environment Canada  \nE = European Climate Assessment and Dataset (Klein Tank et al., 2002)  \nF = U.S. Fort data  \nG = Official Global Climate Observing System (GCOS) or other government-supplied data  \nH = High Plains Regional Climate Center real-time data  \nI = International collection (non U.S. data received through personal contacts)  \nK = U.S. Cooperative Summary of the Day data digitized from paper observer forms (from 2011 to present)  \nM = Monthly METAR Extract (additional ASOS data)  \nN = Community Collaborative Rain, Hail,and Snow (CoCoRaHS)  \nQ = Data from several African countries that had been “quarantined”, that is, withheld from public release until permission was granted from the respective meteorological services  \nR = NCEI Reference Network Database (Climate Reference Network and Regional Climate Reference Network)  \nr = All-Russian Research Institute of Hydro-meteorological Information-World Data Center  \nS = Global Summary of the Day (NCDC DSI-9618)NOTE: “S” values are derived from hourly synoptic reports exchanged on the Global    Telecommunications System (GTS). Daily values derived in this fashion may differ significantly from “true” daily data, particularly for precipitation (i.e., use with caution).  \ns = China Meteorological Administration/National Meteorological Information Center/Climatic Data Center (http://cdc.cma.gov.cn)  \nT = SNOwpack TELemtry (SNOTEL) data obtained from the U.S. Department of Agriculture’s Natural Resources Conservation Service  \nU = Remote Automatic Weather Station (RAWS) data obtained from the Western Regional Climate Center  \nu = Ukraine update  \nW = WBAN/ASOS Summary of the Day from NCDC’s Integrated Surface Data (ISD).  \nX = U.S. First-Order Summary of the Day (NCDC DSI-3210)  \nZ = Datzilla official additions or replacements  \nz = Uzbekistan update  \n\n#### Recommendation\nWhen data are available for the same time from more than one source, the highest priority source is chosen according to the following priority order (from highest to lowest): - Z,R,0,6,C,X,W,K,7,F,B,M,r,E,z,u,b,s,a,G,Q,I,A,N,T,U,H,S  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"station_df[station_df.source_flag == 'E'].head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploration of Station meta data"},{"metadata":{},"cell_type":"markdown","source":"### Variable and feature details\n\nThese variables have the following definitions:  \n\n- ID = the station identification code.  \n    The first two characters denote the FIPS country code. Details for FIPS country code https://www.geodatasource.com/resources/tutorials/international-country-code-fips-versus-iso-3166/     \n    The third character is a network code that identifies the station numbering system used  \n    0 = unspecified (station identified by up to eight alphanumeric characters)  \n    1 = Community Collaborative Rain, Hail,and Snow (CoCoRaHS) based identification number. To ensure consistency with with GHCN \n    Daily, all numbers in the original CoCoRaHS IDs have been left-filled to make them all four digits long. In addition, the \n    characters “-” and “_” have been removed to ensure that the IDs do not exceed 11 characters when preceded by “US1”. For \n    example, the CoCoRaHS ID “AZ-MR-156” becomes “US1AZMR0156” in GHCN-Daily  \n- LATITUDE = latitude of the station (in decimal degrees).  \n- LONGITUDE = longitude of the station (in decimal degrees).  \n- STATE = U.S. postal code for the state (for U.S. and Canadian stations only).  \n- NAME = name of the station.  \n- GSN FLAG = flag that indicates whether the station is part of the GCOS Surface Network (GSN). \n- HCN/CRN FLAG = flag that indicates whether the station is part of the U.S. Historical Climatology Network (HCN). T\n- WMO ID is the World Meteorological Organization (WMO) number for the station. If the station has no WMO number (or one has not  \n    yet been matched to this station), then the field is blank.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nmd_station_df = pd.read_csv(\"/kaggle/input/aws-open-source-weather-transaction-and-metadata/ghcnd-stations.txt\", header = None, sep = '\\s+', \\\n                         names = ['station_id', 'latitude', 'longitude', 'elevation', 'state', 'name', 'gsn_flag', \\\n                                  'hcn_flag', 'wmo_id'])\nmd_station_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Projection for all stations in a city/ town e.g. Berlin"},{"metadata":{"trusted":true},"cell_type":"code","source":"import folium\nfrom folium import features\n\n\nmd_city_cordinates = md_station_df[md_station_df.state.str.contains(\"BERLIN\", na=False)][['state','latitude', 'longitude']]\nmd_city_cordinates\n\nberlin_location = [md_city_cordinates.iloc[0].latitude, md_city_cordinates.iloc[0].longitude]\n\n#tiles=\"https://1.base.maps.api.here.com/maptile/2.1/maptile/newest/normal.day/{z}/{x}/{y}/256/png8?lg=eng&app_id=%s&app_code=%s\"\n\nm = folium.Map(location=berlin_location, zoom_start=11, tiles=\"openstreetmap\", attr=\"HERE.com\")\n\n# mark each station as a point\nfor index, row in md_city_cordinates.iterrows():\n    folium.CircleMarker([row['latitude'], row['longitude']],\n                        radius=15,\n                        popup=row['state'],\n                        fill_color=\"blue\", # divvy color\n                        con_color='white',\n                       ).add_to(m)\n\n    \n\nm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check station details for a city e.g. München"},{"metadata":{"trusted":true},"cell_type":"code","source":"md_station_df[(md_station_df.station_id.str.startswith('GM')) & (md_station_df.state.str.startswith('MUNCHEN'))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Country code master data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom io import StringIO\n\nfile = \"/kaggle/input/aws-open-source-weather-transaction-and-metadata/ghcnd-countries.txt\"\n\ndef parse_country_file(filename):\n    with open(filename) as f:\n        for line in f:\n            yield line.strip().split(' ', 1)\n\ncountry_df = pd.DataFrame(parse_country_file(file))\ncountry_df.columns=['country_code', 'country_name']\ncountry_df[country_df['country_name'].isin(['Germany', 'Spain', 'Italy', 'France', 'United Kingdom'])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## State code master data\n\nThe state codes are used in the station identification number, the table below CODE = is the POSTAL code of the U.S. state/territory or Canadian province where the station is located."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom io import StringIO\n\nfile = \"/kaggle/input/aws-open-source-weather-transaction-and-metadata/ghcnd-states.txt\"\n\ndef parse_country_file(filename):\n    with open(filename) as f:\n        for line in f:\n            yield line.strip().split(' ', 1)\n\nstate_df = pd.DataFrame(parse_country_file(file))\nstate_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GHCND inventory master data\n\nThis is the periods of record for each station and element  \n\n### Data structure\n\n- ID = the station identification code. Please see “ghcnd-stations.txt” for a complete list of stations and their metadata.  \n- LATITUDE = the latitude of the station (in decimal degrees).  \n- LONGITUDE = the longitude of the station (in decimal degrees).  \n- ELEMENT = the element type. See section III for a definition of elements.  \n- FIRSTYEAR = the first year of unflagged data for the given element.  \n- LASTYEAR = the last year of unflagged data for the given element. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfile = \"/kaggle/input/aws-open-source-weather-transaction-and-metadata/ghcnd-inventory.txt\"\nghcnd_inventory_df = pd.read_csv(file, sep = '\\s+', header=None, names = ['staion_id','latitude', 'longitude', 'element', 'firstyear', 'lastyear'])\nghcnd_inventory_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{},"cell_type":"markdown","source":"### Plot Average temperature in Sydney for last N months - on availabiliity"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsydney_station_id = md_station_df[md_station_df.state.str.contains('SYDNEY', na=False)].station_id.unique().tolist()\nsydney_station_data = station_df[station_df.station_code.isin(sydney_station_id)]\n\nsydney_data_plot = sydney_station_data[sydney_station_data.element_type.str.contains(\"TAVG\")][['station_code', 'w_date', 'element_type']]\nsydney_data_plot['element_type_celcius'] = sydney_station_data.element_value/10\n\nsydney_data_pyplot = sydney_data_plot\nsydney_data_pyplot.w_date = pd.to_datetime(sydney_data_pyplot['w_date'], format='%Y%m%d')\nsydney_data_pyplot.set_index(['w_date'],inplace=True)\n\nplt.figure(figsize = (20,4))\nsydney_data_pyplot.plot()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare average temparature of Erlangen, Tokyo and Sydney"},{"metadata":{"trusted":true},"cell_type":"code","source":"hamburg_station_id = md_station_df[md_station_df.state.str.contains('ERLANGEN', na=False)].station_id.unique().tolist()\nhamburg_station_data =  station_df[station_df.station_code.isin(hamburg_station_id)]\nhamburg_data_plot = hamburg_station_data[hamburg_station_data.element_type.str.contains(\"TAVG\")][['station_code', 'w_date', 'element_type']]\nhamburg_data_plot['element_type_celcius'] = hamburg_station_data.element_value/10\n\ntokyo_station_id = md_station_df[md_station_df.state.str.contains('TOKYO', na=False)].station_id.unique().tolist()\ntokyo_station_data =  station_df[station_df.station_code.isin(tokyo_station_id)]\ntokyo_data_plot = tokyo_station_data[tokyo_station_data.element_type.str.contains(\"TAVG\")][['station_code', 'w_date', 'element_type']]\ntokyo_data_plot['element_type_celcius'] = tokyo_station_data.element_value/10\n\nsydney_station_id = md_station_df[md_station_df.state.str.contains('SYDNEY', na=False)].station_id.unique().tolist()\nsydney_station_data =  station_df[station_df.station_code.isin(sydney_station_id)]\nsydney_data_plot = sydney_station_data[sydney_station_data.element_type.str.contains(\"TAVG\")][['station_code', 'w_date', 'element_type']]\nsydney_data_plot['element_type_celcius'] = sydney_station_data.element_value/10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\n#bts_data_seaplot = bts_data_plot\nhamburg_data_plot.w_date = pd.to_datetime(hamburg_data_plot['w_date'], format='%Y%m%d')\ntokyo_data_plot.w_date = pd.to_datetime(tokyo_data_plot['w_date'], format='%Y%m%d')\nsydney_data_plot.w_date = pd.to_datetime(sydney_data_plot['w_date'], format='%Y%m%d')\n\nplt.figure(figsize = (20,4))\nsns.set(rc={'axes.facecolor':'cyan', 'figure.facecolor':'cornflowerblue'})\n#sns.set_style(\"darkgrid\")\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.lineplot(hamburg_data_plot[\"w_date\"],hamburg_data_plot[\"element_type_celcius\"], color = \"red\")\nsns.lineplot(tokyo_data_plot[\"w_date\"],tokyo_data_plot[\"element_type_celcius\"], color = \"darkslategrey\")\nsns.lineplot(sydney_data_plot[\"w_date\"],sydney_data_plot[\"element_type_celcius\"], color = \"steelblue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The state codes are used in the station identification number. In the table below CODE is the FIPS country code of the country where the station is located."},{"metadata":{},"cell_type":"markdown","source":"### Merging station weather with master data"},{"metadata":{"trusted":true},"cell_type":"code","source":"station_tran_ms_df = pd.merge(station_df, md_station_df, left_on = ['station_code'], right_on = ['station_id'], \\\n                                how='left')\nstation_tran_ms_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Find maximum temperature in Germany"},{"metadata":{"trusted":true},"cell_type":"code","source":"station_tran_ms_tmax_df = station_tran_ms_df[(station_tran_ms_df.element_type.str.contains(\"TMAX\" , na=False)) & \n                                            (station_tran_ms_df.station_code.str.startswith('GM', na=False))]\nmax_tmp = station_tran_ms_tmax_df['element_value'].max()\nmax_tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_tmp_loc = station_tran_ms_tmax_df[station_tran_ms_tmax_df.element_value == max_tmp][['state','latitude', 'longitude']]\nmax_tmp_loc\n\nplt_location = [max_tmp_loc.iloc[0].latitude, max_tmp_loc.iloc[0].longitude]\n\nmpl = folium.Map(location=plt_location, zoom_start=11)\nfolium.TileLayer('stamenterrain').add_to(mpl)\n\n\n# mark each station as a point\nfor index, row in max_tmp_loc.iterrows():\n    folium.CircleMarker([row['latitude'], row['longitude']],\n                        radius=15,\n                        popup=row['state'],\n                        fill_color=\"blue\", # divvy color\n                        con_color='white',\n                       ).add_to(mpl)\n\n    \n\nmpl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check station with maximum snowfall"},{"metadata":{"trusted":true},"cell_type":"code","source":"station_tran_snowfall_max_df = station_tran_ms_df[station_tran_ms_df.element_type.str.contains(\"SNOW\" , na=False)]\nmax_snowfall = station_tran_snowfall_max_df['element_value'].max()\nmax_snowfall\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_snowfall_loc = station_tran_snowfall_max_df[station_tran_snowfall_max_df.element_value == max_snowfall][['state','latitude', 'longitude']]\nplt_location = [max_snowfall_loc.iloc[0].latitude, max_snowfall_loc.iloc[0].longitude]\n\nmpl = folium.Map(location=plt_location, zoom_start=11, tiles=\"openstreetmap\", attr=\"HERE.com\")\n\n# mark each station as a point\nfor index, row in max_snowfall_loc.iterrows():\n    folium.CircleMarker([row['latitude'], row['longitude']],\n                        radius=15,\n                        popup=row['state'],\n                        fill_color=\"blue\", # divvy color\n                        con_color='white',\n                       ).add_to(mpl)\n\n    \n\nmpl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** If you like this notebook, please upvote it **"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}