{"cells":[{"metadata":{"_cell_guid":"70c80082-d034-4fcf-ab71-b0249146c904","_uuid":"20b1a12fef056e269f5eb57f61d89445d3853b46"},"cell_type":"markdown","source":"# Diagnostic Test Results for Diabetes and HIV","execution_count":null},{"metadata":{"_cell_guid":"5dc6a44f-1d7c-43fb-8a59-38a7f31fdcec","_uuid":"de37bdf84595d7c3357b37b82528fa65eb36d4d3"},"cell_type":"markdown","source":"### Part 1 - Data Preprocessing","execution_count":null},{"metadata":{"_cell_guid":"40305991-d4d2-47bc-954c-cfb1462f78b5","_uuid":"7068cc7db34cbfbbec0bb1b475463965da46b700"},"cell_type":"markdown","source":"This dataset relates to the Pima Indian Population, near Phoenix, Arizona. The study is fairly old, starting in 1965, with a range of variables being chosen based upon their significance in other studies, including the number of times the individual had been pregnant, body mass index, and age.\n\nFirst, let's load the data,","execution_count":null},{"metadata":{"_cell_guid":"2e1373ee-e8e1-4b7f-b154-4cc0cf3cde2c","_uuid":"fddaa7f159a3582c71daa8a4d41591cc2039aed3","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\ndiabetes = pd.read_csv('../input/pima-indians-diabetes-database//diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9fdc1bfc-f0ea-4b53-9eba-d74fee6c42f4","_uuid":"4e1aae909fe68d3ae34dd02bfe0eab1de122097a","trusted":true},"cell_type":"code","source":"diabetes.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a2f3e3b9-72a5-44ba-ba8e-de55df96821c","_uuid":"147066f616457e0bdd2161c8d888858bde391fd5","trusted":true},"cell_type":"code","source":"diabetes.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4775e2fc-818e-40d2-8a50-5e70a57f615f","_uuid":"d1c48fec0a3c7e4fde466dc27ac51b8c1009f7bc","trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\nsns.countplot(x='Outcome', data=diabetes, palette='hls')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13f0e7a6-67a6-421f-92da-d1d297a2cc3e","_uuid":"0a38d205e4dda717df624dd8c247a14e988902d3"},"cell_type":"markdown","source":"Mean numbers according to outcome","execution_count":null},{"metadata":{"_cell_guid":"01732855-352a-4551-82a6-0c498d7ad1f7","_uuid":"a6cd75c43d0ac3c922b7e93778fc937101e24354","trusted":true},"cell_type":"code","source":"diabetes.groupby('Outcome').mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9d5e45ca-a302-4822-8a25-ec3ba8754741","_uuid":"ff67a4ff3da99eafbcd4fdd40e83ae4042d60d46"},"cell_type":"markdown","source":"From the look of this outcome, if you have 4.86 children, you might be in trouble.\n\nNext, load a few bits and pieces, and then check for any missing values,","execution_count":null},{"metadata":{"_cell_guid":"ac89b150-751e-4cd3-b0ef-bb8c40ff36eb","_uuid":"b08092619c10f101817f1bc5d4031dcc133f2050","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn import linear_model, datasets, metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, auc\nimport math\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1c6ef958-8020-4bfc-b420-1d3f509d74df","_uuid":"2c3f9410663f9e85995eee93753a25575f24c4a0","trusted":true},"cell_type":"code","source":"diabetes.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 2 - Data Visualization","execution_count":null},{"metadata":{"_cell_guid":"40491628-76f7-4302-aa79-b01b50d5bcf0","_uuid":"a07af87c9c9d295e8cfa70480e4787be3e8ce4b1"},"cell_type":"markdown","source":"Glucose is important! Let's use a box-plot to see the difference in terms of outcome,","execution_count":null},{"metadata":{"_cell_guid":"77492a81-2e22-45d4-9fa1-7f02bd3f196e","_uuid":"fecbba6bad0d820f1ed397f6ec6719a776005242","trusted":true},"cell_type":"code","source":"sns.boxplot(x='Outcome', y='Glucose', data=diabetes, palette='hls')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b13524d8-9e91-41ec-aa1d-1c64a8313abd","_uuid":"96e6239021bd93c2d9ae42db4165049f9216688c"},"cell_type":"markdown","source":"So, glucose is raised, on average, in cases with diabetes. And of course, if we wanted to get into feature selection, the classic **correlation plot** would be useful,","execution_count":null},{"metadata":{"_cell_guid":"bd81dd86-ac36-44e4-b6f7-359718eb2ec8","_uuid":"c293d373c4e35b3ebc0409a4a92afd772b02cfbf","trusted":true},"cell_type":"code","source":"sns.heatmap(diabetes.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Different Classification Methods","execution_count":null},{"metadata":{"_cell_guid":"d864e7f2-9c85-44a9-bebf-ebe561ae60fb","_uuid":"25911f9e1ad3aaeb3c093e5384fa7a7f90ba8ad3"},"cell_type":"markdown","source":"Now, let's create a quick, crude model using logistic regression (including splitting into training and test sets, and making predictions),","execution_count":null},{"metadata":{"_cell_guid":"9ff7e909-cfa9-4f8d-ab00-51c97c966172","_uuid":"a484d05e4029715a3fbb6e43bbffca53c2ed6042","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(diabetes.drop('Outcome', 1), diabetes['Outcome'], test_size = .3, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7acbd687-b429-4d28-9ca0-571e4f9f3d47","_uuid":"d32bb24aca9f7ea9c865b360ffb3d67fadca01b2","trusted":true},"cell_type":"code","source":"LogReg = LogisticRegression()\nLogReg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"499615af-ee62-4e3d-b182-c08249ef0abf","_uuid":"987a8ad25a8e4856b0f604cd787c37f15fadc34c","collapsed":true,"trusted":true},"cell_type":"code","source":"y_pred_quant = LogReg.predict_proba(X_test)[:, 1] #Only keep the first column, which is the 'pos' values\ny_pred_bin = LogReg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e4ddd99f-c077-4119-b16e-cbd78c760905","_uuid":"66e5aae79b2c61d8865e21cfe83322d67c2b8e28"},"cell_type":"markdown","source":"[](http://)Now let's create a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix), and work out the sensitivity and specificity,","execution_count":null},{"metadata":{"_cell_guid":"991360a6-95c1-44a3-a98d-0777540ec95d","_uuid":"75395b3ea364365943d503bf3d2fd771feb654e9","trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = metrics.confusion_matrix(y_test, y_pred_bin)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"918e4975-c15d-4c42-b5c3-6410a03d78cf","_uuid":"68984adbd4ca8e08ccbbc41d51717a8345f759b5","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntotal=sum(sum(confusion_matrix))\n\nsensitivity = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[0,1])\nprint('Sensitivity : ', sensitivity )\n\nspecificity = confusion_matrix[1,1]/(confusion_matrix[1,0]+confusion_matrix[1,1])\nprint('Specificity : ', specificity)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e68f3f2-003b-49b1-b8da-4dc5c18b21f2","_uuid":"c9dac856d270812bf09f2cbd729593f0f7868953"},"cell_type":"markdown","source":"Now we encounter the first issue in the world of diagnostic testing, which is that sensitivity and specificity are often treated as static, where-as it of course depends upon the threshold you choose for determining what classes as a positive and what classes as a negative. To check the full range, we use a **[Receiver Operator Curve (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)**,","execution_count":null},{"metadata":{"_cell_guid":"7dd58788-cab9-4b1d-be81-aaddb02a8bb6","_uuid":"e0b4ce75c285c1b5ead674d99b26aec540a40810","collapsed":true,"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_quant)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e998a21e-d209-4466-9c2f-6b850a4afac9","_uuid":"c44d6b535ff4d057c6de06f1d7ff02b8b4154a77","trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for diabetes classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4991ab9d-ca0b-4b78-a3b4-b8ae26554eb4","_uuid":"daa97c98d3fb5eb34e069e0ea9072bf76613b4fb"},"cell_type":"markdown","source":"Another common metric is the **Area Under the Curve**, or **AUC**. This is a convenient way to capture the performance of a model in a single number, although it's not without certain issues. As a rule of thumb, an AUC can be classed as follows,\n\n- 0.90 - 1.00 = excellent\n- 0.80 - 0.90 = good\n- 0.70 - 0.80 = fair\n- 0.60 - 0.70 = poor\n- 0.50 - 0.60 = fail\n\nLet's see what the above ROC gives us,","execution_count":null},{"metadata":{"_cell_guid":"ddf966a7-4ec0-48c4-994b-c561366a53c7","_uuid":"f249bac20568c9e8997be40300aa01dfad3225b9","trusted":true},"cell_type":"code","source":"metrics.auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f20e140-34e2-4195-9a73-7f3e2085d76e","_uuid":"15f9df56c06b7776169914c3575a78ae455631bb"},"cell_type":"markdown","source":"> Borderline good!","execution_count":null},{"metadata":{"_cell_guid":"151f7817-bbe3-4861-83eb-4fe39508e8b4","_uuid":"06948f58b4472f45a52c324d8875057397b25e84"},"cell_type":"markdown","source":"<a id='DevelopingaDiagnosticTest'></a>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}