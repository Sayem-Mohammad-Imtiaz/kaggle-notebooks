{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iris classification using Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn import  datasets\niris=datasets.load_iris()\nx=iris.data\ny=iris.target\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.5)\nfrom sklearn import tree\nclassifier=tree.DecisionTreeClassifier()\nclassifier.fit(x_train,y_train)\npredictions=classifier.predict(x_test)\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iris classification using Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn import  datasets\niris=datasets.load_iris()\nx=iris.data\ny=iris.target\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.5)\nfrom sklearn.naive_bayes import GaussianNB \nclassifier=GaussianNB()\nclassifier.fit(x_train,y_train)\npredictions=classifier.predict(x_test)\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-means Clustering for Old Faithful Geyser Eruptions Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Import the data\ndata_frame = pd.read_csv('/kaggle/input/old-faithful/faithful.csv')\n\n# Standardize the data\nX_std = StandardScaler().fit_transform(data_frame)\n\n# Run local implementation of kmeans\nkm = KMeans(n_clusters=2, max_iter=100)\nkm.fit(X_std)\ncentroids = km.cluster_centers_\n\n# Plot the clustered data\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.scatter(X_std[km.labels_ == 0, 0], X_std[km.labels_ == 0, 1],\n            c='green', label='cluster 1')\nplt.scatter(X_std[km.labels_ == 1, 0], X_std[km.labels_ == 1, 1],\n            c='blue', label='cluster 2')\nplt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=100,\n            c='r', label='centroid')\nplt.legend()\nplt.xlim([-2, 2])\nplt.ylim([-2, 2])\nplt.xlabel('Eruption time (minutes)',  fontsize=16)\nplt.ylabel('Waiting time to next eruption (minutes)', fontsize=16)\nplt.title('Clustered Data from Old Faithful Geyser, \\n Yellowstone, USA',  fontsize=20, fontweight='bold')\nax.set_aspect('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVD and Image compression","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from skimage import data\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2gray\nfrom skimage import img_as_ubyte,img_as_float\nfrom numpy.linalg import svd\nfrom ipywidgets import interact,interactive,interact_manual\n\n\ndef compress_svd(image,k):\n    \"\"\"\n    Perform svd decomposition and truncated (using k singular values/vectors) reconstruction\n    returns\n    --------\n      reconstructed matrix reconst_matrix, array of singular values s\n    \"\"\"\n    U,s,V = svd(image,full_matrices=False)\n    reconst_matrix = np.dot(U[:,:k],np.dot(np.diag(s[:k]),V[:k,:]))\n   \n    return reconst_matrix,s\n\ndef compress_show_gray_images(img_name,k):\n    \"\"\"\n     compresses gray scale images and display the reconstructed image.\n     Also displays a plot of singular values\n    \"\"\"\n    image=gray_images[img_name]\n    original_shape = image.shape\n    reconst_img,s = compress_svd(image,k)\n    fig,axes = plt.subplots(1,2,figsize=(8,5))\n    axes[0].plot(s)\n    compression_ratio =100.0* (k*(original_shape[0] + original_shape[1])+k)/(original_shape[0]*original_shape[1])\n    axes[1].set_title(\"compression ratio={:.2f}\".format(compression_ratio)+\"%\")\n    axes[1].imshow(reconst_img,cmap='gray')\n    axes[1].axis('off')\n    fig.tight_layout()\n\ndef compress_show_color_images_reshape(img_name,k):\n    \"\"\"\n     compress and display the reconstructed color image using the reshape method \n    \"\"\"\n    image = color_images[img_name]\n    original_shape = image.shape\n    image_reshaped = image.reshape((original_shape[0],original_shape[1]*3))\n    image_reconst,_ = compress_svd(image_reshaped,k)\n    image_reconst = image_reconst.reshape(original_shape)\n    compression_ratio =100.0* (k*(original_shape[0] + 3*original_shape[1])+k)/(original_shape[0]*original_shape[1]*original_shape[2])\n    plt.title(\"compression ratio={:.2f}\".format(compression_ratio)+\"%\")\n    plt.imshow(image_reconst)\n    \ndef compress_show_color_images_layer(img_name,k):\n    \"\"\"\n     compress and display the reconstructed color image using the layer method \n    \"\"\"\n    image = color_images[img_name]\n    original_shape = image.shape\n    image_reconst_layers = [compress_svd(image[:,:,i],k)[0] for i in range(3)]\n    image_reconst = np.zeros(image.shape)\n    for i in range(3):\n        image_reconst[:,:,i] = image_reconst_layers[i]\n    \n    compression_ratio =100.0*3* (k*(original_shape[0] + original_shape[1])+k)/(original_shape[0]*original_shape[1]*original_shape[2])\n    plt.title(\"compression ratio={:.2f}\".format(compression_ratio)+\"%\")\n    \n    plt.imshow(image_reconst)\n    \ngray_images = {\n        \"cat\":rgb2gray(img_as_float(data.chelsea())),\n        \"astro\":rgb2gray(img_as_float(data.astronaut())),\n        \"camera\":data.camera(),\n        \"coin\": data.coins(),\n        \"clock\":data.clock(),\n        \"blobs\":data.binary_blobs(),\n        \"coffee\":rgb2gray(img_as_float(data.coffee()))\n}\n\ncolor_images = {\n    \"cat\":img_as_float(data.chelsea()),\n    \"astro\":img_as_float(data.astronaut()),\n    \"coffee\":img_as_float(data.coffee())\n    \n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grayscale Image\ninteract(compress_show_gray_images,img_name=list(gray_images.keys()),k=(1,300));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reshape method to compress a color image\ninteract(compress_show_color_images_reshape,img_name=list(color_images.keys()),k=(0,512));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Layers method to compress color images\ninteract(compress_show_color_images_layer,img_name=list(color_images.keys()),k=(1,550));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Face Recognition with Eigenfaces (PCA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_lfw_people\nfrom sklearn.metrics import classification_report\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import MLPClassifier\n \n \n# Load data\nlfw_dataset = fetch_lfw_people(min_faces_per_person=100)\n \n_, h, w = lfw_dataset.images.shape\nX = lfw_dataset.data\ny = lfw_dataset.target\ntarget_names = lfw_dataset.target_names\n \n# split into a training and testing set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Compute a PCA \nn_components = 100\npca = PCA(n_components=n_components, whiten=True).fit(X_train)\n \n# apply PCA transformation\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\n\nprint(\"Fitting the classifier to the training set\")\nclf = MLPClassifier(hidden_layer_sizes=(1024,), batch_size=256, verbose=True, early_stopping=True).fit(X_train_pca, y_train)\n\ny_pred = clf.predict(X_test_pca)\nprint(classification_report(y_test, y_pred, target_names=target_names))\n\n# Visualization\ndef plot_gallery(images, titles, h, w, rows=3, cols=4):\n    plt.figure()\n    for i in range(rows * cols):\n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n        plt.title(titles[i])\n        plt.xticks(())\n        plt.yticks(())\n \ndef titles(y_pred, y_test, target_names):\n    for i in range(y_pred.shape[0]):\n        pred_name = target_names[y_pred[i]].split(' ')[-1]\n        true_name = target_names[y_test[i]].split(' ')[-1]\n        yield 'predicted: {0}\\ntrue: {1}'.format(pred_name, true_name)\n \nprediction_titles = list(titles(y_pred, y_test, target_names))\nplot_gallery(X_test, prediction_titles, h, w)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}