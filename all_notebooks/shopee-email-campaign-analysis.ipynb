{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Version History\n## each version has its own unique way to build prediction model \n\n#5, #6: Preprocess dataset -> Save/Load (optional) -> Light GBM Model (**VERY SLOW** *_~4h_*)\n#4: the visualizations and thorough analysis supporting version #3 (**VERY FAST** *_<10m_*)\n#3: using H2O.AI -> LGBM model (**SLOW** *_~2h_*)\n#2, #1: conventional technique with Sklearn Gradient Boosting Classifier (**VERY FAST** *_<1h_*)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Credits to [Sandy Khosasi](https://www.kaggle.com/ilosvigil)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random\nimport platform\nimport itertools\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.width', None)\npd.set_option('display.max_column', None)\n\nSEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\nprint('Python version:', platform.python_version())\nprint('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basedir = '../input/shopee-code-league-20/_DA_Marketing_Analytics'\n\n# converting to dataframe\ndf_train = pd.read_csv(os.path.join(basedir,'train.csv'))\ndf_test = pd.read_csv(os.path.join(basedir,'test.csv'))\ndf_users = pd.read_csv(os.path.join(basedir,'users.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Skim thru datasets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. dtypes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_users.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_users.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. unique values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sort(df_train['country_code'].unique()))\nprint(np.sort(df_test['country_code'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sort(df_users['attr_1'].unique()))\nprint(np.sort(df_users['attr_2'].unique()))\nprint(np.sort(df_users['attr_3'].unique()))\nprint(np.sort(df_users['domain'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Domain","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list_unique = df_users['domain'].unique()\ndict_unique = {list_unique[i]: i for i in range(len(list_unique))}\ndf_users['domain'] = df_users['domain'].apply(lambda d: dict_unique[d])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. last{  }day","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(day):\n    try:\n        return np.float(day)\n    except:\n        return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['last_open_day'] = df_train['last_open_day'].apply(convert)\ndf_train['last_login_day'] = df_train['last_login_day'].apply(convert)\ndf_train['last_checkout_day'] = df_train['last_checkout_day'].apply(convert)\n\ndf_test['last_open_day'] = df_test['last_open_day'].apply(convert)\ndf_test['last_login_day'] = df_test['last_login_day'].apply(convert)\ndf_test['last_checkout_day'] = df_test['last_checkout_day'].apply(convert)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. User ID","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.join(df_users, on='user_id', rsuffix='_unused')\ndf_test = df_test.join(df_users, on='user_id', rsuffix='_unused')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. drop unused","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_train['user_id']\ndel df_train['user_id_unused']\ndel df_train['row_id']\n\ndel df_test['user_id']\ndel df_test['user_id_unused']\ndel df_test['row_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. datetime","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['day'] = pd.to_datetime(df_train['grass_date']).dt.dayofweek.astype('category')\ndf_test['day'] = pd.to_datetime(df_test['grass_date']).dt.dayofweek.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_train['grass_date']\ndel df_test['grass_date']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Anomaly","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_age(age):\n    if age < 18 or age >= 100:\n        return np.nan\n    else:\n        return age\n    \ndf_train['age'] = df_train['age'].apply(fix_age)\ndf_test['age'] = df_test['age'].apply(fix_age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. NaN values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# domain\n# 1 -> 'other' domain from previous preprocessing\n# df_train['domain_nan'] = df_train['domain'].isnull()\ndf_train['domain'] = df_train['domain'].fillna(1)\n\n# df_test['domain_nan'] = df_test['domain'].isnull()\ndf_test['domain'] = df_test['domain'].fillna(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inspect changes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_users","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving preprocessed dataset (Optional)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_csv('train_processed.csv', index=False)\ndf_test.to_csv('test_processed.csv', index=False)\ndf_users.to_csv('users_processed.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_parquet('train_processed.parquet', engine='pyarrow')\ndf_test.to_parquet('test_processed.parquet', engine='pyarrow')\ndf_users.to_parquet('users_processed.parquet', engine='pyarrow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nimport lightgbm as lgbm\nimport scipy\n\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('LightGBM version:', lgbm.__version__)\nprint('Scipy version:', scipy.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.copy()\ndel X['open_flag']\n\nX_test = df_test.copy()\n\ny = df_train['open_flag'].to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_feature = [\n    'country_code','attr_1', 'attr_2', 'attr_3',\n    'domain','day',\n#     'last_open_day_nan', 'last_login_day_nan',\n#     'last_checkout_day_nan', 'attr_1_nan', 'attr_2_nan',\n#     'attr_3_nan', 'age_nan', 'domain_nan',\n    \n]\ncat_feature_idx = [X.columns.get_loc(ct) for ct in cat_feature]\ncat_feature_idx","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import matthews_corrcoef\n\nK = [3, 5, 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_dict = {\n    'learning_rate': [0.0075, 0.01, 0.0125],\n    'min_data_in_leaf': [20, 50],\n    'max_bin': [16, 102, 255],\n    'lambda': [\n        # l1, l2\n        [0.0, 0.0],\n        [0.001, 0.01],\n        [0.01, 0.1],\n        [1.0, 0.01],\n    ],\n    'n_estimators': [100, 125, 150]\n}\nparam_key = list(param_dict.keys())\nparam_item = list(param_dict.values())\nparam_item","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_list = list(itertools.product(*param_item))\nparam_list[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(param_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model = pd.DataFrame(columns=[*param_key, *[f'model_{i}' for i in range(sum(K))], *[f'model_{i}_mcc' for i in range(sum(K))], 'average_mcc'])\ndf_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf_list = [StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED) for k in K]\n\nfor param in param_list:\n    ctr = 0\n    model = []\n    mcc_score = []\n    for skf in skf_list:\n        for train_idx, val_idx in skf.split(X, y):\n            X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n\n            model.append(\n                lgbm.LGBMClassifier(\n                    # fixed\n                    is_unbalance=True,\n                    seed=SEED,\n                    extra_trees=True,\n\n                    min_data_per_group=1,\n                    boosting_type='goss',\n                    num_leaves=63,\n                    feature_fraction=0.9,\n                    # variable\n                    learning_rate=param[0],\n                    min_data_in_leaf=param[1],\n                    max_bin=param[2], \n                    lambda_l1=param[3][0],\n                    lambda_l2=param[3][1],\n                    n_estimators=param[4],\n                )\n            )\n            model[ctr].fit(\n                X_train, y_train,\n                categorical_feature=cat_feature_idx\n            )\n\n            y_val_pred = model[ctr].predict(X_val)\n            mcc_score.append(matthews_corrcoef(y_val, y_val_pred))\n\n            ctr += 1\n    df_model.loc[ df_model.shape[0] ] = [\n        *param,\n        *model,\n        *mcc_score,\n        sum(mcc_score) / len(mcc_score)\n    ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model = df_model.sort_values(by=['average_mcc', 'learning_rate'], ascending=[False, True]).reset_index(drop=True)\ndf_model.loc[:1000].to_pickle('model.pkl')\n!ls -lah","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, f1_score, confusion_matrix, precision_score, matthews_corrcoef\n\ndef predict(X, mode='best_mean'):\n    if mode == 'best_mode':\n        y_preds = []\n        for i in range(sum(K)):\n            y_preds.append(df_model.loc[0, f'model_{i}'].predict(X))\n        y_preds = np.array(y_preds)\n        y_preds = scipy.stats.mode(y_preds)\n        y_preds = y_preds[0]\n        y_preds = y_preds.reshape(-1)\n    elif mode == 'best_mean':\n        y_preds = []\n        for i in range(sum(K)):\n            y_preds.append(df_model.loc[0, f'model_{i}'].predict_proba(X))\n        y_preds = np.mean(np.array(y_preds), axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    elif mode == 'ensemble_mode':\n        y_preds = []\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(df_model.loc[i, f'model_{j}'].predict(X))\n        y_preds = np.array(y_preds)\n        y_preds = scipy.stats.mode(y_preds)\n        y_preds = y_preds[0]\n        y_preds = y_preds.reshape(-1)\n    elif mode == 'ensemble_mean':\n        y_preds = []\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(df_model.loc[i, f'model_{j}'].predict_proba(X))\n        y_preds = np.mean(np.array(y_preds), axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    elif mode == 'weighted_ensemble_mean':\n        y_preds = []\n#         model_weight = df_model['average_mcc'].apply(lambda a: a/df_model['average_mcc'].sum())\n        model_weight = []\n        for i in df_model.index:\n            model_weight.append(1 + np.log10(df_model.shape[0] - i + 1))\n        print(model_weight[:10])\n        for i in df_model.index:\n            for j in range(sum(K)):\n                y_preds.append(\n                    df_model.loc[i, f'model_{j}'].predict_proba(X) *\n                    model_weight[i]\n                )\n        y_preds = np.array(y_preds)\n        y_preds = np.mean(y_preds, axis=0)\n        y_preds = np.argmax(y_preds, axis=-1)\n    else:\n        raise ValueError(\"Mode isn't supported\")\n    \n    return y_preds\n\ndef metrics(y_true, y_pred):\n    print('Weighted F1 Score :', f1_score(y_true, y_pred, average='weighted'))\n    print('MCC Score :', matthews_corrcoef(y_true, y_pred))\n    cm = confusion_matrix(y_true, y_pred)\n    cm = pd.DataFrame(cm, [0, 1], [0, 1])\n\n    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. best mode","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = predict(X_train, mode='best_mode')\nmetrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. best mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred2 = predict(X_train, mode='best_mean')\nmetrics(y_train, y_train_pred2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. ensemble mode","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred3 = predict(X_train, mode='ensemble_mode')\nmetrics(y_train, y_train_pred3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. ensemble mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred4 = predict(X_train, mode='ensemble_mean')\nmetrics(y_train, y_train_pred4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. weighted ensemble mean","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred5 = predict(X_train, mode='weighted_ensemble_mean')\nmetrics(y_train, y_train_pred5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_modes = ['best_mode','best_mean','ensemble_mode','ensemble_mean','weighted_ensemble_mean']\n\nfor mdx in pred_modes:\n    y_test_pred = predict(X_test, mode=mdx)\n    df_submission = pd.concat([pd.Series(list(range(0, len(X_test))), name='row_id', dtype=np.int32), pd.Series(y_test_pred, name='open_flag')], axis=1)\n    df_submission.to_csv('submission_'+mdx+'.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.plot_importance(df_model.loc[0, 'model_0'], ignore_zero=False, figsize=(16,9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.plot_split_value_histogram(df_model.loc[0, 'model_0'], 2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}