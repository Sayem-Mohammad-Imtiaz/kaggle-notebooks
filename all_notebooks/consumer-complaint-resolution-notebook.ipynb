{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nimport string\nfrom datetime import datetime, date\nfrom nltk.tokenize import wordpunct_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n%matplotlib inline\npd.pandas.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Data Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/consumer-complaint-resolution-data-set/Consumer_Complaints_train.csv')\ndf_test = pd.read_csv('../input/consumer-complaint-resolution-data-set/Consumer_Complaints_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shape of Train and Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Columns of Train and Test Data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Types"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_types_train = pd.DataFrame(df_train.dtypes, columns = ['Train'])\ndata_types_test = pd.DataFrame(df_test.dtypes, columns = ['Test'])\ndata_types = pd.concat([data_types_train, data_types_test], axis = 1)\ndata_types","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_train = pd.DataFrame(df_train.isna().sum(), columns = ['Train'])\nmissing_values_test = pd.DataFrame(df_test.isna().sum(), columns = ['Test'])\nmissing_values = pd.concat([missing_values_train, missing_values_test], axis = 1)\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_with_missing_values = ['Sub-product', 'Sub-issue', 'Consumer complaint narrative', 'Company public response', 'Tags', 'Consumer consent provided?']\ndf_train = df_train.drop(columns_with_missing_values, axis = 1)\ndf_test = df_test.drop(columns_with_missing_values, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting Date, Month and Year from Date Received Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Year_Received'] = df_train['Date received'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').year)\ndf_test['Year_Received'] = df_test['Date received'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').year)\ndf_train['Month_Received'] = df_train['Date received'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').month)\ndf_test['Month_Received'] = df_test['Date received'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').month)\ndf_train['Day_Received'] = df_train['Date received'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').day)\ndf_test['Day_Received'] = df_test['Date received'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting Date, Month and Year From Date Sent to the Company Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Year_Sent'] = df_train['Date sent to company'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').year)\ndf_test['Year_Sent'] = df_test['Date sent to company'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').year)\ndf_train['Month_Sent'] = df_train['Date sent to company'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').month)\ndf_test['Month_Sent'] = df_test['Date sent to company'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').month)\ndf_train['Day_Sent'] = df_train['Date sent to company'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').day)\ndf_test['Day_Sent'] = df_test['Date sent to company'].apply(lambda dateString : datetime.strptime(dateString,'%Y-%m-%d').day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting Dates from Object Type to Datetime Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Date received'] = pd.to_datetime(df_train['Date received'])\ndf_test['Date received'] = pd.to_datetime(df_test['Date received'])\ndf_train['Date sent to company'] = pd.to_datetime(df_train['Date sent to company'])\ndf_test['Date sent to company'] = pd.to_datetime(df_test['Date sent to company'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculating the Number of Days the Complaint was with the Company"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Days held'] = df_train['Date sent to company'] - df_train['Date received']\ndf_test['Days held'] = df_test['Date sent to company'] - df_test['Date received']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting Days Held to Int"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Days held'] = df_train['Days held'].astype('timedelta64[D]').astype(int)\ndf_test['Days held'] = df_test['Days held'].astype('timedelta64[D]').astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Date Received and Date Sent to Company"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(['Date received', 'Date sent to company'], axis = 1)\ndf_test = df_test.drop(['Date received', 'Date sent to company'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping ZIP Code, Complaint ID"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(['ZIP code', 'Complaint ID'], axis = 1)\ndf_test = df_test.drop(['ZIP code', 'Complaint ID'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imputing Nulls in State by Mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['State'].mode(), df_test['State'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['State'] = df_train['State'].replace(np.nan, 'CA')\ndf_test['State'] = df_test['State'].replace(np.nan, 'CA')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking Missing Values  Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_train = pd.DataFrame(df_train.isna().sum(), columns = ['Train'])\nmissing_values_test = pd.DataFrame(df_test.isna().sum(), columns = ['Test'])\nmissing_values = pd.concat([missing_values_train, missing_values_test], axis = 1)\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Year Sent, Month Sent and Day Sent"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(['Year_Sent', 'Month_Sent', 'Day_Sent'], axis = 1)\ndf_test = df_test.drop(['Year_Sent', 'Month_Sent', 'Day_Sent'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorizing Days into Weeks"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"week_train = []\nfor i in df_train['Day_Received']:\n    if i < 8:\n        week_train.append(1)\n    elif i >= 8 and i < 16:\n        week_train.append(2)\n    elif i >=16 and i < 22:\n        week_train.append(3)\n    else:\n        week_train.append(4)\ndf_train['Week_Received'] = week_train\nweek_test = []\nfor i in df_test['Day_Received']:\n    if i < 8:\n        week_test.append(1)\n    elif i >= 8 and i < 16:\n        week_test.append(2)\n    elif i >=16 and i < 22:\n        week_test.append(3)\n    else:\n        week_test.append(4)\ndf_test['Week_Received'] = week_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Day_Received"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(['Day_Received'], axis = 1)\ndf_test = df_test.drop(['Day_Received'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Disputed Consumers Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"disputed_cons = df_train[df_train['Consumer disputed?'] == 'Yes']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of Disputes"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Consumer disputed?', data = df_train)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Consumer disputed', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        Roughly 21% of the consumer have disputed."},{"metadata":{},"cell_type":"markdown","source":"### Products-wise Disputes"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Product', hue = 'Consumer disputed?', data = df_train)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Product', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        Roughly 37% consumer with mortgage have disputed.\n        Approx. 54% consumer who have disputed are from mortgage or debt collection.\n        68% consumer having disputes are from mortgage, debt collection and credit reporting.\n        Adding credit card consumers and bank account or services consumer will make it 80% and 91% respectively."},{"metadata":{},"cell_type":"markdown","source":"### Top Issues with Highest Disputes"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_issues_disputes = disputed_cons['Issue'].value_counts().sort_values(ascending = False).head(10)\nsns.barplot(x = top_issues_disputes.index, y = top_issues_disputes.values)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Issues', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        66% disputes are from these 10 issues."},{"metadata":{},"cell_type":"markdown","source":"### State with Maximum Disputes"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 10))\nsns.countplot(x = df_train['State'])\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('State', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        15% disputes from CA.\n        25% disputes from CA and FL\n        32% disputes from CA, FL and TX.\n        38% disputes from CA, FL, TX and NY.\n        43% disputes from CA, FL, TX, NY and GA.\n        47% disputes from CA, FL, TX, NY, GA and NJ.\n        50% disputes from CA, FL, TX, NY, GA, NJ and IL.\n        54% disputes from CA, FL, TX, NY, GA, NJ, IL and VA.\n        57% disputes from CA, FL, TX, NY, GA, NJ, IL, VA and PA.\n        61% disputes from CA, FL, TX, NY, GA, NJ, IL, VA, PA and MD."},{"metadata":{},"cell_type":"markdown","source":"### Maximum Disputes Submitted Via"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Submitted via', data = disputed_cons)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Submitted Via', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        72% disputes are submitted via web.\n        88% disputes are submitted via web and referral."},{"metadata":{},"cell_type":"markdown","source":"### Company's Response to the Complaints"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Company response to consumer', data = df_train)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Company Response', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        74% complaints are closed with explanation."},{"metadata":{},"cell_type":"markdown","source":"### Company's Response Leading to Disputes"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Company response to consumer', data = disputed_cons)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Company Response', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        82% disputes are closed with explanation at the initial stage.\n        89% disputes are either closed with explanation or non-monetary relief in the earlier stage."},{"metadata":{"scrolled":true},"cell_type":"markdown","source":"### Whether there are Disputes Instead of Timely Response"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Timely response?', data = disputed_cons)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Timely Response', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        98% disputes were timely repsonded at the intial stages."},{"metadata":{},"cell_type":"markdown","source":"### Year Wise Complaints"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Year_Received', data = df_train)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Year', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        28% complaints are raised in 2015.\n        53% complaints are raised in 2014 and 2015.\n        71% complaints are raised in 2013 to 2015.\n        88% complaints are raised in 2013 to 2016."},{"metadata":{},"cell_type":"markdown","source":"### Year Wise Disputes"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Year_Received', data = disputed_cons)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Year', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        27% disputes are raised in 2015.\n        50% disputes are raised in 2014 and 2015.\n        69% disputes are raised in 2014 to 2016.\n        87% disputes are raised in 2013 to 2016."},{"metadata":{},"cell_type":"markdown","source":"### Month Wise Complaints"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Month_Received', data = df_train)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Month', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        64% complaints are raised in January to July.\n        72% complaints are raised in January to August."},{"metadata":{},"cell_type":"markdown","source":"### Month Wise Disputes"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Month_Received', data = disputed_cons)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Month', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        56% disputes are raised in March to August.\n        73% disputes are raised in January to August."},{"metadata":{},"cell_type":"markdown","source":"### Week Wise Complaints"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Week_Received', data = df_train)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Week', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        30% complaints are in the 4th week of the month.\n        50% complaints are in both the half of the month."},{"metadata":{},"cell_type":"markdown","source":"### Week Wise Disputes "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'Week_Received', data = disputed_cons)\nplt.xticks(fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Week', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        30% disputes are in the 4th week of the month.\n        50% disputes are in both the half of the month."},{"metadata":{},"cell_type":"markdown","source":"### Top Companies with Highest Complaints"},{"metadata":{"trusted":true},"cell_type":"code","source":"worst_company_complaints = df_train['Company'].value_counts().sort_values(ascending = False).head(10)\nsns.barplot(x = worst_company_complaints.index, y = worst_company_complaints.values)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Company', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        53% complaints are for these 10 companies."},{"metadata":{},"cell_type":"markdown","source":"### Top Companies with Highest Disputes"},{"metadata":{"trusted":true},"cell_type":"code","source":"worst_company_disputes = disputed_cons['Company'].value_counts().sort_values(ascending = False).head(10)\nsns.barplot(x = worst_company_complaints.index, y = worst_company_complaints.values)\nplt.xticks(rotation = 90, fontsize = 10, ha = \"right\")\nplt.yticks(fontsize = 10)\nplt.xlabel('Company', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        53% disputes are for these 10 companies."},{"metadata":{},"cell_type":"markdown","source":"### Days Held Column Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Days held'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['Days held'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting Negative Days Held to Zero"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"Days_held_train = []\nfor i in df_train['Days held']:\n    if i < 0:\n        Days_held_train.append(0)\n    else:\n        Days_held_train.append(i)\ndf_train['Days_held'] = Days_held_train\nDays_held_test = []\nfor i in df_test['Days held']:\n    if i < 0:\n        Days_held_test.append(0)\n    else:\n        Days_held_test.append(i)\ndf_test['Days_held'] = Days_held_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Days Held with Negative Values\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop('Days held', axis = 1)\ndf_test = df_test.drop('Days held', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### NLP Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_text_train = df_train['Issue']\nrelevant_text_test = df_test['Issue']\ntokenized_data_train = relevant_text_train.apply(lambda x: wordpunct_tokenize(x.lower()))\ntokenized_data_test = relevant_text_test.apply(lambda x: wordpunct_tokenize(x.lower()))\ndef remove_punctuation(text):\n    no_punctuation = []\n    for w in text:\n        if w not in string.punctuation:\n            no_punctuation.append(w)\n    return no_punctuation\nno_punctuation_data_train = tokenized_data_train.apply(lambda x: remove_punctuation(x))\nno_punctuation_data_test = tokenized_data_test.apply(lambda x: remove_punctuation(x))\nstop_words = stopwords.words('english')\nfiltered_sentence_train = [w for w in no_punctuation_data_train if not w in stop_words]\nfiltered_sentence_train = pd.Series(filtered_sentence_train)\nfiltered_sentence_test = [w for w in no_punctuation_data_test if not w in stop_words]\nfiltered_sentence_test = pd.Series(filtered_sentence_test)\ndef lemmatize_text(text):\n    lem_text = [WordNetLemmatizer().lemmatize(w,pos = 'v') for w in text]\n    return lem_text\nlemmatized_data_train = filtered_sentence_train.apply(lambda x:lemmatize_text(x))\nlemmatized_data_test = filtered_sentence_test.apply(lambda x:lemmatize_text(x))\ndef stem_text(text):\n    stem_text = [PorterStemmer().stem(w) for w in text]\n    return stem_text\nstemmed_data_train = lemmatized_data_train.apply(lambda x:stem_text(x))\nstemmed_data_test = lemmatized_data_test.apply(lambda x:stem_text(x))\ndef word_to_sentence(text):\n    text_sentence = \" \".join(text)\n    return text_sentence\nclean_data_train = stemmed_data_train.apply(lambda x:word_to_sentence(x))\nclean_data_test = stemmed_data_test.apply(lambda x:word_to_sentence(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concating Clean Data to Train and Test Data and Dropping Issue"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Issues_cleaned'] = clean_data_train\ndf_test['Issues_cleaned'] = clean_data_test\ndf_train = df_train.drop('Issue', axis = 1)\ndf_test = df_test.drop('Issue', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping Unneccesary Columns for the Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['Company', 'State', 'Year_Received', 'Days_held']\ndf_train = df_train.drop(drop_cols, axis = 1)\ndf_test = df_test.drop(drop_cols, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Changing Consumer Disputed Column to 0 and 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Consumer disputed?'] = np.where(df_train['Consumer disputed?'] == \"Yes\", 1, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating Dummy Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"dum_cols = ['Product', 'Submitted via', 'Company response to consumer', 'Timely response?']\ndf_train_dummies = pd.get_dummies(df_train[dum_cols], prefix_sep = '_', drop_first = True)\ndf_test_dummies = pd.get_dummies(df_test[dum_cols], prefix_sep = '_', drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concating Dummy Variables and Dropping the Original Columns"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(dum_cols, axis = 1)\ndf_test = df_test.drop(dum_cols, axis = 1)\ndf_train = pd.concat([df_train, df_train_dummies], axis = 1)\ndf_test = pd.concat([df_test, df_test_dummies], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculating TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf = TfidfVectorizer()\nissues_cleaned_train = tf.fit_transform(df_train['Issues_cleaned']).toarray()\nissues_cleaned_test = tf.fit_transform(df_test['Issues_cleaned']).toarray()\ntf_columns_train = []\ntf_columns_test = []\nfor i in range(issues_cleaned_train.shape[1]):\n    tf_columns_train.append('Feature' + str(i+1))\nfor i in range(issues_cleaned_test.shape[1]):\n    tf_columns_test.append('Feature' + str(i+1))\nissues_train = pd.DataFrame(issues_cleaned_train, columns = tf_columns_train)\nissues_test = pd.DataFrame(issues_cleaned_test, columns = tf_columns_test)\nweights = pd.DataFrame(tf.idf_, index = tf.get_feature_names(), columns = ['Idf_weights']).sort_values(by = 'Idf_weights', ascending = False)\nweights.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replacing Issues_cleaned by Vectorized Issues"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop('Issues_cleaned', axis = 1)\ndf_test = df_test.drop('Issues_cleaned', axis = 1)\ndf_train = pd.concat([df_train, issues_train], axis = 1)\ndf_test = pd.concat([df_test, issues_test], axis = 1)\nFeature168 = [0] * 119606\ndf_test['Feature168'] = Feature168","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shape of Train and Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling the Data Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_scaled = pd.DataFrame(StandardScaler().fit_transform(df_train.drop('Consumer disputed?', axis = 1)), columns = df_test.columns)\ndf_test_scaled = pd.DataFrame(StandardScaler().fit_transform(df_test), columns = df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_columns = []\nfor i in range(df_train_scaled.shape[1]):\n    pca_columns.append('PC' + str(i+1))\npca_model = PCA()\npca_model.fit(df_train_scaled)\ndf_pca_train = pd.DataFrame(pca_model.transform(df_train_scaled), columns = pca_columns)\nexplained_info_train = pd.DataFrame(pca_model.explained_variance_ratio_, columns=['Explained Info']).sort_values(by = 'Explained Info', ascending = False)\nimp = []\nfor i in range(explained_info_train.shape[0]):\n    imp.append(explained_info_train.head(i).sum())\nexplained_info_train_sum = pd.DataFrame()\nexplained_info_train_sum['Variable'] = pca_columns\nexplained_info_train_sum['Importance'] = imp\nexplained_info_train_sum.head(60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        So 53 variables are making upto 80% of the information."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_columns = []\nfor i in range(53):\n    pca_columns.append('PC' + str(i+1))\npca_model = PCA(n_components = 53)\npca_model.fit(df_train_scaled)\ndf_pca_train = pd.DataFrame(pca_model.transform(df_train_scaled), columns = pca_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_model = PCA(n_components = 53)\npca_model.fit(df_test_scaled)\ndf_pca_test = pd.DataFrame(pca_model.transform(df_test_scaled), columns = pca_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Spliting the Data Sets Into X and Y"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_pca_train\ny = df_train['Consumer disputed?']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train, Validation and Test Data Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 17)\nX_test = df_pca_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shapes of the Data Sets"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Performance of Different Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), KNeighborsClassifier(), XGBClassifier()]\nmodel_names = ['LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'XGBClassifier']\naccuracy_train = []\naccuracy_val = []\nfor model in models:\n    mod = model\n    mod.fit(X_train, y_train)\n    y_pred_train = mod.predict(X_train)\n    y_pred_val = mod.predict(X_val)\n    accuracy_train.append(accuracy_score(y_train, y_pred_train))\n    accuracy_val.append(accuracy_score(y_val, y_pred_val))\ndata = {'Modelling Algorithm' : model_names, 'Train Accuracy' : accuracy_train, 'Validation Accuracy' : accuracy_val}\ndata = pd.DataFrame(data)\ndata['Difference'] = ((np.abs(data['Train Accuracy'] - data['Validation Accuracy'])) * 100)/(data['Train Accuracy'])\ndata.sort_values(by = 'Validation Accuracy', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"        LogisticRegression is the best model to build the model."},{"metadata":{},"cell_type":"markdown","source":"### Final Model and Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train, y_train)\ny_pred_test = lr.predict(X_test)\ny_pred_test = pd.DataFrame(y_pred_test, columns = ['Prediction'])\ny_pred_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exporting Predictions to CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test.to_csv('Prediction.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}