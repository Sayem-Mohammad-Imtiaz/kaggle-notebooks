{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nI recently found out about the concept of \"found\" poetry, where one takes an existing piece of text and breaks it up in an interesting way that takes a life of its own compared to the original. I had the idea to try to find news headlines that can be broken up in the haiku 5-7-5 syllable structure. After finding the Million News Headlines dataset on Kaggle, I knew I had what I needed to automate the search process!\n\nThis notebook shows what I used to give myself a dataset of potentially haiku-able headlines."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"markdown","source":"## Package installation\n\nTo start, we install the `syllables` and `cmudict` packages. `cmudict` has a large dictionary of words and the number of syllables in them. `syllables` will use heuristics to estimate the number of syllables in a word."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install syllables\n!pip install cmudict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import syllables\nimport cmudict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Syllable counting\n\nHaiku follow a 5-7-5 syllable structure. First, we will write a function to count the syllables in a word using the packages installed above. Then, we will write a haiku detection function that will test if a piece of text follows that syllable structure."},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nsyl_dict = cmudict.dict()\n\ndef num_syl_cmudict(word):\n    '''Count the number of syllables in a word using cmudict\n    \n    Args:\n        - word (str): the word to be counted\n        \n    Returns:\n        - An integer representing the number of syllables, \n          or None if the syllables couldn't be counted\n    '''\n    # Remove all punctuation from the word\n    word = word.translate(str.maketrans('', '', string.punctuation))\n    \n    # Check if word is in the cmudict\n    syls = syl_dict[word]\n    \n    if len(syls) == 0:\n        est = syllables.estimate(word)\n        return est\n    else:\n        ct = 0\n        # The cmudict actually lists all sounds in the word. Counting in\n        # this way allows you to identify the number of syllables.\n        # From StackOverflow:\n        # https://datascience.stackexchange.com/questions/23376/how-to-get-the-number-of-syllables-in-a-word\n        for sound in syls[0]:\n            if sound[-1].isdigit():\n                ct += 1\n        \n        return ct\n\ndef is_haiku(sent):\n    '''Checks if a given piece of text can be split into the haiku 5-7-5 syllable structure\n    \n    Args:\n        - sent (str): the sentence to be tested\n    \n    Returns:\n        - A boolean indicating whether the text is composed of \n          words that can be separated into a haiku\n    '''\n    words = sent.split(\" \")\n    \n    count = 0\n    hit_5 = False\n    hit_7 = False\n\n    # Loop through all the words and check for the \n    # intermediate milestones of a haiku structure\n    for word in words:\n        num_syl = num_syl_cmudict(word)\n\n        if num_syl is None:\n            return False\n        \n        count += num_syl\n        \n        # We hit the first five syllables - reset the counter\n        if count == 5 and not hit_5:\n            count = 0\n            hit_5 = True\n        \n        # If we hit five and then found 7 syllables, \n        # we have our second haiku line\n        if count == 7 and hit_5:\n            count = 0\n            hit_7 = True\n    \n    # If we hit 5 and 7 and there are only 5\n    # syllables left, we have a haiku-able text\n    return ((count == 5) and hit_5 and hit_7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process the dataframe and dump the output into CSV\n\nnews_df = pd.read_csv(\"../input/abcnews-date-text.csv\")\n\nnews_df['is_haiku'] = news_df['headline_text'].map(is_haiku)\nhaiku = news_df[news_df['is_haiku']]\nhaiku.to_csv('haiku_list.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(news_df['is_haiku'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that out of the million news headlines, we found 7486 headlines that were haiku-able! After manual inspection, you'll see that some of these headlines don't fit because abbreviations, etc. weren't counted correctly in the dataset, but this should be enough to get you going!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}