{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id='Top'></a>\n<center>\n<h1><u>Glasdoor Data Analyst Job Market Exploration</u></h1>\n<h3>Author: Robert Kwiatkowski</h3>\n</center>\n\n---\n\n<!-- Start of Unsplash Embed Code - Centered (Embed code by @BirdyOz)-->\n<div style=\"width:60%; margin: 20px 20% !important;\">\n    <img src=\"https://images.unsplash.com/photo-1599658880436-c61792e70672?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=720&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjEyMDd9\" class=\"img-responsive img-fluid img-med\" alt=\"person using macbook pro on black table \" title=\"person using macbook pro on black table \">\n    <div class=\"text-muted\" style=\"opacity: 0.5\">\n        <small><a href=\"https://unsplash.com/photos/eveI7MOcSmw\" target=\"_blank\">Photo</a> by <a href=\"https://unsplash.com/@mjessier\" target=\"_blank\">@mjessier</a> on <a href=\"https://unsplash.com\" target=\"_blank\">Unsplash</a>, accessed 24/09/2020</small>\n    </div>\n</div>\n<!-- End of Unsplash Embed code -->\n\n\nAs Data Analytics becames more and more popularfield it's worth get into details of job offers to know what is exactly required from candidates here. There is a great [report prepared by PwC](https://www.pwc.com/us/en/library/data-science-and-analytics.html) about future of this market I highly recommend you to read.\n\n\nHere, we will explore US data analyst job offers scrapped from Glassdoor and we will answer many insteresting questions, like:\n* What are salaries of data analysts in general?\n* In which state there is the biggest number of offers?\n* What skills are required?\nand many, many more..."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# importing basic libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DATA READING AND CLEANING**"},{"metadata":{},"cell_type":"markdown","source":"Data are stored in a CSV file."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/data-analyst-jobs/DataAnalyst.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"In our dataset there are: {} rows and {} columns.\".format(data.shape[0],data.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the general structure and form of our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of colums are of *object* type. However, \"Founded\" column contains a year so it can be cahnged to integer and \"Easy Apply\" is a *yes/no* column so it can be changed to boolean."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Founded\"] = data[\"Founded\"].astype(\"Int64\")\ndata[\"Easy Apply\"] = data[\"Easy Apply\"].astype(\"bool\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Column \"Unnamed: 0\" can be dropped or used as a new index. I will drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=[\"Unnamed: 0\"], inplace=True)\ndata.replace([-1,-1.0,\"-1\"],np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering and EDA**\n\nTo make our analysis more informative we will create additional columns.\n\nFirst we will check what tools are meantioned in a job description. We will check for:\n* [Python](https://www.python.org/) - a general purpose language\n* [R](https://www.r-project.org/) - a statistical programming language\n* [SQL](https://en.wikipedia.org/wiki/SQL) - Stadard Query Language (most common database querying language)\n* [Excel](https://en.wikipedia.org/wiki/Microsoft_Excel) - super popular Microsoft analytics product\n* [SAS](https://www.sas.com/en_us/solutions/analytics.html) - statistical software suite\n* [AWS](https://aws.amazon.com/) - Amazon Web Services - claud services provider\n* [Stata](https://www.stata.com/) - statistical software package\n* [Power BI](https://powerbi.microsoft.com/en-us/) - Microsoft interactive BI/visualisation software\n* [Microstrategy](https://www.microstrategy.com/en) - BI/visualisation software\n* [Tableau](https://www.tableau.com/) - BI/visualisation software\n* [VBA](https://en.wikipedia.org/wiki/Visual_Basic_for_Applications) - Microsoft's event-driven programming language"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data[\"Python\"] = data[\"Job Description\"].apply(lambda x: 1 if \"Python\" in x or \"python\" in x else 0)\ndata[\"R\"] = data[\"Job Description\"].apply(lambda x: 1 if \" R \" in x or \" R/\" in x or \"R,\" in x else 0)\n\ntoolset = [\"Python\", \"R\",\"SQL\", \"Excel\", \"SAS\",\"AWS\", \"Stata\", \"Power BI\", \"Microstrategy\", \"Tableau\", \"VBA\"]\n\nfor tool in toolset[2:]:\n    data[tool] = data[\"Job Description\"].apply(lambda x: 1 if tool in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tools_sum = data[toolset].sum().sort_values(ascending=False).div(len(data)).mul(100)\nplt.style.use('ggplot')\nax, fig = plt.subplots(figsize=(12,6))\nsns.barplot(tools_sum.index,\n            tools_sum)\nplt.title(\"DA tools in job offers\")\nplt.ylabel(\"Percentage\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In more than 60% of job offers SQL is meantioned. It looks like a core skill for data analyst so you may consider honning your skills in it on [hackerrank](https://www.hackerrank.com/) or on [leetcode](https://leetcode.com/). Moreover, here's a very good article I recommend to read:  [\"Top 5 SQL Analytic Functions Every Data Analyst Needs to Know\"](https://towardsdatascience.com/top-5-sql-analytic-functions-every-data-analyst-needs-to-know-3f32788e4ebb).  \n\nThe second place takes Excel (over 50%), a very common and popular product of Microsoft. Still being am analysis basic tool for many companies.  \nThen Python and Tableau followed by R and SAS.\n\nBelow we'll generate some [Venn diagrams](https://en.wikipedia.org/wiki/Venn_diagram) showing how some of these tools are combined with each other."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from matplotlib_venn import venn2, venn2_circles, venn3, venn3_circles\n\npy = data[\"Python\"].sum()\nr = data[\"R\"].sum()\nsql = data[\"SQL\"].sum()\nexcel = data[\"Excel\"].sum()\n\npy_r = data[(data[\"Python\"]==1) & (data[\"R\"]==1)][\"Python\"].sum()\npy_sql = data[(data[\"Python\"]==1) & (data[\"SQL\"]==1)][\"Python\"].sum()\nr_sql = data[(data[\"R\"]==1) & (data[\"SQL\"]==1)][\"Python\"].sum()\npy_r_sql = data[(data[\"Python\"]==1) & (data[\"R\"]==1) & (data[\"SQL\"]==1)][\"Python\"].sum()\npy_excel = data[(data[\"Python\"]==1) & (data[\"Excel\"]==1) & (data[\"SQL\"]==1)][\"Python\"].sum()\n\nfig, axes = plt.subplots(2,2,figsize=(10,8))\n\nvenn2(subsets = (py, r, py_r), set_labels = (\"Python\", \"R\"), ax=axes[0][0], set_colors=('red', 'green'))\nvenn2_circles(subsets = (py, r, py_r), ax=axes[0][0])\n\nvenn2(subsets = (py, sql,py_sql), set_labels = (\"Python\", \"SQL\",), ax=axes[0][1], set_colors=('red', 'blue'))\nvenn2_circles(subsets = (py, sql,py_sql), ax=axes[0][1])\n\nvenn2(subsets = (r, sql, r_sql), set_labels = (\"R\", \"SQL\",), ax=axes[1][0], set_colors=('green', 'blue'))\nvenn2_circles(subsets = (r, sql, r_sql), ax=axes[1][0])\n\nvenn2(subsets = (py, excel, py_excel), set_labels = (\"Python\", \"Excel\",), ax=axes[1][1], set_colors=('green', 'yellow'))\nvenn2_circles(subsets = (py, excel, py_excel), ax=axes[1][1])\n\nfig.suptitle(\"Venn diagrams - DA tools in job offers\", size=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how three main languages (Python, R and SQL) combine with each other."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(8,8))\n\nvenn3(subsets = {\n    \"100\":py, \"010\":r, \"001\":sql,\n    \"110\":py_r, \"101\":py_sql, \"011\":r_sql,\n    \"111\":py_r_sql},\n    set_labels = (\"Python\", \"R\", \"SQL\"),\n    ax=ax)\n\nvenn3_circles(subsets = {\n    \"100\":py, \"010\":r, \"001\":sql,\n    \"110\":py_r, \"101\":py_sql, \"011\":r_sql,\n    \"111\":py_r_sql},\n    ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will investigate what are the most common job titles."},{"metadata":{"trusted":true},"cell_type":"code","source":"def job_name_cleaner(cell,pos):\n    try:\n        value = str(cell).split(\",\")[pos]\n        return value\n    except:\n        return np.nan\n    \ndata[\"Job Title 1\"] = data[\"Job Title\"].apply(lambda x: job_name_cleaner(x,0))\ndata[\"Job Title 2\"] = data[\"Job Title\"].apply(lambda x: job_name_cleaner(x,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jobT_1 = data[\"Job Title 1\"].value_counts(normalize=True).mul(100)\nprint(\"There are {} various job titles.\".format(len(jobT_1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot 20 most common job titles."},{"metadata":{"trusted":true},"cell_type":"code","source":"jobT_1 = data[\"Job Title 1\"].value_counts(normalize=True).mul(100)\n\nax, fig = plt.subplots(figsize=(14,6))\nsns.barplot(x=jobT_1.index[:20], \n            y=jobT_1.values[:20])\nplt.ylabel(\"Percentage\")\nplt.xticks(rotation=70, ha=\"right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definitely the most basic name - simply a \"Data Analyst\" - is the most popular. Followed by a position with a specified level like: Senior Data Analyst and a Junior Data Analyst. We can see that there are also variations of these names and levels like \"Sr. Data Analyst\", \"Data Analyst I\", \"Data Analyst III\" or simply \"Analyst\".\n\nBecause of that we may want to consolidate some of the names to better reflec the Experience Levels. For this we will create new columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"def experience(job):\n    for w in [\"Junior Data Analyst\", \"Jr.\", \"Data Analyst I\", \"Jr\", \"1\"]:\n        if w in job:\n            return \"Junior\"    \n    for w in [\"Senior\", \"III\", \"Lead\", \"Sr\", \"Sr.\", \"3\", \"Principal\", \"Master\"]:\n        if w in job:\n            return \"Senior\"\n    else:\n        return \"Regular/Other\"\n\ndata[\"Exp. Level\"] = data[\"Job Title 1\"].apply(experience)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jobT_2 = data[\"Exp. Level\"].value_counts(normalize=True).mul(100)\n\nax, fig = plt.subplots(figsize=(12,6))\nplt.pie(jobT_2.values, labels=jobT_2.index, autopct='%1.1f%%', shadow = True, startangle=90, colors=[\"#fccb05\",\"#059efc\",\"#36fa28\"], textprops={\"size\":14})\nplt.title(\"Job offers exerience levels\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Over 70% of job offers are with a generic level title or can be treated as a regular level. Many general-level job offeres contain names specific to a given domain like: \"Marketing Data Analyst\", \"Financial Data Analyst\", \"Data Management Analyst\", etc.\n\nAround 22% of job offers are senior level. \n\nOnly around 7% of job offers are aimed for junior-level which is an obvious problem for anyone who is freshly graduated or doesn't have any previous experience in this domain.  \n\nLet's look now what are the salaries in various locations and how many are there. This will require a little bit of cleaning because they are stored as a text with an estimated range."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def salary_cleaner(cell,pos):\n    if cell == -1:\n        return np.nan\n    else:\n        try:\n            value = str(cell).split(\"K\")[pos].replace(\"$\",\"\").replace(\"-\",\"\")\n            return int(value)\n        except:\n            return np.nan\n    \ndata[\"lower_salary\"] = data[\"Salary Estimate\"].apply(lambda x: salary_cleaner(x,0))\ndata[\"upper_salary\"] = data[\"Salary Estimate\"].apply(lambda x: salary_cleaner(x,1))\ndata[\"average_salary\"] = (data[\"lower_salary\"]+data[\"upper_salary\"])/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locations_salaries = data.groupby([\"Location\"])[[\"lower_salary\",\"upper_salary\",\"average_salary\",\"Job Title\"]].mean().round(1)\nlocations_salaries[\"offers\"] = data.groupby([\"Location\"])[[\"Job Title\"]].count()\nlocations_salaries = locations_salaries.sort_values(by=[\"average_salary\"], ascending=False)\nlocations_salaries.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top of the list is occupied by cities in California. However a city-level is a bit too granual. Let's compare salaries in various states. For this we need more data cleaning."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"locations = data[\"Location\"].str.split(r\",\",expand=True)\nlocations.columns = [\"City\",\"State\",\"temp\"]\nlocations.drop([\"temp\"],axis=1,inplace=True)\n\n#dealing with \"... ,Arapahoe, CO\" syntax\nlocations[locations[\"State\"]==\" Arapahoe\"] = \" CO\"\nlocations[\"State\"] = locations[\"State\"].str.strip()\n\n# concatenating\ndata = pd.concat([data,locations],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_salaries = data.groupby([\"State\"])[[\"lower_salary\",\"upper_salary\",\"average_salary\"]].mean().round(1)\nstates_salaries[\"offers\"] = data.groupby([\"State\"])[[\"average_salary\"]].count()\nstates_salaries = states_salaries.sort_values(by=[\"average_salary\"], ascending=False)\nstates_salaries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax, fig = plt.subplots(figsize=(14,6))\nsns.barplot(x=states_salaries.index, \n            y=states_salaries[\"average_salary\"])\nplt.ylabel(\"Salary [k$]\")\nplt.xticks(rotation=70, ha=\"right\")\nplt.title(\"Average Salaries in various US states\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our database is incomplete because it contains only job offers from 19 states. However, from available data we observe:\n* The **biggest number of job offers** is from **California** (626) and **Texas** (394)\n* The **highest average salaries** are in **California** and **Illiois**\n* The least amount of job offers are in Sansas, South Calorina and Georgia - everywehere less than 4 \n* The lowest average salaries are in Utah and Georgia\n\nLet's create a choropleth map from this what we have."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nfig = go.Figure(data=go.Choropleth(\n    locations=states_salaries.index, # Spatial coordinates\n    z = states_salaries['average_salary'], # Data to be color-coded\n    locationmode = 'USA-states', # set of locations match entries in `locations`\n    colorscale = 'Reds',\n    colorbar_title = \"Average salary [k$]\",\n))\n\nfig.update_layout(\n    title_text = 'Average salary',\n    geo_scope='usa', # limite map scope to USA\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's worth checking what industries are mostly looking for data analysts as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"industries = data[\"Industry\"].value_counts(normalize=True).mul(100)\n\nplt.style.use('ggplot')\nax, fig = plt.subplots(figsize=(14,6))\nsns.barplot(x=industries.index[:20], \n            y=industries.values[:20])\nplt.ylabel(\"Percentage\")\nplt.xticks(rotation=70, ha=\"right\")\nplt.text(15,16, \"No. of industries: {}\".format(len(industries)), size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First two places are taken by generic \"IT services\" and \"Staffing & Outsourcing\". By looking at following places we can see that the following idustries are hiring as well:\n* Healthcare and Biotech/pharmaceutical\n* Financial institutions and banks\n* Advertising/marketing\n* Insurance\n* Colleges and Universities  \n\nNow let's investigate what sizes of companies we are dealing with."},{"metadata":{"trusted":true},"cell_type":"code","source":"sizes = data[\"Size\"].value_counts(normalize=True).mul(100)\n\nplt.style.use('ggplot')\n\nax, fig = plt.subplots(figsize=(12,6))\nsns.barplot(x=sizes.index, \n            y=sizes.values,\n            order = ['1 to 50 employees', '51 to 200 employees',\n                  '201 to 500 employees', '501 to 1000 employees',\n                  '1001 to 5000 employees', '5001 to 10000 employees',\n                  '10000+ employees', 'Unknown'])\nplt.ylabel(\"Percentage\")\nplt.xticks(rotation=70, ha=\"right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The barchart above shows that there is no strong trend but job offers are posted often by smaller companies (up to 200 employees). However, big ones (1000+ employess) are hiring as well."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data[\"Company Name\"] = data[\"Company Name\"].apply(lambda x: str(x).split(\"\\n\")[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Company Name\"].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TOP 5 companies in terms of job offers overall are:\n* [Staffigo](https://www.staffigo.com/) - IT staffing and recruiting company\n* [Diverse Lynx](https://www.diverselynx.com/) - IT staffing and recruiting\n* [Lorven Technologies Inc  ](https://www.lorventech.com/) - IT staffing and recruiting\n* [Kforce](https://www.kforce.com/) - IT staffing and recruiting\n* [Robert Half](https://www.roberthalf.com/) - IT staffing and recruiting\nAs you see staffing and recruiting agencies are posting quite a number of job offers of Glassdor.  \n\nWhat about Healthcare industry?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Industry\"]==\"Health Care Services & Hospitals\"][[\"Company Name\",\"Headquarters\"]].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the Healthcare and Hospitals category:\n* [Cedars-Sinai](https://www.cedars-sinai.org/) - a non-profit hospital in Los Angeles\n* [NYU Langone Health](https://nyulangone.org/) - a healthcare provider\n* [Kaiser Permanente](https://healthy.kaiserpermanente.org/) - one of the largest US healthcare provider\n* [Mount Sinai Medical Center](https://www.mountsinai.org/) - a hospital in New York\n* [IPRO](https://ipro.org/) - a non-profit health organisation"},{"metadata":{},"cell_type":"markdown","source":"Now it's time for Computer Hardware and Software category:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"Industry\"]==\"Computer Hardware & Software\"][[\"Company Name\",\"Headquarters\"]].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here the top companies are:\n* [Apple](https://www.apple.com/) - a well known software/hardware brand\n* [APN Software Services](http://www.apninc.com/) - an offshore outsourcing company\n* [Microsoft Corporation](https://www.microsoft.com/de-de/) - a multinational technology corporation\n* [Intuit](https://www.intuit.com/) - a company developing software for finance and accouting\n* [Autodesk](https://www.autodesk.com/) - a company developing engineering software (e.g. CAD systems)"},{"metadata":{},"cell_type":"markdown","source":"I'm still working on this notebook. If you like it please upvote. \n\nIf you have any questions of suggestions please write in commenst."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}