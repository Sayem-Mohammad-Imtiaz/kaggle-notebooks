{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import the data","metadata":{"id":"NJfBxoaw3Fni"}},{"cell_type":"code","source":"!wget https://www.dropbox.com/sh/ld6fx87zdvlwxiz/AACbD2hgIL5CCzEY19nvXbpDa?dl=0 # Import the data from dropbox","metadata":{"id":"1M2a3onr2Rq0","outputId":"9c23d2ed-128a-49c9-c226-d96dcb708c65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /content/AACbD2hgIL5CCzEY19nvXbpDa?dl=0 # unzip the data","metadata":{"id":"7wgZCH0O3P5o","outputId":"259693e7-d02d-418f-f630-43acfc4f6115"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Data","metadata":{"id":"BJ9B2jK93qs-"}},{"cell_type":"code","source":"# Import basic modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns","metadata":{"id":"P5Upbybl3rvf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/content/train_s3TEQDk.csv\") # Read the train file\ntest = pd.read_csv(\"/content/test_mSzZ8RL.csv\") # Read the test file","metadata":{"id":"32fkawg_324x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show first 10 rows of training set\ntrain.head(10)","metadata":{"id":"S6pAaCYh4AaD","outputId":"0d65f2e5-ba09-4b21-f624-08ab0cf1bb0a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info() #Extract the basic information from the data like dtypes of features, number of non-null values","metadata":{"id":"A_iexBRH4FC1","outputId":"ca11c07b-65c1-4ccf-f801-620d11ed3bd8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"id":"w6iclQdF4aRd","outputId":"9150b49c-eb61-4067-f99b-bfa9bb97b5f0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Credit_Product feature have some null values.**","metadata":{"id":"lyrbyGWn6gTI"}},{"cell_type":"code","source":"train.isnull().sum() # Check the count for null values in feature","metadata":{"id":"XfXxFeGm6cYF","outputId":"2be21207-c5e9-4b66-f6cd-bbeabf89a1cc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"id":"WOti-0lg6oj3","outputId":"b62c8848-5d45-433d-87f1-4da3331a6257"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the null columns from training and testing set\n\nnull_columns_train = [col for col in train.columns if train[col].isnull().sum() !=0]\nnull_columns_test = [col for col in test.columns if test[col].isnull().sum() !=0]\n\n# Print the percentage of null values in each column\ndef perc_null_vals(null_columns, data, dataset_type = None):\n  total_val_counts = data.shape[0] # Total values in the dataset\n  for col in null_columns:\n    null_val_counts = data[col].isnull().sum() # number of null values in the dataset\n    perc_null_vals = float(null_val_counts)*100/total_val_counts\n    print(\"The percentage of null values in {} in the {} set is {:.3f}%\".format(col, dataset_type, perc_null_vals))\n\n# Call the above function\nperc_null_vals(null_columns_train, train, \"train\")\nperc_null_vals(null_columns_test, test, \"test\")","metadata":{"id":"lq0GSioy6rRu","outputId":"f4cdb2a8-f933-4833-d801-bb412b3e0e62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Almost equal percentage of null values are present in both the dataset.**","metadata":{"id":"GH3Zw8Tr8xEY"}},{"cell_type":"markdown","source":"# EDA on trainset","metadata":{"id":"YVls7G0r-_xx"}},{"cell_type":"code","source":"train.head()","metadata":{"id":"gnM3CxqQ_DXx","outputId":"072d3056-44ed-47c6-c90e-e5c609d9a8d7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Occupation'].value_counts()","metadata":{"id":"Zk2JM-f4ALCM","outputId":"10ffac3f-6dd4-43f2-bf33-84c2c9d1da58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for unique values in the categorical columns\ncat_cols = [cols for cols in train.select_dtypes('O').columns]\n\ndef print_unique_vals(data, columns):\n  # iterate over each column and print the unique values in each categorical column as well as their counts\n  for col in columns:\n    print(\"Unqiue values in {} are\".format(col))\n    print(data[col].value_counts())\n    print()\n\n# Call the above method\nprint_unique_vals(train, cat_cols)","metadata":{"id":"GqWzr26n7FYT","outputId":"d919381a-53f3-4e9d-a865-55761c27dd09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check similarly for test set\ncat_cols_test = [col for col in test.select_dtypes('O').columns]\nprint_unique_vals(test, cat_cols_test)","metadata":{"id":"ty2eCi_P_TrH","outputId":"308cd69b-31f6-48d5-bb0a-d68a7977d834"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Every Categorical column other than ID and Region_Code have same subcategories in both train and test set**","metadata":{"id":"SORLwbW6BT-_"}},{"cell_type":"code","source":"# Create a new column called is_lead_text for plotting a pairplot\ntrain['Is_Lead_text'] = train['Is_Lead'].apply(lambda x : \"Yes\" if x==1 else \"No\")\n\n# Create a copy of train set\ntrain_copy = train.copy()\ntrain_copy.drop('Is_Lead',axis = 1, inplace=True)\n\n# Plot the pairplot\nsns.pairplot(train_copy, hue = \"Is_Lead_text\")\nplt.show()","metadata":{"id":"1hi6eP6u_Vwy","outputId":"8a7ebeeb-2d76-4f4e-eaad-69626b28a3df"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract numerical columns and plot scatter plots between each\nnum_cols = [col for col in train_copy.select_dtypes('int')]\n\n# Check the distribution of the numerical features\ntrain_copy.hist(figsize=(12,8))\nplt.show()\n\n# Check for class imbalance\nsns.countplot(x = train_copy['Is_Lead_text'])\nplt.grid()\nplt.show()\n\n# Check for class count w.r.t every other categorical_column\nsns.countplot(x = train_copy['Is_Lead_text'], hue=train_copy['Gender'])\nplt.grid()\nplt.show()\n\nsns.countplot(x = train_copy['Is_Lead_text'], hue=train_copy['Is_Active'])\nplt.grid()\nplt.show()\n\nsns.countplot(x = train_copy['Is_Lead_text'], hue=train_copy['Occupation'])\nplt.grid()\nplt.show()\n\nsns.countplot(x = train_copy['Is_Lead_text'], hue=train_copy['Channel_Code'])\nplt.grid()\nplt.show()\n\nsns.countplot(x = train_copy['Is_Lead_text'], hue=train_copy['Credit_Product'])\nplt.grid()\nplt.show()","metadata":{"id":"Naz1irHaBxws","outputId":"fd880be8-86c3-468d-b2b7-9712761bb762"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy.head()","metadata":{"id":"-RNhk_4GLeUJ","outputId":"ea8ec8ef-6ff0-47a8-a1da-a148b0f9a3fa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot boxplots w.r.t Is_Lead_text\nsns.boxplot(x=train_copy['Credit_Product'], y=train_copy['Avg_Account_Balance'])\nplt.show()\n\nsns.boxplot(x=train_copy['Credit_Product'], y=train_copy['Age'])\nplt.show()\n\nsns.boxplot(x=train_copy['Credit_Product'], y=train_copy['Vintage'])\nplt.show()","metadata":{"id":"i0tqtvvsN5H2","outputId":"723d587d-e031-4ea1-b7f0-ad0623e02e83"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n1.   Those between age 55-60 or Vintage between 60-80 have a Credit_Product.\n2.   Those between age 30-40 do not have a Credit_Product.\n\n","metadata":{"id":"YEiQoSMqPNhu"}},{"cell_type":"code","source":"# Fill na in credit_product\ndef fill_na(data, null_indices):\n  for i in null_indices:\n    if  (55 <= train['Age'].iloc[i] <=60)  and (60 <= train['Vintage'].iloc[i] <= 40):\n      train['Credit_Product'].iloc[i] = \"Yes\"\n    elif 30 <= train['Age'].iloc[i] <= 40:\n      train['Credit_Product'].iloc[i] = \"No\"\n\n\n# Find null indices\nnull_indices = train[train['Credit_Product'].isnull() == True].index\n\n# Call the above method and fill the null values\nfill_na(train, null_indices=null_indices)","metadata":{"id":"dfQwPJhoONK2","outputId":"676c2763-89fb-4f7f-8bda-775c1716defe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"id":"wndUn2kvT6IG","outputId":"fa417228-d28a-4f34-d4a4-52724618b623"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Credit_Product'].value_counts()","metadata":{"id":"EZhDp32CWTq6","outputId":"781746eb-7dd3-409d-b332-55564f274f39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For rest of the null values introduce a new category of \"Unknown\"\ntrain.fillna('Unkown', inplace=True)","metadata":{"id":"t30J8SL4Wh4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Similarly use fill_na(user defined function on test set)\nnull_indices_test = test[test['Credit_Product'].isnull()==True].index\nfill_na(test, null_indices_test)","metadata":{"id":"M6w7yLlCWnB0","outputId":"af8f13b8-eac2-4e15-f5da-fd68aa1f773c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum() # this logic did not work on test set, fill the null vlaues with unknown brand","metadata":{"id":"eJBPH-SSXGw9","outputId":"8e46508c-f45c-4280-ee5e-47acc59c83b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.fillna('Unknown', inplace=True)","metadata":{"id":"PyNliQsjXIa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for null values\ntrain.isnull().sum()","metadata":{"id":"M-ERHm3XXVMF","outputId":"ce2aa7df-8bce-46a9-e005-1ee69f20f68f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"id":"rM5Ire-CXY5_","outputId":"e3de8aa3-6445-4dba-929b-8133550a1f03"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{"id":"7l5YelACXcwk"}},{"cell_type":"code","source":"train.head(10)","metadata":{"id":"bjWdpaZOXabj","outputId":"f3418a49-a168-4413-8e5d-14837b307c90"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the is_lead_text column, ID and Region_Code\ntrain.drop(['ID', 'Region_Code', 'Is_Lead_text'], axis=1, inplace=True)","metadata":{"id":"1DsZxV5NXf7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode the columns\ncat_cols_updated = [cols for cols in train.select_dtypes('O').columns]\ncat_cols_updated","metadata":{"id":"OOYnEPgrXxTb","outputId":"c6d56aa0-4ff5-415f-88b4-43d2cb924168"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndef encoder(data, cat_cols):\n\n  for col in cat_cols:\n    le = LabelEncoder()\n    data[col] = le.fit_transform(data[col].values.reshape((-1,1)))\n  return data\n","metadata":{"id":"g7z3EJ32YFkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_data = encoder(train, cat_cols_updated) # use the encoder function","metadata":{"id":"0rVjFoHMYqmg","outputId":"794f2e0f-579e-44b4-87dd-e929f9567c6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"id":"W__XSuJ2ZGx6","outputId":"4b8e6c66-7d5e-4ed6-ce17-fcfb1d1df2d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store the Sample ID of the test set\ntest_ID = test['ID']","metadata":{"id":"I4JjF5WNbI7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop(['ID', 'Region_Code'],axis=1, inplace=True)\ncat_cols_test_updated = [cols for cols in test.select_dtypes('O').columns]","metadata":{"id":"05ipAqmge0pM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols_test_updated","metadata":{"id":"G0ksqlHqfn5V","outputId":"46ddbb7f-a8c7-4898-a4f8-2d565bb1875f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the encoder funciton\nencoded_data_test = encoder(test, cat_cols_test_updated)","metadata":{"id":"Xw-CD2isZGHc","outputId":"309a47e5-0af1-47e4-874d-ff3f38371bbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_data_test.head()","metadata":{"id":"UoZtgYetYugs","outputId":"cdf70e9e-fc4c-4ba5-ef49-d6cce23fbcd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(encoded_data.corr(), annot=True)\nplt.show()","metadata":{"id":"c8kb4Z2Koobj","outputId":"d94e9ede-1a88-44b6-e044-7900dfb11c3e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the training and testing data\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef scaled_data(data):\n  for col in data.columns:\n    # Min Max Scaler object\n    mms = MinMaxScaler()\n    data[col] = mms.fit_transform(data[col].values.reshape((-1,1)))\n  return data","metadata":{"id":"bbSEcYZqZEzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_training_data = scaled_data(encoded_data.drop('Is_Lead', axis=1))\nfinal_testing_data = scaled_data(encoded_data_test)","metadata":{"id":"qNiJrlTBgO3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_training_data.head()","metadata":{"id":"tWfZsRp8yOeZ","outputId":"fa7a6245-9fc5-4376-c660-0e73e71cdaf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_training_data.columns)","metadata":{"id":"GeMmFdnGybkO","outputId":"e490a567-8999-4f88-b54e-cbcfcf7c3ef1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(final_testing_data.columns)","metadata":{"id":"s0arvCEcySW1","outputId":"e991cdab-f7d4-4f8a-d77a-fcd04fc34d9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learninig Modelling","metadata":{"id":"Bfa7caZUgoCM"}},{"cell_type":"code","source":"final_training_data.head()","metadata":{"id":"JJLnV_UWgTMw","outputId":"a614a986-69d3-485d-b7bd-983bb6273605"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_variable = encoded_data['Is_Lead'] # Store the target variable","metadata":{"id":"3O1whupbgr76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model selection \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n\n# Split the training data\nX_train, X_test, y_train, y_test = train_test_split(final_training_data, target_variable, test_size=0.2, random_state=42)","metadata":{"id":"2cShMHaigx_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to compute all the metrics\ndef compute_metrics(y_true, y_pred, y_score, model):\n\n  # 1. Accuracy Score\n  acc_score = accuracy_score(y_true=y_true, y_pred=y_pred)\n\n  # 2. ROC_AUC_Score\n  roc_score = roc_auc_score(y_true=y_true, y_score=y_score)\n\n  # 3. Precision Score\n  prec = precision_score(y_true=y_true, y_pred=y_pred)\n\n  # Recall Score\n  rec = recall_score(y_true=y_true, y_pred=y_pred)\n\n  # Create a df of all the metrics\n  df_metrics = pd.DataFrame(np.array([acc_score, roc_score, prec, rec]).reshape((1,4)), columns=[\"Accuracy\", \"ROC_AUC_Score\", \"Precision\", \"Recall\"], index=[model])\n  return df_metrics","metadata":{"id":"ziIV4nq5pOLe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{"id":"in7hH-FgirsJ"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV # Logistic Regression Model\n\n# Model object\nlg_clf = LogisticRegressionCV(cv=3, verbose=1, random_state=42, n_jobs=-1)\n\n# fit the model\nlg_clf.fit(X_train, y_train)","metadata":{"id":"6VLAzCKVhVp8","outputId":"3ce44edf-717e-4030-d4bd-02a312cd5279"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predicitons on the test set and compute the metrics\npredictions_1 = lg_clf.predict(X_test)\nprediction_prob1 = lg_clf.predict_proba(X_test)\nprediction_prob1 = prediction_prob1[ : ,1]","metadata":{"id":"J8m_u551hYZa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg_results = compute_metrics(y_true = y_test, y_pred = predictions_1, y_score = prediction_prob1, model = \"Logistic Regression\")","metadata":{"id":"MOrtUNgBl4T-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg_results","metadata":{"id":"K73n7cZ0qYIP","outputId":"9468110f-61c1-430f-9595-7cf6dcf73d27"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree Classifier","metadata":{"id":"6BbxEh6ioXiS"}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Model object\ndt_clf_default = DecisionTreeClassifier() # Default Model\n\n# Fit the model\ndt_clf_default.fit(X_train, y_train)","metadata":{"id":"neqVb2nomG7d","outputId":"b2b542fc-152e-488b-ae58-ac48ddedd25f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions and compute metrics\npredictions_2 = dt_clf_default.predict(X_test)\nprediction_prob2 = dt_clf_default.predict_proba(X_test)\nprediction_prob2 = prediction_prob2[ : ,1]\n\n# Compute the metrics\ndt_clf_default_metrics = compute_metrics(y_true=y_test, y_pred=predictions_2, y_score=prediction_prob2, model = \"Decision Tree Default\")\ndt_clf_default_metrics","metadata":{"id":"P-939YiKpS1c","outputId":"7a421dc1-c4b8-4629-9f40-22d3e9d371ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter Tuning\n\n# set parameters\ncriterion = [\"ginin\", \"entropy\"]\nsplitter = [\"best\", \"random\"]\nmax_depth = [None, 10, 20, 30]\nmin_samples_split = [2,3,4,5,6,8,9,10]\nmin_samples_leaf = [1,2,3,4,5]\nmin_weight_fraction_leaf = [ 0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\nmax_features = [\"auto\", \"sqrt\", \"log2\", None]\nclass_weight = [None, \"balanced\"]\n\n\n# Create a parameter grid\nparams = {\"criterion\" : criterion,\n          \"splitter\" : splitter,\n          \"max_depth\" : max_depth,\n          \"min_samples_split\" : min_samples_split,\n          \"min_samples_leaf\" : min_samples_leaf,\n          \"min_weight_fraction_leaf\" : min_weight_fraction_leaf,\n          \"max_features\" : max_features,\n          \"class_weight\" : class_weight\n          }\n\n# Model Object\ndt_clf = DecisionTreeClassifier(random_state=42)\n\n# Randomised Search CV\nrscv_dt_clf = RandomizedSearchCV(dt_clf, params, n_iter=20, n_jobs=-1, cv=3, verbose=1, random_state=42)\n\n# Fit the model\nrscv_dt_clf.fit(X_train, y_train)","metadata":{"id":"tfe1IUPXpr69","outputId":"c3af13dd-2771-40d3-e659-f2a7a8df3016"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_best_estimator = rscv_dt_clf.best_estimator_","metadata":{"id":"19NmBYrjtRG-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt_best_estimator.fit(X_train, y_train)","metadata":{"id":"Xg_8MCqDuOHN","outputId":"1313498e-2962-4b3a-fb8a-cb1ec7028fcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predicitons and compute metrics\npredictions_3 = dt_best_estimator.predict(X_test)\nprediction_prob3 = dt_best_estimator.predict_proba(X_test)\nprediction_prob3 = prediction_prob3[ : , 1]\n\n# Compute the metrics\ndt_clf_best_est_results = compute_metrics(y_test, predictions_3, prediction_prob3, \"Decision Tree Best Estimator\")\ndt_clf_best_est_results","metadata":{"id":"iing3yBqvVRY","outputId":"fc15d69f-d9b3-446c-ca4b-312c559566da"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Classifier","metadata":{"id":"zhbhrU2dwoAo"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Model Object\nrf_clf_default = RandomForestClassifier() # Default Model\n\n# Fit the model\nrf_clf_default.fit(X_train, y_train)\n\n# Make Predicitons and Compute metrics\npredictions_4 = rf_clf_default.predict(X_test)\nprediction_prob4 = rf_clf_default.predict_proba(X_test)[ : , 1]\n\n# Compute the metrics\nrf_clf_default_results = compute_metrics(y_test, predictions_4, prediction_prob4 , model = \"Random Forest Default\")","metadata":{"id":"J5EP4KuXvwAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_clf_default_results","metadata":{"id":"gNDiWyE3xkee","outputId":"6279c106-f54b-4848-e148-2831f4f2cb7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter Tuninig\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'criterion' : [\"gini\", \"entropy\"],\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 500]\n}\n# Create a based model\nrf = RandomForestClassifier()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\n\n# Fit the model\ngrid_search.fit(X_train, y_train)","metadata":{"id":"EkvDPBsuyNCc","outputId":"5ceea2fc-c79c-46ea-e841-84ea600b7c26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make Predicitons and Compute metrics\npredictions_8 = grid_search.predict(X_test)\nprediction_prob8 = grid_search.predict_proba(X_test)[ : , 1]\n\n# Compute the metrics\nrf_clf_best_results = compute_metrics(y_test, predictions_8, prediction_prob8 , model = \"Random Forest Best Estimator\")","metadata":{"id":"8inPq3vZ4r03"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{"id":"7mi6o5n7dkFQ"}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Model object\nxgb_clf = XGBClassifier()\n\n# Fit the object\nxgb_clf.fit(X_train, y_train)","metadata":{"id":"R5_z980Tyzpw","outputId":"dd62d9fd-e7ad-4354-c614-429d3df9d07c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions and compute metrics\npredictions_5 = xgb_clf.predict(X_test)\nprediction_prob5 = xgb_clf.predict_proba(X_test)[ : , 1]\n\n# compute the metrics\nxgb_clf_results = compute_metrics(y_test, predictions_5, prediction_prob5, model = \"XGB Classifier\")\nxgb_clf_results","metadata":{"id":"_i1j5BJRdwGY","outputId":"1564a65a-f2b3-409d-f0e5-13ea877111c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adaboost Classifier","metadata":{"id":"G4-utzgMf7ey"}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\n# default model\nadb_clf = AdaBoostClassifier()\n\n# Fit the model\nadb_clf.fit(X_train, y_train)\n\n# Make predictions and compute metrics\npredictions_5 = adb_clf.predict(X_test)\nprediction_prob5 = adb_clf.predict_proba(X_test)[ : ,1]","metadata":{"id":"YcoMw6hmeR13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adb_clf_results = compute_metrics(y_test, predictions_5, prediction_prob5, \"AdaBoost Classifier\")","metadata":{"id":"EJgWtDB-hD5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adb_clf_results","metadata":{"id":"Jh6xmFR3hPC9","outputId":"6fb8b2a3-7d5c-46bd-d4fd-e7e7c873c85d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM","metadata":{"id":"MO4M6tBwg2ls"}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Model object\nsvm_clf = SVC()\n\n# Fit the model\nsvm_clf.fit(X_train, y_train)\n\n# Make predictions\npredictions_6 = svm_clf.predict(X_test)\n#prediction_prob6 = svm_clf.predict_proba(X_test)[ : ,1]","metadata":{"id":"eTCjVEppg1S_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute metrics\nsvm_clf.decision_function(X_test)","metadata":{"id":"OyrHIkbthn2D","outputId":"7354fa57-9360-4de2-d01b-83f1ba177449"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Networks","metadata":{"id":"rBYaP2-BiM3c"}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\n\n\n# Build a sequential model\nmodel = Sequential()\n\n# Add layers\nmodel.add(Dense(50, activation='relu', input_shape = (X_train.shape[-1],)))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dropout(0.50))\nmodel.add(Dense(150, activation='relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# buld the model\nprint(model.summary())\n\n# Compile the model\nmetric = tf.metrics.AUC(from_logits=True)\nmodel.compile(optimizer='sgd', loss='binary_crossentropy', metrics=metric)\nhist = model.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=EarlyStopping(patience=10))","metadata":{"id":"rM7ssY3RiD3a","outputId":"b02c3aa3-6501-4525-b7f2-a611160e24f2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions and compute metrics\npredictions_7 = model.predict_classes(X_test)\nprediction_prob7 = model.predict_proba(X_test)\n\n# Compute metrics\nnn_model_metrics = compute_metrics(y_test, predictions_7, prediction_prob7, \"Neural Network\")\nnn_model_metrics","metadata":{"id":"OClFJL2lv62X","outputId":"e908165c-47cc-40a8-e51d-ec41451287f9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"VP94EDaukQVZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{"id":"SYqtVmEorY0Z"}},{"cell_type":"markdown","source":"## Approach 1\n\n\n*   Logistic Regression\n*   Decision Tree\n*   Random Forest Classifier\n*   XGBoost Classifier\n*   AdaBoost Classifier\n*   Neural Network\n\n\n\n\n\n","metadata":{"id":"kF6nImWDramY"}},{"cell_type":"code","source":"final_testing_data.rename(columns={'Credit_Product_Unknown' : 'Credit_Product_Unkown'}, inplace=True)","metadata":{"id":"iWS60l3hz96Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare the models\napproach_1_result_metrics = pd.concat([log_reg_results, \n                                       dt_clf_default_metrics, \n                                       dt_clf_best_est_results, \n                                       rf_clf_default_results,\n                                       xgb_clf_results,\n                                       adb_clf_results,\n                                       nn_model_metrics]).sort_values(['ROC_AUC_Score'], ascending=False)\napproach_1_result_metrics","metadata":{"id":"PWhCjXpm03QX","outputId":"45bcc43e-e100-41ac-be85-e22eaee02b0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions(model, model_object, data, id_column, path=\"/content/\"):\n\n  if model != \"NeuralNetwork\":\n    # make predictions\n    predictions = model_object.predict(data)\n  else:\n    predictions = model_object.predict_classes(data).reshape((-1,))\n\n  # Concatenate the predictions and the ID\n  prediction_df = pd.DataFrame({\"ID\" : test_ID, \"Is_Lead\" : predictions})\n\n  # store into .csv\n  dest = path + model + \"_\" + \"submissions.csv\"\n  prediction_df.to_csv(dest, index=False)","metadata":{"id":"mOfdgKXlraFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\"LogisticRegression\" : lg_clf, \n          \"DecisionTree\" : dt_best_estimator, \n          \"RandomForest\" : rf_clf_default,\n          \"XGBoost\" : xgb_clf,\n          \"AdaBoost\" : adb_clf,\n          \"NeuralNetwork\" : model\n          }\n\n# Iterate over the itemrs and Call the above method\nfor mod, model_obj in models.items():\n  make_predictions(model = mod, model_object=model_obj, data=final_testing_data, id_column = test_ID)","metadata":{"id":"glaSg3FJu0gf","outputId":"a94f7cf8-3a6d-49a6-b803-cc3e7645abd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_testing_data.shape","metadata":{"id":"fGzOddPoy3nk","outputId":"f18aaf3a-51ef-461e-c9db-195038a4119c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"APDkdOun2-m6"},"execution_count":null,"outputs":[]}]}