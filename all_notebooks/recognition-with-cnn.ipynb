{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport keras as kr\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport pickle\nimport os\nimport pandas as pd\nimport random\nfrom keras.preprocessing.image import ImageDataGenerator\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n\n################# Parameters #####################\n\npath = \"/kaggle/input/traffic-signs-classification/myData\" # folder with all the class folders\nlabelFile = '/kaggle/input/traffic-signs-classification/labels.csv' # file with all names of classes\nbatch_size_val=50  # how many to process together\nsteps_per_epoch_val=2000\nepochs_val=10 # how many time to do the process\nimageDimesions = (32,32,3)\ntestRatio = 0.2    # if 1000 images split will 200 for testing\nvalidationRatio = 0.2 # if 1000 images 20% of remaining 800 will be 160 for validation\nlimiting=10 # limit images by classes to test\n###################################################\n\n\ncount = 0\nimages = []\nclassNo = []\nmyList = os.listdir(path)\nprint(\"Total Classes Detected:\",len(myList))\nnoOfClasses=len(myList)\nprint(\"Importing Classes.....\")\nfor x in range (0,len(myList)):\n    myPicList = os.listdir(path+\"/\"+str(count))#[:limiting]\n    for y in myPicList:\n        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n        images.append(curImg)\n        classNo.append(count)\n    print(count, end =\" \")\n    count +=1\nprint(\" \")\nimages = np.array(images)\nclassNo = np.array(classNo)\n\n############################### Split Data\nX_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)\n\n# X_train = ARRAY OF IMAGES TO TRAIN\n# y_train = CORRESPONDING CLASS ID\n\n############################### TO CHECK IF NUMBER OF IMAGES MATCHES TO NUMBER OF LABELS FOR EACH DATA SET\nprint(\"Data Shapes\")\nprint(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\nprint(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\nprint(\"Test\",end = \"\");print(X_test.shape,y_test.shape)\nassert(X_train.shape[0]==y_train.shape[0]), \"The number of images in not equal to the number of lables in training set\"\nassert(X_validation.shape[0]==y_validation.shape[0]), \"The number of images in not equal to the number of lables in validation set\"\nassert(X_test.shape[0]==y_test.shape[0]), \"The number of images in not equal to the number of lables in test set\"\nassert(X_train.shape[1:]==(imageDimesions)),\" The dimesions of the Training images are wrong \"\nassert(X_validation.shape[1:]==(imageDimesions)),\" The dimesionas of the Validation images are wrong \"\nassert(X_test.shape[1:]==(imageDimesions)),\" The dimesionas of the Test images are wrong\"\n\n############################### READ CSV FILE\ndata=pd.read_csv(labelFile)\nprint(\"data shape \",data.shape,type(data))\n\n############################### DISPLAY SOME SAMPLES IMAGES  OF ALL THE CLASSES\nnum_of_samples = []\ncols = 5\nnum_classes = noOfClasses\nfig, axs = plt.subplots(nrows=num_classes, ncols=cols)#, figsize=(5, 300))\nfig.tight_layout()\nfor i in range(cols):\n    for j,row in data.iterrows():\n        x_selected = X_train[y_train == j]\n        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected)- 1), :, :], cmap=plt.get_cmap(\"gray\"))\n        axs[j][i].axis(\"off\")\n        if i == 2:\n            axs[j][i].set_title(str(j)+ \"-\"+row[\"Name\"])\n            num_of_samples.append(len(x_selected))\n\n\n############################### DISPLAY A BAR CHART SHOWING NO OF SAMPLES FOR EACH CATEGORY\nprint(num_of_samples)\nplt.figure(figsize=(12, 4))\nplt.bar(range(0, num_classes), num_of_samples)\nplt.title(\"Distribution of the training dataset\")\nplt.xlabel(\"Class number\")\nplt.ylabel(\"Number of images\")\nplt.show()\n\n############################### PREPROCESSING THE IMAGES\n\ndef grayscale(img):\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    return img\ndef equalize(img):\n    img =cv2.equalizeHist(img)\n    return img\ndef preprocessing(img):\n    img = grayscale(img)     # CONVERT TO GRAYSCALE\n    img = equalize(img)      # STANDARDIZE THE LIGHTING IN AN IMAGE\n    img = img/255            # TO NORMALIZE VALUES BETWEEN 0 AND 1 INSTEAD OF 0 TO 255\n    return img\n\nX_train=np.array(list(map(preprocessing,X_train)))  # TO IRETATE AND PREPROCESS ALL IMAGES\nX_validation=np.array(list(map(preprocessing,X_validation)))\nX_test=np.array(list(map(preprocessing,X_test)))\nplt.imshow(X_train[random.randint(0,len(X_train)-1)])\nplt.show()\n# cv2.imshow(\"GrayScale Images\",X_train[random.randint(0,len(X_train)-1)]) # TO CHECK IF THE TRAINING IS DONE PROPERLY\n\n############################### ADD A DEPTH OF 1\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\nX_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\nX_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n\n\n############################### AUGMENTATAION OF IMAGES: TO MAKEIT MORE GENERIC\ndataGen= ImageDataGenerator(width_shift_range=0.1,   # 0.1 = 10%     IF MORE THAN 1 E.G 10 THEN IT REFFERS TO NO. OF  PIXELS EG 10 PIXELS\n                            height_shift_range=0.1,\n                            zoom_range=0.2,  # 0.2 MEANS CAN GO FROM 0.8 TO 1.2\n                            shear_range=0.1,  # MAGNITUDE OF SHEAR ANGLE\n                            rotation_range=10)  # DEGREES\ndataGen.fit(X_train)\nbatches= dataGen.flow(X_train,y_train,batch_size=20)  # REQUESTING DATA GENRATOR TO GENERATE IMAGES  BATCH SIZE = NO. OF IMAGES CREAED EACH TIME ITS CALLED\nX_batch,y_batch = next(batches)\n\n# TO SHOW AGMENTED IMAGE SAMPLES\nfig,axs=plt.subplots(1,15,figsize=(20,5))\nfig.tight_layout()\n\nfor i in range(15):\n    axs[i].imshow(X_batch[i].reshape(imageDimesions[0],imageDimesions[1]))\n    axs[i].axis('off')\nplt.show()\n\n\ny_train = to_categorical(y_train,noOfClasses)\ny_validation = to_categorical(y_validation,noOfClasses)\ny_test = to_categorical(y_test,noOfClasses)\n\n############################### CONVOLUTION NEURAL NETWORK MODEL\ndef myModel():\n    no_Of_Filters=60\n    size_of_Filter=(5,5) # THIS IS THE KERNEL THAT MOVE AROUND THE IMAGE TO GET THE FEATURES.\n                         # THIS WOULD REMOVE 2 PIXELS FROM EACH BORDER WHEN USING 32 32 IMAGE\n    size_of_Filter2=(3,3)\n    size_of_pool=(2,2)  # SCALE DOWN ALL FEATURE MAP TO GERNALIZE MORE, TO REDUCE OVERFITTING\n    no_Of_Nodes = 500   # NO. OF NODES IN HIDDEN LAYERS\n    model= Sequential()\n    model.add((Conv2D(no_Of_Filters,size_of_Filter,input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n    model.add((Conv2D(no_Of_Filters, size_of_Filter, activation='relu')))\n    model.add(MaxPooling2D(pool_size=size_of_pool)) # DOES NOT EFFECT THE DEPTH/NO OF FILTERS\n\n    model.add((Conv2D(no_Of_Filters//2, size_of_Filter2,activation='relu')))\n    model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu')))\n    model.add(MaxPooling2D(pool_size=size_of_pool))\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(no_Of_Nodes,activation='relu'))\n    model.add(Dropout(0.5)) # INPUTS NODES TO DROP WITH EACH UPDATE 1 ALL 0 NONE\n    model.add(Dense(noOfClasses,activation='softmax')) # OUTPUT LAYER\n    # COMPILE MODEL\n    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n    return model\n\n\n############################### TRAIN\nmodel = myModel()\nprint(model.summary())\nhistory=model.fit_generator(dataGen.flow(X_train,y_train,batch_size=batch_size_val),steps_per_epoch=steps_per_epoch_val,epochs=epochs_val,validation_data=(X_validation,y_validation),shuffle=1)\n\n############################### PLOT\nplt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training','validation'])\nplt.title('loss')\nplt.xlabel('epoch')\nplt.figure(2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['training','validation'])\nplt.title('Acurracy')\nplt.xlabel('epoch')\nplt.show()\nscore =model.evaluate(X_test,y_test,verbose=0)\nprint('Test Score:',score[0])\nprint('Test Accuracy:',score[1])\n\n\n# STORE THE MODEL AS A PICKLE OBJECT\npickle_out= open(\"model_trained.p\",\"wb\")  # wb = WRITE BYTE\npickle.dump(model,pickle_out)\npickle_out.close()\n# cv2.waitKey(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n# import cv2\n# import pickle\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import keras as kr\n# from keras.models import Sequential\n# from keras.layers import Dense\n# from keras.optimizers import Adam\n# from keras.utils.np_utils import to_categorical\n# from keras.layers import Dropout, Flatten\n# from keras.layers.convolutional import Conv2D, MaxPooling2D\n# import cv2\n# from sklearn.model_selection import train_test_split\n# import pickle\n# import os\n# import pandas as pd\n# import random\n# from keras.preprocessing.image import ImageDataGenerator\n\n# imgOriginal = cv2.imread(\"/kaggle/input/traffic-signs-classification/myData/0/0_10002_1577671998.65016.jpg\")\n# labels=pd.read_csv('/kaggle/input/traffic-signs-classification/labels.csv')\n# #############################################\n\n# frameWidth= 640         # CAMERA RESOLUTION\n# frameHeight = 480\n# brightness = 180\n# threshold = 0.75         # PROBABLITY THRESHOLD\n# font = cv2.FONT_HERSHEY_SIMPLEX\n# ##############################################\n\n# # SETUP THE VIDEO CAMERA\n# cap = cv2.VideoCapture(0)\n# cap.set(3, frameWidth)\n# cap.set(4, frameHeight)\n# cap.set(10, brightness)\n# # IMPORT THE TRANNIED MODEL\n# pickle_in=open(\"model_trained.p\",\"rb\")  ## rb = READ BYTE\n# model=pickle.load(pickle_in)\n\n# def grayscale(img):\n#     img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n#     return img\n# def equalize(img):\n#     img = cv2.equalizeHist(img)\n#     return img\n# def preprocessing(img):\n#     img = grayscale(img)\n#     img = equalize(img)\n#     img = img/255\n#     return img\n\n# def getCalssName(classNo):\n#     return labels.loc[labels['ClassId']==classNo[0],'Name'].values[0]\n\n# # READ IMAGE\n# #     success, imgOrignal = cap.read()\n\n\n# # PROCESS IMAGE\n# #     img = np.array(imgOrignal)\n# img = cv2.resize(imgOriginal, (32, 32))\n# img = preprocessing(img)\n# plt.imshow(img)\n# plt.show()\n# #     cv2.imshow(\"Processed Image\", img)\n# img = img.reshape(1, 32, 32, 1)\n# #     cv2.putText(imgOrignal, \"CLASS: \" , (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n# #     cv2.putText(imgOrignal, \"PROBABILITY: \", (20, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n# # PREDICT IMAGE\n# predictions = model.predict(img)\n# classIndex = model.predict_classes(img)\n# probabilityValue =np.amax(predictions)\n# if probabilityValue > threshold:\n#     print(classIndex)\n#     print(getCalssName(classIndex))\n#     plt.text(1, 1, f\"CLASS: {classIndex} {getCalssName(classIndex)}\\nPROBABILITY: {round(probabilityValue*100,2)}%\" ,ha=\"left\",va=\"top\", bbox=dict(fill=False, edgecolor='red', linewidth=2))\n# #     plt.text(1, 5, f\"PROBABILITY: {round(probabilityValue*100,2)}%\", bbox=dict(fill=False, edgecolor='red', linewidth=2))\n\n# plt.imshow(imgOriginal)\n# plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}