{"cells":[{"metadata":{"_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199","_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86"},"cell_type":"markdown","source":"# House Prices Prediction\nReferences:\n* https://www.kaggle.com/learn/machine-learning\n* https://www.kaggle.com/helgejo/an-interactive-data-science-tutorial\n* http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7239f61f-43b3-4abb-9387-ab64a2d1adf2","_uuid":"55636ff2dbc1203ee69b0f7d9eb1096401c682e6","collapsed":true,"trusted":true},"cell_type":"code","source":"######################################################################\n# DEPENDENCES\n######################################################################\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\n\n# # Modelling Algorithms\nfrom sklearn.tree import DecisionTreeRegressor\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.naive_bayes import GaussianNB\n# from sklearn.svm import SVC\n# from sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestRegressor\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.ensemble import GradientBoostingClassifier\n\n# # Modelling Helpers\nfrom sklearn.metrics import mean_absolute_error\n# from sklearn.preprocessing import Imputer\n# from sklearn.preprocessing import Normalizer\n# from sklearn.preprocessing import scale\n# from sklearn.cross_validation import train_test_split\n# from sklearn.cross_validation import StratifiedKFold\n# from sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import train_test_split\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nsns.set_style( 'white' )\npylab.rcParams[ 'figure.figsize' ] = 8 , 6\n\n# Numeric attributes\nnumeric_attributes = ['MSSubClass','LotFrontage','LotArea','OverallQual','OverallCond',\n                      'YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF2','BsmtUnfSF',\n                      'TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea',\n                      'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\n                      'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars',\n                      'GarageArea','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch',\n                      'ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3bc52952-b718-431e-b835-a30618807e5b","_uuid":"c59a3ff4053c543c2e05bb1f93752dde3f1c41ed","collapsed":true,"trusted":true},"cell_type":"code","source":"######################################################################\n# HELPER FUNCTIONS\n######################################################################\n\ndef plot_histograms( df , variables , n_rows , n_cols ):\n    fig = plt.figure() # figsize = ( 16 , 12 ) )\n    for i, var_name in enumerate( variables ):\n        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n        df[ var_name ].hist( bins=10 , ax=ax )\n        ax.set_title(var_name)\n    fig.tight_layout()  # Improves appearance a bit.\n    plt.show()\n\ndef plot_pairwise_relationships(df, x_vars, y_vars):\n    sns.pairplot(data, y_vars=y_vars,x_vars=x_vars)\n    \ndef plot_triple_relationships(df, x, y, groupby, bars=True):\n    if bars:\n        sns.barplot(x=x, y=y, hue=groupby, data=df)\n    else:\n        sns.pointplot(x=x, y=y, hue=groupby, data=df);\n    \ndef plot_distribution( df , target , var , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , hue=var , aspect=4 , row = row , col = col )\n    facet.map( sns.kdeplot , target , shade= True )\n    facet.set( xlim=( 0 , df[ target ].max() ) )\n    facet.add_legend()\n\ndef plot_categories( df , cat , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , row = row , col = col )\n    facet.map( sns.barplot , cat , target )\n    facet.add_legend()\n\ndef plot_regression(df,x_var,y_var):\n    sns.jointplot(x=x_var, y=y_var, data=df, kind=\"reg\");\n    #sns.lmplot(x=x_var, y=y_var, data=df, hue=groupby);\n    \ndef plot_residuals(df,x_var,y_var):\n    sns.residplot(x=x_var, y=y_var, data=df, scatter_kws={\"s\": 80});\n    \ndef plot_prediction(X_test, y_test, y_prediction, y_variable, x_groupby_y):\n    df_test = pd.concat([X_test, y_test],axis=1)\n    df_prediction = pd.DataFrame(data=y_prediction,index=y_test.index,columns=[y_variable])\n    df_prediction = pd.concat([X_test, df_prediction],axis=1)\n    data_all = pd.concat(dict(data=df_test[x_groupby_y], model=df_prediction[x_groupby_y]),names=[\"kind\"]).reset_index()\n    sns.factorplot(x_groupby_y[0], x_groupby_y[2], \"kind\", data=data_all, col=x_groupby_y[1],kind=\"point\", linestyles=[\"-\", \"--\"], markers=[\"o\", \"D\"])\n\ndef plot_correlation_map( df , annot=True):\n    corr = df.corr()\n    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = annot, \n        annot_kws = { 'fontsize' : 12 }\n    )\n\ndef plot_correlation_cluster(df):\n    corr = df.corr()\n    sns.clustermap(data.corr())\n    \ndef describe_more( df ):\n    var = [] ; l = [] ; t = []\n    for x in df:\n        var.append( x )\n        l.append( len( pd.value_counts( df[ x ] ) ) )\n        t.append( df[ x ].dtypes )\n    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n    levels.sort_values( by = 'Levels' , inplace = True )\n    return levels\n\ndef plot_variable_importance( X , y ):\n    tree = DecisionTreeClassifier( random_state = 99 )\n    tree.fit( X , y )\n    plot_model_var_imp( tree , X , y )\n    \ndef plot_model_var_imp( model , X , y ):\n    imp = pd.DataFrame( \n        model.feature_importances_  , \n        columns = [ 'Importance' ] , \n        index = X.columns \n    )\n    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n    imp[ : 10 ].plot( kind = 'barh' )\n    print (model.score( X , y ))\n    \ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\ndef filter_numeric_predictors(data_1, y_variable, data_2=None):\n    data_1.dropna(axis=1,how='any',inplace=True)\n    if data_2 is not None:\n        data_2.dropna(axis=1,how='any',inplace=True)\n        attributes = set(data_train.columns).intersection(set(data_test.columns))\n        attributes.discard(y_variable)\n    else:\n        attributes = data.columns\n        attributes.drop(y_variable)\n    predictors = numeric_attributes.copy()\n    print('{} predictors'.format(len(predictors)))\n    to_delete = [p for p in predictors if p not in attributes]\n    for p in to_delete:\n        predictors.remove(p)\n    print('{} valid predictors'.format(len(predictors)))\n    return data_1,predictors,data_2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3c00e3ca-5e73-4af2-9cc7-8748e51e40da","_kg_hide-output":false,"_uuid":"a811f67234c6d7a4f01b1d4b01d5756c71bf7dc8","collapsed":true,"trusted":true},"cell_type":"code","source":"######################################################################\n# LOADING DATA\n######################################################################\n\nmain_file_path = '../input/train.csv'\ndata = pd.read_csv(main_file_path)\nprint('hello world!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}