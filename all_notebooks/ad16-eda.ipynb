{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Necessary Installs"},{"metadata":{"_uuid":"439849dd-bc2d-4bcc-a443-d1142276f788","_cell_guid":"4d42575b-7af9-4b5f-be9c-a8f81aff5711","trusted":true},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"9d887eae-fd11-48b9-a2b5-06419990ffc9","_cell_guid":"694a08e5-2128-47a9-a2d7-b10cb3347fc5","trusted":true,"scrolled":false},"cell_type":"code","source":"from pathlib import Path\nfrom fastcore.all import *\nimport numpy as np\nimport pandas as pd\nfrom pprint import pprint\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pdb\nfrom collections import OrderedDict, defaultdict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#To display all elements in a cell\nfrom IPython.core.interactiveshell import InteractiveShell  \nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7e2738a-f788-4456-8517-9ebf7a70b0a3","_cell_guid":"6ee709a0-ed56-404c-ad5a-243a6ce2d401","trusted":true,"scrolled":false},"cell_type":"code","source":"main = Path(\"../input/ads16-dataset\")\npart1 = main/'ADS16_Benchmark_part1'/'ADS16_Benchmark_part1'\npart2 = main/'ADS16_Benchmark_part2'/'ADS16_Benchmark_part2'\n\nads_p1 = part1/'Ads'/'Ads'\ncorpus_p1 = part1/'Corpus'/'Corpus'\nads_p2 = part2/'Ads'/'Ads'\ncorpus_p2 = part2/'Corpus'/'Corpus'\n\nads_l = sorted(ads_p1.ls() + ads_p2.ls())\ncorpus_l = sorted(corpus_p1.ls() + corpus_p2.ls())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Print contents of Ads directory\nprint(\"[INFO] Contents of the \\\"Ads\\\" directory:\")\nads_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#Print contents of Corpus directory\nprint(\"[INFO] Contents of the \\\"Corpus\\\" directory:\")\npprint(corpus_l)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring Directory Contents"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def image_grid(image_l, im_height, im_width, n_rows, n_cols):\n    \n    cnt = 0\n    \n    #Define grid dimensions\n    grid_height = im_height * n_rows\n    grid_width = im_width * n_cols\n    \n    #Define figure size dimensions\n    fig_height = int(5 * n_rows)\n    fig_width = int(5 * n_cols)\n    \n    #Create a new image canvas\n    comp_img = Image.new('RGB', (grid_width, grid_height))\n    \n    for i in range(0, grid_width, im_width):\n    \n        for j in range(0, grid_height, im_height):\n        \n            #Load the image and resize dimensions\n            im = Image.open(image_l[cnt])\n            im.thumbnail((im_height, im_width))\n            \n            #Paste it the new image canvas\n            comp_img.paste(im, (i, j))        \n            \n            #Increment counter\n            cnt += 1\n    \n    #Display the canvas\n    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n    ax.imshow(np.asarray(comp_img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"sample_ad = ads_l[0]\nsample_corpus = corpus_l[0]\nprint(\"[INFO] Contents of sample \\\"Ads\\\" folder:\")\nsample_ad.ls()\nprint(\"[INFO] Contents of sample \\\"Corpus\\\" folder:\")\nsample_corpus.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Print a grid of images\nimage_grid(image_l = sample_ad.ls(), im_height = 300, im_width = 300, n_rows = 1, n_cols = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"for file_path in sample_corpus.ls():\n    \n    if file_path.suffix == \".csv\":\n    \n        df_temp = pd.read_csv(file_path, sep=\";\", header=[0], nrows=25)\n        print(f\"\\n[INFO] Printing some contents of {file_path.name}: \\n\")\n        df_temp.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Inspect the contents of the -IM-NEG & -IM-POS folders\nim_neg = sample_corpus/\"U0001-IM-NEG\"\nim_pos = sample_corpus/\"U0001-IM-POS\"\n\nprint(f\"\\n[INFO] Printing contents of folder {im_neg.name}\\n\")\nimage_grid(image_l = im_neg.ls(), im_height = 200, im_width = 200, n_rows = 1, n_cols = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"print(f\"\\n[INFO] Printing contents of folder {im_pos.name}\\n\")\nimage_grid(image_l = im_pos.ls(), im_height = 200, im_width = 200, n_rows = 1, n_cols = 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Interlude: Thoughts on Data Folder Structure\n\n1. There are 20 Ad categories —> 300 Ads and 120 Users in total.\n2. Each Ad Category folder contains a collection of 15 image files. Paths to these 20 folders are contained in `ads_l` in the notebook. An Ad Category is considered to be \"clicked\" if it contains an advert that is \"clicked\" (Refer Point 9)\n3. 300 Ads —> 100 Rich Media Ads, 100 Image Ads and 100 Text Ads.\n3. Each User folder (for e.g. U0001) contains 6 CSV files and 2 folders. Path to each user are contained in `corpus_l`\n4. (CSV #1) U0001-INF.csv (14 cols, 1 row) contains personal information (e.g. Gender, Age, Income...).\n5. (CSV #2) U0001-PREF.csv (5 cols, 1 row) contains preferences (e.g. Most visited websites, most read books...). Each field is a CSV of categories (e.g. Comedy, Horror, Mystery...)\n6. (CSV #3) U0001-B5.csv (3 cols, 10 rows) contains answers to Big Five Inventory-10 personality test.\n7. (CSV #4 & #5) Both U0001-IM-POS.csv & U0001-IM-NEG.csv(5 cols, 2 rows each) refer to the contents of the respective folders and user reactions (e.g. \"my cats\" for an image in POS and \"violence\" for an image in NEG) to the same.\n8. (CSV #6) U0001-RT.csv (20 cols, 2 rows) contains user rating FOR each ad in each ad category along a Likert Scale ranging from +1 to +5. +4 and +5 corresponds to a \"click\" in the paper."},{"metadata":{},"cell_type":"markdown","source":"# Collecting Functions\n\nEach function corresponds to a particular CSV file in a User Folder.\n\nFor a given user, they accept dataframes and return Panda Series."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#For INF, PREF\ndef df_to_series(df):\n    \n    \"\"\"Accepts a dataframe and returns the squeezed Panda Series\"\"\"\n    \n    temp = df.copy()\n    inf_series = temp.squeeze(0)\n    return inf_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#For B5\ndef b5_df_to_ocean_series(df_b5):\n    \n    \"\"\"\n    Accepts a dataframe and returns a processed Pandas Series of Big Five Scores.\n    \n    Scoring the BFI-10 scales:\n    Extraversion: 1R, 6; Agreeableness: 2, 7R; Conscientiousness: 3R, 8; Neuroticism: 4R, 9;\n    Openness: 5R; 10 (R D item is reversed-scored)\n    \"\"\"                  \n    temp = df_b5.copy()\n    \n    #Drop Question# column\n    temp.drop(columns=[\"Question#\"], axis=1, inplace=True)\n    \n    #Scale the dataframe to lie between 1 and 5\n    temp += 3\n    \n    #Set the mask for reverse scores + Reverse the scores\n    reverse_mask = [0, 2, 3, 4, 6]\n    temp.iloc[reverse_mask, :] = 6 - temp.iloc[reverse_mask, :]\n    \n    #Create a dictionary for the different scores \n    idx_dict = {\n        \"E_score\" : [0, 5], \n        \"A_score\" : [1, 6], \n        \"C_score\" : [2, 7], \n        \"N_score\" : [3, 8], \n        \"O_score\" : [4, 9],\n    }\n    \n    #Create another dictionary to be converted into a dataframe\n    scores_dict = {col: temp.iloc[row_l, :].squeeze(1).sum() for col, row_l in idx_dict.items()}\n    ocean_series = pd.Series(scores_dict)\n    \n    return ocean_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#For IM-POS & IM-NEG\ndef pos_neg_df_to_series(df):\n    \n    working_dict = {}\n    temp = df.copy()\n    column_names = temp.columns.tolist()\n    #mod_column_names = [(col_name + \"_location\", col_name + \"_reason\") for col_name in column_names]    \n    \n    #Row 0 —> Paths, Row 1 —> Some strings\n    temp_dict = {col: (temp.loc[0, col], temp.loc[1, col])  for col in column_names}\n    \n    #Iterate through each key and transform tuple into 2 key-value pairs\n    for key, value in temp_dict.items():\n        \n        loc_key = key + \"_location\"\n        reason_key = key + \"_reason\"\n        working_dict[loc_key] = value[0]\n        working_dict[reason_key] = value[1]\n    \n    im_series = pd.Series(working_dict)\n    \n    return im_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#For RT\ndef rt_df_to_series(df):\n    \n    temp = df.copy()\n    temp.drop(index=[0], inplace=True)\n    col_names = temp.columns.tolist()\n    for cat_num, cat in enumerate(col_names):\n        list_responses = temp[cat].str.split(\",\").loc[1] #1 because 0 index was deleted - 1 remains\n        for ad_num, response in enumerate(list_responses):\n            new_col_name = \"Cat\" + str(cat_num + 1) + \"_\" + str(ad_num + 1)\n            temp.loc[1, new_col_name] = response\n    \n    #Drop the old columns\n    temp.drop(columns=col_names, inplace=True)\n    rt_series = pd.to_numeric(temp.squeeze())\n    \n    return rt_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df = pd.DataFrame()\n\nfor corpus in corpus_l:\n\n    result_d = OrderedDict()\n\n    for file_path in corpus.ls():\n\n        if file_path.suffix == \".csv\":        \n\n            df_temp = pd.read_csv(file_path, sep=\";\", header=[0])\n            #print(f\"\\n[INFO] Working on {file_path.stem}: \\n\")\n            if (\"INF\" in file_path.name) or (\"PREF\" in file_path.name):\n                result = df_to_series(df_temp)\n            elif \"B5\" in file_path.name:\n                result = b5_df_to_ocean_series(df_temp)\n            elif \"IM\" in file_path.name:\n                result = pos_neg_df_to_series(df_temp)\n            elif \"RT\" in file_path.name:\n                result = rt_df_to_series(df_temp)\n            else:\n                print(f\"{file_path.name} not recognized\")\n            result.to_dict(OrderedDict)\n            result_d.update(result)\n\n    df_temp = pd.DataFrame(result_d, columns=result_d.keys(), index=[0])\n    df = df.append(df_temp, ignore_index=True)\n\"\"\"\nresult_d = OrderedDict()\n\nfor file_path in sample_corpus.ls():\n\n    if file_path.suffix == \".csv\":        \n\n        df_temp = pd.read_csv(file_path, sep=\";\", header=[0])\n        #print(f\"\\n[INFO] Working on {file_path.stem}: \\n\")\n        if (\"INF\" in file_path.name) or (\"PREF\" in file_path.name):\n            result = df_to_series(df_temp)\n        elif \"B5\" in file_path.name:\n            result = b5_df_to_ocean_series(df_temp)\n        elif \"IM\" in file_path.name:\n            result = pos_neg_df_to_series(df_temp)\n        elif \"RT\" in file_path.name:\n            result = rt_df_to_series(df_temp)\n        else:\n            print(f\"{file_path.name} not recognized\")\n        #result.head()\n        result.to_dict(OrderedDict)\n        result_d.update(result)\n\ndf = pd.DataFrame(result_d, columns=result_d.keys(), index=[0])\ndf.head()\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.tolist()\ndf.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}