{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div width=\"100%\">\n    <img width=\"100%\" src=\"https://storage.googleapis.com/kaggle-datasets-images/228/482/a520351269b547c89afe790820a1087e/dataset-cover.jpeg\"/>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.utils import shuffle\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.display import clear_output\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"dataset\" style=\"color:#301202; background:#d26231; border:0.5px dotted;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n    </center>\n</h1>","metadata":{}},{"cell_type":"code","source":"path = '../input/pima-indians-diabetes-database/diabetes.csv'\ndf = pd.read_csv(path)\ndf.fillna(df.mean(), inplace=True)\ndf = shuffle(df)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"Age\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feat in features:\n    df[feat] /= df[feat].max()\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = plt.figure(figsize=(14,8))\n_ = sns.heatmap(df.corr(), \n        xticklabels=df.corr().columns,\n        yticklabels=df.corr().columns)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = df.drop('Outcome', axis=1)\nlabels = df['Outcome']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n                                        features, labels, test_size=0.20, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"ann\" style=\"color:#301202; background:#d26231; border:0.5px dotted;\"> \n    <center>Artificial neural network\n        <a class=\"anchor-link\" href=\"#ann\" target=\"_self\">¶</a>\n    </center>\n</h1>","metadata":{}},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(16, activation='sigmoid', input_shape=(8, )),\n    tf.keras.layers.Dense(32, activation='sigmoid'),\n    tf.keras.layers.Dense(64, activation='sigmoid'),\n    tf.keras.layers.Dense(16, activation='sigmoid'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n  ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss Function","metadata":{}},{"cell_type":"code","source":"loss_object = tf.keras.losses.BinaryCrossentropy(\n                    from_logits=False, label_smoothing=0, \n                    name='binary_crossentropy'\n                )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss(model, x, y, training):\n    y_ = model(x, training=training)\n\n    return loss_object(y_true=y, y_pred=y_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient function","metadata":{}},{"cell_type":"code","source":"def grad(model, inputs, targets):\n    with tf.GradientTape() as tape:\n        loss_value = loss(model, inputs, targets, training=True)\n    return loss_value, tape.gradient(loss_value, model.trainable_variables)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01, rho=0.1, \n                                        momentum=0.1, epsilon=1e-03)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"y_temp = y_train.values\nX, y = X_train.values, y_temp.reshape(y_temp.shape[0], 1)\n\ny_temp = y_test.values\nX_val, y_val = X_test.values, y_temp.reshape(y_temp.shape[0], 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 3001\n\ntrain_loss_results = []\ntrain_accuracy_results = []\n\ntest_loss_results = []\ntest_accuracy_results = []\n\nloss_fn = tf.keras.metrics.Mean()\nacc_fn = tf.keras.metrics.BinaryAccuracy()\n\nfor epoch in range(num_epochs):\n    epoch_loss_avg = tf.keras.metrics.Mean()\n    epoch_accuracy = tf.keras.metrics.BinaryAccuracy()\n\n    batches = np.array_split(np.arange(len(X)), len(X) // 8)\n    batches = [b.tolist() for b in batches]\n\n    for batch in batches:\n        X_b, y_b = X[batch], y[batch]\n        # Optimize the model\n        loss_value, grads = grad(model, X_b, y_b)\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n        # Track progress\n        epoch_loss_avg.update_state(loss_value)\n        epoch_accuracy.update_state(y_b, model(X_b, training=True))\n\n    # End epoch\n    train_loss_results.append(epoch_loss_avg.result())\n    train_accuracy_results.append(epoch_accuracy.result())\n        \n    test_loss_results.append(loss_fn(y_val, model(X_val)).numpy())\n    test_accuracy_results.append(acc_fn(y_val, model(X_val)).numpy())\n\n    if epoch % 300 == 0:\n        print(\"Epoch {:3d}: Train_Loss:{:3.3f}, Train_Accuracy:{:3.3f}, Test_Loss:{:3.3f}, Test_Accuracy:{:3.3f}\"\n              .format(epoch, epoch_loss_avg.result(), epoch_accuracy.result(),\n                      test_loss_results[-1], test_accuracy_results[-1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analysis","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2, sharex=True, figsize=(14, 8))\nfig.suptitle('Training Metrics')\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(train_loss_results)\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(train_accuracy_results)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2, sharex=True, figsize=(14, 8))\nfig.suptitle('Testing Metrics')\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(test_loss_results)\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(test_accuracy_results)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 id=\"boosted\" style=\"color:#301202; background:#d26231; border:0.5px dotted;\"> \n    <center>Boosted Trees\n        <a class=\"anchor-link\" href=\"#boosted\" target=\"_self\">¶</a>\n    </center>\n</h1>","metadata":{}},{"cell_type":"markdown","source":"## Feature columns","metadata":{}},{"cell_type":"code","source":"fc = tf.feature_column\nNUMERIC_COLUMNS = list(df.drop('Outcome', axis=1).columns)\n\ndef one_hot_cat_column(feature_name, vocab):\n    return fc.indicator_column(\n      fc.categorical_column_with_vocabulary_list(feature_name,\n                                                 vocab))\nfeature_columns = []\n\nfor feature_name in NUMERIC_COLUMNS:\n    feature_columns.append(fc.numeric_column(feature_name,\n                                           dtype=tf.float32))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Boosted Trees Classifier","metadata":{}},{"cell_type":"code","source":"n_batches = 4\n\nest = tf.estimator.BoostedTreesClassifier(feature_columns,\n                                          n_batches_per_layer=n_batches)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create dataset","metadata":{}},{"cell_type":"code","source":"NUM_EXAMPLES = len(y_train)\n\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n    def input_fn():\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n        if shuffle:\n            dataset = dataset.shuffle(NUM_EXAMPLES)\n        # For training, cycle thru dataset as many times as need (n_epochs=None).\n        dataset = dataset.repeat(n_epochs)\n        # In memory training doesn't use batching.\n        dataset = dataset.batch(NUM_EXAMPLES)\n        return dataset\n    return input_fn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input_fn = make_input_fn(X_train, y_train)\neval_input_fn = make_input_fn(X_test, y_test, shuffle=False, n_epochs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Boosted Trees","metadata":{}},{"cell_type":"code","source":"NUM_EXAMPLES = len(y_train)\n\nest.train(train_input_fn, max_steps=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analysis","metadata":{}},{"cell_type":"code","source":"result = est.evaluate(eval_input_fn)\nclear_output()\n\nprint(pd.Series(result))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_dicts = list(est.predict(eval_input_fn))\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n\nprobs.plot(kind='hist', bins=20, title='predicted probabilities')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}