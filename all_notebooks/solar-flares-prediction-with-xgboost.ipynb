{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThis notebook predicts the frequency (measured by daily number) and length of solar flares. Any feedback is welcome and appreciated! <br><br>\nSee the two cells below to get started."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as pyplot\n%matplotlib inline\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.tsa import stattools\n\nimport sklearn\nimport sklearn.model_selection as skms\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom xgboost import XGBRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"def score_dataset(X_train, y_train, X_test, y_test):\n    # low learning rate and many rounds to prevent underfitting\n    model = XGBRegressor(eval_metric='mae',n_estimators=5000, learning_rate = 0.05)\n    # early_stopping_rounds to prevent overfitting\n    model.fit(X_train, y_train, early_stopping_rounds = 8, eval_set = [(X_test, y_test)], verbose=False)\n    predictions = model.predict(X_test)\n    # mae, predictions for each X_test\n    return mean_absolute_error(y_test, predictions), predictions # mean_absolute_error metric","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Predict Solar Flare Peak to End Time"},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering and Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\npath = \"/kaggle/input/instruments-solarflares/flares_and_instruments_v2.csv\"\ndf = pd.read_csv(path, header=0, index_col=0) \n# format time data from string to datetime\ndf['JJJ Start'] = pd.to_datetime(df['JJJ Start'])\ndf['JJJ Peak'] = pd.to_datetime(df['JJJ Peak'])\ndf['JJJ End'] = pd.to_datetime(df['JJJ End'])\n# Feature engineering using the time between Start and Peak to help predict \"Peak to end\" time\ndf['time to peak'] = (df['JJJ Peak'] - df['JJJ Start']).dt.seconds\ndf['peak to end'] = (df['JJJ End'] - df['JJJ Peak']).dt.seconds # predicting this with the model later\n# Feature engineering #2 (time difference between current flare and last)\narr = np.zeros(12455) # initialize array\nfor i in range(1, len(arr)): # compute differences\n    arr[i] = arr[i] + (df['JJJ Peak'][i] - df['JJJ Peak'][i-1]).seconds\narr[0] = np.mean(arr) \n# set column\ndf['diff time'] = arr \n# don't include columns that are already represented or can't be known at time of prediction\ndf = df.drop(['JJJ End', 'JJJ Start', 'JJJ Peak'], axis=1) \n# display data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features (besides the ones I \"engineered\") are described in \"flares_and_instruments_v2.csv\" on the database's home page. They measure details about the solar flares (like class and position) and the instruments used for observing them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform \"JJJ Class\" values from categorical to numerical\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols = pd.DataFrame(OH_encoder.fit_transform(df[['JJJ Class']]))\nOH_cols.index = df.index\ndf = df.drop(['JJJ Class'], axis=1) # replaced by columns with numerical values\ndf = pd.concat([df, OH_cols], axis=1)\ndf.head() # show (1 if the flare fits the \"class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe() # show statistics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting 'peak to end' (include in y, not X)\nX, y = df.drop(['peak to end'], axis=1), df['peak to end']\n# 80% for training, 20% for test data\nX_train, X_test, y_train, y_test = skms.train_test_split(X, y, train_size=0.8, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions using XGBoost\nmae, predictions = score_dataset(X_train, y_train, X_test, y_test)\nprint('MAE %.2f' % mae) # Mean absolute error to two decimal places","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the results\nplot_y_test = y_test[:100] # first 100 correct ones\nplot_predictions = predictions[:100] # first 100 predictions\npyplot.figure(figsize=(20, 5))\npyplot.plot(plot_y_test, label = 'Expected')\npyplot.plot(plot_predictions, label='Predicted')\npyplot.legend()\npyplot.show() # show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Predict Solar Flare Frequency"},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# read data\npath = \"/kaggle/input/instruments-solarflares/flares_and_instruments_v2.csv\"\ndf = pd.read_csv(path, header=0, index_col=0)\n# organize data by solar flares per day\ntime = pd.to_datetime(df['JJJ Start'])\ndf = time.groupby(time.dt.floor('d')).size()\n# show data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of solar flares vs. Time\npyplot.figure(figsize=(30, 6))\npyplot.plot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many past days are correlated with prediction for current day\nplot_acf(df)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [] # organizing the features\nn_in = 7 \n# Shift the data so that the last 7 days are features for the current day\nfor i in range(n_in, 0, -1):\n    features.append(df.shift(i))\nfeatures.append(df.shift(0))\n# combine the features\ndf = pd.concat(features, axis=1)\n# drop rows with missing values\ndf.dropna(inplace = True)\n# Prediction (y) is last feature; exclude it from X\nX, y = df.values[:, :-1], df.values[:, -1]\n# 80% training data, 20% for test data\nX_train, X_test, y_train, y_test = skms.train_test_split(X, y, train_size=0.8, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions using XGBoost\nmae, predictions = score_dataset(X_train, y_train, X_test, y_test)\nprint('MAE %.2f' % mae) # Mean absolute error to two decimal places","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the results\npyplot.figure(figsize=(30, 6))\nplt_y_test = y_test[:100] # first 100 correct ones\nplt_predictions = predictions[:100] # first 100 predictions\npyplot.plot(plt_y_test, label='Expected')\npyplot.plot(plt_predictions, label='Predicted')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}