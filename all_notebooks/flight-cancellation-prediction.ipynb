{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Flight Cancellation Prediction  \n\nGiven *data about US flights in 2015*, let's try to predict whether a given flight will be **cancelled**.\n\nWe will use a logistic regression model to make our predictions. "},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/flight-delays/flights.csv', nrows=50000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_encode(df, column_dict):\n    df = df.copy()\n    for column, prefix in column_dict.items():\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Remove columns with more than 25% missing values\n    missing_columns = df.loc[:, df.isna().mean() >= 0.25].columns\n    df = df.drop(missing_columns, axis=1)\n    \n    # Drop unneeded columns\n    df = df.drop(['YEAR', 'MONTH', 'FLIGHT_NUMBER', 'TAIL_NUMBER'], axis=1)\n    \n    # One-hot encode nominal feature columns\n    df = onehot_encode(\n        df,\n        column_dict={\n            'AIRLINE': 'AL',\n            'ORIGIN_AIRPORT': 'OA',\n            'DESTINATION_AIRPORT': 'DA'\n        }\n    )\n    \n    # Fill remaining missing values with column means\n    remaining_na_columns = df.loc[:, df.isna().sum() > 0].columns\n    for column in remaining_na_columns:\n        df[column] = df[column].fillna(df[column].mean())\n    \n    # Split df into X and y\n    y = df['CANCELLED'].copy()\n    X = df.drop('CANCELLED', axis=1).copy()\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n   \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(model, X_test, y_test):\n    \n    model_acc = model.score(X_test, y_test)\n    print(\"Test Accuracy: {:.2f}%\".format(model_acc * 100))\n    \n    y_true = np.array(y_test)\n    y_pred = model.predict(X_test)\n    \n    cm = confusion_matrix(y_true, y_pred)\n    clr = classification_report(y_true, y_pred, target_names=[\"NOT CANCELLED\", \"CANCELLED\"])\n    \n    plt.figure(figsize=(8, 8))\n    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n    plt.xticks(np.arange(2) + 0.5, [\"NOT CANCELLED\", \"CANCELLED\"])\n    plt.yticks(np.arange(2) + 0.5, [\"NOT CANCELLED\", \"CANCELLED\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/M0ND7Gpdt14"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}