{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CAST RECOGNITION","metadata":{}},{"cell_type":"code","source":"!pip install face_recognition","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import face_recognition as fr\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport face_recognition\nimport numpy as np\nfrom time import sleep\nimport PIL.Image\nimport PIL.ImageDraw\n\ndef get_encoded_faces():\n    \"\"\"\n    :return: dict of (name, image encoded)\n    \"\"\"\n    encoded = {}\n    i = 1\n    print(\"Detecting face...\")\n    for dirpath, dnames, fnames in os.walk(\"../input/my-train/\"):\n        for f in fnames:\n            if f.endswith(\".jpg\") or f.endswith(\".png\"):\n                face = fr.load_image_file(\"../input/my-train/\" + f)\n                landmarks = fr.face_landmarks(face)\n                if(f == \"Gwyneth_Paltrow.jpg\"):\n                    print(\"\\nThe face landmarks for \"+ '{}'.format(f)+' are:')\n                    print(landmarks)\n                    print(\"\\n\")\n                #print(i,\"==>\",end =\"\")\n                \n                if not landmarks:\n                    break\n                else:\n                    encoding = fr.face_encodings(face)[0]\n                    encoded[f.split(\".\")[0]] = encoding\n                    if(f == \"Gwyneth_Paltrow.jpg\"):\n                        print(\"Face-encoded values for \"+'{}'.format(f)+\" are: \")\n                        print(encoded[f.split(\".\")[0]])\n                i = i+1\n                   \n    return encoded","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify_face(im):\n    \"\"\"\n    will find all of the faces in a given image and label\n    them if it knows what they are\n\n    :param im: str of file path\n    :return: list of face names\n    \"\"\"\n    faces = get_encoded_faces()\n    faces_encoded = list(faces.values())\n    known_face_names = list(faces.keys())\n    \n    img = cv2.imread(im, 1)\n    \n    face_locations = face_recognition.face_locations(img)\n    unknown_face_encodings = face_recognition.face_encodings(img, face_locations)\n\n    face_names = []\n    for face_encoding in unknown_face_encodings:\n        matches = face_recognition.compare_faces(faces_encoded, face_encoding)\n        name = \"Cast not found\"\n        face_distances = face_recognition.face_distance(faces_encoded, face_encoding)\n        print()\n        #for i, face_distance in enumerate(face_distances):\n            #print(\"The test image has a distance of {:.2} from known image #{}\".format(face_distance, i))\n            #print(\"- With a very strict cutoff would the test image match the known image? {}\".format(face_distance < 0.5))\n            #print()\n        best_match_index = np.argmin(face_distances)\n        if matches[best_match_index]:\n            name = known_face_names[best_match_index]\n\n        face_names.append(name)\n        pil_image = PIL.Image.fromarray(img)\n\n        for (top, right, bottom, left), name in zip(face_locations, face_names):\n            cv2.rectangle(img, (left-20, top-20), (right+20, bottom+20), (255, 0, 0), 2)\n            cv2.rectangle(img, (left-20, bottom -15), (right+20, bottom+20), (255, 0, 0), cv2.FILLED)\n    plt.figure(figsize = (5,5))\n    plt.rcParams[\"axes.grid\"] = False\n    plt.imshow(img) \n    plt.show()\n    return face_names ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef final(path):\n    print(\"The cast in the movie poster are:\")\n    print(cast)\n    print()\n    prediction(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = '../input/test-data/img_15.jpg'\ncast = classify_face(test_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PERFORMANCE METRICS","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nlabels_face = []\ny_test_face = []\nypred_face = []\ni = 0\nfor files in os.listdir('../input/acc-test'):\n    labels_face.append(files)\n    img = Image.open('../input/acc-test/' + files)\n    y_test_face.append(i)\n    i = i+1\n    ypred_face.append(classify_face('../input/acc-test/' + files))\nprint(y_test_face)\nprint(labels_face)\nprint(ypred_face)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ypred_face)\nprint(labels_face)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypreds = np.array(ypred_face).reshape(1,-1)[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ny_pred_mapped = pd.Series(ypreds).map({'Ajay_Devgan':0,'hansika_motwani':1,'Jayam_Ravi':2,'Aswin':3,'Brad_Pitt':4,'Abishek_Bacchan':5,'Aishwarya_rai':6}).astype(int)\nprint(y_pred_mapped)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_print = pd.Series(ypreds)\ny_pred_print","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Acuuracy of the model:\")\nprint(accuracy_score(y_pred_mapped,y_test_face)*100,\"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix, classification_report\nprint(classification_report(y_pred_mapped, y_test_face))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"face_matrix = multilabel_confusion_matrix(y_test_face,y_pred_mapped)\ndisplay(face_matrix)\nface_matrix[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\ntest_val = y_test_face\npred_val = y_pred_mapped\npred_val = np.round(pred_val)\nc_matrix = confusion_matrix(test_val, pred_val)\ndf_cm = pd.DataFrame(c_matrix, columns=['Abishek_Bacchan','Jayam_Ravi','Aishwarya_rai','Hansika','Ajay_Devgan','Aswin','Brad'], index = ['Abishek_Bacchan','Jayam_Ravi','Aishwarya_rai','Hansika','Ajay_Devgan','Aswin','Brad'])\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (5,5))\nsn.set(font_scale=1.4) \nsn.heatmap(df_cm, cmap=\"PuRd\", annot=True,fmt='',annot_kws={\"size\": 16})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}