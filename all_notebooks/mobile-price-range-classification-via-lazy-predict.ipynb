{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mobile Price Classification using lazy predict\n\nlazy predict is a library that trains a large number of models on a given dataset to determine which one will work best for it\n\nthe goal is to predict a price range for a smartphone based on its specifications.\n\nthe specifcations include a total of 20 columns ranging from 3g availability to touch screen and amount of ram so a very extensive feature set. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/mobile-price-classification/train.csv\")\ntest = pd.read_csv(\"../input/mobile-price-classification/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"after loading in the data, lets take a look at it "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check data types\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if there are any null columns\ntrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe the data\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explortary Data Analaysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of samples for each price range\nfig, ax = plt.subplots(figsize = (10, 4))\nsns.countplot(x ='price_range', data=train)\nplt.xlabel(\"Class Label\")\nplt.ylabel(\"Number of Samples\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"perfectly balanced, as all things should be."},{"metadata":{"trusted":true},"cell_type":"code","source":"# find correlation\ncorr_mat = train.corr()\n\n# each columns correlation with the price\ncorr_mat['price_range']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert all to positive and sort by value\nabs(corr_mat).sort_values(by=['price_range'])['price_range']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can make a few observations from above\n- the ram is the most deciding factor in price range with the highest correlation.\n- the amount of pixels do matter after all.\n- number of cores does not correlate with the price much (could be due to the cores being weak, for example most midrangers nowadays have 8 cores while the Apple A series SoCs have at most 6 cores and still perform miles better)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# battery correlation plot\nfig, ax = plt.subplots(figsize=(14,10))\nsns.boxenplot(x=\"price_range\",y=\"battery_power\", data=train,ax = ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# individual correlation graphs\n\n# get all columns and remove price_range\ncols = list(train.columns.values)\ncols.remove('price_range')\n\n# plot figure\nfig, ax = plt.subplots(7, 3, figsize=(15, 30))\nplt.subplots_adjust(left=0.1, bottom=0.05, top=1.0, wspace=0.3, hspace=0.2)\nfor i, col in zip(range(len(cols)), cols):\n    ax = plt.subplot(7,3,i+1)\n    sns.lineplot(ax=ax,x='price_range', y=col, data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot full heatmap\nfigure(figsize=(20, 14))\nsns.heatmap(corr_mat, annot = True, fmt='.1g', cmap= 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling\nknowing which model to build for a dataset is not an easy task, specially when the columns that have a high correlation with the target variable are less than half the total columns, its also a task that is time consuming in making and tuning these models that is why we will use the LazyPredict library to show us the results of various models without any tuneing and we will implement the top 3 models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract target column\ntarget = train['price_range']\n\n# drop target column from dataset\ntrain.drop('price_range', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# install and import lazypredict\n!pip install lazypredict\nfrom lazypredict.Supervised import LazyClassifier\n\n# split training dataset to training and testing\nX_train, X_test, y_train, y_test = train_test_split(train, target,test_size=.3,random_state =123)\n\n# make Lazyclassifier model(s)\nlazy_clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n\n# fit model(s)\nmodels, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the first 5 models F1 score\ntop = models[:5]\nfigure(figsize=(14, 7))\nsns.lineplot(x=top.index, y=\"F1 Score\", data=top)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we are not really intrested in the predictions dataframe here because we already know those values and they're part of the training dataset"},{"metadata":{},"cell_type":"markdown","source":"from above we can see that the best algorithm for this type of task is logistic regression followed by Discriminant Analysis models and followed closely by GB models.\n\n### Implemented models\n- logistic regression\n- Linear Discriminant Analysis\n- light GBM classifier\n\nthe reason behing skipping on the Quadratic Discriminant Analysis model is because its of the same family as Linear Discriminant Analysis and produces similar results, we also want to implement a diverse range of models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n# Logistic regression\nlog_clf = LogisticRegression(random_state=0).fit(train, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the id column from test to match the size of train\ntest.drop('id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get predictions on test dataset and convert it to a dataframe\nlog_preds = pd.DataFrame(log_clf.predict(test), columns = ['log_price_range'])\n\nlog_preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n# Linear Discriminant Analysis\nlda_clf = LinearDiscriminantAnalysis().fit(train, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get predictions on test dataset and convert it to a dataframe\nlda_preds = pd.DataFrame(lda_clf.predict(test), columns = ['lda_price_range'])\n\nlda_preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n# lightgbm model\nlgbm_clf = LGBMClassifier(objective='multiclass', random_state=5).fit(train, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get predictions on test dataset and convert it to a dataframe\nlgbm_preds = pd.DataFrame(lgbm_clf.predict(test), columns = ['lgbm_price_range'])\n\nlgbm_preds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### comparing model results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dataframe with 3 columns and index from any of the predicted dataframes\nresults = pd.DataFrame(index=log_preds.index, columns=['log', 'lda', 'lgbm'])\n\n# add in data from the 3 predicted dfs\nresults['log'] = log_preds\nresults['lda'] = lda_preds\nresults['lgbm'] = lgbm_preds\n\n# show grouped df\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find columns where all 3 models agree on the result\nequal_rows = 0\nfor row in results.itertuples(index=False):\n    if(row.log == row.lda == row.lgbm):\n        equal_rows += 1\n        \nequal_rows","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from all the 1000 rows the 3 models agree on 62% which means any of these 3 algorithms should be n overall good choice for predicting the price range of a smartphone based on its specifications"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}