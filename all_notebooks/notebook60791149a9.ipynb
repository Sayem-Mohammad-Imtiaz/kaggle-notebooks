{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport PIL.Image\nimport time\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"menu='''\n                   Đồ Án Cuối Kỳ\n            Nhập Môn Trí Tuệ Nhân Tạo\n   bengali.AI Handwritten Grapheme Classification\n            Đoàn Công Hậu - 1824801040101\n            Hà Trọng Phan - 1824801040082\n'''\nprint(menu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_FOLDER = '../input/input-kaggle/'\ntrain_df = pd.read_csv(os.path.join(DATA_FOLDER, 'train.csv'))\ntrain_df.head()\nprint(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv'))\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map_df = pd.read_csv(os.path.join(DATA_FOLDER, 'class_map.csv'))\nclass_map_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_df = pd.read_csv(os.path.join(DATA_FOLDER, 'sample_submission.csv'))\nsample_submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntrain_0_df = pd.read_parquet(os.path.join(DATA_FOLDER,'train_image_data_0.parquet'))\nprint(f\"`train_image_data_0` read in {round(time.time()-start_time,2)} sec.\")  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_0_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_0_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntrain_1_df = pd.read_parquet(os.path.join(DATA_FOLDER,'train_image_data_1.parquet'))\nprint(f\"`train_image_data_1` read in {round(time.time()-start_time,2)} sec.\")  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_1_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntest_0_df = pd.read_parquet(os.path.join(DATA_FOLDER,'test_image_data_0.parquet'))\nprint(f\"`test_image_data_0` read in {round(time.time()-start_time,2)} sec.\") ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_0_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_0_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train: unique grapheme roots: {train_df.grapheme_root.nunique()}\")\nprint(f\"Train: unique vowel diacritics: {train_df.vowel_diacritic.nunique()}\")\nprint(f\"Train: unique consonant diacritics: {train_df.consonant_diacritic.nunique()}\")\nprint(f\"Train: total unique elements: {train_df.grapheme_root.nunique() + train_df.vowel_diacritic.nunique() + train_df.consonant_diacritic.nunique()}\")\nprint(f\"Class map: unique elements: \\n{class_map_df.component_type.value_counts()}\")\nprint(f\"Total combinations: {pd.DataFrame(train_df.groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'])).shape[0]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_gr = class_map_df.loc[(class_map_df.component_type=='grapheme_root'), 'component'].values\ncm_vd = class_map_df.loc[(class_map_df.component_type=='vowel_diacritic'), 'component'].values  \ncm_cd = class_map_df.loc[(class_map_df.component_type=='consonant_diacritic'), 'component'].values   \n\nprint(f\"grapheme root:\\n{15*'-'}\\n{cm_gr}\\n\\n vowel discritic:\\n{18*'-'}\\n{cm_vd}\\n\\n consonant diacritic:\\n{20*'-'}\\n {cm_cd}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#theo giỏi điều tra giá trị thường xuyên\ndef most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals / total * 100, 3)\n    return(np.transpose(tt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#giá trị thường xuyên nhất\nmost_frequent_values(train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#giá trị kiểm tra thường xuyên nhất\nmost_frequent_values(test_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#phân bố giá trị các lớp(class)\ndef plot_count(feature, title, df, size=1):\n    '''\n    Số lô của các lớp của đối tượng địa lý đã chọn; tính năng là một giá trị phân loại\n     param: feature - tính năng mà chúng tôi trình bày sự phân bố của các lớp\n     param: title - tiêu đề hiển thị trong cốt truyện\n     param: df - dataframe\n     param: kích thước - kích thước (từ 1 đến n), nhân với 4 - kích thước của ô\n    '''\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Số lượng và tỷ lệ phần trăm của {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_count('grapheme_root', 'grapheme_root (20 giá trị thường xuyên nhất đầu tiên - train)', train_df, size=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nguyên âm\nplot_count('vowel_diacritic', 'vowel_diacritic (train)', train_df, size=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#phụ âm\nplot_count('consonant_diacritic', 'consonant_diacritic (train)', train_df, size=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_image_from_data(data_df, size=6):\n    '''\n   Hiển thị hình ảnh grapheme từ dữ liệu mẫu\n     param: data_df - mẫu dữ liệu\n     param: size - sqrt (kích thước mẫu dữ liệu)\n    '''\n    plt.figure()\n    fig, ax = plt.subplots(size,size,figsize=(12,12))\n   #hiển thị hình ảnh để lừa chọn kích cở\n    for i, index in enumerate(data_df.index):\n        image_id = data_df.iloc[i]['image_id']\n        flattened_image = data_df.iloc[i].drop('image_id').values.astype(np.uint8)\n        unpacked_image = PIL.Image.fromarray(flattened_image.reshape(137, 236))\n\n        ax[i//size, i%size].imshow(unpacked_image)\n        ax[i//size, i%size].set_title(image_id)\n        ax[i//size, i%size].axis('on')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_image_from_data(train_0_df.sample(36))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vd cho mẫu số 2 bộ hình train_1 vs số lượng là 20 \ndisplay_image_from_data(train_1_df.sample(25), size = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''- áp dụng chức năng này,để hiển thị không phải các grapheme ngẫu nhiên,\n    mà là cùng một grapheme.\n\n    - Đối với điều này, em thực hiện việc lấy mẫu (dựa trên sự biến đổi của gốc grapheme, \ndấu phụ nguyên âm và dấu phụ âm, làm tham số cho hàm).'''\n\n\ndef display_writting_variety(data_df=train_0_df, grapheme_root=72, vowel_diacritic=0,\\\n                             consonant_diacritic=0, size=5):\n    '''\n    Hàm này nhận một tập hợp các dấu gốc grapheme, dấu phụ nguyên âm và dấu phụ âm\n     và hiển thị một mẫu gồm 25 hình ảnh cho grapheme này\n     param: data_df - tập dữ liệu được sử dụng làm nguồn dữ liệu\n     param: grapheme_root - nhãn gốc grapheme\n     param: nguyên âm_diacritic - nhãn dấu phụ nguyên âm\n     param: consonant_diacritic - nhãn dấu phụ âm\n     param: size - sqrt (số lượng hình ảnh sẽ hiển thị)\n    '''\n    sample_train_df = train_df.loc[(train_df.grapheme_root == grapheme_root) & \\\n                                  (train_df.vowel_diacritic == vowel_diacritic) & \\\n                                  (train_df.consonant_diacritic == consonant_diacritic)]\n    print(f\"total: {sample_train_df.shape}\")\n    sample_df = data_df.merge(sample_train_df.image_id, how='inner')\n    print(f\"total: {sample_df.shape}\")\n    gr = sample_train_df.iloc[0]['grapheme']\n    cm_gr = class_map_df.loc[(class_map_df.component_type=='grapheme_root')& \\\n                             (class_map_df.label==grapheme_root), 'component'].values[0]\n    cm_vd = class_map_df.loc[(class_map_df.component_type=='vowel_diacritic')& \\\n                             (class_map_df.label==vowel_diacritic), 'component'].values[0]    \n    cm_cd = class_map_df.loc[(class_map_df.component_type=='consonant_diacritic')& \\\n                             (class_map_df.label==consonant_diacritic), 'component'].values[0]    \n    \n    print(f\"grapheme: {gr}, grapheme root: {cm_gr}, vowel discritic: {cm_vd}, consonant diacritic: {cm_cd}\")\n    sample_df = sample_df.sample(size * size)\n    display_image_from_data(sample_df, size=size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#áp dụng hàm cho một vài kết hợp của dấu gốc grapheme, dấu phụ nguyên âm và dấu phụ âm.\ndisplay_writting_variety(train_0_df,72,1,1,4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_writting_variety(train_0_df,64,1,2,4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#áp dụng hàm cho một vài kết hợp của dấu gốc grapheme, dấu phụ nguyên âm và dấu phụ âm. dùng bộ hình train_1\ndisplay_writting_variety(train_1_df,13,0,0,4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_writting_variety(train_1_df,23,3,2,4,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}