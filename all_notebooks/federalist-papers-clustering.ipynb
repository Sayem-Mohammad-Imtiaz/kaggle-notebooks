{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.corpus import PlaintextCorpusReader\n\nimport plotly as py\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt \nimport plotly.express as pex\nimport holoviews as hv\nhv.extension('bokeh')\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:07.859672Z","iopub.execute_input":"2021-08-07T03:51:07.860095Z","iopub.status.idle":"2021-08-07T03:51:13.114838Z","shell.execute_reply.started":"2021-08-07T03:51:07.859999Z","shell.execute_reply":"2021-08-07T03:51:13.113671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Viewing a pre-creating matrix of functional word frequencies","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(r'/kaggle/input/federalist-papers/fedPapers85.csv')\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:13.116861Z","iopub.execute_input":"2021-08-07T03:51:13.117293Z","iopub.status.idle":"2021-08-07T03:51:13.191072Z","shell.execute_reply.started":"2021-08-07T03:51:13.117248Z","shell.execute_reply":"2021-08-07T03:51:13.19031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.author.value_counts().plot(kind='pie')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:13.19258Z","iopub.execute_input":"2021-08-07T03:51:13.192983Z","iopub.status.idle":"2021-08-07T03:51:13.403466Z","shell.execute_reply.started":"2021-08-07T03:51:13.192953Z","shell.execute_reply":"2021-08-07T03:51:13.402446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I mispelled some file names\ndf = df.replace({'HM_fed_18.txt':'Hamilton_and_Madion_fed_18.txt','HM_fed_19.txt':'Hamilton_and_Madion_fed_19.txt','HM_fed_20.txt':'Hamilton_and_Madion_fed_20.txt'})","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:13.40519Z","iopub.execute_input":"2021-08-07T03:51:13.405511Z","iopub.status.idle":"2021-08-07T03:51:13.412819Z","shell.execute_reply.started":"2021-08-07T03:51:13.405472Z","shell.execute_reply":"2021-08-07T03:51:13.411784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating new features from raw text files","metadata":{}},{"cell_type":"code","source":"# Read all papers into a corpus using NLTK\npaper_corpus = PlaintextCorpusReader(r'/kaggle/input/federalist-papers/FedPapersCorpus/FedPapersCorpus', '.*')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:13.414216Z","iopub.execute_input":"2021-08-07T03:51:13.414538Z","iopub.status.idle":"2021-08-07T03:51:13.442218Z","shell.execute_reply.started":"2021-08-07T03:51:13.414508Z","shell.execute_reply":"2021-08-07T03:51:13.441214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sentences, Words, Characters, Word Length, Sentence Length","metadata":{}},{"cell_type":"code","source":"# Using loops here because the order of files in the corpus and dataframe are different\n# There may be a more optimized way to vectorize this operation\n#    by joining the dataframe with the corpus if required\n\ndf['chars'] = [len(paper_corpus.raw(fileids=[f])) for f in df.filename]\ndf['words'] = [len(paper_corpus.words(fileids=[f])) for f in df.filename]\ndf['sents'] = [len(paper_corpus.sents(fileids=[f])) for f in df.filename]\ndf['word_len'] = df.chars/df.words\ndf['sent_len'] = df.words/df.sents","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:13.443639Z","iopub.execute_input":"2021-08-07T03:51:13.443954Z","iopub.status.idle":"2021-08-07T03:51:15.152579Z","shell.execute_reply.started":"2021-08-07T03:51:13.443918Z","shell.execute_reply":"2021-08-07T03:51:15.151358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Analysis","metadata":{}},{"cell_type":"code","source":"auths = ['Hamilton','Madison','Jay','dispt']","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:15.153851Z","iopub.execute_input":"2021-08-07T03:51:15.154177Z","iopub.status.idle":"2021-08-07T03:51:15.159904Z","shell.execute_reply.started":"2021-08-07T03:51:15.154145Z","shell.execute_reply":"2021-08-07T03:51:15.158856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 2)\nfor i, auth in enumerate(auths):\n    ax[i//2, i%2].hist(df[df.author == auth].words)\n    ax[i//2, i%2].set_title(auth + \" paper length\", weight='bold', size=12)\n    ax[i//2, i%2].set_xlabel(\"Number of Words\")\n    ax[i//2, i%2].set_ylabel(\"Quantity of Papers\")\n    ax[i//2, i%2].set_xlim(0, 7000)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:15.162376Z","iopub.execute_input":"2021-08-07T03:51:15.1627Z","iopub.status.idle":"2021-08-07T03:51:15.876228Z","shell.execute_reply.started":"2021-08-07T03:51:15.162669Z","shell.execute_reply":"2021-08-07T03:51:15.875433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 2)\nfor i, auth in enumerate(auths):\n    ax[i//2, i%2].hist(df[df.author == auth].sent_len)\n    ax[i//2, i%2].set_title(auth + \" avg sent length\", weight='bold', size=12)\n    ax[i//2, i%2].set_xlabel(\"Avg Sentence Length\")\n    ax[i//2, i%2].set_ylabel(\"Quantity of Papers\")\n    ax[i//2, i%2].set_xlim(25, 45)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:15.879612Z","iopub.execute_input":"2021-08-07T03:51:15.879937Z","iopub.status.idle":"2021-08-07T03:51:16.546771Z","shell.execute_reply.started":"2021-08-07T03:51:15.879908Z","shell.execute_reply":"2021-08-07T03:51:16.545567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wordclouds for each author\nfor auth in auths:\n    print(auth)\n    text = paper_corpus.raw(fileids = list(df[df.author == auth].filename))\n    wc = WordCloud().generate(text)\n    plt.figure(figsize=(15,10))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:16.548427Z","iopub.execute_input":"2021-08-07T03:51:16.548846Z","iopub.status.idle":"2021-08-07T03:51:19.512646Z","shell.execute_reply.started":"2021-08-07T03:51:16.548801Z","shell.execute_reply":"2021-08-07T03:51:19.511578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K means clustering with all functional words","metadata":{}},{"cell_type":"code","source":"# Scaling\nscaler = MinMaxScaler()\nc = df.drop(['author', 'filename'], axis=1).columns\ndf[c] = scaler.fit_transform(df[c])","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:19.514006Z","iopub.execute_input":"2021-08-07T03:51:19.514359Z","iopub.status.idle":"2021-08-07T03:51:19.539168Z","shell.execute_reply.started":"2021-08-07T03:51:19.514327Z","shell.execute_reply":"2021-08-07T03:51:19.538129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vals = df.drop(['author', 'filename'], axis=1).values\ndoc_cluster = KMeans(n_clusters = 4)\ndoc_cluster.fit(vals)\nlabs = doc_cluster.labels_\ncentroids = doc_cluster.cluster_centers_","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:19.540289Z","iopub.execute_input":"2021-08-07T03:51:19.54059Z","iopub.status.idle":"2021-08-07T03:51:19.601933Z","shell.execute_reply.started":"2021-08-07T03:51:19.540561Z","shell.execute_reply":"2021-08-07T03:51:19.600857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'] =  labs\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:19.603272Z","iopub.execute_input":"2021-08-07T03:51:19.603589Z","iopub.status.idle":"2021-08-07T03:51:19.634198Z","shell.execute_reply.started":"2021-08-07T03:51:19.603551Z","shell.execute_reply":"2021-08-07T03:51:19.63311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing with Sankey","metadata":{}},{"cell_type":"code","source":"counter_df = df[['author','label']]\ncounter_df['count'] = 1\ncounter_df = counter_df.groupby(['author','label']).agg('count').reset_index()\ncounter_df.label = counter_df.label.astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:19.635454Z","iopub.execute_input":"2021-08-07T03:51:19.635755Z","iopub.status.idle":"2021-08-07T03:51:19.653479Z","shell.execute_reply.started":"2021-08-07T03:51:19.635725Z","shell.execute_reply":"2021-08-07T03:51:19.652267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot = hv.Sankey(counter_df, kdims=[\"author\", \"label\"], vdims=[\"count\"])\nplot.opts(label_position='left',edge_color='author')","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:19.654715Z","iopub.execute_input":"2021-08-07T03:51:19.654987Z","iopub.status.idle":"2021-08-07T03:51:20.091875Z","shell.execute_reply.started":"2021-08-07T03:51:19.65496Z","shell.execute_reply":"2021-08-07T03:51:20.091152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Decision Trees to classify","metadata":{"execution":{"iopub.status.busy":"2021-08-07T02:43:40.560538Z","iopub.execute_input":"2021-08-07T02:43:40.561508Z","iopub.status.idle":"2021-08-07T02:43:40.568357Z","shell.execute_reply.started":"2021-08-07T02:43:40.561348Z","shell.execute_reply":"2021-08-07T02:43:40.566641Z"}}},{"cell_type":"code","source":"test_df = df[df.author == 'dispt']\ntrain_df= df[df.author != 'dispt']\n\nX_test = test_df.drop(['author','filename'],axis=1)\nX_train = train_df.drop(['author','filename'],axis=1)\ny_test = test_df.author\ny_train = train_df.author","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:20.092849Z","iopub.execute_input":"2021-08-07T03:51:20.093258Z","iopub.status.idle":"2021-08-07T03:51:20.103477Z","shell.execute_reply.started":"2021-08-07T03:51:20.093228Z","shell.execute_reply":"2021-08-07T03:51:20.102397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paper_tree = DecisionTreeClassifier()\npaper_tree.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:20.10464Z","iopub.execute_input":"2021-08-07T03:51:20.104952Z","iopub.status.idle":"2021-08-07T03:51:20.125937Z","shell.execute_reply.started":"2021-08-07T03:51:20.104925Z","shell.execute_reply":"2021-08-07T03:51:20.124935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Decision Tree","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(25,20))\n_ = tree.plot_tree(paper_tree,\n                  feature_names = X_train.columns,\n                  class_names = np.sort(y_train.unique()))","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:20.127183Z","iopub.execute_input":"2021-08-07T03:51:20.127467Z","iopub.status.idle":"2021-08-07T03:51:21.0384Z","shell.execute_reply.started":"2021-08-07T03:51:20.12744Z","shell.execute_reply":"2021-08-07T03:51:21.037282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = paper_tree.predict(X_test)\nlist(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T03:51:21.039744Z","iopub.execute_input":"2021-08-07T03:51:21.040093Z","iopub.status.idle":"2021-08-07T03:51:21.049914Z","shell.execute_reply.started":"2021-08-07T03:51:21.040043Z","shell.execute_reply":"2021-08-07T03:51:21.048901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Madison is historically credited as the author of the disputed papers!","metadata":{}}]}