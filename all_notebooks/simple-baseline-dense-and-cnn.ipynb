{"cells":[{"metadata":{"_uuid":"df3160c846cc6941fb0fc0f17bcb71a9462e166f"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"500e22d2093bfa3fb2ec34da4d972f6fa92fe524"},"cell_type":"markdown","source":"# Introduction\n\nThis is ShaCo, a simple Shape Counting dataset. The motivation is providing a simple benchmark, easily customizable, where it's easy to generate as many images as wanted for training.\n\nThis first version includes 50000 images divided on a training set of 42500 and a test set of 7500.\nThe images contain anywhere from 1 to 5 blue circles, 1 to 4 green squares, and 0 to 3 red squares.\nThe number of shapes for a given image is selected at random. The size of the squares and circles also has some small random variation.\nBlue circle and green square quantities are randomly generated with a normal distribution. Red squares are generated depending on the number of green squares, to simulate how in many counting problems there might be some type of object that is less frequent.\nOverlapping of the shapes is allowed, and transparency is used to avoid problems of shapes fully covering one another.\n\nThis is a work in progress."},{"metadata":{"_uuid":"fe2e46f6e1eed8717d4b30ddd4492610009269c0"},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport os\n\nprint(os.listdir(\"../input/shape count\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5617de4676362d79537a1f356d6df00ec806eac0"},"cell_type":"markdown","source":"# Reading the input files\n\nThe images are presented both in the Keras friendly form as .pkl files and as image files.\nHere we load them from the pickle objects.\nThe labels are loaded from the .csv files and transformed into numpy arrays for Keras."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"with open('../input/shape count/train_images_transparent.pkl', 'rb') as inputfile:\n    x_train = pickle.load(inputfile)\n    \nwith open('../input/shape count/test_images_transparent.pkl', 'rb') as inputfile:\n    x_test = pickle.load(inputfile)\n    \ny_train = pd.read_csv('../input/shape count/train_labels.csv', header = None)\n\ny_test = pd.read_csv('../input/shape count/test_labels.csv',header = None)\n\ny_train = np.array(y_train)\n\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6873466fc78a7a91550d28faa73cba88ad2bf60d"},"cell_type":"markdown","source":"The images are 100x100 pixels in size, and contain a random number of semi-transparent shapes.\n(Blue circles, red/green squares).\nLets see an example:"},{"metadata":{"trusted":true,"_uuid":"58e6c07fb947b9653bfb1152d6439676f6ef43cc","scrolled":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport random\n\nrand = random.randint(0,len(x_train))\n\nprint('This image has:')\nprint(str(y_train[rand][0]) + ' blue circles' )\nprint(str(y_train[rand][1]) + ' green squares' )\nprint(str(y_train[rand][2]) + ' red squares' )\nplt.imshow(x_train[rand]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c2110648401358c24cd5251eb44deb44052db1b"},"cell_type":"markdown","source":"The shapes are semi-transparent so that even if a full overlap occurs, it should still be possible to tell how many shapes there are.\n\nLet's make sure that the images are in the proper format. (They should already be if loaded from the .pkl objects)."},{"metadata":{"trusted":true,"_uuid":"ca90b8a5a3e897b4f5aebc8092c5e9fe78debcab"},"cell_type":"code","source":"from keras import backend as K\n\nimg_rows, img_cols = 100,100\n\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n    input_shape = (3, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,3)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,3)\n    input_shape = (img_rows, img_cols, 3)\n    \nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdbc9f7e90f23c4d7f52f10522d42a65d6f3f8c0"},"cell_type":"markdown","source":"Now lets do some simple pre-processing. Just normalizing the images, dividing by 255."},{"metadata":{"trusted":true,"_uuid":"31f8ad84ed7a45a38ce56835bf603fbad1ac166e"},"cell_type":"code","source":"x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d0d3435b8a81479ad2521f49c57c96e25f335a3"},"cell_type":"markdown","source":"We are ready to build our model for Keras. For the purpose of this example, let's get a baseline by using a pair of densely connected layers (a simple Multi Layer Perceptron), and let's also try a small Convolutional Network.\n\nWe will need two models."},{"metadata":{"trusted":true,"_uuid":"be4c00d74047dc4b1b5fd09fea17c5f7321e1bab"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nmodel1 = Sequential()\nmodel1.add(Flatten(input_shape=x_train.shape[1:4]))\nmodel1.add(Dense(512, activation='relu'))\nmodel1.add(Dense(y_train.shape[1], activation='relu'))\n\nmodel2 = Sequential()\nmodel2.add(Conv2D(filters = 32, kernel_size=(3,3), padding = 'same', input_shape=x_train.shape[1:4]))\nmodel2.add(Conv2D(filters = 64, kernel_size=(3,3), padding = 'same'))\nmodel2.add(MaxPooling2D())\nmodel2.add(Flatten())\nmodel2.add(Dense(512, activation='relu'))\nmodel2.add(Dense(y_train.shape[1], activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ee7a662ea8e714e3a02962499fd4223e149ba24"},"cell_type":"markdown","source":"Finally lets compile our models. We can try MSE as loss since this is a regression problem where we try to count the number of objects on the image. The output of the network is a list of 3 values corresponding to the ammounts of each type of shape.\nFor the sake of this simple example we won't use cross-validation or any type of regularization or optimization. These can be tried later on to improve results. Let's just see how these simple models do for this task."},{"metadata":{"trusted":true,"_uuid":"682bd5e0f944dfce01522c0aa81d6c434146865b"},"cell_type":"code","source":"batch_size = 128\nepochs = 5\n\nmodel1.compile(loss='mean_squared_error',\n              optimizer='adam')\n\nmodel1.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1)\n\nscore1 = model1.evaluate(x_test, y_test, verbose=1)\n\nmodel2.compile(loss='mean_squared_error',\n              optimizer='adam')\n\nmodel2.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1)\n\nscore2 = model2.evaluate(x_test, y_test, verbose=1)\n\nprint('MLP loss:', score1)\nprint('CNN loss:', score2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce44d7eafa0c78cf1810e16f26a719173ad4358f"},"cell_type":"markdown","source":"But its not obvious how many miscounts happened, just from looking at the MSE.\nWe retrieve the number of miscounts on the test set below:"},{"metadata":{"trusted":true,"_uuid":"9c47535ce4f8971698e45e34c29ba13321fd3702"},"cell_type":"code","source":"miscounts1 = []\nmiscounts2 = []\n\nfor i in range(0,len(x_test)-1):\n\n    sample = x_test[i]\n    sample = np.expand_dims(sample,axis=0)\n    sample1 = np.round(model1.predict(sample))\n    sample2 = np.round(model2.predict(sample))\n    sample1 = np.abs(y_test[i] - sample1)\n    sample2 = np.abs(y_test[i] - sample2)\n    miscounts1.append(sample1)\n    miscounts2.append(sample2)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"57f8c5f4ea9c3b372474f1ab00750e1458f08122"},"cell_type":"code","source":"totals = pd.DataFrame(pd.DataFrame(y_test).sum())\ntotals1 = pd.DataFrame(pd.DataFrame(np.array(miscounts1).squeeze()).sum())\ntotals2 = pd.DataFrame(pd.DataFrame(np.array(miscounts2).squeeze()).sum())\ntotals = pd.concat([totals,totals1,totals2],axis=1)\n\n\ntotals.columns = ['Test set totals', 'MLP miscounts', 'CNN miscounts']\ntotals.rename(index={0:'Blue Circles',1:'Green Squares', 2:'Red Squares'}, inplace=True)\ntotals.loc['Total'] = totals.sum()\n\nprint(totals)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"257e88c8b9317dee69b4b523e95e0d28c63c4cbd"},"cell_type":"markdown","source":"We see that these models can learn how to count the shapes relatively well with little training.\nHowever given that the dataset is relatively simple, can the result be optimized until there are no miscounts?\nUsing a small convolutional block changed the number of miscounts by an order of magnitude.\n\nMiscounts of green squares happen more often than either Blue Circles (most frequent shape) or Red Squares (least frequent shape). Not immediately clear why that is happening.\n\nPreliminary tests with VGG16 indicated that deeper models aren't necessarily better for this dataset out of the box, so some more fine tuning might be necessary, or maybe using different architectures altogether.\n\nIf and when this dataset is fully solved and there are no more miscounts, it is pretty easy to increment the challenge with more shapes, more variability, other sources of difficulty and other aspects.\n\nSuggestions regarding how to improve the dataset, the models or others, are very welcome!"},{"metadata":{"trusted":true,"_uuid":"a4cda71c116c0fb0d23ec8cf0f22408612d0c5c5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}