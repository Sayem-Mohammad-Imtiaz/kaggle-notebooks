{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy import stats\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"# Read the CSV file and set first column as the dataframe index\ndataset = pd.read_csv(\"../input/nasa-bearing-dataset-dataset-for-set-no-2/merged_dataset_BearingTest_2.csv\", index_col=0)\ndataset.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Column of index 0 is the timestamp (name of the file in the raw dataset)\n\n# Last rows shows the bearing failure (acceleration -> 0) \ndataset.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the signals\nbearing1 = dataset['Bearing 1']\nbearing1_index = bearing1.index.values\nbearing2 = dataset['Bearing 2']\nbearing2_index = bearing1.index.values\nbearing3 = dataset['Bearing 3']\nbearing3_index = bearing1.index.values\nbearing4 = dataset['Bearing 4']\nbearing4_index = bearing1.index.values\n\nfigure(figsize=(15, 4), dpi=80)\n\nbearing1.plot(color='green', label='Bearing 1')\nbearing2.plot(color='yellow', label='Bearing 2')\nbearing3.plot(color='orange', label='Bearing 3')\nbearing4.plot(color='blue', label='Bearing 4')\nplt.xlabel('Timestamp')\nplt.ylabel('Acceleration')\nplt.legend(loc=\"upper left\")  \nplt.title('Time series for all 4 accelerometers', fontweight =\"bold\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalize the dataset","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\n# Dataset is scaled so that maximum for every column is 1\nscaler = preprocessing.MinMaxScaler()\ndataset_scaled = pd.DataFrame(scaler.fit_transform(dataset), \n                              columns=dataset.columns, \n                              index=dataset.index)\ndataset_scaled.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA) & features selection\n## Extract each bearing's acceleration data","metadata":{}},{"cell_type":"code","source":"bearing1 = dataset_scaled['Bearing 1']\nbearing1_index = bearing1.index.values\n\nbearing2 = dataset_scaled['Bearing 2']\nbearing2_index = bearing1.index.values\n\nbearing3 = dataset_scaled['Bearing 3']\nbearing3_index = bearing1.index.values\n\nbearing4 = dataset_scaled['Bearing 4']\nbearing4_index = bearing1.index.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Then plot the 4 signals (normalized) together","metadata":{}},{"cell_type":"code","source":"figure(figsize=(15, 4), dpi=80)\n\nbearing1.plot(color='green', label='Bearing 1')\nbearing2.plot(color='yellow', label='Bearing 2')\nbearing3.plot(color='blue', label='Bearing 3')\nbearing4.plot(color='orange', label='Bearing 4')\nplt.xlabel('Timestamp')\nplt.ylabel('Acceleration')\nplt.legend(loc=\"upper left\")  \nplt.title('Time series for all 4 accelerometers (normalized signals)', fontweight =\"bold\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features selection\nWe're going to carry out a simplified analysis using only in two dimensions. So we have to select 2 out 4 signals.\n - We'll take the 2 curves that have the more *singular* shapes. For this we are assuming that non-selected features have a similar shape to one of the selected\n - From the figure above we can select **Bearings 1 and 3**:\n     - `Bearing 4` shows a similar shape to `Bearing 1`\n     - `Bearing 2` is something between `Bearing 1` and `Bearing 3` (it would be right like that if the signal could be obtained as a linear combination of curves 1 and 3)\n\nLet's remove signals 2 and 4 and plot again.","metadata":{}},{"cell_type":"code","source":"figure(figsize=(15, 4), dpi=80)\n\nbearing1.plot(color='green', label='Bearing 1')\nbearing3.plot(color='blue', label='Bearing 3')\nplt.xlabel('Timestamp')\nplt.ylabel('Acceleration')\nplt.legend(loc=\"upper left\")  \nplt.title('Time series for accelerometers 1 and 3 (normalized signals)', fontweight =\"bold\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bearing 3** show overall greater and number of outliers' values. So select it as the second dimension","metadata":{}},{"cell_type":"code","source":"# VISUALIZE THE DATA IN THE 2 DIMENSIONAL SPACE\n# Transform dataframe columns to np arrays\nsample_size = dataset.shape[0]\n\ndim1_arr = np.array(bearing1)[:sample_size]\ndim2_arr = np.array(bearing3)[:sample_size]\n# Create a meshgrid\nxx, yy = np.meshgrid(np.linspace(0, 1, 200),\n                     np.linspace(0, 1, 200))\n# scatter plot\nfigure(figsize=(7, 6), dpi=80)\nplt.scatter(dim1_arr, dim2_arr, marker='x')\nplt.xlim((0,1))\nplt.ylim((0,1))\nplt.xlabel('Dimension X (bearing 1)')\nplt.ylabel('Dimension Y (bearing 3)')\nplt.title('Scatter plot: '+str(sample_size)+' points from the beginning', fontweight =\"bold\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hence the **reduced dataset** are the columns `Bearing 1` and `Bearing 3` of the whole dataset:","metadata":{}},{"cell_type":"code","source":"dataset_reduced = dataset_scaled[['Bearing 1','Bearing 3']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN algorithm for outliers' identification","metadata":{}},{"cell_type":"code","source":"!pip install pyod","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyod.models.knn import KNN \nfrom pyod.utils.data import get_outliers_inliers\nimport matplotlib.font_manager","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the percentage of outliers\noutlier_fraction = 0.15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the classifier\nclf = KNN(contamination = outlier_fraction)\nclf.fit(dataset_reduced)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compute scores and threshold for labeling outliers","metadata":{}},{"cell_type":"code","source":"scores_pred = clf.decision_function(dataset_reduced)*-1\nprint (\"Scores' predictions range from\", \"{:.4f}\".format(min(scores_pred)), \"to {:.4f}\".format(max(scores_pred)) )\nprint (\"\\nScores' predictions for first 5 points:       \", scores_pred[:5] )\nprint (\"Scores' predictions for 5 intermediate points:\", scores_pred[850:855] )\nprint (\"Scores' predictions for  last 5 points:       \", scores_pred[-5:] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# threshold value to consider a datapoint as outlier\nthreshold = stats.scoreatpercentile(scores_pred, 100 * outlier_fraction)\nprint (\"Threshold value to label outliers is\" , \"{:.4f}\".format(threshold) )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(dataset_reduced) # Dataset is not labeled, so this prediction cannot be used to compute any error\n# !!! We're applying unsupervised learning, just find the index from which the remaining points are labeled as outliers\nprint (\"Outliers prediction for first 5 points:       \", y_pred[:5] )\nprint (\"Outliers prediction for 5 intermediate points:\", y_pred[850:855] )\nprint (\"Outliers predictions for last 5 points:       \", y_pred[-5:] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract outliers","metadata":{}},{"cell_type":"code","source":"## We'll use y_pred to identify outliers\n# Storing the outliers and inliners in different numpy arrays\nX_outliers, X_inliers = get_outliers_inliers(np.array(dataset_reduced), y_pred)\nn_inliers = len(X_inliers)\nn_outliers = len(X_outliers)\nprint(\"There are\", n_inliers, \"inliers and\", n_outliers, \"outliers\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatter plot of outliers","metadata":{}},{"cell_type":"code","source":"figure(figsize=(7, 6), dpi=80)\n\n# Reduced dataset\nplt.scatter(dataset_reduced.iloc[:,0], dataset_reduced.iloc[:,1], marker='x')\n# Encircle outliers\nplt.scatter(X_outliers[:,0],X_outliers[:,1],marker=\"o\",facecolor=\"none\",edgecolor=\"r\",s=70)\n\nplt.xlim((0,1))\nplt.ylim((0,1))\nplt.xlabel('Dimension X (bearing 1)')\nplt.ylabel('Dimension Y (bearing 3)')\nplt.title('Scatter plot encircling the outliers', fontweight =\"bold\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time series plot highlighting outliers","metadata":{}},{"cell_type":"code","source":"# Add a column tagging each point as inlier (0) or outlier (1)\ndataset_reduced['outlier'] = y_pred\n\n# Subset of data points with only outliers\ndataset_outliers = dataset_reduced[ dataset_reduced['outlier']==1 ]\n\nprint(\"There are\", dataset_reduced.shape[0], \"data points, of which\", dataset_outliers.shape[0], \"are outliers\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dimensionX = dataset_reduced.iloc[:,0]\ndimensionY = dataset_reduced.iloc[:,1]\ndimensionX_outliers = dataset_outliers.iloc[:,0]\ndimensionY_outliers = dataset_outliers.iloc[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure(figsize=(15, 4), dpi=80)\n\ntail_size    = 900\nx_ticks_span = 150\n\ntimestamps = dataset_reduced.index[-tail_size:]\n\ndimX_arr = dimensionX[-tail_size:]\nplt.plot(timestamps, dimX_arr, color='green', label='(bearing 1) acceleration')\nplt.plot(dimensionX_outliers.index, dimensionX_outliers, 'v', color='red', label='(bearing 1) outliers')\n\ndimY_arr = dimensionY[-tail_size:]\nplt.plot(timestamps, dimY_arr, color='blue', label='(bearing 3) acceleration')\nplt.plot(dimensionY_outliers.index, dimensionY_outliers, 'v', color='orange', label='(bearing 3) outliers')\n\nplt.xlabel('Timestamp')\nplt.xlim(0,tail_size)\nplt.xticks(np.arange(0, tail_size+1, x_ticks_span), fontsize=10, rotation = 45)\nplt.ylabel('Acceleration')\n\nplt.legend(loc=\"upper left\")  \nplt.title('Time series for accelerometers 1 and 3 showing outliers', fontweight =\"bold\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}}]}