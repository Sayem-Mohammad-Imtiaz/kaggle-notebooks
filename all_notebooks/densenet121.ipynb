{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"root_path = '../input/isic-2019'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DIR = os.path.join(root_path, 'ISIC_2019_Training_Input/ISIC_2019_Training_Input')\npanda_path = os.path.join(root_path, 'ISIC_2019_Training_GroundTruth.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir(IMAGE_DIR)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'This is the image dir: {IMAGE_DIR}')\nprint(f'This is the csv filepath: {panda_path}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential, Model\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    for index, img in enumerate(df.image):\n        img = img+'.jpg'\n        df.image[index]=img\n    df.drop(['UNK'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_val_test_split(df, test_len=1000, val_ratio=0.2):\n    test_rows = (np.random.rand(1000)*df.shape[0]).astype(int)\n    test_df =  df.iloc[test_rows]\n    test_df = test_df.reset_index().drop(['index'], axis=1)\n    df.drop(test_rows, axis=0, inplace=True)\n    df = df.reset_index().drop(['index'], axis=1)\n    val_rows = (np.random.rand(int(val_ratio*df.shape[0]))*df.shape[0]).astype(int)\n    val_df = df.iloc[val_rows]\n    df.drop(val_rows, axis=0, inplace=True)\n    val_df = val_df.reset_index().drop(['index'], axis=1)\n    test_df = test_df.reset_index().drop(['index'], axis=1)\n    df = df.reset_index().drop(['index'], axis=1)\n#     int_dict = {'MEL':int, 'NV':int, 'BCC':int, 'AK':int, 'BKL':int, 'DF':int, 'VASC':int, 'SCC':int}\n#     df = df.astype(int_dict) \n#     val_df = val_df.astype(int_dict)\n#     test_df = test_df.astype(int_dict)\n    return df, val_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = pd.read_csv(panda_path)\npreprocess(full_df)\ntrain_df, val_df, test_df = train_val_test_split(full_df)\nlabels=list(train_df.columns[1:])\nprint(labels)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_class_freqs(labels):\n\n    N = labels.shape[0]\n    \n    positive_frequencies = np.mean(labels, axis=0)\n    negative_frequencies = 1 - positive_frequencies\n\n    return positive_frequencies, negative_frequencies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = list(train_df.columns)[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_and_valid_generator(valid_df=val_df, test_df=test_df, train_df=train_df, image_dir=IMAGE_DIR, x_col='image', y_cols=labels, sample_size=100, batch_size=32, seed=42, target_w = 320, target_h = 320):\n\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=IMAGE_DIR, \n        x_col=\"image\", \n        y_col=y_cols, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # get test generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_train_generator(df=train_df, image_dir=IMAGE_DIR, x_col='image', y_cols=labels, shuffle=True, batch_size=32, seed=42, target_w = 320, target_h = 320):\n    \n    \n    print(\"getting train generator...\") \n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True)\n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = get_train_generator()\nvalid_generator, test_generator= get_test_and_valid_generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = train_generator.__getitem__(0)\nprint(x.shape)\nprint(y.shape)\nplt.imshow(x[2]);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_pos, freq_neg = compute_class_freqs(train_generator.labels)\n\npos_weights = freq_neg\nneg_weights = freq_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \n    def weighted_loss(y_true, y_pred):\n        \n        # initialize loss to zero\n        loss = 0.0\n        \n\n        for i in range(len(pos_weights)):\n            # for each class, add average weighted loss for that class \n            loss += K.mean(-(pos_weights[i]*y_true[:, i]*K.log(y_pred[:, i]+epsilon)\n                             + neg_weights[i]*(1-y_true[:, i])*K.log((1-y_pred[:, i])+epsilon)))\n        return loss\n    \n    return weighted_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nbase_model = DenseNet121(weights='imagenet', include_top=False)\n\nx = base_model.output\n\n# add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(x)\n\n# and a logistic layer\npredictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n//test_generator.batch_size\nhistory = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=valid_generator,\n                        validation_steps=STEP_SIZE_VALID, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_vals = model.predict_generator(valid_generator, steps = len(valid_generator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copied from Coursera util package\nfrom keras.preprocessing import image\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom tensorflow.compat.v1.logging import INFO, set_verbosity\nimport cv2\n\ndef get_roc_curve(labels, predicted_vals, generator):\n    auc_roc_vals = []\n    for i in range(len(labels)):\n        try:\n            gt = generator.labels[:, i]\n            pred = predicted_vals[:, i]\n            auc_roc = roc_auc_score(gt, pred)\n            auc_roc_vals.append(auc_roc)\n            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n            plt.figure(1, figsize=(10, 10))\n            plt.plot([0, 1], [0, 1], 'k--')\n            plt.plot(fpr_rf, tpr_rf,\n                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n            plt.xlabel('False positive rate')\n            plt.ylabel('True positive rate')\n            plt.title('ROC curve')\n            plt.legend(loc='best')\n        except:\n            print(\n                f\"Error in generating ROC curve for {labels[i]}. \"\n                f\"Dataset lacks enough examples.\"\n            )\n    plt.show()\n    return auc_roc_vals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_rocs = get_roc_curve(labels, predicted_vals, valid_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true, y_pred = [], []\nfor pred, arr in zip(predicted_vals, test_generator.labels):\n    y_true.append(np.argmax(arr))\n    y_pred.append(np.argmax(pred))\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\nprint(\"y_true:\", y_true)\nprint(\"y_pred:\", y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n   \n   \n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(y_true, y_pred, labels=range(8))\nconf_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(cm           = conf_mat, \n                      normalize    = False,\n                      target_names = labels,\n                      title        = \"Confusion Matrix\")\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}