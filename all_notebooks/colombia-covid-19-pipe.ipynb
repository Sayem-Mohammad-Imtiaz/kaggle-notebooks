{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Dependencies\nimport numpy as np\nimport pandas as pd\nimport requests\nimport unidecode\nimport datetime\nimport dateutil\nimport subprocess\nimport sys\nimport json\nimport tempfile\nimport os\n\n# Install missing dependencies\ndef install(package):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n# PDFMiner pdfminer.six\ntry:\n    from pdfminer.high_level import extract_text\nexcept Exception:\n    install('pdfminer.six')\n    from pdfminer.high_level import extract_text\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Colombia Covid19 Pipeline\nDataset obtained from [Instituto Nacional de Salud](https://www.ins.gov.co/Noticias/Paginas/Coronavirus.aspx) daily report Covid19 from Colombia.\n\nYou can get the official dataset here: \n[INS - Official Report](https://www.datos.gov.co/Salud-y-Protecci-n-Social/Casos-positivos-de-COVID-19-en-Colombia/gt2j-8ykr)\n\nThe number of new cases are increasing day by day around the world.\nThis dataset has information about reported cases from 32 Colombia departments.\n\nAlso you can get the dataset Google COVID-19 Community Mobility Reports - Colombia.\n\nYou can view and collaborate to the analysis here:\n[colombia_covid_19_analysis](https://www.kaggle.com/sebaxtian/colombia-covid-19-analysis) Kaggle Notebook Kernel."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Data Sources"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\nINPUT_DIR = './'\nif os.path.split(os.path.abspath('.'))[-1] == 'src':\n    INPUT_DIR = '../input'\n# Output data files are available in the \"../output/\" directory.\nOUTPUT_DIR = './'\nif os.path.split(os.path.abspath('.'))[-1] == 'src':\n    OUTPUT_DIR = '../output'\n# Official Daily Report Until Now\nURL_OFFICIAL_DATASET = 'https://www.datos.gov.co/api/views/gt2j-8ykr/rows.csv?accessType=DOWNLOAD'\n# Official Daily Samples Processed\nURL_SAMPLES_PROCESSED = 'https://e.infogram.com/api/live/flex/638d656c-c77b-4326-97d3-e50cb410c6ab/8188140c-8352-4994-85e3-2100a4dbd9db?'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Official Covid19 Colombia Daily Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Official Daily Report Until Now\nwith requests.get(URL_OFFICIAL_DATASET) as official_dataset:\n    with open(os.path.join(OUTPUT_DIR, 'covid19co_official.csv'), 'wb') as dataset_file:\n        dataset_file.write(official_dataset.content)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Open Official Daily Report\ncovid19co = pd.read_csv(os.path.join(OUTPUT_DIR, 'covid19co_official.csv'))\n# Total Daily Report\ncovid19co.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show dataframe\ncovid19co.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show attributes\nlist(covid19co.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update Name Columns\n# Remove Accents and Uppercase\ncovid19co.columns = [unidecode.unidecode(value).upper() for value in covid19co.columns]\n# Show dataframe\ncovid19co.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update texto to title text format\nfor attr in covid19co.columns:\n    if covid19co[attr].dtypes == 'object':\n        covid19co[attr] = covid19co[attr].transform(lambda value: str(value).title())\n# Show dataframe\ncovid19co.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill NaN Values\nif covid19co.isna().sum().sum() > 0:\n    covid19co.fillna(value='-', inplace=True)\n# Show dataframe\ncovid19co.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup Date Format\ndef setup_date(value):\n    try:\n        value = value.split('T')[0].split('-')\n        if len(value) == 3:\n            value = value[2] + '/' + value[1] + '/' + value[0]\n        else:\n            value = '-'\n    except IndexError:\n        value = '-'\n    if len(value) != 10 and len(value) != 1:\n        value = '-'\n    return value\n# Date Columns\ndate_columns = list(filter(lambda value: value.find('FECHA') != -1 or value.find('FIS') != -1, covid19co.columns))\n# For each date column\nfor date_column in date_columns:\n    covid19co[date_column] = covid19co[date_column].transform(lambda value: setup_date(value))\n# Show dataframe\ncovid19co.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add Day, Month, Year, Month Name and Day Name for each Date\n\n# Spanish\nnombre_mes = ['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio', 'Julio', 'Agosto', 'Septiembre', 'Octubre', 'Noviembre', 'Diciembre']\nnombre_dia = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']\n\n# Get day\ndef get_day(value):\n    if value not in '-':\n        return value.split('/')[0]\n    return value\n# Get month\ndef get_month(value):\n    if value not in '-':\n        return value.split('/')[1]\n    return value\n# Get year\ndef get_year(value):\n    if value not in '-':\n        return value.split('/')[2]\n    return value\n# Get month name\ndef get_month_name(value):\n    if value not in '-':\n        return nombre_mes[int(value.split('/')[1]) - 1]\n    return value\n# Get weekday\ndef get_weekday(value):\n    if value not in '-':\n        return nombre_dia[datetime.date(int(value.split('/')[2]), int(value.split('/')[1]), int(value.split('/')[0])).weekday()]\n    return value\n\n# For each date column\nfor date_column in date_columns:\n    covid19co[date_column + ' DIA'] = covid19co[date_column].transform(lambda value: get_day(value))\n    covid19co[date_column + ' MES'] = covid19co[date_column].transform(lambda value: get_month(value))\n    covid19co[date_column + ' ANIO'] = covid19co[date_column].transform(lambda value: get_year(value))\n    covid19co[date_column + ' NOMBRE MES'] = covid19co[date_column].transform(lambda value: get_month_name(value))\n    covid19co[date_column + ' DIA SEMANA'] = covid19co[date_column].transform(lambda value: get_weekday(value))\n# Show dataframe\ncovid19co.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Covid19 Colombia Dataset\n> ***Output file***: covid19co.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save dataframe\ncovid19co.to_csv(os.path.join(OUTPUT_DIR, 'covid19co.csv'), index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Official Covid19 Colombia Samples Processed"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Official Samples Processed Until Now\nwith requests.get(URL_SAMPLES_PROCESSED) as official_dataset:\n    with open(os.path.join(OUTPUT_DIR, 'covid19co_samples_processed_official.json'), 'w') as json_file:\n        json_data = official_dataset.json()\n        del json_data['refreshed']\n        json.dump(json_data, json_file, ensure_ascii=False, indent=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Open Official Samples Processed\nwith open(os.path.join(OUTPUT_DIR, 'covid19co_samples_processed_official.json')) as official_dataset:\n    official_dataset = json.load(official_dataset)\n# Official Samples Processed\nofficial_dataset = official_dataset['data'][0]\ncovid19co_samples_processed = pd.DataFrame(columns=official_dataset[0], data=official_dataset[1:])\n# Total Daily Report\ncovid19co_samples_processed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show dataframe\ncovid19co_samples_processed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update Name Columns\n# Remove Accents and Uppercase\ncovid19co_samples_processed.columns = [unidecode.unidecode(value).upper() for value in covid19co_samples_processed.columns]\n# Show dataframe\ncovid19co_samples_processed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup Date Format\ndef setup_date_samples(value):\n    #print('date:', value)\n    try:\n        value = value.split(' ')\n        value = value[0].split('/')\n        #print(len(value))\n        if len(value) == 3:\n            # Day\n            if len(value[0]) == 1:\n                value[0] = '0' + value[0]\n            # Month\n            if len(value[1]) == 1:\n                value[1] = '0' + value[1]\n            # Year\n            if len(value[2]) == 2:\n                value[2] = value[2] + '20'\n            # Date\n            value = value[0] + '/' + value[1] + '/' + value[2]\n        else:\n            value = '-'\n    except IndexError:\n        value = '-'\n    #print('VALUE:', value)\n    if len(value) != 10 and len(value) != 1:\n        value = '-'\n    return value\n# Setup Date Format\ncovid19co_samples_processed['FECHA'] = covid19co_samples_processed['FECHA'].transform(lambda value: setup_date_samples(value))\n# Show dataframe\ncovid19co_samples_processed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Covid19 Colombia Samples Processed Dataset\n> ***Output file***: covid19co_samples_processed.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save dataframe\ncovid19co_samples_processed.to_csv(os.path.join(OUTPUT_DIR, 'covid19co_samples_processed.csv'), index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Google Community Mobility Reports - Colombia"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Google Community Mobility Reports - Colombia\ngoogle_community_mobility_reports = pd.DataFrame(columns=['date', 'country', 'file', 'url'])\ngoogle_community_mobility_reports['date'] = [dti.strftime('%Y-%m-%d') for dti in pd.date_range(start='2020-03-29', end=datetime.date.today().isoformat(), freq='D')]\ngoogle_community_mobility_reports['country'] = 'Colombia'\ngoogle_community_mobility_reports['file'] = [date + '_CO_Mobility_Report_en.pdf' for date in google_community_mobility_reports['date'].values]\n# Get URL report\ndef get_report_url(file):\n    with requests.get('https://www.gstatic.com/covid19/mobility/' + file) as community_mobility_report:\n        if community_mobility_report.status_code == 200:\n            return community_mobility_report.url\n        else:\n            return np.nan\n# Get URL report\ngoogle_community_mobility_reports['url'] = google_community_mobility_reports['file'].transform(lambda value: get_report_url(value))\n# Drop any report without URL\ngoogle_community_mobility_reports.dropna(inplace=True)\n# Reset index\ngoogle_community_mobility_reports.reset_index(inplace=True, drop=True)\n# Show dataframe\ngoogle_community_mobility_reports.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get/Add Mobility Changes\ndef get_mobility_changes(URL):\n    # Target changes\n    targets = ['Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplaces', 'Residential']\n    # Mobility Changes\n    mobility_changes = []\n    # Get Mobility Report\n    with requests.get(URL) as mobility_report:\n        if mobility_report.status_code == 200:\n            temp = tempfile.NamedTemporaryFile()\n            temp.write(mobility_report.content)\n            with open(temp.name, 'rb') as file:\n                # By pages\n                pdf_text = []\n                page = 0\n                while page != -1:\n                    text = extract_text(file, maxpages=1, page_numbers=[page])\n                    if text:\n                        pdf_text.append(text.split('\\n'))\n                        page += 1\n                    else:\n                        page = -1\n                # Page 1\n                page1 = pdf_text[0]\n                page1 = filter(lambda value: value != '', page1)\n                page1 = filter(lambda value: value in targets or value[-1] == '%', list(page1))\n                page1 = list(page1)[:6]\n                # Page 2\n                page2 = pdf_text[1]\n                page2 = filter(lambda value: value != '', page2)\n                page2 = filter(lambda value: value in targets or value[-1] == '%', list(page2))\n                page2 = list(page2)[:6]\n                # Merge\n                mobility_changes = page1 + page2\n    return mobility_changes\n# Add Mobility Changes\ngoogle_community_mobility_reports['mobility_changes'] = google_community_mobility_reports['url'].transform(lambda value: get_mobility_changes(value))\n# By case\ngoogle_community_mobility_reports['Retail & recreation'] = google_community_mobility_reports['mobility_changes'].transform(lambda value: value[1])\ngoogle_community_mobility_reports['Grocery & pharmacy'] = google_community_mobility_reports['mobility_changes'].transform(lambda value: value[3])\ngoogle_community_mobility_reports['Parks'] = google_community_mobility_reports['mobility_changes'].transform(lambda value: value[5])\ngoogle_community_mobility_reports['Transit stations'] = google_community_mobility_reports['mobility_changes'].transform(lambda value: value[7])\ngoogle_community_mobility_reports['Workplaces'] = google_community_mobility_reports['mobility_changes'].transform(lambda value: value[9])\ngoogle_community_mobility_reports['Residential'] = google_community_mobility_reports['mobility_changes'].transform(lambda value: value[11])\n# Drop column\ngoogle_community_mobility_reports.drop(columns=['mobility_changes'], inplace=True)\n# Sort columns\ngoogle_community_mobility_reports = google_community_mobility_reports[['date', 'country', 'Retail & recreation', 'Grocery & pharmacy', 'Parks', 'Transit stations', 'Workplaces', 'Residential', 'file', 'url']]\n# Setup date format\ngoogle_community_mobility_reports['date'] = [value.strftime('%d/%m/%Y') for value in pd.to_datetime(google_community_mobility_reports['date'], format='%Y-%m-%d')]\n# Show dataframe\ngoogle_community_mobility_reports.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Google Community Mobility Reports - Colombia\n> ***Output file***: google_community_mobility_reports.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save dataframe\ngoogle_community_mobility_reports.to_csv(os.path.join(OUTPUT_DIR, 'google_community_mobility_reports.csv'), index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9-final"},"kernelspec":{"name":"python36964bitvenvvenv83dfe23e093e47f3b91ee1d0340b51b2","display_name":"Python 3.6.9 64-bit ('.venv': venv)"}},"nbformat":4,"nbformat_minor":4}