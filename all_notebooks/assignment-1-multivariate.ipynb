{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport copy\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def MinMaxScaler(rawData):\n    minValue = min(rawData)\n    maxValue = max(rawData)\n    return (rawData/(maxValue-minValue) - minValue/(maxValue-minValue))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kNNImputer(array):\n    output = copy.deepcopy(array)\n    nanIndices = np.where(np.isnan(array))[0]\n    array[np.isnan(array)] = 0\n    for i in range (len(nanIndices)):\n        if nanIndices[i] <= 1:\n            kNNMean = np.sum(array[0:nanIndices[i]+2])/5\n            output[nanIndices[i]] = kNNMean\n        elif nanIndices[i] >= len(array)-2:\n            kNNMean = np.sum(array[nanIndices[i]-2:len(array)-1])/5\n            output[nanIndices[i]] = kNNMean\n        else:\n            kNNMean = np.sum(array[nanIndices[i]-2:nanIndices[i]+2])/5\n            output[nanIndices[i]] = kNNMean\n    return output\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(Z):\n    return 1/(1+np.exp(-Z))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gradientDescentLinReg(wInit,x,y,threshold,alpha):\n    isDiverged = False\n    noOfIterations = 1\n    percentageChangeOfCost = -100000\n    w = copy.deepcopy(wInit)\n    cost = []\n    while percentageChangeOfCost < threshold:\n        h = np.dot(x, w)\n        error = h - y\n        currentCost = np.sum(error ** 2) / (2 * m)\n        if noOfIterations > 1:\n            percentageChangeOfCost = 100 * (currentCost - cost[noOfIterations-1-1]) / currentCost\n        if percentageChangeOfCost > 0:\n            isDiverged = True\n            break\n        gradientVector = np.dot(x.T, error)\n        w -= (alpha / m) * gradientVector\n        cost.append(currentCost)\n        noOfIterations += 1\n    return w,noOfIterations,cost,isDiverged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gradientDescentLogReg(wInit,x,y,threshold,alpha):\n    isDiverged = False\n    noOfIterations = 1\n    percentageChangeOfCost = -100000\n    w = copy.deepcopy(wInit)\n    cost = []\n    while percentageChangeOfCost < threshold:\n        h = sigmoid(np.dot(x, w))\n        error = h - y\n        currentCost = -(np.dot(y.T,np.log(h))[0][0] + np.dot((1-y.T),np.log(1-h))[0][0]) / m\n        if noOfIterations > 1:\n            percentageChangeOfCost = 100 * (currentCost - cost[noOfIterations-1-1]) / currentCost\n        if percentageChangeOfCost > 0:\n            isDiverged = True\n            break\n        gradientVector = np.dot(x.T, error)\n        w -= (alpha / m) * gradientVector\n        cost.append(currentCost)\n        noOfIterations += 1\n    return w,noOfIterations,cost,isDiverged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http://matplotlib.org/examples/color/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\n    \"\"\"\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData = pd.read_csv(\"../input/titanic/train.csv\")\ntestData  = pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Input and Output\n"},{"metadata":{},"cell_type":"markdown","source":"## Inputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"sex = np.where(trainData['Sex'] == 'female',1,0)\npclass = np.array(trainData[\"Pclass\"])\nage = np.array(trainData['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"ageImputed = kNNImputer(age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalizing Input Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sexNormalized = MinMaxScaler(sex)\npclassNormalized = MinMaxScaler(pclass)\nageNormalized = MinMaxScaler(ageImputed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"survived = np.array(trainData[\"Survived\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## No of Data Points"},{"metadata":{"trusted":true},"cell_type":"code","source":"m = survived.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Fitting"},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"### Computing input x and y\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.c_[np.ones((m,1)),sex,pclass,ageImputed]\ny = survived.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Initializing Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = False\nalpha = 0.0001\nthreshold = -0.0001\nwInit = np.zeros((x.shape[1], 1))\ncostList = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"while (not stop):\n    print(alpha)\n    w,noOfIterations,cost,isDiverged = gradientDescentLinReg(wInit,x,y,threshold,alpha)\n    stop = isDiverged\n    if (not isDiverged):\n        currentCostListItem = [alpha, cost]\n        costList.append(currentCostListItem)\n        alpha *= 3\n        wFinalLinReg = w\n        print(noOfIterations,wFinalLinReg)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cost Vs Varying Alpha"},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in range (len(costList)):\n    plt.plot(costList[index][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"linRegPred = np.dot(x,wFinalLinReg)\nlinRegPred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"## Initializing Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = False\nalpha = 0.001\nthreshold = -0.0001\nwInit = np.zeros((x.shape[1], 1))\ncostList = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Applying Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"while (not stop):\n    print(alpha)\n    w,noOfIterations,cost,isDiverged = gradientDescentLogReg(wInit,x,y,threshold,alpha)\n    stop = isDiverged\n    if (not isDiverged):\n        currentCostListItem = [alpha, cost]\n        costList.append(currentCostListItem)\n        alpha *= 3\n        wFinalLogReg = w\n        print(noOfIterations,wFinalLogReg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cost Vs Varying Alpha"},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in range (len(costList)):\n    plt.plot(costList[index][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wFinalLogReg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"logRegPred = sigmoid(np.dot(x,wFinalLogReg))\nlogRegPredBinary = np.where(logRegPred >= 0.5, 1, 0)\npd.DataFrame.from_records(logRegPredBinary).to_csv('pred.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing the Model"},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(cm           = confusion_matrix(y,logRegPredBinary), \n                      normalize    = False,\n                      target_names = ['dead', 'alive'],\n                      title        = \"Confusion Matrix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the Plane of Decision Boundary"},{"metadata":{"trusted":true},"cell_type":"code","source":"xx, yy = np.meshgrid(range(2), range(4))\nz = -(wFinalLogReg[1] * xx + wFinalLogReg[2] * yy + wFinalLogReg[0]) / wFinalLogReg[3]\n\nplt3d = plt.figure().gca(projection='3d')\nplt3d.plot_surface(xx, yy, z, alpha=0.2)\nplt3d.scatter(sex, pclass, ageImputed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly_express as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nlayout = go.Layout(\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    )\n    \n)\n\n\n\n\ntrace1 = go.Scatter3d(\n    x=sex.flatten(),\n    y=pclass.flatten(),\n    z=ageImputed.flatten(),\n    mode='markers',\n    marker=dict(\n        size=3,\n        color='rgb(255,0,0)',                # set color to an array/list of desired values      \n    )\n)\n\ntrace2 = go.Surface(z=z, x=xx, y=yy)\n\nfig = go.Figure(data=[trace1,trace2], layout=layout)\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}