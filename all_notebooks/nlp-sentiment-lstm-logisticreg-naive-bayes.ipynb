{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objective\n\nAs an example, compare a few methods for sentiment analysis: RNN with LSTM, Logistic Regression, and Naive Bayes\n\nLSTM: consider the order of words, use word embedding to represent the input text\n\nLogistic Regression: bag of words approach, use TF-IDF to represent the input text\n\nNaive Bayes: here we also use TF-IDF for text representation, but the model is much different from Logsitic regression,"},{"metadata":{"_cell_guid":"6c53202d-5c34-4859-e7e9-8ef5c7068287","_uuid":"717bb968c36b9325c7d4cae5724a3672e49ff243","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence  # scikit-learn has similar ones. See sklearn.feature_extraction.text\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.utils import resample\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB, ComplementNB, MultinomialNB\nfrom sklearn.preprocessing import LabelEncoder\n\nimport itertools\n\n# get version number of some packages\nimport pkg_resources\nprint(pkg_resources.get_distribution(\"keras\").version)\nprint(pkg_resources.get_distribution(\"scikit-learn\").version)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import data"},{"metadata":{"_cell_guid":"89c8c923-c0bf-7b35-9ab8-e63f00b74e5a","_uuid":"d2bc3bbd2ea3961c49e6673145a0a7226c160e58","trusted":true,"collapsed":true},"cell_type":"code","source":"data = pd.read_csv('../input/Sentiment.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Take a look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('candidate').size().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datetime = pd.to_datetime(data['tweet_created'])\nprint(f\"Tweets are created between {datetime.min()} and {datetime.max()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keep only the neccessary columns\nFor now, let's focus on sentiment analysis only and take only the 'text' and 'sentiment' columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['text','sentiment']].reset_index(drop=True)\n\n# take a look at some random samples and check if the labels are accurate \nidx = np.random.choice(data.index, 5)\nfor i in idx:\n    print(f\"{i:5}  {data.loc[i, 'sentiment']:10}: {data.loc[i, 'text']}\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c0ec63b-cdf8-8e29-812b-0fbbfcea2929","_uuid":"ff12d183224670f9c4c96fd24581b9924d4dff20"},"cell_type":"markdown","source":"# Text Feature Extraction "},{"metadata":{},"cell_type":"markdown","source":"## This shows how keras.preprocessing.text.Tokenizer works"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_text = data['text'].tolist()[0:1]\nprint(f\"sample_text: {sample_text}\")\n\nt = Tokenizer()\nt.fit_on_texts(sample_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the vocabulary\nt.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_to_word_sequence(sample_text[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t.texts_to_sequences(sample_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t.texts_to_matrix(sample_text, mode='tfidf')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sample_text has 15 unique words. If you limit the number of words in the vocabulary to 12."},{"metadata":{"trusted":true},"cell_type":"code","source":"t = Tokenizer(num_words=12)\nt.fit_on_texts(sample_text)\nt.texts_to_sequences(sample_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sequence is shortened because only the most common num_words-1 words will be kept. "},{"metadata":{},"cell_type":"markdown","source":"## Apply Tokenizer to text\n\nHere we limit the vocabulary size to 3000. You can change to see how it affects results. "},{"metadata":{"_cell_guid":"43632d2d-6160-12ce-48b0-e5eb1c207076","_uuid":"d0f8b4542106a279f7398db7285ae5e370b2e813","trusted":true},"cell_type":"code","source":"# choose to exclude neutral samples or not, all codes below will still work\nexclude_neutral = True\nif exclude_neutral:\n    data = data[data.sentiment != \"Neutral\"]\n\n# display class labels\ndisplay(data.groupby('sentiment').size())\n\nnum_classes = len(data['sentiment'].unique())\n\nnum_words = 3000   # the maximum number of words to keep, based on word frequency.\ntransformer = Tokenizer(num_words=num_words)\ntransformer.fit_on_texts(data['text'].values)\nX = transformer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)\nY = pd.get_dummies(data['sentiment'])\nclass_labels = Y.columns.tolist()  # used for plotting confusion matrix\ndisplay(Y.head())\nY = Y.values\nprint(f\"Total {len(transformer.word_index)} words in the vocabulary, {num_words} most common of them are used\")\nprint(f\"X shape {X.shape} \\nY shape {Y.shape} \")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9753421e-1303-77d5-b17f-5f25fa08c452","_uuid":"aa7d103e946e631133d86ef3adc73e1a8b1a1e89"},"cell_type":"markdown","source":"# Build and Train LSTM Network\n\nNote that **num_words**, **embed_dim**, **lstm_out**, **batch_size**, **droupout** variables are hyperparameters, their values are somehow intuitive, can be and should be played with in order to achieve good results. Also note that we are using softmax as activation function. If there are only two target classes, you can use sigmoid function (softmax function reduces to sigmoid function in that case). "},{"metadata":{"_cell_guid":"1ba3cf60-a83c-9c21-05e0-b14303027e93","_uuid":"05cb9ef0ec9e0a4067e3ab7c1bda7b2c1211feda","trusted":true},"cell_type":"code","source":"embed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(num_words, embed_dim, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(units=lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(64,activation='relu'))  # for more model flexibility and smoother transition from 196 to num_classes\nmodel.add(Dense(num_classes,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\n\noriginal_weights = model.get_weights()  # for resetting model weights\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"15f4ee61-47e4-88c4-4b81-98a85237333f","_uuid":"2dae0f3b95a4ba533453c512e573560a8358e162"},"cell_type":"markdown","source":"Split train and test dataset."},{"metadata":{"_cell_guid":"b35748b8-2353-3db2-e571-5fd22bb93eb0","_uuid":"a380bbfae2d098d407b138fc44622c9913a31c07","trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, shuffle=True)\nprint(f\"{X_train.shape[0]:6} samples for train, \\n{X_test.shape[0]:6} samples for test\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2a775979-a930-e627-2963-18557d7bf6e6","_uuid":"8799a667a2c0254cb367c193d86e07ee36d91dd7"},"cell_type":"markdown","source":"Train the Network."},{"metadata":{"_cell_guid":"d5e499ac-2eba-6ff7-8d9a-ff65eb04099b","_uuid":"d0b239912cf67294a9f5af6883bb159c44318fc7","trusted":true},"cell_type":"code","source":"batch_size = 128\nhistory = model.fit(X_train, Y_train, \n                    epochs=10, \n                    batch_size=batch_size, \n                    validation_data=(X_test, Y_test),\n                    verbose=1)\n\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.ylim(bottom=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4ebd7bc1-53c0-0e31-a0b0-b6d0a3017434","_uuid":"47e99d7ed1f27a85eb01dbafc71b66b329fb1d12"},"cell_type":"markdown","source":"Plot confusion matrix"},{"metadata":{"_cell_guid":"1add73e9-c6fb-7e4c-8715-ea92f519d2a6","_uuid":"f80e9f3cf281adb3ab0357cbf6f886eb1dce3005","trusted":true,"collapsed":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_test)\nY_pred_classes = Y_pred.argmax(axis=1)\nY_test_classes = Y_test.argmax(axis=1)\nconfusion_mtx = confusion_matrix(Y_test_classes, Y_pred_classes) \nplot_confusion_matrix(confusion_mtx, classes=class_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Y_test_classes, Y_pred_classes, target_names=class_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model does work becuase prediction for each class is clearly better than random guess. Predicting negative tweets works well, but not for neutral and positive ones. Guess it's understandable that predicting neutral tweets is difficult because it is quite subtle. But the low accuracy for predicting positive tweets may be related to class imbalance - there are many more negative tweets than positive ones in the train data. Let's see if we can improve accuracy by dealing with class imbalance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# class percentage in train data\nsample_composition = Y_train.sum(axis=0)/Y_train.sum()\nsample_composition","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Re-train Model with Updated Sample Weight"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"class_weight = sample_composition.max() / sample_composition\n\nsample_weight = np.ones(Y_train.shape[0])\nfor i in range(Y_train.shape[1]):\n    sample_weight[Y_train[:, i]==1] = class_weight[i] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.set_weights(original_weights) # reset model weights\n\nhistory = model.fit(X_train, Y_train, \n                    sample_weight=sample_weight,\n                    epochs=10, \n                    batch_size=batch_size, \n                    validation_data=(X_test, Y_test),\n                    verbose=1)\n\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.ylim(bottom=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot confusion matrix\nY_pred = model.predict(X_test)\nY_pred_classes = Y_pred.argmax(axis=1)\nY_test_classes = Y_test.argmax(axis=1)\nconfusion_mtx = confusion_matrix(Y_test_classes, Y_pred_classes) \nplot_confusion_matrix(confusion_mtx, classes=class_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Y_test_classes, Y_pred_classes, target_names=class_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall of the positive class improves, but the overall accuray actually becomes slightly worse. "},{"metadata":{"_cell_guid":"890a03c9-316e-4d55-98e1-ba29045eff6c","_uuid":"cfcbefe939b72297019e221ca3f5a283974bffff"},"cell_type":"markdown","source":"# Prediction Example"},{"metadata":{"_cell_guid":"24c64f46-edd1-8d0b-7c7c-ef50fd26b2fd","_uuid":"d9aac68e2013b3beffb6a764cc5b85be83073e66","trusted":true},"cell_type":"code","source":"twt = [\"If Biden gets the nomination, not even Bernie can guarantee Biden progressive voters. Biden has to earn them. He didn't tonight.\"] \n# another example from twitter [\"Biden blatantly lied about his record tonight.\"]\n\n# vectorize the tweet by the pre-fitted tokenizer instance\ntwt = transformer.texts_to_sequences(twt)\n\n# pad the tweet to have same length as train samples\ntwt = pad_sequences(twt, maxlen=X_train.shape[1], dtype='int32', value=0)\n\nsentiment = model.predict(twt, batch_size=1, verbose=1).argmax()\nprint(f\"Sentiment of this tweet is {class_labels[sentiment]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF + Logistic Regression\n\nLet's see how well Logistic Regression works for sentiment classification "},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# use the fitted tokenizer to get the sequences again without the padding zeros\nX = transformer.texts_to_sequences(data['text'].values)\n\n# calcuate TF-IDF\nX = transformer.sequences_to_matrix(X, mode='tfidf')\n\n# Encode target labels (LogisticRegression does not take OneHotEncoding of target labels)\nle = LabelEncoder()\nle.fit(data['sentiment'])\nY = le.transform(data['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, shuffle=True)\nprint(f\"{X_train.shape[0]:6} samples for train, \\n{X_test.shape[0]:6} samples for test\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model\nclf = LogisticRegression(class_weight='balanced').fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean accuracy on test data\nclf.score(X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\nY_pred = clf.predict(X_test)\nconfusion_mtx = confusion_matrix(Y_test, Y_pred) \nplot_confusion_matrix(confusion_mtx, classes=le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# precision and recall\nprint(classification_report(Y_test, Y_pred, target_names=le.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this simple case, performance of logistic regression is only slightly lower than RNN with LSTM. "},{"metadata":{},"cell_type":"markdown","source":"## Prediction Example for Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"twt = [\"If Biden gets the nomination, not even Bernie can guarantee Biden progressive voters. Biden has to earn them. He didn't tonight.\"] \n# another example from twitter [\"Biden blatantly lied about his record tonight.\"]\n\n# get sequence\ntwt = transformer.texts_to_sequences(twt)\n\n# get tfidf \ntwt = transformer.sequences_to_matrix(twt, mode='tfidf')\n\n# predict\nsentiment = le.inverse_transform(clf.predict(twt))[0]\nprint(f\"Sentiment of this tweet is {sentiment}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF + Naive Bayes\n\nNB models are simple and can be extremely fast compared to more sophisticated models. It works quite well in many real-world situations, famously document classification and spam filtering. Let's see how it work in this case."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"clf_NB = MultinomialNB().fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean accuracy on test data\nclf_NB.score(X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion matrix\nY_pred_NB = clf_NB.predict(X_test)\nconfusion_mtx_NB = confusion_matrix(Y_test, Y_pred_NB) \nplot_confusion_matrix(confusion_mtx_NB, classes=le.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# precision and recall\nprint(classification_report(Y_test, Y_pred_NB, target_names=le.classes_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results show that Naive Bayes models also work pretty well. "},{"metadata":{},"cell_type":"markdown","source":"**Next step: It will be interesting to show how much accuracy improvement we will get if word embedding pre-trained with large text corpus. Will work on that when I have the chance.**"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}