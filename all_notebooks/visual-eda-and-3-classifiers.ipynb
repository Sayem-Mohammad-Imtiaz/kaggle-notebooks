{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-23T07:35:53.071372Z","iopub.execute_input":"2021-06-23T07:35:53.071762Z","iopub.status.idle":"2021-06-23T07:35:53.086347Z","shell.execute_reply.started":"2021-06-23T07:35:53.071729Z","shell.execute_reply":"2021-06-23T07:35:53.084923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/congressional-voting-records-data-set/house-votes-84.data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:53.680999Z","iopub.execute_input":"2021-06-23T07:35:53.68134Z","iopub.status.idle":"2021-06-23T07:35:53.697313Z","shell.execute_reply.started":"2021-06-23T07:35:53.68131Z","shell.execute_reply":"2021-06-23T07:35:53.696245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:54.541681Z","iopub.execute_input":"2021-06-23T07:35:54.542125Z","iopub.status.idle":"2021-06-23T07:35:54.572772Z","shell.execute_reply.started":"2021-06-23T07:35:54.542088Z","shell.execute_reply":"2021-06-23T07:35:54.571699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:55.371123Z","iopub.execute_input":"2021-06-23T07:35:55.371461Z","iopub.status.idle":"2021-06-23T07:35:55.390776Z","shell.execute_reply.started":"2021-06-23T07:35:55.37143Z","shell.execute_reply":"2021-06-23T07:35:55.389654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:55.840254Z","iopub.execute_input":"2021-06-23T07:35:55.840648Z","iopub.status.idle":"2021-06-23T07:35:55.894043Z","shell.execute_reply.started":"2021-06-23T07:35:55.840615Z","shell.execute_reply":"2021-06-23T07:35:55.893354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shows the difference in voting behavior between the \n#two parties for the 'education-spending' bill, with each (class name)party colored differently.\nplt.figure()\nsns.countplot(x='education-spending', hue='Class Name', data=df, palette='RdBu')\nplt.xticks([0,1], ['No', 'Yes'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:56.236949Z","iopub.execute_input":"2021-06-23T07:35:56.237548Z","iopub.status.idle":"2021-06-23T07:35:56.383684Z","shell.execute_reply.started":"2021-06-23T07:35:56.237499Z","shell.execute_reply":"2021-06-23T07:35:56.382667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to know which ones do Democrats vote resoundingly in favor of,\n#compared to Republicans out of these bills(satellite and missile)? \nplt.figure()\nsns.countplot(x='anti-satellite-test-ban',hue='Class Name',data=df, palette='RdBu')\nplt.xticks([0,1],['No','Yes'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:56.748945Z","iopub.execute_input":"2021-06-23T07:35:56.749339Z","iopub.status.idle":"2021-06-23T07:35:56.898079Z","shell.execute_reply.started":"2021-06-23T07:35:56.749306Z","shell.execute_reply":"2021-06-23T07:35:56.897012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nsns.countplot(x='mx-missile',hue='Class Name',data=df, palette='RdBu')\nplt.xticks([0,1],['No','Yes'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:57.01507Z","iopub.execute_input":"2021-06-23T07:35:57.015438Z","iopub.status.idle":"2021-06-23T07:35:57.1596Z","shell.execute_reply.started":"2021-06-23T07:35:57.015408Z","shell.execute_reply":"2021-06-23T07:35:57.158899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing KNeighbors classifier from sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\ndf01=df.replace(['n','y','?'],[0,1,np.nan])\n\n#missing values\ndf01.isnull().sum()\ndf01.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:57.219969Z","iopub.execute_input":"2021-06-23T07:35:57.220471Z","iopub.status.idle":"2021-06-23T07:35:57.255363Z","shell.execute_reply.started":"2021-06-23T07:35:57.220425Z","shell.execute_reply":"2021-06-23T07:35:57.254315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing values\nprint(df01.isnull().sum())\nprint(\" \\nTotal Missing values are : \", df01.isnull().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:57.384906Z","iopub.execute_input":"2021-06-23T07:35:57.38527Z","iopub.status.idle":"2021-06-23T07:35:57.394518Z","shell.execute_reply.started":"2021-06-23T07:35:57.38523Z","shell.execute_reply":"2021-06-23T07:35:57.393616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create arrays for the features  and the response varaible\n#Without using .values, X and y are a DataFrame and Series respectively; \n#use of the .values attribute to ensure X and y are NumPy arrays\ny=df01[\"Class Name\"].values                 #the output variable or the predictor\nX=df01.drop(\"Class Name\",axis=1).values    #Deleting from the dataset\n\nimp=SimpleImputer(missing_values=np.nan,strategy='most_frequent')\nimp.fit(X)\nX=imp.transform(X)\n\n\n#imputing with a pipline\n#imp=SimpleImputer(missing_values=np.nan,strategy='mean')\nknn=KNeighborsClassifier(n_neighbors=8)   #instantiate model\nsteps=[('imputation',imp),   #build a pipeline object (each last step must be an transformer and estimator)\n       ('KNeighborsClassifier(n_neighbors=8)',knn)]  #each step is 2 tuple, containing the name for relevant step and estimator","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:57.982116Z","iopub.execute_input":"2021-06-23T07:35:57.982515Z","iopub.status.idle":"2021-06-23T07:35:57.995639Z","shell.execute_reply.started":"2021-06-23T07:35:57.982481Z","shell.execute_reply":"2021-06-23T07:35:57.994501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pass the steps to the pipeline Constructor\npipeline=Pipeline(steps)\n\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=42,stratify=y)\n\n#Create a KNN classifier with 6 Neighbors\n#knn=KNeighborsClassifier(n_neighbors=8)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:58.380023Z","iopub.execute_input":"2021-06-23T07:35:58.380381Z","iopub.status.idle":"2021-06-23T07:35:58.38735Z","shell.execute_reply.started":"2021-06-23T07:35:58.380346Z","shell.execute_reply":"2021-06-23T07:35:58.38615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit the classifier to the data\npipeline.fit(X_train,y_train)\n    \n#predicting the labels for the tesring data\ny_prediction=pipeline.predict(X_test)  #will generate 435 predictions, 1 for each sample\n#y_prediction.replace(['democrat','republic'],[0,1])\n\n#predict and print the label for the new data point X_new\n#new_prediction=knn.predict(X_new)  #will generate 1 prediction\nprint(\"Prediction: {}\".format(y_prediction))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:58.663122Z","iopub.execute_input":"2021-06-23T07:35:58.663502Z","iopub.status.idle":"2021-06-23T07:35:58.691421Z","shell.execute_reply.started":"2021-06-23T07:35:58.66347Z","shell.execute_reply":"2021-06-23T07:35:58.690283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classification report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(y_test,y_prediction,target_names=['democrat','republican']))\nprint(confusion_matrix(y_test,y_prediction))\n#compute Accuracy\nprint(accuracy_score(y_test, y_prediction))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:35:59.317002Z","iopub.execute_input":"2021-06-23T07:35:59.317328Z","iopub.status.idle":"2021-06-23T07:35:59.336774Z","shell.execute_reply.started":"2021-06-23T07:35:59.317299Z","shell.execute_reply":"2021-06-23T07:35:59.335293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import plot_confusion_matrix\n#initiate model\nlogreg=LogisticRegression(solver='lbfgs',max_iter=1000)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:54:01.687941Z","iopub.execute_input":"2021-06-23T08:54:01.688365Z","iopub.status.idle":"2021-06-23T08:54:01.694597Z","shell.execute_reply.started":"2021-06-23T08:54:01.688328Z","shell.execute_reply":"2021-06-23T08:54:01.693334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg.fit(X_train,y_train)\n\n# predict probabilities\n# keep probabilities for the positive outcome only =[:,1]\n#we choose second column that si the probabilites of predicted label being 1\ny_pred_logR=logreg.predict_proba(X_test)[:,1]\n#proba which returns the probability of a given sample being in a particular class.","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:54:02.68801Z","iopub.execute_input":"2021-06-23T08:54:02.688373Z","iopub.status.idle":"2021-06-23T08:54:02.703828Z","shell.execute_reply.started":"2021-06-23T08:54:02.688335Z","shell.execute_reply":"2021-06-23T08:54:02.702232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#when threshold =0, model prdicts 1 for all data(tpr=fpr=1)\n#when threshold =1, model prdicts 0 for all data(tpr=fpr=0)\n#But if we vary threshold between these two extremes ,we get series of  diff tpr and fpr\n#the set points we get is called ROC curve\n#here we used predicted probalites  of model assiging value =1 to obervation in quesio\n#becauew to get both the probolatiy of log reg and prediitons , so we do predict proba- retunrs two arrays\nfpr,tpr,thresholds=roc_curve(y_test, y_pred_logR,pos_label=True)\n\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Logistic Regression Logistic ROC curve')\nplt.show()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-06-23T08:54:03.555442Z","iopub.execute_input":"2021-06-23T08:54:03.555858Z","iopub.status.idle":"2021-06-23T08:54:03.696924Z","shell.execute_reply.started":"2021-06-23T08:54:03.555823Z","shell.execute_reply":"2021-06-23T08:54:03.695949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\ndispl = metrics.plot_confusion_matrix(pipeline, X_test, y_test)\ndispl.figure_.suptitle(\"Confusion Matrix\")\nprint(f\"Confusion matrix:\\n{displ.confusion_matrix}\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:54:04.828795Z","iopub.execute_input":"2021-06-23T08:54:04.829251Z","iopub.status.idle":"2021-06-23T08:54:05.067769Z","shell.execute_reply.started":"2021-06-23T08:54:04.829209Z","shell.execute_reply":"2021-06-23T08:54:05.066852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import  modules\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score\n\n# Compute predicted probabilities: y_pred_prob\ny_pred_logR = logreg.predict_proba(X_test)[:,1]\n\n# Compute and print AUC score\nprint(\"AUC: {}\".format(roc_auc_score(y_test,y_pred_logR)))\n\n# Compute cross-validated AUC scores: cv_auc\ncross_valid_auc = cross_val_score(logreg,X,y,cv=5,scoring='roc_auc')\n\n# Print list of AUC scores\nprint(\"AUC scores computed using 5-fold cross-validation: {}\".format(cross_valid_auc))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:54:06.194857Z","iopub.execute_input":"2021-06-23T08:54:06.195546Z","iopub.status.idle":"2021-06-23T08:54:06.255089Z","shell.execute_reply.started":"2021-06-23T08:54:06.195486Z","shell.execute_reply":"2021-06-23T08:54:06.254251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import GridSearchCV\n\n# Setup the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space} #grid as dictionary\n\n# Instantiate the GridSearchCV object: logreg_cv\nlogreg_cv = GridSearchCV(logreg,param_grid, cv=5)  \n\n#also RandomizedSearchCV will save on computational time but never outperform Gridserach\n\n\nlogreg_cv.fit(X_train,y_train)\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \nprint(\"Best score is {}\".format(logreg_cv.best_score_))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T08:54:08.96787Z","iopub.execute_input":"2021-06-23T08:54:08.968491Z","iopub.status.idle":"2021-06-23T08:54:11.236042Z","shell.execute_reply.started":"2021-06-23T08:54:08.968436Z","shell.execute_reply":"2021-06-23T08:54:11.235106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#under Progress hypertuining and elastic regression\n\n#regularized regression = Elastic regression\nfrom sklearn.linear_model import ElasticNet \nfrom sklearn.metrics import mean_squared_error\n\n\n# Create the hyperparameter grid\nl1_space = np.linspace(0, 1, 30)\nparam_grid = {'l1_ratio':l1_space }\n\n# Instantiate the ElasticNet regressor: elastic_net\nelastic_net = ElasticNet()\n\n# Setup the GridSearchCV object: gm_cv\ngm_cv = GridSearchCV(elastic_net,param_grid,cv=5)\n\n# Fit it to the training data\ngm_cv.fit(X_train,y_train)\n\n# Predict on the test set and compute metrics\ny_pred = gm_cv.predict(X_test)\nr2 = gm_cv.score(X_test, y_test)\nmse = mean_squared_error(y_test,y_pred)\nprint(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\nprint(\"Tuned ElasticNet R squared: {}\".format(r2))\nprint(\"Tuned ElasticNet MSE: {}\".format(mse))\n","metadata":{},"execution_count":null,"outputs":[]}]}