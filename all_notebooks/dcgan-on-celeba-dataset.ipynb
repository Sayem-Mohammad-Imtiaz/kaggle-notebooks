{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Implementation Details\nThe models of the discriminator and generator are inspired from [here](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). The different hyperparameter values and the idea of explicit random weight initialization from a normal distribution with mean 0 and standard deviation 0.02 are taken from this [DCGAN Paper](https://arxiv.org/abs/1511.06434).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Defining Accelerator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.datasets as dataset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport torch.optim as optim\nimport torch.utils as utils\n\n# Input data files are available in the read-only \"../input/\" directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# Input data files are available in the read-only \"../input/\" directory\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Training Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"image_size = 64\ntransform = transforms.Compose([transforms.Resize(image_size), transforms.CenterCrop(image_size), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\nIMAGE_PATH = '../input/celeba-dataset/img_align_celeba/'\n\ndset = dataset.ImageFolder(root = IMAGE_PATH, transform = transform)\ndataloader = utils.data.DataLoader(dset, batch_size = 128, shuffle = True, num_workers = 2, drop_last = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"real_batch = next(iter(dataloader))\nplt.figure(figsize = (8, 8))\nplt.axis('off')\nplt.title('Training Images')\nplt.imshow(np.transpose((vutils.make_grid(real_batch[0].to(device)[:64], padding = 2, normalize = True)).cpu().numpy(), (1, 2, 0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Weight Initialization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def weight_init(instance):\n    classname = instance.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(instance.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(instance.weight.data, 0.0, 0.02)\n        nn.init.constant_(instance.bias.data, 0.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Discriminator Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv2_bn = nn.BatchNorm2d(128)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv3_bn = nn.BatchNorm2d(256)\n        self.conv4 = nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv4_bn = nn.BatchNorm2d(512)\n        self.conv5 = nn.Conv2d(512, 1, kernel_size = 4, stride = 1, padding = 0, bias = False)\n        \n    def forward(self, x):\n        x = x.view(-1, 3, 64, 64)\n        x = F.leaky_relu(self.conv1(x), 0.2, inplace = True)\n        x = self.conv2(x)\n        x = F.leaky_relu(self.conv2_bn(x), 0.2, inplace = True)\n        x = self.conv3(x)\n        x = F.leaky_relu(self.conv3_bn(x), 0.2, inplace = True)\n        x = self.conv4(x)\n        x = F.leaky_relu(self.conv4_bn(x), 0.2, inplace = True)\n        x = self.conv5(x)\n        x = F.sigmoid(x)\n        out = x.view(-1, 1)\n        \n        return out        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generator Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv_transpose1 = nn.ConvTranspose2d(100, 512, kernel_size = 4, stride = 1, padding = 0, bias = False)\n        self.conv_transpose1_bn = nn.BatchNorm2d(512)\n        self.conv_transpose2 = nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv_transpose2_bn = nn.BatchNorm2d(256)\n        self.conv_transpose3 = nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv_transpose3_bn = nn.BatchNorm2d(128)\n        self.conv_transpose4 = nn.ConvTranspose2d(128, 64, kernel_size = 4, stride = 2, padding = 1, bias = False)\n        self.conv_transpose4_bn = nn.BatchNorm2d(64)\n        self.conv_transpose5 = nn.ConvTranspose2d(64, 3, kernel_size = 4, stride = 2, padding = 1, bias = False)\n    \n    def forward(self, x):\n        x = x.view(-1, 100, 1, 1)\n        x = self.conv_transpose1(x)\n        x = F.relu(self.conv_transpose1_bn(x), inplace = True)\n        x = self.conv_transpose2(x)\n        x = F.relu(self.conv_transpose2_bn(x), inplace = True)\n        x = self.conv_transpose3(x)\n        x = F.relu(self.conv_transpose3_bn(x), inplace = True)\n        x = self.conv_transpose4(x)\n        x = F.relu(self.conv_transpose4_bn(x), inplace = True)\n        x = self.conv_transpose5(x)\n        out = torch.tanh(x)\n        \n        return out   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Model Instances","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"D = Discriminator()\nD = D.to(device)\nD = D.float()\nD.apply(weight_init)\nprint(D)\n\nG = Generator()\nG = G.to(device)\nG = G.float()\nG.apply(weight_init)\nprint(G)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining Losses","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = nn.BCELoss()\ndef real_loss_fn(real_out):\n    labels = torch.ones(real_out.size()[0], 1).to(device)\n    loss_real = loss(real_out.squeeze(), labels.squeeze())\n    return loss_real\n\ndef fake_loss_fn(fake_out):\n    labels = torch.zeros(fake_out.size()[0], 1).to(device)\n    loss_fake = loss(fake_out.squeeze(), labels.squeeze())\n    return loss_fake","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining Optimizers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"disc_opt = optim.Adam(D.parameters(), lr = 0.0002, betas = (0.5, 0.999))\ngen_opt = optim.Adam(G.parameters(), lr = 0.0002, betas = (0.5, 0.999)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(D, G, dataloader, disc_opt, gen_opt, num_epochs, fac, batch_size = 128):\n    \n    disc_losses = []\n    gen_losses = []\n    \n    fixed_noise = torch.randn(64, 100).to(device)\n    \n    D.train()\n    G.train()\n    \n    for epoch in range(num_epochs + 1):\n        \n        gen_loss_total = 0\n        disc_loss_total = 0\n        \n        for i, data in enumerate(dataloader, 0):\n            disc_opt.zero_grad()\n            \n            x = data[0].to(device)\n            real_out = D(x.float())\n            real_loss = real_loss_fn(real_out)\n            \n            gen_in1 = torch.randn(batch_size, 100).to(device)\n            disc_gen_in1 = G(gen_in1.float()).detach()\n            fake_out = D(disc_gen_in1.float())\n            fake_loss = fake_loss_fn(fake_out)\n            \n            disc_loss = real_loss + fake_loss\n            disc_loss_total += disc_loss\n            \n            disc_loss.backward()\n            disc_opt.step()\n            \n            gen_opt.zero_grad()\n            \n            gen_in2 = torch.randn(batch_size, 100).to(device)\n            disc_gen_in2 = G(gen_in2.float())\n            real_fake_out = D(disc_gen_in2.float())\n            gen_loss = real_loss_fn(real_fake_out)\n            gen_loss_total += gen_loss\n            \n            gen_loss.backward()\n            gen_opt.step()\n            \n        disc_losses.append(disc_loss_total)\n        gen_losses.append(gen_loss_total)\n        print(\"Epoch \", epoch, \" - \", \"Discriminator Loss: \", disc_loss_total/len(dataloader), \" Generator Loss: \", gen_loss_total/len(dataloader))\n        \n        if epoch % fac == 0:\n            G.eval()\n            sample_out = G(fixed_noise.float())\n            G.train()\n            \n            plt.figure(figsize = (8,8))\n            plt.axis('off')\n            \n            sample_out = vutils.make_grid(sample_out, padding = 2, normalize = True).cpu().detach().numpy()\n            sample_out = np.transpose(sample_out, (1, 2, 0))\n            plt.imshow(sample_out)\n            \n    return disc_losses, gen_losses            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disc_losses, gen_losses = train(D, G, dataloader, disc_opt, gen_opt, 5, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting Losses","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"disc_losses = np.array(disc_losses)\ngen_losses = np.array(gen_losses)\nplt.figure(figsize = (10, 5))\nplt.title('Discriminator and Generator Losses')\nplt.plot(disc_losses, label = 'Discriminator')\nplt.plot(gen_losses, label = 'Generator')\nplt.xlabel('Iterations')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}