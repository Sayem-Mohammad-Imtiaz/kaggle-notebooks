{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 1 : PreProcess Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator,load_img\nimport numpy as np\nimport os\n#import Pillow\n#from PIL import Image\n#import opencv\nfrom PIL import Image\nfrom keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\nimport numpy as np\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, initializers\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nimport numpy as np\n\n\n\nimg_h, img_w = 400,400\nchannels = 3\nbatch_size = 30               \ntrain_dir = '/kaggle/input/breakhis-400x/BreaKHis 400X/train' \ntest_dir = '/kaggle/input/breakhis-400x/BreaKHis 400X/test'\nresult_dir = '/kaggle/output/Kaggle/working'        \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_normal_files = os.listdir(os.path.join(train_dir,'benign'))\nprint(len(train_normal_files))\n#371\n\ntrain_malignant_files = os.listdir(os.path.join(train_dir,'malignant'))\nprint(len(train_malignant_files))\n#777\n\ntest_normal_files = os.listdir(os.path.join(test_dir,'benign'))\nprint(len(test_normal_files))\n#371\n\ntest_malignant_files = os.listdir(os.path.join(test_dir,'malignant'))\nprint(len(test_malignant_files))\n#777\n\nnum_train=len(train_normal_files)+len(train_malignant_files)\nnum_validation=len(test_normal_files)+len(test_malignant_files)\n\nprint(num_train)\nprint(num_validation)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of Learning: 1148 pictures\n#Number of Validation:545 pictures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\n# !ls -lh '/content/gdrive/My Drive/Colab Notebooks/BreakHis/data/train'\n\nnormal_files = os.listdir(os.path.join(train_dir,'benign'))[:12]\nprint(normal_files)\n\npneumonia_files = os.listdir(os.path.join(train_dir,'malignant'))[:12]\nprint(pneumonia_files)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2 : Imaging Data Visual Check"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\n\nfig = plt.figure(figsize=(12,20))\nplt.subplots_adjust(wspace=0.5, hspace=0.5)\n\nfor i in range(12):\n  img = cv2.imread(os.path.join(train_dir,'benign',normal_files[i]))\n  ax = fig.add_subplot(6,2,i+1)\n  ax.set_title('benign'+'- '+normal_files[i])\n  a='('+str(img.shape[0])+','+str(img.shape[1])+')'\n  ax.set_xlabel(a)\n  ax.imshow(img)\nplt.show()\n\nfig = plt.figure(figsize=(12,20))\nplt.subplots_adjust(wspace=0.5, hspace=0.5)\n\nfor i in range(12):\n  img = cv2.imread(os.path.join(train_dir,'malignant',pneumonia_files[i]))\n  ax = fig.add_subplot(6,2,i+1)\n  ax.set_title('malignant'+'- '+normal_files[i])\n  a='('+str(img.shape[0])+','+str(img.shape[1])+')'\n  ax.set_xlabel(a)\n  ax.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 3 : Model Fitting"},{"metadata":{},"cell_type":"markdown","source":"# # Load Module "},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator,load_img\nimport numpy as np\nimport os\n#import Pillow\n#from PIL import Image\n#import opencv\nfrom PIL import Image\nfrom keras.preprocessing.image import load_img, save_img, img_to_array, array_to_img\nimport numpy as np\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, initializers\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nimport numpy as np\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.models import Model\nimport tensorflow as tf\nimport keras\nfrom tensorflow import keras\nfrom keras.layers import Conv2D, MaxPooling2D,Input, GlobalMaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten, Activation,GlobalAveragePooling2D,Input\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras import optimizers\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## InceptionResNetV2 model\n\nimg_h, img_w = 400,400\nchannels = 3\nbatch_size = 30  \nnb_classes = 1\n\n#batch_size = 30  \n#nb_classes = 1\n\ndef analysis_model():\n    \n    # Load InceptionResNetV2 / Because FC layer is unecessary, set include_top=False\n    input_tensor = Input(shape=(img_h,img_w,channels))\n    inception_v3 = InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n    \n    # Load InceptionResNetV2 /  frozen the portion of weight of model.\n    for layer in inception_v3.layers[:775]:\n        layer.trainable = False\n    for layer in inception_v3.layers[775:]:\n        layer.trainable = True\n        \n    # define FC Layer\n        \n    model = Sequential()\n    model.add(inception_v3)\n    model.add(GlobalMaxPooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid', name='sigmoid'))\n\n   # compile model\n    model.compile(loss='binary_crossentropy',\n                  optimizer=optimizers.RMSprop(lr=1e-5),\n                  metrics=['accuracy'])\n    \n    return model\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Learning Rate Set Up"},{"metadata":{"trusted":true},"cell_type":"code","source":"    \ndef step_decay(epoch):\n    initial_lrate = 0.00001 # initial rate for learning\n    drop = 0.5              # decay rate 50%\n    epochs_drop = 10.0      # decay per 10 epochs\n    lrate = initial_lrate * math.pow(\n            drop,\n            math.floor((epoch)/epochs_drop)\n             )\n    return lrate\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # LRHistory Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, Callback\n\nclass LRHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.acc = []\n        self.lr = []\n\n    def on_epoch_end(self, batch, logs={}):\n        self.acc.append(logs.get('acc'))\n        self.lr.append(step_decay(len(self.acc)))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Data Augumentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 / 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    zoom_range=0.8,\n    shear_range=0.2,     \n)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,            \n    target_size=(img_h, img_w), \n    batch_size=batch_size,      \n    class_mode='binary',        \n)\n\n\ntest_datagen = ImageDataGenerator(rescale=1.0 / 255)\n\n\n\nvalidation_generator = test_datagen.flow_from_directory(\n    test_dir,       \n    target_size=(img_h, img_w), \n    batch_size=batch_size,      \n    class_mode='binary',      \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Model Fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"    def train(train_generator,validation_generator,num_train,num_validation,epochs):\n        \n        model=analysis_model()\n        lr_history=LRHistory()\n        lrate = LearningRateScheduler(step_decay())\n        callbacks_list=[lr_history,lrate]\n        \n        \n        history = model.fit(\n            train_generator,\n            \n            epochs=epochs,\n            \n            validation_data=validation_generator,\n            \n            validation_steps=num_validation//batch_size,\n            \n            steps_per_epoch=num_train//batch_size,\n            \n            verbose=1,\n            \n            callbacks=callbacks_list)\n        \n        return history, lr_history","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Execution of model fitting\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"    %%timeit\n    \n    history, lr_history =train(train_generator,validation_generator,1148,545,10)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 4 : Plot for Accuracy, Loss and Learning Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\ndef plot_acc_loss_lr(history):\n    # plot for accuracy\n    plt.plot(history.history['accuracy'],\"-\",label=\"accuracy\")\n    plt.plot(history.history['val_accuracy'],\"-\",label=\"val_acc\")\n    plt.title('accuracy')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    # plot for loss\n    plt.plot(history.history['loss'],\"-\",label=\"loss\",)\n    plt.plot(history.history['val_loss'],\"-\",label=\"val_loss\")\n    plt.title('loss')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(loc='upper right')\n    plt.show()\n    \n   # plot for learning rate\n    plt.plot(lr_history.lr,label=\"learning rate\",color='blue')\n    plt.title('Learning Rate')\n    plt.xlabel('epoch')\n    plt.ylabel('Learning Rate')\n    plt.legend(loc='upper right')\n    plt.show()\n    \n# output \nplot_acc_loss_lr(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5 : Conclusion\n"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}