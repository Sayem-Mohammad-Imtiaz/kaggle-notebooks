{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bank Note Authentication UCI data"},{"metadata":{},"cell_type":"markdown","source":"- Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n\n- Dataset can be used for Binary Classification sample problems\n\n- Identify if bank note is authentic or not"},{"metadata":{},"cell_type":"markdown","source":"# 1. Import the libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploring the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/bank-note-authentication-uci-data/BankNote_Authentication.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- No missing values seen in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of duplicate entries = {df[df.duplicated()].size}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The Duplicate Entries are\ndf[df.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We Drop the duplicate values\ndf = df.drop_duplicates(keep='first')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(f'Number of data samples: {df.shape[0]}')\nprint(f'Number of features: {df.shape[1] - 1}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of samples of Class 0: {df[\"class\"].value_counts()[0]}')\nprint(f'Number of features of Class 1: {df[\"class\"].value_counts()[1]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(df['class'].unique(),df['class'].value_counts(), width=0.5)\nplt.title('Target Value Distribution')\nplt.xlabel('Target Class')\nplt.ylabel('Counts for each class')\nplt.xticks([0,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sns.pairplot(df, hue='class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(bins=20,figsize=(11,9),layout=(2,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Train-Test Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(labels=['class'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['class']\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train,  y_test = train_test_split(X, y, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'X_train shape is {X_train.shape}')\nprint(f'y_train shape is {y_train.shape}')\n\nprint(f'X_test shape is {X_test.shape}')\nprint(f'X_test shape is {y_test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,sharey=True,sharex=True,figsize=(10,5))\n\nax[0].bar(y_train.unique(),y_train.value_counts(), edgecolor='black')\nax[0].set_title('Training Class Labels Distribution')\nax[0].set_xticks(ticks=[0,1])\nax[0].set_xticklabels(labels=[\"Class 0\",\"Class 1\"])\nax[0].set_ylabel('Counts')\n\nax[1].bar(y_test.unique(),y_test.value_counts(), edgecolor='black',color='yellow')\nax[1].set_title('Test Class Labels Distribution')\nax[1].set_xticks(ticks=[0,1])\nax[1].set_xticklabels(labels=[\"Class 0\",\"Class 1\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Scaling the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\n#! Remember to scale on X_train that is based on mean and std of training data\nscaler.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Machine Learning Models"},{"metadata":{},"cell_type":"markdown","source":"## 5.1.1 K Nearest Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def knn_get_training_testing_scores(neighbour_counts):\n    \n    training_scores = []\n    test_scores = []\n\n    for k_neighbours in neighbour_counts:\n        knn_clf = KNeighborsClassifier(n_neighbors=k_neighbours)\n        knn_clf.fit(X_train_scaled,y_train)\n\n        training_scores.append(knn_clf.score(X_train_scaled, y_train))\n        test_scores.append(knn_clf.score(X_test_scaled, y_test))\n\n    return training_scores, test_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbour_count_parameter = [i for i in range(1,11,1)]\ntraining_scores, test_scores = knn_get_training_testing_scores(neighbour_count_parameter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(neighbour_count_parameter,test_scores,label='Training Score')\nplt.plot(neighbour_count_parameter,training_scores, label='Test Score')\n\nplt.xticks(neighbour_count_parameter)\nplt.title('Number of Neighbours vs Train-Test Scores')\nplt.xlabel('Number of Neighbours')\nplt.ylabel('Accuracy Scores')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### We find that k=2 has a good generalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_clf = KNeighborsClassifier(n_neighbors=2)\nknn_clf.fit(X_train_scaled,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_y_hat = knn_clf.predict(X_test_scaled)\n#knn_y_hat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Training Set accuracy score : {knn_clf.score(X_train_scaled, y_train)}')\nprint(f'Test Set accuracy score : {knn_clf.score(X_test_scaled, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.1.2 Perfomace Measures"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix  \nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_confusion_matrix = confusion_matrix(y_test,knn_y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.heatmap(knn_confusion_matrix, annot=True, square=True)\n\nax.set_xlabel('Predicted Class')\nax.set_ylabel('Actual Class')\n\nlabels = ['Class 0', 'Class 1']\nax.set_xticklabels(labels,ha='center', minor=False)\nax.set_yticklabels(labels,ha='center', minor=False)\n\ntitle_string = f'Accuracy Score: {round(knn_clf.score(X_test_scaled, y_test),3)}'\nax.set_title(title_string, size = 13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_report = classification_report(y_test, knn_y_hat, target_names=[\"Class 0\",\"Class 1\"])\nprint(score_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2.1 Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_logistic_regression_train_test_scores(c_parameters):\n    \n    training_scores = []\n    testing_scores = []\n    \n    for c in c_parameters:\n        model = LogisticRegression(C=c)\n        model.fit(X_train_scaled, y_train)\n        training_scores.append(model.score(X_train_scaled,y_train))\n        testing_scores.append(model.score(X_test_scaled,y_test))\n\n    return training_scores,testing_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_parameters = [0.01, 0.1, 1, 10, 100, 1000]\nlr_train_scores, lr_test_scores = get_logistic_regression_train_test_scores(c_parameters)\n\nprint(f'Training Score, Test Scores')\nfor train_score,test_score in zip(lr_train_scores, lr_test_scores):\n    print((train_score,test_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n\nplt.plot(lr_train_scores, label='Training Score',c='b',marker='o')\nplt.plot(lr_test_scores, label='Test Score',c='g',marker='o')\n\nplt.xticks(ticks=range(len(c_parameters)),labels=['0.01', '0.1', '1', '10', '100', '1000'])\n\nplt.xlabel('Coefficient of Regularization (C)')\nplt.ylabel('Accuracy Score')\n\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We find that for C = 1, 10 the model has good scores"},{"metadata":{},"cell_type":"markdown","source":"- Smaller values of C implies lots of regularization, making the model simpler and reducing chance of overfitting.\n- As C increases the effect of regularization decreases, thereby making the model more complex.\n- Very high values of C results in little to no regularization, which results to the model overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_reg = LogisticRegression(C=10)\nlogit_reg.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_reg_y_hat = logit_reg.predict(X_test_scaled)\n#print(logit_reg_y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Training Set accuracy score : {logit_reg.score(X_train_scaled, y_train)}')\nprint(f'Test Set accuracy score     : {logit_reg.score(X_test_scaled, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Features  : {list(df.columns[:-1])}\" )\nprint(f\"Weights   : {list(np.round(logit_reg.coef_[0],3))}\")\nprint(f\"Intercept : {np.round(logit_reg.intercept_,2)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2.2 Performace Measure"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_confusion_matrix = confusion_matrix(y_test,logit_reg_y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.heatmap(lr_confusion_matrix, annot=True, square=True)\n\nax.set_xlabel('Predicted Class')\nax.set_ylabel('Actual Class')\n\nlabels = ['Class 0', 'Class 1']\nax.set_xticklabels(labels,ha='center', minor=False)\nax.set_yticklabels(labels,ha='center', minor=False)\n\ntitle_string = f'Accuracy Score: {round(logit_reg.score(X_test_scaled, y_test),3)}'\nax.set_title(title_string, size = 13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_report = classification_report(y_test, logit_reg_y_hat, target_names=[\"Class 0\",\"Class 1\"])\nprint(score_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}