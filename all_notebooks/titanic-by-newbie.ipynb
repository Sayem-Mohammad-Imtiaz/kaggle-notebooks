{"cells":[{"metadata":{"id":"pxO3HAEKXbaD"},"cell_type":"markdown","source":"# Titanic"},{"metadata":{"id":"LX1TF3s4XbaK","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport re\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"rDjGyaytXbaZ","outputId":"023f27a4-9cb6-4817-ed12-5464062f5116","trusted":true},"cell_type":"code","source":"# Load in the train and test datasets\ntrain = pd.read_csv('../input/titanic-machine-learning-from-disaster/test.csv')\ntest = pd.read_csv('../input/titanic-machine-learning-from-disaster/test.csv')\n\n# Store our passenger ID for easy access\nPassengerId = test['PassengerId']\n\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"id":"g2dvsncuXban","trusted":true},"cell_type":"code","source":"full_data = [train, test]\n\n# Gives the length of the name\ntrain['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)\n# Feature that tells whether a passenger had a cabin on the Titanic\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n\n# Create new feature FamilySize as a combination of SibSp and Parch\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n# Create new feature IsAlone from FamilySize\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n# Remove all NULLS in the Embarked column\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n# Remove all NULLS in the Fare column and create a new feature CategoricalFare\nfor dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n# Create a New feature CategoricalAge\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n# Define function to extract titles from passenger names\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n# Create a new feature Title, containing the titles of passenger names\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n# Group all non-common titles into one single grouping \"Rare\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nfor dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4","execution_count":null,"outputs":[]},{"metadata":{"id":"6BA6Gkj-Xba0","trusted":true},"cell_type":"code","source":"# Feature selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\ntest  = test.drop(drop_elements, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"I2DXDDnCXba8","outputId":"c3223475-827e-4e1b-a029-844306793f13","trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"id":"Jtrbw694XbbG","outputId":"4cc29f9e-1332-473b-8bb9-f7d32965360c","trusted":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"cLcwBZRXXbbR","outputId":"ea2c24a0-1b63-4426-a533-57adb83eb9be","trusted":true},"cell_type":"code","source":"g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', \n                        u'Embarked', u'FamilySize', u'Title']], \n                 hue='Survived', palette = 'seismic', size=1.2, plot_kws=dict(s=10))\ng.set(xticklabels=[])","execution_count":null,"outputs":[]},{"metadata":{"id":"betqXe7KXbbb"},"cell_type":"markdown","source":"Итак, у нас получились два датасета с новыми признаками. Теперь приступим к построению модели.\n\n### Построение модели\n\n### 1.\n\nВоспользуйтесь вашим алгоритмом стекинга из предыдущего домашнего задания. В качестве базовых алгоритмов используйте RandomForestClassifier, SVC, GradientBoostingClassifier и LogisticRegression; в качестве мета-алгоритма - XGBoost.\n\nРазделите данные train на тренировочную и валидационную выборки с random_state=17 и параметром разбиения test_size=.3 (в качестве целевой переменной возьмите столбец Survived, а в качестве признаков - все остальные столбцы).\n\nНиже приведены параметры для каждого из базовых алгоритмов, которые необходимо настроить на 5-кратной кросс-валидации с помощью GridSearchCV:"},{"metadata":{"id":"_u1wEHlnXbbe","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import (GridSearchCV,\n                                     train_test_split,\n                                     StratifiedKFold)\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBClassifier\n\n# параметры базовых алгоритмов\ngbc_params = {'learning_rate': np.arange(0.1, 0.6, 0.1)} # GradientBoostingClassifier\n\nrfc_params = {'n_estimators': range(10, 100, 10), # RandomForestClassifier\n              'min_samples_leaf': range(1, 5)}\n\nsvc_params = {'kernel': ['linear', 'rbf'], # SVC\n              'C': np.arange(0.1, 1, 0.2)}\n\nlr_params = {'C': np.arange(0.5, 1, 0.1)}\n\nskf = StratifiedKFold(n_splits=5, random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# получение тренировочных и валидационных данных\nx_train, x_valid, y_train, y_valid = train_test_split(train.iloc[:,1:].values,\n                                                      train.iloc[:,0].values,\n                                                      random_state=17,\n                                                      test_size=.3)","execution_count":null,"outputs":[]},{"metadata":{"id":"P-LUQKa9Xbbk"},"cell_type":"markdown","source":"### 2.\n1. Определите объект GridSearchCV для всех приведенных параметров каждого алгоритма (в гиперпараметрах алгоритма при его определении, если возможно, укажите random_state=17). Параметр cv устанавливайте равным skf.\n\n2. Обучите каждый из объектов из 1-го пункта на получившейся при разбиении тренировочной выборке. Выведите лучшее сочетание параметров для каждого из алгоритмов.\n\n3. Для каждого обученного алгоритма получите предсказания на валидационных данных и выведите метрику качества, которая соответствует метрике оценки соревнования."},{"metadata":{"id":"so002-PDXbbm","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# инициализация моделей c GridSearchCV\ngbc = GradientBoostingClassifier(random_state=17)\ngbc_gs = GridSearchCV(gbc, gbc_params, cv=skf)\nrfc = RandomForestClassifier(random_state=17)\nrfc_gs = GridSearchCV(rfc, rfc_params, cv=skf)\nsvc = SVC(random_state=17)\nsvc_gs = GridSearchCV(svc, svc_params, cv=skf)\nlr = LogisticRegression(random_state=17)\nlr_gs = GridSearchCV(lr, lr_params, cv=skf)\n\nmeta = XGBClassifier(n_estimators=40)\n\nmodels = [gbc_gs, rfc_gs, svc_gs, lr_gs]\n\nfor model in models:\n    model.fit(x_train, y_train)\n    print('Model=', model)\n    print(model.best_params_)\n    print(f'accuracy={accuracy_score(y_valid, model.predict(x_valid))}')\n    print('---------------------')","execution_count":null,"outputs":[]},{"metadata":{"id":"IrcXh11rXbbr"},"cell_type":"markdown","source":"### 3.\nС помощью GridSearchCV и указанных ниже параметров настройте мета-алгоритм на мета-признаках (используйте 5-кратную валидацию и random_state=17 при определении алгоритма). Матрицу метапризнаков получите из предсказаний, полученных в предыдущем пункте на валидационных данных базовыми алгоритмами. Выведите лучшие параметры."},{"metadata":{"id":"klDpMpPAXbbu","trusted":true},"cell_type":"code","source":"xgb_params = {'n_estimators': range(10, 100, 5),\n              'eta': np.arange(0.1, 1., .1),\n              'min_child_weight': range(1, 10, 1),\n              'subsample': np.arange(0.1, 1., 0.2)}\n\nxgb = XGBClassifier(random_state=17, eval_metric='error')\nxbg_gs = GridSearchCV(xgb, xgb_params, cv=5)\n\nmeta_mtrx = np.empty((x_valid.shape[0], len(models)))\nfor n, model in enumerate(models):\n    meta_mtrx[:, n] = model.predict(x_valid)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Aw3nUCsCXbb2","trusted":true},"cell_type":"code","source":"xbg_gs.fit(meta_mtrx, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xbg_gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"id":"ZdPk3Y6TXbb8"},"cell_type":"markdown","source":"### 4.\nНа основе алгоритма из предыдущего домашнего задания постройте стекинг (используйте 5-кратную кросс-валидацию) для всех моделей с наилучшими подобранными параметрами. В качестве тренировочных данных используйте весь датасет train.csv, а в качестве тестовых - весь датасет test.csv. Сделайте прогноз мета-алгоритма для test.csv."},{"metadata":{"id":"X4yLqrjMXbb_","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\n\n\ndef stacking(models, meta_alg, data_train, targets_train, data_test, targets_test=None, cv=5):\n    \"\"\"Функция стекинга\n    Аргументы:\n    models -- список предварительно инициализированных моделей, которые будут использоваться\n    meta_alg -- метаалгоритм стекинга\n    data_train -- тренировочные признаки\n    targets_train -- целевые переменные тренировочных данных\n    data_test -- тестовые признаки\n    targets_test  -- целевые переменные тестовых данных (default None)\n    random_state -- воспроизводимость модели (default None)\n    test_size -- размер тестовой выборки тренировочных данных (default None)\n    cv -- коэффициент кросс-валидации (default 5)\n    metrics -- список требуемых метрик точности модели при наличии целевых переменнныъ тестовых данных (default [roc_auc_score])\n    \"\"\"\n    meta_mtrx = np.empty((targets_train.shape[0], len(models)))\n#   заполнение матрицы метапризнаков предсказаниями через кроссвалидацию cross_val_predict\n    for n, model in enumerate(models):\n#  заполнение матрицы метапризнаков данными кроссвалидации и обучение моделей на полном тестовом датасете\n        meta_mtrx[:, n] = cross_val_predict(model,\n                                            data_train,\n                                            targets_train,\n                                            cv=cv,\n                                            method='predict')\n        model.fit(data_train, targets_train)\n\n#  обучение модели на матрице метапризнаков и целевых значениях валидационных данных\n    meta_alg.fit(meta_mtrx, targets_train)\n#  предсказания базовых моделей на тестовых данных\n    meta_mtrx_test = np.empty((data_test.shape[0], len(models))) \n    for n, model in enumerate(models):\n        meta_mtrx_test[:, n] = model.predict(data_test)\n#  предсказания метамодели на meta_mtrx_test\n    meta_predict = meta_alg.predict(meta_mtrx_test)\n#  если известны значения тестовых данных, вернуть предсказания и значения всех заданных метрик, иначе вернуть только предсказания\n    return meta_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [gbc, rfc, svc, lr]\n\npredictions = stacking(models,\n                       xgb,\n                       train.iloc[:, 1:].values,\n                       train.iloc[:,0].values,\n                       test.iloc[:, 1:].values)","execution_count":null,"outputs":[]},{"metadata":{"id":"9lhat2YqXbcD"},"cell_type":"markdown","source":"### 5.\nС помощью нижеприведенной функции сформируйте файл посылки для соревнования и отправьте на Kaggle."},{"metadata":{"id":"uOND9iBIXbcF","trusted":true},"cell_type":"code","source":"def write_to_submission_file(predictions, PassengerID, out_file='Submission.csv', columns=['PassengerID', 'Survived']):\n    predicted_df = pd.DataFrame(np.array([PassengerId, predictions]).T, columns=columns)\n    predicted_df.to_csv(out_file, index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"TXFbXmqZXbcJ","trusted":true},"cell_type":"code","source":"write_to_submission_file(predictions, PassengerId)","execution_count":null,"outputs":[]},{"metadata":{"id":"8lLSV_sHXbcN"},"cell_type":"markdown","source":"### 6.\nКаков результат score, полученного на соревновании?"},{"metadata":{"id":"4VEP0qzXXbcO"},"cell_type":"markdown","source":"Ваш ответ:"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}