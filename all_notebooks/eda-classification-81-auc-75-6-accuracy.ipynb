{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stroke Prediction\n","metadata":{"id":"7J6iOlrCbsQb"}},{"cell_type":"markdown","source":"According to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\nThis dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.","metadata":{"id":"Yr9FMnIlbEUj"}},{"cell_type":"markdown","source":"1) id: unique identifier\n2) gender: \"Male\", \"Female\" or \"Other\"\n3) age: age of the patient\n4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n6) ever_married: \"No\" or \"Yes\"\n7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n8) Residence_type: \"Rural\" or \"Urban\"\n9) avg_glucose_level: average glucose level in blood\n10) bmi: body mass index\n11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n12) stroke: 1 if the patient had a stroke or 0 if not\n*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient\n\n\n","metadata":{"id":"OtJAXfLIbAEt"}},{"cell_type":"markdown","source":"## Data cleaning","metadata":{"id":"huqgLrSDbywQ"}},{"cell_type":"code","source":"# Load the dataset\nimport pandas as pd\ndf = pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndf.head()","metadata":{"id":"3OLY5Gzv5Osw","outputId":"eb8eda6d-278b-4101-f7ce-3ce76ff5e73c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df['id']\ndf.info()","metadata":{"id":"Mn933OovcHwQ","outputId":"0189687a-387f-4415-b937-580759771eb7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"id":"hmwTaT0HeC2y","outputId":"5a9cd52d-5c20-49cd-b62a-e28c692fd420","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have NaN data in bmi, for now let's do an EDA ","metadata":{"id":"nKJDygUVCAKB"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2, 5)\naxs[0, 0].bar(df.gender.unique(),  df.gender.value_counts())\naxs[0, 0].set_title('Gender')\naxs[0, 1].bar(df.age.unique(),  df.age.value_counts())\naxs[0, 1].set_title('Age')\naxs[0, 2].bar(df.hypertension.unique(),  df.hypertension.value_counts())\naxs[0, 2].set_title('Hypertension')\naxs[0, 3].bar(df.heart_disease.unique(),  df.heart_disease.value_counts())\naxs[0, 3].set_title('Heart Disease')\naxs[0, 4].bar(df.ever_married.unique(),  df.ever_married.value_counts())\naxs[0, 4].set_title('Ever Married')\naxs[1, 0].bar(df.work_type.unique(),  df.work_type.value_counts())\naxs[1, 0].set_title('Work Type')\naxs[1, 1].bar(df.Residence_type.unique(),  df.Residence_type.value_counts())\naxs[1, 1].set_title('Residence type ')\naxs[1, 2].bar(df.avg_glucose_level.unique(),  df.avg_glucose_level.value_counts())\naxs[1, 2].set_title('avg_glucose_level')\naxs[1, 3].bar(df.stroke.unique(),  df.stroke.value_counts())\naxs[1, 3].set_title('stroke')\naxs[1, 4].bar(df.smoking_status.unique(),  df.smoking_status.value_counts())\naxs[1, 4].set_title('smoking_status')\nfig.set_figheight(8)\nfig.set_figwidth(25)\nfig.tight_layout()\nfig.show()","metadata":{"id":"NcdNuYFog8lt","outputId":"6c40f1ac-9014-46fd-fd69-176d51653973","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can see that our dataset is imbalanced on stroke subjects**","metadata":{"id":"OaVrLq6LGJDV"}},{"cell_type":"code","source":"import numpy as np\n\nneg, pos = np.bincount(df['stroke'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Stroke: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos / total))","metadata":{"id":"ziH2Gi3bH8dJ","outputId":"1ed2cef2-dbdf-4300-b834-ed887e81cdfa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can encode our categorical variables","metadata":{"id":"ru7imOynKqww"}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# LabelEncoder\nle = LabelEncoder()\n\n# apply \"le.fit_transform\"\ndf_encoded = df.apply(le.fit_transform)\ndf_encoded","metadata":{"id":"SNwMJJ7bKdbA","outputId":"cab24b04-350b-4133-e87f-e6a98feb62b5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nfeatures = ['gender','age','hypertension','heart_disease','ever_married', 'work_type', 'Residence_type', 'avg_glucose_level','bmi', 'smoking_status']\nft_to_scale = ['age', 'work_type', 'avg_glucose_level', 'bmi', 'smoking_status']\nscaler = StandardScaler()\ndf_encoded[ft_to_scale] = scaler.fit_transform(df_encoded[ft_to_scale])","metadata":{"id":"24qVpVmLYQPi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_encoded","metadata":{"id":"J7E3OjeTZQSm","outputId":"97c65357-185f-4609-b9cd-310693f3e666","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.catplot(y=\"work_type\", hue=\"stroke\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df)","metadata":{"id":"Vyw1040Lopka","outputId":"1adbd636-2e10-4273-e1f3-40c8cb5f78fb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(y=\"smoking_status\", hue=\"stroke\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df)","metadata":{"id":"e-_N7d8_pAF8","outputId":"6838fa24-f020-4c57-eb22-cc470af027b2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(y=\"heart_disease\", hue=\"stroke\", kind=\"count\",\n            palette=\"pastel\", edgecolor=\".6\",\n            data=df)","metadata":{"id":"Jp-GfP8wpcvH","outputId":"194a2c04-a1e3-4c5a-d9d8-db031ef4a172","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the previous plot that there is some sort of correlation between heart disease history and stroke occurrancies. \nInstead, in this dataset we don't have a major incidence of strokes with smokers. Probably due to the lack of data. ","metadata":{"id":"ZpkFfQ495R34"}},{"cell_type":"markdown","source":"Deal with NaN values\n","metadata":{"id":"hOzz6z-XMTUo"}},{"cell_type":"code","source":"column_means = df_encoded.bmi.mean()\ndf_encoded.bmi = df_encoded.bmi.fillna(column_means)","metadata":{"id":"LZ6HLBwLLs3t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install heatmapz\n","metadata":{"id":"YjDqLCUWqvgU","outputId":"cb284568-597d-43b1-9491-85c16a7b664c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the two methods from heatmap library\nfrom heatmap import heatmap, corrplot\nplt.figure(figsize=(8, 8))\ncorrplot(df_encoded.corr(), size_scale=1000);","metadata":{"id":"J-zYK2I6rDK4","outputId":"acd7a8e5-26c9-470a-bbe6-1259577fe057","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_encoded.info()","metadata":{"id":"y_Xd-5qfM9_U","outputId":"54f433ae-444c-4474-b0f1-30cdc4537d56","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_encoded.describe()","metadata":{"id":"qoBf-DtxPD9d","outputId":"241e9cdf-2e79-4fe8-ef7d-e0706a46f038","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have an imbalanced dataset, we can apply SMOTE technique","metadata":{"id":"AKECnEWkzb65"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df_encoded[features]\ny = df_encoded['stroke']\n# split into 70:30 ration\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n  \n# describes info about train and test set\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","metadata":{"id":"EOWSCiCQzjgZ","outputId":"e2794bb0-32c3-4ccc-b88e-e1c56b8cfffb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n  \n\nsm = SMOTE(random_state = 2)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n  \nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n  \nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))","metadata":{"id":"4zXZnPQ10T1z","outputId":"95d8a2af-1a67-46e9-e5ef-bfe814c8610d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom imblearn.over_sampling import RandomOverSampler","metadata":{"id":"hV-MBKP61sIB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train_res, y_train_res)\nY_pred = log_reg.predict(X_test)\nsns.heatmap(confusion_matrix(y_test, Y_pred),annot=True,fmt='d',cmap='Blues')\nprint(classification_report(y_test, Y_pred))","metadata":{"id":"Xngqs4ks2oqK","outputId":"8bc5c861-ca33-40dc-fc09-0187aba18279","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC()\nclf.fit(X_train_res, y_train_res)\nY_pred = clf.predict(X_test)\nsns.heatmap(confusion_matrix(y_test, Y_pred),annot=True,fmt='d',cmap='Blues')\nprint(classification_report(y_test, Y_pred))","metadata":{"id":"bGcGM2kC4Ncr","outputId":"136a5bf0-3ab6-44b0-cf9b-b1c4f3b09075","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n# Instantiate model with 1000 decision trees\nrf = RandomForestClassifier(n_estimators = 200, random_state = 1, criterion='gini')\n# Train the model on training data\nrf.fit(X_train_res, y_train_res)\nY_pred = rf.predict(X_test)\nsns.heatmap(confusion_matrix(y_test, Y_pred),annot=True,fmt='d',cmap='Blues')\nprint(classification_report(y_test, Y_pred))\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n","metadata":{"id":"JSmTX29QAABt","outputId":"569448ae-1720-4874-9b6f-a8ab0fa572bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LogisticRegression** gives best results for F1 score, let's tune it!","metadata":{"id":"plt-CsQ2jEwI"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"id":"JjkAEHtHiTTL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_models = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0],'solver': ['liblinear','lbfgs']}])]\nfor i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy')\n    grid.fit(X_train_res, y_train_res)\n    best_accuracy = grid.best_score_\n    best_param = grid.best_params_\n    print('{}:\\nBest Accuracy : {:.2f}%'.format(i,best_accuracy*100))\n    print('Best Parameters : ',best_param)\n    print('')\n    print('----------------')\n    print('')","metadata":{"id":"17C2x-fEiGYg","outputId":"c3cea011-fbdc-435c-8d9e-b6f087889650","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score","metadata":{"id":"xafN0bQai7jO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using best fit parameters\nclassifier = LogisticRegression(C= 0.25, random_state= 0, solver= 'liblinear')\nclassifier.fit(X_train_res, y_train_res)\ny_pred = classifier.predict(X_test)\ny_prob = classifier.predict_proba(X_test)[:,1]\ncm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {roc_auc_score(y_test, y_prob)}')\nprint('Accuracy Score: ',accuracy_score(y_test, y_pred))\nprint('F1 Score: ',f1_score(y_test,y_pred))\nprint('Recall: ', recall_score(y_test,y_pred))\n# Visualizing Confusion Matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc AUC Curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend()\nplt.show()","metadata":{"id":"N4avj242ixIC","outputId":"c62add30-56b5-4ee8-97ef-6dd64ed925e8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**81.1% AUC** **75.6% Accuracy** **71.05% Recall** ","metadata":{"id":"oPnmpyyhbCtf"}},{"cell_type":"code","source":"","metadata":{"id":"ZmBFBtN2eTTd"},"execution_count":null,"outputs":[]}]}