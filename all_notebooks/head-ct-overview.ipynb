{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom pydicom import read_file as read_dicom\nimport SimpleITK as sitk\nbase_dir = os.path.join('..', 'input')","execution_count":107,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"all_dicom_paths = glob(os.path.join(base_dir, '*', '*', '*', '*', '*'))\nprint(len(all_dicom_paths), 'dicom files')\ndicom_df = pd.DataFrame(dict(path = all_dicom_paths))\ndicom_df['SliceNumber'] = dicom_df['path'].map(lambda x: int(os.path.splitext(x.split('/')[-1])[0][2:]))\ndicom_df['SeriesName'] = dicom_df['path'].map(lambda x: x.split('/')[-2])\ndicom_df['StudyID'] = dicom_df['path'].map(lambda x: x.split('/')[-3])\ndicom_df['PatientID'] = dicom_df['path'].map(lambda x: x.split('/')[-4].split(' ')[0])\ndicom_df.sample(3)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ff117050589356170973c7e835330a2cda4c15a"},"cell_type":"code","source":"dicom_df.describe(include = 'all')","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"0202187e1dc3a1923df24a114e17073e2f052d70"},"cell_type":"markdown","source":"# Try using pydicom to read\nWe try to use pydicom to read the images and see that without the right jpeg-lossless and jpeg2000 libraries we can only read a portion of them. "},{"metadata":{"_cell_guid":"bd73bcb8-6d69-4b09-99f9-5521dedd3dac","_uuid":"73b8c92a0d5d434d7ec9fb4ff5e69bef805e64b7","trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, 3, figsize = (20, 20))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), dicom_df.sample(9).iterrows()):\n    try:\n        c_slice = read_dicom(c_row['path'])\n        c_ax.imshow(c_slice.pixel_array, cmap = 'bone')\n        c_ax.set_title('{PatientID}\\n{SeriesName}'.format(**c_row))\n    except Exception as e:\n        c_ax.set_title('{}'.format(str(e)[:40]))\n        print(e)\n    c_ax.axis('off')","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"ad3a2c8a33fa23fbd64a85507e2ce0743d38e57c"},"cell_type":"markdown","source":"# Using SimpleITK seems to fix the issue\nUsing SimpleITK instead of pydicom lets us load the images correctly now"},{"metadata":{"trusted":true,"_uuid":"3421e85a831427d3688e31b6a48c9bd78952b328"},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, 3, figsize = (20, 20))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), dicom_df.sample(9).iterrows()):\n    try:\n        c_img = sitk.ReadImage(c_row['path'])\n        c_slice = sitk.GetArrayFromImage(c_img)[0]\n        c_ax.imshow(c_slice, cmap = 'bone')\n        c_ax.set_title('{PatientID}\\n{SeriesName}'.format(**c_row))\n    except Exception as e:\n        c_ax.set_title('{}'.format(str(e)[:40]))\n        print(e)\n    c_ax.axis('off')","execution_count":108,"outputs":[]},{"metadata":{"_uuid":"9fc33fa62086453ce818c33d1637e11a4cc35382"},"cell_type":"markdown","source":"# Classify series name from image\nWe can make a simple model here to identify which series type an image came from"},{"metadata":{"trusted":true,"_uuid":"c9241f8d1d775da185a755cfa5dde109d66e614d"},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\npatid_series_df = dicom_df[['PatientID', 'SeriesName']].drop_duplicates()\n# keep only classes with more than two scans\nvalid_series = patid_series_df.groupby('SeriesName').count().reset_index().query('PatientID>2')['SeriesName']\nseries_name_encoder = LabelEncoder()\nseries_name_encoder.fit(valid_series.values)\npatid_series_df = patid_series_df[patid_series_df['SeriesName'].isin(valid_series)]\nvalid_dicom_df = dicom_df[dicom_df['SeriesName'].isin(valid_series)].copy()\nvalid_dicom_df['cat_vec'] = valid_dicom_df['SeriesName'].map(lambda x: to_categorical(series_name_encoder.transform([x]), num_classes = len(series_name_encoder.classes_)))\nprint(patid_series_df.shape[0], 'unique groups', valid_dicom_df.shape[0], 'rows', len(series_name_encoder.classes_), 'classes')","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34b96889ae36d915175c3945bc9ab6ac5c4f18ca"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_ids, test_ids = train_test_split(patid_series_df[['PatientID', 'SeriesName']], \n                                       test_size = 0.25, \n                                       stratify = patid_series_df['SeriesName'])\n\ntrain_unbalanced_df = valid_dicom_df[valid_dicom_df['PatientID'].isin(train_ids['PatientID'])]\ntest_df = valid_dicom_df[valid_dicom_df['PatientID'].isin(test_ids['PatientID'])]\nprint(train_unbalanced_df.shape[0], 'training images', test_df.shape[0], 'testing images')\ntrain_unbalanced_df['SeriesName'].hist(figsize = (10, 5))","execution_count":84,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f52e0afdf01103244085668d9c1751779be95f1"},"cell_type":"code","source":"train_df = train_unbalanced_df.groupby(['SeriesName']).apply(lambda x: x.sample(1500, replace = True)\n                                                      ).reset_index(drop = True)\nprint('New Data Size:', train_df.shape[0], 'Old Size:', train_unbalanced_df.shape[0])\ntrain_df['SeriesName'].hist(figsize = (20, 5))","execution_count":86,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c251f08afd6004ae37894565180545226d175056"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128) # many of the ojbects are small so 512x512 lets us see them\nimg_gen_args = dict(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range = 0.05, \n                              width_shift_range = 0.02, \n                              rotation_range = 3, \n                              shear_range = 0.01,\n                              fill_mode = 'nearest',\n                              zoom_range = 0.05)\nimg_gen = ImageDataGenerator(**img_gen_args)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"85be6dbc598f46579c61317291fc36fb614be6b0"},"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                              seed = seed,\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.concatenate(in_df[y_col].values,0)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","execution_count":76,"outputs":[]},{"metadata":{"_uuid":"a771c6664f6de7bbb205787f7814b5810b045cd4"},"cell_type":"markdown","source":"# Replace PIL with SimpleITK\nSince we want to open images that are DICOMs we use SimpleITK to open them"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c8e2a983fcf3e247c3907188d1af21d4ec4ab8c8"},"cell_type":"code","source":"import keras.preprocessing.image as KPImage\nfrom PIL import Image\ndef apply_window(data, center, width):\n    low = center - width/2.\n    high = center + width/2\n    data = np.clip(data, low, high)\n    data += -1 * low\n    data /= width\n    return data\ndef read_dicom_image(in_path):\n    c_img = sitk.ReadImage(in_path)\n    c_slice = sitk.GetArrayFromImage(c_img)[0]\n    return c_slice\n    \nclass pil_image_awesome():\n    @staticmethod\n    def open(in_path):\n        if '.dcm' in in_path:\n            # we only want to keep the positive labels not the background\n            c_slice = read_dicom_image(in_path)\n            wind_slice = apply_window(c_slice, 40, 400)\n            int_slice =  (255*wind_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n            return Image.fromarray(int_slice)\n        else:\n            return Image.open(in_path)\n    fromarray = Image.fromarray\nKPImage.pil_image = pil_image_awesome","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"882508db9e54304b0f33868fae54adae3cbeed3a"},"cell_type":"code","source":"batch_size = 16\ntrain_gen = flow_from_dataframe(img_gen, train_df, \n                             path_col = 'path',\n                            y_col = 'cat_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = batch_size)\ntest_gen = flow_from_dataframe(img_gen, test_df, \n                             path_col = 'path',\n                            y_col = 'cat_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = batch_size)","execution_count":87,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"176d48f680ce43f525f1243e7d6332727dcfd726"},"cell_type":"code","source":"t_x, t_y = next(train_gen)\nprint(t_x.shape, '->', t_y.shape)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('{}'.format(series_name_encoder.classes_[np.argmax(c_y, -1)]))\n    c_ax.axis('off')","execution_count":88,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f065238c0d53a40ce1fca57bed3adb1488c69b1b"},"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\nct_model = Sequential()\nct_model.add(BatchNormalization(input_shape = t_x.shape[1:]))\nct_model.add(MobileNet(input_shape = (None, None, 1), include_top = False, weights = None))\nct_model.add(GlobalAveragePooling2D())\nct_model.add(Dropout(0.5))\nct_model.add(Dense(128))\nct_model.add(Dropout(0.5))\nct_model.add(Dense(t_y.shape[1], activation = 'softmax'))\nfrom keras.metrics import top_k_categorical_accuracy\ndef top_5_accuracy(in_gt, in_pred):\n    return top_k_categorical_accuracy(in_gt, in_pred, k=5)\n\nct_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n                           metrics = ['categorical_accuracy', top_5_accuracy])\nct_model.summary()","execution_count":94,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b448e63763fb9f218e0a5f39345e01d62c5c6e78"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cthead')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=6) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":95,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6910f279957dd0a0aeb4d7d338e72dfa79ef6b96"},"cell_type":"code","source":"ct_model.fit_generator(train_gen, \n                       steps_per_epoch = 50,\n                        validation_data = test_gen, \n                       validation_steps = 50,\n                              epochs = 5, \n                              callbacks = callbacks_list,\n                             workers = 4,\n                             use_multiprocessing=False, \n                             max_queue_size = 10\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e18e3170d7456486a9bbb2b3cf13e5f4f2537c85"},"cell_type":"code","source":"_, acc, top5_acc = ct_model.evaluate_generator(test_gen, steps = 50, workers=4)","execution_count":101,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11d542adc3aeb10ecdc4074d296401434283aa0a"},"cell_type":"code","source":"print('Overall Accuracy: %2.1f%%\\nTop 5 Accuracy %2.1f%%' % (acc*100, top5_acc*100))","execution_count":106,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6d2fd621e57c4788f0c22882001dd9fad9d20da1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}