{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thanks to https://www.kaggle.com/madz2000 for his notebook https://www.kaggle.com/madz2000/text-classification-using-keras-nb-97-accuracy \nThe visualizations were borrowed from the notebook. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is my first Kernel on Kaggle, Please upvote if it was of any help.\nLeave a comment if there are any queries.\nThanks..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom bs4 import BeautifulSoup","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nfrom tqdm import tqdm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport sqlite3\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n#from sklearn.externals import joblib\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report\nfrom prettytable import PrettyTable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv',  engine = 'python')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['job_id']\ndel df['salary_range']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(\" \",inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['textdata'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['title']\ndel df['location']\ndel df['department']\ndel df['company_profile']\ndel df['description']\ndel df['requirements']\ndel df['benefits']\ndel df['employment_type']\ndel df['required_experience']\ndel df['required_education']\ndel df['industry']\ndel df['function']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nimport nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = set(stopwords.words('english'))\nlen(stop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re,string,unicodedata\npunctuation = list(string.punctuation)\nstop.update(punctuation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleaner(phrase):\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can't\", 'can not', phrase)\n  \n  # general\n    phrase = re.sub(r\"n\\'t\",\" not\", phrase)\n    phrase = re.sub(r\"\\'re'\",\" are\", phrase)\n    phrase = re.sub(r\"\\'s\",\" is\", phrase)\n    phrase = re.sub(r\"\\'ll\",\" will\", phrase)\n    phrase = re.sub(r\"\\'d\",\" would\", phrase)\n    phrase = re.sub(r\"\\'t\",\" not\", phrase)\n    phrase = re.sub(r\"\\'ve\",\" have\", phrase)\n    phrase = re.sub(r\"\\'m\",\" am\", phrase)\n    \n    return phrase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_title = []\n\nfor sentance in tqdm(df['textdata'].values):\n    sentance = str(sentance)\n    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n    sentance = cleaner(sentance)\n    sentance = re.sub(r'[?|!|\\'|\"|#|+]', r'', sentance)\n    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stop)\n    cleaned_title.append(sentance.strip())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['textdata'] = cleaned_title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.stem import LancasterStemmer,WordNetLemmatizer\nfrom nltk import pos_tag\nfrom nltk.corpus import wordnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20)) # Text that is not fraudulent(0)\nwc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(df[df.fraudulent == 0].textdata))\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20)) # Text that is  fraudulent(1)\nwc = WordCloud(width = 1600 , height = 800 , max_words = 3000).generate(\" \".join(df[df.fraudulent == 1].textdata))\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(x = \"fraudulent\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train, X_test, y_Train, y_test = train_test_split(df.textdata, df.fraudulent, random_state=0, stratify=df.fraudulent, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_cross, y_train, y_cross = train_test_split(X_Train, y_Train, random_state=0, stratify=y_Train, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape\n#X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n#transformed train reviews\ntv_train_reviews=tv.fit_transform(X_train)\n#transformed test reviews\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tv_cross_reviews=tv.transform(X_cross)\nprint('Tfidf_train:',tv_train_reviews.shape)\nprint('Tfidf_test:',tv_cross_reviews.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tv_test_reviews=tv.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha_set=[0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\nTrain_AUC_BOW = []\nCrossVal_AUC_BOW = []\nfor i in alpha_set:\n    naive_b=MultinomialNB(alpha=i)\n    naive_b.fit(tv_train_reviews, y_train)\n    Train_y_pred =  naive_b.predict(tv_train_reviews)\n    Train_AUC_BOW.append(roc_auc_score(y_train,Train_y_pred))\n    CrossVal_y_pred =  naive_b.predict(tv_cross_reviews)\n    CrossVal_AUC_BOW.append(roc_auc_score(y_cross,CrossVal_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import math\nAlpha_set=[]\nfor i in range(len(alpha_set)):\n    Alpha_set.append(math.log(alpha_set[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(Alpha_set, Train_AUC_BOW, label='Train AUC')\nplt.scatter(Alpha_set, Train_AUC_BOW)\nplt.plot(Alpha_set, CrossVal_AUC_BOW, label='CrossVal AUC')\nplt.scatter(Alpha_set, CrossVal_AUC_BOW)\nplt.legend()\nplt.xlabel(\"alpha : hyperparameter\")\nplt.ylabel(\"AUC\")\nplt.title(\"ERROR PLOTS\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_alpha=alpha_set[CrossVal_AUC_BOW.index(max(CrossVal_AUC_BOW))]\nprint(optimal_alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classifier1=MultinomialNB(alpha=optimal_alpha)\nClassifier1.fit(tv_train_reviews, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_train_bow = roc_auc_score(y_train,Classifier1.predict(tv_train_reviews))\nprint (\"AUC for Train set\", auc_train_bow)\n\nauc_test_bow = roc_auc_score(y_test,Classifier1.predict(tv_test_reviews))\nprint (\"AUC for Test set\",auc_test_bow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, log_loss, f1_score\n\npreds = Classifier1.predict(tv_test_reviews)\n\nacc = accuracy_score(y_test, preds)\n\nf1 = f1_score(y_test, preds, average='macro')\n\nprint ('Accuracy is : ', acc)\nprint ('F1 Score is :', f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Confusion Matrix of Test Data')\nTest_mat=confusion_matrix(y_test,preds)\nprint (Test_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_cv = pd.DataFrame(Test_mat, index=[0,1], columns=[0,1])\ncm_cv.index.name = 'Actual'\ncm_cv.columns.name = 'Predicted'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.heatmap(cm_cv,cmap= \"Blues\",annot = True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}