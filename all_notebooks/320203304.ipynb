{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAMPLE_DATASET = \"../input/facial-expression-recognition-challenge/icml_face_data.csv/icml_face_data.csv\"\n#print(SAMPLE_DATASET)\nNUM_CLASSES = 7\nTRAIN_HDF5 = \"./train.hdf5\"\nVAL_HDF5 = \"./val.hdf5\"\nTEST_HDF5 = \"./test.hdf5\"\nMODEL_FILE = \"./model.h5\"\nOUTPUT_PATH = \"./\"\nBATCH_SIZE = 128\n\nDATASET_MEAN_FILE = OUTPUT_PATH + \"/rgb_mean.json\"\n\nMODEL_FILE = OUTPUT_PATH + \"/model.h5\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nimport os\n\nclass EpochCheckpoint(Callback):\n    def __init__(self, outpath, every=5, start_at=0):\n        super(Callback, self).__init__()\n        self.out_path = outpath\n        self.every = every\n        self.start_epoch = start_at\n\n    def on_epoch_end(self, epoch, logs={}):\n        if (self.start_epoch + 1) % self.every == 0:\n            p = os.path.sep.join([self.out_path, \"epoch_{}.hdf5\".format(self.start_epoch + 1)])\n            self.model.save(p, overwrite=True)\n        self.start_epoch += 1\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\nclass ImageToArrayPreprocessor:\n    \n    def __init__(self,data_format=None):\n        self.data_format = data_format\n        \n    def processes(self,image):\n        return img_to_array(image,data_format = self.data_format)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport h5py\n\nclass HDF5DatasetWriter:\n    def __init__(self, dims, output_path, data_key=\"images\", buf_size=1000):\n        if os.path.exists(output_path):\n            raise ValueError(\"您提供的输出文件{}已经存在，请手动删除\".format(output_path))\n        self.db = h5py.File(output_path, \"w\")\n        self.data = self.db.create_dataset(data_key, dims, dtype=\"float\")\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n\n        self.buf_size = buf_size\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n\n    def add(self, raw, label):\n        self.buffer[\"data\"].extend(raw)\n        self.buffer[\"labels\"].extend(label)\n        if len(self.buffer[\"data\"]) >= self.buf_size:\n            self.flush()\n\n    def flush(self):\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}\n\n    def store_class_labels(self, class_labels):\n        dt = h5py.special_dtype(vlen=str)\n        label_dim = (len(class_labels),)\n        label_set = self.db.create_dataset(\"label_names\", label_dim, dtype=dt)\n        label_set[:] = class_labels\n\n    def close(self):\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n        self.db.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\nimport numpy as np\nimport h5py\n\nclass HDF5DatasetGenerator:\n    def __init__(self, db_file, batch_size, preprocessors=None, aug=None, binarize=True, classes=2):\n        self.batch_size = batch_size\n        self.preprocessor = preprocessors\n        self.aug = aug\n        self.binarize = binarize\n        self.classes = classes\n        self.db = h5py.File(db_file,'r')\n        self.numImages = self.db[\"labels\"].shape[0]\n\n    def generator(self, passes=np.inf):\n        epochs = 0\n        while epochs < passes:\n            for i in np.arange(0, self.numImages, self.batch_size):\n                images = self.db[\"images\"][i:i + self.batch_size]\n                labels = self.db[\"labels\"][i:i + self.batch_size]\n\n                if self.binarize:\n                    labels = to_categorical(labels, self.classes)\n                if self.preprocessor is not None:\n                    processed_image = []\n                    for image in images:\n                        for p in self.preprocessor:\n                            image = p.processes(image)\n                        processed_image.append(image)\n                    images = np.array(processed_image)\n                if self.aug is not None:\n                    (images, labels) = next(self.aug.flow(images, labels, batch_size=self.batch_size))\n\n                    yield images, labels\n                epochs += 1\n\n    def close(self):\n        self.db.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport os\nimport numpy as np\nfrom keras.callbacks import BaseLogger\nimport matplotlib.pyplot as plt\n\nclass TrainingMonitor(BaseLogger):\n    def __init__(self,fig_path,json_path=None, start_at =0):\n        super(TrainingMonitor, self).__init__()\n        self.history = {}\n        self.fig_path = fig_path\n        self.json_path = json_path\n        self.start_at = start_at\n\n    def on_train_begin(self, logs={}):\n        if self.json_path is not None:\n            if os.path.exists(self.json_path):\n                self.history = json.loads(open(self.json_path).read())\n\n                if self.start_at > 0:\n                    for k in self.history.keys():\n                        self.history[k] = self.history[k][:self.start_at]\n\n    def on_epoch_end(self, epoch, logs={}):\n        for (k,v) in logs.items():\n            log = self.history.get(k, [])\n            log.append(v)\n            self.history[k] =  log\n\n        if self.json_path is not None:\n            f = open(self.json_path, \"w\")\n            f.write(json.dumps(self.history))\n            f.close()\n\n        if len(self.history[\"loss\"]) >1:\n            N = np.arange(0, len(self.history[\"loss\"]))\n            plt.style.use(\"ggplot\")\n            plt.figure()\n            plt.plot(N, self.history[\"loss\"], label=\"train_loss\")\n            plt.plot(N, self.history[\"val_loss\"], label=\"val_loss\")\n            plt.plot(N, self.history[\"accuracy\"], label=\"train_acc\")\n            plt.plot(N, self.history[\"val_accuracy\"], label=\"val_acc\")\n            epochs = len(self.history[\"loss\"])\n            plt.title(\"Training Loss & Accuracy [Epoch {}]\".format(epochs))\n            plt.xlabel(\"Epoch #\")\n            plt.ylabel(\"Loss/Accuracy\")\n            plt.legend()\n            plt.savefig(self.fig_path)\n            plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nprint(\"加载csv格式数据集文件\")\n\nfile = open(SAMPLE_DATASET)\nfile.__next__()\n(train_images, train_label) = ([], [])\n(val_images, val_label) = ([], [])\n(test_images, test_label) = ([], [])\n\ncount_by_label_train = {}\ncount_by_label_val = {}\ncount_by_label_test = {}\n\nfor row in file:\n    (label, usage, image) = row.strip().split(\",\")\n    label = int(label)\n    image = np.array(image.split(\" \"), dtype=\"uint8\")\n    image = image.reshape((48, 48))\n\n    if usage == \"Training\":\n        train_images.append(image)\n        train_label.append(label)\n        count = count_by_label_train.get(label, 0)\n        count_by_label_train[label] = count + 1\n\n    elif usage == \"PublicTest\":\n        val_images.append(image)\n        val_label.append(label)\n        count = count_by_label_val.get(label, 0)\n        count_by_label_val[label] = count + 1\n\n    elif usage == \"PrivateTest\":\n        test_images.append(image)\n        test_label.append(label)\n        count = count_by_label_test.get(label, 0)\n        count_by_label_test[label] = count + 1\n\nfile.close()\nprint(\"训练集样本数量：{}\".format(len(train_images)))\nprint(\"校验集样本数量：{}\".format(len(val_images)))\nprint(\"测试集样本数量：{}\".format(len(test_images)))\n\nprint(count_by_label_train)\nprint('校验样本分布')\nprint(count_by_label_val)\nprint(\"测试样本分布\")\nprint(count_by_label_test)\n\ndatasets = [(train_images,train_label,TRAIN_HDF5),\n            (val_images,val_label,VAL_HDF5),\n            (test_images,test_label,TEST_HDF5)]\n\nfor (images,labels,outputPath) in datasets:\n    print(\"构建{}...\".format(outputPath))\n    writer = HDF5DatasetWriter((len(images),48,48),outputPath)\n\n    for (image,label) in zip(images,labels):\n        writer.add([image],[label])\n\n    writer.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend\n\nclass MiniVGG11():\n    @staticmethod\n    def build(width,height,channel,classes,reg=0.0002):\n        model = Sequential(name=\"MiniVGG11\")\n        shape = (width, height, channel)\n        channel_dimension = -1\n        if backend.image_data_format == \"channels_first\":\n            shape = (channel, width, height)\n            channel_dimension = 1\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(64,(3,3),padding=\"same\",kernel_regularizer=l2(reg)))\n        model.add(Activation(\"relu\")) \n        model.add(BatchNormalization(axis=channel_dimension)) \n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\", kernel_regularizer=l2(reg)))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(64,(3,3),padding=\"same\",kernel_regularizer=l2(reg)))\n        model.add(Activation(\"relu\")) \n        model.add(BatchNormalization(axis=channel_dimension)) \n        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n        model.add(Flatten())\n        model.add(Dense(64,kernel_regularizer=l2(reg))) \n        model.add(Activation(\"relu\")) \n        model.add(BatchNormalization(axis=channel_dimension)) \n        model.add(Dropout(0.35))\n        model.add(Dense(64,kernel_regularizer=l2(reg))) \n        model.add(Activation(\"relu\")) \n        model.add(BatchNormalization(axis=channel_dimension)) \n        model.add(Dropout(0.35))\n        model.add(Dense(classes,kernel_regularizer=l2(reg))) \n        model.add(Activation(\"softmax\"))\n\n        return model\n\nif __name__ == \"__main__\":\n    model = MiniVGG11.build(48, 48, 1, 7, reg=0.0002)\n    print(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nimport os\nmatplotlib.use(\"Agg\")\n\ntrain_aug = ImageDataGenerator(rotation_range=10,\n                   zoom_range = 0.1,\n                   rescale=1 / 255.0,\n                   fill_mode=\"nearest\")\nval_aug = ImageDataGenerator(rescale=1/255.0)\n\niap = ImageToArrayPreprocessor()\n\ntrain_gen = HDF5DatasetGenerator(TRAIN_HDF5,\n                                 BATCH_SIZE,\n                                 aug=train_aug,\n                                 preprocessors=[iap],\n                                 classes=NUM_CLASSES)\nval_gen = HDF5DatasetGenerator(VAL_HDF5,\n                                 BATCH_SIZE,\n                                 aug=val_aug,\n                                 preprocessors = [iap],\n                                 classes=NUM_CLASSES)\n\nopt = Adam(lr = 1e-3)\nmodel = MiniVGG11.build(width=48,height=48,channel=1,classes=NUM_CLASSES)\nmodel.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])\n\nfig_path = os.path.sep.join([OUTPUT_PATH, \"417.png\"])\ncallbacks = [TrainingMonitor(fig_path=fig_path)]\n\nmodel.fit_generator(train_gen.generator(),\n                    steps_per_epoch=train_gen.numImages//BATCH_SIZE,\n                    validation_data=val_gen.generator(),\n                    validation_steps=val_gen.numImages // BATCH_SIZE,\n                    epochs=35,\n                    max_queue_size=BATCH_SIZE*2,\n                    callbacks=callbacks,\n                    verbose=1)\n\nprint(\"[信息] 保存模型...\")\nmodel.save(MODEL_FILE,overwrite=True)\n\ntrain_gen.close()\nval_gen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\n\ntestAug = ImageDataGenerator(rescale=1 / 255.0)\niap = ImageToArrayPreprocessor()\ntestGen = HDF5DatasetGenerator(TEST_HDF5,\n                               BATCH_SIZE,\n                               preprocessors=[iap],\n                               aug=testAug,\n                               classes=NUM_CLASSES)\n\nprint(\"[信息] 加载网络模型\")\nmodel = load_model(MODEL_FILE)\n(loss,acc) = model.evaluate_generator(testGen.generator(),\n                                      steps=testGen.numImages // BATCH_SIZE,\n                                      max_queue_size=BATCH_SIZE * 2)\n\nprint(\"[信息] 测试集准确率：{:.2f}%\".format(acc*100))\n\ntestGen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}