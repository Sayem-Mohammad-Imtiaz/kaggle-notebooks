{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The Hot Forum Topics"},{"metadata":{},"cell_type":"markdown","source":"This notebook borrowed the methods of words tokenization and vectorization from [https://www.kaggle.com/pavlofesenko/strategies-to-earn-discussion-medals/notebook](http://) "},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction\n\nUsually, different forms of forum topics will result in a different number of views, messages and replies. But this notebook will focus on the relation between the number of views and words in forum topics. By applying hierarchical clustering in tokenized and vectorized words, some keywords, which frequently appear in hot topics, are found. It might provide the kagglers with a perspective of making forum topics with specific words to attract more attention in the Kaggle community.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport spacy # For natural language processing (NLP)\n\nfrom sklearn.manifold import TSNE # For dimension reduction\nfrom sklearn.cluster import KMeans #For clustering\nfrom sklearn.cluster import AgglomerativeClustering\nimport seaborn as sns #For visualization\n\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Preprocessing of forum messages"},{"metadata":{"trusted":true},"cell_type":"code","source":"messages = pd.read_csv('/kaggle/input/meta-kaggle/ForumTopics.csv')\nmessages = messages[messages.Title.notna()] #Remove topics without titles\nmessages.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Vectorization and Visualization of Forum Topics\nFor simplicity, forum topics with over 2000 views are considered as \"Hot\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = messages[messages.TotalViews >=2000].Title.tolist()[:1000] #Find hot topics and select top 1000 ones\ncorpus[-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg', disable=['ner']) #Using NLP module, Spacy, and setting up this module","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = nlp.pipe(corpus) #Tokenization\ncorpus_tok = []\nfor doc in batch:\n    tokens = [token.lemma_.lower() for token in doc if token.is_alpha and token.has_vector and not token.is_stop]\n    tokens_str = ' '.join(tokens)\n    if tokens_str != '':\n        corpus_tok.append(tokens_str)\n\ncorpus_tok[-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_tok = nlp.pipe(corpus_tok) #Vectorization\nX = []\nfor doc in batch_tok:\n    X.append(doc.vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_emb = TSNE(random_state=0).fit_transform(X) #Dimension Reduction\ndf = pd.DataFrame(X_emb, columns=['x', 'y'])\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot('x', 'y', data=df, edgecolor='none', alpha=0.5) #Visualize topics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_h = AgglomerativeClustering(n_clusters=3) #Setting four clusters for hierarchical clustering\ndf['Label'] = model_h.fit_predict(X_emb)\ndf['Tokens'] = corpus_tok\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"palette = sns.color_palette(n_colors=3) #Visualize clusters\nsns.scatterplot('x', 'y', data=df, edgecolor='none', alpha=0.5, hue='Label', palette=palette)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display words in each cluster and their frequency"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster0 = ' '.join(df[df.Label == 0].Tokens.tolist())\nwords0 = Counter(cluster0.split())\nwords0.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### In **cluster0**, the most frequent words are \"submission\",\"leaderboard\",\"final\",\"score\". Perhaps, topics on submission and final results of competitions are popular among kagglers."},{"metadata":{"trusted":true},"cell_type":"code","source":"words0.most_common()[:-10:-1] # The least common words in cluster0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster1 = ' '.join(df[df.Label == 1].Tokens.tolist())\nwords1 = Counter(cluster1.split())\nwords1.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We can see from **cluster1** that kagglers also like talking about dataset and data files."},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster2 = ' '.join(df[df.Label == 2].Tokens.tolist())\nwords2 = Counter(cluster2.split())\nwords2.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### From **cluster2**, it can be concluded that topics about model training and evaluation can be hot in the Kaggle community. "},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nBy conducting simple NLP and hierarchical clustering on forum topics, we can find some characteristics of hot forum topics. But as the data in the experiment is not enough, with only 972 words as shown below, there might be some bias on the patterns of popular topics. Hence, more valid data can be put in similar experiments with NLP and clustering techniques to exploit features of hot forum topics."},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}