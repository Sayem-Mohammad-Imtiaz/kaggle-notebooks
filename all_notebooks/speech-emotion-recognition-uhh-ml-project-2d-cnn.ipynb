{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Speech emotion recognition - UHH ML Project 2D-CNN\n</center> ","metadata":{}},{"cell_type":"markdown","source":"## Introduction \nThis model is our 2D CNN model for Speech Emotion Recognition. It follows this steps\n1. Data prepration and processing\n2. Build a model\n3. Compile model\n4. Serialize model\n5. Validate model\n\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd  \nimport glob \nimport os\nimport sys\nimport numpy as np\n\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense,Input, Flatten, Dropout, Activation, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.utils import np_utils\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder \nimport seaborn as sns\nfrom tqdm import tqdm\nimport keras_tuner as kt\nfrom keras_tuner import HyperModel\nfrom keras_tuner.tuners import Hyperband","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-30T09:34:02.717234Z","iopub.execute_input":"2021-06-30T09:34:02.717566Z","iopub.status.idle":"2021-06-30T09:34:11.147859Z","shell.execute_reply.started":"2021-06-30T09:34:02.717536Z","shell.execute_reply":"2021-06-30T09:34:11.146565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def speedNpitch(data):\n    length_change = np.random.uniform(low=0.8, high = 1)\n    speed_fac = 1.2  / length_change\n    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n    minlen = min(data.shape[0], tmp.shape[0])\n    data *= 0\n    data[0:minlen] = tmp[0:minlen]\n    return data\n\ndef plot_history(history):\n    fig, axs = plt.subplots(2)\n    # create accuracy sublpot\n    axs[0].plot(history.history['acc'], label='train accuracy')\n    axs[0].plot(history.history['val_acc'], label='test accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].legend(loc='lower right')\n    axs[0].set_title('Accuracy eval')\n    # create error sublpot\n    axs[1].plot(history.history['loss'], label='train error')\n    axs[1].plot(history.history['val_loss'], label='test error')\n    axs[1].set_ylabel('Error')\n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(loc='upper right')\n    axs[1].set_title('Error eval')\n    plt.show()\n    \ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n\n    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n        \n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:34:16.498078Z","iopub.execute_input":"2021-06-30T09:34:16.498349Z","iopub.status.idle":"2021-06-30T09:34:16.513575Z","shell.execute_reply.started":"2021-06-30T09:34:16.498323Z","shell.execute_reply":"2021-06-30T09:34:16.512528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data\"></a>\n## 1. Getting Data\nRead in the data csv-file with all labels and paths of the four datasets.","metadata":{}},{"cell_type":"code","source":"ref = pd.read_csv(\"/kaggle/input/data-pathcsv/Data_path.csv\")  \nprint(ref.shape)\ndf=np.empty(shape=(ref.shape[0], 30, 216))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:34:16.51544Z","iopub.execute_input":"2021-06-30T09:34:16.515898Z","iopub.status.idle":"2021-06-30T09:34:16.599471Z","shell.execute_reply.started":"2021-06-30T09:34:16.515835Z","shell.execute_reply":"2021-06-30T09:34:16.598755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are reading the audio file in and try to extract the mfcc features. There we take the mean to save space and to accelerate it.","metadata":{}},{"cell_type":"code","source":"j = 0\ninput_length = 44100 * 2.5\nfor i in tqdm(ref.path):\n    path = i\n    wav, sr = librosa.core.load(path, sr=44100, offset=0.5, duration=2.5, res_type='kaiser_fast')\n    \n    # Random offset / Padding\n    if len(wav) > input_length:\n        max_offset = len(wav) - input_length\n        offset = np.random.randint(max_offset)\n        wav = wav[offset:(input_length+offset)]\n    else:\n        if input_length > len(wav):\n            max_offset = input_length - len(wav)\n            offset = np.random.randint(max_offset)\n        else:\n            offset = 0\n        wav = np.pad(wav, (offset, int(input_length) - len(wav) - offset), \"constant\")\n        \n    wav = speedNpitch(wav)\n    MFCC = librosa.feature.mfcc(y=wav, sr=sr, n_mfcc=30)\n    df[j,0:30,0:MFCC.shape[1]] = MFCC\n    j = j+1   ","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:34:16.6006Z","iopub.execute_input":"2021-06-30T09:34:16.601066Z","iopub.status.idle":"2021-06-30T09:51:07.042937Z","shell.execute_reply.started":"2021-06-30T09:34:16.601023Z","shell.execute_reply":"2021-06-30T09:51:07.040753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(MFCC.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.047487Z","iopub.execute_input":"2021-06-30T09:51:07.048151Z","iopub.status.idle":"2021-06-30T09:51:07.058908Z","shell.execute_reply.started":"2021-06-30T09:51:07.04808Z","shell.execute_reply":"2021-06-30T09:51:07.057771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.06105Z","iopub.execute_input":"2021-06-30T09:51:07.061895Z","iopub.status.idle":"2021-06-30T09:51:07.075145Z","shell.execute_reply.started":"2021-06-30T09:51:07.061835Z","shell.execute_reply":"2021-06-30T09:51:07.073522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"processing\"></a>\n### Data processing\n\nNow the data is being put into a practical format for Keras and the CNN.\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df, ref.labels, test_size = 0.25, random_state = 42)\n#X_train = np.array(X_train)\n#y_train = np.array(y_train)\n#X_test = np.array(X_test)\n#y_test = np.array(y_test)\nX_shape = X_train\nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\nprint(X_train.shape)\nprint(lb.classes_)\nprint(y_train[0:10])\nprint(y_test[0:200])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.081804Z","iopub.execute_input":"2021-06-30T09:51:07.083155Z","iopub.status.idle":"2021-06-30T09:51:07.394615Z","shell.execute_reply.started":"2021-06-30T09:51:07.083088Z","shell.execute_reply":"2021-06-30T09:51:07.393739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=3)\nX_test = np.expand_dims(X_test, axis=3)\nX_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.396821Z","iopub.execute_input":"2021-06-30T09:51:07.397432Z","iopub.status.idle":"2021-06-30T09:51:07.409202Z","shell.execute_reply.started":"2021-06-30T09:51:07.397386Z","shell.execute_reply":"2021-06-30T09:51:07.408123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.410747Z","iopub.execute_input":"2021-06-30T09:51:07.411065Z","iopub.status.idle":"2021-06-30T09:51:07.421171Z","shell.execute_reply.started":"2021-06-30T09:51:07.411035Z","shell.execute_reply":"2021-06-30T09:51:07.420174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"build\"></a>\n## 2. Build a model\nWe are using a 2D CNN. ","metadata":{}},{"cell_type":"code","source":"#Hyper Tuning\nclass CNNHyperModel(HyperModel):\n    def __init__(self, input_shape, num_classes):\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n\n    def build(self, hp):\n        model = tf.keras.Sequential()\n        #input layer\n        model.add(Conv2D(filters=hp.Choice('num_filters_1',values=[16, 256],default=16,), kernel_size=(4,10),activation=hp.Choice('Conv2D_activation_1',values=['relu','tanh','sigmoid'],default='relu'), padding='same', input_shape = (30, 216, 1)))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 2nd Conv2d layer          \n        model.add(Conv2D(filters=hp.Choice('num_filters_2',values=[16, 256],default=16,),activation=hp.Choice('Conv2D_activation_2',values=['relu','tanh','sigmoid'],default='relu'),kernel_size=(4,10),padding='same'))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 3rd Conv2d layer          \n        model.add(Conv2D(filters=hp.Choice('num_filters_3',values=[16, 256],default=16,), activation=hp.Choice('Conv2D_activation_3',values=['relu','tanh','sigmoid'],default='relu'),kernel_size=(4,10),padding='same'))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_3',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 4th Conv2d layer          \n        model.add(Conv2D(filters=hp.Choice('num_filters_4',values=[16, 256],default=16,),activation=hp.Choice('Conv2D_activation_4',values=['relu','tanh','sigmoid'],default='relu'),kernel_size=(4,10),padding='same'))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_4',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 1st Dense layer\n        model.add(Flatten())\n        model.add(Dense(units=hp.Int('units',min_value=32, max_value=512,step=32,default=64),activation=hp.Choice('dense_activation',values=['relu','tanh','sigmoid'],default='relu')))\n        model.add(Dropout(rate=hp.Float('dropout_5', min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n        # Output layer \n        model.add(Dense(14))         \n        model.add(Activation('softmax'))\n        #opt = tf.keras.optimizers.Adam(hp.Float('learning_rate',min_value=1e-4,max_value=1e-2,sampling='LOG',default=1e-3))\n        model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate',min_value=1e-4, max_value=1e-2,sampling='LOG',default=1e-3)),loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])\n        #model.summary()\n        return model","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.422465Z","iopub.execute_input":"2021-06-30T09:51:07.422768Z","iopub.status.idle":"2021-06-30T09:51:07.446646Z","shell.execute_reply.started":"2021-06-30T09:51:07.42274Z","shell.execute_reply":"2021-06-30T09:51:07.445032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES=14\nhypermodel = CNNHyperModel(input_shape=(30, 216, 1), num_classes=NUM_CLASSES)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.449641Z","iopub.execute_input":"2021-06-30T09:51:07.45001Z","iopub.status.idle":"2021-06-30T09:51:07.463299Z","shell.execute_reply.started":"2021-06-30T09:51:07.449974Z","shell.execute_reply":"2021-06-30T09:51:07.462446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HYPERBAND_MAX_EPOCHS = 30\nMAX_TRIALS = 60\nEXECUTION_PER_TRIAL = 3\nSEED = 1\nN_EPOCH_SEARCH = 40\ntuner = Hyperband(hypermodel,max_epochs=HYPERBAND_MAX_EPOCHS,objective='val_accuracy',seed=SEED,executions_per_trial=EXECUTION_PER_TRIAL,directory='hyperband',project_name='TPU1_aug')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.464623Z","iopub.execute_input":"2021-06-30T09:51:07.465109Z","iopub.status.idle":"2021-06-30T09:51:07.475953Z","shell.execute_reply.started":"2021-06-30T09:51:07.46506Z","shell.execute_reply":"2021-06-30T09:51:07.474856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.477635Z","iopub.execute_input":"2021-06-30T09:51:07.478057Z","iopub.status.idle":"2021-06-30T09:51:07.95299Z","shell.execute_reply.started":"2021-06-30T09:51:07.478021Z","shell.execute_reply":"2021-06-30T09:51:07.951291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model normally\ntuner.search(X_train, y_train, epochs=N_EPOCH_SEARCH, validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.955318Z","iopub.status.idle":"2021-06-30T09:51:07.955741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show a summary of the search\ntuner.results_summary()\n\n# Retrieve the best model.\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# Evaluate the best model.\nloss, accuracy = best_model.evaluate(X_test, y_test)\n\nmodel_name = 'best_model_aug.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nbest_model.save(model_path)\nprint('Save model and weights at %s ' % model_path)\n\nmodel_json = best_model.to_json()\nwith open(\"model_json_aug.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.956684Z","iopub.status.idle":"2021-06-30T09:51:07.957102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"compile\"></a>\n## 3. Compile Model \n","metadata":{}},{"cell_type":"code","source":"best_model.compile(optimizer = tf.keras.optimizers.Adam(0.00034981818142934215), loss = tf.keras.losses.categorical_crossentropy, metrics = ['acc'])#tf.keras.losses.categorical_crossentropy.,loss='sparse_categorical_crossentropy'\nhistory = best_model.fit(X_train, y_train, batch_size = 32, epochs = 30, validation_data = (X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.960897Z","iopub.status.idle":"2021-06-30T09:51:07.961294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.962172Z","iopub.status.idle":"2021-06-30T09:51:07.962613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Serialize model","metadata":{}},{"cell_type":"code","source":"model_name = 'EM_2D_aug.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Save model and weights at %s ' % model_path)\n\nmodel_json = model.to_json()\nwith open(\"model_json_aug.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Validate model","metadata":{}},{"cell_type":"code","source":"preds = best_model.predict(X_test, batch_size=16, verbose=1)\n\npreds=preds.argmax(axis=1)\npreds = preds.astype(int).flatten()\npreds = (lb.inverse_transform((preds)))\npreds = pd.DataFrame({'predictedvalues': preds})\n\nactual = y_test.argmax(axis=1)\nactual = actual.astype(int).flatten()\nactual = (lb.inverse_transform((actual)))\nactual = pd.DataFrame({'actualvalues': actual})\n\nfinaldf = actual.join(preds)\nfinaldf1 = actual.join(preds)\n\nfinaldf[170:180]","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.959572Z","iopub.status.idle":"2021-06-30T09:51:07.959968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Emotion by gender accuracy**","metadata":{}},{"cell_type":"code","source":"classes = finaldf.actualvalues.unique()\nclasses.sort()    \n\nc = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\nprint(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\nprint_confusion_matrix(c, class_names = classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.963577Z","iopub.status.idle":"2021-06-30T09:51:07.963975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report \nclasses = finaldf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(finaldf.actualvalues, finaldf.predictedvalues, target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.964934Z","iopub.status.idle":"2021-06-30T09:51:07.965353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gender accuracy result**","metadata":{}},{"cell_type":"code","source":"modidf1 = finaldf1\nmodidf1['actualvalues'] = modidf1.actualvalues.replace({'female_angry':'angry' , 'female_disgust':'disgust', 'female_fear':'fear', 'female_happy':'happy', 'female_sad':'sad'\n                                       , 'female_surprise':'surprise', 'female_neutral':'neutral', 'male_angry':'angry', 'male_fear':'fear', 'male_happy':'happy', 'male_sad':'sad'\n                                       , 'male_surprise':'surprise' , 'male_neutral':'neutral' , 'male_disgust':'disgust'})\n\nmodidf1['predictedvalues'] = modidf1.predictedvalues.replace({'female_angry':'angry', 'female_disgust':'disgust', 'female_fear':'fear', 'female_happy':'happy', 'female_sad':'sad'\n                                       , 'female_surprise':'surprise', 'female_neutral':'neutral', 'male_angry':'angry', 'male_fear':'fear', 'male_happy':'happy', 'male_sad':'sad'\n                                       , 'male_surprise':'surprise', 'male_neutral':'neutral', 'male_disgust':'disgust'})\n\nclasses = modidf1.actualvalues.unique() \nclasses.sort() \n\nd = confusion_matrix(modidf1.actualvalues, modidf1.predictedvalues)\nprint(accuracy_score(modidf1.actualvalues, modidf1.predictedvalues))\nprint_confusion_matrix(d, class_names = classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.966345Z","iopub.status.idle":"2021-06-30T09:51:07.966776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modidf = finaldf\nmodidf['actualvalues'] = finaldf.actualvalues.replace({'female_angry':'female', 'female_disgust':'female', 'female_fear':'female', 'female_happy':'female'\n                                       , 'female_sad':'female', 'female_surprise':'female', 'female_neutral':'female', 'male_angry':'male', 'male_fear':'male', 'male_happy':'male'\n                                       , 'male_sad':'male', 'male_surprise':'male' , 'male_neutral':'male', 'male_disgust':'male'})\n\nmodidf['predictedvalues'] = finaldf.predictedvalues.replace({'female_angry':'female', 'female_disgust':'female', 'female_fear':'female', 'female_happy':'female'\n                                       , 'female_sad':'female', 'female_surprise':'female', 'female_neutral':'female', 'male_angry':'male', 'male_fear':'male', 'male_happy':'male'\n                                       , 'male_sad':'male', 'male_surprise':'male', 'male_neutral':'male', 'male_disgust':'male'})\n\nclasses = modidf.actualvalues.unique()  \nclasses.sort() \n\nc = confusion_matrix(modidf.actualvalues, modidf.predictedvalues)\nprint(accuracy_score(modidf.actualvalues, modidf.predictedvalues))\nprint_confusion_matrix(c, class_names = classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.968031Z","iopub.status.idle":"2021-06-30T09:51:07.968458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report \nclasses = modidf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(modidf.actualvalues, modidf.predictedvalues, target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.969474Z","iopub.status.idle":"2021-06-30T09:51:07.969887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Emotion accuracy**","metadata":{}},{"cell_type":"code","source":"# Classification report \nclasses = modidf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(modidf.actualvalues, modidf.predictedvalues, target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T09:51:07.970765Z","iopub.status.idle":"2021-06-30T09:51:07.971194Z"},"trusted":true},"execution_count":null,"outputs":[]}]}