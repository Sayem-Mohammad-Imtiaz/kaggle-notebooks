{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"############################\n# FrenchNews.csv post process to generate FrenchNewsDayConcat.csv\n# The post process sample FrenchNews.csv at day to compare it with CAC40\n############################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fichier CSV\nimport csv\nimport time\nimport re\n\nimport datetime as dt\n\n#Nom fichier CSV\nCSV_FILE_NAME_INPUT = '../input/french-financial-news/FrenchNews.csv'\nCSV_FILE_NAME_OUTPUT_TEMP = 'temp.csv'\nCSV_FILE_NAME_OUTPUT = 'FrenchNewsDayConcat.csv'\n\nnbrLigneTotalCsvInput=0\n\n#determination taille fichier\nwith open(CSV_FILE_NAME_INPUT, 'r', newline='',encoding = 'utf-8') as file:\n    reader = csv.reader(file, delimiter=',')\n        \n    for row in reader:\n        \n        #Calcule du nombre de ligne total\n        nbrLigneTotalCsvInput += 1\n        \n        #On lit la 1ère date\n        if nbrLigneTotalCsvInput==2:\n            firstDateCsvIn=row[3]\n            \n    lastDateCsvIn=row[3]        \n            \n            \n    \n    #Calcule du nombre de ligne total\n    #nbrLigneTotalCsvInput = sum(1 for row in reader)  # fileObject is your csv.reader\n    \n    \n    print(\"nbrLigneTotal=\" + str(nbrLigneTotalCsvInput))\n    print(\"\\n\")\n    print(\"firstDateCsvIn=\" + firstDateCsvIn)\n    print(\"lastDateCsvIn=\" + lastDateCsvIn)\n    print(\"\\n\")\n\n\n    # Exemple : 08.01.2021\n    dateFormat = \"%d.%m.%Y\"\n\n    # Date debut\n    dateDTfirst = dt.datetime.strptime(firstDateCsvIn, dateFormat)\n    print('dateDTfirst:', dateDTfirst.strftime(dateFormat))\n\n    # Date fin\n    dateDTlast = dt.datetime.strptime(lastDateCsvIn, dateFormat)\n    print('dateDTlast:', dateDTlast.strftime(dateFormat))\n\n    ########################\n    #Force une date de debut\n    ########################\n    #dateDTfirst = dt.datetime(2017, 11, 1)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################\n# Récuperation des cours de bourse\n############################\n\n'''\nLibrairies à installer : \n\n    Numpy\n    Matplotlib\n    Pandas\n    Pandas-datareader (-> pip install pandas-datareader)\n    BeautifulSoup4\n    scikit-learn / sklearn\n\n'''\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport pandas as pd\nimport pandas_datareader.data as web\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#style.use('ggplot')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stocksValues = web.DataReader(\"^FCHI\", 'yahoo', dateDTfirst, dateDTlast)  # CAC40\n\n#with pd.option_context('display.max_rows',10):\n#    print(df_stocksValues)\n    \ndf_stocksValues\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_stocksValues[['High','Low','Open','Close','Adj Close']].plot(figsize=(15, 10))\ndf_stocksValues[['High','Low','Open','Close','Adj Close']].plot(figsize=(15, 10))\n\nplt.show()\n\ndf_stocksValues[['Volume']].plot(figsize=(15, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Date de début : \\n    \" + str(df_stocksValues.index[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# on concatène le sentiment des news de chaque jours\n    \nstart = time.time()\n\n# open csv file in \"write\" mode     // encoding utf-8 pour éviter les erreurs d'encodage\nwith open(CSV_FILE_NAME_OUTPUT_TEMP, 'w', newline='',encoding = 'utf-8') as fileOutput:\n    writerOutput = csv.writer(fileOutput, delimiter=',')\n    \n    \n    # open csv file in \"read\" mode     // encoding utf-8 pour éviter les erreurs d'encodage    \n    with open(CSV_FILE_NAME_INPUT, 'r', newline='',encoding = 'utf-8') as file:\n        \n        reader = csv.reader(file, delimiter=',')\n\n        indexJour=0\n        \n        nbrLignesTraiter=0\n        nbrDateTraiter=0\n        \n        rowWrite=[]\n        titleSentimentSum=0\n        textSentimentSum=0\n        textURLSentimentSum=0\n        \n        nbrNewsJour=0\n        nbrLignesTraiterJour=0\n        \n        for row in reader:  \n            \n            nbrLignesTraiter += 1  \n            nbrNewsJour += 1\n            \n            #Initialisation 1ère date\n            if nbrLignesTraiter == 1:\n                rowWrite.append(\"Nbr Day\")\n                rowWrite.append(\"Date\") \n                rowWrite.append(\"NbrNewsJour\") \n                rowWrite.append(\"Day Sent Vader Title\")\n                rowWrite.append(\"Day Sent Vader Text\")\n                rowWrite.append(\"Day Sent Vader Text URL\")\n                \n                listBourse = list(df_stocksValues.columns.values)   #[\"High\",\"Low\",\"Open\",\"Close\",\"Volume\",\"Adj Close\"]\n                rowWrite.extend(listBourse)\n                \n                writerOutput.writerow(rowWrite) \n                rowWrite=[]\n                #indexJour += 1\n                \n            #Les dates suivantes   \n            else:\n                titleSentimentSum += float(row[17])\n                textSentimentSum += float(row[18])\n                textURLSentimentSum += float(row[19])\n\n                #Date du cours de bourse\n                dateStocks = df_stocksValues.index[indexJour]\n\n                \n                # Date news\n                dateFormat = \"%d.%m.%Y\"\n                dateNews = dt.datetime.strptime(row[3], dateFormat)\n                \n                print(\"dateStocks = \" + str(dateStocks))\n                print(\"dateNews =   \" + str(dateNews))\n                \n                #S'il y a plusieurs news dans un jours\n                if dateStocks < dateNews:\n                    \n                    print(\"### DATES DIFFERANTES ### dateStocks < dateNews\")\n                    nbrDateTraiter += 1\n  \n                    \n                    #Preparation ecriture dans le fichier csv\n                    rowWrite.append(indexJour)\n                    rowWrite.append(dateStocks)\n                    rowWrite.append(nbrNewsJour)\n                    rowWrite.append(titleSentimentSum/nbrNewsJour)\n                    rowWrite.append(textSentimentSum/nbrNewsJour)\n                    rowWrite.append(textURLSentimentSum/nbrNewsJour)\n                    #rowWrite.append(df_stocksValues[\"Open\"][indexJour])\n\n                    listBourse = list(df_stocksValues.iloc[indexJour].values)   #[\"High\",\"Low\",\"Open\",\"Close\",\"Volume\",\"Adj Close\"]\n                    rowWrite.extend(listBourse)                    \n                    \n                    #Ecriture dans le fichier csv        \n                    writerOutput.writerow(rowWrite) \n\n                    indexJour += 1\n\n                    nbrNewsJour=0\n                    \n                    rowWrite=[]\n                    titleSentimentSum=0\n                    textSentimentSum=0\n                    textURLSentimentSum=0\n                \n                #S'il y a pas de news durant un jour (arrive rarement)\n                if dateStocks > dateNews:\n                    \n                    print(\"\\n\\n$$$$ DATES DIFFERANTES $$$$ PAS DE NEWS CE JOUR\\n\\n\")\n                    \n                    # Dans ce cas, le sentiment en neutre => 0\n                    #titleSentimentSum=0\n                    #textSentimentSum=0  \n                    #textURLSentimentSum=0 \n                    \n                    #il faut forcer l'écriture du cours pour rattraper\n                    \n                    \n                    \n             \n            \n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#determination taille fichier de sortie pour voir si tout s'est bien passé\nwith open(CSV_FILE_NAME_OUTPUT_TEMP, 'r', newline='',encoding = 'utf-8') as file:\n    reader = csv.reader(file, delimiter=',')\n    \n    #Calcule du nombre de ligne total\n    nbrLigneTotalCsvOutput = sum(1 for row in reader)  # fileObject is your csv.reader  \n    \n    print(\"Nbr de ligne total : \\n\")\n    print(\"   Fichier d'entrée = \" + str(nbrLigneTotalCsvInput))\n    print(\"   Fichier de sortie = \" + str(nbrLigneTotalCsvOutput))\n    print(\"   Données cours     = \" + str(len(df_stocksValues)))\n    print(\"\\n\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reouverture fichier pour affichage graphique\nwith open(CSV_FILE_NAME_OUTPUT_TEMP, 'r', newline='',encoding = 'utf-8') as file:\n\n    reader = csv.reader(file, delimiter=',')\n\n    for row in reader:  \n\n        nbrLignesTraiter += 1  \n        nbrNewsJour += 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !conda install -c plotly plotly\nimport plotly.express as px\n\ndf = pd.read_csv(CSV_FILE_NAME_OUTPUT_TEMP)\n\nfig = px.line(df, x = 'Date', y = ['Day Sent Vader Title','Day Sent Vader Text','Day Sent Vader Text URL'], title='Sentiment analyse')\nfig.show()\n\nfig = px.line(df, x = 'Date', y = ['NbrNewsJour'], title='Number news per day (The more we are far from the scraping date the less news we get)')\nfig.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Moyennage sentiment analysis \n# Voir : https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html\n\ndf = pd.read_csv(CSV_FILE_NAME_OUTPUT_TEMP)\n\n#Pour test le moyennage est fait sur 20 jours\ndf['Mean sent title'] = df['Day Sent Vader Title'].rolling(window=20,min_periods=0,center=True).mean()\n\ndf['Mean sent text'] = df['Day Sent Vader Text'].rolling(window=20,min_periods=0,center=True).mean()\n\ndf['Mean sent text URL'] = df['Day Sent Vader Text URL'].rolling(window=20,min_periods=0,center=True).mean()\n\n\n# Window type Triangle\n#df['Mean sent text Tri'] = df['Day Sent Vader Text'].rolling(window=20,min_periods=0,center=True,win_type='triang').mean()\n\n#print(df.head())\n\ndf[['Day Sent Vader Text','Mean sent text']].plot(figsize=(15, 10))\nplt.show()\n\n#fig = px.line(df, x = 'Date', y = ['Day Sent Vader Title','Day Sent Vader Text'], title='')\n#fig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Mean sent title','Mean sent text','Mean sent text URL']].plot(figsize=(15, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Superposition graph\n# Voir : https://stackoverflow.com/questions/62853539/plotly-how-to-plot-on-secondary-y-axis-with-plotly-express\n\nfrom plotly.subplots import make_subplots\n\n#df = pd.read_csv(CSV_FILE_NAME_OUTPUT_TEMP)\n\nsubfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# create two independent figures with px.line each containing data from multiple columns\nfig = px.line(df, x = 'Date', y = 'Open', title='')\nfig2 = px.line(df, x = 'Date', y = ['Mean sent text','Mean sent title','Mean sent text URL'], title='')\n\nfig2.update_traces(yaxis=\"y2\")\n\nsubfig.add_traces(fig.data + fig2.data)\nsubfig.layout.xaxis.title=\"Time\"\nsubfig.layout.yaxis.title=\"Open\"\n#subfig.layout.yaxis2.type=\"log\"\nsubfig.layout.yaxis2.title=\"Sentiment\"\n# recoloring is necessary otherwise lines from fig und fig2 would share each color\n# e.g. Linear-, Log- = blue; Linear+, Log+ = red... we don't want this\nsubfig.for_each_trace(lambda t: t.update(line=dict(color=t.marker.color)))\nsubfig.show()\n\n\n#fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OPTIONNEL : Ajout des données moyennés dans un nouveau fichier csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#On\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\ndf.to_csv(CSV_FILE_NAME_OUTPUT, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}