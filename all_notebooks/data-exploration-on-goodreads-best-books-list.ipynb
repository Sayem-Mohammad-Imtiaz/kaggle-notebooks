{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/goodreads-best-books-ever-with-recommendations/Goodreads_BestBooksEver_1-10000.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With describe(), we see that there are actually only 9486 unique books in here, the reason being some books can have many different editions and publications and will be listed here more than once. For authors, we see that there are only 5204 uniques names, because of the same reason above (one book can appear more than once), and/or also simply because one author can have more than one book that appears on the list. ","metadata":{}},{"cell_type":"markdown","source":"# Top 20 authors that show up the most on the list","metadata":{}},{"cell_type":"markdown","source":"First, let's clean the bookTitle column so that each title only appears once for the most accurate counting.","metadata":{}},{"cell_type":"code","source":"df_unique_title = df.drop_duplicates(subset=['bookTitle']) #this drops all duplicates and keep the first value ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"authors = df_unique_title['bookAuthors'].value_counts()[:20]\nprint(authors)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context('poster')\nplt.figure(figsize=(15,10))\nax = sns.barplot(x = authors, y = authors.index)\nax.set_title(\"Authors with the highest frequency on the list\")\nax.set_xlabel(\"Frequency\")\nax.set_ylabel(\"Authors\")\nfor i in ax.patches:\n    ax.text(i.get_width() +.3, i.get_y() + 0.5, str(round(i.get_width())), fontsize = 15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is not surpriring to see Stephen King on top of this list considering that he's one of the most popular and prolific authors of our time. This list seems to be dominated by popular modern authors whose target audience are young readers. ","metadata":{}},{"cell_type":"markdown","source":"# Top 20 books that show up the most ","metadata":{}},{"cell_type":"code","source":"books = df['bookTitle'].value_counts()[:20]\nsns.set_context('notebook')\nplt.figure(figsize=(15,10))\nax = sns.barplot(x = books, y = books.index, palette = \"magma\")\nax.set_title(\"Books with the highest frequency on the list\")\nax.set_xlabel(\"Frequency\")\nax.set_ylabel(\"Books\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Appearing on this list doesn't imply a book is \"good\" per se, but it's an indication that it's at least popular enough that many of its editions/publications are voted to be \"best\" by Goodreads users. Almost all books here are modern titles targeted to young audience. There are some that are considered classics such as *Farenheit 451* and *Animal Farm*.","metadata":{}},{"cell_type":"markdown","source":"# Top 10 most rated books","metadata":{}},{"cell_type":"markdown","source":"To find out this information, we need to keep in mind that there exist different editions/publications of books on this list. What we do not know is whether rating one edition of a book can also affect other editions of the same book. When we sort list by the ratingCount we will see why this is a concern.","metadata":{}},{"cell_type":"code","source":"df.sort_values('ratingCount', ascending = False).loc[:, 'bookTitle':'ratingCount'].head(10).set_index('bookTitle')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we suspect, some popular books will be on the top list under several editions, such as *The Hunger Games*. However, what's interesting is all the editions will have the exact same bookRating and almost the same ratingCount. It would not make much sense in this case to combine the count of all editions because we would very likely double-count. Instead we will keep the first instance of the books and remove any duplicates. ","metadata":{}},{"cell_type":"code","source":"most_rated = df.sort_values('ratingCount', ascending = False).drop_duplicates(subset=['bookTitle']).loc[:, 'bookTitle':'ratingCount'].head(15)\nmost_rated","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So here we still see some duplicates because the bookTitle are not the exact same for *1984* and *To Kill a Mockingbird* but they should still be removed. ","metadata":{}},{"cell_type":"code","source":"most_rated = most_rated[(most_rated['bookTitle'] != \"To Kill a Mockingbird\") & (most_rated['bookTitle'] != \"1984\")].set_index('bookTitle')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nax = sns.barplot(most_rated['ratingCount'], most_rated.index, palette='icefire_r')\nax.set_title(\"Most rated books\")\nax.set_xlabel(\"Ratings Count\")\nax.set_ylabel(\"Books\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top 10 most reviewed books","metadata":{}},{"cell_type":"code","source":"most_reviewed = df.sort_values('reviewCount', ascending = False).drop_duplicates(subset=['bookTitle']).loc[:, 'bookTitle':'reviewCount'].head(10).set_index('bookTitle')\nmost_reviewed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there is no duplicates, we can proceed to plotting right away","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nax = sns.barplot(most_reviewed['reviewCount'], most_reviewed.index, palette='rocket')\nax.set_title(\"Most reviewed books\")\nax.set_xlabel(\"Reviews Count\")\nax.set_ylabel(\"Books\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is interesting to note that *The Hunger Games* gets significantly more written reviews than *Harry Potter and the Sorcerer's Stone* even though the latter dominates in terms of **ratingCount** (or the number of people who only vote stars). \"The Fault in Our Stars\" and \"Gone Girl\" also seem to have a lot of fans who are willing to write (often times lengthy) reviews instead of just voting stars. I read book reviews a lot of Goodreads and personally speaking I would consider this a stronger sign that a book is well-liked by readers. This observation leads us to the next data exploration: ","metadata":{}},{"cell_type":"markdown","source":"# Books with the highest Reviews over Ratings ratio","metadata":{}},{"cell_type":"code","source":"df['reviewsoverratingsRatio'] = df.apply(lambda row: row.reviewCount/row.ratingCount, axis = 1) #create a new column with this metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like before, we will drop duplicates of the books with the same name and keep the first instance only (after sorting descending based on the ratio).","metadata":{}},{"cell_type":"code","source":"temp_highest_ratio = df[['bookTitle','bookRating','ratingCount','reviewCount','reviewsoverratingsRatio']].sort_values('reviewsoverratingsRatio', ascending = False).drop_duplicates(subset=['bookTitle'])\ntemp_highest_ratio.head(10)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_highest_ratio[temp_highest_ratio['bookTitle'] == \"The Hunger Games\"] #an example of a popular book from the previous lists","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this list we do see that there are books that have a very high ratio that almost for every rating there is an accompanying written review. However, these are all books with very few reviews and ratings and thus this ratio does not mean much because as a book accumulates more and more ratings this ratio will likely drop (we will explore this very soon) so we will not see any of the well-known, popular books. In fact, I know none of the books on the top list above. Let's redo this by only include the most popular names, let's say first 30 most rated books. ","metadata":{}},{"cell_type":"code","source":"most_rated_2 = df[['bookTitle','bookRating','ratingCount','reviewCount','reviewsoverratingsRatio']].sort_values(by = 'ratingCount', ascending = False).drop_duplicates(subset=['bookTitle'])\nhighest_ratio = most_rated_2.head(30).sort_values(by = 'reviewsoverratingsRatio', ascending = False)\nhighest_ratio.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For these popular titles, a top high ratio is somewhere between 3%-5%, which might not sound very impressive but we have to keep in mind the very high **ratingCount** they have to begin with.","metadata":{}},{"cell_type":"markdown","source":"# Distribution of the Reviews over Ratings ratio","metadata":{}},{"cell_type":"code","source":"sns.set_context('paper')\nax = sns.displot(df['reviewsoverratingsRatio'], color = 'green', bins = 100, kde = True)\nax.fig.set_figwidth(15)\nax.fig.set_figheight(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To see the exact bins and counts we can use numpy:","metadata":{}},{"cell_type":"code","source":"np.histogram(df['reviewsoverratingsRatio'], bins=100)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can conclude that the majority of books have a ratio between 0-0.2. As we move further to the right of the distribution plot where the ratio steadily increases we see that the count drops really fast which means there are only a few books that have a ratio that high.\n\nThe peak of the distribution is at 0.026 or ~3%. This means that most books will have around 3 written reviews per 100 ratings.\n\nWe can revisit the list of the most popular books with the highest **reviewsoverratingsRatio** and see that most of them (bar the last two) have a ratio > 0.026. Those in my opinion make the *definitive* top 10 best, most-rated, most-reviewed books on Goodreads.","metadata":{}},{"cell_type":"code","source":"highest_ratio[highest_ratio['reviewsoverratingsRatio'] > 0.026].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation between ratingCount and reviewsoverratingsRatio","metadata":{}},{"cell_type":"markdown","source":"We previously speculated that after a certain ratingCount, as the number of ratings a book receives increases, its **reviewoverratingRatio** decreases (meaning more and more people will only leave a rating without writing a review). Let's see if that's a correct statement.","metadata":{}},{"cell_type":"code","source":"sns.set_context('paper')\nax = sns.jointplot(x = \"ratingCount\",y = 'reviewsoverratingsRatio', kind='scatter',  data = df[['reviewsoverratingsRatio','ratingCount']])\nax.set_axis_labels(\"ratingCount\", \"reviewsoverratingsRatio\")\nax.fig.set_figwidth(15)\nax.fig.set_figheight(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at this plot, we notice that the **reviewsoverratingsRatio** is highest when **ratingCount** is close to 0 (on this scale of 10^6). **reviewsoverratingsRatio** drops rapidly as we move from 0 to 100000 ratings and the trends continues on as **ratingCount** increases. To remove outliers, and for the sake of better visiblity, we can limit the range of books to include in this study only ones whose **ratingCount** > 100,000","metadata":{}},{"cell_type":"code","source":"sns.set_context('paper')\nax = sns.jointplot(x = \"ratingCount\",y = 'reviewsoverratingsRatio', kind='scatter',  data = df[df['ratingCount'] >  100000][['reviewsoverratingsRatio','ratingCount']])\nax.set_axis_labels(\"ratingCount\", \"reviewsoverratingsRatio\")\nax.fig.set_figwidth(15)\nax.fig.set_figheight(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}