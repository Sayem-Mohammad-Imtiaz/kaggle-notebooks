{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Nonnegative Matrix Factorization Features\n\nThe aim is to construct user-user similarity matrices based on shared product purchases (and vice-versa) then apply matrix factorization techniques to extract topics (user 'profiles') from these matrices. Such user profiles would become features (columns of $X_s$). "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import NMF","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfile_path = '../input/'\n\nload_data_dtype = {'order_id': np.uint32,\n                   'user_id': np.uint32,\n                   'eval_set': 'category',\n                   'order_number': np.uint8,\n                   'order_dow': np.uint8,\n                   'order_hour_of_day': np.uint8,\n                   # pandas 'gotcha'; leave as float:\n                   'days_since_prior_order': np.float16,\n                   'product_id': np.uint16,\n                   'add_to_cart_order': np.uint8,\n                   'reordered': np.bool\n                   }","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"df_aisles = pd.read_csv(file_path + 'aisles.csv')\ndf_departments = pd.read_csv(file_path + 'departments.csv')\ndf_products = pd.read_csv(file_path + 'products.csv')\n\n# Specify dtype to reduce memory utilization\ndf_order_products_prior = pd.read_csv(file_path + 'order_products__prior.csv',\n                                      dtype=load_data_dtype\n                                      )\ndf_order_products_train = pd.read_csv(file_path + 'order_products__train.csv',\n                                      dtype=load_data_dtype\n                                      )\ndf_orders = pd.read_csv(file_path + 'orders.csv',\n                        dtype=load_data_dtype\n                        )\n\n# df_prior = full products from all prior orders \ndf_prior = pd.merge(df_orders[df_orders['eval_set'] == 'prior'],\n              df_order_products_prior,\n              on='order_id'\n              )\n\n# Useful DataFrame for aisle and department feature construction\ndf_ad = pd.merge(df_prior, df_products, how='left',\n                 on='product_id').drop('product_name', axis=1)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Names of dataset partitions\ndsets = ['train',\n         'test',\n         'kaggle']\n\nusers = dict.fromkeys(dsets)\n\n# Use sklearn utility to partition project users into train and test user lists.\nusers['train'], users['test'] = train_test_split(list(df_orders[df_orders.eval_set == 'train']['user_id']),\n                                                 test_size=0.2,\n                                           random_state=20190502)\n\n# Kaggle submissions test set\nusers['kaggle'] = list(df_orders[df_orders.eval_set == 'test']['user_id'])#.to_list()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split DataFrames we will use in feature construction into dicts of DataFrames\nprior = dict.fromkeys(dsets)\norders = dict.fromkeys(dsets)\nad = dict.fromkeys(dsets)\n\nfor ds in dsets:\n    prior[ds] = df_prior[df_prior['user_id'].isin(users[ds])]\n    orders[ds] = df_orders[df_orders['user_id'].isin(users[ds]) & (df_orders.eval_set == 'prior')]\n    ad[ds] = df_ad[df_ad['user_id'].isin(users[ds])]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create MultiIndex of all (nonempty) (user, product) pairs\n# for pandas 0.24:\n# up_index[ds], _ = pd.MultiIndex.from_frame(prior[ds][['user_id', 'product_id']]).sortlevel()\n# for pandas 0.23.4:\n\nup_index = dict.fromkeys(dsets)\n\nfor ds in dsets:\n    up_index[ds], _ = pd.MultiIndex.from_tuples(list(prior[ds][['user_id', 'product_id']].values),\n                                                names=prior[ds][['user_id', 'product_id']].columns).sortlevel()\n    up_index[ds] = up_index[ds].drop_duplicates()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UP_count = dict.fromkeys(dsets)\nfor ds in dsets:\n    UP_count[ds] = (prior[ds]\n                    .groupby(['user_id', 'product_id'])['order_id']\n                    .count()\n                    .rename('UP_count'))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UP_count_sparse, rows, columns = UP_count['test'].to_sparse().to_coo(row_levels=['user_id'],\n                                             column_levels=['product_id'],\n                                             sort_labels=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn import metrics\n\n# def get_score(model, data, scorer=metrics.explained_variance_score):\n#     \"\"\" Estimate performance of the model on the data \"\"\"\n#     prediction = model.inverse_transform(model.transform(data))\n#     return scorer(data, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspect NMF on UP_count matrix:"},{"metadata":{"trusted":true},"cell_type":"code","source":"factor = NMF(n_components=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W = factor.fit_transform(UP_count_sparse)\nH = factor.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"H.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"factor.reconstruction_err_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(datetime.datetime.now())\nKs = list(range(10, 120, 10))\nerrors_test = []\nfor K in Ks:\n    factor = NMF(n_components=K).fit(UP_count_sparse)\n    errors_test.append(factor.reconstruction_err_)\n    print(datetime.datetime.now())\nprint(errors_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(Ks, errors_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%who","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del (ad, \n     df_ad,\n     df_aisles,\n     df_departments,\n     df_order_products_prior,\n     df_order_products_train,\n     df_orders,\n     df_prior,\n     df_products    \n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build Similarity Matrices"},{"metadata":{"trusted":true},"cell_type":"code","source":"product_similarity = dict.fromkeys(dsets)\nfor ds in dsets:\n    product_similarity[ds] = (prior[ds][['user_id', 'product_id']]\n                              .drop_duplicates()\n                              .sort_values(by=['user_id', 'product_id']))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"product_similarity['train'].info()","execution_count":9,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 6760791 entries, 0 to 32434422\nData columns (total 2 columns):\nuser_id       uint32\nproduct_id    uint16\ndtypes: uint16(1), uint32(1)\nmemory usage: 90.3 MB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"[column combinations](https://stackoverflow.com/questions/47618888/how-generate-all-pairs-of-values-from-the-result-of-a-groupby-in-a-pandas-data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import combinations","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def col_comb(gp, r):\n    return pd.DataFrame(list(combinations(gp.values, r)), \n                            columns=['row', 'col'])\n\nproduct_user = (product_similarity['test']\n                .groupby('user_id')\n                .product_id\n                .apply(col_comb, 2)\n                .reset_index(level=1, drop=True)\n                .reset_index()\n                .groupby(['row','col'])\n                .count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UP_count['test'].head(100).groupby('user_id')['product_id'].apply(lambda prod : list(combinations(prod.values,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(combinations)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}