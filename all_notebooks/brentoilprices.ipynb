{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Brent Oil Prices Prediction using Prophet & ARIMA**.\nArticle explaining the code is [available here](https://medium.com/analytics-vidhya/brent-oil-prices-forecast-with-prophet-and-arima-50f5f177da5b).","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import the csv file\noilPrices = pd.read_csv('/kaggle/input/brent-oil-prices/BrentOilPrices.csv')\n#change column names to more comfortable names\noilPrices.columns=['date', 'price']\n\nprint(\"Data Set:\"% oilPrices.columns, oilPrices.shape)\nprint(\"Data Types:\", oilPrices.dtypes)\n#Check the top five records\noilPrices.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cast Date Column to type date\noilPrices['date'] = pd.to_datetime(oilPrices['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As you may noticed the time series data does not contain the values for Saturday and Sunday. Hence missing values have to be filled. \n#Fill in Weekends - First make date as index (for resample method), then use forward fill ffill(),\n#which will assign the weekend values with Friday value. Resample method for frequency conversion and resampling of time series. Object must have a datetime-like index (DatetimeIndex, PeriodIndex, or TimedeltaIndex), \n#or pass datetime-like values to the on or level keyword\noilPrices.set_index('date', inplace=True)\noilPrices = oilPrices.resample('D').ffill().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make sure we have no null values\noilPrices.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us split the date into year, month and week to explore trend in oil prices\noilPrices['year']=oilPrices['date'].dt.year\noilPrices['month']=oilPrices['date'].dt.month\noilPrices['week']=oilPrices['date'].dt.week","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us read the data until the 1st of January 2019 to split the data and predict prices in 2019\ntrain = oilPrices[(oilPrices['date' ] > '2001-01-01') & (oilPrices['date' ] <= '2019-12-31')]\ntest = oilPrices[oilPrices['date' ] >= '2020-01-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Yearly price visualization\nyearlyPrice=train.groupby([\"year\"])['price'].mean()\nplt.figure(figsize=(16,4))\nplt.title('Oil Prices')\nplt.xlabel('Year')\nplt.ylabel('Price')\nyearlyPrice.plot()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#time-series to decompose our time series into three distinct components: trend, seasonality, and noise.\nmonthlyPrice=oilPrices.groupby([\"month\"])['price'].mean()\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 18, 8\ndecomposition = sm.tsa.seasonal_decompose(yearlyPrice, freq=1, model='additive')\nfig = decomposition.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nd={'ds':train['date'],'y':train['price']}\ndf_pred=pd.DataFrame(data=d)\n# I took off Seasonality as Oil prices on weekends remain same as Friday until next opening on Monday\nmodel = Prophet(daily_seasonality=False)\nmodel.fit(df_pred)\nfuture = model.make_future_dataframe(periods=273)\nforecast = model.predict(future)\nforecast2020 = forecast[(forecast['ds' ] >= '2020-01-01') & (forecast['ds' ] <= '2020-04-21')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 6))\nmodel.plot(forecast, xlabel = 'Date', ylabel = 'Price')\nplt.title('Brent Oil Price Prediction');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(model, forecast2020)  # This returns a plotly Figure\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(forecast2020['ds'], forecast2020['yhat'], label='Predicted Prices')\nax.plot(test['date'], test['price'], label='Original Prices')\nplt.ylim([0,100])\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.title('Prophet Model Brent Oil Prices Forecast 2020')\nplt.xlabel('Month')\nplt.ylabel('Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics\n#Create a series of predicted values and observed ones\nobserved=test['price'].iloc[1:]\npredicted=forecast2020['yhat'].iloc[1:]\n#Reset the index of the series\npredicted.reset_index(drop=True, inplace=True)\nobserved.reset_index(drop=True, inplace=True)\n# loop over the set and find the difference between observed and predicted values then save them in a set\npred_err=[]\nfor count in range(len(observed)):\n    err = predicted[count] - observed[count]\n    pred_err.append(err)\n#Take the Absolute value and find the mean\nmae = statistics.mean(map(abs,pred_err))\nprint('Mean Absolute Error = {}'.format(round(mae, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert to Time Series For ARIMA Estimator\nseries=pd.Series(data=train['price'].to_numpy(), index=train['date'])\n#check if the Index is Datetime format\nseries.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The Augmented Dickey-Fuller test can be used to test for a unit root in a univariate process in the presence of serial correlation.\nfrom statsmodels.tsa.stattools import adfuller\nfrom numpy import log\nresult = adfuller(series)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look if there is a stationary data, which looks non stationary\n#We need stationary data to make time series forecasting\nplt.plot(series[0:100])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the order of differencing (d) in ARIMA model; hence the purpose of differencing it to make the time series stationary\ndaily_series_diff1 = series.diff(periods=1).dropna()\ndaily_series_diff2 = daily_series_diff1.diff(periods=1).dropna()\nfig, ax = plt.subplots()\nax.plot(daily_series_diff1[0:100], label='1st Order Differencing')\nax.plot(daily_series_diff2[0:100], label='2nd Order Differencing')\nplt.ylim([-3,3])\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.title('Time Series')\nplt.xlabel('Date')\nplt.ylabel('Diff')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'figure.figsize':(12,3), 'figure.dpi':120})\nfrom statsmodels.graphics.tsaplots import plot_acf\nfig, axes = plt.subplots(1, 2, sharex=True)\nplot_acf(daily_series_diff1, lags=20, ax=axes[0], title=\"Autocorrelation 1st Order Differencing\")\nplot_acf(daily_series_diff2, lags=20, ax=axes[1], title=\"Autocorrelation 2nd Order Differencing\")\nplt.xlabel('Lag')\nplt.ylabel('ACF')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Determine the number of the moving average by looking at the Partial Autocorrelation : p value should be one based on the Partial Autocorrelation \nplt.rcParams.update({'figure.figsize':(12,3), 'figure.dpi':120})\n#Partial Auto-Correlation\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfig, axes = plt.subplots(1, 2, sharex=True)\nplot_pacf(daily_series_diff1, lags=10, ax=axes[0], title=\"Partial Autocorrelation 1st Order Differencing\")\nplot_pacf(daily_series_diff2, lags=10, ax=axes[1], title=\"Partial Autocorrelation 2nd Order Differencing\")\nplt.xlabel('Lag')\nplt.ylabel('PACF')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima\n#Number of differences required for a stationary series\nfrom pmdarima.arima.utils import ndiffs\ny=series\n# augmented Dickey–Fuller test (adf test)\nprint(\"ADF Test: \",ndiffs(y, test='adf'))\n# Kwiatkowski–Phillips–Schmidt–Shin (KPSS) test\nprint(\"KPSS Test: \",ndiffs(y, test='kpss'))\n# Phillips–Perron (PP) test:\nprint(\"PP Test: \",ndiffs(y, test='pp'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pmdarima as pm\nmodel = pm.auto_arima(series, start_p=1, start_q=1,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n# fit model\nmodel = ARIMA(series, order=(1, 0, 1)).fit(transparams=False)\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Forecast the oil prices for the period start='1/1/2019', end='9/30/2019'\n#typ='levels' if d is not set to zero (d = the number of nonseasonal differences)\nARIMA_Predict = model.predict(start='1/1/2019', end='9/30/2019')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standard deviation of residuals or Root-mean-square error (RMSD) https://www.youtube.com/watch?v=zMFdb__sUpw\nmseProphet = mean_squared_error(test['price'],forecast2020['yhat'])\nmseARIMA = mean_squared_error(test['price'],ARIMA_Predict)\nrmseProphet = sqrt(mseProphet)\nrmseARIMA = sqrt(mseARIMA)\nprint('The Mean Squared Error of ARIMA forecasts is {}'.format(round(mseARIMA, 2)))\nprint('The Root Mean Squared Error of ARIMA forecasts is {}'.format(round(rmseARIMA, 2)))\nprint('The Mean Squared Error of Prophet forecasts is {}'.format(round(mseProphet, 2)))\nprint('The Root Mean Squared Error of Prophet forecasts is {}'.format(round(rmseProphet, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OR you may replace all the above with sklearn simple mae function:\nfrom sklearn.metrics import mean_absolute_error\nmaeARIMA=mean_absolute_error(test['price'],ARIMA_Predict)\nmaeProphet=mean_absolute_error(test['price'],forecast2020['yhat'])\nprint('Mean Absolute Error ARIMA = {}'.format(round(maeARIMA, 2)))\nprint('Mean Absolute Error Prophet = {}'.format(round(maeProphet, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(forecast2020['ds'], ARIMA_Predict, label='Predicted Prices')\nax.plot(test['date'], test['price'], label='Original Prices')\nplt.ylim([0,100])\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.title('ARIMA Model Brent Oil Prices Forecast 2019')\nplt.xlabel('Month')\nplt.ylabel('Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae=mean_absolute_error(test['price'],ARIMA_Predict)\nprint('Mean Absolute Error = {}'.format(round(mae, 2)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}