{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/churn-in-telecoms-dataset/bigml_59c28831336c6604c800002a.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Постановка задачи: определить по каким характеристикам клиенты покидают компанию."},{"metadata":{},"cell_type":"markdown","source":"Целевой признак (target) - churn (отток), имеет тип bool. Принимает два значения: \"False\" - является клиентом компании; \"True\" - клиент покинул компанию. Рассматривается задача обучения с учителем - классификация."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['churn'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Имеет примерно 85.5% лояльных клиентов и примерно 14.5% нелояльных клиентов."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['churn'].value_counts(normalize = True).plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Так как есть существенная разница между лояльными и нелояльными клиентами, то классы \"False\" и \"True\" - несбалансированы."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"state\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Исходя из полученных данных получается, что информация по штатам особо не влияет на отток клиентов. Поэтому уберём её из таблицы."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"area code\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Номер телефона у всех уникальный, поэтому эта характеристика никак не влияет на отток клиентов. Тоже уберём это из таблицы."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = df.drop([\"state\",\"phone number\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2 = df_1.drop([\"churn\", \"area code\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[\"international plan\"] = df_2['international plan'].map({\"yes\":1,\"no\":0})\ndf_2[\"voice mail plan\"] = df_2['voice mail plan'].map({\"yes\":1,\"no\":0})\nX = df_2\n\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1[\"churn\"] = df_1['churn'].map({False:0,True:1})\ny = df_1['churn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.25, random_state = 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred = tree.predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle = True, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ntree_params_max_depth = {'max_depth': np.arange(2, 15)}\ntree_grid = GridSearchCV(tree, tree_params_max_depth, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)\ntree_grid_cv_results_max_depth=tree_grid.cv_results_\ntree_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=7)\ntree_params_min_samples_split = {'min_samples_split': np.arange(2, 50)}\ntree_grid = GridSearchCV(tree, tree_params_min_samples_split, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)\ntree_grid_cv_results_min_samples_split=tree_grid.cv_results_\ntree_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=7, min_samples_split=15)\ntree_params_min_samples_leaf = {'min_samples_leaf': np.arange(1, 50)}\ntree_grid = GridSearchCV(tree, tree_params_min_samples_leaf, cv=kf, scoring='accuracy')\ntree_grid.fit(X_train, y_train)\ntree_grid_cv_results_min_samples_leaf=tree_grid.cv_results_\ntree_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=7, min_samples_split=15, min_samples_leaf=2)\ntree_params_max_features = {'max_features': np.arange(1, X.shape[1])}\ntree_grid = GridSearchCV(tree, tree_params_max_features, cv=kf, scoring='accuracy') \ntree_grid.fit(X_train, y_train)\ntree_grid_cv_results_max_features=tree_grid.cv_results_\ntree_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ((ax11,ax22),(ax33,ax44)) = plt.subplots(nrows=2, ncols=2, sharey=True,figsize=(10, 10))\n\nax11.plot(tree_params_max_depth['max_depth'], tree_grid_cv_results_max_depth['mean_test_score'])\nax11.set_xlabel('max_depth')\nax11.set_ylabel('Mean accuracy on test set')\n\nax22.plot(tree_params_min_samples_split['min_samples_split'], tree_grid_cv_results_min_samples_split['mean_test_score'])\nax22.set_xlabel('min_samples_split')\n\nax33.plot(tree_params_min_samples_leaf['min_samples_leaf'], tree_grid_cv_results_min_samples_leaf['mean_test_score'])\nax33.set_xlabel('min_samples_leaf')\nax33.set_ylabel('Mean accuracy on test set')\n\nax44.plot(tree_params_max_features['max_features'], tree_grid_cv_results_max_features['mean_test_score'])\nax44.set_xlabel('max_features')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно сделать вывод, что один из хороших сетов имеет такие значения: max_depth = 7, min_samples_split = 15, min_samples_leaf = 2, max_features = 16."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(max_depth = 7, min_samples_split = 15, min_samples_leaf = 2, max_features = 16)\ny_pred =best_tree.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Строим графически полученное дерево"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\n\nexport_graphviz(best_tree, out_file='best_tree.dot', feature_names=X.columns)\nprint(open('best_tree.dot').read())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dict(zip(range(len(X.columns)), X.columns))\n\n# Важность признаков\nimportances = best_tree.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n# Plot the feature importancies of the tree\nnum_to_plot = len(X.columns)\nfeature_indices = [ind for ind in indices[:num_to_plot]]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(num_to_plot):\n    print(f+1, features[feature_indices[f]], importances[indices[f]])\n\nplt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[i]) for i in feature_indices]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Лучшая модель получилась с такими гиперпараметрами: max_depth = 7, min_samples_split = 15, min_samples_leaf = 2, max_features = 16. Самые влиятельные из признаков оказались: total day charge и customer service calls."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf_params_n_estimators = {'n_estimators': np.arange(50, 450, 50)}\nrf_grid = GridSearchCV(rf, rf_params_n_estimators, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)\nrf_grid_cv_results_n_estimators = rf_grid.cv_results_\nrf_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 100)\nrf_params_max_depth = {'max_depth': np.arange(2, 15)}\nrf_grid = GridSearchCV(rf, rf_params_max_depth, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)\nrf_grid_cv_results_max_depth = rf_grid.cv_results_\nrf_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 100, max_depth = 13)\nrf_params_min_samples_split = {'min_samples_split': np.arange(2, 50)}\nrf_grid = GridSearchCV(rf, rf_params_min_samples_split, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)\nrf_grid_cv_results_min_samples_split = rf_grid.cv_results_\nrf_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 100, max_depth = 13, min_samples_split = 2)\nrf_params_min_samples_leaf = {'min_samples_leaf': np.arange(1, 50)}\nrf_grid = GridSearchCV(rf, rf_params_min_samples_leaf, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)\nrf_grid_cv_results_min_samples_leaf = rf_grid.cv_results_\nrf_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 100, max_depth = 13, min_samples_split = 2,min_samples_leaf = 1)\nrf_params_max_features = {'max_features': np.arange(2, X.shape[1])}\nrf_grid = GridSearchCV(rf, rf_params_max_features, cv=kf, scoring='accuracy')\nrf_grid.fit(X_train, y_train)\nrf_grid_cv_results_max_features = rf_grid.cv_results_\nrf_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,5))\n\nax.plot(rf_params_n_estimators['n_estimators'], rf_grid_cv_results_n_estimators['mean_test_score'])\nax.set_xlabel('n_estimators')\nax.set_ylabel('Mean accuracy on test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,5))\n\nax.plot(rf_params_max_depth['max_depth'], rf_grid_cv_results_max_depth['mean_test_score'])\nax.set_xlabel('max_depth')\nax.set_ylabel('Mean accuracy on test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,5))\n\nax.plot(rf_params_min_samples_split['min_samples_split'], rf_grid_cv_results_min_samples_split['mean_test_score'])\nax.set_xlabel('min_samples_split')\nax.set_ylabel('Mean accuracy on test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,5))\n\nax.plot(rf_params_min_samples_leaf['min_samples_leaf'], rf_grid_cv_results_min_samples_leaf['mean_test_score'])\nax.set_xlabel('min_samples_leaf')\nax.set_ylabel('Mean accuracy on test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (5,5))\n\nax.plot(rf_params_max_features['max_features'], rf_grid_cv_results_max_features['mean_test_score'])\nax.set_xlabel('max_features')\nax.set_ylabel('Mean accuracy on test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_rf = RandomForestClassifier(n_estimators = 100, max_depth = 13, min_samples_split = 2, min_samples_leaf = 1, max_features = 4)\ny_pred = best_rf.fit(X_train, y_train).predict(X_valid)\naccuracy_score(y_valid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dict(zip(range(len(X.columns)), X.columns))\n\n# Важность признаков\nimportances = best_rf.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n# Plot the feature importancies of the forest\nnum_to_plot = 10\nfeature_indices = [ind for ind in indices[:num_to_plot]]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(num_to_plot):\n    print(f+1, features[feature_indices[f]], importances[indices[f]])\n\nplt.figure(figsize=(15,5))\nplt.title(\"Feature importances\")\nbars = plt.bar(range(num_to_plot), \n               importances[indices[:num_to_plot]],\n               color=([str(i/float(num_to_plot+1)) for i in range(num_to_plot)]),\n               align=\"center\")\nticks = plt.xticks(range(num_to_plot), \n                   feature_indices)\nplt.xlim([-1, num_to_plot])\nplt.legend(bars, [u''.join(features[i]) for i in feature_indices]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Метод ближайших соседей](https://www.kaggle.com/vladyslavb/telecom-churn) в лучшем случае давал результат 89% точности. Дерево решений с оптимальным набором гиперпараметров - 94%. Можно сказать, что модель дерева решений показало лучше результаты, чем метод ближайщих соседей. Модель случайного леса показало результат 96% точности. То есть случайный лес сработал немного лучше, чем дерево решений. Так же наиболее влиятельными признаками оказались: total day charge и customer service calls."},{"metadata":{},"cell_type":"markdown","source":"Из всех рассмотренных моделей на данном датасете, лучше всех показал результаты случайный лес с гиперпараметрами: n_estimators = 100, max_depth = 13, min_samples_split = 2, min_samples_leaf = 1, max_features = 4."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}