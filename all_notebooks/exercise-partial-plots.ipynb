{"cells":[{"metadata":{"_uuid":"c97d314a2ec613e15130a0052c4342d867794c1d"},"cell_type":"markdown","source":"# Exercises\n\n## Set Up\n\nToday you will create partial dependence plots and practice building insights with data from the [Taxi Fare Prediction](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) competition.\n\nWe have again provided code to do the basic loading, review and model-building. Run the cell below to set everything up:"},{"metadata":{"_uuid":"8fe830e20f9749304afa8005292e638dddced885","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Environment Set-Up for feedback system.\nimport sys\nsys.path.append('../input/ml-insights-tools')\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom ex3 import *\nprint(\"Setup Complete\")\n\n# Data manipulation code below here\ndata = pd.read_csv('../input/new-york-city-taxi-fare-prediction/train.csv', nrows=50000)\n\n# Remove data with extreme outlier coordinates or negative fares\ndata = data.query('pickup_latitude > 40.7 and pickup_latitude < 40.8 and ' +\n                  'dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and ' +\n                  'pickup_longitude > -74 and pickup_longitude < -73.9 and ' +\n                  'dropoff_longitude > -74 and dropoff_longitude < -73.9 and ' +\n                  'fare_amount > 0'\n                  )\n\ny = data.fare_amount\n\nbase_features = ['pickup_longitude',\n                 'pickup_latitude',\n                 'dropoff_longitude',\n                 'dropoff_latitude']\n\nX = data[base_features]\n\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nfirst_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(train_X, train_y)\nprint(\"Data sample:\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"633df0f4abae13673c5b9568f0309f66ab4f67b6","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efe784be5df7ee25f2ceb1244222d2cd49679aef"},"cell_type":"markdown","source":"## Question 1\n\nHere is the code to plot the partial dependence plot for pickup_longitude.  Run the following cell."},{"metadata":{"_uuid":"863848691677308d97dcd9b3958c34978b11778d","trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp, get_dataset, info_plots\n\nfeat_name = 'pickup_longitude'\npdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70dbcbfe8a19f3026f7cf17a7d93b7ed461554b3"},"cell_type":"markdown","source":"Why does the partial dependence plot have this U-shape?\n\nDoes your explanation suggest what shape to expect in the partial dependence plots for the other features?\n\nCreate all other partial plots in a for-loop below (slightly modifying the code from the above cell."},{"metadata":{"_uuid":"1280e5935c5697980da6da88f6e7ded0e2226556","trusted":true,"scrolled":false},"cell_type":"code","source":"for feat_name in base_features:\n    pdp_dist = pdp.pdp_isolate(model=first_model, dataset=val_X, model_features=base_features, feature=feat_name)\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96cb90c0f5793bff4cae33cbf9451b26a99ff7be"},"cell_type":"markdown","source":"Do the shapes match your expectations for what shapes they would have? Can you explain the shape now that you've seen them? \n\nUncomment the following line to check your intuition."},{"metadata":{"_uuid":"fe1f0554a247e4d5ede7565a88b3ad66a355075e","trusted":true},"cell_type":"code","source":"q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83596cdefe19bd8c97316a2ac06b89a3a62904bf"},"cell_type":"markdown","source":"## Question 2\n\nNow create a 2D partial dependence plot.  As a reminder, here is the code from the tutorial.  \n\n```\ninter1  =  pdp.pdp_interact(model=my_model, dataset=val_X, model_features=feature_names, features=['Goal Scored', 'Distance Covered (Kms)'])\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=['Goal Scored', 'Distance Covered (Kms)'], plot_type='contour')\nplt.show()\n```\n\nHow do you interpret that shape?"},{"metadata":{"trusted":true,"_uuid":"5d51a945ae6dbab7f7dbd56a69cc5ec481501489"},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"288de13867e37266b97c0497fbcfb419d8a2c61b","trusted":true},"cell_type":"code","source":"# Add your code here\nfeatures_to_plot = ['pickup_longitude', 'dropoff_longitude']\ninter1  =  pdp.pdp_interact(model=first_model, dataset=val_X, model_features=base_features, features=features_to_plot)\n\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe9790781514c813f6b8d260d231a982f5b6366f"},"cell_type":"markdown","source":"Uncomment the line below to see the solution and explanation for how one might reason about the plot shape."},{"metadata":{"_uuid":"30ebee6fda0ac528f791f1e820712758f29279f9","trusted":true},"cell_type":"code","source":"q_2.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44483c78bfdd6a2356fb43ce352d4a6084eb90d2"},"cell_type":"markdown","source":"## Question 3\nConsider a ride starting at longitude -73.92 and ending at longitude -74. Using the graph from the last question, estimate how much money the rider would have saved if they'd started the ride at longitude -73.98 instead?"},{"metadata":{"_uuid":"5b9a89f76353c4eb2ea8751c151b9b7ba8f455a6","trusted":true},"cell_type":"code","source":"savings_from_shorter_trip = 24 - 9\n\n# Uncomment the line below to check your answer\nq_3.check()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b058b106f1389e4edfdd0c485b6f8b92aea859f"},"cell_type":"markdown","source":"For a solution or hint, uncomment the appropriate line below."},{"metadata":{"_uuid":"d490d75f62c42779fc782a46d21db6d59b1e5c8c","trusted":true},"cell_type":"code","source":"q_3.hint()\nq_3.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5e6a62e57a32edee10b66df40120f776636f355"},"cell_type":"markdown","source":"## Question 4\nIn the PDP's you've seen so far, location features have primarily served as a proxy to capture distance traveled. In the permutation importance lessons, you added the features `abs_lon_change` and `abs_lat_change` as a more direct measure of distance.\n\nCreate these features again here. You only need to fill in the top two lines.  Then run the following cell.  **After you run it, identify the most important difference between this partial dependence plot and the one you got above without the absolute value features.**\n\n---"},{"metadata":{"_uuid":"2bfb290df9a3ed44aa468dbbd911ca6391893502","trusted":true},"cell_type":"code","source":"import numpy as np\n\n# create new features\ndata['abs_lon_change'] = np.abs(data.dropoff_longitude - data.pickup_longitude)\ndata['abs_lat_change'] = np.abs(data.dropoff_latitude - data.pickup_latitude)\n\nfeatures_2  = ['pickup_longitude',\n               'pickup_latitude',\n               'dropoff_longitude',\n               'dropoff_latitude',\n               'abs_lat_change',\n               'abs_lon_change']\n\nX = data[features_2]\nnew_train_X, new_val_X, new_train_y, new_val_y = train_test_split(X, y, random_state=1)\nsecond_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(new_train_X, new_train_y)\n\nfeat_name = 'pickup_longitude'\npdp_dist = pdp.pdp_isolate(model=second_model, dataset=new_val_X, model_features=features_2, feature=feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()\n\n# uncomment the line below to check your answer\n#q_4.check()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbdf4458d9a23e61998cb2d89d75eef652552b67"},"cell_type":"markdown","source":"It looks like adding the new features changes where the pickup_longitude becomes good. After -73.94 instead of -73.96.\n\nUncomment the lines below to see a hint or the solution (including an explanation of the important differences between the plots)."},{"metadata":{"_uuid":"cc59c68fc6edbbfc86cc7a4f3f3779a9ec99b61c","trusted":true},"cell_type":"code","source":"q_4.hint()\nq_4.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98b3304b7ea9080ea3ee9857d1f30bb94c8db7f6"},"cell_type":"markdown","source":"## Question 5\nConsider a scenario where you have only 2 predictive features, which we will call `feat_A` and `feat_B`. Both features have minimum values of -1 and maximum values of 1.  The partial dependence plot for `feat_A` increases steeply over its whole range, whereas the partial dependence plot for feature B increases at a slower rate (less steeply) over its whole range.\n\nDoes this guarantee that `feat_A` will have a higher permutation importance than `feat_B`.  Why or why not?\n\nAfter you've thought about it, uncomment the line below for the solution."},{"metadata":{"_uuid":"6460e64b5184fd44e1bddd7fa02ad630c60ddb30","trusted":true},"cell_type":"code","source":"q_5.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b08f84eb2c18957ad8ecce70cd26f728bbc256e3"},"cell_type":"markdown","source":"## Question 6\nCreate a dataset with the following characteristics:\n- There are 2 predictive features and a target\n- Each predictive feature has a range from -2 to 2.\n- The PDP of your first feature (called `X1`) has a positive slope from [-1,1], and a negative slope everywhere else when run in a decision tree model.\n\n*Note: You are supplied the code to create the predictive features, and you only need to create y*"},{"metadata":{"_uuid":"43fe5a0da41328f947208187a3089e099f72fe74","trusted":true},"cell_type":"code","source":"from numpy.random import rand\n\nn_samples = 1000\n\n# Create array holding predictive feature\nX1 = 4 * rand(n_samples) - 2\nX2 = 4 * rand(n_samples) - 2\n# Create y. you should have X in the expression for y\ny = -2 * X1 * (X1<-1) + X1 - 2 * X1 * (X1>1) - X2\n\n\n# create dataframe because pdp_isolate expects a dataFrame as an argument\nmy_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\npredictors_df = my_df.drop(['y'], axis=1)\n\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n\npdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\n\n# visualize your results\npdp.pdp_plot(pdp_dist, 'X1')\nplt.show()\n\nprint(\"Scatter plot of X1 vs y:\")\nplt.scatter(X1, y)\nplt.show()\n\n# uncomment line below to check your solution\n# q_6.check()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"752c8efc7f73548c49ad536fc8b77f9eaa7b0cf4"},"cell_type":"markdown","source":"Uncomment the lines below for a hint or solution"},{"metadata":{"_uuid":"54cf2bce15d363fd9a40a2ecdb5affd29b56a361","trusted":true},"cell_type":"code","source":"q_6.hint()\nq_6.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52b411774dc757fd431b39642ee3b4316e4060c2"},"cell_type":"markdown","source":"## Question 7\nCreate a dataset with 2 features and a target, such that the pdp of the first feature is flat, but its permutation importance is high.  We will use a RandomForest for the model.\n\n*Note: You only need to supply the lines that create the variables X1, X2 and y. The code to check your data is provided*."},{"metadata":{"_uuid":"b477ee5f0fd162308538a8bc5b2b95ebdcdfd720","trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nn_samples = 10000\n\n# Create array holding predictive feature\nX1 = 4 * rand(n_samples) - 2\nX2 = 4 * rand(n_samples) - 2\n# Create y. you should have X in the expression for y\ny = X1 * X2\n\n\n# create dataframe because pdp_isolate expects a dataFrame as an argument\nmy_df = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\npredictors_df = my_df.drop(['y'], axis=1)\n\nmy_model = RandomForestRegressor(n_estimators=30, random_state=1).fit(predictors_df, my_df.y)\n\n\npdp_dist = pdp.pdp_isolate(model=my_model, dataset=my_df, model_features=['X1', 'X2'], feature='X1')\npdp.pdp_plot(pdp_dist, 'X1')\nplt.show()\n\nperm = PermutationImportance(my_model).fit(predictors_df, my_df.y)\n\n# Uncomment the following line to check your answer.\n# q_7.check()\n\n# show the weights for the permutation importance you just calculated\neli5.show_weights(perm, feature_names = ['X1', 'X2'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"534241b8a2ab8f057b001ceead68a22c0c56222f","trusted":true},"cell_type":"code","source":"# Uncomment the following lines for the hint or solution\nq_7.hint()\nq_7.solution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89d82add85e4a8aaad663f7f2bacce03b1ba0bd1"},"cell_type":"markdown","source":"## Congrats\n\nPartial dependence plots can be really interesting. We have a [discussion thread](https://www.kaggle.com/learn-forum/65782) to talk about what real-world topics or questions you'd be curious to see addressed with partial dependence plots. \n\nNext up is **SHAP values** which help you understand the logic for each individual prediction."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}