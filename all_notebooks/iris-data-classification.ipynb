{"cells":[{"metadata":{"_uuid":"9c5cc0ec5fb2ac15fa9ac1b30d9e51a2c2f4c786"},"cell_type":"markdown","source":"Reference:\nSolving A Simple Classification Problem with Python — Fruits Lovers’ Edition by \n**Susan Li**\nChanging the world, one article at a time. Sr. Data Scientist, Toronto Canada. Opinion=my own. \nDec 4, 2017\nhttps://towardsdatascience.com/solving-a-simple-classification-problem-with-python-fruits-lovers-edition-d20ab6b071d2"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndata = pd.read_csv('../input/Iris.csv')\nprint(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a9ef16ef71f48e199be44b24b6348788b296c2a"},"cell_type":"markdown","source":"**Using logistic regression as the model**"},{"metadata":{"trusted":true,"_uuid":"15476ce78d6aacbde2833aa985c52de39fd9ab9b"},"cell_type":"code","source":"feature_names = [ 'PetalLengthCm', 'PetalWidthCm','SepalLengthCm', 'SepalWidthCm']\nX =data[feature_names]\ny=data['Species']\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nprint('Accuracy of Logistic regression classifier on training set: {:.2f}'\n     .format(logreg.score(X_train, y_train)))\nprint('Accuracy of Logistic regression classifier on test set: {:.2f}'\n     .format(logreg.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da74b27169b9dc229fd259616f936845b7273f35"},"cell_type":"markdown","source":"**Plot and decision boundary of the classification**\nSteps involved\n\n1.Convert the categorical variables of the 3 classes in the database Iris-versicolor,Iris-verginica and Iris-setosa,into numeric.\n\n2.Split data into test and train.\n\n3.Knn classifier is used as ml algorithm.\n\n4.Visualizations are done using 2 selected features only-'PetalLengthCm', 'PetalWidthCm'\nand decision boundaries of classes  are plot.\n"},{"metadata":{"trusted":true,"_uuid":"350f60c5e2aeb0ad04add304b8c9b5f62592d464"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nimport matplotlib.cm as cm\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\nimport matplotlib.patches as mpatches\nimport matplotlib.patches as mpatches\ndf = pd.DataFrame(data, columns = ['PetalLengthCm', 'PetalWidthCm','SepalLengthCm', 'SepalWidthCm','Species'])\ndef score_to_numeric(x):\n    if x=='Iris-virginica':\n        return 3\n    if x=='Iris-setosa':\n        return 2\n    if x=='Iris-versicolor':\n        return 1\ndf['score_num'] = df['Species'].apply(score_to_numeric)   \n#df['score_num']\n\nfeature_names = [ 'PetalLengthCm', 'PetalWidthCm','SepalLengthCm', 'SepalWidthCm']\nX =data[feature_names]\ny=df['score_num']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\ndef plot_fruit_knn(X, y, n_neighbors):\n    X_mat = X[['PetalLengthCm', 'PetalWidthCm']].as_matrix()\n    y_mat = y.as_matrix()\n# Create color maps\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n    cmap_bold  = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n    clf = KNeighborsClassifier()\n    clf.fit(X_mat, y_mat)       \n    \n# Plot the decision boundary by assigning a color in the color map\n    # to each mesh point.\n    \n    mesh_step_size = .01  # step size in the mesh\n    plot_symbol_size = 30\n    \n    x_min, x_max = X_mat[:, 0].min() - 1, X_mat[:, 0].max() + 1\n    y_min, y_max = X_mat[:, 1].min() - 1, X_mat[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size),\n                         np.arange(y_min, y_max, mesh_step_size))\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n# Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n# Plot training points\n    plt.scatter(X_mat[:, 0], X_mat[:, 1],s=plot_symbol_size, c=y,  cmap=cmap_bold, edgecolor = 'black')\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    patch0 = mpatches.Patch(color='#FF0000', label='Iris-versicolor')\n    patch1 = mpatches.Patch(color='#00FF00', label='Iris-setosa')\n    patch2 = mpatches.Patch(color='#0000FF', label='Iris-verginica')\n    plt.legend(handles=[patch0, patch1, patch2])\n    plt.xlabel('PetalLengthCm')\n    plt.ylabel('PetalWidthCm')\n    plt.title(\"3-Class classification \")\n    plt.subplots_adjust(bottom=0.1, right=1.9, top=1.5) \n    plt.show()\n\nplot_fruit_knn(X_train, y_train, n_neighbors=9)\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86be6817927511d9b95978400c6533bd8d36689d"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}