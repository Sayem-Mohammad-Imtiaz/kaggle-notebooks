{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classifier \n\nIn this work, we're going to cover lots of things about Naive Bayes Classifier. I implement our algorithm with Scikit-Learn. "},{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction the Naive Bayes Classifier \n\nNaive Bayes Classifier uses the Bayesâ€™ theorem to predict probabilities for each class such as the probability that given record or data point belongs to a particular class. \n\nIt can be used for; \n\n* Text classification\n* Sentiment analysis\n* Spam filtering\n* Recommender systems"},{"metadata":{},"cell_type":"markdown","source":"### What is Naive? Why is it naive? \n\nIt is naive because it ignores all of the dependencies. It assumes event are independent. Features does not affect each othet. \nLet me explaing it an example. For a spam classifier, our equations would be like abowe. \n\n$$P(Spam \\, | \\, Word) = \\frac{P(Word \\, | \\, Spam) \\, P(Spam)} {P(Word)}$$ \n\nSo, for a sample sentence, \"we are good.\". It would be like abowe. \n\n$$ \\frac{P(We \\, | \\, Spam) \\, P(Spam)} {P(We)} x  \\frac{P(are \\, | \\, Spam) \\, P(Spam)} {P(are)} x \\frac{P(Good \\, | \\, Spam) \\, P(Spam)} {P(Good)}$$ "},{"metadata":{},"cell_type":"markdown","source":"# 2. Notebook Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\nimport category_encoders as ce\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Import Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/adult-dataset/adult.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = ['age', 'workclass', 'fnlwgt', 'education', 'never_married', 'marital_status', 'occupation', 'relationship',\n             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n\ndata.tail() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.income = pd.get_dummies(data.income)[' >50K']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this dataset we have numeric and categorical features. For numeric features, it's ok. There is no problem with them. But we have to analyze our categorical variables and we do some encoding for them. \n\nTo do this, let's take them."},{"metadata":{},"cell_type":"markdown","source":"## Explore Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_names = []\nfor feature in data.columns: \n    if data[feature].dtype == object: \n        categorical_names.append(feature)\ncategorical_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_names].head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_names].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_names].isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in data[categorical_names].columns:\n    print('FEATURE NAME:', feature)\n    print(data[feature].value_counts())\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see abowe there is some missing values in our seperated dataframes. But pandas' methods like isna() or isnull() couldn't detect them because of their value. It's coded as a ?. \n\nIn this case, we are going to replace them with nan values and we visualize them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in data.columns:\n    data[feature].replace(' ?', np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check this, \n\ndata[data.occupation == ' ?']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.native_country.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_names].isnull().any() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see it with a plot. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(data[categorical_names].isnull(), yticklabels=False, cbar=False, cmap='viridis')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore Numerical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = [var for var in data.columns if data[var].dtype!='O']\n\ndata[numerical_features].head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[numerical_features].isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_names].isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Impute missing categorical variables with most frequent value"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The mode of a set of values is the value that appears most often. It can be multiple values.\ndata.workclass.mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.workclass.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_colls = data.isnull().any().loc[data.isnull().any().values == True].index\nna_colls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in na_colls:\n    data[i].fillna(data[i].mode()[0], inplace=True)\n\ndata.isnull().any() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(data[categorical_names].isnull(), yticklabels=False, cbar=False, cmap='viridis')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding Categorial Variables "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[categorical_names].head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to use the method called One Hot Encoding. One hot encoding is the most widespread approach, and it works very well unless your categorical variable takes on a large number of values. \nOne hot encoding creates new (binary) columns, indicating the presence of each possible value from the original data. \n\n* In our data set, there is just one column that may be a problem for this technique. NATIVE_COUNTRY has got 41 different categories. It's not convenient for this method."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in categorical_names: \n    print(str.upper(i), data[i].value_counts().shape[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_names_withoutone = categorical_names\ncategorical_names_withoutone.remove('native_country')\nencoder = ce.OneHotEncoder(cols=categorical_names_withoutone)\n\ndata_encoded = encoder.fit_transform(data)\n\ndata_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am going to use the Mean Encoding Method. \nMean encoding represents a probability of your target variable, conditional on each value of the feature.\nLet's see this. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('native_country has got', data.native_country.value_counts().shape[0], 'features.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_encoded_nativeCont = data_encoded.groupby(['native_country'])['income'].mean().to_dict() \ndata_encoded.native_country = data_encoded.native_country.map(mean_encoded_nativeCont)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_encoded.native_country","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creation Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = data_encoded.income \nfeatures = data_encoded.drop('income', axis=1) \n\nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33)\n\ngnb = GaussianNB() \ngnb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = gnb.predict(X_test)\n\nprediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics and Evaluation\n\n## Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = (y_test == prediction).sum() \nprint('classified correctly', correct) \nwrong = X_test.shape[0] - correct \nprint('classified incorretly', wrong)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The Accuracy is', correct / X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"prediction_train = gnb.predict(X_train)\ncorrect_train = (y_train == prediction_train).sum()\nprint('classified correctly in train set', correct_train) \nwrong_train = X_train.shape[0] - correct_train\nprint('classified incorrectly in train set', wrong_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for overfitting and underfitting\n\nThe training-set accuracy score is 0.7957827 while the test-set accuracy to be  0.79311 So, there is no sign of overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The accuracy for train set is', correct_train / X_train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualising the Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# chart styling info \n\nyaxis_label = '>50K'\nxaxis_label = '<=50K'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_probabilities = gnb.predict_proba(X_test)\nprob0 = log_probabilities[:,0]\nprob1 = log_probabilities[:,1]\n\nsummary_df = pd.DataFrame({yaxis_label: prob0, xaxis_label: prob1, 'labels':y_test})\nsummary_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x=xaxis_label, y=yaxis_label, data=summary_df, height=6.5, fit_reg=False, legend=False,\n          scatter_kws={'alpha': 0.5, 's': 25}, hue='labels', markers=['o', 'x'], palette='hls')\n\n\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}