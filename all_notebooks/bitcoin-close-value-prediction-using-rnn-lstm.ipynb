{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bit coin close prediction using RNN & LSTM"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In RNN,as the gradient of the training samples gets propagated backward through our network, it gets weaker and weaker, by the time it gets to those neurons that represent older data points in our time-series it has no juice to adjust them properly. This problem is called Vanishing Gradient. A LSTM cell is a type of RNN which stores important information about the past and forgets the unimportant pieces. In this way, when gradient back-propagates, it wonâ€™t be consumed by unnecessary information.**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-09-14.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Close']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As timestamp field is of int type, we have to convert that to date type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date']=pd.to_datetime(df['Timestamp'],unit='s').dt.date\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group=df.groupby('Date')\ngroup.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=group['Close'].mean()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Taking last 50 records for test & remaining for train set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=data.iloc[:len(data)-50]\nx_test=data.iloc[len(x_train):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=np.array(x_train)\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=x_train.reshape(x_train.shape[0],1)\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler(feature_range=(0,1))\nxtrain_scaled=scaler.fit_transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(xtrain_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timestep=50\nx_train=[]\ny_train=[]\n\nfor i in range(timestep,xtrain_scaled.shape[0]):\n    x_train.append(xtrain_scaled[i-timestep:i,0])\n    y_train.append(xtrain_scaled[i,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In the above loop, we took the previous value of a set at y and nxt 50 samples at x, for training the RNN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,y_train=np.array(x_train),np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1) #reshaped for RNN\nprint(\"x_train shape= \",x_train.shape)\nprint(\"y_train shape= \",y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,SimpleRNN,Dropout,Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg=Sequential()\n\nreg.add(SimpleRNN(128,activation='relu',return_sequences=True,input_shape=(x_train.shape[1],1)))\nreg.add(Dropout(0.25))\n\nreg.add(SimpleRNN(256,return_sequences=True,activation='relu'))\nreg.add(Dropout(0.25))\n\nreg.add(SimpleRNN(512,return_sequences=True,activation='relu'))\nreg.add(Dropout(0.35))\n\nreg.add(SimpleRNN(256,return_sequences=True,activation='relu'))\nreg.add(Dropout(0.25))\n\nreg.add(SimpleRNN(128,return_sequences=True,activation='relu'))\nreg.add(Dropout(0.25))\n\nreg.add(Flatten())\n\nreg.add(Dense(1))\n\n\nreg.compile(optimizer='adam',loss='mean_squared_error')\nreg.fit(x_train,y_train,epochs=100,batch_size=64)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Processing test data for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs=data[len(data)-len(x_test)-timestep:]\ninputs=inputs.values.reshape(-1,1)\ninputs=scaler.transform(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest=[]\nfor i in range(timestep,inputs.shape[0]):\n    xtest.append(inputs[i-timestep:i,0])\nxtest=np.array(xtest)\nxtest=xtest.reshape(xtest.shape[0],xtest.shape[1],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data=reg.predict(xtest)\npredicted_data=scaler.inverse_transform(predicted_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test=np.array(x_test)\ndata_test=data_test.reshape(len(data_test),1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(data_test,color=\"r\",label=\"true result\")\nplt.plot(predicted_data,color=\"b\",label=\"predicted result\")\nplt.legend()\nplt.xlabel(\"Time(50 days)\")\nplt.ylabel(\"Close Values\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout,Flatten\n\nmodel=Sequential()\n\nmodel.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n\nmodel.add(Dense(1))\n\nmodel.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\n\nmodel.fit(x_train,y_train,epochs=100,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs=data[len(data)-len(x_test)-timestep:]\ninputs=inputs.values.reshape(-1,1)\ninputs=scaler.transform(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest=[]\nfor i in range(timestep,inputs.shape[0]):\n    xtest.append(inputs[i-timestep:i,0])\nxtest=np.array(xtest)\nxtest=xtest.reshape(xtest.shape[0],xtest.shape[1],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data=model.predict(xtest)\npredicted_data=scaler.inverse_transform(predicted_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test=np.array(x_test)\ndata_test=data_test.reshape(len(data_test),1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(data_test,color=\"r\",label=\"true result\")\nplt.plot(predicted_data,color=\"b\",label=\"predicted result\")\nplt.legend()\nplt.xlabel(\"Time(50 days)\")\nplt.ylabel(\"Close Values\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above two plots, we can able to see that the LSTM model performs well than the RNN model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}