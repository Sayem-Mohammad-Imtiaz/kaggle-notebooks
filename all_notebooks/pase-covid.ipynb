{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from types import SimpleNamespace\nfrom functools import lru_cache\nimport os\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport pandas as pd\nimport numpy as np\nimport scipy.io.wavfile\nimport scipy.fftpack\nimport scipy.linalg\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.optim as optim\nimport math","metadata":{"papermill":{"duration":2.196644,"end_time":"2021-05-10T09:33:28.351249","exception":false,"start_time":"2021-05-10T09:33:26.154605","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:38.430275Z","iopub.execute_input":"2021-05-23T18:09:38.430563Z","iopub.status.idle":"2021-05-23T18:09:40.501903Z","shell.execute_reply.started":"2021-05-23T18:09:38.430493Z","shell.execute_reply":"2021-05-23T18:09:40.501124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 95% Confidence Interval for AUC. Hanley and McNeil (1982). https://gist.github.com/doraneko94/e24643136cfb8baf03ef8a314ab9615c\ndef roc_auc_score_ci(y_true, y_score, positive=1):\n    AUC = roc_auc_score(y_true, y_score)\n    N1 = sum(y_true == positive)\n    N2 = sum(y_true != positive)\n    Q1 = AUC / (2 - AUC)\n    Q2 = 2*AUC**2 / (1 + AUC)\n    SE_AUC = math.sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n    lower = AUC - 1.96*SE_AUC\n    upper = AUC + 1.96*SE_AUC\n    if lower < 0:\n        lower = 0\n    if upper > 1:\n        upper = 1\n    return AUC, (lower, upper)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T18:35:46.538541Z","iopub.execute_input":"2021-05-23T18:35:46.538885Z","iopub.status.idle":"2021-05-23T18:35:46.545905Z","shell.execute_reply.started":"2021-05-23T18:35:46.538851Z","shell.execute_reply":"2021-05-23T18:35:46.544861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install PyTorch QRRN for the PASE encoder\n!pip3 install git+https://github.com/jarfo/pytorch-qrnn.git","metadata":{"_kg_hide-output":true,"papermill":{"duration":9.487541,"end_time":"2021-05-10T09:33:37.864107","exception":false,"start_time":"2021-05-10T09:33:28.376566","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:40.503325Z","iopub.execute_input":"2021-05-23T18:09:40.50363Z","iopub.status.idle":"2021-05-23T18:09:49.326249Z","shell.execute_reply.started":"2021-05-23T18:09:40.503597Z","shell.execute_reply":"2021-05-23T18:09:49.325274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install PASE encoder\n!rsync -qzav /kaggle/input/problem-agnostic-speech-encoder-pase/pase-master/pase-master .\n%cd pase-master\n!python3 setup.py install\n%cd -\n!rm -Rf pase-master\nimport pkg_resources\npkg_resources.get_distribution('pase').activate()\nfrom pase.models.frontend import wf_builder","metadata":{"_kg_hide-output":true,"papermill":{"duration":9.599995,"end_time":"2021-05-10T09:33:47.478433","exception":false,"start_time":"2021-05-10T09:33:37.878438","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:49.328305Z","iopub.execute_input":"2021-05-23T18:09:49.32866Z","iopub.status.idle":"2021-05-23T18:09:59.128159Z","shell.execute_reply.started":"2021-05-23T18:09:49.328622Z","shell.execute_reply":"2021-05-23T18:09:59.127304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataset with (key, wave_file, target_id) entries\ndef make_dataset(kaldi_path, class_to_id):\n    text_path = os.path.join(kaldi_path, 'text')     # labels\n    wav_path = os.path.join(kaldi_path, 'wav.scp')   # audio files\n\n    key_to_word = dict()\n    key_to_wav = dict()\n    \n    with open(wav_path, 'rt') as wav_scp:\n        for line in wav_scp:\n            key, wav = line.strip().split(' ', 1)\n            key_to_wav[key] = wav\n            key_to_word[key] = None # default\n\n    if os.path.isfile(text_path):\n        with open(text_path, 'rt') as text:\n            for line in text:\n                key, word = line.strip().split(' ', 1)\n                key_to_word[key] = word\n\n    wavs = []\n    for key, wav_command in key_to_wav.items():\n        word = key_to_word[key]\n        word_id = class_to_id[word] if word is not None else -1 # default for test\n        wav_item = [key, wav_command, word_id]\n        wavs.append(wav_item)\n\n    return wavs","metadata":{"execution":{"iopub.status.busy":"2021-05-23T18:09:59.129863Z","iopub.execute_input":"2021-05-23T18:09:59.130227Z","iopub.status.idle":"2021-05-23T18:09:59.139006Z","shell.execute_reply.started":"2021-05-23T18:09:59.130187Z","shell.execute_reply":"2021-05-23T18:09:59.138052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def wav_read(path):\n    sr, y = scipy.io.wavfile.read(path)\n    y = y/32768 # Normalize to -1..1\n    return y, sr","metadata":{"papermill":{"duration":0.023685,"end_time":"2021-05-10T09:33:47.518831","exception":false,"start_time":"2021-05-10T09:33:47.495146","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.140532Z","iopub.execute_input":"2021-05-23T18:09:59.1409Z","iopub.status.idle":"2021-05-23T18:09:59.149614Z","shell.execute_reply.started":"2021-05-23T18:09:59.140863Z","shell.execute_reply":"2021-05-23T18:09:59.14879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The PASE model use the raw (padded) signal as input \ndef param_loader(path, max_seconds):\n    y, sfr = wav_read(path)\n    y = y.astype(np.float32)\n    # if len(y) > 16000*max_seconds:\n    #    print(path, ':', len(y)/16000, 'seconds')\n    y.resize(16000*max_seconds) # Ten seconds with zero padding\n    return y","metadata":{"papermill":{"duration":0.022457,"end_time":"2021-05-10T09:33:47.557655","exception":false,"start_time":"2021-05-10T09:33:47.535198","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.150826Z","iopub.execute_input":"2021-05-23T18:09:59.151394Z","iopub.status.idle":"2021-05-23T18:09:59.159551Z","shell.execute_reply.started":"2021-05-23T18:09:59.151355Z","shell.execute_reply":"2021-05-23T18:09:59.158764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Target values and id mapping\ndef get_classes():\n    classes = ['neg', 'pos']\n    weight = None\n    class_to_id = {label: i for i, label in enumerate(classes)}\n    return classes, weight, class_to_id","metadata":{"papermill":{"duration":0.024248,"end_time":"2021-05-10T09:33:47.59839","exception":false,"start_time":"2021-05-10T09:33:47.574142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.160736Z","iopub.execute_input":"2021-05-23T18:09:59.1613Z","iopub.status.idle":"2021-05-23T18:09:59.173583Z","shell.execute_reply.started":"2021-05-23T18:09:59.16125Z","shell.execute_reply":"2021-05-23T18:09:59.172782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PyTorch Dataset\nclass Loader(data.Dataset):\n\n    def __init__(self, root, max_seconds=20):\n\n        classes, weight, class_to_id = get_classes()\n        self.root = root\n        self.wavs = make_dataset(root, class_to_id)\n        self.classes = classes\n        self.weight = weight\n        self.class_to_id = class_to_id\n        self.loader = param_loader\n        self.max_seconds = max_seconds\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (key, params, target) where target is class_index of the target class.\n        \"\"\"\n        key, path, target = self.wavs[index]\n        path = '../input/covid/wavs16k/' + path\n        params = self.loader(path, self.max_seconds)\n        return key, params, target\n\n    def __len__(self):\n        return len(self.wavs)","metadata":{"papermill":{"duration":0.027176,"end_time":"2021-05-10T09:33:47.683834","exception":false,"start_time":"2021-05-10T09:33:47.656658","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.1771Z","iopub.execute_input":"2021-05-23T18:09:59.177368Z","iopub.status.idle":"2021-05-23T18:09:59.185202Z","shell.execute_reply.started":"2021-05-23T18:09:59.177332Z","shell.execute_reply":"2021-05-23T18:09:59.184095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline model using a pre-trained [PASE+ model](https://github.com/santi-pdp/pase), LSTM, Average Poling, and Max Poling","metadata":{}},{"cell_type":"code","source":"class PASE(nn.Module):\n    def __init__(self, input_size=256, hidden_size=64, num_layers=1, seqlen=800):\n        super(PASE, self).__init__()       \n            \n        self.pase = wf_builder('/kaggle/input/problem-agnostic-speech-encoder-pase/pase-master/pase-master/cfg/frontend/PASE+.cfg')\n        self.pase.load_pretrained('/kaggle/input/problem-agnostic-speech-encoder-pase/FE_e199.ckpt', load_last=True, verbose=True)\n            \n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.seqlen = seqlen\n            \n        self.lstm = nn.LSTM(input_size, self.hidden_size, self.num_layers, batch_first=True, dropout=0.2, bidirectional=False)\n\n        # Adaptive Average Pooling (output has always the same seqlen size)\n        self.pool = nn.AdaptiveAvgPool1d(self.seqlen)\n\n        self.classifier = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(True),           \n            nn.Dropout(0.1),            \n            nn.Linear(hidden_size, 1),\n        )           \n          \n        \n    def forward(self, x):\n        \n        # PASE needs an additional dimension\n        x.unsqueeze_(1)\n        # (B,1,16000 x max_seconds)\n        \n        out = self.pase(x)\n        # out shape: (B,256,100 x max_seconds)\n\n        out = self.pool(out)\n        # out shape: (B,256,seqlen)\n\n        out = out.transpose(1,2)\n        # out shape: (B,seqlen,256)\n\n        out, _ = self.lstm(out)\n        # out shape: (B,seqlen,H)\n\n        out, _ = out.max(dim=1)\n        # out = out.mean(dim=1)\n        # out shape: (B,H)\n\n        out = self.classifier(out)\n        # out shape: (B,1)\n\n        return out.squeeze(-1)","metadata":{"id":"79opq8kbeIQ9","papermill":{"duration":0.052858,"end_time":"2021-05-10T09:33:47.768246","exception":false,"start_time":"2021-05-10T09:33:47.715388","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.186868Z","iopub.execute_input":"2021-05-23T18:09:59.187394Z","iopub.status.idle":"2021-05-23T18:09:59.198143Z","shell.execute_reply.started":"2021-05-23T18:09:59.187356Z","shell.execute_reply":"2021-05-23T18:09:59.197255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(loader, model, criterion, optimizer, epoch, cuda, log_interval, weight=None, max_norm=1, verbose=True):\n    model.train()\n    global_epoch_loss = 0\n    samples = 0\n    for batch_idx, (_, data, target) in enumerate(loader):\n        if cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target.float())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n        optimizer.step()\n        global_epoch_loss += loss.data.item() * len(target)\n        samples += len(target)\n        if verbose and (batch_idx % log_interval == 0):\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, samples, len(loader.dataset), 100*samples/len(loader.dataset), global_epoch_loss/samples))\n    return global_epoch_loss / samples","metadata":{"papermill":{"duration":0.221956,"end_time":"2021-05-10T09:33:48.446014","exception":false,"start_time":"2021-05-10T09:33:48.224058","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.199402Z","iopub.execute_input":"2021-05-23T18:09:59.199912Z","iopub.status.idle":"2021-05-23T18:09:59.211939Z","shell.execute_reply.started":"2021-05-23T18:09:59.199874Z","shell.execute_reply":"2021-05-23T18:09:59.210942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(loader, model, criterion, cuda, verbose=True, data_set='Test', save=None):\n    model.eval()\n    test_loss = 0\n    tpred = []\n    ttarget = []\n\n    if save is not None:\n        csv = open(save, 'wt')\n        print('index,prob', file=csv)\n\n    with torch.no_grad():\n        for keys, data, target in loader:\n            if cuda:\n                data, target = data.cuda(), target.cuda()\n            output = model(data)\n            pred = output.sigmoid()\n            tpred.append(pred.cpu().numpy())\n\n            if target[0] != -1:\n                loss = criterion(output, target.float()).data.item()\n                test_loss += loss * len(target) # sum up batch loss \n                ttarget.append(target.cpu().numpy())\n\n            if save is not None:\n                for i, key in enumerate(keys):\n                    print(f'{key},{pred[i]}', file=csv)\n    \n    if len(ttarget) > 0:\n        test_loss /= len(loader.dataset)\n        auc, auc_ci = roc_auc_score_ci(np.concatenate(ttarget), np.concatenate(tpred))\n        if verbose:\n            print('\\n{} set: Average loss: {:.4f}, AUC: {:.1f}% ({:.1f}% - {:.1f}%)\\n'.format(\n                data_set, test_loss, 100 * auc, auc_ci[0]*100, auc_ci[1]*100))\n\n        return test_loss, auc","metadata":{"papermill":{"duration":0.05096,"end_time":"2021-05-10T09:33:48.531064","exception":false,"start_time":"2021-05-10T09:33:48.480104","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:41:17.977263Z","iopub.execute_input":"2021-05-23T18:41:17.977595Z","iopub.status.idle":"2021-05-23T18:41:17.988348Z","shell.execute_reply.started":"2021-05-23T18:41:17.977569Z","shell.execute_reply":"2021-05-23T18:41:17.987235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = SimpleNamespace(\n    # general options\n    train_path = '../input/covid/train',         # train data folder\n    valid_path = '../input/covid/valid',         # valid data folder\n    test_path = '../input/covid/test',           # test data folder\n    batch_size = 20,                             # training and valid batch size\n    test_batch_size = 20,                        # batch size for testing\n    arch = 'PASE',                               # PASE, VGG11, VGG13, VGG16, VGG19\n    epochs = 50,                                 # maximum number of epochs to train\n    lr = 0.0001,                                 # learning rate\n    momentum = 0.9,                              # SGD momentum, for SGD only\n    optimizer = 'adam',                          # optimization method: sgd | adam\n    seed = 1234,                                 # random seed\n    log_interval = 5,                            # how many batches to wait before logging training status\n    patience = 10,                               # how many epochs of no loss improvement should we wait before stop training\n    checkpoint = '.',                            # checkpoints directory\n    train = True,                                # train before testing\n    cuda = True,                                 # use gpu\n    num_workers = 2,                             # how many subprocesses to use for data loading\n)","metadata":{"papermill":{"duration":0.043731,"end_time":"2021-05-10T09:33:48.606047","exception":false,"start_time":"2021-05-10T09:33:48.562316","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.227326Z","iopub.execute_input":"2021-05-23T18:09:59.227944Z","iopub.status.idle":"2021-05-23T18:09:59.241511Z","shell.execute_reply.started":"2021-05-23T18:09:59.227907Z","shell.execute_reply":"2021-05-23T18:09:59.240759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args.cuda = args.cuda and torch.cuda.is_available()\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)\n    print('Using CUDA with {0} GPUs'.format(torch.cuda.device_count()))\n\n\n# build model\nif args.arch == 'PASE':\n    model = PASE(256)\nif args.cuda:\n    model.cuda()\n\n# Define criterion\ncriterion = nn.BCEWithLogitsLoss(reduction='mean') # This loss combines a Sigmoid layer and the BCELoss in one single class.","metadata":{"papermill":{"duration":7.062397,"end_time":"2021-05-10T09:33:55.700344","exception":false,"start_time":"2021-05-10T09:33:48.637947","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:09:59.242834Z","iopub.execute_input":"2021-05-23T18:09:59.243497Z","iopub.status.idle":"2021-05-23T18:10:05.636041Z","shell.execute_reply.started":"2021-05-23T18:09:59.243454Z","shell.execute_reply":"2021-05-23T18:10:05.635201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model (Only new parameters)","metadata":{"papermill":{"duration":0.018517,"end_time":"2021-05-10T09:33:55.737693","exception":false,"start_time":"2021-05-10T09:33:55.719176","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# freeze PASE+ parameters\nfor param in model.pase.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-05-23T18:10:05.637212Z","iopub.execute_input":"2021-05-23T18:10:05.637552Z","iopub.status.idle":"2021-05-23T18:10:05.641785Z","shell.execute_reply.started":"2021-05-23T18:10:05.637518Z","shell.execute_reply":"2021-05-23T18:10:05.640754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading data\nif args.train:\n    train_dataset = Loader(args.train_path)\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True,\n        num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n\n    valid_dataset = Loader(args.valid_path)\n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset, batch_size=args.batch_size, shuffle=None,\n        num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n\n    # define optimizer\n    if args.optimizer.lower() == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n    else:\n        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\n    best_valid_auc = 0\n    iteration = 0\n    epoch = 1\n    best_epoch = epoch\n    \n    # trainint with early stopping\n    t0 = time.time()\n    while (epoch < args.epochs + 1) and (iteration < args.patience):\n        train(train_loader, model, criterion, optimizer, epoch, args.cuda, args.log_interval,\n            weight=train_dataset.weight)\n        valid_loss, valid_auc = test(valid_loader, model, criterion, args.cuda, data_set='Validation')\n        if not os.path.isdir(args.checkpoint):\n            os.mkdir(args.checkpoint)\n        torch.save(model.state_dict(), './{}/model{:03d}.pt'.format(args.checkpoint, epoch))\n        if valid_auc <= best_valid_auc:\n            iteration += 1\n            print('AUC was not improved, iteration {0}'.format(str(iteration)))\n        else:\n            print('Saving state')\n            iteration = 0\n            best_valid_auc = valid_auc\n            best_epoch = epoch\n            state = {\n                'valid_auc': valid_auc,\n                'valid_loss': valid_loss,\n                'epoch': epoch,\n            }\n            if not os.path.isdir(args.checkpoint):\n                os.mkdir(args.checkpoint)\n            torch.save(state, './{}/ckpt.pt'.format(args.checkpoint))\n        epoch += 1\n        print(f'Elapsed seconds: ({time.time() - t0:.0f}s)')\n    print(f'Best AUC: {best_valid_auc*100:.1f}% on epoch {best_epoch}')","metadata":{"papermill":{"duration":66.366088,"end_time":"2021-05-10T09:35:02.122951","exception":false,"start_time":"2021-05-10T09:33:55.756863","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:46:08.865615Z","iopub.execute_input":"2021-05-23T18:46:08.866065Z","iopub.status.idle":"2021-05-23T18:47:07.426869Z","shell.execute_reply.started":"2021-05-23T18:46:08.865982Z","shell.execute_reply":"2021-05-23T18:47:07.42456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Best AUC: {best_valid_auc*100:.1f}% on epoch {best_epoch}')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T18:47:41.452775Z","iopub.execute_input":"2021-05-23T18:47:41.453111Z","iopub.status.idle":"2021-05-23T18:47:41.457258Z","shell.execute_reply.started":"2021-05-23T18:47:41.453079Z","shell.execute_reply":"2021-05-23T18:47:41.456336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Model","metadata":{"papermill":{"duration":0.238677,"end_time":"2021-05-10T09:49:47.513041","exception":false,"start_time":"2021-05-10T09:49:47.274364","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_dataset = Loader(args.test_path)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=args.test_batch_size, shuffle=None,\n    num_workers=args.num_workers, pin_memory=args.cuda, sampler=None)\n\n# get best epoch and model\nstate = torch.load('./{}/ckpt.pt'.format(args.checkpoint))\nepoch = state['epoch']\nprint(\"Testing model (epoch {})\".format(epoch))\nmodel.load_state_dict(torch.load('./{}/model{:03d}.pt'.format(args.checkpoint, epoch)))\nif args.cuda:\n    model.cuda()\n\nresults = 'submission.csv'\nprint(\"Saving results in {}\".format(results))\ntest(test_loader, model, criterion, args.cuda, save=results)","metadata":{"papermill":{"duration":8.730673,"end_time":"2021-05-10T09:49:56.469183","exception":false,"start_time":"2021-05-10T09:49:47.73851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-23T18:33:42.376125Z","iopub.status.idle":"2021-05-23T18:33:42.376485Z"},"trusted":true},"execution_count":null,"outputs":[]}]}