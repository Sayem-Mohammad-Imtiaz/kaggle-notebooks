{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3663d953-2bf7-149f-aa97-922b92d02588"},"source":"<strong>DS11: Analyze ann raking the cities</strong><br/>i goal is to rank all cities according issues like health, crime in city, quality live and other."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e599ef60-16f6-b228-ee83-07235bfa69a8"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # to basic visualization \nimport seaborn as sns # to statictics visualization\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"189d54cb-e352-5d21-e78c-33cda55e0fb9"},"source":"<h1>Cleaning and analyze the data</h1>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf8110e9-112c-d680-0db8-0918724c54b1"},"outputs":[],"source":"#load datasets\ncities_data = pd.read_csv(\"../input/cities.csv\")\ncost_life_data = pd.read_csv(\"../input/movehubcostofliving.csv\")\nquality_life_data = pd.read_csv(\"../input/movehubqualityoflife.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad6e9380-4ea6-6941-a286-b3584731d64e"},"outputs":[],"source":"#show sample of datasets\ncost_life_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11e2c091-3e73-ce40-ec1a-c4d1a486c18d"},"outputs":[],"source":"#show sample of datasets\nquality_life_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4e1dbf7-0599-05a2-0cb5-c27949211a9b"},"outputs":[],"source":"#show sample of data\ncities_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc3ba638-c9a4-1e47-b6bc-1d8508fd1c3f"},"outputs":[],"source":"#analyze if preliminary missing data in datasets\nprint(\"analyze of 'the cities' dataset: \\n\",cities_data.isnull().sum() )\nprint( \"analyze of 'the cost of life' dataset: \\n\",cost_life_data.isnull().sum() )\nprint(\"analyze of 'the quality of life' dataset: \\n\",quality_life_data.isnull().sum() )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47c40b91-e85d-2041-e00e-80816452db0e"},"outputs":[],"source":"#show the dimension of datasets\nprint(\"dimension of row-columns of 'cities' data set:\", cities_data.shape )\nprint(\"dimension of row-columns of 'cost of life' data set:\", cost_life_data.shape )\nprint(\"dimension of row-columns of 'quality of life' data set:\", quality_life_data.shape )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff7ff990-88a2-3390-0f57-248e54fddd3c"},"outputs":[],"source":"#see the row with missing data and fit the missing data in cities data set\nmissing_data = cities_data[ cities_data.isnull().any( axis = 1 ) ]\nfit_missing_data = {'Sevastopol':'Rusia' , 'Simferopol':'Rusia' , 'Pri≈°tina':'Kosovo' }\nfor  first,second in fit_missing_data.items() :\n    cities_data.ix[ cities_data.City == first, 'Country'] = second\ncities_data.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af5b9773-9237-361d-8a6e-45485b4416b3"},"outputs":[],"source":"#integrate/merge datasets to the unique dataset and cleaning row with missing data\ndata_proof = pd.merge( cost_life_data , quality_life_data, how = 'right', on = \"City\" )\ndata_proof['City'] = data_proof['City'].str.lower()\ncities_data['City'] = cities_data['City'].str.lower()\n#convert series to list to join with data_proof by selected cities without missing data\ncities_selected = cities_data[ cities_data['City'].isin( data_proof['City'] ) ]\ndata_proof = pd.merge(  data_proof , cities_selected , how = 'right', on = 'City' )\n#show if dataset have missing value in any columns\ndata_proof.head()\nprint( data_proof.isnull().sum(),'\\n',data_proof.shape )\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8430341a-5816-6415-d547-4ae60a739f3d"},"outputs":[],"source":"#get the number of country and sort it\ncountry = data_proof.groupby([\"Country\"]).size().sort_values(ascending =  False).to_frame()\ncountry.columns = [\"Size\"]\ncountry"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd8fa180-e4ae-6556-18f6-09d1b00febb5"},"source":"i can see that there are most country with 1 size than other country"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}