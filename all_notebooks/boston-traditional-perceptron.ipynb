{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Configuration\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"boston = pd.read_csv('../input/boston-housing-dataset/HousingData.csv')\nboston","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.keys()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Set Characteristics:**  \n\n:Number of Instances: 506 \n\n:Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n:Attribute Information (in order)\n    - CRIM     per capita crime rate by town\n    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n    - INDUS    proportion of non-retail business acres per town\n    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n    - NOX      nitric oxides concentration (parts per 10 million)\n    - RM       average number of rooms per dwelling\n    - AGE      proportion of owner-occupied units built prior to 1940\n    - DIS      weighted distances to five Boston employment centres\n    - RAD      index of accessibility to radial highways\n    - TAX      full-value property-tax rate per \\$10,000\n    - PTRATIO  pupil-teacher ratio by town\n    - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n    - LSTAT    \\% lower status of the population\n    - MEDV     Median value of owner-occupied homes in $1000's","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 20 null values in each [CRIM, ZN, INDUS, CHAS, AGE, LSTAT] columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"boston[boston.CRIM.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston[boston.ZN.isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And all null values are not located in same rows.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Comparing Crim Rate with Average Number of Rooms per Town","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nboston_CRIM = boston.CRIM\nboston_RM = boston.RM\n\nplt.scatter(boston_RM, boston_CRIM, marker = 'o')\nplt.scatter(boston_RM.mean(), boston_CRIM.mean(), marker = '^')\nplt.scatter(np.median(boston_RM), np.median(boston_CRIM), marker = 'v')\n\nplt.title('Boston Crime-Rooms comparison Plot')\nplt.ylabel('Crime Rate')\nplt.xlabel('No. of Rooms')\nplt.legend(['CR_relation','mean','median'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Theory I wanted to find in this plot\n- When the average number of Rooms goes up, the Crime rate goes down (downward direction graph)\n\nPhenomena I found in this plot\n- There are some weird values which has extreamly high rate of crime. Except those values, the graph shows almost normal distribution and the mean and median values are located at center of the graph.\n- But still, the relation between average room numbers and crime rate is uncertain.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Comparing Distances to Centeres with Pupil-Teacher Ratio per Town","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"boston_DIS = boston.DIS\nboston_PTR = boston.PTRATIO\n\nplt.scatter(boston_DIS, boston_PTR, marker = 'o', color = 'orange')\nplt.scatter(boston_DIS.mean(), boston_PTR.mean(), marker = '^', color = 'black')\nplt.scatter(np.median(boston_DIS), np.median(boston_PTR), marker = 'v', color = 'blue')\n\nplt.title('Boston Distances to Centers - PTRATIO Comparison Plot')\nplt.ylabel('Pupil-Teacher Ratio')\nplt.xlabel('Distances to Centeres')\nplt.legend(['DPT_relation', 'mean', 'median'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Theory I wanted to find in this plot\n- When the Distances to centeres goes up, the pupil-teacher ratio goes up (Upward direction graph)\n\nPhenomena I found in this plot\n- All the values are scattered. Weak relations between Urbanism of area and Interest of Education of schools.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing & Data Cleansing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Box Plot of the values\n\nsee how the values are distributed and how's the outline.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = boston.drop(columns = 'MEDV')\nY = boston.MEDV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# you could not make boxplot with dataframe. so, make it as numpy array.\n\nX_np = X.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(X_np)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1~4 and 7, 13th features are vacant in the graph because of the null values.\\\nLet's fill the NA.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Fill the NA\n\nusing dataframe.fillna","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_mean = X.fillna(X.mean())\nX_mean.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_mean = X_mean.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(X_mean)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you can see those distributions of all columns.\\\nBut there are a huge gap in values between each columns.\\\nSo we need to scale the values!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## scaling the values\n\nfor make the values able to compare\\\nalso for the machine learning model albe to learn balanced.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_scaler = scaler.fit_transform(X_mean)\n\nplt.boxplot(X_scaler)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[1st : CRIM,2nd : ZN,4th : CHAS,6th : RM,8th : DIS,11th : PTRATIO,12th : B,13th : LSTAT] columns have odds values.\\\nSo we need to make the values being in the extreme.\\\nIf the values are over the max value, make the values in the uppter extreme.\\\nAnd if the values are under the lower extreme, make the values in the lower extreme.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![img](https://d2mvzyuse3lwjc.cloudfront.net/doc/en/UserGuide/images/Customizing_the_Box_Chart_Box_Tab_Controls/Customizing_the_Box_Chart_Box_Tab_Controls_4.png?v=2729)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaler.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing outlier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pd = pd.DataFrame(X_scaler, columns = X.columns)\nX_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(X_scaler)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"X_pd[X_pd.CRIM > np.percentile(X_pd.CRIM,25)] = np.percentile(X_pd.CRIM,25)\nX_pd[X_pd.CRIM < np.percentile(X_pd.CRIM,75)] = np.percentile(X_pd.CRIM,75)\nX_pd2 = X_pd.to_numpy\n\nplt.boxplot(X_pd2)\nplt.show()\n# np.percentile(X_pd.CRIM, 25), np.percentile(X_pd.CRIM, 75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = boston.drop(columns=['MEDV'])\nY = boston['MEDV']\n\nfrom sklearn.model_selection import train_test_split\n\nx_train_all, x_test, y_train_all, y_test = train_test_split(X,Y,test_size = 0.2)\nx_train, x_val, y_train, y_val = train_test_split(x_train_all,y_train_all,test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Traditional - Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\nlr.fit(x_train, y_train)\nlr.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\npred_lr = lr.predict(x_test)\nmetrics.r2_score(y_test, pred_lr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Linear Model - ElasticNet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nen_9 = ElasticNet(alpha=0.9)\nen_9.fit(x_train, y_train)\nen_9.score(x_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Perceptron","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nregular = 0.1 # regularization amount\n\nmetrics_nm = ['accuracy','mean_squared_error']\n\nmodel = tf.keras.Sequential()\nmodel.add(layers.Input(shape=x_train.shape[1]))\nmodel.add(layers.Dense(32, activation='relu',\n         kernel_regularizer = tf.keras.regularizers.l2(regular),  # Dense Regularization\n         activity_regularizer = tf.keras.regularizers.l2(regular)))  # Dense Regularization\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(1))\n\nmodel.compile(optimizer='SGD', loss='mse', metrics=metrics_nm)\n\nhist = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Veryfying by graph with weights & bias**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nweights, biases = model.layers[1].get_weights()\nprint(weights.shape, biases.shape)\n\nplt.subplot(212)\nplt.plot(weights,'x')\nplt.plot(biases, 'o')\nplt.title('L2 - 0.1')\n\nplt.subplot(221)\nplt.plot(hist.history['accuracy'],'^--',label='accuracy')\nplt.plot(hist.history['val_accuracy'],'^--', label='v_accuracy')\nplt.legend()\nplt.title('L2 - 0.1')\n\nplt.subplot(222)\nplt.plot(hist.history['loss'],'x--',label='loss')\nplt.plot(hist.history['val_loss'],'x--', label='val_loss')\nplt.legend()\nplt.title('L2 - 0.1')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model Fitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs=100, batch_size=16, validation_split=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before predict test data, need to scale","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = standardScaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(x_test, y_test, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Results **","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn import metrics\n\nmetrics.r2_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}