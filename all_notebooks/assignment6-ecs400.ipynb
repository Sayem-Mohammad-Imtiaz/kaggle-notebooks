{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#Name: SUMAN SHAW\n#SRN: 01FB16ECS400\n#Assignment-6 Data Analytics\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#importing the csv file\nimport os\nprint(os.listdir(\"../input\")) #the csv file for absenteeism at work is present in the input directory\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#viewing the dataset\ndata_file = \"../input/Absenteeism_at_work.csv\"\ndf= pd.read_csv(data_file)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a63fe1ec20e20a34b37f674e3e7304d3f3a7e000"},"cell_type":"code","source":"#removing the outliers\nsns.boxplot(df['Absenteeism time in hours'])\nmedian = np.median(df['Absenteeism time in hours'])\nq75, q25 = np.percentile(df['Absenteeism time in hours'], [75 ,25])\niqr = q75 - q25\nprint(\"Lower outlier bound:\",q25 - (1.5*iqr))\nprint(\"Upper outlier bound:\",q75 + (1.5*iqr))\n#setting the lower and upper bounds for outliers\ndf= df[df['Absenteeism time in hours']<=17]\ndf= df[df['Absenteeism time in hours']>=-7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef6ad8a80349108b28bc90b7cb84871c3a581bba"},"cell_type":"code","source":"#Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\ny=df['Absenteeism time in hours']\nX=df.drop('Absenteeism time in hours',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad2d1e5c1f76919d16f3b5e6deec1aae3a7ff533"},"cell_type":"code","source":"#scaling the data\nfrom sklearn import preprocessing\nX_scaled_train = preprocessing.scale(X_train)\nX_scaled_test = preprocessing.scale(X_test)\nX_scaled_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cb12459855175aa680cfb4ed8603f13b2a31026"},"cell_type":"code","source":"#Support Vector Machine (SVM)\nimport pandas as pd\nfrom sklearn.svm import SVC\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.metrics import classification_report, confusion_matrix\ndf = pd.read_csv(\"../input/Absenteeism_at_work.csv\")\nX = df.iloc[:, :-1].values  #labels and attributes separated here\ny = df.iloc[:, 14].values\nfrom sklearn.model_selection import train_test_split  #splitting the dataset for SVM\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n\n#Scaling the data\nfrom sklearn.preprocessing import StandardScaler  \nscaler = StandardScaler()  \nscaler.fit(X_train)\nX_train = scaler.transform(X_train)  \nX_test = scaler.transform(X_test) \nsvclassifier = SVC(kernel='sigmoid')  \nsvclassifier.fit(X_train, y_train) \ny_pred = svclassifier.predict(X_test)  \n\nfrom sklearn import metrics\nprint(\"Accuracy of SVM Model:\",metrics.accuracy_score(y_test, y_pred)*100, \"\\n\\n\")\nfrom sklearn.metrics import classification_report, confusion_matrix \nprint(\"Confusion matrix:\\n\")\nprint(confusion_matrix(y_test, y_pred),\"\\n\\nComputing the performance measures:\")  \nprint(classification_report(y_test, y_pred)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e73242b3715fdaa558be1502abea8707ab4ff65"},"cell_type":"code","source":"#Decision Tree Classifier\nimport matplotlib.pyplot as plt  \n%matplotlib inline\n\ndataset = pd.read_csv(\"../input/Absenteeism_at_work.csv\")  \n\nX = dataset.drop('Absenteeism time in hours', axis=1)  \ny = dataset['Absenteeism time in hours']  \n\n#splitting for decision tree\nfrom sklearn.model_selection import train_test_split  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)  \n\nfrom sklearn.tree import DecisionTreeClassifier  \nclassifier = DecisionTreeClassifier()  \nclassifier.fit(X_train, y_train)  \ny_pred = classifier.predict(X_test)  \n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score \nprint(\"Accuracy for Decision Tree:\")\nprint(accuracy_score(y_test, y_pred)*100)\nprint(\"\\nConfusion Matrix:\\n\")\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\n\")\nprint(\"Computing the Performance measures: \\n\")\nprint(classification_report(y_test, y_pred))  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e23ae15d1896fb341211e3a77e0e47ddd4a8d9e2"},"cell_type":"code","source":"\"\"\"\"OBSERVATIONS: 1.According to the results,both SVM and Decision trees are quite close in terms of accuracy,with SVM being the slightly more accurate counterpart with 45.045% accuracy and decision tree having 43.243% accuracy,but as we know, accuracy is not the best measure for assessing classification models, so we cannot conclude anything on the basis of accuracy alone. 2.The overall precision of decision tree classifier is more than that of SVM with 0.44 and 0.34 respectively. Precision tells about the exactness of the model, which is more in the case of Decision trees.3.Also the F1-score and support values for Decision tree is higher than that of SVM.CONCLUSION:From this analysis, we can conclude that Decision Tree Classifier is a better fit for this data.\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"634e68bca6e6604dbd33e9b07e7ad308da534c33"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}