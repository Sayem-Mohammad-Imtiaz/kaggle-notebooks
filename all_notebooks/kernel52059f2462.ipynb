{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport string\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nimport re\nfrom nltk.stem import PorterStemmer\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv')\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Category']= data['Category'].map(lambda x:x.lower())\ndata = data.replace({'Category':{'ham':1, 'spam':0}})\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Unique classes : \\n', data['Category'].unique())\nprint('Classes ratio : \\n', data['Category'].value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message_length'] = data['Message'].apply(len)\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message_length'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11,5)})\nsns.distplot(data['Message_length'] ,hist=True, bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_zero = data[data['Category'] ==0 ]\ndata_one = data[data['Category'] ==1 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data_zero['Message_length'] ,hist=False, bins=100)\nsns.distplot(data_one['Message_length'] ,hist=False, bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def punctuationremoval(dataset):\n    clean_list = [char for char in dataset if char not in string.punctuation]\n    clean_data = ''.join(clean_list)\n    return clean_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message'] = data['Message'].apply(punctuationremoval)\ndata['Message'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = stopwords.words('english')\nprint(stop_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stopword_removal(dataset):\n    tokenization = word_tokenize(dataset)\n    clean_data = [word.lower() for word in tokenization if word not in stop_words]\n    return clean_data\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message'] = data['Message'].apply(stopword_removal)\ndata['Message'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def number_removal(dataset):\n    clean_list = []\n    for i in dataset:\n        if not re.search('\\d',i):\n            clean_list.append(i)\n    clean_data = ' '.join(clean_list) \n    return clean_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message'] = data['Message'].apply(number_removal)\ndata['Message'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"porter = PorterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message'] = data['Message'].apply(lambda x:x.split())\ndata['Message'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stem_update(dataset):\n    stem_list = []\n    for word in dataset:\n        word = porter.stem(word)\n        stem_list.append(word)\n    stem_data = ' '.join(stem_list)\n    return stem_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Message'] = data['Message'].apply(stem_update)\ndata['Message'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nbow_data = CountVectorizer().fit(data['Message'])\nprint(len(bow_data.vocabulary_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_20 = data['Message'][20]\nprint(message_20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_20 = bow_data.transform([message_20])\nprint(message_20)\nprint(message_20.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(bow_data.get_feature_names()[5139])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_bow = bow_data.transform(data['Message'])\nprint(message_bow.shape[1])\nprint(message_bow.nnz)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sparisty = ( 100*message_bow.nnz / (message_bow.shape[0]*message_bow.shape[1]))\nprint(sparisty)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transform = TfidfTransformer().fit(message_bow)\ntfidf_trans = tfidf_transform.transform(message_bow)\nprint(tfidf_trans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators =10, criterion = 'entropy', random_state = 0)\nclassifier.fit(tfidf_trans,data['Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classifier.predict(message_bow)[2])\nprint(data.Category[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_predictions = classifier.predict(message_bow)\nprint(all_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(data['Category'],all_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics \nprint(metrics.accuracy_score(data['Category'],all_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_message, test_message, train_label, test_label = train_test_split(data['Message'], data['Category'], test_size=0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\npipeline = Pipeline([\n    ('bow', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('classifier',RandomForestClassifier()),]\n    \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.fit(train_message, train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = pipeline.predict(test_message)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\ncm = confusion_matrix(test_label,prediction)\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"BuPu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(prediction,test_label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(prediction,test_label))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}