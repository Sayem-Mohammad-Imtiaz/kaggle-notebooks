{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Today I'll work on classifying genders by their voice using classical ML and some data analysis and visualizations"},{"metadata":{},"cell_type":"markdown","source":"### Importing libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import datasets\nfrom sklearn.naive_bayes import GaussianNB\n#model selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\n#preprocess.\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder,OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train= pd.read_csv('/kaggle/input/voicegender/voice.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### from data description we know that :\n\nmeanfreq: mean frequency (in kHz)\n\nsd: standard deviation of frequency\n\nmedian: median frequency (in kHz)\n\nQ25: first quantile (in kHz)\n\nQ75: third quantile (in kHz)\n\nIQR: interquantile range (in kHz)\n\nskew: skewness (see note in specprop description)\n\nkurt: kurtosis (see note in specprop description)\n\nsp.ent: spectral entropy\n\nsfm: spectral flatness\n\nmode: mode frequency\n\ncentroid: frequency centroid (see specprop)\n\npeakf: peak frequency (frequency with highest energy)\n\nmeanfun: average of fundamental frequency measured across acoustic signal\n\nminfun: minimum fundamental frequency measured across acoustic signal\n\nmaxfun: maximum fundamental frequency measured across acoustic signal\n\nmeandom: average of dominant frequency measured across acoustic signal\n\nmindom: minimum of dominant frequency measured across acoustic signal\n\nmaxdom: maximum of dominant frequency measured across acoustic signal\n\ndfrange: range of dominant frequency measured across acoustic signal\n\nmodindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range\n\nlabel: male or female"},{"metadata":{},"cell_type":"markdown","source":"### let's check missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### no missing values"},{"metadata":{},"cell_type":"markdown","source":"### performing EDA with plots."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### let's check if we have outliers in our data by calculating the 1.5 IQR range"},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_outliers(col):\n    q1,q3=df[col].quantile([0.25,0.75])\n    iqr=q3-q1\n    rang=1.5*iqr\n    return(q1-rang,q3+rang)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Univariate analysis"},{"metadata":{},"cell_type":"markdown","source":"### since all features are numeric, I'll use histogram and box plot "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(col):\n    fig,axes=plt.subplots(1,2)\n    sns.boxplot(data=df,x=col,ax=axes[0])\n    sns.distplot(a=df[col],ax=axes[1],color='#ff4125')\n    fig.set_size_inches(15,5)\n    lower,upper = check_outliers(col)\n    l=[df[col] for i in df[col] if i>lower and i<upper] \n    print(\"Number of data points remaining if outliers removed : \",len(l))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('meanfreq')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. from box plot: we have some outliers according to 1.5 IQR rule\n2. from distplot: the distribution is not perfect;y normal, we have very little -ve skewness >> we can normalize that.\n3. more outliers are on the left of the distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('sd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('median')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('Q25')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('Q75')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('skew')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('kurt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('sp.ent')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('sfm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot('meanfun')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=df,x='label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### luckily our data is balanced \"equal number of classes\""},{"metadata":{},"cell_type":"markdown","source":"##  Bivariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"1. Correlation between data features"},{"metadata":{},"cell_type":"markdown","source":"### make class labels 0,1 instead of male, female"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label']=df['label'].replace({'male':1,'female':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation heatmap \ncor_mat= df[:].corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(30,12)\nsns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. IQR is the most correlated feature with the target label\n2. median and centroid () , mean freq and centroid >> delete centroid\n3. other obseravtions, there are weak correlations and high ones, i'll delete some columns in feature engineering."},{"metadata":{},"cell_type":"markdown","source":"### plot features against target label to compare distributions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_against_target(feature):\n    sns.factorplot(data=df,y=feature,x='label',kind='box')\n    fig=plt.gcf()\n    fig.set_size_inches(7,7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('meanfreq')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### females have higher mean frequency than males."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('sd')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('median')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('Q25')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('IQR')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we know the strong relation between the target label and IQR and this is "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('sp.ent')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_against_target('meanfun')  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### let's plot a pairplot grid with scatter plots to compare features"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.PairGrid(df[['meanfreq','sd','median','Q25','IQR','sp.ent','sfm','meanfun','label']], hue = \"label\")\ng = g.map(plt.scatter).add_legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'll comment on this section in the feature engineering"},{"metadata":{},"cell_type":"markdown","source":"### let's remove the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    l,u=check_outliers(col)\n    df=df[(df[col]>l)&(df[col]<u)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### so the number of observations reduced when we deleted the outliers."},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering, My fav part. ^^"},{"metadata":{},"cell_type":"markdown","source":"so according to previous plots, we'll delete \"skew,kurt,mindom,maxdom,centroid\""},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df=df.copy()\ntemp_df.drop(['skew','kurt','mindom','maxdom','centroid'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### creating new features"},{"metadata":{"trusted":true},"cell_type":"code","source":"## skewness with pearson coefficient\ntemp_df['pear_skew']=temp_df['meanfreq']-temp_df['mode']\ntemp_df['pear_skew']=temp_df['pear_skew']/temp_df['sd']\ntemp_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=temp_df,y='pear_skew',x='label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"change median column to be 1/3(2mean+mode)"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df['meanfreq']=temp_df['meanfreq'].apply(lambda x:x*2)\ntemp_df['median']=temp_df['meanfreq']+temp_df['mode']\ntemp_df['median']=temp_df['median'].apply(lambda x:x/3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=temp_df,y='median',x='label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\nscaled_df=scaler.fit_transform(temp_df.drop('label',axis=1))\nX=scaled_df\nY=df['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ML"},{"metadata":{},"cell_type":"markdown","source":"### logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lr=LogisticRegression()\nclf_lr.fit(x_train,y_train)\npred=clf_lr.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn=KNeighborsClassifier()\nclf_knn.fit(x_train,y_train)\npred=clf_knn.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_svm=SVC()\nclf_svm.fit(x_train,y_train)\npred=clf_svm.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DECISION TREE classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_dt=DecisionTreeClassifier()\nclf_dt.fit(x_train,y_train)\npred=clf_dt.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### random forest classifer"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf=RandomForestClassifier()\nclf_rf.fit(x_train,y_train)\npred=clf_rf.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### gradient boosting "},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_gb=GradientBoostingClassifier()\nclf_gb.fit(x_train,y_train)\npred=clf_gb.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## compare the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[LogisticRegression(),LinearSVC(),SVC(kernel='rbf'),KNeighborsClassifier(),RandomForestClassifier(),\n        DecisionTreeClassifier(),GradientBoostingClassifier(),GaussianNB()]\nmodel_names=['LogisticRegression','LinearSVM','rbfSVM','KNearestNeighbors','RandomForestClassifier','DecisionTree',\n             'GradientBoostingClassifier','GaussianNB']\n\nacc=[]\nd={}\n\nfor model in range(len(models)):\n    clf=models[model]\n    clf.fit(x_train,y_train)\n    pred=clf.predict(x_test)\n    acc.append(accuracy_score(pred,y_test))\n     \nd={'Modelling Algo':model_names,'Accuracy':acc}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=pd.DataFrame(d)\nacc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(y='Modelling Algo',x='Accuracy',data=acc);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tuning SVM with grid search cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"params_dict={'C':[0.001,0.01,0.1,1,10,100],'gamma':[0.001,0.01,0.1,1,10,100],'kernel':['linear','rbf']}\nclf=GridSearchCV(estimator=SVC(),param_grid=params_dict,scoring='accuracy',cv=10)\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### show best parameter values to train on"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best score\nclf.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train on these paramaters\nclf_svm=SVC(C=100,gamma=0.01,kernel='rbf')\nclf_svm.fit(x_train,y_train)\npred=clf_svm.predict(x_test)\nprint(accuracy_score(pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(clf_svm.predict(x_test),y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(precision_score(clf_svm.predict(x_test),y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## There's not a remarkable difference between the original and tuned model, but it's a good practice."},{"metadata":{},"cell_type":"markdown","source":"## to me this notebook is about visuals more than modelling, but I had fun doing it with classic ML and it gave good results without the need for ANNs."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}