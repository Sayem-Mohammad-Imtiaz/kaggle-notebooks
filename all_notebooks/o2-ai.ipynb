{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install lifetimes --upgrade\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# visualization\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# sns.set_style('whitegrid')\ncolor = sns.color_palette()\n\n\n%matplotlib inline\n\n\nimport lifetimes\n\n#Let's make this notebook reproducible \nnp.random.seed(42)\n\nimport random\nrandom.seed(42)\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading ecommerce data\ndata_file = '../input/customer_segmentation/customer_segmentation.csv'\necommerce_data =pd.read_csv(data_file , engine=\"python\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change the column names\n\necommerce_data.rename(index=str, columns={'InvoiceNo': 'invoice_num',\n                              'StockCode' : 'stock_code',\n                              'Description' : 'description',\n                              'Quantity' : 'quantity',\n                              'InvoiceDate' : 'invoice_date',\n                              'UnitPrice' : 'unit_price',\n                              'CustomerID' : 'cust_id',\n                              'Country' : 'country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Cleaning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check missing values for each column\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values for each column \necommerce_data.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out the rows with missing values\necommerce_data[ecommerce_data.isnull().any(axis=1)].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change the invoice_date format - String to Timestamp format\necommerce_data['invoice_date'] = pd.to_datetime(ecommerce_data.invoice_date, format='%m/%d/%Y %H:%M')\necommerce_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove rows with missing values\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ecommerce_new without missing values\necommerce_new = ecommerce_data.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing values for each column \necommerce_new.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Formate data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# change columns type - String to Int type \necommerce_new['cust_id'] = ecommerce_new['cust_id'].astype('int64')\necommerce_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Remove Quantity with negative values\necommerce_new = ecommerce_new[ecommerce_new.quantity > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_new.describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add the column - amount_spent\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# amount_spent = quantity ** unit_price\necommerce_new['amount_spent'] = ecommerce_new['quantity'] * ecommerce_new['unit_price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rearrange all the columns for easy reference\necommerce_new = ecommerce_new[['invoice_num','invoice_date','stock_code','description','quantity','unit_price','amount_spent','cust_id','country']]\necommerce_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_new.insert(loc=2, column='year_month', value=ecommerce_new['invoice_date'].map(lambda x: 100*x.year + x.month))\necommerce_new.insert(loc=3, column='month', value=ecommerce_new.invoice_date.dt.month)\n# +1 to make Monday=1.....until Sunday=7\necommerce_new.insert(loc=4, column='day', value=(ecommerce_new.invoice_date.dt.dayofweek)+1)\necommerce_new.insert(loc=5, column='hour', value=ecommerce_new.invoice_date.dt.hour)\necommerce_new.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"elog = ecommerce_new[['cust_id','invoice_date']]\ndisplay(elog.sample(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### >  Date range of orders"},{"metadata":{"trusted":true},"cell_type":"code","source":"elog.invoice_date.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ecommerce_new.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating RFM Matrix based on transaction log\n### Spliting calibration and holdout period"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom lifetimes.utils import calibration_and_holdout_data\n\ncalibration_period_ends = '2011-9-09 12:50:00'\n\n\nsummary_cal_holdout = calibration_and_holdout_data(elog, \n                                                   customer_id_col = 'cust_id', \n                                                   datetime_col = 'invoice_date', \n                                                   freq = 'D', #days\n                                        calibration_period_end=calibration_period_ends,\n                                        observation_period_end='2011-12-09 12:50:00' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature set\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (summary_cal_holdout.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training model - MBG/NBD\nModel assumptions:\n\n* While active, the number of transactions made by a customer follows a Poisson process with transaction rate  λ .\n* Heterogeneity in  λ  across customers follows a Gamma distribution with shape parameter  r  and scale parameter  α .\n* At time zero and right after each purchase the customer becomes inactive with a constant probability  p .\n* Heterogeneity in  p  across customers follows a Gamma distribution with parameter  a  and  b .\n* The transaction rate  λ  and the dropout probability  p  vary independently across customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\nfrom lifetimes import ModifiedBetaGeoFitter\n\nmbgnbd = ModifiedBetaGeoFitter(penalizer_coef=0.01)\nmbgnbd.fit(summary_cal_holdout['frequency_cal'], \n        summary_cal_holdout['recency_cal'], \n        summary_cal_holdout['T_cal'],\n       verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mbgnbd)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Estimating customer lifetime value using the Gamma-Gamma model\nThe Gamma-Gamma model and the independence assumption:\n\nModel assumes that there is no relationship between the monetary value and the purchase frequency. In practice we need to check whether the Pearson correlation between the two vectors is close to 0 in order to use this model."},{"metadata":{},"cell_type":"markdown","source":"## Predictions for each customer\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 90 # days to predict in the future \nsummary_cal_holdout['predicted_purchases'] = mbgnbd.conditional_expected_number_of_purchases_up_to_time(t, \n                                                                                      summary_cal_holdout['frequency_cal'], \n                                                                                      summary_cal_holdout['recency_cal'], \n                                                                                      summary_cal_holdout['T_cal'])\n\nsummary_cal_holdout['p_alive'] = mbgnbd.conditional_probability_alive(summary_cal_holdout['frequency_cal'], \n                                                                         summary_cal_holdout['recency_cal'], \n                                                                         summary_cal_holdout['T_cal'])\nsummary_cal_holdout['p_alive'] = np.round(summary_cal_holdout['p_alive'] / summary_cal_holdout['p_alive'].max(), 2)\n\n#summary_cal_holdout['clv'] = gg.customer_lifetime_value(\n#    mbgnbd, #the model to use to predict the number of future transactions\n#    summary_cal_holdout['frequency_cal'],\n#    summary_cal_holdout['recency_cal'],\n#    summary_cal_holdout['T_cal'],\n#    summary_cal_holdout['monetary_value_cal'],\n#    time=3, # months\n#    discount_rate=0 #0.0025 # = 0.03/12 monthly discount rate ~ 3% annually\n#)\n#summary_cal_holdout['clv'] += (-1*summary_c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(summary_cal_holdout.sample(2).T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model evaluation\nAccessing model fit"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\nfrom lifetimes.plotting import plot_period_transactions\nax = plot_period_transactions(mbgnbd, max_frequency=7)\nax.set_yscale('log')\nsns.despine();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\nfrom lifetimes.plotting import plot_calibration_purchases_vs_holdout_purchases\n\nplot_calibration_purchases_vs_holdout_purchases(mbgnbd, summary_cal_holdout)\nsns.despine();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Customer Probability History\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lifetimes.plotting import plot_history_alive\nfrom datetime import date\nfrom pylab import figure, text, scatter, show\n\nindividual = summary_cal_holdout.iloc[400]\n\nid = individual.name\nt = 365*50\n\ntoday = date.today()\ntwo_year_ago = today.replace(year=today.year - 2)\none_year_from_now = today.replace(year=today.year + 1)\n\nsp_trans = elog.loc[elog['cust_id'] == id]\n\nfrom lifetimes.utils import calculate_alive_path\n\nt = (today - sp_trans.invoice_date.min().date()).days\np_alive_today = pd.DataFrame(calculate_alive_path(mbgnbd, sp_trans, 'invoice_date', t, freq='D'))[0].tail(1).values\np_alive_today = np.round(p_alive_today[0], 2)\nprint('Probability that customer is alive today is', p_alive_today)\n\nt = (one_year_from_now - sp_trans.invoice_date.min().date()).days\nax = plot_history_alive(mbgnbd, t, sp_trans, 'invoice_date', start_date=two_year_ago) #, start_date='2016-01-01'\nax.vlines(x=today, ymin=0, ymax=1.05, colors='#4C4C4C')\nax.hlines(y=0.8, xmin=two_year_ago, xmax=one_year_from_now, colors='#4C4C4C')\n\nax.set_xlim(two_year_ago, one_year_from_now) # sp_trans.ORDER_DATE.min()\nax.set_ylim(0, 1.05)\n\nplt.xticks(rotation=-90)\ntext(0.75, 0.1, p_alive_today, ha='center', va='center', transform=ax.transAxes)\n\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicted Transactions with Time\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"elog.columns = ['cust_id', 'invoice_date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Get expected and actual repeated cumulative transactions.\n\nfrom lifetimes.utils import expected_cumulative_transactions\n\nt = (elog.invoice_date.max() - elog.invoice_date.min()).days\ndf = expected_cumulative_transactions(mbgnbd, elog, 'invoice_date', 'cust_id', t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Calibration period = 2016-09-04 to 2017-09-30\nfrom datetime import datetime\n\ncal = datetime.strptime('2018-06-30', '%Y-%m-%d')\n\nfrom lifetimes.plotting import plot_cumulative_transactions\nt = (elog.invoice_date.max() - elog.invoice_date.min()).days\nt_cal = (cal - elog.invoice_date.min()).days\nplot_cumulative_transactions(mbgnbd, elog, 'invoice_date', 'cust_id', t, t_cal, freq='D')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\nfrom lifetimes.plotting import plot_incremental_transactions\nplot_incremental_transactions(mbgnbd, elog, 'invoice_date', 'cust_id', t, t_cal, freq='D')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict the conditional, expected average lifetime value of our customers.\nModel performance will increase if it is trained on all the data and not a sample as is the case here...\n\nCheers.."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}