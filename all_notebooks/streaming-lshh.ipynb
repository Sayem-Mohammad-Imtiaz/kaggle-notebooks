{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* > # EE226 - Coding 2\n## Streaming algorithm & Locality Sensitive Hashing","metadata":{}},{"cell_type":"markdown","source":"### Streaming: DGIM","metadata":{}},{"cell_type":"markdown","source":"DGIM is an efficient algorithm in processing large streams. When it's infeasible to store the flowing binary stream, DGIM can estimate the number of 1-bits in the window. In this coding, you're given the *stream_data.txt* (binary stream), and you need to implement the DGIM algorithm to count the number of 1-bits. Write code and ask the problems below.","metadata":{}},{"cell_type":"markdown","source":"### Your task","metadata":{}},{"cell_type":"markdown","source":"1. Set the window size to 1000, and count the number of 1-bits in the current window.","metadata":{}},{"cell_type":"code","source":"import time\nsize_window=1000\ntime_location=30000\nn_max_bucket=4\nbucket_n=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Merge1():\n    for i in range(len(bucket_n)-1,n_max_bucket-1,-1):\n        if bucket_n[i]['sum']==bucket_n[i-n_max_bucket]['sum']:\n            bucket_n[i-n_max_bucket]['sum']+=bucket_n[i-n_max_bucket+1]['sum']\n            bucket_n[i-n_max_bucket]['timestamp']=bucket_n[i-n_max_bucket+1]['timestamp']\n            del bucket_n[i-n_max_bucket+1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Count_DGIM1():\n    summ=0\n    start_time=time.time()\n    with open('../input/coding2/stream_data.txt', 'r') as f:\n        temp=f.readline()\n        temp=temp.replace('\\t', '')\n        for i in range(time_location):\n            text=temp[i]\n            if len(bucket_n)>0 and i+1-size_window==bucket_n[0]['timestamp']:\n                del bucket_n[0]\n            if int(text)==1:\n                bucket={\"timestamp\":i+1,\"sum\":1}\n                bucket_n.append(bucket)\n                Merge1()\n    for i in range(len(bucket_n)):\n        summ+=bucket_n[i]['sum']\n    print(bucket_n)\n    summ-=bucket_n[0]['sum']/2\n    return summ if len(bucket_n)>0 else 0,time.time()-start_time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bit_sum,bit_time=Count_DGIM1()\nprint(\"当前窗口中1的估计个数为：%d,运行时间为:%f\"%(bit_sum,bit_time))\nprint(\"相同大小桶个数越多越接近精确解\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Write a function that accurately counts the number of 1-bits in the current window, and compare the difference between its running time and space and the DGIM algorithm.","metadata":{}},{"cell_type":"code","source":"def Count_ACTUAL():\n    bit_sum=0\n    start_time=time.time()\n    with open('../input/coding2/stream_data.txt', 'r') as f:\n        temp=f.readline()\n        temp=temp.replace('\\t', '')\n        for i in range(time_location-size_window,time_location):\n            text=temp[i]\n            if int(text)==1:\n                bit_sum+=1\n    return bit_sum ,time.time()-start_time\n                ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bit_act_sum,bit_act_time=Count_ACTUAL()\n\nprint(\"当前窗口中1的精确个数为：%d,运行时间为:%f\"%(bit_act_sum,bit_act_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locality Sensitive Hashing","metadata":{}},{"cell_type":"markdown","source":"The locality sensitive hashing (LSH) algorithm is efficient in near-duplicate document detection. In this coding, you're given the *docs_for_lsh.csv*, where the documents are processed into set of k-shingles (k = 8, 9, 10). *docs_for_lsh.csv* contains 201 columns, where column 'doc_id' represents the unique id of each document, and from column '0' to column '199', each column represents a unique shingle. If a document contains a shingle ordered with **i**, then the corresponding row will have value 1 in column **'i'**, otherwise it's 0. You need to implement the LSH algorithm and ask the problems below.","metadata":{}},{"cell_type":"markdown","source":"### Your task","metadata":{}},{"cell_type":"markdown","source":"Use minhash algoirthm to create signature of each document, and find 'the most similar' documents under Jaccard similarity. \nParameters you need to determine:\n1) Length of signature (number of distinct minhash functions) *n*. Recommanded value: n > 20.\n\n2) Number of bands that divide the signature matrix *b*. Recommanded value: b > n // 10.","metadata":{}},{"cell_type":"code","source":"# Your code here, you can add cells if necessary\nimport random\nimport hashlib\nimport pandas as pd\nimport numpy as np\ndf=pd.read_csv('../input/coding2/docs_for_lsh.csv')\ntmp=df.values\nmatrix=tmp[:,1:]\nprint(matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc_id = df['doc_id'].tolist()\nnonZeroShingle = matrix[0].nonzero()\ni = 1\nfinal_id=[0]\nprint(matrix.shape[0])\nwhile i < matrix.shape[0]:\n    if sum(matrix[i][nonZeroShingle]) == 0:\n        i += 1\n    else:   \n        final_id.append(i)\n        i += 1\nfile = []\nfor i in range(len(final_id)):\n    file.append(matrix[final_id[i],:].tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrixnew=np.array(file)\nprint(type(matrixnew))\nprint(matrixnew.shape)\nmatrixnew=matrixnew.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigGen(matrix):\n    # the row sequence set\n    seqSet = [i for i in range(matrix.shape[0])]\n    # initialize the sig vector as [-1, -1, ..., -1]\n    result = [-1 for i in range(matrix.shape[1])]\n    count = 0\n    while len(seqSet) > 0:\n        # choose a row of matrix randomly\n        randomSeq = random.choice(seqSet)\n        for i in range(matrix.shape[1]):\n            if matrix[randomSeq][i] != 0 and result[i] == -1:\n                result[i] = randomSeq\n                count += 1\n        if count == matrix.shape[1]:\n            break\n        seqSet.remove(randomSeq)\n    # return a list\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigMatrixGen(input_matrix, n):\n    result = []\n    for i in range(n):\n        #print(i)\n        sig = sigGen(input_matrix)\n        result.append(sig)\n    # return a ndarray\n    return np.array(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nresult=sigMatrixGen(matrixnew, 100)\nprint(result)\ndata=[]\ndata1=[]\nfor i in range(result.shape[1]):\n    data.append(len(set(result[:,0]) & set(result[:,i])))\n    a=result[:,0]- result[:,i]\n    summ=0\n    for i in range(a.shape[0]):\n        if a[i]==0:\n            summ=summ+1\n    data1.append(summ)\n#print(data)\n#print(data1)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate the sig matrix\nsigMatrix = sigMatrixGen(matrixnew, 120)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#直接比较相同shingle个数\ndata=[]\ndata1=[]\nfor i in range(sigMatrix.shape[1]):\n    data.append(len(set(sigMatrix[:,0]) & set(sigMatrix[:,i])))\n    a=sigMatrix[:,0]- sigMatrix[:,i]\n    summ=0\n    for i in range(a.shape[0]):\n        if a[i]==0:\n            summ=summ+1\n    data1.append(summ)\nrank = [index for index, value in sorted(list(enumerate(data1)), key=lambda x:x[1],reverse = True)]\nprint(rank[1:31])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LSH计算\nb=8\nr=15\nhashBuckets = {}\nbegin, end = 0, r\n\n\n# count the number of band level\ncount = 0\n\nwhile end <= sigMatrix.shape[0]:\n\n    count += 1\n\n    # traverse the column of sig matrix\n    for colNum in range(sigMatrix.shape[1]):\n\n        # generate the hash object, we used md5\n        hashObj = hashlib.md5()\n\n        # calculate the hash value\n        band = str(sigMatrix[begin: begin + r, colNum]) + str(count)\n        hashObj.update(band.encode())\n\n        # use hash value as bucket tag\n        tag = hashObj.hexdigest()\n\n        # update the dictionary\n        if tag not in hashBuckets:\n            hashBuckets[tag] = [colNum]\n        elif colNum not in hashBuckets[tag]:\n            hashBuckets[tag].append(colNum)\n    begin += r\n    end += r","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_final = set()\nqueryCol = 0\nfor key in hashBuckets:\n    if 0 in hashBuckets[key]:\n        for i in hashBuckets[key]:\n            result_final.add(i)\n\nresult_final.remove(queryCol)\nprint(len(result_final))\n#print(hashBuckets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final=[]\nresult_final1=list(result_final)[0:30]\nfor i in result_final1:\n    final.append(final_id[i])\nprint(final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Problem: For document 0 (the one with id '0'), list the **30** most similar document ids (except document 0 itself). You can valid your results with the [sklearn.metrics.jaccard_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html) function.\n\nTips: You can adjust your parameters to hash the documents with similarity *s > 0.8* into the same bucket.","metadata":{}},{"cell_type":"code","source":"# 内置函数计算\nfrom sklearn.metrics import jaccard_score\njac_file = []\nmatrix1=matrixnew.T\nprint(matrix1)\nfor i_file in range(1,len(matrix1)):\n    jac_file.append(jaccard_score(np.array(matrix1[0]),np.array(matrix1[i_file])))\njac_30 = []\nfor num in range(30):\n    jac_30.append(jac_file.index(max(jac_file))+1)\n    jac_file[jac_file.index(max(jac_file))] = 0\nprint(jac_30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final1=[]\nfor i in jac_30:\n    final1.append(final_id[i])\nprint(final1)\nfinal2=[]\nfor i in rank[1:31]:\n    final2.append(final_id[i])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print('使用LSH得到的结果与内置函数相同的个数：%d'%len(set(final)&set(final1)))\n#print('使用直接计算相似度得到的结果与内置函数相同的个数：%d'%len(set(final1)&set(final2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}