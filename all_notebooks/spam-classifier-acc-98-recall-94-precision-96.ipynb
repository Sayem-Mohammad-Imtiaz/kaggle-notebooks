{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>Email Spam Classifer</center>\n## <center>Clasify the Collection of SMS messages to tagged as spam or legitimate</center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Content\n * [***Introduction***](#introduction)\n * [***Data Visualization***](#visualization)\n   * [***Distribution of text***](#distribution)\n   * [***Wordcloud***](#wordcloud)\n   * [***N-grams visualization***](#ngram)\n * [***Data pre-processing***](#preprocess)\n * [***Model Building***](#model)\n   * [***Logistic Regression***](#logistic)\n   * [***Naive Bayes***](#naive)\n   * [***Support Vector Machine***](#support)\n   * [***Random Forest Classifer***](#random)\n * [***Conclusion***](#conclusion)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id = 'introduction'></a>\n# <Center>Introduction</center>\nThe SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam. <br> The files contain one message per line. Each line is composed by two columns: **Label** contains the label (ham or spam) and **message** contains the raw text.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\nimport string\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv',encoding='latin-1')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True, axis=1)\ndata.columns = ['label','message']\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['label']).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id ='visualization'></a>\n# <center>Data Visualization</center>\nBasic exploration of data to understand data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.label.replace({'ham':0,'spam':1}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='distribution'></a>\n## Distribution of Text\nLength of data is analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\ndata[data.label==0].message.apply(len).plot(kind='hist',alpha=0.6,bins=35,label='Ham messages')\ndata[data.label==1].message.apply(len).plot(kind='hist', color='red',alpha=0.6,bins=35,label='Ham messages')\n\nplt.legend()\nplt.xlabel(\"Message Length\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='wordcloud'></a>\n## <center>WORDCLOUD</center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## WORDCLOUD FOR TEXT THAT IS NOT SPAM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20)) \nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(data[data.label == 0].message))\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## WORDCLOUD FOR TEXT THAT IS SPAM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(data[data.label == 1].message))\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='ngram'></a>\n## <center>N-gram visualization</center>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_corpus(text):\n    words = []\n    for i in text:\n        for j in i.split():\n            words.append(j.strip())\n    return words\ncorpus = get_corpus(data.message)\ncorpus[:5]\nfrom collections import Counter\ncounter = Counter(corpus)\nmost_common = counter.most_common(10)\nmost_common = dict(most_common)\nmost_common","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Uni-gram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=list(most_common.values()),y=list(most_common.keys()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bi-gram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_text_ngrams(corpus, n, g):\n    vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\nplt.figure(figsize = (16,9))\nmost_common_bi = get_top_text_ngrams(data.message,10,2)\nmost_common_bi = dict(most_common_bi)\nsns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tri-gram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\nmost_common_bi = get_top_text_ngrams(data.message,10,3)\nmost_common_bi = dict(most_common_bi)\nsns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = 'preprocess'></a>\n# <center>Data Pre-Processing</center>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    STOPWORDS = stopwords.words('english') + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n    \n    # Now just remove any stopwords\n    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"textFeatures = data['message'].copy()\ntextFeatures = textFeatures.apply(text_process)\nvectorizer = TfidfVectorizer(\"english\")\nfeatures = vectorizer.fit_transform(textFeatures)\n\nX_train, X_test, y_train, y_test = train_test_split(features, data['label'], test_size=0.3, random_state=111)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = 'model'></a>\n# <center>Model Building</center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id= 'logistic'></a>\n## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegressionCV(cv=10, random_state=0)\nclf.fit(X_train, y_train)\nclf_prediction = clf.predict(X_test)\nlg_acc = accuracy_score(y_test,clf_prediction)\nprint('\\n')\nprint('Accuracy of Naive Bayes =',accuracy_score(y_test,clf_prediction))\nprint('\\n-----------------\\n')\nprint(classification_report(y_test,clf_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_true=y_test, y_pred=clf_prediction)\ngroup_names = ['True pos','False Pos','False Neg','True neg']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nplt.figure(figsize=(15,10))\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='naive'></a>\n## Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb = MultinomialNB(alpha=0.2)\nmnb.fit(X_train, y_train)\nmnb_prediction = mnb.predict(X_test)\nmnb_acc=accuracy_score(y_test,mnb_prediction)\nprint('\\n')\nprint('Accuracy of Naive Bayes =',accuracy_score(y_test,mnb_prediction))\nprint('\\n-----------------\\n')\nprint(classification_report(y_test,mnb_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_true=y_test, y_pred=mnb_prediction)\ngroup_names = ['True pos','False Pos','False Neg','True neg']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nplt.figure(figsize=(15,10))\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='Support'></a>\n## Support Vector Machine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVC(kernel='sigmoid', gamma=1.0)\nsvm.fit(X_train, y_train)\nsvm_prediction = svm.predict(X_test)\nsvm_acc = accuracy_score(y_test,svm_prediction)\nprint('\\n')\nprint('Accuracy of Naive Bayes =',accuracy_score(y_test,svm_prediction))\nprint('\\n-----------------\\n')\nprint(classification_report(y_test,svm_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_true=y_test, y_pred=svm_prediction)\ngroup_names = ['True pos','False Pos','False Neg','True neg']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nplt.figure(figsize=(15,10))\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='random'></a>\n## Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=50, max_depth=None, n_jobs=-1)\nrf.fit(X_train, y_train)\nrf_prediction = rf.predict(X_test)\nrf_acc = accuracy_score(y_test,rf_prediction)\nprint('\\n')\nprint('Accuracy of Naive Bayes =',accuracy_score(y_test,rf_prediction))\nprint('\\n-----------------\\n')\nprint(classification_report(y_test,rf_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_true=y_test, y_pred=rf_prediction)\ngroup_names = ['True pos','False Pos','False Neg','True neg']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in\n                cf_matrix.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in\n                     cf_matrix.flatten()/np.sum(cf_matrix)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n          zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\nplt.figure(figsize=(15,10))\n\nsns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='conclusion'></a>\n# <center>Conclusion</center>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We have Tried **Logistic Regression, Naive Bayes, Support Vector Machine and Random Forest classifier** to compare which model perform best.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Based on accuracy of models **Naive Bayes** outperform other classifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = np.argmax([lg_acc,mnb_acc,svm_acc,rf_acc])\nclassification = {0:'Logistic Regression',1:'Naive bayes',2:'Support Vector Classifcation',3:'Random Forest Classifier'}\nprint('Best classifier based on accuracy is {}'.format(classification[acc]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" >   But in our case we wish to more focus on reducing **False Positive**.\n >   - we want to select a model which doesn't classify Normal(Ham) messages as Spam messages because this could cause more   harm as important messages can be classified as spam and it can cause loss.\n >\n >   - so, In our case we should select model whose **precision** is better and also considering **Recall**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":">   To understand **Precision and Recall Trade Off**: \n>    - To fully evaluate the effectiveness of a model, we must examine both precision and recall.<br> </t>Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### precision of Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Logistic Regression  is ',precision_score(y_test, clf_prediction))\nprint('\\n')\nprint('Naive Bayes is ',precision_score(y_test, mnb_prediction))\nprint('\\n')\nprint('Support Vector Machine Regression is ',precision_score(y_test, svm_prediction))\nprint('\\n')\nprint('Random Forest Classifer is ',precision_score(y_test, rf_prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recall of Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Logistic Regression  is ',recall_score(y_test, clf_prediction))\nprint('\\n')\nprint('Naive Bayes is ',recall_score(y_test, mnb_prediction))\nprint('\\n')\nprint('Support Vector Machine Regression is ',recall_score(y_test, svm_prediction))\nprint('\\n')\nprint('Random Forest Classifer is ',recall_score(y_test, rf_prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Considering overall performance of *** Precision and Recall***\n>  - Naive Bayes is Best Model.\n\n> ### Considering ***Precision***\n> - Random Forest is Best Model.\n\n> ### Considering ***Recall***\n> - Naive Bayes is best model.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### Overall We should Select Either Naive Bayes model or Logistic Regession in Spam Classsifier Use Case.\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}