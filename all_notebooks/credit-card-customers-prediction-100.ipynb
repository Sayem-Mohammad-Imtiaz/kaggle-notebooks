{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Credit Card customers\n\n* CLIENTNUM          :  Client number. Unique identifier for the customer holding the account\n* Attrition_Flag     :  Internal event (customer activity) variable - if the account is closed then 1 else 0\n* Customer_Age       :  Demographic variable - Customer's Age in Years\n* Gender             :  Demographic variable - M=Male, F=Female\n* Dependent_count    :  Demographic variable - Number of dependents\n* Education_Level    :  Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n* Marital_Status     :  Demographic variable - Married, Single, Divorced, Unknown\n* Income_Category    :  Demographic variable - Annual Income Category of the account holder (< $40K, $40K - 60K, $60K - $80K, $80K-$120K, >\n* Card_Category      :  Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n* Months_on_book     :  Period of relationship with bank\n* Total_Relationship_Count :  Total no. of products held by the customer\n* Months_Inactive_12_mon   :  No. of months inactive in the last 12 months\n* Contacts_Count_12_mon    :  No. of Contacts in the last 12 months\n* Credit_Limit             ;  Credit Limit on the Credit Card\n* Total_Revolving_Bal      :  Total Revolving Balance on the Credit Card\n* Avg_Open_To_Buy          :  Open to Buy Credit Line (Average of last 12 months)\n* Total_Amt_Chng_Q4_Q1     :  Change in Transaction Amount (Q4 over Q1)\n* Total_Trans_Amt          :  Total Transaction Amount (Last 12 months)\n* Total_Trans_Ct           :  Total Transaction Count (Last 12 months)\n* Total_Ct_Chng_Q4_Q1      :  Change in Transaction Count (Q4 over Q1)\n* Avg_Utilization_Ratio    :  Average Card Utilization Ratio\n* Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1 : \n* Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2' :\n\n![](https://www.madd.org/wp-content/uploads/2017/11/Card-Handoff-2.jpg)\n\n"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install dataprep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dataprep.eda import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1- library and package "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# manipulation data\nimport pandas as pd\nimport numpy as np\n\n#visualiation data\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport matplotlib\nimport plotly.graph_objects as go\nimport plotly.express as px\n\n#default theme\nsns.set(context='notebook', style='darkgrid', palette='colorblind', font='sans-serif', font_scale=1, rc=None)\nmatplotlib.rcParams['figure.figsize'] =[8,8]\nmatplotlib.rcParams.update({'font.size': 15})\nmatplotlib.rcParams['font.family'] = 'sans-serif'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2- laod and analysis data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/credit-card-customers/BankChurners.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CLIENTNUM : Client number. Unique identifier for the customer holding the account ==> so we gonna drop it (usless)\ndf=df.drop('CLIENTNUM',axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so lie we c we had :\n* 10127 Rows\n* 22 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data type plot\ndf.dtypes.value_counts().plot.pie(explode=[0.1,0.1,0.1],autopct='%1.1f%%',shadow=True)\nplt.title('type of our data');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### some notes :\nby applicing the describe() we can see are the most frequent valuer on eaxh columns are  :\n1. Attrition_Flag : Existing Customer \n2. Gender : the famale \n3. Education_Level : Graduate \n4. Marital_Status : Married\n5. Income_Category : Less than $40K\n6. Card_Category : Blue"},{"metadata":{},"cell_type":"markdown","source":"# 3- finding missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values=df.isnull().sum()\npercent_missing = df.isnull().sum()/df.shape[0]*100\n\nvalue = {\n    'missing_values ':missing_values,\n    'percent_missing %':percent_missing\n}\nframe=pd.DataFrame(value)\nframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"our data is so clean happy news :) "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# 4- data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"create_report(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5- features transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Attrition_Flag.replace({'Existing Customer': 1, 'Attrited Customer': 0}, inplace=True)\n\ndf.Gender.replace({'F': 0, 'M': 1}, inplace=True)\n\ndf.Education_Level.replace({'Graduate': 0, 'High School': 1, 'Unknown': 2,'Uneducated':3,'College':4,'Post-Graduate':5,'Doctorate':6}, inplace=True)\n\ndf.Marital_Status.replace({'Married': 0, 'Single': 1,'Unknown':2,'Divorced':3}, inplace=True)\n\ndf.Income_Category.replace({'Less than $40K': 0,'$80K - $120K': 1, '$60K - $80K': 2,'Unknown':3}, inplace=True)\ndf.Income_Category.replace({'$40K - $60K': 4}, inplace=True)\ndf.Income_Category.replace({'$120K +': 5}, inplace=True)\n\ndf.Card_Category.replace({'Blue': 0, 'Silver': 1,'Gold':2,'Platinum':3}, inplace=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data type plot\ndf.dtypes.value_counts().plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True)\nplt.title('type of our data');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6- feautres selection"},{"metadata":{},"cell_type":"markdown","source":"## A- corr map"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr().style.background_gradient(cmap='coolwarm').set_precision(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## B-the most 10 important feature are"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection\n\nplt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\n\nx = df.drop('Attrition_Flag',axis=1)\ny = df.Attrition_Flag\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.title('the most 10 important feature are')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['Customer_Age','Customer_Age','Gender','Dependent_count','Education_Level','Marital_Status','Income_Category','Card_Category','Months_on_book','Total_Relationship_Count','Months_Inactive_12_mon','Contacts_Count_12_mon','Credit_Limit','Avg_Open_To_Buy','Total_Amt_Chng_Q4_Q1','Total_Ct_Chng_Q4_Q1'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7- data split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns=[\"Attrition_Flag\"])\ny = df[\"Attrition_Flag\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\n#Applying GradientBoostingClassifier Model \n\n\nGBCModel = GradientBoostingClassifier(n_estimators=100,max_depth=3,random_state=33) \nGBCModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('GBCModel Train Score is : ' , GBCModel.score(X_train, y_train))\nprint('GBCModel Test Score is : ' , GBCModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = GBCModel.predict(X_test)\ny_pred_prob = GBCModel.predict_proba(X_test)\n#print('Predicted Value for GBCModel is : ' , y_pred[:10])\n#print('Prediction Probabilities Value for GBCModel is : ' , y_pred_prob[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True,cmap='GnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## A- LOGISTIC REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making Confusion Matrix and calculating accuracy score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nmodel = LogisticRegression()\n\n#Fit the model\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nmylist = []\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n# accuracy score\nacc_logreg = accuracy_score(y_test, y_pred)\n\nmylist.append(acc_logreg)\nprint(cm)\nprint(acc_logreg,'%')\n# drawing confusion matrix\nsns.heatmap(cm, center = True,cmap='GnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B- KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the optimum number of neighbors \n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nlist1 = []\nfor neighbors in range(1,5):\n    classifier = KNeighborsClassifier(n_neighbors=neighbors, metric='minkowski')\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    list1.append(accuracy_score(y_test,y_pred))\nplt.plot(list(range(1,5)), list1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the K Nearest Neighbor Classifier on the Training set\n\nclassifier = KNeighborsClassifier(n_neighbors=3)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\n\ny_pred = classifier.predict(X_test)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the confusion matrix and calculating accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nacc_knn = accuracy_score(y_test, y_pred)\nmylist.append(acc_knn)\nprint(cm)\nprint(acc_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drawing confusion matrix\nsns.heatmap(cm, center = True,cmap='GnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## C- SUPPORT VECTOR MACHINE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor c in [0.5,0.6,0.7,0.8,0.9,1.0]:\n    classifier = SVC(C = c, random_state=0, kernel = 'rbf')\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    list1.append(accuracy_score(y_test,y_pred))\nplt.plot([0.5,0.6,0.7,0.8,0.9,1.0], list1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Support Vector Classifier on the Training set\n\nfrom sklearn.svm import SVC\nclassifier = SVC(C = 1.0, random_state=0, kernel = 'rbf')\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the test set results\n\ny_pred = classifier.predict(X_test)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the confusion matrix and calculating accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nacc_svc = accuracy_score(y_test, y_pred)\nprint(cm)\nprint(acc_svc,'%')\nmylist.append(acc_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## D) DecisionTreeClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Finding the optimum number of max_leaf_nodes\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor leaves in range(2,15):\n    classifier = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    list1.append(accuracy_score(y_test,y_pred))\n#print(mylist)\nplt.plot(list(range(2,15)), list1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Decision Tree Classifier on the Training set\n\nclassifier = DecisionTreeClassifier(max_leaf_nodes = 5, random_state=0, criterion='entropy')\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the test set results\n\ny_pred = classifier.predict(X_test)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the confusion matrix and calculating accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nacc_decisiontree = accuracy_score(y_test, y_pred)\nprint(cm)\nprint(acc_decisiontree)\nmylist.append(acc_decisiontree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## E- ANN (neural network )"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnp.random.seed(0)\nimport tensorflow as tf\n\n# Initialising the ANN\n\nann = tf.keras.models.Sequential()\n\n# Adding the input layer and the first hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n\n# Adding the second hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n\n# Adding the third hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n\n# Adding the fourth hidden layer\n\nann.add(tf.keras.layers.Dense(units = 7, activation = 'relu'))\n\n# Adding the output layer\n\nann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n\n# Compiling the ANN\n\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )\n\n# Training the ANN on the training set\n\nann.fit(X_train, y_train, batch_size = 16, epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the test set results\n\ny_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.9)\nnp.set_printoptions()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the confusion matrix, calculating accuracy_score \n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# confusion matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint()\n\n# accuracy\nac_ann = accuracy_score(y_test,y_pred)\nprint(\"Accuracy\")\nprint(ac_ann)\nmylist.append(ac_ann)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F- xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nlist1 = []\nfor estimators in range(10,30,1):\n    classifier = XGBClassifier(n_estimators = estimators, max_depth=12, subsample=0.7)\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    list1.append(accuracy_score(y_test,y_pred))\n#print(mylist)\nplt.plot(list(range(10,30,1)), list1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(n_estimators = 15, max_depth=12, subsample=0.7)\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the confusion matrix and calculating the accuracy score\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nac_xgboost = accuracy_score(y_test, y_pred)\nmylist.append(ac_xgboost)\nprint(cm)\nprint(ac_xgboost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n               'ANN',   \n              'Decision Tree','xgboost'],\n    'Score': [acc_svc, acc_knn, acc_logreg, \n               ac_ann, acc_decisiontree,ac_xgboost\n              ]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=models.Model, y=models.Score, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"% of Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}