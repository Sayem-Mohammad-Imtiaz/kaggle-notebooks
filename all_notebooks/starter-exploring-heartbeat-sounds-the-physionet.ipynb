{"cells":[{"metadata":{},"cell_type":"markdown","source":"Inspired by https://medium.com/@taposhdr/audio-file-processing-ecg-audio-using-python-a919a9351952"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        'print(os.path.join(dirname, filename))'\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/heart-sounds-physionet-challange-2016/training/training-a/\"\nfrom pathlib import Path\n\npathlist = Path(data_dir).glob('**/*.asm')\nfor path in pathlist:\n     # because path is object not string\n     path_in_str = str(path)\nprint(data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../input/heart-sounds-physionet-challange-2016/training'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Installing the libary "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, confusion_matrix, auc, roc_auc_score, precision_recall_curve, accuracy_score\n\nfrom IPython.display import Audio\nfrom scipy.io import wavfile\nfrom glob import glob\n\n#Note : LibROSA is a python package for music and audio analysis. \nimport librosa\nimport librosa.display\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, confusion_matrix, auc, roc_auc_score, precision_recall_curve, accuracy_score\n\nfrom IPython.display import Audio\nfrom scipy.io import wavfile\nfrom glob import glob\n\n#Note : LibROSA is a python package for music and audio analysis. \nimport librosa\nimport librosa.display\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.newbedev.com/python/howto/how-to-iterate-over-files-in-a-given-directory/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_wave_file(path):\n    wav, sr = librosa.load(path)\n    return wav, sr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wav_path = '../input/heart-sounds-physionet-challange-2016/training/'\nwav, sr = load_wave_file(wav_path+'training-a/a0409.wav')\nwav2, sr2 = load_wave_file(wav_path+'training-a/a0408.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wav, sr = load_wave_file(wav_path+'training-a/a0409.wav')\nplt.plot(wav)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as ipd\nwav, sr = load_wave_file(wav_path+'training-a/a0409.wav')\nipd.Audio(wav,rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/heart-sounds-physionet-challange-2016/training/training-c/\"\naudio_files = glob(data_dir+'/*.wav')\nlen(audio_files)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"../input/heart-sounds-physionet-challange-2016/training/training-{}\".format('c')\nfor data in data_dir:\n    audio_files = glob(data_dir+'/*.wav')\nprint(len(audio_files))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\npath = \"../input/heart-sounds-physionet-challange-2016/training/\"\nmn = 20\nfolders = ([name for name in os.listdir(path)\n            if os.path.isdir(os.path.join(path, name)) and name.startswith(\"t\")]) # get all directories \nfor folder in folders:\n    contents = os.listdir(os.path.join(path,folder)) # get list of contents\n    if len(contents) > mn: # if greater than the limit, print folder and number of contents\n        print(folder,len(contents))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/'\ndf_1 = pd.read_csv(wav_path+'training-b/REFERENCE.csv')\ndf_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_a = pd.read_csv(wav_path+'training-a/REFERENCE.csv',names=[\"wavfile\", \"actuals\", \"pred\"])\ntraining_b = pd.read_csv(wav_path+'training-b/REFERENCE.csv',names=[\"wavfile\", \"actuals\", \"pred\"])\ntraining_c = pd.read_csv(wav_path+'training-c/REFERENCE.csv',names=[\"wavfile\", \"actuals\", \"pred\"])\ntraining_d = pd.read_csv(wav_path+'training-d/REFERENCE.csv',names=[\"wavfile\", \"actuals\", \"pred\"])\ntraining_e = pd.read_csv(wav_path+'training-e/REFERENCE.csv',names=[\"wavfile\", \"actuals\", \"pred\"])\ntraining_f = pd.read_csv(wav_path+'training-f/REFERENCE.csv',names=[\"wavfile\", \"actuals\", \"pred\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_a.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_e.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_a.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_e.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(audio_files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio, sfreq = librosa.load(audio_files[0])\ntime = np.arange(0,len(audio))/sfreq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.plot(time,audio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for file in range(0, len(audio_files),1):\n    audio, sfreq = librosa.load(audio_files[file])\n    fig,ax = plt.subplots()\n    time = np.arange(0,len(audio))/sfreq\n    ax.plot(time,audio)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([training_a, training_b,training_c,training_d,training_e,training_f], axis=0)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"actuals\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution graphs (histogram/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotPerColumnDistribution(train, 10, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Helper Function\ndef get_wave_path(wav_file_name,wav_path):\n    if (wav_file_name[0] =='a'):\n        wav_path = wav_path + \"training-a/\" + wav_file_name +\".wav\"\n        #print(wav_path)\n    elif (wav_file_name[0] =='b'):\n        wav_path = wav_path + \"training-b/\" + wav_file_name +\".wav\"\n    elif (wav_file_name[0] =='c'):\n        wav_path = wav_path + \"training-c/\" + wav_file_name +\".wav\"\n    elif (wav_file_name[0] =='d'):\n        wav_path = wav_path + \"training-d/\" + wav_file_name +\".wav\"\n    elif (wav_file_name[0] =='e'):\n        wav_path = wav_path + \"training-e/\" + wav_file_name +\".wav\"\n    elif (wav_file_name[0] =='f'):\n        wav_path = wav_path + \"training-f/\" + wav_file_name +\".wav\"\n    return wav_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io import wavfile\nnormals = train.query('actuals == \"1\"')['wavfile'].tolist()\nprint(wav_path)\nnormal_sound_file = get_wave_path(str(normals[1]),wav_path)\nprint(normal_sound_file)\nAudio(normal_sound_file)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_wav, sr = load_wave_file(wav_path+'training-a/a0009.wav')\nipd.Audio(wav,rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython.display as ipd\n#plot a normal wave\nnormal_wav, sr = load_wave_file(normal_sound_file)\n#Abnormals\nabnormals = train.query('actuals == \"-1\"')['wavfile'].tolist()\n#print(wav_path)\nabnormal_sound_file = get_wave_path(str(abnormals[1]),wav_path)\n#plot a normal wave\nabnormal_wav, sr = load_wave_file(abnormal_sound_file)\n\nprint(abnormal_sound_file)\nipd.Audio(abnormal_wav, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the normal and Abnormal sound waves side by side\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 5))\naxes[0].plot(normal_wav,color=\"b\")\naxes[0].set_title('Normal Wave')\naxes[1].plot(abnormal_wav,color=\"r\")\naxes[1].set_title('Abnormal Wave')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}