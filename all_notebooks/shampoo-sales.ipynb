{"cells":[{"metadata":{"_uuid":"f83b100733e05bdca30770430a43d78ab557db2c","_cell_guid":"7500c108-839a-4149-b034-0e67339c143a"},"cell_type":"markdown","source":"https://machinelearningmastery.com/use-dropout-lstm-networks-time-series-forecasting/\n\nhttps://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/","outputs":[],"execution_count":null},{"metadata":{"_uuid":"6709fd5f63503e7b4c551c8f7aa08fb556eed439","_cell_guid":"831d51c6-bc30-481c-b9a1-fce57c202db9","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1369810dd538918c978848e2fe9e6c171fa30935","_cell_guid":"1f1d65f9-012d-41db-977c-9f0d0e650668","trusted":false,"collapsed":true},"cell_type":"code","source":"from pandas import read_table\ndf = read_table('../input/sales-of-shampoo-over-a-three-ye.csv',sep=',')\ndf[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5ec32c874e5dc1521ea584e623d2ff9feda0047","_cell_guid":"875cfe8b-ca2a-4ee1-ad9a-e72b4f53eb5b","trusted":false,"collapsed":true},"cell_type":"code","source":"df['Month'] = \"2018-\" + df['Month']\ndf = df[:-1]\ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"884436067ec909d82b07933f8a00b9fc00a15c08","_cell_guid":"89918b06-b66a-4f06-a72c-5ba434286ae7","trusted":false,"collapsed":true},"cell_type":"code","source":"df.Month = pd.to_datetime(df.Month, format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab1ad6e3ebc7816c643fd2953c064613d70b7b6c","_cell_guid":"6eaa59e3-c0ce-4bf0-a33f-515383623a16","trusted":false,"collapsed":true},"cell_type":"code","source":"# load and plot dataset\n\nfrom pandas import datetime\nfrom matplotlib import pyplot\n# load dataset\n#def parser(x):\n#\treturn datetime.strptime('190'+x, '%Y-%m')\n#series = read_csv('../input/sales-of-shampoo-over-a-three-ye.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n# summarize first few rows\nprint(df.head())\n# line plot\ndf.plot()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcbe5167b16ca5cf08c559bf10aab91fbb867b71","_cell_guid":"75665b90-de59-4543-aaea-25bb0a52d32a","trusted":false,"collapsed":true},"cell_type":"code","source":"from pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nimport matplotlib\n# be able to save images on server\n#matplotlib.use('Agg')\nfrom matplotlib import pyplot\nimport numpy\n\n# date-time parsing function for loading the dataset\ndef parser(x):\n\treturn datetime.strptime('190'+x, '%Y-%m')\n\n# frame a sequence as a supervised learning problem\ndef timeseries_to_supervised(data, lag=1):\n\tdf = DataFrame(data)\n\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n\tcolumns.append(df)\n\tdf = concat(columns, axis=1)\n\treturn df\n\n\n\n# scale train and test data to [-1, 1]\ndef scale(train, test):\n\t# fit scaler\n\tscaler = MinMaxScaler(feature_range=(-1, 1))\n\tscaler = scaler.fit(train)\n\t# transform train\n\ttrain = train.reshape(train.shape[0], train.shape[1])\n\ttrain_scaled = scaler.transform(train)\n\t# transform test\n\ttest = test.reshape(test.shape[0], test.shape[1])\n\ttest_scaled = scaler.transform(test)\n\treturn scaler, train_scaled, test_scaled\n\n# inverse scaling for a forecasted value\ndef invert_scale(scaler, X, yhat):\n\tnew_row = [x for x in X] + [yhat]\n\tarray = numpy.array(new_row)\n\tarray = array.reshape(1, len(array))\n\tinverted = scaler.inverse_transform(array)\n\treturn inverted[0, -1]\n\n# evaluate the model on a dataset, returns RMSE in transformed units\ndef evaluate(model, raw_data, scaled_dataset, scaler, offset, batch_size):\n\t# separate\n\tX, y = scaled_dataset[:,0:-1], scaled_dataset[:,-1]\n\t# reshape\n\treshaped = X.reshape(len(X), 1, 1)\n\t# forecast dataset\n\toutput = model.predict(reshaped, batch_size=batch_size)\n\t# invert data transforms on forecast\n\tpredictions = list()\n\tfor i in range(len(output)):\n\t\tyhat = output[i,0]\n\t\t# invert scaling\n\t\tyhat = invert_scale(scaler, X[i], yhat)\n\t\t# invert differencing\n\t\tyhat = yhat + raw_data[i]\n\t\t# store forecast\n\t\tpredictions.append(yhat)\n\t# report performance\n\trmse = sqrt(mean_squared_error(raw_data[1:], predictions))\n\t# reset model state\n\tmodel.reset_states()\n\treturn rmse\n\n# fit an LSTM network to training data\ndef fit_lstm(train, test, raw, scaler, batch_size, nb_epoch, neurons):\n\tX, y = train[:, 0:-1], train[:, -1]\n\tX = X.reshape(X.shape[0], 1, X.shape[1])\n\t# prepare model\n\tmodel = Sequential()\n\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n\tmodel.add(Dense(1))\n\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n\t# fit model\n\ttrain_rmse, test_rmse = list(), list()\n\tfor i in range(nb_epoch):\n\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n\t\tmodel.reset_states()\n\t\t# evaluate model on train data\n\t\traw_train = raw[-(len(train)+len(test)+1):-len(test)]\n\t\ttrain_rmse.append(evaluate(model, raw_train, train, scaler, 0, batch_size))\n\t\t# evaluate model on test data\n\t\traw_test = raw[-(len(test)+1):]\n\t\ttest_rmse.append(evaluate(model, raw_test, test, scaler, 0, batch_size))\n\thistory = DataFrame()\n\thistory['train'], history['test'] = train_rmse, test_rmse\n\treturn history\n\n# create a differenced series\ndef difference(dataset, interval=1):\n\tdiff = list()\n\tfor i in range(interval, len(dataset)):\n\t\tvalue = dataset[i] - dataset[i - interval]\n\t\tdiff.append(value)\n\treturn Series(diff)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d886fba37aaac6ad60bc11b5da58da92a148a0d7","_cell_guid":"3440970b-1e2f-468a-8384-8e6d63942379","trusted":false,"collapsed":true},"cell_type":"code","source":"# config\nn_lag = 1\nn_repeats = 10\nn_epochs = 1000 \nn_batch = 4\nn_neurons = 3\n# load dataset\n#series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n# transform data to be stationary\n#print(series.values)\nraw_values = df['Sales of shampoo over a three year period'].values\ndiff_values = difference(raw_values, 1)\n# transform data to be supervised learning\nsupervised = timeseries_to_supervised(diff_values, n_lag)\nsupervised_values = supervised.values[n_lag:,:]\n# split data into train and test-sets\ntrain, test = supervised_values[0:-12], supervised_values[-12:]\n# transform the scale of the data\nscaler, train_scaled, test_scaled = scale(train, test)\n# fit and evaluate model\ntrain_trimmed = train_scaled[2:, :]\n# run diagnostic tests\nfor i in range(n_repeats):\n    history = fit_lstm(train_trimmed, test_scaled, raw_values, scaler, n_batch, n_epochs, n_neurons)\n    pyplot.plot(history['train'], color='blue')\n    pyplot.plot(history['test'], color='orange')\n    print('%d) TrainRMSE=%f, TestRMSE=%f' % (i+1, history['train'].iloc[-1], history['test'].iloc[-1]))\npyplot.savefig('diagnostic_baseline.png')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e761cce4c9a4489ed7ab0cbaa2f0e0abbceac327","_cell_guid":"eafa4126-733e-41cf-9c94-de76c35f9074","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}