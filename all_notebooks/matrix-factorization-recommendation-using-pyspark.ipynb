{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Matrix factorization** is a class of collaborative filtering algorithms used in recommender systems. **Matrix factorization** approximates a given rating matrix as a product of two lower-rank matrices.\nIt decomposes a rating matrix R(nxm) into a product of two matrices W(nxd) and U(mxd).\n\n\\begin{equation*}\n\\mathbf{R}_{n \\times m} \\approx \\mathbf{\\hat{R}} = \n\\mathbf{V}_{n \\times k} \\times \\mathbf{V}_{m \\times k}^T\n\\end{equation*}"},{"metadata":{},"cell_type":"markdown","source":"**Additional NOTE**\n\nIf you are interested in learning or exploring more about importance of feature selection in machine learning, then refer to my below blog offering.\n\nhttps://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/"},{"metadata":{},"cell_type":"markdown","source":"### Notebook - Table of Content\n\n1. [**Importing necessary libraries**](#1.-Importing-necessary-libraries)   \n2. [**Loading the data into PySpark dataframes**](#2.-Loading-the-data-into-PySpark-dataframes) \n3. [**Basic data exploration**](#3.-Basic-data-exploration)  \n    3.1 [**Total number of users, movies and ratings**](#3.1-Total-number-of-users,-movies-and-ratings)  \n    3.2 [**Distribution of ratings**](#3.2-Distribution-of-ratings)  \n    3.3 [**Ratings per user**](#3.3-Ratings-per-user)      \n    3.4 [**Ratings per movie**](#3.4-Ratings-per-movie)  \n4. [**Train-test split**](#4.-Train-test-split)  \n5. [**ALS based recommendation**](#5.-ALS-based-recommendation)  \n    5.1 [**Analysing the model**](#5.1-Analysing-the-model)     \n    5.2 [**Evaluating the results**](#5.2-Evaluating-the-results)  \n    5.3 [**Hyperparameter tuning**](#5.3-Hyperparameter-tuning)\n6. [**Additional performance measures for Recommendation**](#6.-Additional-performance-measures-for-Recommendation)      \n    6.1 [**Precision and Recall**](#6.1-Precision-and-Recall)    \n7. [**Handling Cold Start problem**](#7.-Handling-Cold-Start-problem)        "},{"metadata":{},"cell_type":"markdown","source":"### 1. Importing the necessary libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark import SparkContext, SQLContext   # required for dealing with dataframes\nfrom pyspark.sql.functions import isnan, count, col\nfrom pyspark.ml.evaluation import RegressionEvaluator\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pyspark.ml.recommendation import ALS      # for Matrix Factorization using ALS ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = SparkContext()      # instantiating spark context \nsqlContext = SQLContext(sc) # instantiating SQL context ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Loading the data into PySpark dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"jester_ratings_df = sqlContext.read.csv(\"/kaggle/input/jester-17m-jokes-ratings-dataset/jester_ratings.csv\",header = True, inferSchema = True)\njester_items_df = sqlContext.read.csv(\"/kaggle/input/jester-17m-jokes-ratings-dataset/jester_items.csv\",header = True, inferSchema = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Ratings dataset shape:\", (jester_ratings_df.count(), len(jester_ratings_df.columns)))\njester_ratings_df.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/jester-17m-jokes-ratings-dataset/jester_ratings.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/input/jester-17m-jokes-ratings-dataset/jester_items.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[\"jokeId\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(df2[\"jokeId\"].unique().tolist()) - set(df[\"jokeId\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"jokeId\"].isin([1, 2, 3, 4, 6, 9, 10, 11, 12, 14])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"rating\"].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jester_ratings_df.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Basic data exploration\n\n#### 3.1 Total number of users, movies and ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of unique users: \", jester_ratings_df.select(\"userId\").distinct().count())\nprint(\"Number of unique jokes: \", jester_ratings_df.select(\"jokeId\").distinct().count())\nprint(\"Total number of ratings: \", jester_ratings_df.count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2 Distribution of ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\nax.set_title('Ratings distribution', fontsize=15)\nsns.distplot(jester_ratings_df.toPandas()['rating'], kde=False, bins = 8,hist_kws=dict(edgecolor=\"k\", linewidth=2))\nax.set_xlabel(\"ratings in interval\")\nax.set_ylabel(\"Total number of ratings\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.3 Ratings per user"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_per_user = jester_ratings_df.groupby('userId').agg({\"rating\":\"count\"})\nratings_per_user.describe().show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Minimum number of ratings given by a user = **1**\n* Maximum number of ratings given by a user = **140**\n* Average ratings per user = **30**(after rounding)"},{"metadata":{},"cell_type":"markdown","source":"#### 3.4 Ratings per joke"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_per_joke = jester_ratings_df.groupby('jokeId').agg({\"rating\":\"count\"})\nratings_per_joke.describe().show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Minimum number of ratings to a joke = **166** \n* Maximum number of ratings to a joke = **59122**\n* Average ratings per joke = **12582**(after rounding) "},{"metadata":{},"cell_type":"markdown","source":"### 4. Train-test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test = jester_ratings_df.randomSplit([0.9,0.1])   # 90:10 ratio\nprint(\"Training data size : \", X_train.count())\nprint(\"Test data size : \", X_test.count())\nprint(\"Number of unique users in Training set\", X_train[[\"userId\"]].distinct().count())\nprint(\"Number of unique users in Test set\", X_test[[\"userId\"]].distinct().count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. ALS based recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"als = ALS(userCol=\"userId\",itemCol=\"jokeId\",ratingCol=\"rating\",rank=5, maxIter=10, seed=0)\nmodel = als.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying the latent features for five users\nmodel.userFactors.show(5, truncate = False)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.transform(X_test).show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.1 Analysing the model\n\nIt is common to have users and/or items in the test dataset that were not part of the training dataset and transform() method implementation of ALS returns **NaN** predictions for such records.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.transform(X_test).where(isnan('prediction')).show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[X_train.userId.isin([24578,54401,63338,19639,479])].show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"User with ids [24578,54401,63338,19639,479] from the test set are not available in the training dataset. Hence, the trained model does not generate latent factors for such users and the transform() method returns **NaN** predictions for them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# total number of NaN predictions\nmodel.transform(X_test).where(isnan('prediction')).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.transform(X_test[[\"userId\",\"jokeId\"]]).na.drop()[[\"prediction\"]].show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.2. Evaluating the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predictions = model.transform(X_train)\ntest_predictions = model.transform(X_test).na.drop()\nprint(\"RMSE on training data : \", evaluator.evaluate(train_predictions))\nprint(\"RMSE on test data: \", evaluator.evaluate(test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.ml.tuning import CrossValidator,ParamGridBuilder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = ParamGridBuilder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = ParamGridBuilder().addGrid(ALS.rank, [5, 6, 7, 8, 9, 10]) \\\n        .addGrid(ALS.regParam, [0.001, 0.01, 0.1, 1, 10]) \\\n        .build()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = ParamGridBuilder().addGrid(ALS.rank, [5]).build()\n        #.addGrid(ALS.regParam, [0.001]) \\\n        #.build()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = ParamGridBuilder().build()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CrossValidator(estimator=ALS(userCol=\"userId\",itemCol=\"jokeId\",ratingCol=\"rating\",coldStartStrategy=\"drop\"),estimatorParamMaps=params, evaluator=evaluator)\ncv.fit(X_train)\n#cv = cv.setNumFolds(10).setSeed(0).fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = cv.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.avgMetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.avgMetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.avgMetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.avgMetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.avgMetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator.evaluate(cv.transform(X_test).na.drop())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator.evaluate(cv.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator.evaluate(cv.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.where((X_train.userId == 5518) & (X_train.jokeId==148)).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# joining X_test and prediction dataframe and also dropping the records for which no predictions made\nratesAndPreds = X_test.join(other=predictions,on=['userId','jokeId'],how='inner').na.drop() \nratesAndPreds.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Step 5. Evaluating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting the columns into numpy arrays for direct and easy calculations \nrating = np.array(ratesAndPreds.select(\"rating\").collect()).ravel()\nprediction = np.array(ratesAndPreds.select(\"prediction\").collect()).ravel()\nprint(\"RMSE : \", np.sqrt(np.mean((rating - prediction)**2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Step 6. Recommending jokes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# recommending top 3 jokes for all the users with highest predicted rating \nmodel.recommendForAllUsers(3).show(5,truncate = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.recommendForAllUsers(3).count()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}