{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = \"../input/sms-spam-collection-dataset/spam.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(data_path, 'r', encoding=\"ISO-8859-1\") as f:\n  lines = f.readlines()\n  print(lines[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(data_path, encoding=\"ISO-8859-1\", usecols=['v1', 'v2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Target Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='v1', data=data)\nplt.show() \nprint(f\"% of Spam Obervations {data[data['v1']=='spam'].shape[0]/data.shape[0]}\")\nprint(f\"% of Non Spam Obervations {data[data['v1']=='ham'].shape[0]/data.shape[0]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing Text"},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_punctuation(x):\n  x = re.sub(r\" \", \"\", x)\n  lst_punc = re.findall(r'[^A-Za-z0-9.,/]', x)\n  return len(lst_punc)\n\ndef count_capitals(x):\n  x = re.sub(r\" \", \"\", x)\n  lst_caps = re.findall(r'^[A-Z][A-Z]+', x)\n  #print(lst_caps)\n  return len(lst_caps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_spam = data[data['v1']=='spam'].shape[0]\nnum_ham = data[data['v1']=='ham'].shape[0]\n\nnew_features = pd.DataFrame(data={\"Punct Count\":data['v2'].apply(lambda x:count_punctuation(x)),\n                                  \"Cap Count\":data['v2'].apply(lambda x:count_capitals(x)),\n                                  \"Text Len\":data['v2'].apply(lambda x:len(x))})\nnew_features['target'] = data['v1']\naverage_spam_punct_count = new_features[new_features['target']=='spam']['Punct Count'].sum()/num_spam\naverage_ham_punct_count = new_features[new_features['target']=='ham']['Punct Count'].sum()/num_ham\nprint(\"Average Number of Punctuations for Spam: {:.3f}\".format(average_spam_punct_count))\nprint(\"Average Number of Punctuations for Ham: {:.3f}\".format(average_ham_punct_count), end='\\n\\n')\n\naverage_spam_cap_count = new_features[new_features['target']=='spam']['Cap Count'].sum()/num_spam\naverage_ham_cap_count = new_features[new_features['target']=='ham']['Cap Count'].sum()/num_ham\nprint(\"Average Number of Capitals for Spam: {:.3f}\".format(average_spam_cap_count))\nprint(\"Average Number of Capitals for Ham: {:.3f}\".format(average_ham_cap_count), end='\\n\\n')\n\naverage_spam_len = new_features[new_features['target']=='spam']['Text Len'].sum()/num_spam\naverage_ham_len = new_features[new_features['target']=='ham']['Text Len'].sum()/num_ham\nprint(\"Average Text Length for Spam: {:.3f}\".format(average_spam_len))\nprint(\"Average Text Length for Ham: {:.3f}\".format(average_ham_len))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictive Modelling"},{"metadata":{},"cell_type":"markdown","source":"## Using just the numerical attributes from text"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing numerical data\n\nmm1 = MinMaxScaler()\nmm2 = MinMaxScaler()\nmm3 = MinMaxScaler()\nnew_features['Punct Count'] = mm1.fit_transform(new_features['Punct Count'].to_numpy().reshape((-1, 1)))\nnew_features['Cap Count'] = mm2.fit_transform(new_features['Cap Count'].to_numpy().reshape((-1, 1)))\nnew_features['Text Len'] = mm3.fit_transform(new_features['Text Len'].to_numpy().reshape((-1, 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_features.iloc[:, :3].to_numpy()\nlb = LabelEncoder() \nY = lb.fit_transform(new_features['target'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=2)\nfor train_index, test_index in skf.split(X, Y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = Y[train_index], Y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = lr.predict(X_test)\npred_probs = lr.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, preds))\nprint(\"AUC Score for Logistic Regression: {:.3f}\".format(roc_auc_score(y_test, pred_probs[:, 1])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using TF-IDF with Logistic Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(ngram_range=(2, 3), max_df=600, min_df=5)\ntfidf.fit(data['v2'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_feats = tfidf.transform(data['v2'].tolist())\nprint(tfidf_feats.shape)\n\n# Merge our numerical Text features(Punctuation/Capital Counts) with Tfidf features\n\nX_tf = tfidf_feats.toarray()\nX_all = np.concatenate([X_tf, X], axis=1)\nprint(X_all.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=2)\nfor train_index, test_index in skf.split(X_all, Y):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X_all[train_index], X_all[test_index]\n    y_train, y_test = Y[train_index], Y[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nlr.fit(X_train, y_train)\npreds = lr.predict(X_test)\npred_probs = lr.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, preds))\nprint(\"AUC Score: {:.3f}\".format(roc_auc_score(y_test, pred_probs[:, 1])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We definitely need to improve the recall for Spam messages and precision for ham messages can also be improved "},{"metadata":{},"cell_type":"markdown","source":"## Trying a few more classifiers and optimizing hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=300, max_depth=5)\nrf.fit(X_train, y_train)\npreds = rf.predict(X_test)\npred_probs = rf.predict_proba(X_test)\nprint(classification_report(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npreds = knn.predict(X_test)\npred_probs = knn.predict_proba(X_test)\nprint(classification_report(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(hidden_layer_sizes=(128, 256, 512))\nmlp.fit(X_train, y_train)\npreds = mlp.predict(X_test)\npred_probs = mlp.predict_proba(X_test)\nprint(classification_report(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's take two of our better classifiers - MLP and Logistic Regeression (We can also go for Knn) and try to find best hyperparameters for them before ensembing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimizing hyperparameters for Logisitic Regression classifier\n\nlr_param_dict = {\"C\":[0.001, 0.01, 0.1, 1, 10],\n                 \"max_iter\": [50, 100, 200, 500]\n                 }\nscores = ['precision', 'recall']\n\n# Using boiler plate code from Scikit-learn documentation\nfor score in scores:\n    print(\"# Tuning hyper-parameters for %s\" % score)\n    print()\n\n    clf = GridSearchCV(\n        LogisticRegression(), lr_param_dict, scoring='%s_macro' % score\n    )\n    clf.fit(X_train, y_train)\n\n    print(\"Best parameters set found on development set:\")\n    print()\n    print(clf.best_params_)\n    print()\n    print(\"Grid scores on development set:\")\n    print()\n    means = clf.cv_results_['mean_test_score']\n    stds = clf.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n        print(\"%0.3f (+/-%0.03f) for %r\"\n              % (mean, std * 2, params))\n    print()\n\n    print(\"Detailed classification report:\")\n    print()\n    print(\"The model is trained on the full development set.\")\n    print(\"The scores are computed on the full evaluation set.\")\n    print()\n    y_true, y_pred = y_test, clf.predict(X_test)\n    print(classification_report(y_true, y_pred))\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best params for Logistic Regression classifier - C : 10, max_iter : 500\n\nSkipping for MLP for now."},{"metadata":{},"cell_type":"markdown","source":"## Ensembling"},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = VotingClassifier([('lr', LogisticRegression(C=10, max_iter=500)), ('mlp', MLPClassifier(hidden_layer_sizes=(128, 256, 512)))], voting='soft')\nvc.fit(X_train, y_train)\npreds = vc.predict(X_test)\npred_probs = vc.predict_proba(X_test)\nprint(classification_report(y_test, preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AUC Score for Ensemble: {:.3f}\".format(roc_auc_score(y_test, pred_probs[:, 1])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have improved our recall a fare bit, optimizing MLP hyperparameters should improve it further. We can also try KNN/SVC for further analysis.\n\nFuture Work - \n* Try a few more classifiers.\n* Analyze important features/ feature selection.\n* Error Analysis"},{"metadata":{},"cell_type":"markdown","source":"Constructive criticism/suggesstions are welcome.\n\nHappy Kaggling!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}