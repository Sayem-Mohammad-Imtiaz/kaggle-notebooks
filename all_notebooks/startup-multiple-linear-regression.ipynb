{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-04T05:46:08.3347Z","iopub.execute_input":"2021-06-04T05:46:08.335472Z","iopub.status.idle":"2021-06-04T05:46:08.371809Z","shell.execute_reply.started":"2021-06-04T05:46:08.33529Z","shell.execute_reply":"2021-06-04T05:46:08.370672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/startup-logistic-regression/50_Startups.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:10.44209Z","iopub.execute_input":"2021-06-04T05:46:10.442533Z","iopub.status.idle":"2021-06-04T05:46:10.470066Z","shell.execute_reply.started":"2021-06-04T05:46:10.442491Z","shell.execute_reply":"2021-06-04T05:46:10.468679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:11.741983Z","iopub.execute_input":"2021-06-04T05:46:11.742337Z","iopub.status.idle":"2021-06-04T05:46:11.777799Z","shell.execute_reply.started":"2021-06-04T05:46:11.742304Z","shell.execute_reply":"2021-06-04T05:46:11.776643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this dataset we have R&D spend,Administrator, Marketing Spend and profit. Our goal is to make a model which can best predict the profit gain by which company. So Profit is our dependent variable and other features are independent variables. ","metadata":{}},{"cell_type":"code","source":"df.head(n=4)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:12.862194Z","iopub.execute_input":"2021-06-04T05:46:12.862664Z","iopub.status.idle":"2021-06-04T05:46:12.900777Z","shell.execute_reply.started":"2021-06-04T05:46:12.862624Z","shell.execute_reply":"2021-06-04T05:46:12.899628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:13.382014Z","iopub.execute_input":"2021-06-04T05:46:13.38244Z","iopub.status.idle":"2021-06-04T05:46:13.414585Z","shell.execute_reply.started":"2021-06-04T05:46:13.382389Z","shell.execute_reply":"2021-06-04T05:46:13.413361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check Null Value\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:13.901909Z","iopub.execute_input":"2021-06-04T05:46:13.902275Z","iopub.status.idle":"2021-06-04T05:46:13.912803Z","shell.execute_reply.started":"2021-06-04T05:46:13.902245Z","shell.execute_reply":"2021-06-04T05:46:13.911479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split Dataset into X and y\nX=df.drop(columns='Profit')\ny=df['Profit']\nprint(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:47:30.07316Z","iopub.execute_input":"2021-06-04T05:47:30.073625Z","iopub.status.idle":"2021-06-04T05:47:30.081666Z","shell.execute_reply.started":"2021-06-04T05:47:30.07359Z","shell.execute_reply":"2021-06-04T05:47:30.080357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['State'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:47:36.152152Z","iopub.execute_input":"2021-06-04T05:47:36.152692Z","iopub.status.idle":"2021-06-04T05:47:36.15983Z","shell.execute_reply.started":"2021-06-04T05:47:36.152635Z","shell.execute_reply":"2021-06-04T05:47:36.158549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make object type variable into numeric\n# from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n# LE=LabelEncoder()\n# df.iloc[:,3]=LE.fit_transform(df.iloc[:,3])\n# OHE=OneHotEncoder()\n# OHE.fit_transform(df[['State']]).toarray()\nX=pd.get_dummies(X,drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:47:36.947375Z","iopub.execute_input":"2021-06-04T05:47:36.947792Z","iopub.status.idle":"2021-06-04T05:47:36.958845Z","shell.execute_reply.started":"2021-06-04T05:47:36.947755Z","shell.execute_reply":"2021-06-04T05:47:36.957716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check any outlier on features having numeric values\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfor i in X.iloc[:,0:3]:\n    plt.boxplot(df[i],notch=True,patch_artist=True)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:15.922209Z","iopub.execute_input":"2021-06-04T05:46:15.92301Z","iopub.status.idle":"2021-06-04T05:46:16.374406Z","shell.execute_reply.started":"2021-06-04T05:46:15.922964Z","shell.execute_reply":"2021-06-04T05:46:16.373002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check Multicollinearity. \n#VIF=1/1-R2 (R2 is required to determine the coefficient in linear regression)\n#Greater the value of R2, greater the value of VIF. Value above 5 considers the high collinearity.\n#VIF (Variance Influation factor is the method through which we can check the multicollinearity)\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\npd.DataFrame({'Features':X.columns,'VIF':[ VIF(X.values,i) for i in range(len(X.columns))]})","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:47:46.113888Z","iopub.execute_input":"2021-06-04T05:47:46.114291Z","iopub.status.idle":"2021-06-04T05:47:46.134383Z","shell.execute_reply.started":"2021-06-04T05:47:46.114258Z","shell.execute_reply":"2021-06-04T05:47:46.133566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above table we can see that R&D Spend and Marketing Spend having little collinearity. So we are considering both feature for model building","metadata":{}},{"cell_type":"code","source":"#Split X and y into test and train\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=21)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:47:54.803491Z","iopub.execute_input":"2021-06-04T05:47:54.80396Z","iopub.status.idle":"2021-06-04T05:47:54.811927Z","shell.execute_reply.started":"2021-06-04T05:47:54.803929Z","shell.execute_reply":"2021-06-04T05:47:54.811244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel_mlr=LinearRegression()\nmodel_mlr.fit(X_train,y_train)\nprint(model_mlr.coef_)\nprint(model_mlr.intercept_)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:17.961831Z","iopub.execute_input":"2021-06-04T05:46:17.962364Z","iopub.status.idle":"2021-06-04T05:46:18.108625Z","shell.execute_reply.started":"2021-06-04T05:46:17.962308Z","shell.execute_reply":"2021-06-04T05:46:18.107241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model_mlr.predict(X_test)\nx_pred=model_mlr.predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:18.612128Z","iopub.execute_input":"2021-06-04T05:46:18.612566Z","iopub.status.idle":"2021-06-04T05:46:18.622222Z","shell.execute_reply.started":"2021-06-04T05:46:18.612521Z","shell.execute_reply":"2021-06-04T05:46:18.621011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check model performance for traina and test\nfrom sklearn.metrics import mean_squared_error\ntrain_score=model_mlr.score(X_train,y_train)\ntest_score=model_mlr.score(X_test,y_test)\nprint(train_score)\nprint(test_score)\nprint(f\"RMSE score of training dataset is : {np.sqrt(mean_squared_error(y_train,x_pred))}\")\nprint(f\"RMSE score of testing dataset is {np.sqrt(mean_squared_error(y_test,y_pred))}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:19.202239Z","iopub.execute_input":"2021-06-04T05:46:19.202656Z","iopub.status.idle":"2021-06-04T05:46:19.216713Z","shell.execute_reply.started":"2021-06-04T05:46:19.202619Z","shell.execute_reply":"2021-06-04T05:46:19.215549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test this model with unseen or new data\n[110221,120223,423112,0,0,1]\nnp.round(model_mlr.predict(np.array([[110221,120223,423112,1,0]])),2)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:19.742591Z","iopub.execute_input":"2021-06-04T05:46:19.742995Z","iopub.status.idle":"2021-06-04T05:46:19.751372Z","shell.execute_reply.started":"2021-06-04T05:46:19.742961Z","shell.execute_reply":"2021-06-04T05:46:19.750311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The difference between train score and test score is {test_score-train_score}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:46:20.812126Z","iopub.execute_input":"2021-06-04T05:46:20.812691Z","iopub.status.idle":"2021-06-04T05:46:20.818366Z","shell.execute_reply.started":"2021-06-04T05:46:20.812652Z","shell.execute_reply":"2021-06-04T05:46:20.817517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To minimize the difference we have to use \"Backward Elimination\", this method provides the importance features which gives the good prediction result. ","metadata":{}},{"cell_type":"code","source":"#Preparation of Backward Elimination\nimport statsmodels.api as sma\n\n#Here we have to manually add b0 which is constant features in MLR but not associated with any of the column\ndataset=X.copy()\ndataset['x0']=np.ones((len(X),1),dtype='int')\n#Now we will choose all columns and fit them into OLS and then check which p-value is greater than SL value (0.05)\ndataset_opt=dataset.iloc[:,[5,3,4,0,1,2]]\nsma_ola=sma.OLS(endog=y,exog=dataset_opt).fit()\nsma_ola.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T06:31:05.449573Z","iopub.execute_input":"2021-06-04T06:31:05.449913Z","iopub.status.idle":"2021-06-04T06:31:05.475194Z","shell.execute_reply.started":"2021-06-04T06:31:05.449885Z","shell.execute_reply":"2021-06-04T06:31:05.474284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above OLS method we can see that feature \"State_Florida\",\"State New York\" and \"Administration\" having high p value which is greater than SL of 0.05. So we will remove those features and prepare a model","metadata":{}},{"cell_type":"code","source":"dataset_opt=dataset_opt.iloc[:,[0,3,5]]\nsma_ola=sma.OLS(y,dataset_opt).fit()\nsma_ola.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T06:32:08.263621Z","iopub.execute_input":"2021-06-04T06:32:08.264013Z","iopub.status.idle":"2021-06-04T06:32:08.289113Z","shell.execute_reply.started":"2021-06-04T06:32:08.263981Z","shell.execute_reply":"2021-06-04T06:32:08.287791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R&D spend also having high p value which is greater than SL value of 0.05. So we need to remove this. ","metadata":{}},{"cell_type":"code","source":"dataset_opt=dataset_opt[['x0','R&D Spend']]\nresults=sma.OLS(y,dataset_opt).fit()\nresults.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T06:37:46.283607Z","iopub.execute_input":"2021-06-04T06:37:46.284089Z","iopub.status.idle":"2021-06-04T06:37:46.312169Z","shell.execute_reply.started":"2021-06-04T06:37:46.284059Z","shell.execute_reply":"2021-06-04T06:37:46.311065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make the model using this feature and see what is the difference we are getting\n#Extract X and y from dataframe (Here we are using only R&D as independent variable)\n\nX=df.iloc[:,[0]].values\ny=df.iloc[:,-1].values\n\n#Split X and y into test and train\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=21)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n#Make model\nfrom sklearn.linear_model import LinearRegression\nmodel_mlr=LinearRegression()\nmodel_mlr.fit(X_train,y_train)\nprint(model_mlr.coef_)\nprint(model_mlr.intercept_)\n\ny_pred=model_mlr.predict(X_test)\nx_pred=model_mlr.predict(X_train)\n\n#Check model performance for traina and test\nfrom sklearn.metrics import mean_squared_error\ntrain_score=model_mlr.score(X_train,y_train)\ntest_score=model_mlr.score(X_test,y_test)\nprint(train_score)\nprint(test_score)\nprint(f\"RMSE score of training dataset is : {np.sqrt(mean_squared_error(y_train,x_pred))}\")\nprint(f\"RMSE score of testing dataset is {np.sqrt(mean_squared_error(y_test,y_pred))}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T06:46:34.900963Z","iopub.execute_input":"2021-06-04T06:46:34.901327Z","iopub.status.idle":"2021-06-04T06:46:34.919157Z","shell.execute_reply.started":"2021-06-04T06:46:34.901296Z","shell.execute_reply":"2021-06-04T06:46:34.917669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The difference between train score and test score is {test_score-train_score}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T06:47:32.708333Z","iopub.execute_input":"2021-06-04T06:47:32.708731Z","iopub.status.idle":"2021-06-04T06:47:32.714078Z","shell.execute_reply.started":"2021-06-04T06:47:32.708695Z","shell.execute_reply":"2021-06-04T06:47:32.712943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}