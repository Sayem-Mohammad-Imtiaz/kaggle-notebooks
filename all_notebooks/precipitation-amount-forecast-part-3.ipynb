{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# An analysis regarding the prediction of precipitation amount in Seattle provided by an Atmospheric Scientist\n\n## Objective:\n\n- The customer would like to know the predicted precipitation amount on a specific day by using MLAs.\n\n- The input dataset (seattleWeather_1948-2017.csv) provides information on a few Meteorological variables in Seattle from 1948 to 2017. \n\n- The input variables (predictors) are: Date, RAIN, TMAX, and TMIN. The last three are numerical continuous variables. RAIN is boolean.\n\n- The outcome or dependent variable is: PRCP (continuous)\n\n- In part 1 and part 2, I predicted the likelihood of whether it rains or not using feature engineering and the MLAs hyperparameters tuning, and achieved an accuracy score of 83%.\n\n- Here, (part 3), I will examine the precipitation amount forecast which is much more challenging.\n \n\n### Importing important libraries:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport os\n\nfrom pandas import Series, DataFrame\nfrom pylab import rcParams\nfrom sklearn import preprocessing\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LinearRegression\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df = pd.read_csv('/kaggle/input/did-it-rain-in-seattle-19482017/seattleWeather_1948-2017.csv')\nprint(met_df.head()); print(); print()\nmet_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The description and unit of each variable:\n- DATE = the date of the observation\n- PRCP = the amount of precipitation, in inches\n- TMAX = the maximum temperature for that day, in degrees Fahrenheit\n- TMIN = the minimum temperature for that day, in degrees Fahrenheit\n- RAIN = TRUE if rain was observed on that day, FALSE if it was not"},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaing:\n\n### Step 1: Correcting wrong values or outliers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data description makes sense, and the mean, min, and max values of each variable are reasonable, meaning there should not be a mistake in the data (such as a very large temperature of 200 F)."},{"metadata":{},"cell_type":"markdown","source":"### Step 2: Imputing missing values (necessary for linear regression):\n\nThere are only three missing data points for each PRCP and RAIN. So, we use median for PRCP to fill in the gaps."},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_median = met_df.PRCP.median()\nmet_df.PRCP.fillna(P_median, inplace = True)\nmet_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3: Dropping binary (boolean) variable (necessary for linear regression):\n- The outcome is continuous, so we drop RAIN which is binary."},{"metadata":{"trusted":true},"cell_type":"code","source":"met_df.drop('RAIN', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 4: Change DATE variable to datetime format:"},{"metadata":{"trusted":true},"cell_type":"code","source":"date = pd.to_datetime(met_df.DATE, format=\"%Y-%m-%d\")\nmet_df['DATE'] = date\nmet_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 5: feature engineering:\n\n- As seen in previous parts, precipitation amount and temperature are poorly correlated, but we extract new features from those two that will likely have a much higher correlation.\n\n- Imagine today is 4 Jan. 2018. We can expect that the PRCP is close to the average PRCP on 4 Jan. in all previous years. So, we calculate a new variable: daily_PRCP (average PRCP on a specific day for all years).\n\n- Similarly, we calculate other new variables: daily_TMAX (average TMAX on a specific day for all years) and daily_TMIN. We hope that daily_PRCP would be highly correlated with daily_TMAX and daily_TMIN."},{"metadata":{"trusted":true},"cell_type":"code","source":"## daily TMAX\nfrom datetime import datetime\nDoY_str = met_df.DATE.dt.strftime('%j')\nDay_of_Year = [int(a) for a in DoY_str]\n#group data based on \"day of year\"\ngroupD      = met_df.groupby(Day_of_Year)\nDoY_TMAX   = groupD['TMAX'].mean()  # daily climatological mean TMAX\ndaily_TMAX = [DoY_TMAX[a] for a in Day_of_Year]\n\n## daily TMIN\nDoY_TMIN   = groupD['TMIN'].mean()  # daily climatological mean TMIN\ndaily_TMIN = [DoY_TMIN[a] for a in Day_of_Year]\n\n\n## daily PRCP\n#group data based on \"day of year\"\nDoY_PRCP   = groupD['PRCP'].mean()  # daily climatological mean PRCP\ndaily_PRCP = [DoY_PRCP[a] for a in Day_of_Year]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add all these new variables to DataFrame:\ndaily_PRCP_df  = pd.DataFrame(daily_PRCP,  columns = ['daily_PRCP'])\ndaily_TMAX_df  = pd.DataFrame(daily_TMAX,  columns = ['daily_TMAX'])\ndaily_TMIN_df  = pd.DataFrame(daily_TMIN,  columns = ['daily_TMIN'])\n\nmet_new_df = pd.concat([met_df['DATE'],met_df['PRCP'],met_df['TMAX'],met_df['TMIN'],\n                        daily_TMAX_df,daily_TMIN_df,daily_PRCP_df], axis = 1)\n\nmet_new_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nWe will verify that Linear Regression assumptions are met:\n- All variables are continuous numeric, and not categorical.\n- Data is free of outliers and missing values.\n- A linear relationship exists between each predictor and the response.\n- All predictors are independent of each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nrcParams['figure.figsize'] = 10, 8\nsb.set_style('whitegrid')\n\nsb.pairplot(met_new_df, palette = 'husl')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at the distribution of variables in the above pair-plots, we can say that all the variables are continuous numeric (necessary for linear regression)."},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 8, 6\nsb.heatmap(met_new_df.corr(), vmin=-1, vmax=1, annot=True, cmap = 'RdBu_r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The new variabels extracted via feature engineering appear to be very useful.\n- Unlike very low correlation between PRCP and TMAX (or TMIN), daily_PRCP is highly correlated with daily_TMAX and daily_TMIN.\n- We should also note that daily_TMAX, daily_TMIN, TMAX, and TMIN are highly correlated. So, we need to drop all but one of them, because features should be independent of each other in linear regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axis = plt.subplots(1, 3,figsize=(16,5))\nsb.scatterplot(x = 'daily_TMAX', y ='daily_PRCP', data = met_new_df, ax = axis[0])\nsb.scatterplot(x = 'daily_TMIN', y ='daily_PRCP', data = met_new_df, ax = axis[1])\nsb.scatterplot(x = 'daily_TMAX', y ='daily_TMIN', data = met_new_df, ax = axis[2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- By looking at left and middle panels, we can verify that definitely there is a linear relationship between daily_TMAX and daily_PRCP, and between daily_TMIN and daily_PRCP. Also, there is no ovious outlier in both panels.\n\n- As expected, daily_TMAX and daily_TMIN are not independent: this means that there are factors such as season, weather systems and sky cloudiness that affect both of them. We will drop daily_TMIN, because it is not independent of daily_TMAX, and it also has lower correlation with daily_PRCP.\n\n----\nThe relationships among daily_TMAX, daily_TMIN and daily_PRCP can be understood as seasonal cycle of weather and climate. It is shown in the below plot. But we don't use the variable \"day of year\" in the Linear Regression model, because its relation with other variables is not linear, and the linear correlation between \"day of year\" and each of the three variables is very low."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(8,6))\nax2 = ax1.twinx()\nax1.scatter(Day_of_Year, daily_TMAX, c='purple')\nax1.scatter(Day_of_Year, daily_TMIN, c='orange')\nax2.scatter(Day_of_Year, daily_PRCP, c='g')\nplt.grid(False)\nax1.set_xlabel('Day of year', fontsize=14)\nax1.set_ylabel('daily_TMAX & daily_TMIN', fontsize=14)\nax2.set_ylabel('daily_PRCP', fontsize=16, c='g')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n---\nWe keep daily_TMAX as predictor and daily_PRCP as outcome. Other variables should be dropped:"},{"metadata":{"trusted":true},"cell_type":"code","source":"met_new_df.drop(['DATE','PRCP','TMIN','TMAX','daily_TMIN'], inplace = True, axis=1)\nmet_new_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing the linear regression model:\n\n\n### Spliting the data into test and train sets:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(met_new_df['daily_TMAX'].values.reshape(-1, 1),\n                                                   met_new_df['daily_PRCP'], test_size=0.2, random_state=10)                             \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression Model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Lin_Reg = LinearRegression()\nLin_Reg.fit(X_train, Y_train)\nR_squared_train = Lin_Reg.score(X_train, Y_train)\nprint(R_squared_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The score vlaue is the R square of the prediction. It's a measure of how well the prediction from our linear regression model actually matches the real values.\n\n- Let's retrieve coefficient and intercept of our linear model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Lin_Reg.coef_[0], Lin_Reg.intercept_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The equation for linear regression:\n\ndaily_PRCP = daily_TMAX * LinReg.coef[0] + LinReg.intercept_\n\nWe plot our regression model and see how it fits the train dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"T = np.array(range(42,79))\nP = Lin_Reg.coef_[0] *  T + Lin_Reg.intercept_\n\nfig, ax1 = plt.subplots(figsize=(8, 6))\nplt.plot(T, P, color = 'purple', lw = 3)\nplt.scatter(X_train, Y_train, c = 'orange')\n\nax1.set_xlabel('daily_TMAX', fontsize=14)\nax1.set_ylabel('daily_PRCP', fontsize=14)\n\nTITLE1 = 'Train dataset: daily_PRCP = %.4f'% Lin_Reg.coef_\nTITLE2 = ' * daily_TMAX + %.4f, ' %Lin_Reg.intercept_\nTITLE3 = 'R-squared = %.3f'% R_squared_train\nTITLE = TITLE1 + TITLE2 + TITLE3\nax1.set_title(TITLE, fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Validation:\n\nWe would like to see how our model predicts the test dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"R_squared_test = Lin_Reg.score(X_test, Y_test)\nprint(R_squared_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So, this model has a score value of 77% for test dataset, meaning that it can predict daily_PRCP from daily_TMAX correctly in 77% of the times for test dataset.\n\n- We explore the prediction by plotting predicted daily_PRCP vs. test daily_PRCP:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = Lin_Reg.predict(X_test)\n\nT = [0, 0.1, 0.2, 0.28]\n\nfig, ax1 = plt.subplots(figsize=(7, 7))\nplt.plot(T, T, color = 'b', lw = 3)\nplt.scatter(Y_test, Y_pred, c = 'g')\n\nax1.set_xlabel('test daily_PRCP', fontsize=14)\nax1.set_ylabel('predicted daily_PRCP', fontsize=14)\n\nTITLE = 'test R-squared = %.3f'% R_squared_test\nax1.set_title(TITLE, fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So it seems that the model works well for low values of daily_PRCP. However, when daily_PRCP is greater than 0.2 in., the model under-predict daily_PRCP. This means that daily_TMAX might not be very good at predicting daily_PRCP for high values of daily_PRCP.\n- This is due to the nature of weather processes: TMAX is more dependent of cloudiness, but the higher amount of precipitation does not really affect TMAX.\n- Note that we will not use nonlinear models, because our data does not show nonlinear pattern. The use of nonlinear models in this case would lead to over-fitting problem."},{"metadata":{},"cell_type":"markdown","source":"### K-fold cross-validation\n\nWe use this validation to make sure the accuracy score is not dependent on the train-test split. In other words, we want to verify that the train-test split is random."},{"metadata":{"trusted":true},"cell_type":"code","source":"CV_scores = cross_val_score(Lin_Reg.fit(X_train, Y_train), X_test, Y_test, cv=5)\nprint ('5-fold cross-validation: scores = ')\nprint(CV_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So, the scores from cross-validation do not vary much, and range between 0.752 and 0.774"},{"metadata":{"trusted":true},"cell_type":"code","source":"CV_prediction = cross_val_predict(Lin_Reg.fit(X_train, Y_train), X_test, Y_test, cv=5)\nCV_R_squared = metrics.r2_score(Y_test, CV_prediction)\nCV_R_squared","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cross-validation determines that the model can predict correctly in 76% of the times."},{"metadata":{},"cell_type":"markdown","source":"## Discussion:\n\n- By using the Linear Regression Model, we reach an accuracy score of 76.5%, which means that our model at best can predict precipitation amount correctly in 76.5% of times for the test dataset.\n\n- Using cross-validation, we showed that our results are independent of the train-test split.\nfurther enhancement of score needs more features and more data.\n\n- Note that I dropped the variable 'RAIN' to avoid high accuracy that would be wrong and misleading: 'RAIN' and 'PRCP' are strongly related.\n----\n\n### Future Work:\nIn the future, I will use additional features (variables such as wind, pressure, El Nino index, Atmospheric River index, and so on), use data for a longer time range, and employ more feature engineering to improve the prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}