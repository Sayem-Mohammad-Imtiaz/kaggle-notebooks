{"cells":[{"metadata":{"id":"Jss9SOnVpOqF"},"cell_type":"markdown","source":"# Import"},{"metadata":{"id":"a4mocddmRLmQ","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom scipy import sparse\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{"id":"uFOVwsoHqxOb","trusted":true},"cell_type":"code","source":"class ProprecessingData:\n  def load_data(self) -> pd.DataFrame:\n    \"\"\"\n    Read file csv withd pandas\n    \"\"\"\n    name = [\"URL\", \"category\"]\n    path_file = '../input/url-classification-dataset-dmoz/URL Classification.csv'\n    df = pd.read_csv(path_file, names=name, na_filter=False)\n    X = df[\"URL\"]\n    y = df[\"category\"]\n    \n    return X, y\n  def split_data(self, test_size) -> pd.DataFrame:\n    \"\"\"\n    Spilit data into train set and test set\n    \"\"\"\n    X, y = self.load_data()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n\n    \n    return X_train, X_test, y_train, y_test\n  def tfidf_train(self, X_train: pd.DataFrame) -> sparse.csr.csr_matrix:\n    \"\"\"\n    Fit X for TFIDF\n    Output : Vector TIFIDF type csr_matrix\n    \"\"\"\n    self.vectorizer = CountVectorizer(stop_words = ['http', 'www', 'com', 'net',\n                                                    'org', 'jp', 'bc', \n                                                    'html', 'htm', 'index'])\n    word_count_vector = self.vectorizer.fit_transform(X_train)\n    self.tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True) \n    tf_idf_vector = self.tfidf_transformer.fit_transform(word_count_vector)\n    \n    return tf_idf_vector\n  def tfidf_test(self, X_test: pd.DataFrame) -> sparse.csr.csr_matrix:\n    \"\"\"\n    Fit X for TFIDF\n    Output : Vector TIFIDF type csr_matrix\n    \"\"\"\n    word_count_vector_test = self.vectorizer.transform(X_test)\n    tf_idf_vector_test = self.tfidf_transformer.transform(word_count_vector_test)\n    return tf_idf_vector_test","execution_count":null,"outputs":[]},{"metadata":{"id":"M1-q3Zt5zg_-","trusted":true},"cell_type":"code","source":"propre_data = ProprecessingData()\nX_train, X_test, y_train, y_test = propre_data.split_data(0.2)","execution_count":null,"outputs":[]},{"metadata":{"id":"dsbFu4jX0r3G","trusted":true},"cell_type":"code","source":"tf_idf_vector = propre_data.tfidf_train(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"phwGbbzX09dT","trusted":true},"cell_type":"code","source":"tf_idf_vector_test = propre_data.tfidf_test(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"so3jyac-pE5v"},"cell_type":"markdown","source":"# Visualize Data"},{"metadata":{"id":"NUokzYyUhhoS","outputId":"d5709020-1bbc-40ca-c9f8-6aa7904e7c81","trusted":true},"cell_type":"code","source":"labels = ['Adult', 'Arts', 'Business', 'Computers', 'Games', 'Health', 'Home', 'Kids',\n          'News', 'Recreation', 'Reference', 'Science', 'Shopping', 'Society', 'Sports']\nlabels_count = np.unique(y_train, return_counts=True)\nfig, ax = plt.subplots(figsize=(20, 8))\nax.bar(labels_count[0], labels_count[1], 0.5, tick_label=labels, color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Peb_15jhor9Q","outputId":"e9f74878-ae1b-450e-d574-649351ae9177","trusted":true},"cell_type":"code","source":"labels = ['Adult', 'Arts', 'Business', 'Computers', 'Games', 'Health', 'Home', 'Kids',\n          'News', 'Recreation', 'Reference', 'Science', 'Shopping', 'Society', 'Sports']\nlabels_count = np.unique(y_test, return_counts=True)\nfig, ax = plt.subplots(figsize=(20, 8))\nax.bar(labels_count[0], labels_count[1], 0.5, tick_label=labels, color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"12DsXqaXvH-n"},"cell_type":"markdown","source":"We notice here that the data is unbalanced, uneven between the class labels."},{"metadata":{"id":"6ajWzSizsrPW","outputId":"fc1aac60-422c-4e7c-87b9-1abc3e6a571b","trusted":true},"cell_type":"code","source":"print(tf_idf_vector_test.shape)\nprint(type(tf_idf_vector_test))","execution_count":null,"outputs":[]},{"metadata":{"id":"Hr1iX5XU2GcB"},"cell_type":"markdown","source":"The shape and data type of data when converted to tf_idf is csr_matrix."},{"metadata":{"id":"z20D9VzsxWls"},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"id":"SWJSUAPhSpxX","trusted":true},"cell_type":"code","source":"class MultinomialNB:\n  def __init__(self, alpha: float=1.0):\n    self.alpha = alpha\n  def fit(self, X_train: pd.DataFrame, y_train: pd.DataFrame):\n    \"\"\"\n    Fit data training to Naive Bayes\n    Input: X_train: type csr_matrix \n    y_train: list\n    \"\"\"\n    m, n = X_train.shape\n    self._classes = np.unique(y_train)\n    # Count class\n    n_classes = len(self._classes)\n    # Init matrix prior,likelihood\n    self._priors = np.zeros(n_classes)\n    self._likelihood = np.zeros((n_classes, n))\n    for idx, c in enumerate(self._classes):\n      bool_c = np.array(c==y_train)\n      # Data of class c\n      X_train_c = X_train[bool_c]\n      # Caculate prior and likelihood\n      self._priors[idx] = (X_train_c.shape[0] / m)\n      self._likelihood[idx,:] =  np.log((X_train_c.sum(axis=0) + self.alpha) / np.sum((X_train_c.sum(axis=0) + self.alpha)))\n  def cal_c_likelihood(self, c_likeli, x_test):\n    \"\"\"\n    Calculate multi likelihood of class c with x test\n    \"\"\"\n    return x_test * np.log(c_likeli)[:, np.newaxis]\n  def _predict(self, x_test) -> list:\n    \"\"\"\n    Calculate sum likelihood and prior of class c.\n    Argmax class c have posteriors.\n    \"\"\"\n    posteriors = []\n    for idx, c in enumerate(self._classes):\n      prior_c = np.log(self._priors[idx])\n      likelihood_c = x_test * self._likelihood[idx, :]\n      posteriors_c = np.sum(likelihood_c) + prior_c\n      posteriors.append(posteriors_c)\n    return self._classes[np.argmax(posteriors)]\n  def predict(self, X_test) -> list:\n    \"\"\"\n    predict output for X test\n    Input: csr_matrix\n    Output: list\n    \"\"\"\n    return [self._predict(x_test) for x_test in tqdm(X_test)]","execution_count":null,"outputs":[]},{"metadata":{"id":"PfS0AS0rNSxM","trusted":true},"cell_type":"code","source":"clf = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"id":"cRgDHI03FdDY","trusted":true},"cell_type":"code","source":"clf.fit(tf_idf_vector, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ca453NGGYlSE","outputId":"9b026768-486f-4c0f-c15a-43f006c38554","trusted":true},"cell_type":"code","source":"y_pred = clf.predict(tf_idf_vector_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Sz-UvK4fwwcb","outputId":"1df9ce2b-424f-46f5-e6c6-dda1f8c3ade7","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ntarget_names = np.unique(y_test)\nprint(classification_report(y_test, y_pred, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"id":"M3lPpDRk4iYE"},"cell_type":"markdown","source":"The method is straight forward. Just take the average of the precision and recall of the system on different sets.\nA weighted average is the average of a data set that recognizes certain numbers as more important than others.\n"},{"metadata":{"id":"RXQnv7h63cjo"},"cell_type":"markdown","source":"The model's Accuracy is: 0.38 but the f1-score of some very low classes is like News=0.0 and shopping=0.02. That the model has not predicted the classes with little data"},{"metadata":{"id":"3O_mwMU8wAft","outputId":"96a94219-dcd3-421d-82f8-65cfcbe7d4ea","trusted":true},"cell_type":"code","source":"array = confusion_matrix(y_test, y_pred)\ncm=np.array(array)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\ndf_cm = pd.DataFrame(cm, index = [i for i in \"0123456789ABCDE\"],\n                  columns = [i for i in \"0123456789ABCDE\"])\nplt.figure(figsize = (20,15))\nsns.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}