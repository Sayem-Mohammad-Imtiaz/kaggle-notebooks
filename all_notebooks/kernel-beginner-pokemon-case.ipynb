{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # for visualization \n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\",\"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/pokemon.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation map\nf,ax = plt.subplots(figsize = (18,8))\nsns.heatmap(data.corr(),annot = True,linewidths = 5, fmt = '.1f',linecolor  = 'green' , ax = ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 1. INTRODUCTION TO PYTHON¶\n\n\nMATPLOTLIB\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n1. Line plot is better when x axis is time.\n2. Scatter is better when there is correlation between two variables\n3. .Histogram is better when we need to see distribution of numerical data.\n4. Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'Line',color = 'green',label = 'Speed',linewidth = 1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth = 1,alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc = 'upper right') # legend puts label into plot\nplt.xlabel('X axis')\nplt.ylabel('Y axis')\nplt.title('Line Plot')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defence')\nplt.title('Attack Defense Scatter Plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (15,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DICTIONARY¶\nWhy we need dictionary?\n\nIt has 'key' and 'value'\nFaster than lists \nWhat is key and value. Example:\ndictionary = {'spain' : 'madrid'}\nKey is spain.\nValues is madrid. \n\nIt's that easy. \nLets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to run all code you need to take comment this line\n# del dictionary         # delete entire dictionary     \nprint(dictionary)       # it gives error because dictionary is deleted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PANDAS\nWhat we need to know about pandas?\n\nCSV: comma - separated values"},{"metadata":{"trusted":true},"cell_type":"code","source":"Series = data['Defense']\nprint(type(Series))\ndata_frame = data[['Defense']]\nprint(type(data_frame))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before continue with pandas, we need to learn logic, control flow and filtering. \nComparison operator: ==, <, >, <= \nBoolean operators: and, or ,not \nFiltering pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison operator\nprint(3 > 2)\nprint(3!=2)\n# Boolean operators\nprint(True and False)\nprint(True or False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 Filtering pandas Data Frame\nx= data['Defense']>200 ## There are only three pokemon who have higher defense than 200\ndata[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2 Filtering pandas with logical and\n# There are only two pokemon who have defense greater than 200 and attack greater than 100\n data[(data['Defense']>200) & (data['Attack']>100)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"WHILE and FOR LOOPS¶\nWe will learn most basic while and for loops"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition (i is not equal 5 )is true\ni = 0\nwhile i != 5:\n    print ('i is : ',i)\n    i += 1\nprint(i , 'is equal to 5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition (i is not equal to 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is :' ,i)\nprint('')\n\n## Enumerate index and value of list \n# index  : value  = 0:1,1:2,2:3,3:4\nfor index ,value in enumerate(lis):\n    print(index,\": \",value)\nprint('')\n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index , value in data[['Attack']][0:2].iterrows():\n    print(index,\";\",value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. In this part, you learn:\n\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always used and main for being data scientist\n* While and for loops"},{"metadata":{},"cell_type":"markdown","source":"2. PYTHON DATA SCIENCE TOOLBOX\n\n\nUSER DEFINED FUNCTION\nWhat we need to know about functions:\n docstrings: documentation for functions. Example: \nfor f(): \n\"\"\"This is docstring for documentation of function f\"\"\"\n\ntuble: sequence of immutable python objects. \ncant modify values \ntuble uses paranthesis like tuble = (1,2,3) \nunpack tuble into several variables like a,b,c = tuble"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuble_ex():\n    \"\"\" return defined t tube\"\"\"\n    t = (1,2,3)\n    return t\na ,b,c = tuble_ex()\nprint(a,b,c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SCOPE¶\nWhat we need to know about scope:\n\nglobal: defined main body in script\nlocal: defined in a function\nbuilt in scope: names in predefined built in scope module such as print, len \n\nLets make some basic examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"# guess print what\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x)      # x = 2 global scope\nprint(f())    # x = 3 local scope","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What if there is no local scope\nx = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NESTED FUNCTION¶\n* function inside function.\n* There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Nested function\ndef square():\n    \"\"\"return square of value\"\"\"\n    def add():\n        \"\"\"add two local variable\"\"\"\n        x =2 \n        y = 3\n        z = x+y\n        return z\n    return add()**2\n\nprint(square())\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DEFAULT and FLEXIBLE ARGUMENTS¶\nDefault argument example: \n* def f(a, b=1):\n  \"\"\" b = 1 is default argument\"\"\"\n* Flexible argument example: \n* def f(*args):\n \"\"\" *args can be one or more\"\"\"\n\n* def f(** kwargs)\n \"\"\" **kwargs is a dictionary\"\"\"\n\n\nlets write some code to practice"},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(3))\n# what if we want to change default arguments\nprint(f(5,4,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(3)\nprint(\"\")\nf(1,2,3,4)\n\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\"print key and value of dictionary\"\"\"\n    for key,value in kwargs.items():\n        print(key ,\":\",value)\nf(country = 'spain',capital = 'madrid',population = 123456)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nLAMBDA FUNCTION\nFaster way of writing function"},{"metadata":{"trusted":true},"cell_type":"code","source":"square = lambda x: x**2 # where x is the name of argument\nprint(square(4))\ntot = lambda x,y,z : x+y+z\nprint(tot(2,3,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANONYMOUS FUNCTİON\n* Like lambda function but it can take more than one arguments.\n* \n* map(func,seq) : applies a function to all the items in a list"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_list = [1,2,3]\ny = map(lambda x : x**2,number_list)\nprint(list(y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nITERATORS\n* iterable is an object that can return an iterator\n* iterable: an object with an associated iter() method \n* example: list, strings and dictionaries\n* iterator: produces next value with next() method"},{"metadata":{"trusted":true},"cell_type":"code","source":"# iteration example\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(*it)         # print remaining iteration","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"zip(): zip lists"},{"metadata":{"trusted":true},"cell_type":"code","source":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nlist3 = [9,10,11,12]\nz = zip(list1,list2,list3)\nprint(z)\nz_list = list(z)\nprint(z_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"un_zip = zip(*z_list)\nprint(un_zip)\nun_list1,un_list2,un_list3 = list(un_zip) # unzip returns tuble\nprint(un_list1)\nprint(un_list2)\nprint(un_list3)\nprint(type(un_list2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LIST COMPREHENSİON¶\n* One of the most important topic of this kernel \n* We use list comprehension for data analysis often. \n* list comprehension: collapse for loops for building lists into a single line \n* Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long. We can make it one line code that is list comprehension."},{"metadata":{"trusted":true},"cell_type":"code","source":"num1 = [1,2,3]\nnum2 = [i +1 for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* [i + 1 for i in num1 ]: list of comprehension \n* i +1: list comprehension syntax \n* for i in num1: for loop syntax \n* i: iterator \n* num1: iterable object"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\nnum1 = [5,10,15,6]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed)/len(data.Speed)\ndata[\"speed_level\"] = ['high' if i > threshold else 'low' for i in data.Speed]\ndata.loc[:10,['speed_level','Speed']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Up to now, you learn\n\n* User defined function\n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n* Anonymous function\n* Iterators\n* List comprehension"},{"metadata":{},"cell_type":"markdown","source":"**3. Cleaning Data**"},{"metadata":{},"cell_type":"markdown","source":"DIAGNOSE DATA for CLEANING¶\n\nWe need to diagnose and clean data before exploring. \nUnclean data:\n\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/pokemon.csv')\ndata.head()  # head shows first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tail shows last 5 rows\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns gives column names of features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape gives number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nEXPLORATORY DATA ANALYSIS\n\nvalue_counts(): Frequency counts \noutliers: the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR \n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\nWhat is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in middle of the sequence. In this case it would be 11.\n* \n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* \n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna = False ))\n# if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VISUAL EXPLORATORY DATA ANALYSIS¶\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TIDY DATA¶\n* We tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nPIVOTING DATA\nReverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CONCATENATING DATA\nWe can concatenate two dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis = 0,ignore_index = True)\n# axis = 0 : adds dataframes in row \nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in column i.e joining done by column \nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DATA TYPES¶\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical. \n* We can make conversion data types like from str to categorical or from int to float \n* Why is category important:\n* \n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklearn(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MISSING DATA and TESTING WITH ASSERT¶\n\nIf we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean \n* Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check Type 2\ndata[\"Type 2\"].value_counts(dropna = False)\n# As you can see , there are 386 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?\ndata1[\"Type 2\"].value_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true\n# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Type 2\"].fillna('empty',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Type 2'].value_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, you learn:\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert"},{"metadata":{},"cell_type":"markdown","source":"4. PANDAS FOUNDATION\n\n\nREVİEW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n\n\nBUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n* zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\nprint(zipped)\ndata_dict = dict(zipped)\nprint(data_dict)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting\ndf[\"income\"] = 0 # Broadcasting entire column\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nVISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n * bins: number of bins\n * range(tuble): min and max values of bins\n * normed(boolean): normalize or not\n * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting all data\ndata1 = data.loc[:,['Attack','Defense','Speed']]\ndata1.plot()\n# it is confusing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram subplot with non cummulative and cummulative\nfig ,axes = plt.subplots(nrows = 2,ncols = 1)\ndata1.plot(kind = \"hist\", y = \"Defense\",bins = 50,range = (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n\n*     count: number of entries\n*     mean: average of entries\n*     std: standart deviation\n*     min: minimum entry\n*     25%: first quantile\n*     50%: median or second quantile\n\n*     75%: third quantile\n* max: maximum entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nINDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1]))\n# As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Close Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object= pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make data as index\ndata2 = data2.set_index(\"date\")\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RESAMPLING PANDAS TIME SERIES¶\n* Resampling: statistical method over different time intervals\n* Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’\n* https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MANIPULATING DATA FRAMES WITH PANDAS¶\n\n\n\nINDEXING DATA FRAMES\n\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/pokemon.csv')\ndata = data.set_index('#')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata[\"HP\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.HP[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1,[\"HP\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\ndata[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nSLICING DATA FRAME\n* Difference between selecting columns\n* Series and data frames\n* Slicing and indexing series\n* Reverse slicing\n* From something to end"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\ndata.loc[1:10,\"Speed\":]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nFILTERING DATA FRAMES\n\nCreating boolean series Combining filters Filtering column based others"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.HP > 200\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering column based others\ndata.HP[data.Speed<15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nTRANSFORMING DATA\n\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\ndata.HP.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\ndata.HP.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining column using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"INDEX OBJECTS AND LABELED DATA¶\n\nindex: sequence of label"},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HIERARCHICAL INDEXING¶\n\nSetting indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('../input/pokemon.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PIVOTING DATA FRAMES¶\n\npivoting: reshape tool"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nSTACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nMELTING DATA FRAMES\n\nReverse of pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CATEGORICALS AND GROUPBY"},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}