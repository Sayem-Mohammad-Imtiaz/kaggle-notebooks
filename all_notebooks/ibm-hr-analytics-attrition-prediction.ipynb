{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Task:\n\nIn this section, we find the best classifier that can be used to predict the variable - 'Attrition' based on the various features present in the dataset.\n\nAs in our case, it is critical to classify Attrition correctly we will be considering Recall of 1 (as we wish to have less False Negatives predicted by our model) along with overall accuracy for our evaluation metric of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport  matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing the unwanted EmployeeNumber,Over18 and EmployeeCount column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['EmployeeNumber'],axis = 1)\ndf = df.drop(['Over18'],axis = 1)\ndf = df.drop(['EmployeeCount'],axis=1)\ndf = df.drop(['StandardHours'],axis=1)\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Target Variable"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['Attrition'].value_counts().plot(kind='bar', color=\"blue\", alpha=.65)\nplt.title(\"Attrition Breakdown\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### OBSERVATION\nThe dataset is imbalanced so we have to apply SMOTE technique"},{"metadata":{},"cell_type":"markdown","source":"### Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,15))\nsns.heatmap(df.corr(),annot=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How is Gender Related to Attrition?"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df['Gender'],df['Attrition']).plot(kind='bar')\nplt.title('Attrition with respect to Gender')\nplt.xlabel('Gender')\nplt.ylabel('Frequency of Attrition')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the above chart, Gender seems to have some effect on Attrition. It seems like more male employees have been attritioned than the female employees. We will cross-check using Chi-square test"},{"metadata":{},"cell_type":"markdown","source":"How is Gender Related to Attrition?"},{"metadata":{},"cell_type":"markdown","source":"### Is Business Travel the reason for Attrition?"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df['BusinessTravel'],df['Attrition']).plot(kind='bar')\nplt.title('Attrition with respect to BusinessTravel')\nplt.xlabel('BusinessTravel')\nplt.ylabel('Frequency of Attrition')\nplt.xticks(rotation=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### OBSERVATION\nThe attrition increases from Non-Travel > Travel_Frequently>Travel_Rarely. But the number of employees also increases. We will perform statistical analysis to confirm whether business travel is statistically related to attrition."},{"metadata":{},"cell_type":"markdown","source":"### Is there higher Attrition for a specific department?"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df['Department'],df['Attrition']).plot(kind='bar', stacked=True)\nplt.title('Attrition with respect to Department')\nplt.xlabel('Department')\nplt.ylabel('Frequency of Attrition')\nplt.xticks(rotation=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Attrition with respect to Education Field"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npd.crosstab(df['EducationField'],df['Attrition']).plot(kind='bar',stacked=False)\nplt.title('Attrition with respect to EducationField')\nplt.xlabel('EducationField')\nplt.ylabel('Frequency of Attrition')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Attrition with respect to Job Role"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npd.crosstab(df['JobRole'],df['Attrition']).plot(kind='bar', stacked=False)\nplt.title('Attrition with respect to JobRole')\nplt.xlabel('JobRole')\nplt.ylabel('Frequency of Attrition')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Attrition with respect to marital status"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df['MaritalStatus'],df['Attrition']).plot(kind='bar', stacked=False)\nplt.title('Attrition with respect to MaritalStatus')\nplt.xlabel('MaritalStatus')\nplt.ylabel('Frequency of Attrition')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender'] = df['Gender'].map({'Female':0, 'Male':1}).astype(int)\ndf['BusinessTravel'] = df['BusinessTravel'].map({'Travel_Rarely':2, 'Travel_Frequently':1, 'Non-Travel':0}).astype(int)\ndf['OverTime'] = df['OverTime'].map({'Yes':0, 'No':1}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using dummy variable to convert categorical variables to numerical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy1 = pd.get_dummies(df['EducationField'])\ndummy2 = pd.get_dummies(df['JobRole'])\ndummy3 = pd.get_dummies(df['MaritalStatus'])\ndummy4 = pd.get_dummies(df['Department'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Joining the original dataframe and all the dummy variables produced\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.concat([df,dummy1,dummy2,dummy3,dummy4],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dropping the original variables from the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(['EducationField','JobRole','MaritalStatus','Department'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mapping Attrition variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Attrition'] = df['Attrition'].map({'Yes':0, 'No':1}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Attrition column will be assigned to Y and all other variables are assigned to X"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop(['Attrition'],axis=1)\nY=df['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the shape function on X, we know that the dataframe has *1470 data points* and *48 features* that can be used to predict 'Attrition' stored in y. \n\nThe different classification models that can be used for this task are:\n- KNN Classification\n- Logistic Regression\n- Support Vector Machine - Linear SVC\n- Support Vector Machine with Kernel trick â€“ Rbf, Poly, Linear\n- Decision Tree\n\nBut before we start applying these classification models, a three-fold split is performed on the entire dataset\n\nThus, we fit the above models using train and validation set and after finding the best classifier, we check for the accuracy of the best classifier using test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nX_trainval_org, X_test_org, y_trainval, y_test = train_test_split(X,Y, random_state = 2)\n\n# split train+validation set into training and validation sets\nX_train_org, X_valid_org, y_train, y_valid = train_test_split(X_trainval_org, y_trainval, random_state=1)\n\nscaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train_org)\nX_valid = scaler.fit_transform(X_valid_org)\nX_trainval = scaler.fit_transform(X_trainval_org)\nX_test = scaler.transform(X_test_org)\n\nprint(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the results, it can be said that the training set has 826 data points, validation set has 276 data points and testing set has 368 data points.\n\nLet us fit model - KNN Classifier using train and validation set and find the best parameter - *'K'* using naive grid search.\n\n## KNN Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\ntrain_score_array = []\nvalid_score_array = []\n\nbest_score = 0\n\nfor k in range(1,10):\n    knn_clf = KNeighborsClassifier(k)\n    knn_clf.fit(X_train, y_train)\n    train_score_array.append(knn_clf.score(X_train, y_train))\n    score = knn_clf.score(X_valid, y_valid)\n    valid_score_array.append(score)\n    if score > best_score:\n            best_score = score\n            best_parameters = {'K': k}\n            best_K = k\n\nx_axis = range(1,10)\nplt.plot(x_axis, train_score_array, c = 'g', label = 'Train Score')\nplt.plot(x_axis, valid_score_array, c = 'b', label = 'Validation Score')\nplt.legend()\nplt.xlabel('k')\nplt.ylabel('MSE')\n\nprint(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameter value of K for this model is 8 which gives an accuracy of 0.84 on the validation dataset.\n\nWe review this parameter using cross validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nknn_grid = KNeighborsClassifier(best_K)\n\nscores = cross_val_score(knn_grid, X_trainval, y_trainval, cv =10, scoring = 'accuracy')\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average cross-validation score for the parameter K = 8 is 0.85 \n\nLet us find the best parameter for this model using GridSearchCV:"},{"metadata":{"trusted":true},"cell_type":"code","source":"k_range = list(range(1, 11))\n\nparam_grid = dict(n_neighbors=k_range)\n\ngrid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_trainval, y_trainval)\n\ndf = pd.DataFrame(grid_search.cv_results_)\n%matplotlib inline\nx_axis = range(1,11)\nplt.plot(x_axis, df.mean_train_score, c = 'g', label = 'Train Score')\nplt.plot(x_axis, df.mean_test_score, c = 'b', label = 'Validation Score')\nplt.legend()\nplt.xlabel('k')\nplt.ylabel('CV Score')\n\nprint(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameter for this model using GridSearchCV is 8. Eventhough we found the best parameter as K = 8  using the naive grid search, but with parameter K = 8, the average cross validation is 0.85 which is better than the average cross validation of the naive grid search. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n \npred_knn = grid_search.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_knn))\n\nconfusion = confusion_matrix(y_test, pred_knn)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_knn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision,recall,fscore,support=score(y_test,pred_knn)\n\nprint ('Recall    : {}'.format(recall[0]))\nprint ('F1-Score    : {}'.format(fscore[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the accuracy,recall and f1-score of this model for the best parameter - K are 0.85,0.15 and 0.23 respectively"},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores={}\n\nClassification_Scores.update({'KNN Classification':[metrics.accuracy_score(y_test,pred_knn),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['Classifier','Best Parameters','Accuracy_Score','Recall of 0']\nclf_model_para = pd.DataFrame(columns=columns)\n\nclf_model_para=clf_model_para.append({'Classifier':'KNN Classification',\n                                      'Best Parameters':grid_search.best_params_,\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_knn),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from warnings import simplefilter\n\nsimplefilter(action='ignore', category=FutureWarning)\n\nfrom sklearn.linear_model import LogisticRegression\n\nc_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\ntrain_score_l1 = []\ntrain_score_l2 = []\nvalid_score_l1 = []\nvalid_score_l2 = []\n\nbest_score = 0\nl1 = 'l1'\nl2 = 'l2'\n\nfor c in c_range:\n    log_l1 = LogisticRegression(penalty = 'l1', C = c,solver='liblinear')\n    log_l2 = LogisticRegression(penalty = 'l2', C = c,solver='lbfgs')\n    \n    log_l1.fit(X_train, y_train)\n    log_l2.fit(X_train, y_train)\n    \n    train_score_l1.append(log_l1.score(X_train, y_train))\n    train_score_l2.append(log_l2.score(X_train, y_train))\n    \n    score = log_l1.score(X_valid, y_valid)\n    valid_score_l1.append(score)\n    if score > best_score:\n            best_score = score\n            best_parameters = {'C': c , 'penalty': l1}\n            best_C = c\n            best_Penalty = 'l1'\n    \n    score = log_l2.score(X_valid, y_valid)\n    valid_score_l2.append(score)\n    if score > best_score:\n            best_score = score\n            best_parameters = {'C': c , 'penalty' : l2}\n            best_C = c\n            best_Penalty = 'l2'\n    \nplt.subplot(1,2,1)\nplt.plot(c_range, train_score_l1, label = 'Train score, penalty = l1')\nplt.plot(c_range, valid_score_l1, label = 'Test score, penalty = l1')\nplt.xscale('log')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(c_range, train_score_l2, label = 'Train score, penalty = l2')\nplt.plot(c_range, valid_score_l2, label = 'Test score, penalty = l2')\nplt.xscale('log')\nplt.legend()\n\nprint(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameter value of C and Penalty for this model are 1 and `l2` respectively which gives a score of 0.88 on the validation dataset.\n\nWe review this parameter using cross validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"log_grid = LogisticRegression(penalty = best_Penalty, C = best_C)\n\nscores = cross_val_score(log_grid, X_trainval, y_trainval, cv =10, scoring = 'accuracy')\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average cross-validation score for the best parameters (1 and l2) is 0.88.\n\nLet us find the best parameter for this model using GridSearchCV:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'penalty': ['l1','l2'],\n             'C':  [0.001, 0.01, 0.1, 1, 10, 100]}\n\ngrid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_trainval, y_trainval)\n\nprint(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameter for this model using GridSearchCV is `C=1` and `penalty = l2` giving average cross-validation score same as that of naive grid search.\n\nThus, we will choose the best parameter for Logistic Regression as `C=1` and `penalty = l2`."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_log = grid_search.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_log))\n\nconfusion = confusion_matrix(y_test, pred_log)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_log))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision,recall,fscore,support=score(y_test,pred_log)\n\nprint ('Recall    : {}'.format(recall[0]))\nprint ('F1Score    : {}'.format(fscore[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the accuracy,recall and f1 score of this model for the best parameter  C=1 and penalty = l2 are 0.875,0.32 and 0.47"},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores.update({'Logistic Classification':[metrics.accuracy_score(y_test,pred_log),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model_para=clf_model_para.append({'Classifier':'Logistic Classification',\n                                      'Best Parameters':grid_search.best_params_,\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_log),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support-Vector Classification\n\nLet us apply some SVC models on this dataset.\n\n### LinearSVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\ntrain_score_list = []\nvalid_score_list = []\n\nbest_score = 0\n\nfor C in [0.001, 0.01, 0.1, 1, 10, 100]:\n    linear_svc = LinearSVC(C=C, max_iter=10000)\n    linear_svc.fit(X_train,y_train)\n    train_score_list.append(linear_svc.score(X_train,y_train))\n    score = linear_svc.score(X_valid, y_valid)\n    valid_score_list.append(score)\n    if score > best_score:\n        best_score = score\n        best_parameters = {'C' : C}\n        best_C = C\n\nx_range = [0.001, 0.01, 0.1, 1, 10, 100]\nplt.plot(x_range, train_score_list, c = 'g', label = 'Train Score')\nplt.plot(x_range, valid_score_list, c = 'b', label = 'Validation Score')\nplt.xscale('log')\nplt.legend(loc = 3)\nplt.xlabel('Regularization parameter')\n\nprint(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using LinearSVC, we get a score of 0.89 for the regularization parameter C = 1.\n\nLets check the average cross-validation score for this parameter C = 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_svc_grid = LinearSVC(C = best_C, max_iter=10000)\nscores = cross_val_score(linear_svc_grid, X_trainval, y_trainval, cv = 10, scoring = 'accuracy')\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get an average cross-validation score of 0.88 for C = 1. \n\nThe average cross validation score using GridSearchCV is given by:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\ngrid_search = GridSearchCV(LinearSVC(max_iter=10000), param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_trainval, y_trainval)\n\ndf = pd.DataFrame(grid_search.cv_results_)\n%matplotlib inline\nplt.plot(x_range, df.mean_train_score, c = 'g', label = 'Train Score')\nplt.plot(x_range, df.mean_test_score, c = 'b', label = 'Validation Score')\nplt.xscale('log')\nplt.legend(loc = 3)\nplt.xlabel('Regularization Parameter')\n\nprint(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the results of both the grid search methods - naive grid search and GridSearchCV, we get the same average cross-validation score of 0.88 for regularization parameter `c=10` compared to naive grid search. \n\nAlso, from the above graph we see that for this model, with the increase in the value of regularization parameter i.e. when less regularization is done, the model has more features and performs better compared to when more regularization is done."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_linear_svc = grid_search.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_linear_svc))\n\nconfusion = confusion_matrix(y_test, pred_linear_svc)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_linear_svc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision,recall,fscore,support=score(y_test,pred_linear_svc)\n\nprint ('Recall    : {}'.format(recall[0]))\nprint ('F1Score    : {}'.format(fscore[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the accuracy,recall and F1Score of this model for the best parameter - C=1 are 0.8699,0.34 and 0.47 respectively"},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores.update({'Linear_SVC':[metrics.accuracy_score(y_test,pred_linear_svc),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model_para=clf_model_para.append({'Classifier':'Linear_SVC',\n                                      'Best Parameters':grid_search.best_params_,\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_linear_svc),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVC - rbf\n\nThe hyper-parameters for this model are `gamma` and regularlization term `C`."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\ntrain_score_list = []\nvalid_score_list = []\n\nbest_score = 0\n\nfor gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n        svc_rbf = SVC(kernel='rbf', gamma=gamma, C=C)\n        svc_rbf.fit(X_train,y_train)\n        train_score_list.append(svc_rbf.score(X_train,y_train))\n        score = svc_rbf.score(X_valid, y_valid)\n        valid_score_list.append(score)\n        if score > best_score:\n            best_score = score\n            best_parameters = {'gamma': gamma , 'C' : C}\n            best_Gamma = gamma\n            best_C = C\n\nprint(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best paramaters for this kernel are `gamma = 0.01` and `C = 100` which gives a score of 0.87 on the validation set.\nThe average cross-validation score for these parameters is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_rbf_grid = SVC(kernel='rbf', gamma = best_Gamma, C = best_C)\n\nscores = cross_val_score(svc_rbf_grid, X_trainval, y_trainval, cv =10, scoring = 'accuracy')\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the results of both the grid search methods - we got the average cross validation score as 0.87 and 0.88 \n\nLet us check for the average cross-validation score using GridSearchCV."},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n             'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n\ngrid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_trainval, y_trainval)\n\nprint(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameters that we got from GridSearchCV are C = 100 and gamma = 0.01. Compared to the best parameters we got from naive grid search (C = 100 and gamma = 0.01), the average cross-validation score increased from 0.87 to 0.88.\n\nThus the best parameters for this model are C = 100 and gamma = 0.01."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rbf = grid_search.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_rbf))\n\nconfusion = confusion_matrix(y_test, pred_rbf)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_rbf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision,recall,fscore,support=score(y_test,pred_rbf)\n\nprint ('Recall    : {}'.format(recall[0]))\nprint ('F1-Score    : {}'.format(fscore[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the accuracy,recall and f1-score of this model for the best parameter - C=100 and gamma = 0.01 are 0.875,0.34 and 0.48  respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores.update({'SVC RBF Kernel':[metrics.accuracy_score(y_test,pred_rbf),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model_para=clf_model_para.append({'Classifier':'SVC RBF Kernel',\n                                      'Best Parameters':grid_search.best_params_,\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_rbf),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVC - Poly"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score_list = []\nvalid_score_list = []\n\nbest_score = 0\n\nfor degree in range(1,5):\n    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n        for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n            svc_poly = SVC(kernel='poly', degree = degree, C=C, gamma = gamma)\n            svc_poly.fit(X_train,y_train)\n            train_score_list.append(svc_poly.score(X_train,y_train))\n            score = svc_poly.score(X_valid, y_valid)\n            valid_score_list.append(score)\n            if score > best_score:\n                best_score = score\n                best_parameters = {'degree': degree , 'C' : C, 'gamma' : gamma}\n                best_Degree = degree\n                best_C = C\n                best_gamma = gamma\n\nprint(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best paramaters for this kernel are `degree = 1`, `gamma = 100` and `C = 0.01` which gives a score of 0.88 on the validation set.\nThe average cross-validation score for these parameters is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_poly_grid = SVC(kernel='poly',degree = best_Degree, C=best_C, gamma = best_Gamma)\n\nscores = cross_val_score(svc_poly_grid, X_trainval, y_trainval, cv =10, scoring = 'accuracy')\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average cross-validation score for the best parameters is 0.84.\n\nLet's check for the best parameter using GridSearchCV:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n             'C': [0.001, 0.01, 0.1, 1, 10, 100],\n             'degree': [1,2,3,4,5]}\n\ngrid_search = GridSearchCV(SVC(kernel='poly'), param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_trainval, y_trainval)\n\nprint(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameters that we got from GridSearchCV are degree = 1, C = 1 and gamma = 100.\n\nCompared to the best parameters we got from naive grid search (degree = 1, C = 1 and gamma = 100), the average cross-validation score remained same (0.88).\n\nThus the best parameters for this model are degree = 1, C = 1 and gamma = 100. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_poly = grid_search.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_poly))\n\nconfusion = confusion_matrix(y_test, pred_poly)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_poly))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision,recall,fscore,support=score(y_test,pred_poly)\n\nprint ('Recall    : {}'.format(recall[0]))\nprint ('FScore    : {}'.format(fscore[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the accuracy,recall and f1score of this model for the best parameter - degree = 1, C = 1 and gamma = 100 are 0.88,0.32 and 0.45 respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores.update({'SVC Poly Kernel':[metrics.accuracy_score(y_test,pred_poly),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model_para=clf_model_para.append({'Classifier':'SVC Poly Kernel',\n                                      'Best Parameters':grid_search.best_params_,\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_poly),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM-linear"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\ntrain_score_list = []\nvalid_score_list = []\n\nbest_score = 0\n\nfor degree in range(1,5):\n    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n        for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n            svc_poly = SVC(kernel='linear', degree = degree, C=C, gamma = gamma)\n            svc_poly.fit(X_train,y_train)\n            train_score_list.append(svc_poly.score(X_train,y_train))\n            score = svc_poly.score(X_valid, y_valid)\n            valid_score_list.append(score)\n            if score > best_score:\n                best_score = score\n                best_parameters = {'degree': degree , 'C' : C, 'gamma' : gamma}\n                best_Degree = degree\n                best_C = C\n                best_gamma = gamma\n\nprint(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best paramaters for this kernel are `degree = 1`, `gamma = 0.001` and `C = 1` which gives a score of 0.87 on the validation set.\nThe average cross-validation score for these parameters is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nsvc_poly_grid = SVC(kernel='linear',degree = best_Degree, C=best_C, gamma = best_gamma)\n\nscores = cross_val_score(svc_poly_grid, X_trainval, y_trainval, cv =10, scoring = 'accuracy')\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average cross-validation score for the best parameters is 0.88.\n\nLet's check for the best parameter using GridSearchCV:"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n             'C': [0.001, 0.01, 0.1, 1, 10, 100],\n             'degree': [1,2,3,4,5]}\n\ngrid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=10, return_train_score=True)\n\ngrid_search.fit(X_trainval, y_trainval)\n\nprint(\"Best parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best parameters that we got from GridSearchCV are degree = 1, C = 100 and gamma = 0.001.\n\nCompared to the best parameters we got from naive grid search (degree = 1, C = 1 and gamma = 0.001), the average cross-validation score remained same (0.88).\n\nThus the best parameters for this model are degree = 1, C = 100 and gamma = 0.001."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\nfrom sklearn.metrics import confusion_matrix, classification_report \npred_linear = grid_search.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_linear))\n\nconfusion = confusion_matrix(y_test, pred_linear)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_linear))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores.update({'SVC Poly Linear':[metrics.accuracy_score(y_test,pred_linear),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model_para=clf_model_para.append({'Classifier':'SVC Poly Linear',\n                                      'Best Parameters':grid_search.best_params_,\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_linear),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndtree = DecisionTreeClassifier()\n\ndtree.fit(X_trainval, y_trainval)\nprint(\"Accuracy on training set: {:.3f}\".format(dtree.score(X_trainval, y_trainval)))\nprint(\"Accuracy on test set: {:.3f}\".format(dtree.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are getting an accuracy of 1.00 on the training set as it goes till highest depth. We are getting an accuracy of 0.799 on the testing set.\n\nLet us check for the average cross-validation score for this model using cross_val_score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_cv = DecisionTreeClassifier()\nscores = cross_val_score(dtree_cv, X_trainval, y_trainval, cv = 10, scoring = 'accuracy' )\nprint(\"Cross-validation scores: {}\".format(scores))\n\nprint(\"Average cross-validation score: {:.2f}\".format(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_tree = dtree.predict(X_test)\nprint(metrics.accuracy_score(y_test,pred_tree))\n\nconfusion = confusion_matrix(y_test, pred_tree)\nprint(\"Confusion matrix:\\n{}\".format(confusion))\n\nprint(classification_report(y_test,pred_tree))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision,recall,fscore,support=score(y_test,pred_tree)\n\nprint ('Recall    : {}'.format(recall[0]))\nprint ('F1Score    : {}'.format(fscore[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores.update({'Decison Tree':[metrics.accuracy_score(y_test,pred_tree),recall[0],fscore[0]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model_para=clf_model_para.append({'Classifier':'Decision Tree',\n                                      'Best Parameters':' ',\n                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_tree),\n                                      'Recall of 0':recall[0]},ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Best Classifier\n\nLet's check for the accuracy score and recall for all the above model: "},{"metadata":{},"cell_type":"markdown","source":"SVC Poly Linear depicts SVC Linear"},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_Scores=pd.DataFrame(Classification_Scores)\nClassification_Scores.rename({0:'Accuracy_Score',1:'Recall',2:'F1-Score'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(56,5))\n\nClassification_Scores.plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our evaluation strategy is based on the having best recall value and best F1-Score as the dataset is imbalanced and (as we do not wish to misclassify the employess which are likely to cause attrition i.e. have less false negatives in our confusion matrix)\n\nFrom the above graph, it can be said that we are getting an accuracy of 0.88, recall score of 0.34 and f1-score of 0.48 for SVC - RBF\n\nThus, it is the best classifier that can be used for predicting the attrition rate."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}