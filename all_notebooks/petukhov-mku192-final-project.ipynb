{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Моделирование стоимости бриллиантов\n\nЦель моей работы - проанализировать базу данных, включающую в себя основные характеристики бриллиантов, с целью прогнозирования их цены с учетом различных факторов. В конечном итоге, мной будет разработана обучающая машина, способная выполнять данную функцию."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n\ndiamonds = pd.read_csv(\"../input/diamonds/diamonds.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Первичное рассмотрение и проверка работы базы данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно попробовать вытащить еще немного информации из базы данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно заметить такой показатель, как \"Unnamed 0\". В целом, он нам не нужен и его можно убрать."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds = diamonds.drop(\"Unnamed: 0\", axis = 1)\n\ndiamonds[\"price\"] = diamonds[\"price\"].astype(float)\n\ndiamonds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как можно заметить, в выборка представляет из себя 53490 образцов и стоит сказать, что нет ни одной пропуска в наборе данных.\n\nДля того, чтобы упросить работы с данными, необходимо перевести все основные категории-характеристика бриллиантов в числовые.\n\nСначала, в целом, надо посмотреть, какие категории присутствуют в базе данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"cut\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"color\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"clarity\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно сделать вывод о том, что категорий не так много! Но это не отменяет большое количество столбцов.\n\nДалее можно сделать основное заключение по числовым атрибутам базы данных и сделать гистограмму на их основе.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.hist(bins = 50, figsize = (20, 15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Создание тест сета\n\nБлагодаря созданию тестового сета мы можем проверить производительность работы имеющейся базы данных на примере новых экземпляров. Однако перед этим необходимо провести стратификацию выборки на отдельные подгруппы, которая позволит выделить конкретные экземпляры, которые позволяю более правильно оценить набор всех данных в целом\n\nЧтобы провести эту операцию, нам необходимо узнать атрибуты, которые будет лучше всего коррелировать с ценой бриллианта, поэтому мной будет проведено определение стандартного коэффициента корреляции по Пирсону."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = diamonds.corr()\n\nplt.subplots(figsize = (10, 8))\nsns.heatmap(corr_matrix, annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Итак, какие выводы можно сделать:\n- x, y, z обладают самой сильной корреляцией с price\n- carat также обладает одной из самых корреляций с price (0,92)\n- самая слабая корреляция наблюдается у table и depth\n\nТеперь построим гистограмму такого атрибута как carat"},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"carat\"].hist(bins = 50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Большинство алмазов примерно от 0,3 до 1,5 карат. Далее разделим их на 5 категорий, причем следующие после 5-й категории сливаются в 5-ю категорию."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"carat_cat\"] = np.ceil(diamonds[\"carat\"] / 0.35)\n\ndiamonds[\"carat_cat\"].where(diamonds[\"carat_cat\"] < 5, 5.0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь можно посмотреть, сколько алмазов распределено по категориям в каратах."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"carat_cat\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds[\"carat_cat\"].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Распределение выглядит довольно хорошо. После этого мы можем выполнить стратификационную выборку на основе категории carat при помощи функции \"StratifiedShuffleSplit\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n\nfor train_index, test_index in split.split(diamonds, diamonds[\"carat_cat\"]):\n    strat_train_set = diamonds.loc[train_index]\n    strat_test_set = diamonds.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"После всех приготовлений, теперь такая переменная, как carat_cat нам уже не нужна и мы можем ее убрать"},{"metadata":{"trusted":true},"cell_type":"code","source":"for set in (strat_train_set, strat_test_set):\n    set.drop([\"carat_cat\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь обозначим нашу базу данных как \"Stratified Train set\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds = strat_train_set.copy()\ndiamonds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Визуализация полученных данных\n\nТеперь можно сделать некоторые визуализации и провести наблюдения из полученных рисунков."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(diamonds[[\"price\", \"carat\", \"cut\"]], hue = \"cut\", height = 5)\nplt.show()\nsns.barplot(x = \"carat\", y = \"cut\", data = diamonds)\nplt.show()\nsns.barplot(x = \"price\", y = \"cut\", data = diamonds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"«Fair» огранки наиболее весомые, но они не самые дорогие алмазы. «Premium» весят меньше, чем \"fair\", а затем стоят дороже. «Ideal» весят намного меньше, и они наименее дороги. Таким образом, огранка относительно учитывается при определении цены алмаза."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(diamonds[[\"price\", \"carat\", \"color\"]], hue = \"color\", height = 5)\nplt.show()\nsns.barplot(x = \"carat\", y = \"color\", data = diamonds)\nplt.show()\nsns.barplot(x = \"price\", y = \"color\", data = diamonds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Здесь мы можем видеть, что цвет J, который является наиболее взвешенным, также является самым дорогим. Последние 2 сюжета очень похожи. Мы могли видеть здесь, что цвет алмаза также очень зависит от его цены."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(diamonds[[\"price\", \"carat\", \"clarity\"]], hue = \"clarity\", height = 5)\nplt.show()\nsns.barplot(x = \"carat\", y = \"clarity\", data = diamonds)\nplt.show()\nsns.barplot(x = \"price\", y = \"clarity\", data = diamonds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Здесь мы можем видеть, что I1 не обладает наивысшей четкостью, хотя он и самый дорогой. Но есть еще кое-что: кроме I1, если остальное останется, цена на бриллиант могут быть довольно относительными его ясности в некоторой степени.\n\n## Шкалирование основных свойств\n\nСкалирование объектов может быть выполнено двумя способами: Минимальное-максимальное скалирование и Стандартизация. Я бы предпочел использовать стандартизацию, потому что на нее гораздо меньше влияют выбросы."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds = strat_train_set.drop(\"price\", axis = 1)\n\ndiamond_labels = strat_train_set[\"price\"].copy()\n\ndiamonds_num = diamonds.drop([\"cut\", \"color\", \"clarity\"], axis = 1)\ndiamonds_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nnum_scaler = StandardScaler()\ndiamonds_num_scaled = num_scaler.fit_transform(diamonds_num)\n\npd.DataFrame(diamonds_num_scaled).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Это то, как будут выглядеть наши данные в процессе обработки. Так мы сделали обучающую машину, которая позволяет прогнозировать.\n\n## Обработка атрибутов\n\nТеперь мы создаем один двоичный атрибут для каждой категории: один атрибут будет один, а остальные - 0. Это называется One-Hot Encoding. Scikit-Learn предоставляет кодировщик OneHotEncoder для преобразования атрибутов нашей категории в векторы One-Hot."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds_cat = diamonds[[\"cut\", \"color\", \"clarity\"]]\ndiamonds_cat.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\ndiamonds_cat_encoded = cat_encoder.fit_transform(diamonds_cat)\n\npd.DataFrame(diamonds_cat_encoded.toarray()).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как я говорил ранее, в нашей таблице, в конечном счете, будет много столбцов.\n\n## Трансформация \n\nДля того, чтобы не было проблем при обработке данных, необходимоперейти к классу Scikit-Learn ColumnTransformer. Это объединение обеспечивает единый конвейер для всего набора данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(diamonds_num)\ncat_attribs = [\"cut\", \"color\", \"clarity\"]\n\npipeline = ColumnTransformer([\n    (\"num\", StandardScaler(), num_attribs), \n    (\"cat\", OneHotEncoder(), cat_attribs) \n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds_ready = pipeline.fit_transform(diamonds)\n\npd.DataFrame(diamonds_ready).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь у нас есть наш недавно преобразованный набор данных, который можно легко использовать в наших алгоритмах машинного обучения.\n\n## Разработка модели и проверка ее работы\n\nСледующим шагом я создам одну функцию, которая будет проходить через каждый алгоритм. У меня также будут переменные, которые содержат результаты алгоритмов для будущих сравнений. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom random import randint\n\nX_test = strat_test_set.drop(\"price\", axis = 1)\ny_test = strat_test_set[\"price\"].copy()\n\nmodels_rmse = []\ncvs_rmse_mean = []\ntests_rmse = []\ntests_accuracy = []\nmodels = []\n\ndef display_model_performance(model_name, model, diamonds = diamonds_ready, labels = diamond_labels,\n                              models_rmse = models_rmse, cvs_rmse_mean = cvs_rmse_mean, tests_rmse = tests_rmse,\n                              tests_accuracy = tests_accuracy, pipeline = pipeline, X_test = X_test,\n                              y_test = y_test, cv = True):\n\n    model.fit(diamonds, labels)\n    \n    predictions = model.predict(diamonds)\n    \n    model_mse = mean_squared_error(labels, predictions)\n    model_rmse = np.sqrt(model_mse)\n    \n    cv_score = cross_val_score(model, diamonds, labels, scoring = \"neg_mean_squared_error\", cv = 10)\n    cv_rmse = np.sqrt(-cv_score)\n    cv_rmse_mean = cv_rmse.mean()\n    \n    print(\"RMSE: %.4f\" %model_rmse)\n    models_rmse.append(model_rmse)\n    \n    print(\"CV-RMSE: %.4f\" %cv_rmse_mean)\n    cvs_rmse_mean.append(cv_rmse_mean)\n    \n    print(\"--- Test Performance ---\")\n    \n    X_test_prepared = pipeline.transform(X_test)\n    \n    model.fit(X_test_prepared, y_test)\n    \n    test_predictions = model.predict(X_test_prepared)\n    \n    test_model_mse = mean_squared_error(y_test, test_predictions)\n    test_model_rmse = np.sqrt(test_model_mse)\n    print(\"RMSE: %.4f\" %test_model_rmse)\n    tests_rmse.append(test_model_rmse)\n    \n    test_accuracy = round(model.score(X_test_prepared, y_test) * 100, 2)\n    print(\"Accuracy:\", str(test_accuracy)+\"%\")\n    tests_accuracy.append(test_accuracy)\n    \n    start = randint(1, len(y_test))\n    some_data = X_test.iloc[start:start + 7]\n    some_labels = y_test.iloc[start:start + 7]\n    some_data_prepared = pipeline.transform(some_data)\n    print(\"Predictions:\\t\", model.predict(some_data_prepared))\n    print(\"Labels:\\t\\t\", list(some_labels))\n    \n    models.append(model_name)\n    \n    plt.scatter(diamond_labels, model.predict(diamonds_ready))\n    plt.xlabel(\"Actual\")\n    plt.ylabel(\"Predicted\")\n    x_lim = plt.xlim()\n    y_lim = plt.ylim()\n    plt.plot(x_lim, y_lim, \"k--\")\n    plt.show()\n    \n    print(\"------- Test -------\")\n    plt.scatter(y_test, model.predict(X_test_prepared))\n    plt.xlabel(\"Actual\")\n    plt.ylabel(\"Predicted\")\n    plt.plot(x_lim, y_lim, \"k--\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь мы можем приступить к подгонке моделей и получить ошибку их производительности. Помним, что для оценки эффективности мы используем среднеквадратическую ошибку.\n\nНачнем с самой простой модели - «Линейная регрессия»"},{"metadata":{},"cell_type":"markdown","source":"### Линейная регрессия"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize = True)\ndisplay_model_performance(\"Linear Regression\", lin_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Регрессия \"Случайный лес\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators = 10, random_state = 42)\ndisplay_model_performance(\"Random Forest Regression\", forest_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Регрессия \"Дерево решений\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state = 42)\ndisplay_model_performance(\"Decision Tree Regression\", tree_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Сравнение ранее рассмотренных регрессий "},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models = pd.DataFrame({ \"Algorithms\": models, \"Models RMSE\": models_rmse, \"CV RMSE Mean\": cvs_rmse_mean,\n                              \"Tests RMSE\": tests_rmse, \"Tests Accuracy\": tests_accuracy })\ncompare_models.sort_values(by = \"Tests Accuracy\", ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Хорошо. Стоит обратить внимание, что вытекает точность 100% из модели регрессии \"Дерево решений\". Это слишком идеально. Стоит отметить, что некоторые наборы данных из набора тестов были выбраны и сравнены, возможно, это и правильно. Другая модель, от которой мы могли бы зависеть, - это «Случайный Лес». Это работает относительно хорошо, на мой взгляд."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = \"Tests Accuracy\", y = \"Algorithms\", data = compare_models)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Сохранение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\nwith open('final_model.pkl', 'wb') as f:\n    pickle.dump(tree_reg, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Заключение\n\nАлгоритм \"Дерево решений\" выигрывает здесь!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}