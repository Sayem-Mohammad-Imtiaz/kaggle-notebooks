{"cells":[{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\"><br>\nPredicting User Average Rating using Board Games Dataset\n</p>\n<table>\n<col width=\"550\">\n<col width=\"450\">\n<tr>\n<p style=\"font-family: Arial; font-size:2.75em;\">\n<td><img src=\"https://www.theatkinson.co.uk/website/wp-content/uploads/2019/05/Board-games-900x600.jpg\" align=\"middle\" style=\"width:550px;height:360px;\"/></td>\n<td>\n\nFor this study, I am using board games' data set from <a href=\"https://www.kaggle.com\">Kaggle</a>. The  <a href=\"https://www.kaggle.com/gutsyrobot/games-data/data\">data set</a> is originally scraped from <a href=\"https://boardgamegeek.com/\">BoardGameGeek</a> (BGG), a board game review site. \n    \nThe data contains average rating of board games along with metadata like year of  publication, playing time, minimum age of players etc.\n    \n<br>\nI was excited to explore this real data set from BGG which involves a large community of board game hobbyists like me. The data set can be analysed for top games in terms of user comments, ratings or ease of understanding. \n<br>\n\nFinally, the goal of the project is to build a model to predict average user ratings and study important features for the model. \n<br>\n    \nThis report is made keeping following audiences in mind:\n* **Players**: To review is board game has been rated as good before making a buying decision.\n\n* **Marketing Analysts**: To predict average rating for a game before introducing it on the marketplace. If therating is poor, docusing on which features can improve the rating.\n\n* **Creators**: To analyse what kind of games have been rated high or low from historical data and what are the important features.\n\n\n<br>\n<br>\n</td>\n    </p>\n</tr>\n\n</table>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## IMPORT LIBRARIES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom math import sqrt\nsns.set(color_codes=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## READ CSV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df = pd.read_csv('../input/games-data/games.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us now explore our data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**81312 records across 20 featueres**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA ATTRIBUTES\n\nThe data description is as follows\n\n* **id**  -Id of the game. The field should be unique which will be verified in sunbsequent cells.\n* **type** - Type of Board games\n* **name** - Name of the game\n* **yearpublished** - The year a game was published. (float format)\n* **minplayers** - Minimum number of players that can play the game. \n* **maxplayers** - Maximum number of players that can play the game.\n* **playingtime** - average playing time to finish the game.\n* **minplaytime** -  minimum playing time to finish the game.\n* **maxplaytime** - maximum playing time to finish the game.\n* **minage** - minimum age of a player \n* **users_rated** - number of users that rated the game.\n* **average_rating** - average rating of the game. This will be the target variable for my study.\n* **bayes_average_rating** - BoardGameGeek replace the average by the Bayesian average. In Bayesian statistics we establish teh value as per priori assumptions. When evidence comes in we can update this prior. More can be read at https://www.evanmiller.org/bayesian-average-ratings.html\n* **total_owners** - Total number of people who own the game.\n* **total_traders** - Total no of traders selling the game on marketplace.\n* **total_wanters** - Current number of BGG members who are willing to purchase this game on marketplace.\n* **total_wishers** - Current number of who have added the game in wish list.\n* **total_comments** - Total no of comments received by users for a game.\n* **total_weights** - total weight by all the users for rating for how difficult a game is to understand.\n* **average_weight** - a community rating for how difficult a game is to understand.Weight is scored on a scale from 0.0 to 5.0 with 5 being difficult to comprehend or heavy game.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preliminary analysis shows:**\n* We can see 0's as minimum values for lot of columns- user_rated, average_rating, minplayers, maxplayers, minage etc. \n* average rating is on scale of 0 to 10.  \n* yearpublished has negatives\n* min age range is from 0 to 120 \n* average weight is on the scale of 0 to 5\n\nLet us see what is proportion of boardgame and boardgame expansion categories\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA CLEANING\n\n**Check for nulls**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.isnull().any(axis=1).any()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with_null=games_df.shape[0]\nwith_null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.dropna(inplace=True)#NaN values didnt get dropped using dropna()\ngames_df.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"without_null=games_df.shape[0]\nwithout_null\nprint(\"%d removed after dropping nulls\"%(with_null-without_null))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check for duplicates**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.duplicated().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['id'].nunique() \n#Business sense dictates us to look at unique ID values rather than names which might have clerical errors!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.drop_duplicates(subset =\"id\", inplace = True)\ngames_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_dups=games_df.shape[0]\nno_dups\nprint(\"%d duplicates removed from data set\"%(without_null-no_dups))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA and VISUALIZATION\n**Analysis of years in which games were published.**\n<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">\nThe data set has -ve years and year =0. The data type is float for year column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['yearpublished'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['yearpublished'] = games_df['yearpublished'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['yearpublished'].min()#-ve dates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']>0].yearpublished.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']<=0].yearpublished.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']==0].yearpublished.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, axis = plt.subplots()\n# Grid lines, Xticks, Xlabel, Ylabel\n\naxis.yaxis.grid(True)\naxis.set_title('year published vs average rating',fontsize=10)\naxis.set_xlabel('year published',fontsize=10)\naxis.set_ylabel('average rating',fontsize=10)\n\naxis.scatter(games_df['yearpublished'],games_df['average_rating'])\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"games published during B.C era are very less. Majority of the games are published in later years. The descriptive statistics shows 75% of board games after year 1900s.\nThere does not seem to be any realtion in year published and average rating.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(5,5))\nplt.hist(games_df['yearpublished'])\n\nplt.xlabel('year of publishing the game')\nplt.ylabel('# of Board games')\nplt.title('Histogram')\n\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Currently, I want to see the plot for yearspublished.\n<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">\nHow to work with negative years and yearpublished=0?\n    \nInitially, I removed the records where yearpublished was negative or 0.\nThere are 7690 such records.\n\nBut, on closer ispection of data and history, I found out that -ve year represent years in BC or Before Christ.\n-3500 is min value which is 3500 BC.\nThe game corresponding to that is \"Senet\" which is an ancient game (https://en.wikipedia.org/wiki/Senet)\nAnd can be traced to BC period.\nHence, I will retain the -ve values.\n\nBut, 0 years are not valid as 1BC is followed by 1 AD. The games where yeard published is 0 are games like carrom or some unpublished prototype. It looks either BGG web site could not trace the history or the data was not available. \n\nI will remove data where yearpublished is 0 LATER. There are **7668** such records\nYears like 220, 500 are 220 AD and 500 AD.\nWe are currently in 2020 CE or 2020 AD.\n\n**Challenge with data type of year**\nAs data deals with BC values in negatives, the date conversion pd.to_datetime() was not working for me and throwing out of bound errors. I would like to explore more on this but for now, I will leave the data type of this field as int.\nAnd, going forward check the histogram.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let us check which game is the oldest ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']==-3500]['name']#-ve dates\n#Senet is the oldest game available in our data set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How many records have 0 value in yearspublished**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df2=games_df[games_df['yearpublished']!=0]\nprint(games_df2.shape)\nprint(games_df.shape[0]-games_df2.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">ANALYSIS OF average_rating and users_rated\n\nLet us plot histogram for average rating.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.hist(games_df[\"average_rating\"])\n\nplt.xlabel('Average Rating')\nplt.ylabel('# of Board games')\nplt.title('Histogram')\n\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many records have 0 average rating.\nI will try to analyse if any user has rated for these records.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(games_df['average_rating'].min())\nprint(games_df['users_rated'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['average_rating'] == 0]['users_rated'].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rating cannot be 0, Users have not rated the game.\nprint(games_df[(games_df['average_rating']==0)].id.count())\nprint(games_df[(games_df['users_rated']==0)].id.count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**24355** board games without any user rating. Hence, these records have 0 average_rating.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['average_rating']!=0.0)].average_rating.sort_values().head(5)\n#0 rating rows should be dropped from the analysis,as 0 rating means game was not rated or the data is not available","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Remove records with 0 average rating**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df3 = games_df[games_df[\"average_rating\"]==0]\ngames_df3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# eliminating all the rows having average_rating = 0 or less than 0, since average rating can not be less than 1.\ngames_df = games_df[games_df[\"average_rating\"]>0]\nprint(games_df.shape)\ngames_df = games_df[games_df[\"users_rated\"] > 0]\nprint(games_df.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the histogram for average rating again","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nplt.hist(games_df[\"average_rating\"])\n\nplt.xlabel('Average Rating')\nplt.ylabel('# of Board games')\nplt.title('Histogram')\n\nplt.grid(True)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check describe function again","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"games_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">Analysis of no of players and playing time- Can these columns take value 0?\n\nFrom describe() function, I saw that min value for fields like minplayers, maxplayers, playingtime, minplayingtime, maxplayingtime, minage are 0. I want to analyse how many records do we have with such data.\n\nI plan to remove the records with condition:\n\n* where both minplayers or maxplayers=0 \n* where any of the 3 fields: playingtime, minplayingtime, maxplayingtime =0\n* minage =0 might mean for less than 1 year kids. But, does one prefer few months old infant to play board game? Hence, I plan to remove this as well","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['maxplayers'] == 0) | (games_df['minplayers'] == 0)].id.count()\n#3229 records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['playingtime'] == 0) | (games_df['minplaytime'] == 0) | (games_df['maxplaytime'] == 0)].id.count()\n#9712 records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['minage'] == 0) ].id.count()\n#12319 records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.shape\n#55064-3229-12319-9712","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter=(games_df['maxplayers'] > 0) & (games_df['minplayers'] > 0) & (games_df['minage'] > 0) & \\\n           (games_df['playingtime'] > 0) & (games_df['minplaytime'] > 0) & (games_df['maxplaytime'] > 0) \n\ngames_df = games_df[filter]\ngames_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analysis of years in which games were published.**\nComing back to this field, let us see if earlier cleaning has changed our data.\n\nThe data set has -ve years and year =0. The data type is int for year column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['yearpublished'].min()#-ve dates \n#minimum value is same","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']>0].yearpublished.min()\n#Change in the min year in AD era","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']<0].yearpublished.count()\n#12 games in BC era","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A filter was cretaed with condition where min and max players, min age , min adn max playing time are greater than 0.\nAfter filtering out these records, we are left with **37005** records.\n\nLet us check describe function again and see descriptive statistics of our data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['yearpublished']==0].yearpublished.count()\n#1587 records where year published is 0. I will remove these records.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But, 0 years are not valid as 1BC is followed by 1 AD. The games where yeard published is 0 are games like carrom or some unpublished prototype. It looks either BGG web site could not trace the history or the data was not available. \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let us check which game is the oldest ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Remove records where years published is 0**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df=games_df[games_df['yearpublished']!=0]\nprint(games_df.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(games_df.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final data looks good now. The summary of **data cleaning and preparation** is as under:\nWe started with **81312** records in our data set.\n\n* Null Values- 44 records removed\n* Duplicates- 1849 duplicate records which were removed from data set.\n* Average rating 0 as no user rated for those games- 24355 suvh records removed\n* Invalid data for minage: 12319 records removed where minimum age is 0 year\n* Invalid data for minplayer and maxplayer- 3229 records removed which had 0 value in these fields.\n* Invalid data for playingtime, minplaytime and maxplaytime: 9712 records removed where these values showed 0 playtime.\n* Yearspublished: The year is in int format due to BC and AD values. I am keeping negative values as they represent B.C. I removed data where yearpublished =0, *1587* such records after all the above cleaning. In original dat set 7668 such records were present.\n* After data cleaning and preparation, we are left with **35418** records","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br> Top Board Games</p>\n\n**Further exploring the data**\nWhat is the mean playing time for all the games put together?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['playingtime'].mean()\n# mean has increased after al teh cleaning and preparation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Which board game has highest no of comments and in which year it was published ?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df['total_comments'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['total_comments']==games_df['total_comments'].max())]['name']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['total_comments']==games_df['total_comments'].max())]['yearpublished']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['total_comments']== games_df['total_comments'].max()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[(games_df['total_comments']==games_df['total_comments'].max())]['name']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Which games have received least number of comments?**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[games_df['total_comments']== games_df['total_comments'].min()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What was the average minage of all games per game \"type\"? (boardgame & boardgameexpansion)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.groupby('type').mean()['minage']\n#board game expansion see more mean, probably the creators can see what improvements can be done","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Is there a correlation between average_rating and baysian rating for the games?**\nI will also check the scatter plot of these twio fields","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[['average_rating','bayes_average_rating']].corr() # very less correlation.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_rated = games_df['average_rating'].sort_values().value_counts()\nhigh_rated[:10]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Majority of the movies are rated 6 and 5. Games rated 10 or highest are the least.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"high_rated_games = games_df[games_df['average_rating']==10][['name','total_comments','users_rated']]\nhigh_rated_games[:10]\n#a misleading result as very less users rasted the game bringing average rating to higer value.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Top games with respect to total users rated, comments ,bayes rating**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[['name','users_rated','total_comments','average_rating','bayes_average_rating']].sort_values('total_comments',ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top_users_rated['name','users_rated'][:10].plot(kind='bar', figsize=(15,10))\ntop_users_rated=games_df[['name','total_comments']].sort_values('total_comments',ascending=False)\n#top_users_rated.reindex(index=[1,2], columns=['name','users_rated'])\ntop_users_rated[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_users_rated=games_df[['name','users_rated','total_comments','average_rating','bayes_average_rating']].sort_values('users_rated',ascending=False)\ntop_users_rated[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#top_users_rated['name','users_rated'][:10].plot(kind='bar', figsize=(15,10))\ntop_users_rated=games_df[['name','users_rated']].sort_values('users_rated',ascending=False)\ntop_users_rated.reindex(index=[1,2], columns=['name','users_rated'])\ntop_users_rated[:10].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scatter plots for visualizing the relation between features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, axis = plt.subplots()\n# Grid lines, Xticks, Xlabel, Ylabel\n\naxis.yaxis.grid(True)\naxis.set_title('Scatter Plot',fontsize=10)\naxis.set_ylabel('Average Rating',fontsize=10)\naxis.set_xlabel('Bayes Average Rating',fontsize=10)\n\nX = games_df['bayes_average_rating']\nY = games_df['average_rating']\n\naxis.scatter(X, Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks bayes_average_rating is 0 even when average rating is high.\nWe have cases where bayes rating adjusts average ratingto lower or higher value. Majority of bayes rating lies in the range 5-8. Let us see how bayes rating varies with no of users and year published. From previous graph, we saw that after 1900s, games were given more rating. It can be attributed to improved games too. But, we would like to see how bayes rating changed.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, axis = plt.subplots()\n# Grid lines, Xticks, Xlabel, Ylabel\n\naxis.yaxis.grid(True)\naxis.set_title('Scatter Plot',fontsize=10)\naxis.set_ylabel('# of Users rated',fontsize=10)\naxis.set_xlabel('Bayes Average Rating',fontsize=10)\n\nX = games_df['bayes_average_rating']\nY = games_df['users_rated']\n\naxis.scatter(X, Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If a game was rated by large no of users, bayes rating was at higher level. So, bayes rating compensates for low no of votes. High rating by less no of users can be misleading and we can see that can be adjusted by bayes rating\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nfig, axis = plt.subplots()\n# Grid lines, Xticks, Xlabel, Ylabel\n\naxis.yaxis.grid(True)\naxis.set_title('Scatter Plot',fontsize=10)\naxis.set_ylabel('years published',fontsize=10)\naxis.set_xlabel('Bayes Average Rating',fontsize=10)\n\nX = games_df['bayes_average_rating']\nY = games_df['yearpublished']\n\naxis.scatter(X, Y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df[['yearpublished','users_rated','average_rating','bayes_average_rating']].groupby('yearpublished').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the output of above cells, we can observe that bayes rating is less than average rating where # of users that rated the game is less. If # of users are more, bayes rating might not change too much. There can be other factors impacting bayes rating. In year 2017, mean of user rated is only 7.5. Despite having high average of 6.8, bayes rating was dropped to 0.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**For our project average_rating is the target variable or response variable. So we wil analyse rest of the features with average_rating**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(games_df['users_rated'],games_df['average_rating'],color='b')\nplt.ylabel('Average Rating')\nplt.xlabel('# of Users rated the games')\nplt.title('Scatter plot')\n\nplt.grid(True)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(games_df['average_weight'],games_df['average_rating'],color='b')\nplt.ylabel('Average Rating')\nplt.xlabel('Average Weight')\nplt.title('Scatter plot')\n\nplt.grid(True)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have used scatter plot in a function and this function will be called using for loop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scatter(df, x, y):\n    #function to plot scatter plots\n    fig, axis = plt.subplots()\n    # Grid lines, Xticks, Xlabel, Ylabel\n\n    axis.yaxis.grid(True)\n    axis.set_title('Scatter Plot',fontsize=10)\n    axis.set_xlabel(x,fontsize=10)\n    axis.set_ylabel(y,fontsize=10)\n\n    X = df[x]\n    Y = df[y]\n\n    axis.scatter(X, Y)\n    plt.show()\n    #End of function\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_df=games_df\nplot_df=plot_df.drop(columns=['id','name','type','average_rating'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig, axs = plt.subplots(1,2)\nfor i in plot_df:\n    print(i+\" Vs average rating\")\n    plot_scatter(games_df, i, 'average_rating')\n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">INFERENCES from  Plots\n    \n* The features don't show linear relation with average_ratings\n* Only average_weight shows little bit linear relationship. We will cross check this with correlation plt.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## CORRELATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df=games_df\ncorr_df=corr_df.drop(columns=['id','name','type'])\ncorr_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(15,15)})\nsns.heatmap(corr_df.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">INFERENCE\n    \n* playingtime, minplaytime, maxplaytime are highly correlated with each other\n* user_rated, total_owners,total_traders, total_wanters,total_wishers, total_comments,total_weights are also highly correlated with each other. \n* total_owners show high correlation with users_rated, total_weights and total_comments\n* total_wanters and total_wishers are highly correlated\n* users_rated is also correlated highly with total_weights and total_comments.\n* none of the variables show high correlation with average_rating\n* average_weight which is a scale for gauging ease of understanding game shows some amount of correlation i.e., 0.33\n* minage also shows 0.3 correlation with average_rating","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Is there a linear relationship between average_weight & average_rating?","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.regplot(x=\"average_weight\", y=\"average_rating\", data=games_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract Features and Target ('average_rating') Values into Separate Dataframes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#All features\nfeatures=['minplayers', 'maxplayers','playingtime', 'minplaytime', 'maxplaytime', 'minage', 'users_rated', 'total_owners',\n      'total_traders', 'total_wanters', 'total_wishers', 'total_comments','total_weights', 'average_weight']\n    \n    \n#Features after removing correlated independent variables    \nfeatures2=['minplayers', 'maxplayers','playingtime', 'minage', 'users_rated', 'average_weight']\n# with target only average weight shows some correlation\n      \n#features=[ 'minage',  'average_weight']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#with features1:\nX = games_df[features]\n#With features 2\nX2 = games_df[features2]\n\ny = games_df['average_rating']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the Dataset into Training and Test Datasets.\nI am splitting test train on the basis of feature1 and feature 2 (less no of features)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=222)#feature 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, test_size=0.30, random_state=222)#  feature2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LINEAR REGRESSION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"   \n* Phase 1:First linear regression model build on features\n\n* Phase 2 :model build on features 2, correlated independent variables removed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = LinearRegression()\nregressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features 2, correlated variables removed\nregressor2 = LinearRegression()\nregressor2.fit(X_train2, y_train2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### result of model with feature 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(regressor.coef_)\nintercept = regressor.intercept_\nprint(\"Intercept\",intercept)\n#coefficient of average_weight is highest , hence 1 unit increase in average weight will increase rating by 0.27 units","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* coefficient of average_weight is highest , hence 1 unit increase in average weight will increase rating by 0.27 units","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### result of model with  feature 2, correlated independent variables removed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(regressor2.coef_)\n\nintercept2 = regressor2.intercept_\nprint(\"Intercept\",intercept2)\nprint(regressor2.score(X_train2, y_train2))\n#coefficient of average_weight is highest , hence 1 unit increase in average weight will increase rating by 0.308 units","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* coefficient of average_weight is highest , hence 1 unit increase in average weight will increase rating by 0.3 units","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Prediction using Linear Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = regressor.predict(X_test)#feature 1\ny_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction2 = regressor2.predict(X_test2)#feature 2\ny_prediction2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\"><br>\nWhat is the mean of the expected target value in test set ?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction\nfrom scipy import stats\n#a = np.arange(y_prediction)\nstats.describe(y_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction2\nfrom scipy import stats\n\nstats.describe(y_prediction2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"variance is less for feature 2 based model but the min and max predicted value vary a lot from actual min and max. Let us calculate Root Mean squared error ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\"><br>\nEvaluate Linear Regression Accuracy using Root Mean Square Error","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\nRMSE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE2 = sqrt(mean_squared_error(y_true = y_test2, y_pred = y_prediction2))\nRMSE2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"High RMSE for both models, model is not fit.\nNext we will use only feature 1 as there is not much difference between the two models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## DECISION TREE REGRESSOR","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = DecisionTreeRegressor(max_depth=10)\nregressor.fit(X_train, y_train)\nprint(regressor.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">Prediction using Decision Tree Regressor\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = regressor.predict(X_test)\ny_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction\nfrom scipy import stats\n\nstats.describe(y_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sqrt(0.939)\n0.9690201236300513*0.9690201236300513","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.25em;color:purple; font-style:bold\">Evaluate Decision Tree Regression Accuracy using Root Mean Square Error","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\nRMSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ADABOOST REGRESSOR","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\n_regressor = AdaBoostRegressor()\n_regressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(_regressor.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = _regressor.predict(X_test)\ny_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\nRMSE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**INFERENCE**\n\n* AdaBoost Regression gave the lowest RMSE\n* RMSE from all the 3 models show that we have high errors and model are not fit\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## CONCLUSIONS\n\nThe high RMSE limits the model to be used in production setting. The\ndata has inherent limitations. From our study, we can see that more important\nfeatures are required to make our model robust. We do not have data on\ndemographics of users that can be incorporated in the model. The data also gives\nlittle information about the game itself.\nAdditional information like category of game or tags that gives information on\ntheme e.g. Strategy, Mystery, Wargame, Sports, etc. could have improved our\nmodel.\nText analytics on User reviews in text form could also help to see the which\nfeatures are influencing user ratings.\nDue to data quality issues, the model was highly underfit. \nThough, we can conclude that our features capture 44% of variance in average_rating.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## FUTURE WORK\n\nIt was exciting to work on real data that might not give expected results. In future, I\nwould like to apply unsupervised learning and create clusters on this data. Feature\nengineering can also be used by creating new features from available data.\nBayesian average rating is another area which would be interesting to look at.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## REFERENCES\n\n1.\nhttps://www.evanmiller.org/bayesian-average-ratings.html\n\n2.\nhttps://github.com/ThaWeatherman/scrapers/tree/master/boardgamegeek\n\n3.\nhttps://en.wikipedia.org/wiki/BoardGameGeek\n\n4.\nhttps://www.kaggle.com/gutsyrobot/games-data/data\n\n5.\nhttps://www.kaggle.com/thuwaarahanragu/basic-data-visualization","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}