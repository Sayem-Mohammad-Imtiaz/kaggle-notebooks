{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading and formatting the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data = pd.read_csv(\"/kaggle/input/instagram-fake-spammer-genuine-accounts/train.csv\")\nY_train = input_data[\"fake\"]\nX_train = input_data.drop(\"fake\", axis=1)\ntest_data = pd.read_csv(\"/kaggle/input/instagram-fake-spammer-genuine-accounts/test.csv\")\nY_test = test_data[\"fake\"]\nX_test = test_data.drop(\"fake\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building the neural network model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import *\nmodel = keras.models.Sequential()\nmodel.add(Dense(50, input_dim = 11, activation=\"relu\"))\nmodel.add(Dense(20, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training and evaluating the model."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras import metrics\nmodel.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\nmodel.fit(X_train, Y_train, batch_size = 40000, epochs = 200, verbose = 0)\nloss = model.evaluate(X_test, Y_test, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making predictions on new data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\nfake = 0\nwith open('fakeAcc', 'w') as csv_file:\n    write = csv.writer(csv_file, delimiter=',')\n    with open('/kaggle/input/jarviscsv/Jarvis.csv', 'rt', encoding='UTF8') as csvfile:\n        readCSV = csv.reader(csvfile, delimiter=',', lineterminator='\\n')\n        for row in readCSV:\n            \n                user = row[0]\n                name = row[1]\n                pic = row[2]\n                bio = row[3]\n                col10 = int(row[4])\n                col11 = int(row[5])\n                col7 = int(row[6])\n                col8 = int(row[7]) \n                col9 = int(row[8])\n\n                #Column 1\n                col1 = 1\n                if pic == 'https://instagram.faep8-2.fna.fbcdn.net/v/t51.2885-19/44884218_345707102882519_2446069589734326272_n.jpg?_nc_ht=instagram.faep8-2.fna.fbcdn.net&_nc_ohc=CgRv3KotZXUAX92x_dJ&oh=9c0e8a7b8e58234fa2e781c4f25d4982&oe=5F17A10F&ig_cache_key=YW5vbnltb3VzX3Byb2ZpbGVfcGlj.2':\n                    col1 = 0\n\n                #Column 2\n                userDigits = 0\n                for i in user:\n                    if i.isdigit():\n                        userDigits += 1\n                col2 = float(userDigits/len(user))\n\n                #Column 3\n                tokens = name.split(\" \")\n                col3 = len(tokens)\n\n                #Column 4\n                nameDigits = 0\n                for i in name:\n                    if i.isdigit():\n                        nameDigits += 1\n                name4 = name.replace(' ', '')\n                if len(name) == 0:\n                    name4 = \" \"\n                col4 = float(nameDigits/len(name4))\n\n                #Column 5\n                col5 = 0\n                if name == user:\n                    col5 = 1\n\n                #Column 6\n                col6 = len(bio)\n                arr = [[col1,col2,col3,col4,col5,col6,col7,col8,col9,col10,col11]]\n                y_pred = model.predict(arr)\n\n                if y_pred[0] == 1:\n                    fake+= 1  \n\n                #Write to file \n\n                write.writerow([user, y_pred[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}