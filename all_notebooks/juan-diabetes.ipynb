{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\\*\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Pima diabetes"},{"metadata":{},"cell_type":"markdown","source":"# 1. Preliminares"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_selection import SelectKBest, chi2, RFE\nfrom sklearn.preprocessing import KBinsDiscretizer, FunctionTransformer, Normalizer\nimport seaborn as sns\nfrom matplotlib import pyplot as mpl\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as panda\nfrom imblearn.over_sampling import SMOTE\n\n\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Añadimos librerias y generamos una seed"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"El conjunto de datos que vamos a emplear es `Pima diabetes`.\nTiene dos posibles resultados.\n\n* `0` Cuando el paciente no tiene diabetes\n* `1` Cuando el paciente tiene diabetes\n\nQue conforman los valores de la variable a predecir, la variable objetivo (`Outcome`). Se tienene en cuenta las siguientes variables predictoras:\n\n* `Age`: Edad del paciente.\n* `Pregnancies`: Número de embarazos de la paciente.\n* `Glucose`: Concentración de glucosa en plasma sanguíneo.\n* `BloodPressure`: Presión diastólica arterial (mm Hg).\n* `SkinThickness`: Grosor de la piel en el triceps (mm).\n* `insulin`: Cantidad de insulina en sangre (mu Insulina/ml).\n* `BMI`: Índice de Masa Corporal (kg/m^2).\n* `DiabetesPedigreeFunction`: Función para el historial de diabetes en la familia del paciente.\n"},{"metadata":{},"cell_type":"markdown","source":"Cargamos el data-set"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\nindex = None\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el caso de Pima Diabetes no disponemos de variable índice, asi que index lo ponemos a \"none\""},{"metadata":{},"cell_type":"markdown","source":"![](http://)"},{"metadata":{},"cell_type":"markdown","source":" Usamos la función head para obtener las n primeras instancias del conjunto de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pero para conseguir una muestra menos sesgada hacemos una aleatoria, porque los data-set suelen estar ordenanos en función de sus variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos conjunto de datos separado dos subconjuntos, uno con las variables predictoras (X) y otro con la variable objetivo (y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que los conjuntos de las variables predictoras y el de la variable objetivo se han sepeparado correctamente"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos también con la variable objetivo:\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para hacer un proceso de Holdout creamos la muestra de Test y la muestra de training con la siguiente proporción:\n\n* Muestra training (70%)\n* Muestra test (típicamente, 30%)\n\n\nPara realizar un *holdout* podemos utilizar el método `train_test_split` de `scikit-learn`:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comenzamos con las variables predictoras del conjunto de datos de training:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hacemos la muestra con el conjunto de training"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Ahora para ver las propiedades de nuestro conjunto de datos y poder sacar conclusiones de cara al preprocesamiento usaremos gráficos y estadisticos."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"Con shape podemos saber la cantidad de casos que hay en nuestra base de datos frente a la cantidad que variables que disponemos, 768 pacientes estudiados frente a las nueve variables que disponemos, que son las diferentes pruebas que se han hecho a estos pacientes."},{"metadata":{},"cell_type":"markdown","source":"Usamos el metodo info para saber de que tipo son las variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En nuestro caso todas las variables predictoras son varibales continuas, y solo la variable obejetivo es una variable discreta,"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestra variable objetivo tiene dos posibles valores, 0 y 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Vamos a comenzar visualizando las variables numéricas del conjunto de datos usando histogramas para las variables numéricas y diagramas de barras para las variables categóricas"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar varias variables tiene tienen datos ruidosos, todos los que tienen una cantidad 0, alejados de la mayoría de valores de esas variables, este sería el caso de`Glucose` , `BloodPressure`, `SkinThickness`,`insulin` y `BMI`. Tambein podemos ver que `SkinThickness`, `Age` y `Insulin` tienen una disposición central. No encuentro valores anomalos en este analisis multivariado."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el caso de nuestra única variable categórica podemos ver que la muestra no esta balanceada, de nuestros 768 pacientes la mayoría dio negativo en tener diabetes como nos dice este analisis univariado."},{"metadata":{},"cell_type":"markdown","source":"A continuacion creamos dos matrices para analizar la correlación entre pares de variables, en el primer caso el numero de cada hueco representa la coincidencia o solopamiento entre variables , que en caso de ser demasiado alta nos podria indicar la redundancia de ciertas variables predictoras"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=mpl.subplots(figsize=(31,31))\ncorrMatrix = X_train.corr()\n\nsns.heatmap(corrMatrix,annot=True,linewidths=.5,fmt=\".1f\",ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viendo el resultado ninguna de las variables predictoras es redundante"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta caso a diferencia de la de iris no podemos averiguar claramente el poder discriminatorio de cada variable predictora pues hay muchos datos ruidosos."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"![](http://)Lo primero que haremos para tratar los datos crudos sera una imputación de valores perdidos,hay varias variables , 'Glucose','BloodPressure','Insulin','BMI','SkinThickness', que por el contexto no deberían tener valores a 0, así que lo que haremos será sustituir esos valores por la mediana de cada uno , separando también segun la variable objetivo."},{"metadata":{},"cell_type":"markdown","source":"[](http://)Calculamos la mediana de esas variables para usarlas a modo de marcador"},{"metadata":{"trusted":true},"cell_type":"code","source":"def medina(variable):\n    sumt1=[]\n    sumt2=[]\n    n1=0\n    n2=0\n    t=0\n    for i in data[variable]:\n        j=data['Outcome'][t]\n        t=t+1\n        if (j==1 and i>0):\n            n1=n1+1\n            sumt1.append(i)\n        elif (j ==0 and i>0):\n            n2=n2+1\n            sumt2.append(i)\n    return (np.median(sumt1),np.median(sumt2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"medina('Glucose')\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"medina('BloodPressure')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"medina('BMI')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"medina('SkinThickness')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"medina('Insulin')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con las medianas calculadas pasamos a remplazar los 0 por NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"col=['Glucose','BloodPressure','Insulin','BMI','SkinThickness']\nfor i in col:\n    data[i].replace(0, np.nan, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora remplazamos los NaN por las medianas calculadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[(data['Outcome'] == 0 ) & (data['Insulin'].isnull()), 'Insulin'] = 102.5\ndata.loc[(data['Outcome'] == 1 ) & (data['Insulin'].isnull()), 'Insulin'] = 169.5\ndata.loc[(data['Outcome'] == 0 ) & (data['Glucose'].isnull()), 'Glucose'] = 107\ndata.loc[(data['Outcome'] == 1 ) & (data['Glucose'].isnull()), 'Glucose'] = 140\ndata.loc[(data['Outcome'] == 0 ) & (data['SkinThickness'].isnull()), 'SkinThickness'] = 27\ndata.loc[(data['Outcome'] == 1 ) & (data['SkinThickness'].isnull()), 'SkinThickness'] = 32\ndata.loc[(data['Outcome'] == 0 ) & (data['BloodPressure'].isnull()), 'BloodPressure'] = 70\ndata.loc[(data['Outcome'] == 1 ) & (data['BloodPressure'].isnull()), 'BloodPressure'] = 74.5\ndata.loc[(data['Outcome'] == 0 ) & (data['BMI'].isnull()), 'BMI'] = 30.1\ndata.loc[(data['Outcome'] == 1 ) & (data['BMI'].isnull()), 'BMI'] = 34.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que los valores con 0 de las variables han sido eliminados"},{"metadata":{},"cell_type":"markdown","source":"Para tratar los datos anomalos usaremos StandarScaler que \"escala\" la propiedad restando por la media y diviendo por la desviación estándar, con esto conseguiremos que los datos anomalos sean menos sesgados que le resto en comparacion con el resto."},{"metadata":{"trusted":true},"cell_type":"code","source":"yOut = data.Outcome\nXOut = data.drop('Outcome', axis = 1)\ncolumns = XOut.columns\nscaler = StandardScaler()\nXOut = scaler.fit_transform(XOut)\ndataOut_x = panda.DataFrame(XOut, columns = columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Creamos nuevos subconjuntos sin los datos anomalos"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(dataOut_x, yOut,\n                                                                    stratify=yOut, random_state = seed, train_size = train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y por último discretizaremos,teniendo en cuenta lo visto en el diagrama de puntos probaremos con las tres discretizaciones , las tres con dos bins ya que nuestra variable objetivo tiene dos valores"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizerQuantile = KBinsDiscretizer(n_bins=2, strategy='quantile')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizerUniform = KBinsDiscretizer(n_bins=2, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizerKmeans = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"Genreamos modelos de ZeroR y de CART. Para ello usamos los siguientes clasificadores de la librería  scikit-learn"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El algoritmo zero_r no nos dara mucha precisión pero nos servira como baseline, como referencia para el resto. Para que salga la clase más frecuente del subconjunto train usamos el hiperparámetro strategy=\"most_frequent\""},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tambien creamos una pipeline para cada una de las discretizaciones y usando el algoritmo CART"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model_Quantile = make_pipeline(discretizerQuantile, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model_Uniform = make_pipeline(discretizerUniform, tree_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model_Kmeans = make_pipeline(discretizerKmeans, tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"* ### ZERO-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El zero-r nos da la precisión más baja de los algoritmos testeados."},{"metadata":{},"cell_type":"markdown","source":"* ### CART sin discretización."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### CART con discretizacion de igual frecuencia (Quantile)"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model_Quantile,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### CART con discretizacion de igual anchura (Uniform)"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model_Uniform,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### CART con discretizacion basada en k-medias (Kmeans)"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model_Kmeans,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver ninguna de las tres discretizaciones resultan en una mejora del algoritmo CART, todo lo contrario pues la precisión del algortimo es sensible superior sin ninguna discretización, aun así podemos observar que la que da mejor resultado de las tres es la discretización de igual anchura. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}