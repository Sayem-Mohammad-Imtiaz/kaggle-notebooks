{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import os\n__print__ = print\ndef print(string):\n    os.system(f'echo \\\"{string}\\\"')\n    __print__(string)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout\nfrom keras.models import Model\n\nimport os,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20, 10\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd# Any results you write to the current directory are saved as output.\nfrom IPython.display import display, Image\nfrom keras.preprocessing.image import ImageDataGenerator,load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, BatchNormalization,Activation,UpSampling2D,Add\n\nimport tensorflow as tf\n# Any results you write to the current directory are saved as output.\nfrom IPython.display import display, Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"class JoinedGen(tf.keras.utils.Sequence):\n    def __init__(self, input_gen, target_gen):\n        self.input_gen = input_gen\n        self.target_gen = target_gen\n\n        assert len(input_gen) == len(target_gen)\n\n    def __len__(self):\n        return len(self.input_gen)\n\n    def __getitem__(self, i):\n        x = self.input_gen[i]\n        y = self.target_gen[i]\n\n        return x, y\n\n    def on_epoch_end(self):\n        self.input_gen.on_epoch_end()\n        self.target_gen.on_epoch_end()\n        self.target_gen.index_array = self.input_gen.index_array\n\n        \ndef get_generator(df,shuffle,rescale,batchSize):\n    generator_imgs = ImageDataGenerator(rescale = rescale)\n    \n    clean_img_gen = generator_imgs.flow_from_dataframe(dataframe=df,\n                                           x_col=\"clean\", \n                                           class_mode=None,\n                                           target_size=(224,224),\n                                           validate_filenames = True,\n                                           shuffle = shuffle,\n                                           batch_size=batchSize)\n    \n    adv_img_gen = generator_imgs.flow_from_dataframe(dataframe=df,\n                                           x_col=\"adv\", \n                                           class_mode=None,\n                                           target_size=(224,224),\n                                           validate_filenames = True,\n                                           shuffle = shuffle,\n                                           batch_size=batchSize)\n    \n    return JoinedGen(adv_img_gen,clean_img_gen)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_filenames(text_file, clean_directory ,adv_directory):\n    \n    clean_imgs = list()\n    adv_imgs = list()\n    \n    with open(text_file,'r') as f:\n        for line in f.readlines():\n            line = line.split()\n            clean_filename = clean_directory + line[0]\n            adv_filename = adv_directory  + line[1]\n            clean_imgs.append(clean_filename)\n            adv_imgs.append(adv_filename)\n            \n    return clean_imgs,adv_imgs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adv_image_dir = '../input/covidx-adversarial-samples/hgd_adv/content/drive/MyDrive/Capstone Project/Dataset/data/forHGD_new/'\nclean_image_dir = '../input/covidx-adversarial-samples/hgd_clean/content/drive/MyDrive/Capstone Project/Dataset/data/forHGD_new_clean/'\n\ntrain_metadata = '../input/covidx-adversarial-samples/forHGD_new_train.txt'\nval_metadata = '../input/covidx-adversarial-samples/forHGD_new_val.txt'\ntest_metadata = '../input/covidx-adversarial-samples/forHGD_new_test.txt'\n\ntrain_clean,train_adv = get_filenames(train_metadata,clean_image_dir,adv_image_dir)\nval_clean,val_adv = get_filenames(val_metadata,clean_image_dir,adv_image_dir)\ntest_clean,test_adv = get_filenames(test_metadata,clean_image_dir,adv_image_dir)\n\n\ndf_train = pd.DataFrame({'clean' : train_clean, 'adv' : train_adv})\ndf_test = pd.DataFrame({'clean' : test_clean, 'adv' : test_adv})\ndf_val = pd.DataFrame({'clean' : val_clean , 'adv' : val_adv})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = get_generator(df_train,shuffle = True, rescale = 1/255 , batchSize = 24)\nvalid_gen = get_generator(df_val,shuffle = True, rescale = 1/255 , batchSize = 24)\ntest_gen = get_generator(df_test,shuffle = True, rescale = 1/255, batchSize =24 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Construction of Model","metadata":{}},{"cell_type":"markdown","source":"## *Feedforward Model*","metadata":{}},{"cell_type":"code","source":"\"\"\"\ninput_layer = Input(shape=(224,224, 3))\n\n\n# Feed Forward path\n\n#Layer-1  C2\nlayer1_conv1 = Conv2D(64,3,padding = 'same')(input_layer)\nlayer1_conv1  = BatchNormalization()(layer1_conv1)\nlayer1_conv1 = Activation(\"relu\")(layer1_conv1)\nlayer1_conv2 = Conv2D(64,3,padding = 'same')(layer1_conv1)\nlayer1_conv2  = BatchNormalization()(layer1_conv2)\nlayer1_conv2 = Activation(\"relu\")(layer1_conv2)\n\n\n#Layer-2 C3\n\nlayer2_conv1 = Conv2D(128,3,strides = (2,2),padding = 'same')(layer1_conv2)\nlayer2_conv1  = BatchNormalization()(layer2_conv1)\nlayer2_conv1 = Activation(\"relu\")(layer2_conv1)\n\nlayer2_conv2 = Conv2D(128,3,padding = 'same')(layer2_conv1)\nlayer2_conv2  = BatchNormalization()(layer2_conv2)\nlayer2_conv2 = Activation(\"relu\")(layer2_conv2)\n\nlayer2_conv3 = Conv2D(128,3,padding = 'same')(layer2_conv2)\nlayer2_conv3  = BatchNormalization()(layer2_conv3)\nlayer2_conv3 = Activation(\"relu\")(layer2_conv3)\n\n#Layer-3 C3\n\n\n\nlayer3_conv1 = Conv2D(256,3,strides = (2,2),padding = 'same')(layer2_conv3)\nlayer3_conv1  = BatchNormalization()(layer3_conv1)\nlayer3_conv1 = Activation(\"relu\")(layer3_conv1)\n\nlayer3_conv2 = Conv2D(256,3,padding = 'same')(layer3_conv1)\nlayer3_conv2  = BatchNormalization()(layer3_conv2)\nlayer3_conv2 = Activation(\"relu\")(layer3_conv2)\n\nlayer3_conv3 = Conv2D(256,3,padding = 'same')(layer3_conv2)\nlayer3_conv3  = BatchNormalization()(layer3_conv3)\nlayer3_conv3 = Activation(\"relu\")(layer3_conv3)\n\n\n#Layer-4 C3\n\n\nlayer4_conv1 = Conv2D(256,3,strides =(2,2),padding = 'same')(layer3_conv3)\nlayer4_conv1  = BatchNormalization()(layer4_conv1)\nlayer4_conv1 = Activation(\"relu\")(layer4_conv1)\n\nlayer4_conv2 = Conv2D(256,3,padding = 'same')(layer4_conv1)\nlayer4_conv2  = BatchNormalization()(layer4_conv2)\nlayer4_conv2 = Activation(\"relu\")(layer4_conv2)\n\nlayer4_conv3 = Conv2D(256,3,padding = 'same')(layer4_conv2)\nlayer4_conv3  = BatchNormalization()(layer4_conv3)\nlayer4_conv3 = Activation(\"relu\")(layer4_conv3)\n\n\n#Layer-5 C3\n\nlayer5_conv1 = Conv2D(256,3,strides = (2,2),padding = 'same')(layer4_conv3)\nlayer5_conv1  = BatchNormalization()(layer5_conv1)\nlayer5_conv1 = Activation(\"relu\")(layer5_conv1)\n\nlayer5_conv2 = Conv2D(256,3,padding = 'same')(layer5_conv1)\nlayer5_conv2  = BatchNormalization()(layer5_conv2)\nlayer5_conv2 = Activation(\"relu\")(layer5_conv2)\n\nlayer5_conv3 = Conv2D(256,3,padding = 'same')(layer5_conv2)\nlayer5_conv3  = BatchNormalization()(layer5_conv3)\nlayer5_conv3 = Activation(\"relu\")(layer5_conv3)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *Feedback Path*","metadata":{}},{"cell_type":"code","source":"\"\"\"\n# Feedback Path\n\n# Layer-6\n\n# F\nlayer6_bi_interpolation = UpSampling2D(interpolation = 'bilinear')(layer5_conv3)\nlayer6_fusion = concatenate([layer4_conv3, layer6_bi_interpolation])\n\n# C3\nlayer6_conv1 = Conv2D(256,3,padding = 'same')(layer6_fusion)\nlayer6_conv1  = BatchNormalization()(layer6_conv1)\nlayer6_conv1 = Activation(\"relu\")(layer6_conv1)\n\nlayer6_conv2 = Conv2D(256,3,padding = 'same')(layer6_conv1)\nlayer6_conv2  = BatchNormalization()(layer6_conv2)\nlayer6_conv2 = Activation(\"relu\")(layer6_conv2)\n\nlayer6_conv3 = Conv2D(256,3,padding = 'same')(layer6_conv2)\nlayer6_conv3  = BatchNormalization()(layer6_conv3)\nlayer6_conv3 = Activation(\"relu\")(layer6_conv3)\n\n#Layer -7 \n\n# F\nlayer7_bi_interpolation = UpSampling2D(interpolation = 'bilinear')(layer6_conv3)\nlayer7_fusion = concatenate([layer3_conv3, layer7_bi_interpolation])\n\n# C3\nlayer7_conv1 = Conv2D(256,3,padding = 'same')(layer7_fusion)\nlayer7_conv1  = BatchNormalization()(layer7_conv1)\nlayer7_conv1 = Activation(\"relu\")(layer7_conv1)\n\nlayer7_conv2 = Conv2D(256,3,padding = 'same')(layer7_conv1)\nlayer7_conv2  = BatchNormalization()(layer7_conv2)\nlayer7_conv2 = Activation(\"relu\")(layer7_conv2)\n\nlayer7_conv3 = Conv2D(256,3,padding = 'same')(layer7_conv2)\nlayer7_conv3  = BatchNormalization()(layer7_conv3)\nlayer7_conv3 = Activation(\"relu\")(layer7_conv3)\n\n\n\n#Layer -8 \n\n# F\nlayer8_bi_interpolation = UpSampling2D(interpolation = 'bilinear')(layer7_conv3)\nlayer8_fusion = concatenate([layer2_conv3, layer8_bi_interpolation])\n\n# C3\nlayer8_conv1 = Conv2D(128,3,padding = 'same')(layer8_fusion)\nlayer8_conv1  = BatchNormalization()(layer8_conv1)\nlayer8_conv1 = Activation(\"relu\")(layer8_conv1)\n\nlayer8_conv2 = Conv2D(128,3,padding = 'same')(layer8_conv1)\nlayer8_conv2  = BatchNormalization()(layer8_conv2)\nlayer8_conv2 = Activation(\"relu\")(layer8_conv2)\n\nlayer8_conv3 = Conv2D(128,3,padding = 'same')(layer8_conv2)\nlayer8_conv3  = BatchNormalization()(layer8_conv3)\nlayer8_conv3 = Activation(\"relu\")(layer8_conv3)\n\n#Layer -9 \n\n# F\nlayer9_bi_interpolation = UpSampling2D(interpolation = 'bilinear')(layer8_conv3)\nlayer9_fusion = concatenate([layer1_conv2, layer9_bi_interpolation])\n\n# C2\nlayer9_conv1 = Conv2D(64,3,padding = 'same')(layer9_fusion)\nlayer9_conv1  = BatchNormalization()(layer9_conv1)\nlayer9_conv1 = Activation(\"relu\")(layer9_conv1)\n\nlayer9_conv2 = Conv2D(64,3,padding = 'same')(layer9_conv1)\nlayer9_conv2  = BatchNormalization()(layer9_conv2)\nlayer9_conv2 = Activation(\"relu\")(layer9_conv2)\n\n# Layer-10 \n\n# Conv 1x1\n\nlayer_10_conv1 = Conv2D(3,1,padding='same')(layer9_conv2)\n\n# Layer-11\n\nlayer_11_sum = Add()([layer_10_conv1,input_layer])\n\noutput_layer = layer_11_sum\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_unet = Model(input_layer,output_layer)\n# model_unet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# tf.keras.utils.plot_model(model_unet, show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Training Of Model*\n","metadata":{}},{"cell_type":"code","source":"# model_unet.compile(optimizer='adam', loss='MSE',metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir './Model_19March/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import keras.callbacks\n# path = './Model_19March/'\n# class CustomSaver(keras.callbacks.Callback):\n#     def on_epoch_end(self, epoch, logs={}):  # or save after some epoch, each k-th epoch etc.\n#             self.model.save(path + \"/model_{}\".format(epoch))\n# saver = CustomSaver()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with tf.device('/gpu:0'):\n#     history = model_unet.fit(train_gen,\n#                     epochs=100,\n#                     shuffle=True,\n#                     validation_data=valid_gen,\n#                     callbacks=[saver])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# import time\n# test_gen.input_gen.reset()\n# test_gen.target_gen.reset()\n\n# adv = model_unet.predict(test_gen)\n# clean = list()\n# fname = list()\n# for i in range(len(df_test)):\n#     img = cv2.imread(df_test['clean'][i])\n#     img = cv2.normalize(img, None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n#     fname.append(df_test['clean'][i])\n#     print(i)\n#     clean.append(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from skimage.measure import compare_ssim, compare_psnr\n# from skimage.metrics import structural_similarity \n# from skimage import data, img_as_float\n\n# print(structural_similarity(np.array(clean), adv,multichannel = True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Construction of Model","metadata":{}},{"cell_type":"code","source":"try:\n    del model_unet\nexcept:\n    pass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(input_layer):\n    conv1 = Conv2D(64,(3,3), activation='relu', padding='same')(input_layer)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(64,(3,3), activation='relu', padding='same')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D((2,2))(conv1)\n#     pool1 = Dropout(0.25)(pool1)\n    \n#     conv2 = Conv2D(128,(3,3),strides = (2,2), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128,(3,3), activation='relu', padding='same')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(128,(3,3), activation='relu', padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(128,(3,3), activation='relu', padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D((2,2))(conv2)\n#     pool2 = Dropout(0.5)(pool2)\n\n#     conv3 = Conv2D(256,(3,3),strides =(2,2), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256,(3,3), activation='relu', padding='same')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(256,(3,3), activation='relu', padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(256,(3,3), activation='relu', padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPooling2D((2,2))(conv3)\n#     pool3 = Dropout(0.5)(pool3)\n    \n#     conv4 = Conv2D(256,(3,3),strides =(2,2), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256,(3,3), activation='relu', padding='same')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256,(3,3), activation='relu', padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256,(3,3), activation='relu', padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    pool4 = MaxPooling2D((2,2))(conv4)\n#     pool4 = Dropout(0.5)(pool4)\n\n#     convm = Conv2D(256,(3,3),strides =(2,2), activation='relu', padding='same')(pool4)\n    convm = Conv2D(256,(3,3), activation='relu', padding='same')(pool4)\n    convm = BatchNormalization()(convm)\n    convm = Conv2D(256,(3,3), activation='relu', padding='same')(convm)\n    convm = BatchNormalization()(convm)\n    convm = Conv2D(256,(3,3), activation='relu', padding='same')(convm)\n    convm = BatchNormalization()(convm)\n    \n    deconv4 = Conv2DTranspose(256,(3,3), strides=(2,2), padding='same')(convm)\n    deconv4 = BatchNormalization()(deconv4)\n    \n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(256,(3,3), activation='relu', padding='same')(uconv4)\n    uconv4 = BatchNormalization()(uconv4)\n    uconv4 = Conv2D(256,(3,3), activation='relu', padding='same')(uconv4)\n    uconv4 = BatchNormalization()(uconv4)\n    uconv4 = Conv2D(256,(3,3), activation='relu', padding='same')(uconv4)\n    uconv4 = BatchNormalization()(uconv4)\n    \n    deconv3 = Conv2DTranspose(256,(3,3), strides=(2,2), padding='same')(uconv4)\n    deconv3 = BatchNormalization()(deconv3)\n\n    uconv3 = concatenate([deconv3, conv3])\n#     uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(256, (3,3), activation='relu', padding='same')(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    uconv3 = Conv2D(256, (3,3), activation='relu', padding='same')(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    uconv3 = Conv2D(256, (3,3), activation='relu', padding='same')(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    \n    deconv2 = Conv2DTranspose(128,(3,3), strides=(2,2), padding='same')(uconv3)\n    deconv2 = BatchNormalization()(deconv2)\n    \n    uconv2 = concatenate([deconv2, conv2])\n#     uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(128, (3,3), activation='relu', padding='same')(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = Conv2D(128, (3,3), activation='relu', padding='same')(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = Conv2D(128, (3,3), activation='relu', padding='same')(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n\n    \n    deconv1 = Conv2DTranspose(64,(3,3), strides=(2,2), padding='same')(uconv2)\n    deconv1 = BatchNormalization()(deconv1)\n    uconv1 = concatenate([deconv1, conv1])\n#     uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(64, (3,3), activation='relu', padding='same')(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    uconv1 = Conv2D(64, (3,3), activation='relu', padding='same')(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    \n    last_layer = Conv2D(3, (1,1), padding='same', activation = 'sigmoid')(uconv1)\n    \n    \n    output_layer = Add()([last_layer,input_layer])\n    return output_layer\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_model(input_layer, start_neurons):\n#     64\n#     conv1 = Conv2D(start_neurons*1,(3,3), activation='relu', padding='same')(input_layer)\n#     conv1 = Conv2D(start_neurons*1,(3,3), activation='relu', padding='same')(conv1)\n#     pool1 = MaxPooling2D((2,2))(conv1)\n#     pool1 = Dropout(0.25)(pool1)\n    \n#     conv2 = Conv2D(start_neurons*2,(3,3), activation='relu', padding='same')(pool1)\n#     conv2 = Conv2D(start_neurons*2,(3,3), activation='relu', padding='same')(conv2)\n#     pool2 = MaxPooling2D((2,2))(conv2)\n#     pool2 = Dropout(0.5)(pool2)\n\n#     conv3 = Conv2D(start_neurons*4,(3,3), activation='relu', padding='same')(pool2)\n#     conv3 = Conv2D(start_neurons*4,(3,3), activation='relu', padding='same')(conv3)\n#     pool3 = MaxPooling2D((2,2))(conv3)\n#     pool3 = Dropout(0.5)(pool3)\n    \n#     conv4 = Conv2D(start_neurons*8,(3,3), activation='relu', padding='same')(pool3)\n#     conv4 = Conv2D(start_neurons*8,(3,3), activation='relu', padding='same')(conv4)\n#     pool4 = MaxPooling2D((2,2))(conv4)\n#     pool4 = Dropout(0.5)(pool4)\n\n#     #Middle\n#     convm = Conv2D(start_neurons * 16, (3,3), activation='relu', padding='same')(pool4)\n#     convm = Conv2D(start_neurons * 16, (3,3), activation='relu', padding='same')(convm)\n    \n#     #upconv part\n#     deconv4 = Conv2DTranspose(start_neurons*8,(3,3), strides=(2,2), padding='same')(convm)\n#     uconv4 = concatenate([deconv4, conv4])\n#     uconv4 = Dropout(0.5)(uconv4)\n#     uconv4 = Conv2D(start_neurons*8, (3,3), activation='relu', padding='same')(uconv4)\n#     uconv4 = Conv2D(start_neurons*8, (3,3), activation='relu', padding='same')(uconv4)\n    \n#     deconv3 = Conv2DTranspose(start_neurons*8,(3,3), strides=(2,2), padding='same')(uconv4)\n#     uconv3 = concatenate([deconv3, conv3])\n#     uconv3 = Dropout(0.5)(uconv3)\n#     uconv3 = Conv2D(start_neurons*4, (3,3), activation='relu', padding='same')(uconv3)\n#     uconv3 = Conv2D(start_neurons*4, (3,3), activation='relu', padding='same')(uconv3)\n    \n#     deconv2 = Conv2DTranspose(start_neurons*8,(3,3), strides=(2,2), padding='same')(uconv3)\n#     uconv2 = concatenate([deconv2, conv2])\n#     uconv2 = Dropout(0.5)(uconv2)\n#     uconv2 = Conv2D(start_neurons*2, (3,3), activation='relu', padding='same')(uconv2)\n#     uconv2 = Conv2D(start_neurons*2, (3,3), activation='relu', padding='same')(uconv2)\n    \n#     deconv1 = Conv2DTranspose(start_neurons*8,(3,3), strides=(2,2), padding='same')(uconv2)\n#     uconv1 = concatenate([deconv1, conv1])\n#     uconv1 = Dropout(0.5)(uconv1)\n#     uconv1 = Conv2D(start_neurons*1, (3,3), activation='relu', padding='same')(uconv1)\n#     uconv1 = Conv2D(start_neurons*1, (3,3), activation='relu', padding='same')(uconv1)\n    \n#     output_layer = Conv2D(3, (1,1), padding='same', activation='sigmoid')(uconv1)\n#     return output_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Defining target image size and Input size and building model\nimg_size_target = 224\ninput_layer = Input((img_size_target, img_size_target,3))\noutput_layer = build_model(input_layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nsurrogate_model = load_model('../input/best-model/Best_Model_20.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_func(y_true,y_pred):\n    true = surrogate_model(y_true)\n    pred = surrogate_model(y_pred)\n#     mse_loss = tf.keras.losses.MSE(y_true,y_pred)\n    hgd_loss = tf.math.reduce_mean(tf.abs(true - pred))\n#     pgd_loss = tf.math.reduce_mean(tf.abs(y_true - y_pred))\n    # msle\n#     return tf.add(hgd_loss,pgd_loss)\n    return hgd_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initializing and compiling model\nmodel_unet = Model(input_layer, output_layer)\nmodel_unet.compile(optimizer='adam', loss=loss_func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET Summary","metadata":{}},{"cell_type":"code","source":"# model_unet.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"import keras\n\ncheckpoint_path = \"Model_PGD\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights every 5 epochs\ncp_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_path, \n    verbose=1, \n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_unet.fit(x_train_noisy, x_train,\n#                 epochs=15,\n#                 batch_size=64,\n#                 shuffle=True,\n#                 validation_data=(x_test_noisy, x_test))\n# import keras.callbacks\n# path = './HGD_MODEL_Kaggle/'\n# class CustomSaver(keras.callbacks.Callback):\n#     def on_epoch_end(self, epoch, logs={}):  # or save after some epoch, each k-th epoch etc.\n#             self.model.save(path + \"model_{}\".format(epoch))\n# saver = CustomSaver()\n\nwith tf.device('/device:GPU:0'):\n    history = model_unet.fit(train_gen,\n                    epochs=100,\n                    shuffle=True,\n                    validation_data=valid_gen,\n                    callbacks = [cp_callback])","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}