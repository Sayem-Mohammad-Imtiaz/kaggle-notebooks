{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tech Assignment:**\n\n\nPROBLEM: EazyDiner is a table reservation platform for consumers looking for dining places. Will a new customer who signs up with us, make a booking in the first 7 days of signing up? If the probability is <20% then keep it in a 0 bucket otherwise in a 1 bucket.\n \n\n====================================================================================================","metadata":{}},{"cell_type":"markdown","source":"Whole customers can be divided into 2 groups.\n\n**1. who signed up but not booked.**\n\n**2. who signed up and booked.**\n\nFurther those who booked can be classified into two groups\n\n**1. who booked within 7 days of their signup.**\n\n**2. who booked after 7 days of their signup.**\n\nFrom step/code 1 to 7 is used to extract those customers who booked within 7 days of their signup.\nStep/code 8 and 9 is used to answer the question-\"**If the probability is <20% then keep it in a       0 bucket otherwise in a 1 bucket.**\"\n\n\n=====================================================================================================","metadata":{}},{"cell_type":"code","source":"import os          \nos.getcwd()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=====================================================================================================\n#### 1. Below code:-\nwill extract only (cust_id & signup_date) columns from \"0_Sample_BOOKINGS_Dataset_1.xlsx - SEPT-NOV_CUST_DATA_BOOKINGS.csv\" then store them into dictionary \"signup\"\n\nand will extract only (cust_id & date) columns from \"0_Sample_CUSTOMER_Dataset_2.xlsx - SEPT-NOV_CUST_DATA.csv\" then store them into dictionary \"booking\"\n\nAfter that it compare those two dictionary \"signup\" and \"booking\" against key(\"cust_id\") then drop those key & value pair if \"cust_id\" don't match.\n\n=====================================================================================================","metadata":{}},{"cell_type":"markdown","source":"##================Don't run this script, I stored the output and used further where required=========\n##================This script will take 30-35 minute to run =================\n##code\\extracting_Dictionary_From_Rawdata.py\n\nimport pandas as pd\nimport itertools\n\nA = pd.read_csv(r\"../input/eazydiner/0_Sample_BOOKINGS_Dataset_1.xlsx - SEPT-NOV_CUST_DATA_BOOKINGS.csv\")\nB = pd.read_csv(r\"../input/eazydiner/0_Sample_CUSTOMER_Dataset_2.xlsx - SEPT-NOV_CUST_DATA.csv\")\n\nmy_booking_date = A['date'].tolist()\nmy_cust_id = A['cust_id'].tolist()\n\nmy_signup_date = B['signup_date'].tolist()\nmy_cust_ids = B['cust_id'].tolist()\n\n\nbooking = dict(zip(my_cust_id, my_booking_date))   \nsignup = dict(zip(my_cust_ids, my_signup_date))   \ne = {}   # signup dictionary common/intersection  with booking dictionary [key value pair are stored in sign_new.csv file]\n\nprint(dict(itertools.islice(booking.items(), 12)))\nprint(dict(itertools.islice(signup.items(), 12)))\n\nfor i in booking:\n    for j in signup:\n        if i == str(j):\n            e[str(j)] = signup[j]\n            #print(e)\n            #print(len(e))\n            if len(e) % 1000 == 0:\n                print(str((len(e)*100)/61333) + '% completed') \n\nprint(len(e))\nprint(e)\nprint(\"Done\")\n\n##================This script will take 30-35 minute to run =================\n##================Don't run this script, I stored the output and used further where required=========","metadata":{}},{"cell_type":"markdown","source":"=====================================================================================================\n\nOutput of Dictionary **\"e\"** is stored in **3_sign_new.py** and\n\nOutput of Dictionary **\"booking\"** is stored in **3_book_new.py** and\n\nthese two files are kept in input data section of kaggle.\n\n=====================================================================================================","metadata":{}},{"cell_type":"markdown","source":"#### 2. Below code will copy **3_sign_new.py,3_book_new.py,4_book_df.csv,4_sign_df.csv** from input data to kaggle **working directory**","metadata":{}},{"cell_type":"code","source":"from shutil import copyfile\ncopyfile(src = \"../input/eazydiner/3_sign_new.py\", dst = \"../working/sign_new.py\")\ncopyfile(src = \"../input/eazydiner/3_book_new.py\", dst = \"../working/book_new.py\")\ncopyfile(src = \"../input/eazydiner/4_book_df.csv\", dst = \"../working/4_book_df.csv\")\ncopyfile(src = \"../input/eazydiner/4_sign_df.csv\", dst = \"../working/4_sign_df.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Below code will convert the dictionary form \"**book_new.py**\" into **CSV** file \"**4_book_df.csv**\"","metadata":{}},{"cell_type":"code","source":"# code\\dict_to_CSV_signCommonData_new.py\n\nimport csv\nfrom book_new import *\n\nprint(len(book_new))\n\na_file = open(\"./4_book_df.csv\", \"w\")\nwriter = csv.writer(a_file)\nfor key, value in book_new.items():\n    writer.writerow([key, value])\n\na_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. Below code will convert the dictionary form \"**sign_new.py**\" into **CSV** file \"**4_sign_df.csv**\"","metadata":{}},{"cell_type":"code","source":"import csv\nfrom sign_new import *\n\nprint(len(sign_new))\n\na_file = open(\"./4_sign_df.csv\", \"w\")\nwriter = csv.writer(a_file)\nfor key, value in sign_new.items():\n    writer.writerow([key, value])\n\na_file.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. Below code will merge two CSV files **\"4_sign_df.csv\", \"4_book_df.csv\"** into one CSV file **\"mergedCSV.csv\"**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# reading two csv files\ndata1 = pd.read_csv(r\"../input/eazydiner/4_sign_df.csv\")\ndata2 = pd.read_csv(r\"../input/eazydiner/4_book_df.csv\")\n\n# using merge function by setting how='inner'\ndf = pd.merge(data1, data2, how='inner')\n\n#print(type(df))\nprint(df.head())\n\ndf.to_csv('mergedCSV.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6. Below code will convert **string object to datetime object** and **update dataframe** of both **signup_date & book_date columns**\n#### For example convert **9/1/2020 to 2020-09-01 00:00:00**","metadata":{}},{"cell_type":"code","source":"#converting string object to datetime object and update dataframe\n# both signup_date & book_date columns updated\nimport datetime as dt\nimport pandas as pd\n\ndf3 = pd.read_csv(r\"../input/eazydiner/5_mergedCSV_clean.csv\")\na = df3['signup_date'].tolist()\nb = df3['book_date'].tolist()\n\n#print(len(a))\n#print(len(b))\n\nfor count,ele in enumerate(a):\n    #print(ele)\n    #print(type(ele))\n    date_time_obj = dt.datetime.strptime(ele, '%m/%d/%Y')\n    #print(date_time_obj)\n    #print(type(date_time_obj))\n    df3.at[count,'signup_date']= date_time_obj\n\nfor count,ele in enumerate(b):\n    #print(ele)\n    #print(type(ele))\n    date_time_obj1 = dt.datetime.strptime(ele, '%m/%d/%Y')\n    #print(date_time_obj)\n    #print(type(date_time_obj))\n    df3.at[count,'book_date']= date_time_obj1\n\n#print(df3.head())\n\ndf3['Diff_day'] = (df3['book_date'] - df3['signup_date']).dt.days\n\nprint(df3.head())\n\ndf3.to_csv('mergedCSV_cleanDay.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7. Below code will find number of days after which a customer will book after signup i.e we need to **find difference between signup date and book date**\n\n#### Then remove rows of dataframe where **Diff_day** is more than 7\n","metadata":{}},{"cell_type":"code","source":"# Removing rows of dataframe where Diff_day > 7\n\nimport pandas as pd\n\ndf1 = pd.read_csv(r\"../input/eazydiner/6_mergedCSV_cleanDayFinal.csv\")\ndel df1['Unnamed: 0']\n#print(df1.head())\n\na = df1['Diff_day'].tolist()\nlst = []\nfor count,ele in enumerate(a):\n    #print(type(ele))\n    if ele > 7:\n        #print(ele)\n        #print(count)\n        lst.append(count)\n\n    #df1.drop(count)\n    #update_df = df1\n#print(lst)\n\nupdate_df = df1.drop(lst)\nprint(update_df.head())\nupdate_df.to_csv('7_mergedCSV_cleanDayFinal7.csv')\nprint(\"DONE\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=====================================================================================================\n\nAfter finding those customers who booked within 7 days of their signup now we need to segregate them into two groups i.e\n\n**1. The customers those who have probability of booking within 7 days less than 20%--(Kept in Bucket0)**\n\n**2. The customers those who have probability of booking within 7 days more than 20%--(Kept in Bucket0)**\n\nFrom **histogram and cummulative distribution of difference days**(bookdate-signupdate) it is found that,\n\n**the customers who books within (2 0r 3 or 4 or 5 or 6 or 7)days are are having probability less than 20% so kept in bucket0.**\n\n**And the customers who books within (0 or 1)days are are having probability more than 20% so kept in bucket1.**\n\nHistogram and Cummulative distributions are kept in Input section of kaggle.\n\n=====================================================================================================","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### 8. Below code will separate **\"Diff_day\" of (0 & 1) and (2 & 3 & 4 & 5 & 6 & 7)** and store them in separate CSV files **\"9_01.csv\" and \"10_234567.csv\"**","metadata":{}},{"cell_type":"code","source":"# extracting/separating (0 & 1) and (2 & 3 & 4 & 5 & 6 & 7) Diff_day cust_id from whole\n\nimport pandas as pd\n\ndf1 = pd.read_csv(r\"../input/eazydiner/8_mergedCSV_cleanDayFinal7_remov_signD_bookD.csv\")\ndel df1['Unnamed: 0']\n#print(df1.head())\n\na = df1['Diff_day'].tolist()\nlst1 = []\nlst2 = []\nfor count,ele in enumerate(a):\n\n    if ele == 7 or ele == 6 or ele == 5 or ele == 4 or ele == 3 or ele == 2:\n        #print(ele)\n        #print(count)\n        lst1.append(count)\n    else:\n        lst2.append(count)\n\n#print(lst1)\n\nupdate_df1 = df1.drop(lst1)\nupdate_df2 = df1.drop(lst2)\nprint(update_df1.head())\nprint(update_df.head())\nupdate_df1.to_csv('9_01.csv')\nupdate_df2.to_csv('10_234567.csv')\nprint(\"DONE\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9. Below code will delete **Diff_day** columns from **01.csv & 234567.csv** file then savig them to **bucket1.csv and bucket0.csv** files resp.\n","metadata":{}},{"cell_type":"code","source":"# deleting Diff_day columns from 01.csv & 234567.csv file then savig them to bucket1.csv and bucket0.csv files resp.\n\n\nimport pandas as pd\n\ndf1 = pd.read_csv(r\"../input/eazydiner/9_01.csv\")\ndf2 = pd.read_csv(r\"../input/eazydiner/10_234567.csv\")\n\ndel df1['Unnamed: 0']\ndel df2['Unnamed: 0']\ndel df1['Diff_day']\ndel df2['Diff_day']\nprint(df1.head())\nprint(df2.head())\n\ndf1.to_csv('bucket1.csv')\ndf2.to_csv('bucket0.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Output\n### **bucket0.csv** and **bucket1.csv** are the **final buckets** of customers as per requirment.","metadata":{}}]}