{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:51.96854Z","iopub.execute_input":"2021-08-22T06:13:51.968869Z","iopub.status.idle":"2021-08-22T06:13:51.973007Z","shell.execute_reply.started":"2021-08-22T06:13:51.968839Z","shell.execute_reply":"2021-08-22T06:13:51.972145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/fraud-detection-bank-dataset-20k-records-binary/fraud_detection_bank_dataset.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.027378Z","iopub.execute_input":"2021-08-22T06:13:52.027651Z","iopub.status.idle":"2021-08-22T06:13:52.16768Z","shell.execute_reply.started":"2021-08-22T06:13:52.027627Z","shell.execute_reply":"2021-08-22T06:13:52.166785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.169037Z","iopub.execute_input":"2021-08-22T06:13:52.1695Z","iopub.status.idle":"2021-08-22T06:13:52.186253Z","shell.execute_reply.started":"2021-08-22T06:13:52.169465Z","shell.execute_reply":"2021-08-22T06:13:52.185458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['Unnamed: 0'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.187964Z","iopub.execute_input":"2021-08-22T06:13:52.188449Z","iopub.status.idle":"2021-08-22T06:13:52.201762Z","shell.execute_reply.started":"2021-08-22T06:13:52.188414Z","shell.execute_reply":"2021-08-22T06:13:52.200928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.203146Z","iopub.execute_input":"2021-08-22T06:13:52.203502Z","iopub.status.idle":"2021-08-22T06:13:52.214984Z","shell.execute_reply.started":"2021-08-22T06:13:52.203469Z","shell.execute_reply":"2021-08-22T06:13:52.21413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'nnumber of columns {len(df.columns)}')","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.245678Z","iopub.execute_input":"2021-08-22T06:13:52.245939Z","iopub.status.idle":"2021-08-22T06:13:52.250338Z","shell.execute_reply.started":"2021-08-22T06:13:52.245916Z","shell.execute_reply":"2021-08-22T06:13:52.249425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'total number of na values : {df.isna().sum().sum()}')","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.251954Z","iopub.execute_input":"2021-08-22T06:13:52.252541Z","iopub.status.idle":"2021-08-22T06:13:52.265185Z","shell.execute_reply.started":"2021-08-22T06:13:52.252506Z","shell.execute_reply":"2021-08-22T06:13:52.264084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.312151Z","iopub.execute_input":"2021-08-22T06:13:52.312442Z","iopub.status.idle":"2021-08-22T06:13:52.570493Z","shell.execute_reply.started":"2021-08-22T06:13:52.312419Z","shell.execute_reply":"2021-08-22T06:13:52.56949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function will drop the list of columns who have only have one unique value\ndef func1(df):\n    l = []\n    for i in df.columns:\n        if len(df[i].unique()) <2:\n            l.append(i)\n    df = df.drop(l,axis =1)\n    return df\n\ndf = func1(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.572062Z","iopub.execute_input":"2021-08-22T06:13:52.572421Z","iopub.status.idle":"2021-08-22T06:13:52.609616Z","shell.execute_reply.started":"2021-08-22T06:13:52.572386Z","shell.execute_reply":"2021-08-22T06:13:52.608719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(100,70))\nsns.heatmap(df.corr(),annot = True,linewidths=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:13:52.611606Z","iopub.execute_input":"2021-08-22T06:13:52.612193Z","iopub.status.idle":"2021-08-22T06:14:37.765342Z","shell.execute_reply.started":"2021-08-22T06:13:52.612153Z","shell.execute_reply":"2021-08-22T06:14:37.761353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func2(df):\n    x  = df.drop(['targets'],axis = 1)\n    col = x.columns\n    y = df['targets']\n    from sklearn.preprocessing import MinMaxScaler\n    norm = MinMaxScaler()\n    X = norm.fit_transform(x)\n    df1 = pd.concat([pd.DataFrame(X,columns = col ),y],axis = 1)\n    return df1\ndf = func2(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:14:37.766979Z","iopub.execute_input":"2021-08-22T06:14:37.767516Z","iopub.status.idle":"2021-08-22T06:14:37.815787Z","shell.execute_reply.started":"2021-08-22T06:14:37.767477Z","shell.execute_reply":"2021-08-22T06:14:37.814915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function will remove features who are least related to Dependent variable\ndef func3(df):\n    from sklearn.feature_selection import SelectKBest, chi2\n    x  = df.drop(['targets'],axis = 1)\n    y = df['targets']\n    best_feature = SelectKBest(score_func = chi2,k = len(x.columns))\n    fit = best_feature.fit(x,y)\n    scores = fit.scores_\n    columns = x.columns\n    l = []\n    for i in range(len(columns)):\n        if scores[i]<1:\n            l.append(columns[i])\n    X = x.drop(l,axis = 1)\n    df1 = pd.concat([X,y],axis = 1)\n    return df1\n\ndf = func3(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:14:37.817366Z","iopub.execute_input":"2021-08-22T06:14:37.818013Z","iopub.status.idle":"2021-08-22T06:14:37.872434Z","shell.execute_reply.started":"2021-08-22T06:14:37.81797Z","shell.execute_reply":"2021-08-22T06:14:37.871443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function will represent scale\ndef func4(df):\n    from sklearn.ensemble import ExtraTreesClassifier\n    x  = df.drop(['targets'],axis = 1)\n    y = df['targets']\n    model = ExtraTreesClassifier()\n    model.fit(x,y)\n    imp_fet = pd.Series(model.feature_importances_,index = x.columns)\n    plt.figure(figsize=(100,70))\n    imp_fet.nlargest(len(x.columns)).plot(kind = 'barh')\n    plt.show()\nfunc4(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:14:37.873969Z","iopub.execute_input":"2021-08-22T06:14:37.874624Z","iopub.status.idle":"2021-08-22T06:14:41.849638Z","shell.execute_reply.started":"2021-08-22T06:14:37.874581Z","shell.execute_reply":"2021-08-22T06:14:41.848786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['col_91','col_40','col_103','col_93','col_105','col_72','col_88','col_59','col_101','col_80','col_88','col_59','col_75','col_61','col_45','col_100','col_43','col_32'],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:14:41.851909Z","iopub.execute_input":"2021-08-22T06:14:41.852359Z","iopub.status.idle":"2021-08-22T06:14:41.861426Z","shell.execute_reply.started":"2021-08-22T06:14:41.852325Z","shell.execute_reply":"2021-08-22T06:14:41.860596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function will over Sample Minority class by duplication\ndef func5(df):\n    from imblearn.over_sampling import RandomOverSampler\n    oversam = RandomOverSampler(sampling_strategy='minority')\n    x  = df.drop(['targets'],axis = 1)\n    y = df['targets']\n    X , Y = oversam.fit_resample(x,y)\n    df1 = pd.concat([X,Y],axis =1)\n    return df1\ndf = func5(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:14:41.863269Z","iopub.execute_input":"2021-08-22T06:14:41.863715Z","iopub.status.idle":"2021-08-22T06:14:41.91692Z","shell.execute_reply.started":"2021-08-22T06:14:41.863645Z","shell.execute_reply":"2021-08-22T06:14:41.916048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this function will fill with  outliners quantile value\ndef func6(df):\n    for i in df.columns:\n        if i!='targets':\n            q1 = df[i].quantile(0.25)\n            q3 = df[i].quantile(0.75)\n            iqr = q3 - q1\n            low = q1 -1.5*iqr\n            high = q3+ 1.5*iqr\n            out1 = df[(df[i]<low)].values\n            out2 = df[(df[i]>high)].values\n            df[i].replace(out1,low,inplace = True)\n            df[i].replace(out2,high,inplace = True)\n    return df\nprint(df.shape)\ndf = func6(df)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:14:41.918415Z","iopub.execute_input":"2021-08-22T06:14:41.918796Z","iopub.status.idle":"2021-08-22T06:17:58.548554Z","shell.execute_reply.started":"2021-08-22T06:14:41.918741Z","shell.execute_reply":"2021-08-22T06:17:58.547686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.drop(['targets'],axis = 1)\ny = df['targets']","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:17:58.569063Z","iopub.execute_input":"2021-08-22T06:17:58.571876Z","iopub.status.idle":"2021-08-22T06:17:58.593694Z","shell.execute_reply.started":"2021-08-22T06:17:58.57184Z","shell.execute_reply":"2021-08-22T06:17:58.592779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func7(model,x,y):\n    from sklearn.model_selection import train_test_split\n    x_train,x_test,y_train,y_test = train_test_split(x,y,shuffle = False,test_size = 0.3,random_state = 0,shuffle = False)\n    model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    score1 = model.score(x_test,y_test)\n    from numpy import mean\n    from sklearn.model_selection import KFold, cross_val_score\n    cv = KFold(n_splits=10, random_state=1, shuffle= True)\n    score2 = mean(cross_val_score(model, x, y, scoring = 'accuracy', cv = cv ,n_jobs=-1))\n    from sklearn.metrics import accuracy_score, log_loss \n    from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score \n    score3 = accuracy_score(y_test,y_pred)\n    score5 = precision_score(y_test,y_pred)\n    score6 = recall_score(y_test,y_pred)\n    score7 = f1_score(y_test,y_pred)    \n    a = (score1 + score2 + score3 + score5 + score6 + score7)/6\n    return a","metadata":{"execution":{"iopub.status.busy":"2021-08-22T06:18:35.832305Z","iopub.execute_input":"2021-08-22T06:18:35.832734Z","iopub.status.idle":"2021-08-22T06:18:35.844225Z","shell.execute_reply.started":"2021-08-22T06:18:35.832697Z","shell.execute_reply":"2021-08-22T06:18:35.843149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def func8(x,y):\n    l = []\n    def m1(x,y):\n        from sklearn.linear_model import LogisticRegression\n        a  = None\n        return a\n    \n    def m2(x,y):\n        from sklearn.naive_bayes import GaussianNB\n        a  = None\n        return a\n\n    def m3(x,y):\n        from sklearn.linear_model import SGDClassifier\n        a  = None\n        return a\n\n    def m4(x,y):\n        from sklearn.neighbors import KNeighborsClassifier\n        a  = None\n        return a\n\n    def m5(x,y):\n        from sklearn.tree import DecisionTreeClassifier\n        a  = None\n        return a\n\n    def m6(x,y):\n        from sklearn.ensemble import RandomForestClassifier\n        a  = None\n        return a\n\n    def m7(x,y):\n        from sklearn.svm import SVC\n        a  = None\n        return a\n    \n    return l","metadata":{},"execution_count":null,"outputs":[]}]}