{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Objective\n### To predict whether a patient is at risk for a heart attack. This is a binary outcome.\n\nPositive (+) = 1, patient is at risk\nNegative (-) = 0, patient is not at risk","metadata":{}},{"cell_type":"markdown","source":"# Understanding the Dataset\n* age (#)\n* sex : 1 = Male, 0 = Female (Binary)\n* (cp) chest pain [type (4 values, Ordinal)]: 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\n* (trestbps) resting blood pressure (#)\n* (chol) serum cholestoral in mg/dl (#)\n* (fbs) fasting blood sugar > 120 mg/dl (Binary) [1 = true; 0 = false]\n* (restecg) resting electrocardiographic results [values 0,1,2]\n* (thalach) maximum heart rate achieved (#)\n* (exang) exercise induced angina (Binary) [1 = yes; 0 = no]\n* (oldpeak) = ST depression induced by exercise relative to rest (#)\n* (slope) of the peak exercise ST segment (Ordinal) [ 1: upsloping, 2: flat , 3: downsloping)\n* (ca) number of major vessels (0-3, Ordinal) colored by fluoroscopy\n* (thal) maximum heart rate achieved (Ordinal) [3 = normal; 6 = fixed defect; 7 = reversable defect]","metadata":{}},{"cell_type":"markdown","source":"# Exploring the Dataset ","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/heart-attack-prediction/data.csv')\ndata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## visualization of Correlation in Data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncorrmat = data.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True, annot=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**OldPeak**(ST depression induced by exercise relative to rest) and **CP** ( Chest Pain Type ) have the most correlation with **target** ( diagnosis of heart disease)","metadata":{}},{"cell_type":"code","source":"\nfor col in data.columns:\n    if 'num' in col:\n        continue\n    print(col, '\\n------------\\n') \n    print(\"Unknown % = {}\".format(len(data[data[col] == '?'])/ len(data)))\n    print(\"Median: {}\".format(data[data[col] != '?'][col].median()))\n    print(\"Mean: {}\".format(data[data[col] != '?'][col].mean()))\ntemp = data.drop(['ca', 'thal', 'slope'], axis=1)\ntemp.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in temp.columns:\n    print(col, '\\n----------------\\n',temp[temp[col] == '?'], '\\n-----------------------\\n')\n# print(temp[temp != '?'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing the Data","metadata":{}},{"cell_type":"code","source":"data.rename(columns={'num       ': 'target'}, inplace=True) \ndata.drop(['ca', 'thal', 'slope'], axis=1, inplace=True)\n#Deleting outliers for now\ndata.drop(index=[2, 31, 34, 44, 65, 72, 75, 86, 91, 97, 101, 102, 108, 124, 134, 154, 168, 182, 226, 239, 244, 275, 278, 27, 81, 107, 131, 144, 166, 197, 199, 260, 90] , inplace=True)\n\n# for col in data.columns:\n#     data.drop(index=data[data[col] == '?'], inplace=True)\n# data['chol']=data['chol'].replace('?', data[data['chol'] != '?']['chol'].median())\n# data=data.replace('?',None)\n# data=data.replace('?',0)\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting Pandas Dummies for ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n\n#data = pd.get_dummies(data, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope','thal','ca'])\ndata = pd.get_dummies(data, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang'])","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scaling the other attributes using normal scaler\n\nstandardScaler = StandardScaler()\ncolumns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n    \ndata[columns_to_scale] = standardScaler.fit_transform(data[columns_to_scale])\nscaling_values = {}\ncomputed_scaling_values = [standardScaler.mean_, np.sqrt(standardScaler.var_)]\nfor idx, col in enumerate(columns_to_scale):\n    scaling_values[col] = {'mean': computed_scaling_values[0][idx], 'std': computed_scaling_values[1][idx]}\nscaling_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Preprocessed Data","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting data as Train and Test","metadata":{}},{"cell_type":"code","source":"y = data['target']\nX = data.drop('target',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n\n#80% Train and 20% Test Data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the Target (Heart Disease)\nplt.figure(figsize=(6,4))\nsns.countplot(y)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analysing the shape of X_train and X_test Data\n\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # MODELS\n\n     1) SVM\n     2) Random Forest\n     3) Logistic Regression\n     4) Multi-layer Perceptron classifier \n     5) Extra Trees","metadata":{}},{"cell_type":"markdown","source":"# 1) Using SVM","metadata":{}},{"cell_type":"markdown","source":"## Running SVM model with Various Kernals","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n#Function for storing model scores using various kernals\nsvc_scores = []\nkernel_type = ['linear', 'poly', 'rbf', 'sigmoid']\nfor type in kernel_type:\n    svc_classifier = SVC(kernel = type)\n    svc_classifier.fit(X_train, y_train)\n    svc_scores.append(svc_classifier.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting the accuracy\n\nfor i in range(len(kernel_type)):\n    label = round(svc_scores[i], 5)\n    plt.text(i, svc_scores[i], label)\nplt.xlabel('Kernels')\nplt.ylabel('Scores')\nplt.title('Support Vector Classifier scores for different kernels')\nplt.bar(kernel_type, svc_scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the **rbf** kernel gives the maximum accuracy. Training the final model in rbf","metadata":{}},{"cell_type":"code","source":"#Training the model on 'rbf' Kernal\n\nsvc =  SVC(kernel='linear')\nsvc.fit(X_train, y_train)\nsvc_predicted = svc.predict(X_test)\nsvc_conf_matrix = confusion_matrix(y_test, svc_predicted)\nsvc_acc_score = accuracy_score(y_test, svc_predicted)\n\n#Printing the confussion matrix and accuracy scores\nprint(\"confussion matrix\")\nprint(svc_conf_matrix)\nprint(classification_report(y_test, svc_predicted))\nprint(\"\\n\")\nprint(\"Accuracy of Support Vector Classifier: {:.3f}\".format(svc_acc_score*100),'%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel=RandomForestClassifier(n_estimators=500)\nmodel.fit(X_train,y_train)\nrfpred=model.predict(X_test)\nRF_conf_matrix = confusion_matrix(y_test, rfpred)\nrf_acc_score = accuracy_score(y_test, rfpred)\n\n#Printing the confussion matrix and accuracy scores\nprint(\"confussion matrix\")\nprint(RF_conf_matrix)\nprint(classification_report(y_test, rfpred))\nprint(\"\\n\")\nprint(\"Accuracy of Random Forest Classifier: {:.3f}\".format(rf_acc_score*100),'%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nmodel = lr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\n\n#Printing the confussion matrix and accuracy scores\nprint(\"confussion matrix\")\nprint(lr_conf_matrix)\nprint(\"\\n\")\nprint(classification_report(y_test,lr_predict))\nprint(\"Accuracy of Logistic Regression: {:.3f}\".format(lr_acc_score*100),'%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) Multi-layer Perceptron classifier ","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nMLP = MLPClassifier(hidden_layer_sizes=(32), learning_rate_init=0.001, max_iter=1000)\nmodel = MLP.fit(X_train, y_train)\nMLP_predict = MLP.predict(X_test)\nMLP_conf_matrix = confusion_matrix(y_test, MLP_predict)\nMLP_acc_score = accuracy_score(y_test, MLP_predict)\n\n\n#Printing the confussion matrix and accuracy scoresprint(\"confussion matrix\")\nprint(MLP_conf_matrix)\nprint(\"\\n\")\nprint(classification_report(y_test,MLP_predict))\nprint(\"Accuracy of Multilayer Perceptron classifier: {:.3f}\".format(MLP_acc_score*100),'%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5) Extra Trees","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\n\nmodel=ExtraTreesClassifier(n_estimators=100,random_state=1)\nmodel.fit(X_train,y_train)\netpred=model.predict(X_test)\nET_conf_matrix = confusion_matrix(y_test, etpred)\net_acc_score = accuracy_score(y_test, etpred)\n\n#Printing the confussion matrix and accuracy scores\nprint(\"confussion matrix\")\nprint(ET_conf_matrix)\nprint(classification_report(y_test, etpred))\nprint(\"\\n\")\nprint(\"Accuracy of Extra Trees Classifier: {:.3f}\".format(et_acc_score*100),'%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top Scorers on non CV'ed \n\n    1) SVM - 86%\n    2) Logistic - 84.9%\n    3) RF - 81%","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cv_model(classifier, splits=10):\n    accuracy = []\n    skf = StratifiedKFold(n_splits=splits)\n    for train_idx, test_idx in skf.split(X, y):\n        X_train, X_test, y_train, y_test = X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n        classifier.fit(X_train, y_train)\n        model_prediction = classifier.predict(X_test)\n        conf_matrix = confusion_matrix(y_test, model_prediction)\n        acc_score = accuracy_score(y_test, model_prediction)\n        accuracy.append(acc_score)\n    print('Accuracy:\\n', accuracy)\n    print('Average Accuracy:', np.mean(accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_type = ['linear', 'poly', 'rbf', 'sigmoid']\nfor t in kernel_type:\n    print(\"Kernel: \", t)\n    cv_model(SVC(kernel=t), 10)\n    print('\\n------------------\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model(LogisticRegression(), 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model(RandomForestClassifier(n_estimators=800), 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model( MLPClassifier(hidden_layer_sizes=(32), learning_rate_init=0.001, max_iter=10000))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_model(ExtraTreesClassifier(n_estimators=500,random_state=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cv_model_get_best_fit(classifier, splits=10):\n    accuracy = []\n    batch = []\n    skf = StratifiedKFold(n_splits=splits)\n    for train_idx, test_idx in skf.split(X, y):\n        X_train, X_test, y_train, y_test = X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n        batch.append([X_train, X_test, y_train, y_test])\n        classifier.fit(X_train, y_train)\n        model_prediction = classifier.predict(X_test)\n        conf_matrix = confusion_matrix(y_test, model_prediction)\n        acc_score = accuracy_score(y_test, model_prediction)\n        accuracy.append(acc_score)\n    print('Accuracy:\\n', accuracy)\n    print('Average Accuracy:', np.mean(accuracy))\n    print('Max Accuracy:{} at {} '.format(np.max(accuracy), np.argmax(accuracy)))\n    return batch[np.argmax(accuracy)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = SVC(kernel='linear')\nX_train, X_test, y_train, y_test = cv_model_get_best_fit(final_model)\n\nfinal_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[X_test.iloc[20], '===================',y_test.iloc[20]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model.predict(X_test.iloc[19].values.reshape(1, 19))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\njoblib.dump(final_model, 'model.sav')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}