{"cells":[{"metadata":{"id":"Zc0oV8MrJHOy"},"cell_type":"markdown","source":"# Mall Customer Segmentation: <font color='blue'>K-Means Clustering</font> & <font color='red'>Hierarchical Clustering</font> \n* Importing the libraries\n* Importing the dataset\n* Dataset information (Pandas Profiling)\n* Elbow method to find the optimal number of clusters\n* Using the dendrogram to find the optimal number of clusters\n* Training the K-Means model on the dataset\n* Training the Hierarchical Clustering model on the dataset\n* Visualising the K-means clusters\n* Visualising the Hierarchical clusters\n* **Conclusion**"},{"metadata":{"id":"CIRYUN_tJHO1"},"cell_type":"markdown","source":"\n## Importing the libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"Qox5N0GsJHO2"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"id":"52ZELqxZJHO5"},"cell_type":"markdown","source":"\n## Importing the dataset"},{"metadata":{"trusted":true,"id":"ZZqx2rUsJHO6"},"cell_type":"code","source":"dataset = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\nX = dataset.iloc[:, [3, 4]].values","execution_count":null,"outputs":[]},{"metadata":{"id":"p4h9vCBgJHO9"},"cell_type":"markdown","source":"## Dataset information (Pandas Profiling) "},{"metadata":{"trusted":true,"id":"epBSRdmLJHO9"},"cell_type":"code","source":"import pandas_profiling as pp\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"CAp1k_SjJHPA"},"cell_type":"code","source":"pp.ProfileReport(dataset, title = 'Pandas Profiling report of \"dataset\"', html = {'style':{'full_width': True}})","execution_count":null,"outputs":[]},{"metadata":{"id":"2DKyTBUMJHPD"},"cell_type":"markdown","source":"## <font color='blue'>Elbow method to find the optimal number of clusters</font>"},{"metadata":{"trusted":true,"id":"I6cYLaalJHPE","outputId":"8553823c-03e2-4b36-d938-08a545ee323a"},"cell_type":"code","source":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss, c = 'blue')\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Izx49hQvJHPI"},"cell_type":"markdown","source":"## <font color='red'>Using the dendrogram to find the optimal number of clusters</font>"},{"metadata":{"trusted":true,"id":"YNW3ng6eJHPI","outputId":"d1a7810a-b11e-49fe-cda0-c41643bd6a51"},"cell_type":"code","source":"import scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"ilRz99Z7JHPM"},"cell_type":"markdown","source":"## <font color='blue'>Training the K-Means model on the dataset</font>"},{"metadata":{"trusted":true,"id":"LCKP4BrLJHPM"},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 42)\ny_kmeans = kmeans.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"rLCxTkO2JHPP"},"cell_type":"markdown","source":"## <font color='red'>Training the Hierarchical Clustering model on the dataset</font>"},{"metadata":{"trusted":true,"id":"9TXEAWUNJHPQ"},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"TbuYrtr0JHPS"},"cell_type":"markdown","source":"## <font color='blue'>Visualising the K-Means clusters</font>"},{"metadata":{"trusted":true,"id":"XR3jN0XWJHPS","outputId":"2f51eb41-acb6-43f8-801a-9e5301383429"},"cell_type":"code","source":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 50, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 50, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 50, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 50, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 50, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, marker = '+', c = 'black', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"FQ91PbS2JHPW"},"cell_type":"markdown","source":"## <font color='red'>Visualising the Hierarchical clusters</font>"},{"metadata":{"trusted":true,"id":"Kv7DEjWRJHPX","outputId":"1a114766-28cc-4b43-daed-418d8713dbe4"},"cell_type":"code","source":"plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 50, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 50, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 50, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 50, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 50, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, marker = '+', c = 'black', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"6ekoV2GKJHPa"},"cell_type":"markdown","source":"# <font color='green'>conclusion</font>\n* **For large number of data K-Means Clustering is always good.**\n* **Reason: It's easy to find the optimal no of clusters in K-Means because of elbow method. (we can't find the optimal no of clusters accuratley by using dendogram for large number of data. hence, for large number of data Hierarchical clustering is not possible)**\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}