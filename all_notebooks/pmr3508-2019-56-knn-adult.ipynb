{"cells":[{"metadata":{},"cell_type":"markdown","source":"                           Escola Politécnica da Universidade de São Paulo\n                                         Data: 13/09/2019\n#       PMR3508 - Aprendizado de Máquina e Reconhecimento de Padrões\n### Análise e aplicação do k-NN a base *adult*\n#### Autor: Lucas Nunes Sequeira"},{"metadata":{},"cell_type":"markdown","source":"# 1. Preparação dos dados (*Data Prep*)"},{"metadata":{},"cell_type":"markdown","source":"Nessa primeira etapa, começo importando algumas bibliotecas que usaremos ao longo do desenvolvimento do notebook. Além disso, faremos um tratamento nos **dados faltantes** com o uso da biblioteca *pandas*."},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Importação de bibliotecas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n%matplotlib inline\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Importação dos dados\n\nAgora, subo o arquivo *train_data.csv* através do *pandas* na forma de **DataFrame**, considerando também valores <font color='red'>*?*</font> como <font color='red'>*Nan*</font>."},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/adult-pmr3508\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/adult-pmr3508/train_data.csv\", na_values = '?')\ndf_train.set_index('Id',inplace=True)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Forma do DataFrame:', df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Identificando os **dados faltantes** (*missing data*)\n\nNessa etapa dessa seção, identifico os **dados faltantes** utilizando algumas ferramentas do *pandas*. Para em seguida analisar o tipo, se é aleatório ou não por exemplo."},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = ((df_train.isnull().sum()/df_train.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar que os **dados faltantes** concentram-se em 3 colunas: '*occupation*', '*workclass*' e '*native.country*'. Observo as distribuições das colunas, para analisarmos melhor:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('occupation:\\n')\nprint(df_train['occupation'].describe())\n\nprint('\\n\\nworkclass:\\n')\nprint(df_train['workclass'].describe())\n\nprint('\\n\\nnative.country:\\n')\nprint(df_train['native.country'].describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para os três casos, devido a alta frequência da moda, utilizarei a moda como valor imputado."},{"metadata":{"trusted":true},"cell_type":"code","source":"value = df_train['workclass'].describe().top\ndf_train['workclass'] = df_train['workclass'].fillna(value)\n\nvalue = df_train['native.country'].describe().top\ndf_train['native.country'] = df_train['native.country'].fillna(value)\n\nvalue = df_train['occupation'].describe().top\ndf_train['occupation'] = df_train['occupation'].fillna(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_train.isnull().sum().sort_values(ascending = False)\npercent = ((df_train.isnull().sum()/df_train.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, agora nosso banco de dados para o treino está limpo e pronto para ser analisado."},{"metadata":{},"cell_type":"markdown","source":"# 2. Análise exploratória dos dados\n\nNessa etapa, utilizarei as bibliotecas: *matplotlib*, *pandas* e *seaborn* como ferramentas para analisarmos e visualizarmos os dados, e assim tirar algumas conclusões sobre os mesmos."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\nsns.set()\nsns.pairplot(df_train, vars = cols, hue = 'income')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Descrição dos dados\n\nObservaremos com o uso da função *.describe()* e *.hist()* do *pandas* para clarear nossas primeiras inferências."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De cara observamos que as colunas *capital.gain* e *capital.loss* possuem grupos bem definidos e distantes, para isso, veremos seu histograma:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\ndf_train['capital.gain'].hist(color = 'coral')\nplt.xlabel('capital gain')\nplt.ylabel('quantity')\nplt.title('Capital gain histogram')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\ndf_train['capital.loss'].hist(color = 'coral')\nplt.xlabel('capital loss')\nplt.ylabel('quantity')\nplt.title('Capital loss histogram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logo vemos que há uma concentração quase absoluta para valores pequenos, enquanto há poucos, bastante altos. Agora para termos uma noção da curva de idades do banco de dados, avalio com *.hist()*"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\ndf_train['age'].hist(color = 'coral')\nplt.xlabel('age')\nplt.ylabel('quantity')\nplt.title('Age histogram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Além disso, podemos também avaliar com a função *.distplot()* do *seaborn* para compararmos com uma **curva de distribuição**."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.set()\nplt.figure(figsize=(13,7))\nsns.distplot(df_train['age'], color = 'darkorchid', bins = 70)\nplt.ylabel('quantity')\nplt.title('Distribution of age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que há uma grande quantidade de jovens (20 a 40 anos) nessa população."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\ndf_train['hours.per.week'].hist(color = 'coral')\nplt.xlabel('hours per week')\nplt.ylabel('quantity')\nplt.title('Hours per week histogram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concluímos também que em maioria (e em média) os indivídos desse banco de dados trabalham 40 horas por semana (8 horas por dia e finais de semana livre) o que é saudável. No entanto, há uma parcela significativa que excede esse número, analiso a seguir."},{"metadata":{"trusted":true},"cell_type":"code","source":"super_work = df_train[df_train['hours.per.week'] > 40]\nplt.figure(figsize=(13, 7))\nsuper_work['hours.per.week'].hist(color = 'coral', bins = 5)\nplt.xlabel('hours per week')\nplt.ylabel('quantity')\nplt.title('Hours per week histogram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E esses '*super trabalhadores*' que trabalham acima de 40 horas por semana constituem um grupo que cai exponencialmente com as horas de trabalho, no entanto, vemos por exemplo que em média eles trabalham:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = super_work['hours.per.week'].describe()['mean']\nprint('{0} horas por semana ({1} horas por dia com finais de semana livre). O que é algo que já começa a ser bastante desgastante para o trabalhador.'.format(int(mean), int(mean/5)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Comparação dos dados\n\nNessa subseção faremos uma análise comparativa entre os dados dos indivídos do banco de dados. Utilizaremos histogramas, gráficos de pizza e boxplots.\n\nPrimeiro, crio uma função de comparação para histogramas."},{"metadata":{"trusted":true},"cell_type":"code","source":"def compare_histogram(df, obj_var, test_var, obj_labels = None, alpha = 0.7):\n    \n    if obj_labels is None:\n        obj_labels = df[obj_var].unique()\n    \n    #obj_var = 'income'\n    #obj_labels = ['>50K', '<=50K']\n    #test_var = 'age' (for example)\n    \n    temp = []\n    n_labels = len(obj_labels)\n    for i in range(n_labels):\n        temp.append(df[df[obj_var] == obj_labels[i]])\n        temp[i] = np.array(temp[i][test_var]).reshape(-1,1)\n\n    fig = plt.figure(figsize= (13,7))\n    \n    for i in range(n_labels):\n        plt.hist(temp[i], alpha = alpha)\n    plt.xlabel(test_var)\n    plt.ylabel('quantity')\n    plt.title('Histogram over \\'' + test_var + '\\' filtered by \\'' + obj_var + '\\'')\n    plt.legend(obj_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_histogram(df_train, 'income', 'age')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sobre o histograma acima (*age* e *income*) vemos que há uma distribuição relativamente normal sobre as pessoas que recebem *>50K* com o termo médio próximo de 45 anos; já para pessoas *<=50K* , observa-se que com o aumento da idade, há uma redução na quantidade de pessoas que recebem o valor.\n\nAgora, farei uma análise sobre a distribuição de sexo."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\ndf_train['sex'].value_counts().plot(kind = 'pie')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que há nos dados, mais homens que mulheres, com relação à esses valores, temos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# male = qtd sex == Male\nmale = df_train[df_train['sex'] == 'Male'].count()[0]\n\n# female = qtd sex == Female\nfemale = df_train.shape[0] - male","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Temos {0} homens e {1} mulheres, ou seja, apenas {2:3.2f}% são mulheres.\".format(male, female, female*100/(female+male)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_histogram(df_train, 'income', 'sex')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sobre o histograma acima, nota-se que há uma grande discrepância percentual (veja os valores abaixo) entre mulheres que recebem *>50K* e homens que recebem o mesmo valor, vemos que há muito mais homens que recebem *>50K*. Esses resultados sugerem que há **desigualdade de gênero** tratando-se do salário."},{"metadata":{"trusted":true},"cell_type":"code","source":"# male_income = [qtd > 50K, qtd <= 50K]\nmale_income = []\ntemp = df_train[df_train['sex'] == 'Male']\nmale_income.append(temp[temp['income'] == '>50K'].count()[0])\nmale_income.append(male-male_income[0])\n\n# female_income = [qtd > 50K, qtd <= 50K]\nfemale_income = []\ntemp = df_train[df_train['sex'] == 'Female']\nfemale_income.append(temp[temp['income'] == '>50K'].count()[0])\nfemale_income.append(female-female_income[0])\n\n# % of male that has >50K income:\nmale_over = male_income[0]/male\n\n# % of female that has >50K income:\nfemale_over = female_income[0]/female","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Temos que dentre os homens, {0:1.2f}% possuem renda anual superior a 50.000, já dentre as mulheres, temos {1:2.2f}% apenas que possuem renda anual superior a 50.000.'.format(male_over*100, female_over*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ainda sobre a questão de gênero, temos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_histogram(df_train, 'sex', 'hours.per.week')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O que vemos é que existem muito mais homens (inclusive percentualmente) que trabalham mais de 40 horas por semana, e percentualmente vemos mais mulheres trabalhando menos de 30 horas semanais. Agora analisarei as ocupações."},{"metadata":{"trusted":true},"cell_type":"code","source":"female = df_train[df_train['sex'] == 'Female']\nmale = df_train[df_train['sex'] == 'Male']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\nmale['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\nplt.ylabel('quantity')\nplt.title('Histogram of male over occupations')\n\nplt.figure(figsize=(13, 7))\nfemale['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\nplt.ylabel('quantity')\nplt.title('Histogram of female over occupations')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que há uma nítida diferença entre a empregabilidade dos homens e das mulheres. Além disso observamos também que não há mulheres que trabalham nas *Armed-Forces*, será uma política exclusiva?"},{"metadata":{},"cell_type":"markdown","source":"Agora, faremos algumas análises étnicas."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\ndf_train['race'].value_counts().plot(kind = 'pie')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O que vemos é uma concentração bastante elevada da quantidade de pessoas brancas nessa população pesquisada."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"compare_histogram(df_train, 'income', 'race')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observando o histograma acima, podemos de cara visualizar que provavelmente há um percentual maior de pessoas brancas que recebem mais do 50.000 sobre as pessoas negras, amer-indian-eskimo e outros. Os valores seguem abaixo."},{"metadata":{"trusted":true},"cell_type":"code","source":"# kind = qtd race == 'unique'\nwhite = df_train[df_train['race'] == 'White'].count()[0]\nblack = df_train[df_train['race'] == 'Black'].count()[0]\namer = df_train[df_train['race'] == 'Amer-Indian-Eskimo'].count()[0]\nother = df_train[df_train['race'] == 'Other'].count()[0]\nasian = df_train[df_train['race'] == 'Asian-Pac-Islander'].count()[0]\n\n# kind_income = [qtd > 50K, qtd <= 50K]\nwhite_income = []\ntemp = df_train[df_train['race'] == 'White']\nwhite_income.append(temp[temp['income'] == '>50K'].count()[0])\nwhite_income.append(white-white_income[0])\n\nblack_income = []\ntemp = df_train[df_train['race'] == 'Black']\nblack_income.append(temp[temp['income'] == '>50K'].count()[0])\nblack_income.append(black-black_income[0])\n\namer_income = []\ntemp = df_train[df_train['race'] == 'Amer-Indian-Eskimo']\namer_income.append(temp[temp['income'] == '>50K'].count()[0])\namer_income.append(amer-amer_income[0])\n\nasian_income = []\ntemp = df_train[df_train['race'] == 'Asian-Pac-Islander']\nasian_income.append(temp[temp['income'] == '>50K'].count()[0])\nasian_income.append(asian-asian_income[0])\n\nother_income = []\ntemp = df_train[df_train['race'] == 'Other']\nother_income.append(temp[temp['income'] == '>50K'].count()[0])\nother_income.append(other-other_income[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Brancos:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(white_income[0]*100/white))\nprint('Negros:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(black_income[0]*100/black))\nprint('Amer-Indian-Eskimo:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(amer_income[0]*100/amer))\nprint('Asian-Pac-Islander:\\n   {0:1.2f}% recebem mais de 50.000\\n'.format(asian_income[0]*100/asian))\nprint('Outros:\\n   {0:1.2f}% recebem mais de 50.000'.format(other_income[0]*100/other))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Disso podemos concluir, que há também uma certa **desigualdade racial**, em que etinias não descrita em *Others*, e as etnias *Black* e *Amer-Indian-Eskimo* recebem proporcionalmente menos que as demais. Em seguida, comparemos as duas etinias em maior quantidade (brancos e negros), com relação às ocupações."},{"metadata":{"trusted":true},"cell_type":"code","source":"white = df_train[df_train['race'] == 'White']\nblack = df_train[df_train['race'] == 'Black']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\nwhite['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\nplt.ylabel('quantity')\nplt.title('Histogram of white people over occupations')\n\nplt.figure(figsize=(13, 7))\nblack['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\nplt.ylabel('quantity')\nplt.title('Histogram of black people over occupations')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Novamente vemos que há uma grande diferença entre as ocupações para cada etnia. Além disso podemos fazer uma comparação sobre a educação."},{"metadata":{"trusted":true},"cell_type":"code","source":"var1 = 'race'\nvar2 = 'education.num'\n\ndata = pd.concat([df_train[var2], df_train[var1]], axis=1)\n\nf, ax = plt.subplots(figsize=(15, 7))\n\nsns.boxplot(x=var1, y=var2, data=data, notch = True)\nplt.title('Boxplot of education num over race')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos novamente, brancos e Asian-Pac-Islander, com uma educação em média superior às demais etnias."},{"metadata":{},"cell_type":"markdown","source":"Agora, analisaremos os salários das ocupações, para tirarmos mais conclusões."},{"metadata":{"trusted":true},"cell_type":"code","source":"over_50k = df_train[df_train['income'] == '>50K']\nunder_50k = df_train[df_train['income'] == '<=50K']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13, 7))\nover_50k['occupation'].value_counts().plot(kind = 'bar', color = 'purple')\nplt.ylabel('quantity')\nplt.title('Histogram of income over 50K over occupations')\n\nplt.figure(figsize=(13, 7))\nunder_50k['occupation'].value_counts().plot(kind = 'bar', color = 'coral')\nplt.ylabel('quantity')\nplt.title('Histogram of income under 50K over occupations')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que aqueles que recebem acima de 50.000 em maioria são *Exec-managerial*, seguido por *Prof-specialty*, que são ocupações ocupadas em maioria por homens brancos. Já aqueles que recebem menos de 50.000 ocupam em maioria *Adm-clerical*, *Craft-repair*, *Other-service* e *Sales*, que são áreas que empregam maioria mulheres e negros."},{"metadata":{},"cell_type":"markdown","source":"Uma análise também interessante é sobre as idades."},{"metadata":{"trusted":true},"cell_type":"code","source":"var2 = 'age'\nvar1 = 'hours.per.week'\n\ndata = pd.concat([df_train[var2], df_train[var1]], axis=1)\n\nf, ax = plt.subplots(figsize=(14, 15))\n\nsns.boxplot(x=var1, y=var2, data=data, orient = 'h')\nplt.title('Boxplot of age over hours per week')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui vemos que pessoas muito jovens trabalham em média menos de 40 horas por semana, provavelmente pois devem trabalhar meio período. Assim como pessoas mais idosas, em média trabalham também menos de 40 horas por dia.\n\nUma outra avaliação é sobre a quantidade de tempo de trabalho por semana com relação ao nível de educação das pessoas."},{"metadata":{"trusted":true},"cell_type":"code","source":"var2 = 'education'\nvar1 = 'hours.per.week'\n\ndata = pd.concat([df_train[var2], df_train[var1]], axis=1)\n\nf, ax = plt.subplots(figsize=(13, 7))\n#ax.set_ylim(0,10000)\n\norder = ['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th',\n         '11th', '12th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc',\n         'Some-college', 'Bachelors', 'Masters', 'Doctorate']\nsns.boxplot(x=var1, y=var2, data=data, order = order)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que as pessoas com os maiores níveis de educação, normalmente trabalham mais de 40 horas por dia, como aqueles que possuem título de doutorado, mestrado e bacharel; como também os que concluiram uma escola profissionalizante."},{"metadata":{},"cell_type":"markdown","source":"# 3. Análise e preprocessamento dos atributos\n\nNessa seção usaremos bibliotecas como *skitlearn* para fazermos alguns preprocessamento dos dados, como também algumas análises de correlação entre os atributos para otimizarmos nosso aprendizado de máquina no futuro. "},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Tratamento dos atributos\n\nAgora, farei um tratamento sobre alguns dos atributos qualitativos e quantitativos de forma a numerar aqueles ordenáveis por exemplo."},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.1 Alguns tratamentos de dados\n\nreferência: https://www.rdocumentation.org/packages/arules/versions/1.6-3/topics/Adult\n\n*education*\n\n- qualitativo ordenado\n    - Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate\n    \n*workclass*\n\n- booleano\n    - isPrivate\n    \n*age*\n *   \n- quantitativo ordenado\n     - Young (0-25) < Middle-aged (26-45) < Senior (46-65) < Old (66+)\n     \n*hours.per.week*\n\n- quantitativo ordenado\n    - Part-time (0-25) < Full-time (25-40) < Over-time (40-60) < Too-much (60+).\n\n*capital.gain* e *capital.loss*\n\n- quantitativo ordenado\n    - None (0) < Low (0 - mediana dos valores maiores que zero) and High (> mediana dos valores maiores que zero)."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['income'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora vou dividir os atributos quantitativos e qualitativos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"base.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quantitative_columns = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\nqualitative_columns = ['education', 'marital.status', 'occupation', 'relationship', 'race',\n                       'sex', 'native.country', 'income']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.2 Funções\n\nAlgumas declarações de funções para o tratamento dos dados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def isprivate(value):\n    if value == 'Private':\n        return 1\n    return 0\n\ndef catg(value, categories, ordenation = None):\n    if ordenation is not None:\n        ordenation = np.arange(0, len(categories))\n    for pos in ordenation:\n        if value == categories[pos]:\n            return pos\n    return -1\n\ndef equals(value, x):\n    for v in x:\n        if v == value:\n            return 1\n    return 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.3 *workclass*"},{"metadata":{"trusted":true},"cell_type":"code","source":"base['workclass'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# privado: 1 se trabalha para o privado, 0 caso contrario\nprivate = pd.DataFrame({'private': base['workclass'].apply(isprivate)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.4 *native.country*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['native.country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# usa: 1 se é sul_global, 0 caso contrário\ncountries = ['Mexico', 'Philippines', 'Puerto-Rico', 'El-Salvador', 'India', 'Cuba', 'Jamaica',\n             'South', 'China', 'Dominican-Republic', 'Vietnam', 'Guatemala', 'Columbia', 'Taiwan',\n             'Haiti', 'Iran', 'Nicaragua', 'Peru', 'Ecuador', 'Trinadad&Tobago', 'Cambodia',\n             'Laos', 'Thailand', 'Yugoslavia', 'Outlying-US(Guam-USVI-etc)', 'Honduras']\nsul_global = pd.DataFrame({'sul.global': base['native.country'].apply(equals, args = [countries])})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.5 *education*"},{"metadata":{},"cell_type":"markdown","source":"Preschool < 1st-4th < 5th-6th < 7th-8th < 9th < 10th < 11th < 12th < HS-grad < Prof-school < Assoc-acdm < Assoc-voc < Some-college < Bachelors < Masters < Doctorate"},{"metadata":{"trusted":true},"cell_type":"code","source":"base['education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"edu_order = [15, 11, 5, 12, 10, 1, 14, 7, 2, 8, 4, 13, 0, 3, 6, 9]\nargs = [base['education'].unique(), edu_order]\neducation_classes = pd.DataFrame({'education.classes': base['education'].apply(catg, args = args)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.6 *hours.per.week*"},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = pd.cut(base['hours.per.week'], bins = [-1, 25, 40, 60, 200], labels = [0, 1, 2, 3])\nhours_per_week_clusters = pd.DataFrame({'hours.per.week.clusters': aux})\nhours_per_week_clusters = hours_per_week_clusters.astype(np.int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1.7 *capital.gain* e *capital.loss*"},{"metadata":{"trusted":true},"cell_type":"code","source":"median = np.median(base[base['capital.gain'] > 0]['capital.gain'])\naux = pd.cut(base['capital.gain'],\n             bins = [-1, 0, median, base['capital.gain'].max()+1],\n             labels = [0, 1, 2])\ncapital_gain_clusters = pd.DataFrame({'capital.gain.clusters': aux})\ncapital_gain_clusters = capital_gain_clusters.astype(np.int)\n\nmedian = np.median(base[base['capital.loss'] > 0]['capital.loss'])\naux = pd.cut(base['capital.loss'],\n             bins = [-1, 0, median, base['capital.loss'].max()+1],\n             labels = [0, 1, 2])\ncapital_loss_clusters = pd.DataFrame({'capital.loss.clusters': aux})\ncapital_loss_clusters = capital_loss_clusters.astype(np.int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = pd.concat([sul_global, private, education_classes, \n                      hours_per_week_clusters, capital_gain_clusters, \n                      capital_loss_clusters], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por fim, construimos essa pequena tabela de dados que podem vir a ser uteis."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"aux = base['income'].apply(equals, args = [['>50K']])\n\naux = pd.concat([new_data, pd.DataFrame({'income': aux})], axis = 1)\n\nnew = aux.astype(np.int)\naux.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A seguir, uma simples visualização com uma matriz de correlação para termos uma ideia das contribuições sobre *income*."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat = aux.corr()\ncorr_mat\nsns.set()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr_mat, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Junção da base com os valores construídos e seleção de alguns atributos por intuição"},{"metadata":{"trusted":true},"cell_type":"code","source":"base = base.drop(['fnlwgt', 'education', 'sex', 'native.country', 'workclass', 'marital.status'], axis = 1)\nbase.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = pd.concat([new_data, base], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Encoding dos dados classicatórios\n\nUtilizo o LabelEncoder() para fazer o tratamento dos dados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing as prep\n\nnames = ['occupation', 'relationship', 'race']\nenc_x = []\nfor i in range(len(names)):\n    enc_x.append(prep.LabelEncoder())\nenc_y = prep.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor name in names:\n    base[name] = enc_x[i].fit_transform(base[name])\n    i += 1\n\nbase['income'] = enc_y.fit_transform(base['income'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 Matriz de correlação\n\nAgora, farei uma análise sobre a correlação entre os atributos, para isso utilizarei da matriz de correlação do próprio **DataFrame** associado ao *seaborn*."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"aux = base.astype(np.int)\n\ncorr_mat = aux.corr()\nf, ax = plt.subplots(figsize=(20, 13))\nsns.heatmap(corr_mat, vmax=.7, square=True, cmap=\"coolwarm\", annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Remoção de atributos pouco relevantes\n\nUtilizo a matriz de correlação acima, para visualisar e reduzir a dimenção do problema excluindo atributos pouco relevantes."},{"metadata":{"trusted":true},"cell_type":"code","source":"unselected_columns = []\nunselected_columns.append('capital.loss')\nunselected_columns.append('capital.gain')\nunselected_columns.append('sul.global')\nunselected_columns.append('private')\nunselected_columns.append('education.classes')\nunselected_columns.append('hours.per.week.clusters')\n\nbase = base.drop(unselected_columns, axis = 1)\nbase.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aux = base.astype(np.int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat = aux.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr_mat, vmax=.7, square=True, cmap=\"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Agrupamento por K-NN\n\nNessa última etapa, utilizarei a biblioteca *sklearn* para utilização do método de aprendizado **k-NN**. Nesse processo, farei o uso da **validação cruzada** para avaliar o desempenho do modelo."},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Escalonamento dos dados\n\nPrimeiro farei um tratamento sobre os dados, de forma a escaloná-los utilizando *StandardScaler*."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = base.drop(['income'], axis = 1)\ny = base['income']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_x = StandardScaler()\n\nX = scaler_x.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Definição do hiperparâmetro k do k-NN\n\nPrimeiro, avaliaremos o comportamento do aprenzidado para k = 1, ..., 29 para que possamos identificar o melhor valor de k para utilizarmos para prever os valores da base de teste a ser importada. Essa avaliação, será feita com a utilização da validação cruzada com 5 *folds*, e assim será possível determinar o melhor hiperparâmetro k que se aplicará ao nosso problema."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_mean = []\nscores_std = []\n\nk_lim_inf = 1\nk_lim_sup = 30\n\nfolds = 5\n\nk_max = None\nmax_std = 0\nmax_acc = 0\n\ni = 0\nprint('Finding best k...')\nfor k in range(k_lim_inf, k_lim_sup):\n    \n    KNNclf = KNeighborsClassifier(n_neighbors=k, p = 1)\n    \n    score = cross_val_score(KNNclf, X, y, cv = folds)\n    \n    scores_mean.append(score.mean())\n    scores_std.append(score.std())\n    \n    if scores_mean[i] > max_acc:\n        k_max = k\n        max_acc = scores_mean[i]\n        max_std = scores_std[i]\n    i += 1\n    if not (k%3):\n        print('   K = {0} | Best CV acc = {1:2.2f}% +/-{3:4.2f}% (best k = {2})'.format(k, max_acc*100, k_max, max_std*100))\nprint('\\nBest k: {}'.format(k_max))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nplt.errorbar(np.arange(k_lim_inf, k_lim_sup), scores_mean, scores_std,\n             marker = 'o', markerfacecolor = 'purple' , linewidth = 3,\n             markersize = 10, color = 'coral', ecolor = 'purple', elinewidth = 1.5)\n\n\nyg = []\nx = np.arange(0, k_lim_sup+1)\nfor i in range(len(x)):\n    yg.append(max_acc)\nplt.plot(x, yg, '--', color = 'purple', linewidth = 1)\nplt.xlabel('k')\nplt.ylabel('accuracy')\nplt.title('KNN performed on several values of k')\nplt.axis([0, k_lim_sup, min(scores_mean) - max(scores_std), max(scores_mean) + 1.5*max(scores_std)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Acima vemos o gráfico dos erros médios sobre a validação cruzada para diferentes valores de k, em que foi possível determinar o melhor k que satisfaz nosso problema."},{"metadata":{},"cell_type":"markdown","source":"### 4.4 Treinamento do k-NN\n\nAgora, faremos o treinamento do k-NN utilizando nossa base de treino, em seguida inferimos sobre nossa acurácia da base de testes."},{"metadata":{"trusted":true},"cell_type":"code","source":"k = k_max\n\nKNNclf = KNeighborsClassifier(n_neighbors=k, p = 1)\nKNNclf.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Predição dos valores sem classe\n\nNessa última etapa, utilizaremos o nosso classificador treinado para predizer sobre as classes do banco de dados teste que não possui valor de classe atribuído aos indivíduos."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/adult-pmr3508/test_data.csv\", na_values='?')\ndf_test.set_index('Id', inplace = True)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Adição das colunas extra"},{"metadata":{"trusted":true},"cell_type":"code","source":"# capital.gain.cluster\nmedian = np.median(df_test[df_test['capital.gain'] > 0]['capital.gain'])\naux = pd.cut(df_test['capital.gain'],\n             bins = [-1, 0, median, df_test['capital.gain'].max()+1],\n             labels = [0, 1, 2])\ncapital_gain_clusters = pd.DataFrame({'capital.gain.clusters': aux})\ncapital_gain_clusters = capital_gain_clusters.astype(np.int)\n\n# capital.loss.cluster\nmedian = np.median(df_test[df_test['capital.loss'] > 0]['capital.loss'])\naux = pd.cut(df_test['capital.loss'],\n             bins = [-1, 0, median, df_test['capital.loss'].max()+1],\n             labels = [0, 1, 2])\ncapital_loss_clusters = pd.DataFrame({'capital.loss.clusters': aux})\ncapital_loss_clusters = capital_loss_clusters.astype(np.int)\n\nnew_data = pd.concat([capital_gain_clusters, capital_loss_clusters], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['age', 'education.num', 'occupation', 'relationship', 'race', 'hours.per.week']\n\nbase_test = pd.concat([new_data, df_test[features]], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.2 Verificando dados faltantes"},{"metadata":{"trusted":true},"cell_type":"code","source":"total = base_test.isnull().sum().sort_values(ascending = False)\npercent = ((base_test.isnull().sum()/base_test.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value = base_test['occupation'].describe().top\nbase_test['occupation'] = base_test['occupation'].fillna(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = base_test.isnull().sum().sort_values(ascending = False)\npercent = ((base_test.isnull().sum()/base_test.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3 Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"names = ['occupation', 'relationship', 'race']\n\ni = 0\nfor name in names:\n    base_test[name] = enc_x[i].transform(base_test[name])\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.4 Predição da base teste"},{"metadata":{},"cell_type":"markdown","source":"Enfim, predizemos as classes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_prev = scaler_x.transform(base_test.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = KNNclf.predict(X_prev)\n\ntemp = enc_y.inverse_transform(temp)\ntemp = {'Income': temp}\npredictions = pd.DataFrame(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.5 Submissão do resultado\n\nPor fim, escrevo os resultados em **submission.csv**"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.to_csv(\"submission.csv\", index = True, index_label = 'Id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exercício Extra - Costa Rican Household Poverty Levels\n\n# 6. Dados\n\n### 6.1 Importando bibliotecas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.2 Importando dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/rs-costa-rican-household-poverty-level-prediction/train.csv')\ndf_train.set_index('ID_num', inplace = True)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.3 Seleção de dados por intuição"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['idhogar', 'parentesco1', 'escolari', 'SQBmeaned', 'hogar_nin', 'hogar_total', 'area1',\n            'lugar1', 'cielorazo', 'pisonotiene', 'v14a', 'abastaguano', 'v2a1',\n            'hacdor', 'meaneduc', 'SQBovercrowding', 'abastaguadentro',\n            'tipovivi1', 'Target']\nbase = df_train[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.4 Filtragem por parentesco e idhogar"},{"metadata":{"trusted":true},"cell_type":"code","source":"base = base[base['parentesco1'] == 1]\nbase.shape\n\nbase = base.drop(['idhogar', 'parentesco1'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = base.astype(np.float)\nprint('shape:', base.shape)\nbase.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = base.corr()\nsns.set()\nplt.figure(figsize=(13,9))\nsns.heatmap(corrmat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Limpeza dos dados\n\n### 7.1 Determinando dados faltantes"},{"metadata":{"trusted":true},"cell_type":"code","source":"total = base.isnull().sum().sort_values(ascending = False)\npercent = ((base.isnull().sum()/base.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.2 Fazendo alterações sobre a base"},{"metadata":{"trusted":true},"cell_type":"code","source":"base = base.drop(['v2a1'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.2.1 *SQBmeaned*"},{"metadata":{"trusted":true},"cell_type":"code","source":"base['SQBmeaned'].plot(kind = 'box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = 'SQBmeaned'\nbase[col] = base[col].fillna(base[col].describe().mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7.2.1 *meaneduc*"},{"metadata":{"trusted":true},"cell_type":"code","source":"base['meaneduc'].plot(kind = 'box')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = 'meaneduc'\nbase[col] = base[col].fillna(base[col].describe().mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = base.isnull().sum().sort_values(ascending = False)\npercent = ((base.isnull().sum()/base.isnull().count())*100).sort_values(ascending = False)\nmissing_data = pd.concat([total, percent], axis = 1, keys = ['Total', '%'])\nmissing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Visualização dos dados\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def labels(x):\n    if x == 1.0:\n        return 'extreme poverty'\n    if x == 2.0:\n        return 'moderate poverty'\n    if x == 3.0:\n        return 'vulnerable households'\n    return 'non vulnerable households'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base['Target'] = base['Target'].apply(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.1 Pairplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['escolari', 'SQBmeaned', 'area1', 'lugar1', 'hogar_nin', 'hogar_total', 'SQBovercrowding']\n\nsns.set()\nsns.pairplot(base, hue = 'Target', vars = cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.2 Boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"var2 = 'escolari'\nvar1 = 'Target'\n\nf, ax = plt.subplots(figsize=(14, 8))\n\nsns.boxplot(x=var1, y=var2, data=base, order = ['extreme poverty', 'moderate poverty', 'vulnerable households', 'non vulnerable households'])\nplt.title('Boxplot of escolari over Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Maior a escolaridade, maior o nível social (em média)"},{"metadata":{"trusted":true},"cell_type":"code","source":"var2 = 'hogar_nin'\nvar1 = 'Target'\n\nf, ax = plt.subplots(figsize=(14, 8))\n\nsns.boxplot(x=var1, y=var2, data=base, order = ['extreme poverty', 'moderate poverty', 'vulnerable households', 'non vulnerable households'])\nplt.title('Boxplot of hogar_nin over Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nivel socioeconômico descresce com aumento de crianças"},{"metadata":{"trusted":true},"cell_type":"code","source":"var2 = 'SQBmeaned'\nvar1 = 'Target'\n\nf, ax = plt.subplots(figsize=(14, 8))\n\nsns.boxplot(x=var1, y=var2, data=base, order = ['extreme poverty', 'moderate poverty', 'vulnerable households', 'non vulnerable households'])\nplt.title('Boxplot of escolari over Target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Com aumento do nível socio-econômico, temos também o aumento médio do tamanho das habitações"},{"metadata":{},"cell_type":"markdown","source":"### 8.3 Histogramas"},{"metadata":{"trusted":true},"cell_type":"code","source":"base.hist(column='cielorazo', by ='Target', figsize=(10,10), color = 'coral')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentual de casas com teto aumenta com o nível socio-econômico"},{"metadata":{"trusted":true},"cell_type":"code","source":"base.hist(column='pisonotiene', by ='Target', figsize=(10,10), color = 'coral')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aparentemente o percentual de casas sem chão decresce com aumento do nível socio-econômico, mas são poucos casos."},{"metadata":{"trusted":true},"cell_type":"code","source":"base.hist(column='v14a', by ='Target', figsize=(10,10), color = 'coral')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O percentual de casas sem banheiro parece aumentar também com o aumento do nível socioeconômico, mas são poucos exemplos."},{"metadata":{},"cell_type":"markdown","source":"# 9. Imputar dados"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"~~~\ntarget = base['Target']\naux1 = pd.DataFrame({'Target | %': target.value_counts(normalize=True)})\naux1\n~~~"},{"metadata":{},"cell_type":"markdown","source":"**Vemos nesse caso que a distribuição dos dados desfavorece a presença de *extreme poverty*"},{"metadata":{},"cell_type":"markdown","source":"### 9.1 Atributo: *pisonotiene*"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"~~~\nsem_chao = base[base['pisonotiene'] == 1.0]\nsem_chao.shape\n~~~"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"~~~\nbatch = 32\nn_batchs = int(500/batch)\nbase_aux = sem_chao.sample(batch)\nfor i in range(n_batchs):\n    base_aux = pd.concat([base_aux, sem_chao.sample(batch)], axis = 0)\n~~~"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"~~~\nbase = pd.concat([base, base_aux], axis = 0)\n~~~"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"~~~\nbase.hist(column='pisonotiene', by ='Target', figsize=(10,10), color = 'coral')\n~~~"},{"metadata":{},"cell_type":"markdown","source":"# 10. Seleção e escalonamento dos dados"},{"metadata":{},"cell_type":"markdown","source":"### 10.1 Seleção dos melhores atributos"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = base.corr()\nsns.set()\nplt.figure(figsize=(13,10))\nsns.heatmap(corrmat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = base.drop(['cielorazo', 'v14a', 'abastaguano', 'tipovivi1', 'hacdor'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 10.2 Escalonamento dos dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = base.drop('Target', axis = 1)\ny = base['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_x = StandardScaler()\n\nX = scaler_x.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Classificador k-NN"},{"metadata":{},"cell_type":"markdown","source":"### 11.1 Seleção dos hiperparâmetros por CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_mean = []\nscores_std = []\n\nk_lim_inf = 1\nk_lim_sup = 36\n\nfolds = 5\n\nk_max = None\nmax_acc = 0\n\ni = 0\nprint('Finding best k...')\nfor k in range(k_lim_inf, k_lim_sup):\n    \n    KNNclf = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='manhattan', p=2)\n    \n    score = cross_val_score(KNNclf, X, y, cv = folds)\n    \n    scores_mean.append(score.mean())\n    scores_std.append(score.std())\n    \n    if scores_mean[i] > max_acc:\n        k_max = k\n        max_acc = scores_mean[i]\n    i += 1\n    if not (k%3):\n        print('   K = {0} | Best CV acc = {1:2.2f}% (best k = {2})'.format(k, max_acc*100, k_max))\nprint('\\nBest k: {}'.format(k_max))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nplt.errorbar(np.arange(k_lim_inf, k_lim_sup), scores_mean, scores_std,\n             marker = 'o', markerfacecolor = 'purple' , linewidth = 3,\n             markersize = 10, color = 'coral', ecolor = 'purple', elinewidth = 1.5)\n\n\nyg = []\nx = np.arange(0, k_lim_sup+1)\nfor i in range(len(x)):\n    yg.append(max_acc)\nplt.plot(x, yg, '--', color = 'purple', linewidth = 1)\nplt.xlabel('k')\nplt.ylabel('accuracy')\nplt.title('KNN performed on several values of k')\nplt.axis([0, k_lim_sup, min(scores_mean) - max(scores_std), max(scores_mean) + 1.5*max(scores_std)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}