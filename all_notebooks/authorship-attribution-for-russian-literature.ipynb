{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# NLP: classification task"},{"metadata":{},"cell_type":"markdown","source":"## Notes"},{"metadata":{},"cell_type":"markdown","source":"This notebook is a completely finished text classification work in the sense that this laptop contains all the steps necessary for analyzing and training the model, except for collecting raw data, and produces the result."},{"metadata":{},"cell_type":"markdown","source":"Each numbered part is essentially a stand-alone notebook. Thus, it is possible to divide this notebook into three parts."},{"metadata":{},"cell_type":"markdown","source":"If you are only interested in the classification model, then skip directly to step 3."},{"metadata":{},"cell_type":"markdown","source":"# 1) Dataset creation"},{"metadata":{},"cell_type":"markdown","source":"## Overview"},{"metadata":{},"cell_type":"markdown","source":"This part is needed to create a raw dataset for the task of classifying sentences by authorship from the original texts. The output will be a csv file in the format: \"sentence\", \"author\"."},{"metadata":{},"cell_type":"markdown","source":"To create a dataset, works are used (at start of this work):"},{"metadata":{},"cell_type":"markdown","source":"\n|Author|Works|\n|---------  |-------|\n|А.П. Чехов | Collection of stories |\n|Ф.М. Достоевский| Collection of selected works |\n|Л.Н. Толстой| Most Popular Writings |"},{"metadata":{},"cell_type":"markdown","source":"## File creation"},{"metadata":{},"cell_type":"markdown","source":"### Packages import"},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import List\nimport random\n\nimport glob\nfrom nltk import tokenize, download\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is necessary to tokenize the offer, it is enough to call it on the working machine once:"},{"metadata":{"trusted":true},"cell_type":"code","source":"download('punkt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function for loading and preprocessing text"},{"metadata":{},"cell_type":"markdown","source":"Let's create a list of sentences, the length of which is more than 5 characters, since shorter ones, most likely, do not carry information useful for attribution. Generally speaking, these sentences can express, and express quite vividly, the writing style of a particular author; however, this is not used in the model."},{"metadata":{},"cell_type":"markdown","source":"To improve the performance of the offer tokenizer, some character combinations are replaced. So, the replicas will be separate from the speech of the author in sentences, and the problem with quotes should be solved."},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_text(filepath: str, min_char: int = 5) -> List[str]:\n    \n    text = str()\n    with open(filepath, 'r', encoding='utf8') as file:\n        text = file.read().replace('\\n', '. ')\n        text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n        text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n    \n    sentences = tokenize.sent_tokenize(text)    \n    sentences = [sentence for sentence in sentences if len(sentence) >= min_char]\n\n    return list(sentences)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create a sentence| set for each author"},{"metadata":{"trusted":true},"cell_type":"code","source":"chekhov = []\nfor path in glob.glob('../input/russian-literature/prose/Chekhov/*.txt'):\n    chekhov += split_text(path)\n    \ndostoevsky = []\nfor path in glob.glob('../input/russian-literature/prose/Dostoevsky/*.txt'):\n    dostoevsky += split_text(path)\n\ntolstoy = []\nfor path in glob.glob('../input/russian-literature/prose/Tolstoy/*.txt'):\n    tolstoy += split_text(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_dict = { 'Chekhov': chekhov, 'Dostoevsky': dostoevsky, 'Tolstoy': tolstoy }\n\nfor key in text_dict.keys():\n    print(key, ':', len(text_dict[key]), ' sentences')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each list contains 21'860 to 117'861 sentences. In order to have an even distribution of authors in our set, we will limit the set for each, for example, to 20'000 sentences."},{"metadata":{},"cell_type":"markdown","source":"### Combining sentences"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\n\nmax_len = 20_000\n\nnames = [chekhov, dostoevsky, tolstoy]\n\ncombined = []\nfor name in names:\n    name = np.random.choice(name, max_len, replace = False)\n    combined += list(name)\n\nprint('Length of combo and internally shuffled list:', len(combined))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create a marked list"},{"metadata":{},"cell_type":"markdown","source":"At this point, it is important to indicate the labels of the authors (their names) in the same order as in the previous step, otherwise the data will simply turn out to be incorrect. So far, a simple regulating mechanism does not come to mind."},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Chekhov'] * max_len + ['Dostoevsky'] * max_len + ['Tolstoy'] * max_len\n\nprint('Length of marked list:', len(labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The output of the quantity was needed for additional control over the data and their labels. Equality means that every sentence in our dataset will have a label (correct or incorrect - it should have been controlled before)."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(combined) == len(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Randomly shuffle the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(3)\n\nzipped = list(zip(combined, labels))\nrandom.shuffle(zipped)\ncombined, labels = zip(*zipped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exporting the resulting dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"out_data = pd.DataFrame()\nout_data['text'] = combined\nout_data['author'] = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(out_data.head())\nprint(out_data.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_data.to_csv('author_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Dataset preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Preparing data for use in model training and explore it."},{"metadata":{},"cell_type":"markdown","source":"## Importing packages and loading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nimport time\n\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport nltk\nfrom nltk.stem.porter import PorterStemmer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('author_data.csv', encoding='utf8')\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = list(data['text'].values)\nauthor = list(data['author'].values)\n\nprint('Dataset contains {} notes.'.format(len(text)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data exploration"},{"metadata":{},"cell_type":"markdown","source":"Number of sentences for each author:"},{"metadata":{"trusted":true},"cell_type":"code","source":"authors = Counter(author)\nauthors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_names = list(authors.keys())\nauthor_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at some sample sentences:"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(73)\nn = len(text)\n\nfor _ in range(5):\n    print(text[np.random.randint(0, n)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculating statistics by words:"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_count = np.array([len(sent.split()) for sent in text])\nchar_count = np.array([len(sent) for sent in text])\nave_length = char_count / word_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_stats(var):    \n    print('\\t Min: ', np.min(var))\n    print('\\t Max: ', np.max(var))\n    print('\\t Average: ', np.mean(var))\n    print('\\t Median: ', np.median(var))\n    print('\\t Percentile 1%: ', np.percentile(var, 1))\n    print('\\t Percentile 95%: ', np.percentile(var, 95))\n    print('\\t Percentile 99%: ', np.percentile(var, 99))\n    print('\\t Percentile 99.5%: ', np.percentile(var, 99.5))\n    print('\\t Percentile 99.9%: ', np.percentile(var, 99.9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Word count"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Word count statistics:')\nget_stats(word_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(word_count, kde=True, bins=80, color='green').set_title('Distribution of word count')\nplt.xlabel('Sentence length in words')\nplt.ylabel('Number of offers')\nplt.xlim(0, 100)\nplt.savefig('word_count.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Character count"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Character count statistics:')\nget_stats(char_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(char_count, kde=True, bins=80, color='green').set_title('Distribution of characters')\nplt.xlabel('Sentence length in characters')\nplt.ylabel('Number of sentences')\nplt.xlim(0, 400)\nplt.savefig('char_count.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average length"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average length statistics:')\nget_stats(ave_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(ave_length, kde=True, bins=80, color='green').set_title('Distribution of average word length')\nplt.xlabel('Average word length in characters')\nplt.ylabel('Number of sentences')\nplt.xlim(0, 10)\nplt.savefig('ave_length.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Examining outliers in data"},{"metadata":{},"cell_type":"markdown","source":"### Extremely long sentences"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"word_outliers = np.where(word_count > 150)\n\nfor i in word_outliers[0][:5]:\n    print('Author: {}, Sentence length: {}'.format(author[i], word_count[i]))\n    print(text[i], '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_authors = {author : 0 for author in author_names}\n\nfor i in word_outliers[0]:\n    max_authors[author[i]] += 1\n\nCounter(max_authors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extremely short"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"word_outliers = np.where(word_count < 2)\n\nfor i in word_outliers[0][:10]:\n    print('Sentence length: {}'.format(word_count[i]))\n    print(text[i], '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring symbols"},{"metadata":{},"cell_type":"markdown","source":"Let's create a dictionary showing the number of dataset inclusions for each character."},{"metadata":{"trusted":true},"cell_type":"code","source":"text_string = ''\nfor sents in text:\n    text_string += sents.lower()\n\nchar_cnt = Counter(text_string)\nprint(char_cnt)\nprint(len(char_cnt), 'unusual symbols in data.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All symbols used:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(char_cnt.keys()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among them there are many that do not belong to the standard ones, such as punctuation or Cyrillic characters. Let's highlight those sentences in which they occur."},{"metadata":{"trusted":true},"cell_type":"code","source":"accented_chars = ['f', 'u', 'r', 's', 'i', 'c', 'h', '́', 'n', 'd', 'p', 'e', 'a', 't', 'o', 'l', 'x', 'm', 'j', 'é', 'ô', 'v', 'q', 'ê', 'g', 'b', 'k', 'y', 'à', 'і', 'z', 'w', 'è', 'ó', 'ö', '°', 'ç', 'ï', 'á', 'ü', 'ù', 'û', 'î', 'ѣ', 'â']\n\naccented_text = []\nfor i in range(len(text)):\n    for j in text[i]:\n        if j in accented_chars:\n            accented_text.append(i)\n        \naccented_text = list(set(accented_text))\n \nprint(len(accented_text), 'sentences contains unusual symbols.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in accented_text[:10]:\n    print('Sentence number {}: '.format(i))\n    print(text[i], '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the above research proposals, we can say that our data is quite suitable for analysis. The only thing is that you need to remove the indented blocks and some invalid characters that are artifacts of the original text."},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{},"cell_type":"markdown","source":"This is exactly where we remove the unacceptable uninformative characters."},{"metadata":{"trusted":true},"cell_type":"code","source":"text = [excerpt.replace('\\xa0', '').replace('\\x7f', '') for excerpt in text]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And big blocks of indentation."},{"metadata":{"trusted":true},"cell_type":"code","source":"ctr = 0\nfor excerpt in text:\n    if '  ' in excerpt:\n        ctr += 1\n\nprint(ctr, 'occurrences of large blocks of indentation.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_text = []\nfor excerpt in text:\n    while '  ' in excerpt:\n        excerpt = excerpt.replace('  ',' ')\n    new_text.append(excerpt)\n\ntext = new_text\nprint(len(text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove punctuation and convert all letters of the sentence to lowercase."},{"metadata":{"trusted":true},"cell_type":"code","source":"normed_text = []\n\nfor sent in text:\n    new = sent.lower()\n    new = new.translate(str.maketrans('','', string.punctuation))\n    new = new.replace('“', '').replace('”', '') # english quotes\n    new = new.replace('‟', '').replace('”', '') # french quotes\n    new = new.replace('«', '').replace('»', '') # christmas tree quotes\n    new = new.replace('—', '').replace('–', '') # em dash\n    new = new.replace('(', '').replace(')', '')\n    new = new.replace('…', '') # ellipsis as one character\n    \n    normed_text.append(new)\n    \nprint(normed_text[0:5])\nprint(len(normed_text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save the prepared data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = normed_text\n\ndata.to_csv('preprocessed_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysys"},{"metadata":{},"cell_type":"markdown","source":"Teaching and learning models."},{"metadata":{},"cell_type":"markdown","source":"## Importing packages and loading pre-prepared data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import List\n\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport string\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, Embedding\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.text import one_hot\nfrom keras.callbacks import ModelCheckpoint \n\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"preprocessed_data.csv\", encoding='utf8')\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normed_text = list(data['text'])\nauthor = list(data['author'])\n\nauthors_names = list(Counter(author).keys())\nauthors_count = len(authors_names)\n\nnormed_text = [str(i) for i in normed_text]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Section with statistics and output functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes: List[str],\n                          normalize: bool = False,\n                          title: str = 'Confusion matrix',\n                          cmap = plt.cm.Greens):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print('Normalized confusion matrix')\n    else:\n        print('Unnormalized confusion matrix')\n\n    print(cm)\n       \n    df_cm = pd.DataFrame(cm, index = classes,\n                  columns = classes)\n    sns.heatmap(df_cm, annot=True, cmap = cmap)\n    plt.ylabel('Right author')\n    plt.xlabel('Predicted author')\n    plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history_of_accurancy(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model\\'s accurancy')\n    plt.ylabel('accurancy')\n    plt.xlabel('epochs')\n    plt.legend(['teaching data', 'test data'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history_of_loss(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model\\'s error')\n    plt.ylabel('error')\n    plt.xlabel('epochs')\n    plt.legend(['teaching data', 'test data'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing data for direct use"},{"metadata":{},"cell_type":"markdown","source":"### We select the training and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_train, text_test, author_train, author_test = train_test_split(normed_text, author, test_size=0.2, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(text_train))\nprint(np.shape(text_test))\nprint(np.shape(author_train))\nprint(np.shape(author_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create n-gram sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_n_grams(excerpt_list: List[str], n: int, vocab_size: int, seq_size: int):\n    n_gram_list = []\n\n    for excerpt in excerpt_list:\n        excerpt = excerpt.replace(\" \", \"\")\n\n        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n\n        new_string = \" \".join(n_grams)\n\n        hot = one_hot(new_string, round(vocab_size * 1.3))\n\n        hot_len = len(hot)\n        if hot_len >= seq_size:\n            hot = hot[0:seq_size]\n        else:\n            diff = seq_size - hot_len\n            extra = [0]*diff\n            hot = hot + extra\n\n        n_gram_list.append(hot)\n    \n    n_gram_array = np.array(n_gram_list)\n    \n    return n_gram_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_vocab_size(excerpt_list: List[str], n: int, seq_size: int) -> int:\n    n_gram_list = []\n\n    for excerpt in excerpt_list:\n        excerpt = excerpt.replace(\" \", \"\")\n   \n        n_grams = [excerpt[i:i + n] for i in range(len(excerpt) - n + 1)]\n\n        gram_len = len(n_grams)\n        if gram_len >= seq_size:\n            n_grams = n_grams[0:seq_size]\n        else:\n            diff = seq_size - gram_len\n            extra = [0]*diff\n            n_grams = n_grams + extra\n        \n        n_gram_list.append(n_grams)\n    \n    n_gram_list = list(np.array(n_gram_list).flat)\n    \n    n_gram_cnt = Counter(n_gram_list)\n    vocab_size = len(n_gram_cnt)\n    \n    return vocab_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Determine the size of the dictionary for n from 1 to 3 inclusive:"},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_sizes = []\nfor i in range(1, 4):\n    vocab_sizes.append(get_vocab_size(text_train, i, 350))\n    print('Size for n =', i, 'is:', vocab_sizes[i - 1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And create lists of n-grams:"},{"metadata":{"trusted":true},"cell_type":"code","source":"gram1_train = create_n_grams(text_train, 1, vocab_sizes[0], 350)\ngram2_train = create_n_grams(text_train, 2, vocab_sizes[1], 350)\ngram3_train = create_n_grams(text_train, 3, vocab_sizes[2], 350)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram1_test = create_n_grams(text_test, 1, vocab_sizes[0], 350)\ngram2_test = create_n_grams(text_test, 2, vocab_sizes[1], 350)\ngram3_test = create_n_grams(text_test, 3, vocab_sizes[2], 350)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(gram1_train))\nprint(np.shape(gram2_train))\nprint(np.shape(gram3_train))\n\nprint(np.shape(gram1_test))\nprint(np.shape(gram2_test))\nprint(np.shape(gram3_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Определим максимальное значение n-грамм, что будет использовано для создания сети."},{"metadata":{"trusted":true},"cell_type":"code","source":"max_1gram = np.max(gram1_train)\nmax_2gram = np.max(gram2_train)\nmax_3gram = np.max(gram3_train)\n\nprint('Max value for 1-gramms: ', max_1gram)\nprint('Max value for bigramms: ', max_2gram)\nprint('Max value for trigramms: ', max_3gram)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorization"},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_train = text_train\nprocessed_test = text_test\n\nprint(processed_train[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(strip_accents = 'unicode', min_df = 6)\nvectorizer.fit(processed_train)\n\nprint('Dictionary size: ', len(vectorizer.vocabulary_))\n\nwords_train = vectorizer.transform(processed_train)\nwords_test = vectorizer.transform(processed_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_lb = LabelBinarizer()\n\nauthor_lb.fit(author_train)\nauthor_train_hot = author_lb.transform(author_train)\nauthor_test_hot = author_lb.transform(author_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model implementation"},{"metadata":{},"cell_type":"markdown","source":"https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/"},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_model(input_len: int, output_size: int, vocab_size : int, embedding_dim: int, verbose: bool = True,\n                drop_out_pct: float = 0.25, conv_filters: int = 500, activation_fn: str = 'relu', pool_size: int = 2, learning: float = 0.0001):\n    inputs1 = Input(shape=(input_len,))\n    embedding1 = Embedding(vocab_size, embedding_dim)(inputs1)\n    drop1 = Dropout(drop_out_pct)(embedding1)\n    conv1 = Conv1D(filters=conv_filters, kernel_size=3, activation=activation_fn)(drop1)\n    pool1 = MaxPooling1D(pool_size=pool_size)(conv1)\n    flat1 = Flatten()(pool1)\n    \n    inputs2 = Input(shape=(input_len,))\n    embedding2 = Embedding(vocab_size, embedding_dim)(inputs2)\n    drop2 = Dropout(drop_out_pct)(embedding2)\n    conv2 = Conv1D(filters=conv_filters, kernel_size=4, activation=activation_fn)(drop2)\n    pool2 = MaxPooling1D(pool_size=pool_size)(conv2)\n    flat2 = Flatten()(pool2)\n    \n    inputs3 = Input(shape=(input_len,))\n    embedding3= Embedding(vocab_size, embedding_dim)(inputs3)\n    drop3 = Dropout(drop_out_pct)(embedding3)\n    conv3 = Conv1D(filters=conv_filters, kernel_size=5, activation=activation_fn)(drop3)\n    pool3 = MaxPooling1D(pool_size=pool_size)(conv3)\n    flat3 = Flatten()(pool3)\n    \n    merged = concatenate([flat1, flat2, flat3])\n    \n    output = Dense(output_size, activation='softmax')(merged)\n    \n    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=output)\n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning), metrics=['accuracy'])\n    \n    if verbose:\n        print(model.summary())\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculations"},{"metadata":{"trusted":true},"cell_type":"code","source":"gram1_model = define_model(350, authors_count, max_1gram + 1, 26)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram1_model_history = gram1_model.fit([gram1_train, gram1_train, gram1_train], author_train_hot, epochs=10, batch_size=32, \n                verbose = 1, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram2_model = define_model(350, authors_count, max_2gram + 1, 300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram2_model_history = gram2_model.fit([gram2_train, gram2_train, gram2_train], author_train_hot, epochs=10, batch_size=32, \n                verbose = 1, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time.time()\ngram3_model = define_model(350, authors_count, max_3gram + 1, 600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram3_model_history = gram3_model.fit([gram3_train, gram3_train, gram3_train], author_train_hot, epochs=10, batch_size=32, \n                verbose=1, validation_split=0.2)\nt1 = time.time()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3-gramm first model statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"author_pred1 = gram3_model.predict([gram3_test, gram3_test, gram3_test])\n\nt2 = time.time()\n\nauthor_pred1 = author_lb.inverse_transform(author_pred1)\n\naccuracy = accuracy_score(author_test, author_pred1)\nprecision, recall, f1, support = score(author_test, author_pred1)\nave_precision = np.average(precision, weights = support/np.sum(support))\nave_recall = np.average(recall, weights = support/np.sum(support))\nave_f1 = np.average(f1, weights = support/np.sum(support))\nconfusion = confusion_matrix(author_test, author_pred1, labels=authors_names)\n    \nprint('Accurancy:', accuracy)\nprint('Average Precision:', ave_precision)\nprint('Average Recall:', ave_recall)\nprint('Average F1 Score:', ave_f1)\nprint('Learning time:', (t1 - t0), 'seconds')\nprint('Prediction time:', (t2 - t1), 'seconds')\nprint('Confusion matrix:\\n', confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(confusion, classes=authors_names, \\\n                      normalize=True, title='Normalized confusion matrix - Model 1')\n\nplt.savefig('confusion_model1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history_of_accurancy(gram3_model_history)\nplt.savefig('accurancy_model1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history_of_loss(gram3_model_history)\nplt.savefig('loss_model1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.utils.plot_model(gram3_model, 'gram3_model1_arh.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The trigram model showed the best results in terms of accuracy, so you should choose it as the main one.\n\nThe improved version should only be trained for 5 epochs, because the graph shows a plateau and even a decline in model accuracy after this point."},{"metadata":{},"cell_type":"markdown","source":"## Improvement"},{"metadata":{},"cell_type":"markdown","source":"Retraining the trigram model with the addition of an additional channel."},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_model2(input_len: int, output_size: int, vocab_size: int, embedding_dim: int, verbose: bool = True,\n                drop_out_pct: float = 0.25, conv_filters: int = 500, activation_fn: str = 'relu', pool_size:int = 2, learning: float = 0.0001):\n    \n    inputs1 = Input(shape=(input_len,))\n    embedding1 = Embedding(vocab_size, embedding_dim)(inputs1)\n    drop1 = Dropout(drop_out_pct)(embedding1)\n    conv1 = Conv1D(filters=conv_filters, kernel_size=3, activation=activation_fn)(drop1)\n    pool1 = MaxPooling1D(pool_size=pool_size)(conv1)\n    flat1 = Flatten()(pool1)\n    \n    inputs2 = Input(shape=(input_len,))\n    embedding2 = Embedding(vocab_size, embedding_dim)(inputs2)\n    drop2 = Dropout(drop_out_pct)(embedding2)\n    conv2 = Conv1D(filters=conv_filters, kernel_size=4, activation=activation_fn)(drop2)\n    pool2 = MaxPooling1D(pool_size=pool_size)(conv2)\n    flat2 = Flatten()(pool2)\n\n    inputs3 = Input(shape=(input_len,))\n    embedding3= Embedding(vocab_size, embedding_dim)(inputs3)\n    drop3 = Dropout(drop_out_pct)(embedding3)\n    conv3 = Conv1D(filters=conv_filters, kernel_size=5, activation=activation_fn)(drop3)\n    pool3 = MaxPooling1D(pool_size=pool_size)(conv3)\n    flat3 = Flatten()(pool3)\n    \n    inputs4 = Input(shape=(input_len,))\n    embedding4 = Embedding(vocab_size, embedding_dim)(inputs4)\n    drop4 = Dropout(drop_out_pct)(embedding4)\n    conv4 = Conv1D(filters=conv_filters, kernel_size=6, activation=activation_fn)(drop4)\n    pool4 = MaxPooling1D(pool_size=pool_size)(conv4)\n    flat4 = Flatten()(pool4)\n    \n    merged = concatenate([flat1, flat2, flat3, flat4])\n    \n    output = Dense(output_size, activation='softmax')(merged)\n    \n    model = Model(inputs = [inputs1, inputs2, inputs3, inputs4], outputs = output)\n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning), metrics=['accuracy'])\n    \n    if verbose:\n        print(model.summary())\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time.time()\ngram3_model2 = define_model2(350, authors_count, max_3gram + 1, 600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram3_model2_history = gram3_model2.fit([gram3_train, gram3_train, gram3_train, gram3_train], author_train_hot, epochs=5, batch_size=32, \n                verbose=1, validation_split=0.2)\nt1 = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"author_pred2 = gram3_model2.predict([gram3_test, gram3_test, gram3_test, gram3_test])\n\nt2 = time.time()\n\nauthor_pred2 = author_lb.inverse_transform(author_pred2)\n\naccuracy = accuracy_score(author_test, author_pred2)\nprecision, recall, f1, support=score(author_test, author_pred2)\nave_precision = np.average(precision, weights=support/np.sum(support))\nave_recall = np.average(recall, weights=support/np.sum(support))\nave_f1 = np.average(f1, weights=support/np.sum(support))\nconfusion = confusion_matrix(author_test, author_pred2, labels=authors_names)\n    \nprint('Accurancy:', accuracy)\nprint('Average Precision:', ave_precision)\nprint('Average Recall:', ave_recall)\nprint('Average F1 Score:', ave_f1)\nprint('Learning time:', (t1 - t0), 'seconds')\nprint('Predict time:', (t2 - t1), 'seconds')\nprint('Confusion matrix:\\n', confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(confusion, classes=authors_names, \\\n                      normalize=True, title='Normalized confusion matrix - Model 2')\n\nplt.savefig('confusion_model2.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history_of_accurancy(gram3_model2_history)\nplt.savefig('accurancy_model2.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history_of_loss(gram3_model2_history)\nplt.savefig('loss_model2.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.utils.plot_model(gram3_model2, 'gram3_model2_arh.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4*) Benchmarks and comparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_list = []\nprec_list = []\nrecall_list = []\nf1_list = []\n\nfor i in range(10):\n    author_pred3 = np.random.choice(authors_names, len(author_test))\n\n    accuracy = accuracy_score(author_test, author_pred3)\n    precision, recall, f1, support = score(author_test, author_pred3)\n    ave_precision = np.average(precision, weights = support/np.sum(support))\n    ave_recall = np.average(recall, weights = support/np.sum(support))\n    ave_f1 = np.average(f1, weights = support/np.sum(support))\n    \n    accuracy_list.append(accuracy)\n    prec_list.append(ave_precision)\n    recall_list.append(ave_recall)\n    f1_list.append(ave_f1)\n\nprint('Accurancy:', accuracy_list, np.mean(accuracy_list), np.std(accuracy_list))\nprint('Average Precision:', prec_list, np.mean(prec_list), np.std(prec_list))\nprint('Average Recall:', recall_list, np.mean(recall_list), np.std(recall_list))\nprint('Average F1 Score:', f1_list, np.mean(f1_list), np.std(f1_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(100):\n    print('Sentence', i, '- Right answer =', author_test[i],  'Model\\'s 1 predict =', author_pred1[i], \n         'Model\\'s 2 predict =', author_pred2[i])\n    print(text_test[i], '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_averages(true, pred, text):\n    \n    correct_len_chars = []\n    incorrect_len_chars = []\n    correct_len_words = []\n    incorrect_len_words = []\n\n    \n    for i in range(len(true)):\n        if true[i] == pred[i]:\n            correct_len_chars.append(len(text[i]))\n            correct_len_words.append(len(text[i].split()))\n        else:\n            incorrect_len_chars.append(len(text[i]))\n            incorrect_len_words.append(len(text[i].split()))\n    \n    correct_ave_chars = np.mean(correct_len_chars)\n    correct_ave_words = np.mean(correct_len_words)\n    incorrect_ave_chars = np.mean(incorrect_len_chars)\n    incorrect_ave_words = np.mean(incorrect_len_words)\n    \n    print('t-test for characters')\n    print(stats.ttest_ind(correct_len_chars, incorrect_len_chars, equal_var = False))\n    \n    print('\\nt-test for words')\n    print(stats.ttest_ind(correct_len_words, incorrect_len_words, equal_var = False))\n    \n    return correct_ave_chars, correct_ave_words, incorrect_ave_chars, incorrect_ave_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_ave_chars1, correct_ave_words1, incorrect_ave_chars1, incorrect_ave_words1\\\n= calculate_averages(author_test, author_pred1, text_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_ave_chars2, correct_ave_words2, incorrect_ave_chars2, incorrect_ave_words2\\\n= calculate_averages(author_test, author_pred2, text_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model 1 - Average length correct predicted sentences by characters =', correct_ave_chars1, \n        ', incorrect =', incorrect_ave_chars1)\nprint('Model 2 - Average length correct predicted sentences by characters =', correct_ave_chars2, \n      ', incorrect =', incorrect_ave_chars2)\n\nprint('\\nModel 1 - Average length correct predicted sentences by words =', correct_ave_words1, \n        ', incorrect =', incorrect_ave_words1)\nprint('Model 2 - Average length correct predicted sentences by words =', correct_ave_words2, \n      ', incorrect =', incorrect_ave_words2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}