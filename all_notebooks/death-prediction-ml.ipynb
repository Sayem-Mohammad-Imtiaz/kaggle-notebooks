{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <u> Death Prediction</u>\n<u>Authored by : Pratham Tripathi [(github)](http://https://github.com/pratham0203) </u>\n\nIn this Solution we are going to use two MAchine Learning Algorithms namely:\n\n- Logistic Regression\n- SVM (Simple Vector Machine)\n\n## <u> Logistic Regression </u>\nLogistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n\n## <u> Simple Vector Machine </u>\nSupport Vector Machine” (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges. However, it is mostly used in classification problems.What it does is instead of choosing a paticular line of regression or anything it uses Kernel which is plotting of points on a hyperplane and then by using a separator it distinguishes different classes thus the classification takes place.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pylab as py\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes','ejection_fraction', 'high_blood_pressure', 'platelets','serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time','DEATH_EVENT']]\ndata[\"DEATH_EVENT\"] = data[\"DEATH_EVENT\"].astype(\"int\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Selecting Feature (X) and target Variable (y)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.asanyarray(data[['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes','ejection_fraction', 'high_blood_pressure', 'platelets','serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']])\nX[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.asanyarray(data['DEATH_EVENT'])\ny[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Processing the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Database","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Set:\",X_train.shape,y_train.shape)\nprint(\"Test Set:\",X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C = 0.01, solver = \"liblinear\").fit(X_train,y_train)\nLR","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Vector Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVC(kernel=\"sigmoid\")\nclf.fit(X_train,y_train)\ny_hat = clf.predict(X_test)\ny_hat[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = LR.predict(X_test)\nyhat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat_prob = LR.predict_proba(X_test)\nyhat_prob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix Definition ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport itertools\ndef plot_confusion_matrix(cm,classes,\n                         normalize = False,\n                         title='Confusion Matrix',\n                         cmap = plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float')/cm.sum(axis = 1)[:,np.newaxis]\n        print(\"After Normalization\")\n    else:\n        print(\"Without Normalization\")\n    print(cm)\n    plt.imshow(cm,interpolation='nearest',cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks,classes,rotation = True,color='white')\n    plt.yticks(tick_marks,classes,rotation =True,color='white')\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max()/2\n    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i,format(cm[i,j],fmt),\n                horizontalalignment = \"center\",\n                color = 'white' if cm[i,j]>thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.xlabel(\"Predicted\",color='white',size=20)\n    plt.ylabel(\"True\",color='white',size=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F1 Score of Logisitic Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1_score(y_test,yhat,average = \"weighted\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## F1 Score of SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_test,y_hat,average = \"weighted\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix for Logisitic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix=confusion_matrix(y_test,yhat,labels=[0,1])\nnp.set_printoptions(precision = 2)\nprint(classification_report(y_test,yhat))\nplt.figure()\nplot_confusion_matrix(cnf_matrix,classes=['Survived(0)','Died(1)'],normalize=False,title='Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Confusion Matrix for ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix=confusion_matrix(y_test,y_hat,labels=[0,1])\nnp.set_printoptions(precision = 2)\nprint(classification_report(y_test,yhat))\nplt.figure()\nplot_confusion_matrix(cnf_matrix,classes=['Survived(0)','Died(1)'],normalize=False,title='Confusion Matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}