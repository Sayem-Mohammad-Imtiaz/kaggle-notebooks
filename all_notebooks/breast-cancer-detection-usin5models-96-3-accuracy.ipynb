{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r'../input/breastcancerwisconsin/bc2.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets check the dtypes\ndf.info()\n#only one 'Bare Nuclei' object type feature remainig all are int type  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets analyse the Bare Nuclei \n\nprint(df['Bare Nuclei'].value_counts())\n# we can see that the values are numberical but there special character '?' assigned \n# we will handle this value by replacing this with median value\ndf['Bare Nuclei'] = df['Bare Nuclei'].replace('?',np.nan)\ndf['Bare Nuclei'].fillna(df['Bare Nuclei'].median(),inplace=True)\n\ndf['Bare Nuclei'] = df['Bare Nuclei'].astype('int')\nprint(df['Bare Nuclei'].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check for the null values \ndf.isnull().sum()\ndf.isnull().apply(pd.value_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"EDA","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can remove the ID column as it has less relvance\ndf.drop('ID',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['Class'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Class'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\npos=1\nfor i in df.columns:\n    plt.subplot(2,5,pos)\n    sns.boxplot(df[i],orient= \"v\")\n    plt.title(i)\n    pos +=1\n   \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets see the the outliers %\n\nfor k, v in df.items():\n        q1 = v.quantile(0.25)\n        q3 = v.quantile(0.75)\n        irq = q3 - q1\n        v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n        perc = np.shape(v_col)[0] * 100.0 / np.shape(df)[0]\n        print(\"Column %s outliers = %.2f%%\" % (k, perc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reducing the outliers \nfor i in df.columns:\n    q1,q2,q3 = df[i].quantile([0.25,0.50,0.75])\n    iqr  = q3-q1\n    a = df[i]>=q3+1.5*iqr\n    b = df[i]<=q1-1.5*iqr\n    df[i] = np.where(a|b,q2,df[i])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#After removong the outlier lets see the differnce \nfor k, v in df.items():\n        q1 = v.quantile(0.25)\n        q3 = v.quantile(0.75)\n        irq = q3 - q1\n        v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n        perc = np.shape(v_col)[0] * 100.0 / np.shape(df)[0]\n        print(\"Column %s outliers = %.2f%%\" % (k, perc))\n        \n#We can see the outlier are incresing ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets see the skweness \npos=1\nplt.figure(figsize=(20,6))\nfor i in df.columns:\n    plt.subplot(2,5,pos)\n    sns.distplot(df[i],pos)\n    pos +=1\n    plt.title(i)\n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets try to reduce the skewness\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.iloc[:,:-1]\ny = df['Class']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor col in x.columns:\n    if np.abs(x[col].skew()) > 0.3:\n        x[col] = np.log1p(x[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation \ncorr = df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\nsns.heatmap(corr[(corr>=0.5)|(corr<=-0.4)],vmax=1,vmin=-1,annot=True,cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('Class',axis=1).corrwith(df['Class']).plot(kind='bar',title='Corr with Class')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cell shape, cell size and Bare Nuclei are major factors in class detection\n#cell shape and cell size are highly corr so we can consider one feature \n#Mitoses doesnot have any corr with class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bivaraint analysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsns.jointplot(x=df['Cell Shape'],y = df['Cell Size'],kind='scatter')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.violinplot(x=df['Cell Shape'],y=df['Cell Size'],hue=df['Class'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=df['Cell Shape'],y=df['Cell Size'],hue=df['Class'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-1 is that outlier is present","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lof = LocalOutlierFactor()\nlof.fit_predict(x)[0:10]\nx_score = lof.negative_outlier_factor_\noutlier_score= pd.DataFrame()\noutlier_score[\"score\"]=x_score\n\nlofthreshold= -2.5\nloffilter= outlier_score[\"score\"]< lofthreshold\noutlier_index = outlier_score[loffilter].index.to_list()\nx = x.drop(outlier_index)\ny = y.drop(outlier_index).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape,y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(x=df['Cell Shape'],y=df['Cell Size'],)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(x=df['Cell Shape'],y=df['Bare Nuclei'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(x=df['Cell Size'],y=df['Bare Nuclei'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scl = StandardScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = pd.DataFrame(scl.fit_transform(x),columns=x.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x['Mitoses'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can remove the Mitoses feature \nx.drop('Mitoses',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LogisticRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = clf.predict(xtest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score = clf.score(xtrain,ytrain)\ntest_score = accuracy_score(ytest,pred)\ntn,fp,fn,tp=confusion_matrix(ytest,pred).ravel()\nrecall = round(tp/(tp+fn),3)\nspecificity = round(tn/(tn+fp),3)\nprecision = round(tp/(tp+fp),3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final = pd.DataFrame({'Model':['Logistic Reg'],'accuracy':[test_score],'True +ve rate':[recall],'True -ve Rate':[specificity],'precision':[precision]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets try to improve the accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = pd.DataFrame(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier()\ntree.fit(xtrain, ytrain)\n\npred = tree.predict(xtest)\n\ntrain_score = tree.score(xtrain,ytrain)\ntest_score = accuracy_score(ytest,pred)\ntn,fp,fn,tp=confusion_matrix(ytest,pred).ravel()\nrecall = round(tp/(tp+fn),3)\nspecificity = round(tn/(tn+fp),3)\nprecision = round(tp/(tp+fp),3)\nfinal.loc[1] = ['Decision Tree',test_score,recall,specificity,precision]\nfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(xtrain,ytrain)\npred = rf.predict(xtest)\ntrain_score = rf.score(xtrain,ytrain)\ntest_score = accuracy_score(ytest,pred)\ntn,fp,fn,tp=confusion_matrix(ytest,pred).ravel()\nrecall = round(tp/(tp+fn),3)\nspecificity = round(tn/(tn+fp),3)\nprecision = round(tp/(tp+fp),3)\nfinal.loc[2] = ['Random Forest',test_score,recall,specificity,precision]\nfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets try using Cross validastion\n\nfrom sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = cross_val_score(clf,x,y,cv=5,n_jobs=4,verbose=2).mean()\ncv1 = cross_val_score(tree,x,y,cv=5,n_jobs=4,verbose=2).mean()\ncv2 = cross_val_score(rf,x,y,cv=5,n_jobs=4,verbose=2).mean()\nprint(cv,cv1,cv2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cross validation with Random forest had given better accuracy of 96%","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = SVC()#rbf by default","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = svm.predict(xtest)\ntrain_score = svm.score(xtrain,ytrain)\ntest_score = accuracy_score(ytest,pred)\ntn,fp,fn,tp=confusion_matrix(ytest,pred).ravel()\nrecall = round(tp/(tp+fn),3)\nspecificity = round(tn/(tn+fp),3)\nprecision = round(tp/(tp+fp),3)\nfinal.loc[3] = ['SVM',test_score,recall,specificity,precision]\nfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets see if we further tune the RF and accuracy has imporved or not","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_params  = {\n    \"svm\" : {\n        \"model\":SVC(gamma=\"auto\"),\n        \"params\":{\n            'C' : [1,10,20],\n            'kernel':['poly','linear','sigmoid']\n        }\n    },\n    \n    \"decision_tree\":{\n        \"model\": DecisionTreeClassifier(),\n        \"params\":{\n            'criterion':[\"entropy\",\"gini\"],\n            \"max_depth\":[5,8,9]\n        }\n    },\n    \n    \"random_forest\":{\n        \"model\": RandomForestClassifier(),\n        \"params\":{\n            \"n_estimators\":[1,5,10],\n            \"max_depth\":[5,8,9]\n        }\n    },\n   \n    \n    'logistic_regression' : {\n        'model' : LogisticRegression(solver='liblinear',multi_class = 'auto'),\n        'params': {\n            \"C\" : [1,5,10]\n        }\n    }\n    \n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score=[]\nfrom sklearn.model_selection import GridSearchCV\nfor model_name,mp in model_params.items():\n    clf = GridSearchCV(mp[\"model\"],mp[\"params\"],cv=8,return_train_score=False)\n    clf.fit(x,y)\n    score.append({\n        \"Model\" : model_name,\n        \"Best_Score\": clf.best_score_,\n        \"Best_Params\": clf.best_params_\n    })\ndf5 = pd.DataFrame(score,columns=[\"Model\",\"Best_Score\",\"Best_Params\"])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_tuned = SVC(C=1,kernel='linear')#rbf by default\nsvm_tuned.fit(xtrain,ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = svm_tuned.predict(xtest)\ntrain_score = svm_tuned.score(xtrain,ytrain)\ntest_score = accuracy_score(ytest,pred)\ntn,fp,fn,tp=confusion_matrix(ytest,pred).ravel()\nrecall = round(tp/(tp+fn),3)\nspecificity = round(tn/(tn+fp),3)\nprecision = round(tp/(tp+fp),3)\nfinal.loc[4] = ['SVM_tuned',0.963,recall,specificity,precision]\nfinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tune SVM has imnpored the accuracy to 96.3% whne Linear Kernel was used","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}