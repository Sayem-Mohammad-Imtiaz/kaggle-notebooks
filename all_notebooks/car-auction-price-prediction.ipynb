{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Car Auction Price Prediction  \n\nGiven *data about cars for sale in an auction*, let's try to predict the **price** of a given car.\n\nWe will use various regression models to make our predictions. "},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/usa-cers-dataset/USA_cars_datasets.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_encode(df, columns_with_positive_values):\n    df = df.copy()\n    for column, positive_value in columns_with_positive_values:\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef onehot_encode(df, columns_with_prefixes):\n    df = df.copy()\n    for column, prefix in columns_with_prefixes:\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1) \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unnecessary columns\n    df = df.drop(['Unnamed: 0', 'vin', 'lot'], axis=1)\n    \n    # Binary encode the title_status and country columns\n    df = binary_encode(\n        df,\n        columns_with_positive_values=[\n            ('title_status', 'salvage insurance'),\n            ('country', ' canada')\n        ]\n    )\n    \n    # One-hot encode the brand, model, color, state, and condition columns\n    df = onehot_encode(\n        df,\n        columns_with_prefixes=[\n            ('brand', 'br'),\n            ('model', 'md'),\n            ('color', 'cl'),\n            ('state', 'st'),\n            ('condition', 'cd')\n        ]\n    )\n    \n    # Fixes LightGBM error\n    df = df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n    \n    # Split df into X and y\n    y = df['price'].copy()\n    X = df.drop('price', axis=1).copy()\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    \"                     Linear Regression\": LinearRegression(),\n    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor(),\n    \"                               XGBoost\": XGBRegressor(),\n    \"                              LightGBM\": LGBMRegressor(),\n    \"                              CatBoost\": CatBoostRegressor(verbose=0)\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models.items():\n    print(name + \" R^2 Score: {:.5f}\".format(model.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/BFx8cJJoq9k"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}