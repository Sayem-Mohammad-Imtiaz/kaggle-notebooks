{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport collections\nfrom datetime import datetime, timedelta\nfrom functools import partial\nimport math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n#from kaggle_datasets import KaggleDatasets\nfrom torchvision import datasets, transforms ,utils,models\nimport efficientnet.tfkeras as efn\n\nfrom tensorflow.keras.applications import ResNet50V2,ResNet101V2,ResNet152V2,DenseNet201\nimport cv2\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport os\nimport shutil\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\nimport pathlib\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nprint(\"Tensorflow version \" + tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create strategy from tpu\nistpu=False\nif istpu:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = 16 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nIMAGE_SIZE = [512, 512]\nEPOCHS = 20\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test_ApKoW4T.csv')\nsample = pd.read_csv('../input/sample_submission_ns2btKE.csv')\ntrain = pd.read_csv('../input/train/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict = {1: 'Cargo', \n2:'Military', \n3:'Carrier', \n4:'Cruise', \n5:'Tankers'}\ntrain['category_label'] = train['category'].map(convertlabeldict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, holdout = train_test_split(train, test_size=0.2, random_state=0, \n                               stratify=train['category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index(drop=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout = holdout.reset_index(drop=True)\nholdout.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.reset_index(drop=True)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def copy_files_local(df,basedir,destinationfolder):\n    for i,row in df.iterrows():\n        currentfileloc = basedir + row['image']\n        if not os.path.exists(destinationfolder):\n            os.makedirs(destinationfolder)\n        shutil.copy(currentfileloc, destinationfolder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"copy_files_local(train,'../input/train/images/','../train/')\ncopy_files_local(holdout,'../input/train/images/','../holdout/')\ncopy_files_local(test,'../input/train/images/','../test/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../train/ | wc -l\n!ls ../holdout/ | wc -l\n!ls ../test/ | wc -l\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_filenames(df,category,image_num):\n    return random.sample(df[df.category==category]['image'].tolist(),image_num)\n\ndef random_brightness(image):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    rand = random.uniform(0.6, 1.0)\n    hsv[:, :, 2] = rand*hsv[:, :, 2]\n    rand = random.uniform(1.0, 1.5)\n    hsv[:, :, 1] = rand*hsv[:, :, 1]\n    new_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    return new_img\n\n\ndef zoom(image,rows,cols):\n    zoom_pix = random.randint(5, 10)\n    zoom_factor = 1 + (2*zoom_pix)/rows\n    image = cv2.resize(image, None, fx=zoom_factor,\n                       fy=zoom_factor, interpolation=cv2.INTER_LINEAR)\n    top_crop = (image.shape[0] - rows)//2\n    left_crop = (image.shape[1] - cols)//2\n    image = image[top_crop: top_crop+rows,\n                  left_crop: left_crop+cols]\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\ndef createaugimagesv2(df,category,image_num,dirname):\n    filename = get_filenames(df,category,image_num)\n    for images in filename:\n        if images[-8:]!='_enh.jpg' and images[-9:]!='_enh1.jpg':\n            imagepath = dirname + images\n            image = cv2.imread(imagepath)\n            rows,cols,channel = image.shape\n            image = np.fliplr(image)\n\n            op1 = random.randint(0, 1)\n            op2 = random.randint(0, 1)\n            op3 = random.randint(0, 1)\n            if op1:\n                image = random_brightness(image)\n            if op2:\n                image = zoom(image,rows,cols)\n            newimagepath = dirname + images.split('.')[0]+'_'+str(category) + '_enh.jpg'\n            try:\n                image = cv2.resize(image, (224, 224))\n                cv2.imwrite(newimagepath, image)\n            except:\n                print(\"file {0} is not converted\".format(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef im_convert(tensor):\n    image = tensor.clone().detach().numpy()\n    image = image.transpose(1, 2, 0)\n    image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n    image = image.clip(0, 1)\n    return image\n\ndef createaugimages(df,category,image_num,dirname):\n    filename = get_filenames(df,category,image_num)\n    for images in filename:\n        if images[-9:]!='_enh1.jpg':\n            imagepath = dirname + images\n            pil_im = Image.open(imagepath, 'r').convert('RGB')\n            op1 = random.randint(0, 1)\n            if op1 ==1:\n                changeimg = transforms.Compose([ \n                                        transforms.RandomRotation(5),\n                                        transforms.Resize(224),\n                                        transforms.ToTensor()\n                                       ])\n            else:\n                changeimg = transforms.Compose([ \n                            transforms.RandomHorizontalFlip(),\n                            transforms.RandomRotation(10),\n                            transforms.Resize(224),\n                            transforms.ToTensor()\n                           ])\n\n            img = changeimg(pil_im)\n            newimagepath = dirname + images.split('.')[0]+'_'+str(category) + '_enh1.jpg'\n            utils.save_image(img,newimagepath)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resizeall(dirname):\n    filename = os.listdir(dirname)\n    non3channel = []\n    for images in filename:\n        imagepath = dirname + images\n        image = cv2.imread(imagepath)\n        if image.shape[2] !=3:\n            non3channel.append(images)\n    return non3channel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict = {1: 'Cargo', \n2:'Military', \n3:'Carrier', \n4:'Cruise', \n5:'Tankers'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 1908 - 1095\nb = 1908 - 1050\nc = 1908 - 824\nd = 1908 - 749","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1    1696\n#5     973\n#2     933\n#3     733\n#4     666","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"createaugimagesv2(train,5,1696 - 1095,'../train/')\ncreateaugimagesv2(train,2,1696 - 1050,'../train/')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"createaugimagesv2(train,3,733,'../train/')\ncreateaugimagesv2(train,4,666,'../train/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"createaugimages(train,1,500,'../train/')\ncreateaugimages(train,5,500,'../train/')\ncreateaugimages(train,2,500,'../train/')\ncreateaugimages(train,3,733,'../train/')\ncreateaugimages(train,4,666,'../train/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"createaugimagesv2(train,3,288,'../train/')\ncreateaugimagesv2(train,4,400,'../train/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../train/'\ndata_dir = pathlib.Path(data_dir)\nenh_files = list(data_dir.glob('*_enh.jpg'))\nenh_files1 = list(data_dir.glob('*_enh1.jpg'))\nallfiles = enh_files+enh_files1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(allfiles),len(set(allfiles))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index(drop=False)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout = holdout.reset_index(drop=False)\nholdout.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.reset_index(drop=False)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enh_df = pd.DataFrame()\ni = max(train['index'])\nfor file in allfiles:\n    st = str(file)\n    cat = st.split('_')[1]\n    st = st.split('/')[-1]\n    i = i+1\n    enh_df = enh_df.append({'index': int(i), 'image': st, 'category': int(cat),'category_label':convertlabeldict[int(cat)]}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enh_df['index']=enh_df['index'].apply(int)\ntrain = pd.concat([train,enh_df]).reset_index(drop=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def null_finder(df):\n    for col in df.columns.tolist():\n        print(\"For column {0} : NULLS are {1}\".format(col,sum(df[col].isnull())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_finder(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_finder(holdout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_finder(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!ls ../train/ | wc -l\n!ls ../holdout/ | wc -l\n!ls ../test/ | wc -l\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../train/'\ndata_dir = pathlib.Path(data_dir)\nroses = list(data_dir.glob('*_enh.jpg'))\nimport IPython.display as display\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfor image_path in roses[:3]:\n    print(image_path)\n    display.display(Image.open(str(image_path)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nimg_size = 224\ntrain_image_count = 10546\nhold_image_count = 1251\nSTEPS_PER_EPOCH = np.ceil(train_image_count/BATCH_SIZE)\nSTEPS_PER_EPOCH_HOLD = np.ceil(hold_image_count/BATCH_SIZE)\nSTEPS_PER_EPOCH,STEPS_PER_EPOCH_HOLD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_img(img):\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    #img = tf.cast(image, tf.float32) / 255.0 \n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # resize the image to the desired size.\n    return tf.image.resize(img, [img_size, img_size])\n\ndef get_images_label(image,label):\n    img = tf.io.read_file(image)\n    img = decode_img(img)\n    label = tf.cast(label, tf.int32)\n    return img,label\n\ndef convert_cat(image,label):\n    label = tf.convert_to_tensor(tf.keras.utils.to_categorical(label, num_classes=5, dtype='float32'))\n    return image,label\n\ndef get_images_id(image,ids):\n    img = tf.io.read_file(image)\n    img = decode_img(img)\n    ids = tf.cast(ids, tf.int32)\n    return img,ids\n\ndef data_augment(image, label, seed=2020):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image, seed=seed)\n#    image = tf.image.random_flip_up_down(image, seed=seed)\n#    image = tf.image.random_brightness(image, 0.1, seed=seed)\n#    image = tf.image.random_jpeg_quality(image, 85, 100, seed=seed)\n#    image = tf.image.resize(image, [256, 256])\n#    image = tf.image.central_crop(image, [224, 224])\n#    image = tf.image.random_crop(image, [224, 224], seed=seed)\n    #image = tf.image.random_saturation(image, 0, 2)\n    return image, label \n\ndef data_reshape(image,label,seed=2020):\n#    image = tf.image.resize(image, [256, 256])\n    #image = tf.image.central_crop(image, [224, 224])\n    image = tf.image.random_crop(image, [img_size, img_size], seed=seed)\n    return image,label\n    \n\ndef get_training_dataset(dataset):\n    dataset = dataset.map(get_images_label, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    #dataset = dataset.map(convert_cat, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(BATCH_SIZE * 50)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(dataset):\n    dataset = dataset.map(get_images_label, num_parallel_calls=AUTOTUNE)\n    #dataset = dataset.map(data_reshape, num_parallel_calls=AUTO)\n    #dataset = dataset.map(convert_cat, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    #dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_test_dataset(dataset):\n    dataset = dataset.map(get_images_id, num_parallel_calls=AUTOTUNE)\n    #dataset = dataset.map(data_reshape, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#BATCH_SIZE = 64\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nCLASSES =[1,2,3,4,5]\n\ndataset_train = tf.data.Dataset.from_tensor_slices(('../train/'+train['image'].values,np.array(pd.get_dummies(train['category'].values))))\ndataset_holdout = tf.data.Dataset.from_tensor_slices(('../holdout/'+holdout['image'].values,np.array(pd.get_dummies(holdout['category'].values))))\ndataset_test = tf.data.Dataset.from_tensor_slices(('../test/'+test['image'].values,test['index'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_ds_train = get_training_dataset(dataset_train)\nfinal_ds_holdout = get_training_dataset(dataset_holdout)\nfinal_ds_test = get_test_dataset(dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(25):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        value = label_batch.numpy().tolist()\n        value = value[n].index(1) + 1\n        plt.title(convertlabeldict[value])\n        plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, label_batch = next(iter(final_ds_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nshow_batch(image_batch, label_batch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image,caregory in final_ds_holdout.take(5):\n    print(image.shape,caregory.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"convertlabeldict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def macro_f1(y, y_hat, thresh=0.5):\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#with strategy.scope():\nenet=False\nif enet:\n    features_model = efn.EfficientNetB7(\n        input_shape=(256, 256, 3),\n        weights='imagenet',\n        include_top=False\n    )\nelse:\n    features_model = DenseNet201(\n        input_shape=(img_size, img_size, 3),\n        weights='imagenet',\n        include_top=False\n    )\n\nmodel = tf.keras.Sequential([\n    features_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.compile(\n    #optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n    optimizer=tf.keras.optimizers.Adam(lr=0.00001),\n    #optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n    #loss = 'categorical_crossentropy',\n    #loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    #loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    #metrics=[tf.keras.metrics.SparseCategoricalCrossentropy()]\n    #metrics = tf.keras.metrics.sparse_categorical_accuracy()\n    loss = 'categorical_crossentropy',\n    #loss = macro_f1,\n    metrics=['categorical_accuracy']\n)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gpu_name = tf.test.gpu_device_name()\ngpu_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1**(epoch / s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(lr0=0.01, s=20)\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\nhistory = model.fit(\n    final_ds_train, \n    steps_per_epoch=STEPS_PER_EPOCH,\n    epochs=15, \n    validation_data=final_ds_holdout,\n    validation_steps=STEPS_PER_EPOCH_HOLD,\n    #validation_data=dataset_holdout\n    callbacks=[lr_schedule]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprobabilities = model.predict(final_ds_test)\npredictions = np.argmax(probabilities, axis=-1) +1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Counter(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Generating submission.csv file...')\ntest_ids_ds = final_ds_test.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(2680))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_training_curves(history.history['loss'], history.history['loss'], 'loss', 211)\ndisplay_training_curves(history.history['categorical_accuracy'], history.history['categorical_accuracy'], 'accuracy', 212)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}