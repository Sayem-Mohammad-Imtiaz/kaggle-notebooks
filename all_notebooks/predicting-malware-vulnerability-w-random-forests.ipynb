{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install fastai==0.7.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.imports import *\nfrom fastai.structured import *\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\nimport os, gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set paths for training and test data\nTRAIN_PATH = \"../input/microsoft-train\"\nTEST_PATH = \"../input/microsoft/microsoft-malware-prediction\"\n\n!ls {TRAIN_PATH}\n!ls {TEST_PATH}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n#             print(\"******************************\")\n#             print(\"Column: \",col)\n#             print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n#             print(\"dtype after: \",props[col].dtype)\n#             print(\"******************************\")\n    \n    # Print final result\n#     print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n#     mem_usg = props.memory_usage().sum() / 1024**2 \n#     print(\"Memory usage is: \",mem_usg,\" MB\")\n#     print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return props","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntraining_df = pd.read_csv(f'{TRAIN_PATH}/train.csv', low_memory=False)\n\n# downcast unnecessarily large dtypes to reduce overall size of dataframe\ntraining_df = reduce_mem_usage(training_df)\ntrain_cats(training_df)\n\n# change the HasDetection column's datatype from Float64 to Category\ntraining_df['HasDetections'] = training_df['HasDetections'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# clean the dataset by replacing na values, converting category types to numeric types, and stripping \n# the target column from the dataset\ndf, y, nas = proc_df(training_df, 'HasDetections', subset=400_000)\n\n#delete the original training dataset; no longer need it\n#del training_df\n#gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to split training set to set aside a validation set\ndef split_data(data, n):\n    return data[:n].copy(), data[n:].copy()\n\n# create validation set\nn_valid = 100_000\nn_trn = len(df)-n_valid\n\nX_train, X_valid = split_data(df, n_trn)\ny_train, y_valid = split_data(y, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\n#train the Random Forest classifier model\nclf = RandomForestClassifier(n_estimators=50, n_jobs=-1, verbose=1)\nclf.fit(X_train, y_train)\n\n#shows the importance of each feature as a predictor of whether a given machine has any\n#malware detections\nprint(clf.feature_importances_)\n\nprediction = clf.predict(X_valid)\n\n# how'd we do?\nroc_auc_score(y_valid, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n\n# do some of that good, good garbage collection\ndel X_train, X_valid, y_train, y_valid, df, y \ngc.collect()\n\n#create DataFrame to store results in\nresults_cols = ['MachineIdentifier','HasDetections']\nresults_df = pd.DataFrame(columns=results_cols)\n\nranges = [None, range(1,1_000_000), range(1, 2_000_000), range(1, 3_000_000), \n          range(1, 4_000_000), range(1, 5_000_000), range(1, 6_000_000), \n          range(1, 7_000_000)]\n\n# read in the test set and do all the processing steps\nfor i in ranges:\n    test_chunk = pd.read_csv(f'{TEST_PATH}/test.csv', low_memory=False, skiprows=i, nrows=1_000_000)\n    \n    # clean the dataset\n    test_chunk = reduce_mem_usage(test_chunk)\n    train_cats(test_chunk)\n    test_df, _, nas = proc_df(test_chunk, na_dict=nas)\n    \n    # make prediction for the chunk \n    predictions = clf.predict(test_df)\n\n    # create a temporary DataFrame to store current iterations predictions and append results to global list\n    tmp_df = pd.DataFrame({'MachineIdentifier': test_chunk['MachineIdentifier'],\n                         'HasDetections': predictions})\n    results_df = results_df.append(tmp_df)\n    \n    # delete everything from this iteration\n    del tmp_df, test_df, test_chunk\n    gc.collect()\n    \n# reset row indices \nresults_df = results_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop duplicate rows \nresults_copy = results_df.drop_duplicates(subset='MachineIdentifier', keep='first', inplace=False)\ndel results_df\ngc.collect()\n\n# save results to csv file\nresults_copy.to_csv('malware_predictions.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}