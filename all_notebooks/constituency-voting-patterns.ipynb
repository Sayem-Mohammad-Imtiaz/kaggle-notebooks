{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Put the data into DataFrames**","metadata":{}},{"cell_type":"code","source":"result = pd.read_csv('/kaggle/input/brexit-and-ethnicity/results.csv')\ncon_data = pd.read_csv('/kaggle/input/brexit-and-ethnicity/UK-constituency-data.csv')\ncon_eth = pd.read_csv('/kaggle/input/brexit-and-ethnicity/Consituancy Ethnicity.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the data sort by constituancy","metadata":{}},{"cell_type":"code","source":"\nprint(len(result))\nresult.sort_values('Constituency', inplace=True)\nresult.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(con_data))\ncon_data.sort_values('PCON14NM', inplace=True)\ncon_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(con_eth))\ncon_eth.sort_values('ConstituencyName', inplace=True)\ncon_eth.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# There are 5 extra rows in con_data (UK has 650 constiuancies). Need to find these non constituancies and remove","metadata":{}},{"cell_type":"code","source":"# put them all into lists to compare \nresult_cons = result['Constituency'].to_list()\ncon_data_cons = con_data['PCON14NM'].to_list()\ncon_eth_cons = con_eth['ConstituencyName'].to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I think the extra entries are regions so will just check on first four chars. I expect some of the consituancies may have been spelt differently \n\nshort_cons = []\n\nfor entry in result_cons:\n    short_cons.append(entry[:8])\n\nfor entry in con_data_cons:\n    if entry[:8] not in short_cons:\n        print(entry)\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove these surplus rows\n\ncon_data.drop(con_data[con_data['PCON14NM'] == 'Wales'].index, inplace = True)\ncon_data.drop(con_data[con_data['PCON14NM'] == 'UK'].index, inplace = True)\ncon_data.drop(con_data[con_data['PCON14NM'] == 'England'].index, inplace = True)\ncon_data.drop(con_data[con_data['PCON14NM'] == 'Scotland'].index, inplace = True)\ncon_data.drop(con_data[con_data['PCON14NM'] == 'Northern Ireland'].index, inplace = True)\n\nprint(len(con_data))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Quick check all Dataframes are aligned ","metadata":{}},{"cell_type":"code","source":"# re run lists to check the constituancies are the same. I expect some differencies in entry but they should be similar. \nresult_cons = result['Constituency'].to_list()\ncon_data_cons = con_data['PCON14NM'].to_list()\ncon_eth_cons = con_eth['ConstituencyName'].to_list()\n\n# I previously checked all but used enumerate to reduce print out \n\nfor index, (res, data, con) in enumerate(zip(result_cons, con_data_cons, con_eth_cons)):\n    if index % 20 == 0:\n        print(res, data, con)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build the Data Frame by adding the usefull date to results ","metadata":{}},{"cell_type":"code","source":"con_data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the following columns are the ones I am interestes in for this one\n\nsalary = con_data['salary'].to_list()\nnonukborn = con_data['nonukborn'].to_list()\ndegree = con_data['degree'].to_list()\n\nresult['Salary'] = salary\nresult['nonukborn'] = nonukborn\nresult['degree'] = degree\n\nresult.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_eth.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pop_white = con_eth['PopWhiteConst%'].to_numpy() \n\n\nresult['pop white'] = pop_white\n\n\n# result.set_index('Constituency', inplace = True)\n\nresult.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert Leave and Remain from object to float64","metadata":{}},{"cell_type":"code","source":"result.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_number(number):\n    value = number.split(\"%\")[0]\n    value = float(value)\n    return value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.Leave = result.Leave.apply(lambda x: get_number(x))\nresult.Remain = result.Remain.apply(lambda x: get_number(x))\nresult.nonukborn = pd.to_numeric(result[\"nonukborn\"], downcast=\"float\")\nresult.degree = pd.to_numeric(result[\"degree\"], downcast=\"float\")\n\nresult.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking at spread of Leave votes ","metadata":{}},{"cell_type":"code","source":"bins = [20, 25, 30, 35, 40, 45, 50, 55, 60, 70, 75, 80]\nplt.hist(result.Leave, bins = bins, color='#3452eb')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation of leave %vote to ethinicites and not born in the UK  ","metadata":{}},{"cell_type":"code","source":"ethnicity_columns = ['pop white', 'nonukborn'] \n\nfor column in ethnicity_columns:\n    cor_ethnicity_leave = result[['Leave', column]]\n    print(cor_ethnicity_leave.corr())\n    cor_ethnicity_leave.plot.scatter(x=column, y = 'Leave')\n    \n# 0.3 is cosidered the threshold for a corralation and this just about acheives it for non white. \n# The non UK born however is stronger. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['Salary', 'degree']\n\nfor column in columns:\n    corr_edu_salary_leave = result[['Leave', column]]\n    print(corr_edu_salary_leave.corr())\n    corr_edu_salary_leave.plot.scatter(x=column, y = 'Leave')\n\n# Here the corrlation is much stronger ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare  data for machine learning\n","metadata":{}},{"cell_type":"code","source":"# Create a copy of data set for ML model to Leave Win win\nremain_leave = result.copy()\n\n# Create a new column for remain win or leave win  \n\nremain_leave['result'] = remain_leave.Remain - remain_leave.Leave\n\ndef remain_or_leave(x):\n    if x >= 0:\n        return 'R'\n    else:\n        return 'L'\n\nremain_leave['result'] = remain_leave['result'].apply(lambda x: remain_or_leave(x))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check \nremain_leave.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"remain_leave.set_index('Constituency', inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_remain_leave = remain_leave.result\nX_remain_leave = remain_leave.drop(columns=['result', 'Leave', 'Remain'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preliminary Classification Model using Decsion Tree Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_remain_leave, y_remain_leave, train_size=0.8, test_size=0.2)\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n#Create a decision tree model\nclf=DecisionTreeClassifier(random_state=42)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_valid)\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_valid, y_pred))\n\nd = {'true': y_valid, 'preds': y_pred}\n\ndf = pd.DataFrame(data = d)\n\nprint(df.head(10))\n\nfrom sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(clf, X_valid, y_valid)\n\n# initial accuracy is promising - try to improve with optimisation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot the tree","metadata":{}},{"cell_type":"code","source":" from sklearn import tree\n\nplt = plt.figure(figsize=(10,10))\ntree.plot_tree(clf,\n         filled = True,\n         rounded= True,\n         class_names = ['L', 'R'],\n         feature_names = X_remain_leave.columns)\nplt.show()\n\n# tree is very large. with the optimisation mentioned earlier we will prune this using alpha","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prune the tree...\n\nAfter watching 'Decision Trees in Python from Start to Finish' by Josh Starmer (well worth a watch on youtube) I have broken this part down into a similar way as it shows how the pruning is done very well. ","metadata":{}},{"cell_type":"code","source":"# get a list of alphas\n\npath = clf.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas = path.ccp_alphas\nccp_alphas[:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run these alphas through the model to get their accuracies\n\npruned_clfs = []\n\nfor alpha in ccp_alphas:\n    clf_pruned=DecisionTreeClassifier(ccp_alpha = alpha, random_state=42)\n    clf_pruned.fit(X_train,y_train)\n    pruned_clfs.append(clf_pruned)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot this is a graph to show graphically how the alpha effects accuracy\n\ntrain_scores = [clf.score(X_train, y_train) for clf in pruned_clfs]\ntest_scores = [clf.score(X_valid, y_valid) for clf in pruned_clfs]\n\nimport matplotlib.pyplot as plt\n\n\nfig, ax = plt.subplots(1,1)\nax.set_xlabel('Alpha')\nax.set_ylabel('Acuracy')\nax.set_title('accuracy vs alphas for test and train data')\nax.plot(ccp_alphas, train_scores, marker='o', label = 'train', drawstyle = 'steps-post')\nax.plot(ccp_alphas, test_scores, marker ='o', label = 'test', drawstyle = 'steps-post')\nax.legend()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# is alpha of 0,020 sensitive to data?\nfrom sklearn.model_selection import cross_val_score\n\nopti_clf = DecisionTreeClassifier(ccp_alpha = 0.005)\nscores = cross_val_score(opti_clf, X_train, y_train, cv = 5)\n\ndf = pd.DataFrame(data = {'tree': range(5), 'accuracy': scores})\ndf.plot(x='tree', y='accuracy')\n\n# very much so, lets use cross validation to eliminate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Alpha is sensitive to data so need to cross validate ","metadata":{}},{"cell_type":"code","source":"looped_alpha_values = []\n\nfor alpha in ccp_alphas:\n    opti_clf=DecisionTreeClassifier(ccp_alpha = alpha)\n    scores = cross_val_score(opti_clf, X_train, y_train, cv = 10)\n    looped_alpha_values.append([alpha, np.mean(scores), np.std(scores)])\n\nalpha_results = pd.DataFrame(looped_alpha_values, columns = ['alpha', 'mean accuracy', 'std'] )\n\nalpha_results.plot(x='alpha',\n                  y='mean accuracy',\n                  yerr = 'std',\n                  marker = 'o',\n                  linestyle = '--')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From dataframe above find optimised alpha \n\n# Locate highest accuracy\nm1, m2 = alpha_results['mean accuracy'].nlargest(2).index\n\nalpha_one = alpha_results.iloc[m1,0]\nalpha_two = alpha_results.iloc[m2,0]\n\n# Optimised alpha is the mid point between those two alpha accuracies\nalpha_optimised = (alpha_one + alpha_two)/2\n\nprint(alpha_optimised)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we have the optimised alpha we can put into model ","metadata":{}},{"cell_type":"code","source":"# Create the model and then display the confusion matrix + accuracy\n\noptimised_tree = DecisionTreeClassifier(ccp_alpha = alpha_optimised)\n\noptimised_tree = optimised_tree.fit(X_train,y_train)\n\nplot_confusion_matrix(optimised_tree,\n                     X_valid,\n                     y_valid,\n                     labels = ['R', 'L'])\nprint('accuracy =', optimised_tree.score(X_valid, y_valid))\n\n# Model is much better at predicting leave constituancies than remain. This could be because more constituancies voted to leave so the model\n# has an inbuilt bias to leave","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the tree diagram. Not suprisingly degree is at the top. That had the strongest correlation in the initial analysis\n\nplt.figure(figsize=(15,7.5))\ntree.plot_tree(optimised_tree,\n         filled = True,\n         rounded= True,\n         class_names = ['L', 'R'],\n         feature_names = X_remain_leave.columns)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importance of each feature\n","metadata":{}},{"cell_type":"code","source":"# again this is displayed below. Salary was the least important\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(clf, random_state=1).fit(X_valid, y_valid)\n\neli5.show_weights(perm, feature_names = X_valid.columns.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If we look at the SHAP values we can see again degree has the biggest impact, Im not sure how to interpret the non white graph at the bottom \n\nfrom pdpbox import pdp, get_dataset, info_plots\nfeature_cols = X_train.columns.to_list()\n\nfor feature in feature_cols:\n    feature_to_plot = 'Distance Covered (Kms)'\n    pdp_dist = pdp.pdp_isolate(model=optimised_tree, dataset=X_valid, model_features=feature_cols, feature=feature)\n    pdp.pdp_plot(pdp_dist, feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}