{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install numpyro","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nimport pandas as pd\nimport numpy as onp\nimport matplotlib.pyplot as plt\n\nimport jax.numpy as np\nfrom jax import random\n\nimport numpyro\nimport numpyro.distributions as dist\nfrom numpyro.examples.datasets import COVTYPE, load_dataset\nfrom numpyro.infer import HMC, MCMC, NUTS\n\nfrom jax.random import PRNGKey\n\nnumpyro.set_platform(\"gpu\") #Use GPU for MCMC\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MCMC inference to adjust expected pass/run rate for coach and quarterback\n\nIt requires special libraries to do so because of data size."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pbp = None\nseasons = list(range(2009, 2020))\n\nfor season in seasons:\n    path = '/kaggle/input/nflsr-pbp/regular_season/reg_pbp_{}.csv'.format(season)\n    sea_pbp = pd.read_csv(path)\n    \n    if pbp is not None:\n        pbp = pd.concat([pbp,sea_pbp],axis=0)\n    else:\n        pbp = sea_pbp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some renames\npbp = pbp.rename(columns={'yardline_100':'yards_for_td','ydstogo':'distance'})\n\npbp['half'] = onp.where(pbp['game_seconds_remaining'] > 1800, 0, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for this analysis I'm going to omit 4th down. 4th down brings its own set of complications but could be analyzed in future work\n\npbp = pbp.loc[pbp.down.isin([1,2,3])]\n\n# only care about passes and runs\npbp.groupby(['play_type','down'])['distance'].count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# since a lot of no plays are runs with holding calls, or passes with interference, I want to keep as many as possible\n# the decision to run or pass was there despite the penalty \npbp = pbp.loc[pbp.play_type.isin(['pass','run','no_play'])]\n\n# clean no plays\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('sacked')), 'play_type'] = 'pass'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('complete')), 'play_type'] = 'pass'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('incomplete')), 'play_type'] = 'pass'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('pass')), 'play_type'] = 'pass'\n\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('up the middle')), 'play_type'] = 'run'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('right guard')), 'play_type'] = 'run'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('right tackle')), 'play_type'] = 'run'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('right end')), 'play_type'] = 'run'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('left guard')), 'play_type'] = 'run'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('left tackle')), 'play_type'] = 'run'\npbp.loc[(pbp.play_type=='no_play')&(pbp.desc.str.contains('left end')), 'play_type'] = 'run'\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verification that remaining \"no plays\" are pre-snap penalties\npbp.loc[pbp.play_type=='no_play'].desc.head(50).values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pbp = pbp.loc[pbp.play_type.isin(['pass','run'])]\nprint(\"There are {} plays in this dataset\".format(len(pbp)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add head coaches\n\ncoaches = None\nfor season in seasons:\n    path = '/kaggle/input/nflsr-pbp/coaches/{}_HC.csv'.format(season)\n    sea_coach = pd.read_csv(path)\n    sea_coach['Season']=season\n    if coaches is not None:\n        coaches = pd.concat([coaches,sea_coach],axis=0)\n    else:\n        coaches = sea_coach\n        \ncoaches.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some data cleaning\n# match up team ids\nprint(onp.sort(pbp.posteam.unique()))\n\n# lower counts means multiple ids\n# print(pbp.groupby(['posteam'])['epa'].count().reset_index().sort_values(by=['epa']))\n\nprint(onp.sort(coaches.Tm.unique()))\n\nnflR_to_nflR = {\n    'JAC':'JAX',\n    'SD':'LAC',\n    'STL':'LA',\n}\n\npbp['posteam'] = pbp['posteam'].copy().replace(nflR_to_nflR)\npbp['defteam'] = pbp['defteam'].copy().replace(nflR_to_nflR)\n\n\ncoach_to_nflR = {\n    'GNB':'GB',\n    'KAN':'KC',\n    'LAR':'LA',\n    'NOR':'NO',\n    'NWE':'NE',\n    'SDG':'LAC',\n    'SFO':'SF',\n    'STL':'LA',\n    'TAM':'TB'\n}\n\ncoaches['Tm'] = coaches['Tm'].copy().replace(coach_to_nflR)\n\nstill_diff = list(set(pbp.posteam.unique()) - set(coaches.Tm.unique()))\nprint(\"There are now {} teams with different abbreviations\".format(len(still_diff)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# goal is to add head coach column to nflscrapR data\n\n# i'll assemble a dataframe that has the following cols:\n# [season     week      team       coach]     \n\n# there is definitely a good way to do this with a dataframe pivot but i'll do the slower simple dumber way with 2 for loops\ncoach_df = []\ni = 0\nfor index, row in coaches.iterrows():\n    season = row['Season']\n    begin = row['Begin']\n    end = row['End'] + 1\n    coach = row['Coach']\n    team = row['Tm']\n    weeks = list(range(begin, end))\n    for week in weeks:\n        coach_df.append([season, week, team, coach])\n            \ncoach_df = pd.DataFrame(coach_df, columns=['season', 'week', 'posteam', 'head_coach'])\n\ncoach_df = coach_df.drop_duplicates()\ncoach_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load in week data separately & merge with pbp data\n\nwk_id = None\n\nfor season in seasons:\n    path = '/kaggle/input/nflsr-pbp/games_data/regular_season/reg_games_{}.csv'.format(season)\n    sea_wk = pd.read_csv(path)\n    \n    if wk_id is not None:\n        wk_id = pd.concat([wk_id,sea_wk],axis=0)\n    else:\n        wk_id = sea_wk\n        \nwk_id = wk_id[['game_id','season','week']]\npbp = pd.merge(pbp, wk_id, how='left', on=['game_id','game_id'])\n\npbp[['season','week','posteam']].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pbp = pbp.reset_index(drop=True)\npbp = pd.merge(pbp, coach_df, how='left', left_on=['season','week','posteam'], right_on=['season','week','posteam'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forward fill passer, so we know QB on run plays\n# not perfect but reasonable\n\npbp = pbp.sort_values(by=['posteam','season','week','game_seconds_remaining'], ascending=[True,True,True,False])\n\npbp.passer_player_name = pbp.passer_player_name.copy().fillna(method='ffill')\n\n# change secs remaining to mins, easier for interpretation\n#pbp.loc[:,'half_seconds_remaining'] = pbp['half_seconds_remaining'].copy() * 60\npbp = pbp.rename(columns={'half_seconds_remaining':'hsec'})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target from string to bool\npbp.loc[:,'play_type'] = pbp.play_type.copy().replace({\"run\":\"0\",\"pass\":\"1\"}).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['season','week','posteam','head_coach','passer_player_name','score_differential','down','distance','half','hsec','play_type']\n\npbp[cols].isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, I'm going to see if I can get a good result for the last 10,000 nfl plays by using teams as categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndata = pbp[cols]\n\ndata = data.sort_values(by=['season','week'],ascending=[False,False])\ndata = data[:10000]\n\n# shuffle data \ndata = data.sample(frac=1)\n\nle = LabelEncoder()\nle.fit(data.posteam)\n\ndata.loc[:,'i_team'] = le.transform(data.posteam.copy())\n\n# print(\"there are {} teams in the dataset\".format(data.i_team.max()+1))\n\n# data.groupby(['i_team'])['play_type'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# following https://www.kaggle.com/s903124/numpyro-speed-benchmark\n\n# numpyro.set_host_device_count(2)\n\nd = {\"passes\": np.array(data.play_type.values),\n     \"team\": np.array(data.i_team.values)}\n\ndef model(team, passes=None, link=False):\n    a_bar = numpyro.sample(\"a_bar\", dist.Normal(0, 10))\n    sigma_a = numpyro.sample(\"sigma_a\", dist.HalfCauchy(5))\n#     b_bar = numpyro.sample(\"b_bar\", dist.Normal(0, 10))\n#     sigma_b = numpyro.sample(\"sigma_b\", dist.HalfCauchy(5))\n\n#     intercept = numpyro.sample(\"intercept\",dist.Normal(0.3,1))#\n    a = numpyro.sample(\"a\", dist.Normal(a_bar, sigma_a), sample_shape=(len(data['i_team'].unique()),))\n#     b = numpyro.sample(\"b\", dist.Normal(b_bar, sigma_b), sample_shape=(len(d['batter_code'].unique()),))\n\n    # non-centered paramaterization\n#     a = numpyro.sample('a',  dist.TransformedDistribution(dist.Normal(0., 1.), dist.transforms.AffineTransform(a_bar, sigma_a)), sample_shape=(len(d['pitcher_code'].unique()),))\n#     b = numpyro.sample('b',  dist.TransformedDistribution(dist.Normal(0., 1.), dist.transforms.AffineTransform(b_bar, sigma_b)), sample_shape=(len(d['batter_code'].unique()),))\n\n    logit_p = a[team] + 0.39 # 0.39 is median \n    if link:\n        p = expit(logit_p)\n        numpyro.sample(\"p\", dist.Delta(p), obs=p)\n    numpyro.sample(\"pass_rate\", dist.Binomial(logits=logit_p), obs=passes)\n\nmcmc = MCMC(NUTS(model), 1000, 1000, num_chains=2)\nmcmc.run(PRNGKey(0), d['team'], passes=d['passes'], extra_fields=('potential_energy','mean_accept_prob',))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vars(mcmc)\nle.classes_\n\n# there is definitely a better way to do this\ni = 0\nfor team in le.classes_:\n    print(team, \"average\", np.mean(np.asarray(mcmc._states['z']['a'][:,:,i])), \"std\", np.std(np.asarray(mcmc._states['z']['a'][:,:,i])))\n    i+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mcmc.print_summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Situation-adjusted"},{"metadata":{"trusted":true},"cell_type":"code","source":"# d = {\"passes\": np.array(data.play_type.values),\n#      \"team\": np.array(data.i_team.values),\n#     \"score_diff\":np.array(data.score_differential.values)}\n\n# def model(team, score_diff, passes=None, link=False):\n#     a_bar = numpyro.sample(\"a_bar\", dist.Normal(0, 10))\n#     sigma_a = numpyro.sample(\"sigma_a\", dist.HalfCauchy(5))\n#     sd_bar = numpyro.sample(\"b_bar\", dist.Normal(0, 10))\n#     sigma_sd = numpyro.sample(\"sigma_b\", dist.HalfCauchy(5))\n\n# #     intercept = numpyro.sample(\"intercept\",dist.Normal(0.3,1))#\n#     a = numpyro.sample(\"a\", dist.Normal(a_bar, sigma_a), sample_shape=(len(data['i_team'].unique()),))\n#     sdiff_b = numpyro.sample(\"sdiff_b\", dist.Normal(sd_bar, sigma_sd))\n\n#     # non-centered paramaterization\n# #     a = numpyro.sample('a',  dist.TransformedDistribution(dist.Normal(0., 1.), dist.transforms.AffineTransform(a_bar, sigma_a)), sample_shape=(len(d['pitcher_code'].unique()),))\n# #     b = numpyro.sample('b',  dist.TransformedDistribution(dist.Normal(0., 1.), dist.transforms.AffineTransform(b_bar, sigma_b)), sample_shape=(len(d['batter_code'].unique()),))\n\n#     logit_p = + score_diff * sdiff_b + a[team] + 0.39 # 0.39 is median \n#     if link:\n#         p = expit(logit_p)\n#         numpyro.sample(\"p\", dist.Delta(p), obs=p)\n#     numpyro.sample(\"pass_rate\", dist.Binomial(logits=logit_p), obs=passes)\n\n# mcmc = MCMC(NUTS(model), 1000, 1000, num_chains=2)\n# mcmc.run(PRNGKey(0), d['team'], d['score_diff'], passes=d['passes'], extra_fields=('potential_energy','mean_accept_prob',))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# sum_df = []\n# # there is definitely a better way to do this\n# i = 0\n# for team in le.classes_:\n#     sum_df.append([team, np.round(np.mean(np.asarray(mcmc._states['z']['a'][:,:,i])),3), np.round(np.std(np.asarray(mcmc._states['z']['a'][:,:,i])),3)])\n#     i+=1\n    \n# sum_df = pd.DataFrame(sum_df, columns=['team','mean_effect','uncertainty'])\n\n# sum_df = sum_df.round(3).sort_values(by=['mean_effect'], ascending=False)\n\n# sum_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More situation adjusted (add down, distance, half, time_remain)\nAlso increase to 25K samples\n(Takes a long time, so commented out)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data = pbp[cols]\n\n# data = data.sort_values(by=['season','week'],ascending=[False,False])\n# data = data[:25000]\n\n# # shuffle data \n# data = data.sample(frac=1)\n\n# le = LabelEncoder()\n# le.fit(data.posteam)\n\n# data.loc[:,'i_team'] = le.transform(data.posteam.copy())\n\n# print(\"there are {} teams in the dataset\".format(data.i_team.max()+1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# season                    0\n# week                      0\n# posteam                   0\n# head_coach                0\n# passer_player_name        0\n# score_differential        0\n# down                      0\n# distance                  0\n# half                      0\n# half_seconds_remaining    0\n# play_type                 0\n\n# d = {\"passes\": np.array(data.play_type.values),\n#      \"team\": np.array(data.i_team.values),\n#     \"score_diff\":np.array(data.score_differential.values),\n#     \"down\":np.array(data.down.values),\n#     \"dist\":np.array(data.distance.values),\n#     \"half\":np.array(data.half.values),\n#     \"hsec\":np.array(data.hsec.values),}\n\n# def model(team, score_diff, down, ydstogo, half, hsec, passes=None, link=False):\n#     a_bar = numpyro.sample(\"a_bar\", dist.Normal(0, 10))\n#     sigma_a = numpyro.sample(\"sigma_a\", dist.HalfCauchy(5))\n    \n#     sd_bar = numpyro.sample(\"b_bar\", dist.Normal(0, 10))\n#     sigma_sd = numpyro.sample(\"sigma_b\", dist.HalfCauchy(5))\n#     down_bar = numpyro.sample(\"down_bar\", dist.Normal(0, 10))\n#     sigma_down = numpyro.sample(\"sigma_down\", dist.HalfCauchy(5))\n#     dist_bar = numpyro.sample(\"dist_bar\", dist.Normal(0, 10))\n#     sigma_dist = numpyro.sample(\"sigma_dist\", dist.HalfCauchy(5))\n#     half_bar = numpyro.sample(\"half_bar\", dist.Normal(0, 10))\n#     sigma_half = numpyro.sample(\"sigma_half\", dist.HalfCauchy(5))\n#     hsec_bar = numpyro.sample(\"hsec_bar\", dist.Normal(0, 10))\n#     sigma_hsec = numpyro.sample(\"sigma_hsec\", dist.HalfCauchy(5))\n\n# #     intercept = numpyro.sample(\"intercept\",dist.Normal(0.3,1))#\n#     a = numpyro.sample(\"a\", dist.Normal(a_bar, sigma_a), sample_shape=(len(data['i_team'].unique()),))\n    \n#     sdiff_b = numpyro.sample(\"sdiff_b\", dist.Normal(sd_bar, sigma_sd))\n#     down_b = numpyro.sample(\"down_b\", dist.Normal(down_bar, sigma_down))\n#     dist_b = numpyro.sample(\"dist_b\", dist.Normal(dist_bar, sigma_dist))\n#     half_b = numpyro.sample(\"half_b\", dist.Normal(half_bar, sigma_half))\n#     hsec_b = numpyro.sample(\"hsec_b\", dist.Normal(hsec_bar, sigma_hsec))\n    \n\n#     logit_p = + score_diff * sdiff_b + down * down_b + ydstogo * dist_b + half * half_b + hsec * hsec_b + a[team] + 2.73 # 2.73 is median \n#     if link:\n#         p = expit(logit_p)\n#         numpyro.sample(\"p\", dist.Delta(p), obs=p)\n#     numpyro.sample(\"pass_rate\", dist.Binomial(logits=logit_p), obs=passes)\n\n# mcmc = MCMC(NUTS(model), 1000, 1000, num_chains=2)\n# mcmc.run(PRNGKey(0), d['team'], d['score_diff'], d['down'], d['dist'], d['half'], d['hsec'], passes=d['passes'], extra_fields=('potential_energy','mean_accept_prob',))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mcmc.print_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# sum_df = []\n# i = 0\n# for team in le.classes_:\n#     sum_df.append([team, np.round(np.mean(np.asarray(mcmc._states['z']['a'][:,:,i])),3), np.round(np.std(np.asarray(mcmc._states['z']['a'][:,:,i])),3)])\n#     i+=1\n    \n# sum_df = pd.DataFrame(sum_df, columns=['team','mean_effect','uncertainty'])\n\n# sum_df = sum_df.round(3).sort_values(by=['mean_effect'], ascending=False)\n\n# sum_df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the Super Bowl I want an estimate of coaching confidence dependent on QB. I expect it to be high for Mahomes and low for Jimmy G"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pbp[cols]\n\n# only Andy Reid, Kyle Shanahan\n# sample = data.loc[data.head_coach.isin(['Andy Reid','Kyle Shanahan'])]\nandy = data.loc[data.head_coach.isin(['Andy Reid'])]\nandy = andy.sort_values(by=['season','week'],ascending=[False,False])\n# only need a sample of his plays\nandy = andy[:3700]\nkyle = data.loc[data.head_coach.isin(['Kyle Shanahan'])]\nsample = pd.concat([andy,kyle],axis=0)\n\n# also want a league average control\ncontrol = data.loc[~data.head_coach.isin(['Andy Reid','Kyle Shanahan'])]\n\n# while I could separate out head coach and quarterback, for small number of categories I'll just use one indicators\n\n# A.Reid + P.Mahomes: 0\n# A.Reid - P.Mahomes: 1\n# KS + JG: 2\n# KS - JG: 3\n# League Avg Control: 4\n\ncontrol = control.sample(frac=1)\ncontrol = control[:int((len(sample)/2))] # reasonably balanced \n\ndata = pd.concat([control,sample], axis=0)\n\ndel sample\ndel control\ndel andy\ndel kyle\nimport gc\ngc.collect()\n\ndata['cat_effect'] = np.nan\ndata.loc[(data.head_coach=='Andy Reid')&(data.passer_player_name=='P.Mahomes'), 'cat_effect'] = 0\ndata.loc[(data.head_coach=='Andy Reid')&(data.passer_player_name!='P.Mahomes'), 'cat_effect'] = 1\ndata.loc[(data.head_coach=='Kyle Shanahan')&(data.passer_player_name=='J.Garoppolo'), 'cat_effect'] = 2\ndata.loc[(data.head_coach=='Kyle Shanahan')&(data.passer_player_name!='J.Garoppolo'), 'cat_effect'] = 3\ndata.loc[~data.head_coach.isin(['Andy Reid','Kyle Shanahan']), 'cat_effect'] = 4\n\nprint(data.groupby(['cat_effect'])['play_type'].count())\nprint(len(data))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.sample(frac=1)\n\nd = {\"passes\": np.array(data.play_type.values),\n     \"cat\": np.array(data.cat_effect.astype(int).values),\n    \"score_diff\":np.array(data.score_differential.values),\n    \"down\":np.array(data.down.values),\n    \"dist\":np.array(data.distance.values),\n    \"half\":np.array(data.half.values),\n    \"hsec\":np.array(data.hsec.values),}\n\ndef model(team, score_diff, down, ydstogo, half, hsec, passes=None, link=False):\n    # only works for cpu\n    #numpyro.set_host_device_count(4)\n    \n    cat_bar = numpyro.sample(\"cat_bar\", dist.Normal(0, 10))\n    sigma_cat = numpyro.sample(\"sigma_cat\", dist.HalfCauchy(5))\n\n\n    intercept = numpyro.sample(\"intercept\",dist.Normal(0,10))\n    cats = numpyro.sample(\"cats\", dist.Normal(cat_bar, sigma_cat), sample_shape=(len(data['cat_effect'].unique()),))\n    \n    sdiff_b = numpyro.sample(\"sdiff_b\", dist.Normal(-0.05, 1))\n    down_b = numpyro.sample(\"down_b\", dist.Normal(0.5, 1))\n    dist_b = numpyro.sample(\"dist_b\", dist.Normal(0, 1))\n    half_b = numpyro.sample(\"half_b\", dist.Normal(0, 1))\n    hsec_b = numpyro.sample(\"hsec_b\", dist.Normal(0, 0.01))\n    \n\n    logit_p = + score_diff * sdiff_b + down * down_b + ydstogo * dist_b + half * half_b + hsec * hsec_b + cats[team]\n    if link:\n        p = expit(logit_p)\n        numpyro.sample(\"p\", dist.Delta(p), obs=p)\n    numpyro.sample(\"pass_rate\", dist.Binomial(logits=logit_p), obs=passes)\n\nmcmc = MCMC(NUTS(model), 2000, 1000, num_chains=4)\nmcmc.run(PRNGKey(0), d['cat'], d['score_diff'], d['down'], d['dist'], d['half'], d['hsec'], passes=d['passes'], extra_fields=('potential_energy','mean_accept_prob',))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mcmc.print_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mcmc._states['z']['cats'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# different score differentials\nx = np.linspace(-28, 28, 100)\n\ndown = 1\nydstogo = 10\nhalf = 1\nhsec_remain = 0\n\ndown_b = np.mean(np.asarray(mcmc._states['z']['down_b']))\ndist_b = np.mean(np.asarray(mcmc._states['z']['dist_b']))\nhalf_b = np.mean(np.asarray(mcmc._states['z']['half_b']))\nhsec_b = np.mean(np.asarray(mcmc._states['z']['hsec_b']))\nsdiff_b = np.mean(np.asarray(mcmc._states['z']['sdiff_b']))\n\nbase = down * down_b + ydstogo * dist_b + half * half_b + hsec_remain * hsec_b + sdiff_b*x\n\npat = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,0]))\npat_error = 0.11\nhigh_pat = base + pat_error + pat\npat_y = base + pat\nlow_pat = base - pat_error + pat\n\nnpat = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,1]))\nnpat_error = 0.11\nhigh_npat = base + npat_error + npat\nnpat_y = base + npat\nlow_npat = base - npat_error + npat\n\n# inverse logit\nhigh_pat = 1 / (1 + np.exp(-(high_pat)))\npat_y = 1 / (1 + np.exp(-(pat_y)))\nlow_pat = 1 / (1 + np.exp(-(low_pat)))\n\nhigh_npat = 1 / (1 + np.exp(-(high_npat)))\nnpat_y = 1 / (1 + np.exp(-(npat_y)))\nlow_npat = 1 / (1 + np.exp(-(low_npat)))\n\nfig = plt.figure(figsize=(12,6))\n\nplt.plot(x, pat_y, color='maroon', label='Andy Reid with Patrick Mahomes')\nplt.fill_between(x, high_pat, low_pat,alpha=0.5, edgecolor='maroon', facecolor='red')\n\nplt.plot(x, npat_y, color='darkgreen', label='Andy Reid before Patrick Mahomes')\nplt.fill_between(x, high_npat, low_npat,alpha=0.5, edgecolor='darkgreen', facecolor='g')\n\nla = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,3]))\nla_y = base + la\nla_y = 1 / (1 + np.exp(-(la_y)))\nplt.plot(x, la_y, color='black', label='League Average')\n\nplt.legend()\nplt.suptitle(\"Does Andy Reid Pass More With Mahomes?\", fontsize=18)\nplt.title(\"1st and 10, 1st Play of Second Half\")\nplt.xlabel(\"Score Differential\")\nplt.ylabel(\"Probability of Pass\")\n\nplt.savefig('./ReidWMahomes1st&10.png')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"down = 3\nydstogo = 15\nhalf = 2\nhsec_remain = 5*60\n\nbase = down * down_b + ydstogo * dist_b + half * half_b + hsec_remain * hsec_b + sdiff_b*x\n\nhigh_pat = base + pat_error + pat\npat_y = base + pat\nlow_pat = base - pat_error + pat\n\nhigh_npat = base + npat_error + npat\nnpat_y = base + npat\nlow_npat = base - npat_error + npat\n\n# inverse logit\nhigh_pat = 1 / (1 + np.exp(-(high_pat)))\npat_y = 1 / (1 + np.exp(-(pat_y)))\nlow_pat = 1 / (1 + np.exp(-(low_pat)))\n\nhigh_npat = 1 / (1 + np.exp(-(high_npat)))\nnpat_y = 1 / (1 + np.exp(-(npat_y)))\nlow_npat = 1 / (1 + np.exp(-(low_npat)))\n\nfig = plt.figure(figsize=(12,6))\n\nplt.plot(x, pat_y, color='maroon', label='Andy Reid with Patrick Mahomes')\nplt.fill_between(x, high_pat, low_pat,alpha=0.5, edgecolor='maroon', facecolor='red')\n\nplt.plot(x, npat_y, color='darkgreen', label='Andy Reid before Patrick Mahomes')\nplt.fill_between(x, high_npat, low_npat,alpha=0.5, edgecolor='darkgreen', facecolor='g')\n\nla = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,3]))\nla_y = base + la\nla_y = 1 / (1 + np.exp(-(la_y)))\nplt.plot(x, la_y, color='black', label='League Average')\n\nplt.legend()\nplt.suptitle(\"Does Andy Reid Pass More With Mahomes?\", fontsize=18)\nplt.title(\"3rd and 15, 2nd Half, 5 Min Remaining\")\nplt.xlabel(\"Score Differential\")\nplt.ylabel(\"Probability of Pass\")\n\nplt.savefig('./ReidWMahomesLate.png')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# different score differentials\nx = np.linspace(-28, 28, 100)\n\ndown = 1\nydstogo = 10\nhalf = 1\nhsec_remain = 0\n\nbase = down * down_b + ydstogo * dist_b + half * half_b + hsec_remain * hsec_b + sdiff_b*x\n\njg = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,2]))\njg_error = 0.12\nhigh_jg = base + jg_error + jg\njg_y = base + jg\nlow_jg = base - jg_error + jg\n\nnjg = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,3]))\nnjg_error = 0.12\nhigh_njg = base + njg_error + njg\nnjg_y = base + njg\nlow_njg = base - njg_error + njg\n\n# inverse logit\nhigh_jg = 1 / (1 + np.exp(-(high_jg)))\njg_y = 1 / (1 + np.exp(-(jg_y)))\nlow_jg = 1 / (1 + np.exp(-(low_jg)))\n\nhigh_njg = 1 / (1 + np.exp(-(high_njg)))\nnjg_y = 1 / (1 + np.exp(-(njg_y)))\nlow_njg = 1 / (1 + np.exp(-(low_njg)))\n\nfig = plt.figure(figsize=(12,6))\n\nplt.plot(x, jg_y, color='maroon', label='Kyle Shanahan with Jimmy Garoppalo')\nplt.fill_between(x, high_jg, low_jg,alpha=0.5, edgecolor='tomato', facecolor='maroon')\n\nplt.plot(x, njg_y, color='goldenrod', label='Kyle Shanahan without Jimmy Garoppalo')\nplt.fill_between(x, high_njg, low_njg,alpha=0.5, edgecolor='brown', facecolor='goldenrod')\n\n# league average\n# la = np.mean(np.asarray(mcmc._states['z']['cats'][:,:,3]))\n# la_y = base + la\n# la_y = 1 / (1 + np.exp(-(la_y)))\n# plt.plot(x, la_y, color='black', label='League Average')\n\nplt.legend()\nplt.suptitle(\"Does Kyle Shanahan Pass More With Jimmy G?\", fontsize=18)\nplt.title(\"1st and 10, 1st Play of Second Half\")\nplt.xlabel(\"Score Differential\")\nplt.ylabel(\"Probability of Pass\")\n\nplt.savefig('./KyleWJG.png')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_df = []\ni = 0\nfor cat in ['Andy & Pat','Andy W/O Pat','Kyle & Jimmy','Kyle W/O Jimmy','League Avg']:\n    sum_df.append([cat, np.mean(np.asarray(mcmc._states['z']['cats'][:,:,i])), np.std(np.asarray(mcmc._states['z']['cats'][:,:,i]))])\n    i+=1\n    \nsum_df = pd.DataFrame(sum_df, columns=['team','mean_effect','uncertainty'])\n\nsum_df = sum_df.round(8).sort_values(by=['mean_effect'], ascending=False)\n\nsum_df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# data = pbp[cols]\n\n# # only Andy Reid, Kyle Shanahan\n# # sample = data.loc[data.head_coach.isin(['Andy Reid','Kyle Shanahan'])]\n# andy = data.loc[data.head_coach.isin(['Andy Reid'])]\n# andy = andy.sort_values(by=['season','week'],ascending=[False,False])\n# # only need a sample of his plays\n# andy = andy[:3700]\n# kyle = data.loc[data.head_coach.isin(['Kyle Shanahan'])]\n# sample = pd.concat([andy,kyle],axis=0)\n\n# # also want a league average control\n# control = data.loc[~data.head_coach.isin(['Andy Reid','Kyle Shanahan'])]\n\n# # while I could separate out head coach and quarterback, for small number of categories I'll just use one indicators\n\n# # A.Reid + P.Mahomes: 0\n# # A.Reid - P.Mahomes: 1\n# # KS + JG: 2\n# # KS - JG: 3\n# # League Avg Control: 4\n\n# control = control.sample(frac=1)\n# control = control[:int((len(sample)/2))] # reasonably balanced \n\n# data = pd.concat([control,sample], axis=0)\n\n# del sample\n# del control\n# del andy\n# del kyle\n# import gc\n# gc.collect()\n\n# data['cat_effect'] = np.nan\n# data.loc[(data.head_coach=='Andy Reid')&(data.passer_player_name=='P.Mahomes'), 'cat_effect'] = 0\n# data.loc[(data.head_coach=='Andy Reid')&(data.passer_player_name!='P.Mahomes'), 'cat_effect'] = 1\n# data.loc[(data.head_coach=='Kyle Shanahan')&(data.passer_player_name=='J.Garoppolo'), 'cat_effect'] = 2\n# data.loc[(data.head_coach=='Kyle Shanahan')&(data.passer_player_name!='J.Garoppolo'), 'cat_effect'] = 3\n# data.loc[~data.head_coach.isin(['Andy Reid','Kyle Shanahan']), 'cat_effect'] = 4\n\n# print(data.groupby(['cat_effect'])['play_type'].count())\n# print(len(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}