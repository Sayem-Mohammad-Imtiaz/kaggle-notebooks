{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"LpCN9VqO6i0m","outputId":"16c78292-ef72-41bb-91d1-3c98c3958932","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"-En1BYW06i0s","trusted":true},"cell_type":"code","source":"#import necessary libraries\nimport numpy as np\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets,transforms,models\nimport torch.nn.functional as F\nfrom torch import nn,optim\n\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.optim import lr_scheduler\n\nimport torchvision\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"id":"xE_KnADF6i0v","trusted":true},"cell_type":"code","source":"train_dir='/kaggle/input/sign-language-mnist/sign_mnist_train.csv'\ntest_dir='/kaggle/input/sign-language-mnist/sign_mnist_test.csv'\n\ntrain=pd.read_csv(train_dir)\ntest=pd.read_csv(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"id":"yeRLiDUv6i0y","outputId":"c0983a50-6be8-4dc3-99c1-751d09e6e2ce","trusted":true},"cell_type":"code","source":"#check train data\ntrain.head(10) ","execution_count":null,"outputs":[]},{"metadata":{"id":"VZH3EnkX6i03","outputId":"310e3edb-49b6-4808-e9de-3984c09e93dc","trusted":true},"cell_type":"code","source":"#check test data\ntest.head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"x_-LTv-e6i06","outputId":"0bac282c-50f2-48cf-9331-82a159074ccb","trusted":true},"cell_type":"code","source":"#Number of classes we have \n\nprint(train['label'].unique())\n\nprint(\"Number of classes : \",len(train['label'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"id":"mD-qAwph6i08","outputId":"e2683a74-04a2-4cf0-9817-75d948561ee3","trusted":true},"cell_type":"code","source":"#obtain all rows and all columns except the 0 index column\n\ntrain_data = train.iloc[:, 1:].values\nprint(\"Number of train images:\", train_data.shape[0])\ntrain_labels=train.loc[:, 'label']\nprint(\"Number of pixels in each image:\", train_data.shape[1])\n\ntest_data = test.iloc[:, 1:].values\nprint(\"Number of test images:\", test_data.shape[0])\ntest_labels=test.loc[:, 'label']\nprint(\"Number of pixels in each image:\", test_data.shape[1])\n\n\n\nnew_train_labels=np.where(train_labels>8, train_labels-1, train_labels)\nnew_test_labels=np.where(test_labels>8, test_labels-1, test_labels)\n\n\n\nunique_val = np.array(new_test_labels)\n#np.append (unique_val, 9)\nprint(np.unique(unique_val))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Bun_bAy66i0_","outputId":"30488c46-cb75-45cc-88e3-67641f54977a","trusted":true},"cell_type":"code","source":"train_data.shape , new_train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"nsm8WSz56i1D","outputId":"d45af2bd-0381-4aa0-e5fd-06837a31faa3","trusted":true},"cell_type":"code","source":"from PIL import Image \n\nImage.open(\"/kaggle/input/sign-language-mnist/amer_sign2.png\")","execution_count":null,"outputs":[]},{"metadata":{"id":"-R6eO3O86i1G","trusted":true},"cell_type":"code","source":"letters={0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'k',10:'L',11:'M',12:'N',13:'O',14:'P',15:'Q',16:'R',17:'S',18:'T',19:'U',20:'V',21:'W',22:'X',23:'Y'}","execution_count":null,"outputs":[]},{"metadata":{"id":"VWaV_BnQ6i1J","outputId":"c00c1586-ed4d-4406-8d77-62152c0d4e05","trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(24,8))\n\nfor i in range(27):\n  \n  plt.subplot(3,9,i+1)\n  plt.imshow(train_data[i].reshape(28,28))\n  plt.axis('off')\n  plt.title(letters[int((new_train_labels[i]))])","execution_count":null,"outputs":[]},{"metadata":{"id":"XS-3IDbH6i1M","outputId":"6de859ca-44b8-46d9-d073-368b1100b9bc","trusted":true},"cell_type":"code","source":"\nplt.figure(figsize = (30,10))\nsns.countplot(new_train_labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"_t3NG8HZ6i1P","trusted":true},"cell_type":"code","source":"\n#Data Augmentation\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(25),\n        \n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], \n                            [0.5])\n]),\n    \n    'valid': transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], \n                             [0.5])\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{"id":"bvKjmxqf6i1S","trusted":true},"cell_type":"code","source":"class DtProcessing(Dataset):\n    \n    #initialise the class variables - transform, data, target\n    def __init__(self, data, target, transform=None): \n        self.transform = transform\n        self.data = data.reshape((-1,28,28)).astype(np.float32)[:,:,:,None]\n        # converting target to torch.LongTensor dtype\n        self.target = torch.from_numpy(target).long() \n    \n    #retrieve the X and y index value and return it\n    def __getitem__(self, index): \n        return self.transform(self.data[index]), self.target[index]\n    \n    #returns the length of the data\n    def __len__(self): \n        return len(list(self.data))\n      \n","execution_count":null,"outputs":[]},{"metadata":{"id":"-xtXH_a46i1V","trusted":true},"cell_type":"code","source":"#divide train set into train and validation set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(train_data, new_train_labels, test_size = .2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"id":"_PsjD8NN6i1Y","trusted":true},"cell_type":"code","source":"      \ndset_train = DtProcessing(X_train, y_train, transform=data_transforms['train'])\n\ntrain_loader = torch.utils.data.DataLoader(dset_train, batch_size=20,\n                                          shuffle=True, num_workers=0)\n\ndset_valid = DtProcessing(X_valid, y_valid, transform=data_transforms['valid'])\n\nvalid_loader = torch.utils.data.DataLoader(dset_valid, batch_size=20,\n                                          shuffle=True, num_workers=0)\n\n\ndset_test = DtProcessing(test_data, new_test_labels, transform=data_transforms['valid'])\n\ntest_loader =torch.utils.data.DataLoader(dset_test, batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"7CT-Vzmg6i1c","trusted":true},"cell_type":"code","source":"\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n  \n  def __init__(self):\n    \n    super(Net,self).__init__()\n    \n    #input depth , output depth , kernel size(filter)x\n    \n    self.conv1=nn.Conv2d(1,32,kernel_size=(3, 3),padding=(1, 1),stride=(1, 1))\n    \n    self.conv2=nn.Conv2d(32,32,kernel_size=(3, 3),padding=(1, 1),stride=(1, 1))\n    \n    self.conv3=nn.Conv2d(32,64,kernel_size=(3, 3),padding=(1, 1),stride=(1, 1))\n    \n    #padding for last conv layer \n    self.adapt = nn.AdaptiveMaxPool2d((3,3))  \n    \n    #padding layer\n    self.pool=nn.MaxPool2d(2,2)\n    \n    #dropout layer\n    self.drop=nn.Dropout(p=0.2)\n    \n    #fc layers \n    self.fc1=nn.Linear(64*3*3,240)\n    \n   \n    self.fc2=nn.Linear(240,24)\n    \n    self.softmax = nn.LogSoftmax(dim=1)\n    \n  def forward(self,x):\n    \n    x=self.pool(F.leaky_relu(self.conv1(x)))\n    \n    x=self.pool(F.leaky_relu(self.conv2(x)))\n    \n    x=self.adapt(F.leaky_relu(self.conv3(x)))\n    \n    \n    #flatten Images\n    x = x.view(x.size(0), -1)\n    \n    x=self.drop(x)\n    \n    x=F.leaky_relu(self.fc1(x))\n    \n    \n    x=self.drop(x)\n    \n    x=self.fc2(x)\n    \n    return self.softmax(x)","execution_count":null,"outputs":[]},{"metadata":{"id":"kfPBrIee6i1g","trusted":true},"cell_type":"code","source":"\nmodel = Net()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\nif torch.cuda.is_available():\n  \n    model = model.cuda()\n    criterion = criterion.cuda()","execution_count":null,"outputs":[]},{"metadata":{"id":"tbCstCPq6i1i","trusted":true},"cell_type":"code","source":"from torch.autograd import Variable\n\n\n\ndef train(n_epochs=100):\n  \n  Training_loss=[]\n  Validation_loss=[]\n  \n  valid_loss_min = np.Inf # track change in validation loss\n\n  for epoch in range(1, n_epochs+1):\n    \n    \n\n        # keep track of training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        #train\n        model.train()\n    \n    \n        for data, target in train_loader:\n                 \n         \n        \n            if torch.cuda.is_available():\n                   data, target = data.cuda(), target.cuda()\n            \n        # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(Variable(data))\n        \n        #print(target.shape)\n        # calculate the batch loss\n            loss = criterion(output, Variable(target))\n        # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n        # perform a single optimization step (parameter update)\n            optimizer.step()\n        # update training loss\n            train_loss += loss.item()*data.size(0)\n    #validate\n        model.eval()\n        accuracy=0.0\n        with torch.no_grad():\n          for data, target in valid_loader:\n      \n                 data, target = Variable(data), Variable(target)\n        \n        #data, target = Variable(data), Variable(target)\n                 if torch.cuda.is_available():\n                         data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n                 output = model(data)\n        \n        # calculate the batch loss\n                 loss = criterion(output, target)\n        # update average validation loss \n                 valid_loss += loss.item()*data.size(0)\n        \n        \n        \n    \n    # calculate average losses\n        train_loss = train_loss/len(train_loader.dataset)\n        valid_loss = valid_loss/len(valid_loader.dataset)\n        \n        Training_loss.append(train_loss/len(train_loader))\n        Validation_loss.append(valid_loss/len(valid_loader))\n        \n        # print training/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t '.format(\n        epoch, train_loss, valid_loss))\n    \n    \n    \n    \n    \n    # save model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n                  print(\"==============================================================================================\")\n                  print('Validation loss decreased ({:.6f} --> {:.6f}).  >>>>>>>  Saving model ...'.format(\n                   valid_loss_min,\n                     valid_loss)) \n                  print(\"==============================================================================================\")\n                  torch.save(model.state_dict(), 'SignModel1.pt')\n                  valid_loss_min = valid_loss\n  plt.figure(figsize = (25,10))                \n  plt.plot(Training_loss, label='Training loss')\n  plt.plot(Validation_loss, label='Validation loss')\n  plt.legend(frameon=False)      \n        ","execution_count":null,"outputs":[]},{"metadata":{"id":"zlvPcboT6i1l","outputId":"02697ba2-b166-4a36-e1fa-a6c1e201896a","trusted":true},"cell_type":"code","source":"train(80)","execution_count":null,"outputs":[]},{"metadata":{"id":"uThd29AD6i1p","trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('SignModel1.pt'))\n\nclasses=['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']","execution_count":null,"outputs":[]},{"metadata":{"id":"GRoW1YXZ6i1r","trusted":true},"cell_type":"code","source":"def Cal_accurac():\n  test_loss = 0.0\n  class_correct = list(0. for i in range(24))\n  class_total = list(0. for i in range(24))\n\n  model.eval()\n# iterate over test data\n  for data, target in test_loader:\n    \n    batch_size = data.size(0)\n    #print(batch_size)\n    # move tensors to GPU if CUDA is available\n    if torch.cuda.is_available():\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    \n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\n  test_loss = test_loss/len(test_loader)\n  print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n  for i in range(24):\n    if class_total[i] > 0 :\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\n  print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"id":"zVqa7ezQ6i1v","outputId":"b1b457c9-e980-4f16-8709-dba09f69c046","trusted":true},"cell_type":"code","source":"Cal_accurac()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}