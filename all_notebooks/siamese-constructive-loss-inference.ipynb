{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n#from google.colab.patches import cv2_imshow\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\nimport numpy as np\nimport cv2\n\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,Input,Lambda\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow_datasets as tfds\nfrom functools import partial\nfrom albumentations import (\n    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,Normalize,RandomBrightnessContrast,\n    VerticalFlip,\n    Rotate\n)\nimport pandas as pd\n#from google.colab.patches import cv2_imshow\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\nimport numpy as np\nimport cv2\n\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,Input,Lambda\n\n#from albumentations import *\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"id":"99dLJGwSVUkE","execution":{"iopub.status.busy":"2021-06-10T00:47:41.587446Z","iopub.execute_input":"2021-06-10T00:47:41.587797Z","iopub.status.idle":"2021-06-10T00:47:48.027058Z","shell.execute_reply.started":"2021-06-10T00:47:41.587765Z","shell.execute_reply":"2021-06-10T00:47:48.026035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pictureCsv = pd.read_csv(\"../input/mnist-zeroshot-learning/trainPictureArray.csv\")\nsigmoidTrain = pd.read_csv(\"../input/mnist-zeroshot-learning/pictureIndexData.csv\")","metadata":{"id":"y5hEGgMBvdiP","execution":{"iopub.status.busy":"2021-06-10T00:47:48.031667Z","iopub.execute_input":"2021-06-10T00:47:48.033736Z","iopub.status.idle":"2021-06-10T00:47:53.415857Z","shell.execute_reply.started":"2021-06-10T00:47:48.033694Z","shell.execute_reply":"2021-06-10T00:47:53.415023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/trainvalsplit/trainSplit.csv\")\nvalidation = pd.read_csv(\"../input/trainvalsplit/validationSplit.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:53.417626Z","iopub.execute_input":"2021-06-10T00:47:53.417981Z","iopub.status.idle":"2021-06-10T00:47:53.464642Z","shell.execute_reply.started":"2021-06-10T00:47:53.417944Z","shell.execute_reply":"2021-06-10T00:47:53.463888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pictureCsvNoLabel = pictureCsv.iloc[:,:-1]\npictureCsvNoLabel = tf.convert_to_tensor(pictureCsvNoLabel.to_numpy())","metadata":{"id":"Q2To4a4K-gc9","execution":{"iopub.status.busy":"2021-06-10T00:47:53.46773Z","iopub.execute_input":"2021-06-10T00:47:53.46799Z","iopub.status.idle":"2021-06-10T00:47:58.544381Z","shell.execute_reply.started":"2021-06-10T00:47:53.467966Z","shell.execute_reply":"2021-06-10T00:47:58.543506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"firstPictureIndex = train[\"firstPictureIndex\"].values\nsecondPictureIndex = train[\"secondPictureIndex\"].values\n\nfirstPictureIndexValidation = validation[\"firstPictureIndex\"].values\nsecondPictureIndexValidation = validation[\"secondPictureIndex\"].values","metadata":{"id":"rP4lFqKtv3fC","execution":{"iopub.status.busy":"2021-06-10T00:47:58.545766Z","iopub.execute_input":"2021-06-10T00:47:58.546126Z","iopub.status.idle":"2021-06-10T00:47:58.554526Z","shell.execute_reply.started":"2021-06-10T00:47:58.546089Z","shell.execute_reply":"2021-06-10T00:47:58.55357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = pictureCsv.iloc[0][:-1].to_numpy()\nimageV2 = np.stack([image,image,image])","metadata":{"id":"XNb3rqhc69yA","execution":{"iopub.status.busy":"2021-06-10T00:47:58.556055Z","iopub.execute_input":"2021-06-10T00:47:58.556388Z","iopub.status.idle":"2021-06-10T00:47:58.571893Z","shell.execute_reply.started":"2021-06-10T00:47:58.556353Z","shell.execute_reply":"2021-06-10T00:47:58.571187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pictureCsv","metadata":{"id":"dbm4rOZb9DFW","outputId":"fee6b069-fc87-4436-d66a-0875437fc7b2","execution":{"iopub.status.busy":"2021-06-10T00:47:58.573165Z","iopub.execute_input":"2021-06-10T00:47:58.573532Z","iopub.status.idle":"2021-06-10T00:47:58.622368Z","shell.execute_reply.started":"2021-06-10T00:47:58.573494Z","shell.execute_reply":"2021-06-10T00:47:58.621356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixels = image.reshape((28, 28))\n\n        # Plot\nplt.title('Label is {label}'.format(label=2))\nplt.imshow(pixels, cmap='gray')\nplt.show()","metadata":{"id":"AQggZCB49GOe","outputId":"83211b00-f034-436b-c7bb-bee6d16e15f5","execution":{"iopub.status.busy":"2021-06-10T00:47:58.625222Z","iopub.execute_input":"2021-06-10T00:47:58.625613Z","iopub.status.idle":"2021-06-10T00:47:58.803919Z","shell.execute_reply.started":"2021-06-10T00:47:58.625573Z","shell.execute_reply":"2021-06-10T00:47:58.802945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = Compose([\n            HorizontalFlip(),\n            VerticalFlip(),\n            #Normalize(),\n            #RandomBrightnessContrast(),\n           Normalize()\n        ])","metadata":{"id":"GRmt2gDjWArE","execution":{"iopub.status.busy":"2021-06-10T00:47:58.809169Z","iopub.execute_input":"2021-06-10T00:47:58.811694Z","iopub.status.idle":"2021-06-10T00:47:58.81863Z","shell.execute_reply.started":"2021-06-10T00:47:58.811643Z","shell.execute_reply":"2021-06-10T00:47:58.817347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(index,process_type = \"train\",target_shape = (224,224)):\n    \"\"\"\n    Load the specified file as a JPEG image, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n    image = tf.reshape(pictureCsvNoLabel[index],(28,28))\n    image = tf.stack([image, image, image],axis=2)\n    #image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.reshape(image,(28,28,3))*255\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, target_shape)\n    \n    if process_type == \"train\":\n        image = process_Augment_data(image,img_size = target_shape[0])\n        \n    return image\n\ndef aug_fn(image, img_size):\n    data = {\"image\":image}\n    aug_data = transforms(image=image)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n    return aug_img\n\ndef process_Augment_data(image, img_size):\n    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float64)\n    return aug_img\n\ndef preprocess_siamese(positive, negative):\n    \"\"\"\n    Given the filenames corresponding to the three images, load and\n    preprocess them.\n    \"\"\"\n\n    return (\n        preprocess_image(positive),\n        preprocess_image(negative),\n    )","metadata":{"id":"tQ9wA4GqIIpH","execution":{"iopub.status.busy":"2021-06-10T00:47:58.819946Z","iopub.execute_input":"2021-06-10T00:47:58.820515Z","iopub.status.idle":"2021-06-10T00:47:58.843733Z","shell.execute_reply.started":"2021-06-10T00:47:58.820474Z","shell.execute_reply":"2021-06-10T00:47:58.840398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imageFinalize = preprocess_image(0)","metadata":{"id":"H1Kk__cv-l1L","outputId":"91250bd6-6556-41a2-9a1f-4c48d0e3721c","execution":{"iopub.status.busy":"2021-06-10T00:47:58.849768Z","iopub.execute_input":"2021-06-10T00:47:58.851959Z","iopub.status.idle":"2021-06-10T00:47:59.300847Z","shell.execute_reply.started":"2021-06-10T00:47:58.85191Z","shell.execute_reply":"2021-06-10T00:47:59.300024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = pictureCsv.iloc[0][:-1].to_numpy().reshape((28,28))\nimageV2 = np.stack([image,image,image],axis=2)\n#imageV2 = imageV2.reshape((28,28,3))\n#imageV2 = np.swapaxes(imageV2,0,2)\nresized = cv2.resize(imageV2, (224,224), interpolation = cv2.INTER_AREA)\nresized = resized*255","metadata":{"id":"XSXt-gfY7x3C","execution":{"iopub.status.busy":"2021-06-10T00:47:59.303968Z","iopub.execute_input":"2021-06-10T00:47:59.304239Z","iopub.status.idle":"2021-06-10T00:47:59.319252Z","shell.execute_reply.started":"2021-06-10T00:47:59.304214Z","shell.execute_reply":"2021-06-10T00:47:59.318386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.320463Z","iopub.execute_input":"2021-06-10T00:47:59.320803Z","iopub.status.idle":"2021-06-10T00:47:59.326417Z","shell.execute_reply.started":"2021-06-10T00:47:59.320768Z","shell.execute_reply":"2021-06-10T00:47:59.325589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1):  \n  plt.subplot(330 + 1 + i)\n  plt.imshow(imageV2 , cmap=plt.get_cmap('gray'))\n  plt.show()","metadata":{"id":"tkkpypbs7Xcg","outputId":"b2dcbe97-602d-4033-f90a-b3adbb4bb89c","execution":{"iopub.status.busy":"2021-06-10T00:47:59.327911Z","iopub.execute_input":"2021-06-10T00:47:59.328189Z","iopub.status.idle":"2021-06-10T00:47:59.425847Z","shell.execute_reply.started":"2021-06-10T00:47:59.328166Z","shell.execute_reply":"2021-06-10T00:47:59.425073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Add Data Augmentation","metadata":{}},{"cell_type":"code","source":"transforms = Compose([\n            HorizontalFlip(),\n            VerticalFlip(),\n           Normalize()\n        ])\n\nval_transforms = Compose([\n           Normalize()\n        ])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.428611Z","iopub.execute_input":"2021-06-10T00:47:59.428903Z","iopub.status.idle":"2021-06-10T00:47:59.432658Z","shell.execute_reply.started":"2021-06-10T00:47:59.428877Z","shell.execute_reply":"2021-06-10T00:47:59.431744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(index,process_type = \"train\",target_shape = (224,224)):\n    \"\"\"\n    Load the specified file as a JPEG image, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n    image = tf.reshape(pictureCsvNoLabel[index],(28,28))\n    image = tf.stack([image, image, image],axis=2)\n    #image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.reshape(image,(28,28,3))*255\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, target_shape)\n    \n    if process_type == \"train\":\n        image = process_Augment_data(image,img_size = target_shape[0])\n    elif process_type == \"validation\":\n        image = process_Augment_data_validation(image,img_size = target_shape[0])\n    return image\n\ndef preprocess_image_test(index,process_type = \"train\",target_shape = (224,224)):\n    \"\"\"\n    Load the specified file as a JPEG image, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n    image = tf.reshape(testTensor[index],(28,28))\n    image = tf.stack([image, image, image],axis=2)\n    #image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.reshape(image,(28,28,3))*255\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, target_shape)\n    \n    if process_type == \"train\":\n        image = process_Augment_data(image,img_size = target_shape[0])\n    elif process_type == \"validation\":\n        image = process_Augment_data_validation(image,img_size = target_shape[0])\n    return image\n\ndef aug_fn(image, img_size):\n    data = {\"image\":image}\n    aug_data = transforms(image=image)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n    return aug_img\n\ndef aug_fn_test(image, img_size):\n    data = {\"image\":image}\n    aug_data = val_transforms(image=image)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n    return aug_img\n\ndef process_Augment_data(image, img_size):\n    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n    return aug_img\n\ndef process_Augment_data_validation(image, img_size):\n    aug_img = tf.numpy_function(func=aug_fn_test, inp=[image, img_size], Tout=tf.float32)\n    return aug_img\n\ndef preprocess_siamese(positive, negative,mode=\"train\"):\n    \"\"\"\n    Given the filenames corresponding to the three images, load and\n    preprocess them.\n    \"\"\"\n\n    return (\n        preprocess_image(positive,mode),\n        preprocess_image(negative,mode),\n    )","metadata":{"id":"AULtmTCMwHn1","execution":{"iopub.status.busy":"2021-06-10T00:47:59.434132Z","iopub.execute_input":"2021-06-10T00:47:59.434652Z","iopub.status.idle":"2021-06-10T00:47:59.451848Z","shell.execute_reply.started":"2021-06-10T00:47:59.434615Z","shell.execute_reply":"2021-06-10T00:47:59.451015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessEmbeddingTest(positive,mode=\"validation\"):\n    \"\"\"\n    Given the filenames corresponding to the three images, load and\n    preprocess them.\n    \"\"\"\n\n    return (\n        preprocess_image_test(positive,mode)\n    )","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.454685Z","iopub.execute_input":"2021-06-10T00:47:59.454986Z","iopub.status.idle":"2021-06-10T00:47:59.462932Z","shell.execute_reply.started":"2021-06-10T00:47:59.454961Z","shell.execute_reply":"2021-06-10T00:47:59.462065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def contrastive_loss(y, preds, margin=1):\n\t# explicitly cast the true class label data type to the predicted\n\t# class label data type (otherwise we run the risk of having two\n\t# separate data types, causing TensorFlow to error out)\n\ty = tf.cast(y, preds.dtype)\n\t# calculate the contrastive loss between the true labels and\n\t# the predicted labels\n\tsquaredPreds = K.square(preds)\n\tsquaredMargin = K.square(K.maximum(margin - preds, 0))\n\tloss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n\t# return the computed contrastive loss to the calling function\n\treturn loss","metadata":{"id":"E3AV_jyuxNSn","execution":{"iopub.status.busy":"2021-06-10T00:47:59.464301Z","iopub.execute_input":"2021-06-10T00:47:59.46472Z","iopub.status.idle":"2021-06-10T00:47:59.473098Z","shell.execute_reply.started":"2021-06-10T00:47:59.464681Z","shell.execute_reply":"2021-06-10T00:47:59.472202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sigmoidTrain[\"symmetrylabel\"].values","metadata":{"id":"5ffu7mVJGnq1","outputId":"1de54536-cabe-4534-b557-826a37c51dac","execution":{"iopub.status.busy":"2021-06-10T00:47:59.474358Z","iopub.execute_input":"2021-06-10T00:47:59.474722Z","iopub.status.idle":"2021-06-10T00:47:59.484966Z","shell.execute_reply.started":"2021-06-10T00:47:59.474669Z","shell.execute_reply":"2021-06-10T00:47:59.483971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(listFirstPictureIndex,listSecondPictureIndex,batchsize,labels,useType=\"train\"):\n    FirstIndex = listFirstPictureIndex\n    SecondIndex = listSecondPictureIndex\n    dataset1 = tf.data.Dataset.from_tensor_slices(FirstIndex)\n    dataset2 = tf.data.Dataset.from_tensor_slices(SecondIndex)\n    labelDatasets = tf.data.Dataset.from_tensor_slices(labels)\n    \n    dataset = tf.data.Dataset.zip((dataset1, dataset2))\n    dataset = dataset.map(lambda x,y:preprocess_siamese(x,y,useType))\n    \n    dataset = tf.data.Dataset.zip((dataset,labelDatasets))\n    dataset = dataset.batch(batchsize, drop_remainder=False).prefetch(8)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.486378Z","iopub.execute_input":"2021-06-10T00:47:59.486751Z","iopub.status.idle":"2021-06-10T00:47:59.493783Z","shell.execute_reply.started":"2021-06-10T00:47:59.486712Z","shell.execute_reply":"2021-06-10T00:47:59.492971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_datasetTest(pictureEmbeddingIndex,batchsize,useType=\"validation\"):\n    FirstIndex = pictureEmbeddingIndex\n    dataset = tf.data.Dataset.from_tensor_slices(FirstIndex)\n    \n    dataset = dataset.map(lambda x:preprocessEmbeddingTest(x))\n    \n    dataset = dataset.batch(batchsize, drop_remainder=False).prefetch(8)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.495163Z","iopub.execute_input":"2021-06-10T00:47:59.49575Z","iopub.status.idle":"2021-06-10T00:47:59.502962Z","shell.execute_reply.started":"2021-06-10T00:47:59.49571Z","shell.execute_reply":"2021-06-10T00:47:59.502099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"symmetrylabel\"].values","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.50512Z","iopub.execute_input":"2021-06-10T00:47:59.505399Z","iopub.status.idle":"2021-06-10T00:47:59.520805Z","shell.execute_reply.started":"2021-06-10T00:47:59.505373Z","shell.execute_reply":"2021-06-10T00:47:59.519973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = create_dataset(firstPictureIndex,secondPictureIndex,64,train[\"symmetrylabel\"].values,\"train\")\nval_ds = create_dataset(firstPictureIndexValidation,secondPictureIndexValidation,64,validation[\"symmetrylabel\"].values,\"validation\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:47:59.527728Z","iopub.execute_input":"2021-06-10T00:47:59.528022Z","iopub.status.idle":"2021-06-10T00:47:59.8646Z","shell.execute_reply.started":"2021-06-10T00:47:59.527996Z","shell.execute_reply":"2021-06-10T00:47:59.863773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"positive_images = firstPictureIndex \nnegative_images = secondPictureIndex\n\nimage_count = len(positive_images )\n\npositive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)\nnegative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\nlabel_dataset = tf.data.Dataset.from_tensor_slices(sigmoidTrain[\"symmetrylabel\"].values)\n# To generate the list of negative images, let's randomize the list of\n# available images and concatenate them together.\n\n#negative_images = triplettrain[\"Negative\"].values\n#np.random.RandomState(seed=32).shuffle(negative_images)\n\n#negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n#negative_dataset = negative_dataset.shuffle(buffer_size=4096)\n\ndataset = tf.data.Dataset.zip((positive_dataset, negative_dataset))\n#dataset = dataset.shuffle(buffer_size=1024)\ndataset = dataset.map(preprocess_siamese)\n\ndataset = tf.data.Dataset.zip((dataset,label_dataset))\ndataset = dataset.shuffle(buffer_size=1024)\n\n# Let's now split our dataset in train and validation.\ntrain_dataset = dataset.take(round(image_count * 0.8))\nval_dataset = dataset.skip(round(image_count * 0.8))\n\ntrain_dataset = train_dataset.batch(32, drop_remainder=False)\ntrain_dataset = train_dataset.prefetch(8)\n\nval_dataset = val_dataset.batch(32, drop_remainder=False)\nval_dataset = val_dataset.prefetch(8)\"\"\"","metadata":{"id":"yBU3kmd7-Bce","execution":{"iopub.status.busy":"2021-06-10T00:47:59.867591Z","iopub.execute_input":"2021-06-10T00:47:59.867956Z","iopub.status.idle":"2021-06-10T00:47:59.874863Z","shell.execute_reply.started":"2021-06-10T00:47:59.867919Z","shell.execute_reply":"2021-06-10T00:47:59.873779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in train_ds.take(3):\n  break","metadata":{"id":"M3AE4VB4a46U","outputId":"ee84da72-ea79-4f87-f1cc-5d813aa620d7","execution":{"iopub.status.busy":"2021-06-10T00:47:59.876597Z","iopub.execute_input":"2021-06-10T00:47:59.876975Z","iopub.status.idle":"2021-06-10T00:48:01.224372Z","shell.execute_reply.started":"2021-06-10T00:47:59.876937Z","shell.execute_reply":"2021-06-10T00:48:01.22352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for data in val_ds.take(3):\n  break","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:01.227857Z","iopub.execute_input":"2021-06-10T00:48:01.228113Z","iopub.status.idle":"2021-06-10T00:48:02.441603Z","shell.execute_reply.started":"2021-06-10T00:48:01.228087Z","shell.execute_reply":"2021-06-10T00:48:02.440769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def euclidean_distance(vectors):\n\t# unpack the vectors into separate lists\n\t(featsA, featsB) = vectors\n\t# compute the sum of squared distances between the vectors\n\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n\t# return the euclidean distance between the vectors\n\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))","metadata":{"id":"9qPnG9oC25s-","execution":{"iopub.status.busy":"2021-06-10T00:48:02.443023Z","iopub.execute_input":"2021-06-10T00:48:02.443367Z","iopub.status.idle":"2021-06-10T00:48:02.450625Z","shell.execute_reply.started":"2021-06-10T00:48:02.443331Z","shell.execute_reply":"2021-06-10T00:48:02.449798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input1 = tf.keras.Input(shape=(224,224,3))\ninput2 = tf.keras.Input(shape=(224,224,3))\neffinetB0 = EfficientNetB0(include_top=False,weights=\"imagenet\")(input1)\neffinetB0_siamese = EfficientNetB0(include_top=False,weights=\"imagenet\")(input2)\npooling1= tf.keras.layers.GlobalAveragePooling2D()(effinetB0)\npooling2 = tf.keras.layers.GlobalAveragePooling2D()(effinetB0_siamese)\ndistance = Lambda(euclidean_distance)([pooling1, pooling2])\n\nfirstEffinet = tf.keras.Model(\n    inputs=input1, outputs=pooling1,name = \"effinetB0\"\n)\n\ntwinEffinet = tf.keras.Model(\n    inputs = input2,outputs= pooling2,name=\"effinetB0_siamese\"\n)\n\ninputA = tf.keras.Input(shape=(224,224,3))\ninputB = tf.keras.Input(shape=(224,224,3))\n\nfeatureFirst = firstEffinet(inputA)\nfeatureSecond = twinEffinet(inputB)\n\ndistance = Lambda(euclidean_distance)([featureFirst , featureSecond ])\nsiamese_network = Model(inputs=[inputA,inputB], outputs=distance)","metadata":{"id":"piKvWUJ8wehM","outputId":"b4684f85-c209-40a5-8f8a-1778c01d77dc","execution":{"iopub.status.busy":"2021-06-10T00:48:02.452122Z","iopub.execute_input":"2021-06-10T00:48:02.452466Z","iopub.status.idle":"2021-06-10T00:48:08.156348Z","shell.execute_reply.started":"2021-06-10T00:48:02.452432Z","shell.execute_reply":"2021-06-10T00:48:08.155312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_network.get_weights()[-1].mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:08.157603Z","iopub.execute_input":"2021-06-10T00:48:08.157952Z","iopub.status.idle":"2021-06-10T00:48:08.313706Z","shell.execute_reply.started":"2021-06-10T00:48:08.157914Z","shell.execute_reply":"2021-06-10T00:48:08.312939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_network.load_weights(\"../input/k/polapob/siamese-constructive-loss/siamesemodel05-validationloss0.03.h5\")\nsiamese_network.get_weights()[-1].mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:08.314962Z","iopub.execute_input":"2021-06-10T00:48:08.315296Z","iopub.status.idle":"2021-06-10T00:48:09.485608Z","shell.execute_reply.started":"2021-06-10T00:48:08.31526Z","shell.execute_reply":"2021-06-10T00:48:09.484823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"firstEffinet.get_weights()[-1].mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:09.486926Z","iopub.execute_input":"2021-06-10T00:48:09.487261Z","iopub.status.idle":"2021-06-10T00:48:09.568555Z","shell.execute_reply.started":"2021-06-10T00:48:09.487225Z","shell.execute_reply":"2021-06-10T00:48:09.567749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_network.load_weights(\"../input/k/polapob/siamese-constructive-loss/siamesemodel07-validationloss0.02.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:09.569702Z","iopub.execute_input":"2021-06-10T00:48:09.570043Z","iopub.status.idle":"2021-06-10T00:48:10.559762Z","shell.execute_reply.started":"2021-06-10T00:48:09.570015Z","shell.execute_reply":"2021-06-10T00:48:10.558871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"firstEffinet.get_weights()[-1].mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:10.56136Z","iopub.execute_input":"2021-06-10T00:48:10.561706Z","iopub.status.idle":"2021-06-10T00:48:10.646643Z","shell.execute_reply.started":"2021-06-10T00:48:10.561668Z","shell.execute_reply":"2021-06-10T00:48:10.645747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:10.647883Z","iopub.execute_input":"2021-06-10T00:48:10.648268Z","iopub.status.idle":"2021-06-10T00:48:10.653323Z","shell.execute_reply.started":"2021-06-10T00:48:10.648236Z","shell.execute_reply":"2021-06-10T00:48:10.651419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testData = pd.read_csv(\"../input/mnist-zeroshot-learning/testMnist.csv\")\ntestPictureIndex = testData.index.values","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:10.654887Z","iopub.execute_input":"2021-06-10T00:48:10.655248Z","iopub.status.idle":"2021-06-10T00:48:15.788826Z","shell.execute_reply.started":"2021-06-10T00:48:10.655212Z","shell.execute_reply":"2021-06-10T00:48:15.787923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testTensor = tf.convert_to_tensor(testData.iloc[:,1:-1].to_numpy())\ntestTensor","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:15.790154Z","iopub.execute_input":"2021-06-10T00:48:15.790481Z","iopub.status.idle":"2021-06-10T00:48:16.123643Z","shell.execute_reply.started":"2021-06-10T00:48:15.790446Z","shell.execute_reply":"2021-06-10T00:48:16.122589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"trainPrediction = []\nfor data in tqdm(create_datasetTest(firstPictureIndex,256)):\n    trainPrediction.append(firstEffinet.predict(data))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:16.125086Z","iopub.execute_input":"2021-06-10T00:48:16.125454Z","iopub.status.idle":"2021-06-10T00:48:16.130522Z","shell.execute_reply.started":"2021-06-10T00:48:16.125415Z","shell.execute_reply":"2021-06-10T00:48:16.129578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testPrediction = []\nfor data in tqdm(create_datasetTest(testPictureIndex,256)):\n    testPrediction.append(firstEffinet.predict(data))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:48:16.131729Z","iopub.execute_input":"2021-06-10T00:48:16.132256Z","iopub.status.idle":"2021-06-10T00:50:31.058003Z","shell.execute_reply.started":"2021-06-10T00:48:16.132215Z","shell.execute_reply":"2021-06-10T00:50:31.057124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testPredictionEmbedding = [eachPrediction for preds in testPrediction for eachPrediction in preds]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:50:31.059658Z","iopub.execute_input":"2021-06-10T00:50:31.060043Z","iopub.status.idle":"2021-06-10T00:50:31.076229Z","shell.execute_reply.started":"2021-06-10T00:50:31.060003Z","shell.execute_reply":"2021-06-10T00:50:31.075185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myTestEmbedding = pd.DataFrame(testPredictionEmbedding,columns=[f\"Embedding{i}\" for i in range(1280)])\nmyTestEmbedding[\"label\"] = testData[\"label\"]\nmyTestEmbedding.to_csv(\"myTestEmbedding.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:50:31.07768Z","iopub.execute_input":"2021-06-10T00:50:31.078055Z","iopub.status.idle":"2021-06-10T00:52:33.306912Z","shell.execute_reply.started":"2021-06-10T00:50:31.078018Z","shell.execute_reply":"2021-06-10T00:52:33.305999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize data","metadata":{}},{"cell_type":"code","source":"!pip install swat","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:52:33.308462Z","iopub.execute_input":"2021-06-10T00:52:33.308797Z","iopub.status.idle":"2021-06-10T00:52:43.479916Z","shell.execute_reply.started":"2021-06-10T00:52:33.30876Z","shell.execute_reply":"2021-06-10T00:52:43.478961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import swat\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom timeit import timeit","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:52:43.483292Z","iopub.execute_input":"2021-06-10T00:52:43.483558Z","iopub.status.idle":"2021-06-10T00:52:43.613421Z","shell.execute_reply.started":"2021-06-10T00:52:43.483529Z","shell.execute_reply":"2021-06-10T00:52:43.612602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport time\nimport numpy as np\nimport pandas as pd\n#from sklearn.datasets import fetch_mldata\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:52:43.614704Z","iopub.execute_input":"2021-06-10T00:52:43.615044Z","iopub.status.idle":"2021-06-10T00:52:43.642268Z","shell.execute_reply.started":"2021-06-10T00:52:43.61501Z","shell.execute_reply":"2021-06-10T00:52:43.641549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def VisualizePCA(csvFile,n_embedding = 256):\n  speechRepresentation2 = pd.read_csv(csvFile)\n  data_subset = speechRepresentation2.iloc[:,:n_embedding].to_numpy()\n  pca = PCA(n_components=3)\n  pca_result = pca.fit_transform(data_subset)\n  df_subset2 = pd.DataFrame()\n  df_subset2['pca-one'] = pca_result[:,0]\n  df_subset2['pca-two'] = pca_result[:,1] \n  df_subset2['pca-three'] = pca_result[:,2]\n  print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n  df_subset2[\"label\"] = speechRepresentation2[\"label\"]\n\n  ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n  ax.scatter(\n    xs=df_subset2[\"pca-one\"], \n    ys=df_subset2[\"pca-two\"], \n    zs=df_subset2[\"pca-three\"], \n    c=df_subset2[\"label\"], \n    cmap='tab10'\n)\n  ax.set_xlabel('pca-one')\n  ax.set_ylabel('pca-two')\n  ax.set_zlabel('pca-three')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:52:43.643453Z","iopub.execute_input":"2021-06-10T00:52:43.643787Z","iopub.status.idle":"2021-06-10T00:52:43.65185Z","shell.execute_reply.started":"2021-06-10T00:52:43.643752Z","shell.execute_reply":"2021-06-10T00:52:43.650635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nX, y = load_digits().data, load_digits().target\nfrom cuml.manifold import TSNE\nspeechRepresentation2 = pd.read_csv(\"./myTestEmbedding.csv\")\ndata_subset = speechRepresentation2.iloc[:,:1280].to_numpy()\n\ny = speechRepresentation2[\"label\"].values\ntsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\ntsne_results = tsne.fit_transform(data_subset)\n\n# To plot the embedding\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.scatter(tsne_results[:,0], tsne_results[:,1], c = y, s = 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:52:43.653381Z","iopub.execute_input":"2021-06-10T00:52:43.653746Z","iopub.status.idle":"2021-06-10T00:53:03.993733Z","shell.execute_reply.started":"2021-06-10T00:52:43.653708Z","shell.execute_reply":"2021-06-10T00:53:03.992897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\ncdict = {5: 'red', 6: 'blue', 7: 'green',8:\"lightblue\",9:\"orange\"}\nfig, ax = plt.subplots()\ngroup = y \nscatter_x = tsne_results[:,0]\nscatter_y = tsne_results[:,1]\n\nfor g in np.unique(group):\n    ix = np.where(group == g)\n    ax.scatter(scatter_x[ix], scatter_y[ix], c = cdict[g], label = g, s = 0.5)\nax.legend()\nplt.show()\n#plt.scatter(tsne_results[:,0], tsne_results[:,1], c = y, s = 0.5)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:03.994938Z","iopub.execute_input":"2021-06-10T00:53:03.995266Z","iopub.status.idle":"2021-06-10T00:53:04.466312Z","shell.execute_reply.started":"2021-06-10T00:53:03.99523Z","shell.execute_reply":"2021-06-10T00:53:04.465344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testDataV2 = pd.DataFrame({\"embedding1\":scatter_x,\"embedding2\":scatter_y,\"label\":y})","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:04.467775Z","iopub.execute_input":"2021-06-10T00:53:04.468141Z","iopub.status.idle":"2021-06-10T00:53:04.473535Z","shell.execute_reply.started":"2021-06-10T00:53:04.468103Z","shell.execute_reply":"2021-06-10T00:53:04.47273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testDataV2.to_csv(\"./myTestEmbedding2.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:04.474847Z","iopub.execute_input":"2021-06-10T00:53:04.475389Z","iopub.status.idle":"2021-06-10T00:53:04.645603Z","shell.execute_reply.started":"2021-06-10T00:53:04.475352Z","shell.execute_reply":"2021-06-10T00:53:04.644752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def VisualizeTSNE(csvFile,n_embedding = 256):\n  speechRepresentation2 = pd.read_csv(csvFile)\n  data_subset = speechRepresentation2.iloc[:,:n_embedding].to_numpy()\n    \n  tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n  tsne_results = tsne.fit_transform(data_subset)\n  print(\"Waiting F***ing long time.\")\n  y = speechRepresentation2[\"label\"].values\n\n  plt.scatter(tsne_results[:,0], tsne_results[:,1], c = y, s = 0.5)\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:04.646898Z","iopub.execute_input":"2021-06-10T00:53:04.647227Z","iopub.status.idle":"2021-06-10T00:53:04.655404Z","shell.execute_reply.started":"2021-06-10T00:53:04.647193Z","shell.execute_reply":"2021-06-10T00:53:04.652672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VisualizeTSNE(\"./myTestEmbedding.csv\",n_embedding = 1280)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:04.657231Z","iopub.execute_input":"2021-06-10T00:53:04.657704Z","iopub.status.idle":"2021-06-10T00:53:28.718858Z","shell.execute_reply.started":"2021-06-10T00:53:04.657666Z","shell.execute_reply":"2021-06-10T00:53:28.716995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VisualizePCA(\"./myTestEmbedding.csv\",n_embedding = 1280)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:28.721276Z","iopub.execute_input":"2021-06-10T00:53:28.72167Z","iopub.status.idle":"2021-06-10T00:53:45.775764Z","shell.execute_reply.started":"2021-06-10T00:53:28.721632Z","shell.execute_reply":"2021-06-10T00:53:45.774938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testData[\"label\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:45.780027Z","iopub.execute_input":"2021-06-10T00:53:45.782222Z","iopub.status.idle":"2021-06-10T00:53:45.793204Z","shell.execute_reply.started":"2021-06-10T00:53:45.782182Z","shell.execute_reply":"2021-06-10T00:53:45.792336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils.vis_utils import plot_model\n\nplot_model(siamese_network, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:53:45.797542Z","iopub.execute_input":"2021-06-10T00:53:45.799732Z","iopub.status.idle":"2021-06-10T00:53:46.496418Z","shell.execute_reply.started":"2021-06-10T00:53:45.799682Z","shell.execute_reply":"2021-06-10T00:53:46.495279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featureFirst = firstEffinet(inputA)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:05.080455Z","iopub.execute_input":"2021-06-10T00:54:05.080779Z","iopub.status.idle":"2021-06-10T00:54:05.664897Z","shell.execute_reply.started":"2021-06-10T00:54:05.08075Z","shell.execute_reply":"2021-06-10T00:54:05.664038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = Model()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:05.666446Z","iopub.execute_input":"2021-06-10T00:54:05.666793Z","iopub.status.idle":"2021-06-10T00:54:05.675578Z","shell.execute_reply.started":"2021-06-10T00:54:05.666753Z","shell.execute_reply":"2021-06-10T00:54:05.674798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputA = tf.keras.Input(shape=(224,224,3))\nfeatureFirst = firstEffinet(inputA)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:05.6772Z","iopub.execute_input":"2021-06-10T00:54:05.67767Z","iopub.status.idle":"2021-06-10T00:54:06.587772Z","shell.execute_reply.started":"2021-06-10T00:54:05.677523Z","shell.execute_reply":"2021-06-10T00:54:06.586931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def contrastive_loss(y, preds, margin=1):\n\t# explicitly cast the true class label data type to the predicted\n\t# class label data type (otherwise we run the risk of having two\n\t# separate data types, causing TensorFlow to error out)\n\ty = tf.cast(y, preds.dtype)\n\t# calculate the contrastive loss between the true labels and\n\t# the predicted labels\n\tsquaredPreds = K.square(preds)\n\tsquaredMargin = K.square(K.maximum(margin - preds, 0))\n\tloss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n\t# return the computed contrastive loss to the calling function\n\treturn loss","metadata":{"id":"Dc8lMAwj6gW4","execution":{"iopub.status.busy":"2021-06-10T00:54:07.492263Z","iopub.execute_input":"2021-06-10T00:54:07.492598Z","iopub.status.idle":"2021-06-10T00:54:07.498036Z","shell.execute_reply.started":"2021-06-10T00:54:07.492566Z","shell.execute_reply":"2021-06-10T00:54:07.497047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_network.summary()","metadata":{"id":"E1BE4ISHx7JX","outputId":"e17adf87-2f47-440e-ecc3-892c45228fd6","execution":{"iopub.status.busy":"2021-06-10T00:54:08.477356Z","iopub.execute_input":"2021-06-10T00:54:08.47768Z","iopub.status.idle":"2021-06-10T00:54:08.513839Z","shell.execute_reply.started":"2021-06-10T00:54:08.477651Z","shell.execute_reply":"2021-06-10T00:54:08.513017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_siamese_test(positive, negative,mode=\"validation\"):\n    \"\"\"\n    Given the filenames corresponding to the three images, load and\n    preprocess them.\n    \"\"\"\n\n    return (\n        preprocess_image_test(positive,mode),\n        preprocess_image_test(negative,mode),\n    )","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:09.40202Z","iopub.execute_input":"2021-06-10T00:54:09.402341Z","iopub.status.idle":"2021-06-10T00:54:09.406432Z","shell.execute_reply.started":"2021-06-10T00:54:09.402312Z","shell.execute_reply":"2021-06-10T00:54:09.405605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset_Similarity(listFirstPictureIndex,listSecondPictureIndex,batchsize,labels,useType=\"train\"):\n    FirstIndex = listFirstPictureIndex\n    SecondIndex = listSecondPictureIndex\n    dataset1 = tf.data.Dataset.from_tensor_slices(FirstIndex)\n    dataset2 = tf.data.Dataset.from_tensor_slices(SecondIndex)\n    labelDatasets = tf.data.Dataset.from_tensor_slices(labels)\n    \n    dataset = tf.data.Dataset.zip((dataset1, dataset2))\n    dataset = dataset.map(lambda x,y:preprocess_siamese_test(x,y,useType))\n    \n    dataset = tf.data.Dataset.zip((dataset,labelDatasets))\n    dataset = dataset.batch(batchsize, drop_remainder=False).prefetch(8)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:10.431145Z","iopub.execute_input":"2021-06-10T00:54:10.431471Z","iopub.status.idle":"2021-06-10T00:54:10.437865Z","shell.execute_reply.started":"2021-06-10T00:54:10.431441Z","shell.execute_reply":"2021-06-10T00:54:10.436877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity = pd.read_csv(\"../input/testpredictionmnistdata/TestPredictionData.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:10.663918Z","iopub.execute_input":"2021-06-10T00:54:10.664242Z","iopub.status.idle":"2021-06-10T00:54:10.776106Z","shell.execute_reply.started":"2021-06-10T00:54:10.664212Z","shell.execute_reply":"2021-06-10T00:54:10.775076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity.drop_duplicates(inplace=True)\ntestSimilarity.reset_index(drop=True,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:11.763182Z","iopub.execute_input":"2021-06-10T00:54:11.763585Z","iopub.status.idle":"2021-06-10T00:54:11.791381Z","shell.execute_reply.started":"2021-06-10T00:54:11.763531Z","shell.execute_reply":"2021-06-10T00:54:11.790568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:12.99731Z","iopub.execute_input":"2021-06-10T00:54:12.997735Z","iopub.status.idle":"2021-06-10T00:54:13.012549Z","shell.execute_reply.started":"2021-06-10T00:54:12.997691Z","shell.execute_reply":"2021-06-10T00:54:13.011554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdsv2 = create_dataset_Similarity(testSimilarity[\"ImageA\"],testSimilarity[\"ImageB\"],64,testSimilarity[\"label\"].values,\"validation\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:13.418115Z","iopub.execute_input":"2021-06-10T00:54:13.418435Z","iopub.status.idle":"2021-06-10T00:54:13.541341Z","shell.execute_reply.started":"2021-06-10T00:54:13.418406Z","shell.execute_reply":"2021-06-10T00:54:13.540309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = []\nfor data,label in tqdm(testdsv2):\n    prediction.append(siamese_network.predict(data))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T00:54:13.620288Z","iopub.execute_input":"2021-06-10T00:54:13.620577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarityPred = [eachvalue for listValue in prediction for eachvalue in listValue]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity[\"distance\"]=[j for i in similarityPred for j in i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity[\"predLabel\"] = testSimilarity[\"distance\"].apply(lambda x:0 if x > 1 else 1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity[testSimilarity[\"predLabel\"]==testSimilarity[\"label\"]].label.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = (testSimilarity[\"predLabel\"] == testSimilarity[\"label\"]).sum()/testSimilarity.shape[0] * 100\nprint(accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(index,process_type = \"train\",target_shape = (224,224)):\n    \"\"\"\n    Load the specified file as a JPEG image, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n    image = tf.reshape(pictureCsvNoLabel[index],(28,28))\n    image = tf.stack([image, image, image],axis=2)\n    #image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.reshape(image,(28,28,3))*255\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, target_shape)\n    \n    if process_type == \"train\":\n        image = process_Augment_data(image,img_size = target_shape[0])\n    elif process_type == \"validation\":\n        image = process_Augment_data_validation(image,img_size = target_shape[0])\n    return image\n\ndef preprocess_image_test(index,process_type = \"train\",target_shape = (224,224)):\n    \"\"\"\n    Load the specified file as a JPEG image, preprocess it and\n    resize it to the target shape.\n    \"\"\"\n    image = tf.reshape(testTensor[index],(28,28))\n    image = tf.stack([image, image, image],axis=2)\n    #image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.reshape(image,(28,28,3))*255\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, target_shape)\n    \n    if process_type == \"train\":\n        image = process_Augment_data(image,img_size = target_shape[0])\n    elif process_type == \"validation\":\n        image = process_Augment_data_validation(image,img_size = target_shape[0])\n    return image\n\ndef aug_fn(image, img_size):\n    data = {\"image\":image}\n    aug_data = transforms(image=image)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n    return aug_img\n\ndef aug_fn_test(image, img_size):\n    data = {\"image\":image}\n    aug_data = val_transforms(image=image)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n    return aug_img\n\ndef process_Augment_data(image, img_size):\n    aug_img = tf.numpy_function(func=aug_fn, inp=[image, img_size], Tout=tf.float32)\n    return aug_img\n\ndef process_Augment_data_validation(image, img_size):\n    aug_img = tf.numpy_function(func=aug_fn_test, inp=[image, img_size], Tout=tf.float32)\n    return aug_img\n\ndef preprocess_siamese(positive, negative,mode=\"train\"):\n    \"\"\"\n    Given the filenames corresponding to the three images, load and\n    preprocess them.\n    \"\"\"\n\n    return (\n        preprocess_image(positive,mode),\n        preprocess_image(negative,mode),\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity = pd.read_csv(\"../input/mnist-zeroshot-learning/testMnist.csv\")\ntestSimilarity ","metadata":{"id":"ZnIOPkEjGNy_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = []\ntestSimilarity.index.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = testSimilarity \nallTrainIndex = testSimilarity.index.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newDataSample = [20000,20000,20000,20000,20000]\noneData = train_data[train_data[\"label\"] == 1]\ncheckAnchorPictureIndex = []\ncheckPositivePictureIndex = []\ncheckNegativePictureIndex = []\nfor number in tqdm(range(len(newDataSample))):\n  numberOfDataAdded = newDataSample[number]\n  addData = train_data[train_data[\"label\"] == number + 5]\n  negativeData = train_data[train_data[\"label\"] != number + 5]\n  for i in range(int(numberOfDataAdded)):\n    while True:\n      a = random.randint(0,len(allTrainIndex)-1)\n      b = random.randint(0,len(allTrainIndex)-1)\n      c = random.randint(0,len(allTrainIndex)-1)\n      if a in addData.index and b in addData.index and a != b and c in negativeData.index:\n        checkAnchorPictureIndex.append(a)\n        checkPositivePictureIndex.append(b)\n        checkNegativePictureIndex.append(c)\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testTriplePicture = pd.DataFrame({\"Anchor\":checkAnchorPictureIndex,\n                                   \"Positive\":checkPositivePictureIndex,\n                                   \"Negative\":checkNegativePictureIndex}\n                                  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testSimilarity.iloc[[5720,23662,28271],:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testTriplePicture[\"label\"] = 1\nanotherSample = testTriplePicture[[\"Positive\",\"Negative\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anotherSample[\"label\"] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"firstSample = testTriplePicture[[\"Anchor\",\"Positive\",\"label\"]]\nfirstSample.columns = [\"ImageA\",\"ImageB\",\"label\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"firstSample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anotherSample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testData = pd.concat([anotherSample,firstSample],axis=0).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testData.to_csv(\"TestPredictionData.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anotherSample.columns = [\"ImageA\",\"ImageB\",\"label\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}