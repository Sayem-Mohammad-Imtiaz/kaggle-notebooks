{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Classification of stroke diseases**","metadata":{}},{"cell_type":"markdown","source":"> **In the first stage, we conducted a complete and detailed exploration and analysis of stroke disease data, and the results we obtained are very useful information. You can view this kernel through the following link:\nhttps://www.kaggle.com/alimohammedbakhiet/eda-for-stroke-dataset**\n\n> **In the second stage, we will apply machine learning algorithms and neural networks to craft that data and we will work hard to get the highest results in accuracy for the test data.**\n\n> **Let's have fun...**","metadata":{}},{"cell_type":"markdown","source":"> **In the first step we will do the usual things like reading the data and cleaning the data, and then we will move on to splitting the data and creating the models:**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.562064Z","iopub.execute_input":"2021-08-06T22:47:45.562389Z","iopub.status.idle":"2021-08-06T22:47:45.57248Z","shell.execute_reply.started":"2021-08-06T22:47:45.562341Z","shell.execute_reply":"2021-08-06T22:47:45.571472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.573938Z","iopub.execute_input":"2021-08-06T22:47:45.574222Z","iopub.status.idle":"2021-08-06T22:47:45.597919Z","shell.execute_reply.started":"2021-08-06T22:47:45.574194Z","shell.execute_reply":"2021-08-06T22:47:45.596898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.602595Z","iopub.execute_input":"2021-08-06T22:47:45.60289Z","iopub.status.idle":"2021-08-06T22:47:45.622814Z","shell.execute_reply.started":"2021-08-06T22:47:45.602862Z","shell.execute_reply":"2021-08-06T22:47:45.621679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We will now drop some columns and replace some of them and transform the data.**","metadata":{}},{"cell_type":"code","source":"data=data.drop([\"id\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.624669Z","iopub.execute_input":"2021-08-06T22:47:45.62534Z","iopub.status.idle":"2021-08-06T22:47:45.635664Z","shell.execute_reply.started":"2021-08-06T22:47:45.625288Z","shell.execute_reply":"2021-08-06T22:47:45.634342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here we will replace one column with another and drop the original.\nbmi_median = data.bmi.median()\ndata['bmi_median'] = data.bmi.fillna(bmi_median)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.637905Z","iopub.execute_input":"2021-08-06T22:47:45.63853Z","iopub.status.idle":"2021-08-06T22:47:45.646666Z","shell.execute_reply.started":"2021-08-06T22:47:45.638483Z","shell.execute_reply":"2021-08-06T22:47:45.645764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.647801Z","iopub.execute_input":"2021-08-06T22:47:45.648186Z","iopub.status.idle":"2021-08-06T22:47:45.673221Z","shell.execute_reply.started":"2021-08-06T22:47:45.648159Z","shell.execute_reply":"2021-08-06T22:47:45.672202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data.drop([\"bmi\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.674396Z","iopub.execute_input":"2021-08-06T22:47:45.674667Z","iopub.status.idle":"2021-08-06T22:47:45.68142Z","shell.execute_reply.started":"2021-08-06T22:47:45.67464Z","shell.execute_reply":"2021-08-06T22:47:45.680221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.683004Z","iopub.execute_input":"2021-08-06T22:47:45.683437Z","iopub.status.idle":"2021-08-06T22:47:45.69761Z","shell.execute_reply.started":"2021-08-06T22:47:45.683393Z","shell.execute_reply":"2021-08-06T22:47:45.696798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Here I convert the data.**","metadata":{}},{"cell_type":"code","source":"data[\"gender\"]=data[\"gender\"].map({\"Male\":0 , \"Female\":1 , \"Other\":2})\ndata[\"ever_married\"]=data[\"ever_married\"].map({\"Yes\":1 , \"No\":0 })\ndata[\"work_type\"]=data[\"work_type\"].map({'Private':0, 'Self-employed':1, 'Govt_job':2, 'children':3, 'Never_worked':4 })\ndata[\"smoking_status\"]=data[\"smoking_status\"].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3 })\ndata[\"Residence_type\"]=data[\"Residence_type\"].map({'Urban':0, 'Rural':1})","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.698972Z","iopub.execute_input":"2021-08-06T22:47:45.699466Z","iopub.status.idle":"2021-08-06T22:47:45.717689Z","shell.execute_reply.started":"2021-08-06T22:47:45.699413Z","shell.execute_reply":"2021-08-06T22:47:45.716677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.719609Z","iopub.execute_input":"2021-08-06T22:47:45.719901Z","iopub.status.idle":"2021-08-06T22:47:45.734961Z","shell.execute_reply.started":"2021-08-06T22:47:45.719873Z","shell.execute_reply":"2021-08-06T22:47:45.734228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.736409Z","iopub.execute_input":"2021-08-06T22:47:45.736937Z","iopub.status.idle":"2021-08-06T22:47:45.745337Z","shell.execute_reply.started":"2021-08-06T22:47:45.736906Z","shell.execute_reply":"2021-08-06T22:47:45.744639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target=data[\"stroke\"]\nfeatures=data.drop([\"stroke\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.746297Z","iopub.execute_input":"2021-08-06T22:47:45.746689Z","iopub.status.idle":"2021-08-06T22:47:45.757622Z","shell.execute_reply.started":"2021-08-06T22:47:45.746662Z","shell.execute_reply":"2021-08-06T22:47:45.756942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(features)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.758551Z","iopub.execute_input":"2021-08-06T22:47:45.758925Z","iopub.status.idle":"2021-08-06T22:47:45.771784Z","shell.execute_reply.started":"2021-08-06T22:47:45.758899Z","shell.execute_reply":"2021-08-06T22:47:45.770986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Let's start building some machine learning algorithms:**","metadata":{"execution":{"iopub.status.busy":"2021-08-06T08:45:39.029649Z","iopub.execute_input":"2021-08-06T08:45:39.030279Z","iopub.status.idle":"2021-08-06T08:45:39.036248Z","shell.execute_reply.started":"2021-08-06T08:45:39.030231Z","shell.execute_reply":"2021-08-06T08:45:39.035554Z"}}},{"cell_type":"markdown","source":"# **1 . Random Forest Algorithm**","metadata":{}},{"cell_type":"code","source":"x_train,x_test, y_train, y_test = train_test_split(X,target,test_size=0.25,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.772753Z","iopub.execute_input":"2021-08-06T22:47:45.773143Z","iopub.status.idle":"2021-08-06T22:47:45.779868Z","shell.execute_reply.started":"2021-08-06T22:47:45.773116Z","shell.execute_reply":"2021-08-06T22:47:45.779193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.781567Z","iopub.execute_input":"2021-08-06T22:47:45.781973Z","iopub.status.idle":"2021-08-06T22:47:45.791246Z","shell.execute_reply.started":"2021-08-06T22:47:45.781933Z","shell.execute_reply":"2021-08-06T22:47:45.790437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val, x_test, y_val, y_test=train_test_split(x_test, y_test, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.793118Z","iopub.execute_input":"2021-08-06T22:47:45.793627Z","iopub.status.idle":"2021-08-06T22:47:45.803229Z","shell.execute_reply.started":"2021-08-06T22:47:45.793583Z","shell.execute_reply":"2021-08-06T22:47:45.802384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( x_val.shape, x_test.shape, y_val.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.804438Z","iopub.execute_input":"2021-08-06T22:47:45.804932Z","iopub.status.idle":"2021-08-06T22:47:45.814798Z","shell.execute_reply.started":"2021-08-06T22:47:45.804888Z","shell.execute_reply":"2021-08-06T22:47:45.813532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Since we have some outliers in our data and I noted them in the first stage, I'm going to use Random Forest because they are good at dealing with outliers.**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.816399Z","iopub.execute_input":"2021-08-06T22:47:45.817052Z","iopub.status.idle":"2021-08-06T22:47:45.876119Z","shell.execute_reply.started":"2021-08-06T22:47:45.817019Z","shell.execute_reply":"2021-08-06T22:47:45.875341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RandomForestClassifierModel=RandomForestClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.877185Z","iopub.execute_input":"2021-08-06T22:47:45.877492Z","iopub.status.idle":"2021-08-06T22:47:45.881337Z","shell.execute_reply.started":"2021-08-06T22:47:45.877461Z","shell.execute_reply":"2021-08-06T22:47:45.880644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {\n    \"n_estimators\":[50,70,100,150,200],\n    \"max_depth\":[7,11,13,15,32,None]\n    \n}","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.882476Z","iopub.execute_input":"2021-08-06T22:47:45.882963Z","iopub.status.idle":"2021-08-06T22:47:45.892173Z","shell.execute_reply.started":"2021-08-06T22:47:45.882928Z","shell.execute_reply":"2021-08-06T22:47:45.891463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  I will pass the classifier and parameters and the number of iteration in the GridSearchCV method.\ncv = GridSearchCV(RandomForestClassifierModel,parameters,cv=5)\ncv.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:47:45.893983Z","iopub.execute_input":"2021-08-06T22:47:45.894537Z","iopub.status.idle":"2021-08-06T22:48:52.317652Z","shell.execute_reply.started":"2021-08-06T22:47:45.894506Z","shell.execute_reply":"2021-08-06T22:48:52.316765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I have defined the method for printing all the iteration done and scores in each iteration.\ndef display(results):\n    print(f'Best parameters are: {results.best_params_}')\n    print(\"\\n\")\n    mean_score = results.cv_results_['mean_test_score']\n    std_score = results.cv_results_['std_test_score']\n    params = results.cv_results_['params']\n    for mean,std,params in zip(mean_score,std_score,params):\n        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:52.31944Z","iopub.execute_input":"2021-08-06T22:48:52.319728Z","iopub.status.idle":"2021-08-06T22:48:52.325451Z","shell.execute_reply.started":"2021-08-06T22:48:52.319699Z","shell.execute_reply":"2021-08-06T22:48:52.324557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(cv)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:52.326603Z","iopub.execute_input":"2021-08-06T22:48:52.326883Z","iopub.status.idle":"2021-08-06T22:48:52.349061Z","shell.execute_reply.started":"2021-08-06T22:48:52.326856Z","shell.execute_reply":"2021-08-06T22:48:52.345939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RandomForestClassifierModel=RandomForestClassifier(n_estimators=70, criterion='gini', max_depth=7,\n                                min_samples_split=2, min_samples_leaf=1,min_weight_fraction_leaf=0.0,\n                                max_features='auto',max_leaf_nodes=7,min_impurity_decrease=0.0,\n                                min_impurity_split=None, bootstrap=True,oob_score=False, n_jobs=-1,\n                                random_state=0, verbose=0,warm_start=True)\nRandomForestClassifierModel.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:52.350172Z","iopub.execute_input":"2021-08-06T22:48:52.350482Z","iopub.status.idle":"2021-08-06T22:48:52.606242Z","shell.execute_reply.started":"2021-08-06T22:48:52.350453Z","shell.execute_reply":"2021-08-06T22:48:52.605304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(x_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(x_test, y_test))\n# This instruction calculates the percentage of importance for each of the features.\nprint('RandomForestClassifierModel features importances are : ' , RandomForestClassifierModel.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:52.607436Z","iopub.execute_input":"2021-08-06T22:48:52.607725Z","iopub.status.idle":"2021-08-06T22:48:52.926179Z","shell.execute_reply.started":"2021-08-06T22:48:52.607697Z","shell.execute_reply":"2021-08-06T22:48:52.924653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The accuracy of the test data reached 94%.**","metadata":{}},{"cell_type":"code","source":"#Calculating Prediction\ny_pred = RandomForestClassifierModel.predict(x_test)\ny_pred_prob = RandomForestClassifierModel.predict_proba(x_test)\nprint('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:10])\nprint(\"real values of y_test>>>>>>>>>>>>>>>>>>>>>>>>>>>is : \\n\" ,y_test[:10] )\nprint('Prediction Probabilities Value for RandomForestClassifierModel is : ' , y_pred_prob[:10])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:52.92751Z","iopub.execute_input":"2021-08-06T22:48:52.927804Z","iopub.status.idle":"2021-08-06T22:48:53.143515Z","shell.execute_reply.started":"2021-08-06T22:48:52.927775Z","shell.execute_reply":"2021-08-06T22:48:53.142357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating Confusion Matrix\nfrom sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix\nconfusion_matrix(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:53.145084Z","iopub.execute_input":"2021-08-06T22:48:53.145504Z","iopub.status.idle":"2021-08-06T22:48:53.15385Z","shell.execute_reply.started":"2021-08-06T22:48:53.14546Z","shell.execute_reply":"2021-08-06T22:48:53.152886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(RandomForestClassifierModel,x_test,y_test);","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:53.155158Z","iopub.execute_input":"2021-08-06T22:48:53.15561Z","iopub.status.idle":"2021-08-06T22:48:53.467085Z","shell.execute_reply.started":"2021-08-06T22:48:53.15558Z","shell.execute_reply":"2021-08-06T22:48:53.466131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Let's build a deep learning algorithm**","metadata":{}},{"cell_type":"code","source":"# Now we are going to use a neural network for classification\n# Here we will call the libraries that we need.\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # empty neural network\nfrom keras.layers import Dense # layer constitution\nimport keras \nfrom keras.layers import Dropout\nfrom keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:53.46827Z","iopub.execute_input":"2021-08-06T22:48:53.468584Z","iopub.status.idle":"2021-08-06T22:48:55.609663Z","shell.execute_reply.started":"2021-08-06T22:48:53.468555Z","shell.execute_reply":"2021-08-06T22:48:55.608592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = keras.utils.normalize(x_train, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:55.611004Z","iopub.execute_input":"2021-08-06T22:48:55.611313Z","iopub.status.idle":"2021-08-06T22:48:55.616422Z","shell.execute_reply.started":"2021-08-06T22:48:55.611276Z","shell.execute_reply":"2021-08-06T22:48:55.615293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model= Sequential([\n    Dense(1000, activation='relu', input_shape=(10,)),\n    Dropout(0.5),\n    Dense(100, activation='relu'),\n    Dropout(0.5),\n    Dense(1000, activation='relu'),\n    Dropout(0.3),\n    Dense(7, activation='relu'),\n    Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n              \nhist = model.fit(x_train, y_train,\n          batch_size=10, epochs=40,\n          validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:48:55.617736Z","iopub.execute_input":"2021-08-06T22:48:55.61804Z","iopub.status.idle":"2021-08-06T22:49:50.521843Z","shell.execute_reply.started":"2021-08-06T22:48:55.618011Z","shell.execute_reply":"2021-08-06T22:49:50.520609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:49:50.524433Z","iopub.execute_input":"2021-08-06T22:49:50.524742Z","iopub.status.idle":"2021-08-06T22:49:50.701718Z","shell.execute_reply.started":"2021-08-06T22:49:50.524711Z","shell.execute_reply":"2021-08-06T22:49:50.700514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T22:54:57.538405Z","iopub.execute_input":"2021-08-06T22:54:57.53896Z","iopub.status.idle":"2021-08-06T22:54:57.709769Z","shell.execute_reply.started":"2021-08-06T22:54:57.538913Z","shell.execute_reply":"2021-08-06T22:54:57.708886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It was a fast neural network to extract quick but good results.**","metadata":{}},{"cell_type":"markdown","source":"# **The end**","metadata":{}},{"cell_type":"markdown","source":"**I applied some quick algorithms and extracted an accuracy rate of 94% of the evaluation data.\nthank you for your time**","metadata":{}}]}