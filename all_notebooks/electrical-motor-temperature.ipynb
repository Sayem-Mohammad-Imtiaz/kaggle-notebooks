{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello ! \n\nIn this kernel, i will try to estimate a model that explains the torque and the stator_winding variables in the dataset. I will use correlation to be able to figure what are the variables that has the more effect on the two outputs (torque and stator_winding). This will help reduce the quantity of variables used and also simply the models which is always the best thing to do (the best models are the simplest models).\nI won't be splitting the datasets to training and testing datasets but i would rather use each profile as a seperate experiment and then compare the models' parameters estimated to see their consistency.\n\nHope that you will enjoy my kernel !"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom random import randint\nfrom sklearn.linear_model import LinearRegression\n\n# ignore Deprecation Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the data and assign it to a dataframe :"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having a look at the first row of the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Exploration and Analysis**\n\nLet's check some information about the dataset and see if there is any NaN or missing values in the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That is good news ! It does not look like there is missing values and there are no NaN.\n\nSo each profile is actually an experiment that was conducted and the measures were recorded during each experiment. Let's see how many experiment we have"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the unique profile IDs\nunique_profiles_id = df['profile_id'].unique()\n\nprint('Number of unique profiles: %i'%len(unique_profiles_id))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are the records on 52 experiments and as it was stated in the introduction of the dataset they are all independant. We can now look at how many points we have per experiment since we will be using individually to define models."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_point_profile = np.zeros(len(unique_profiles_id))\nfor i in range(len(unique_profiles_id)):\n    num_point_profile[i] = df[df['profile_id']==unique_profiles_id[i]].shape[0]\n\nprint('Profile ID with minimum number of points %i and it has %i points' %(unique_profiles_id[np.where(num_point_profile == np.amin(num_point_profile))],\n                                                                 min(num_point_profile)))    \nf, ax = plt.subplots(figsize=(18,5))\nplt.bar(unique_profiles_id, (num_point_profile/df.shape[0])*100)\nplt.xlabel('Profile ID')\nplt.ylabel('Number of points compared to the \\n total number of points(%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So as we can see from the graph, that all the profiles have a good amount of points. \n\nNow we will need to see in each experiment if we can see the interaction between the measured variables. This will help us minimize the number of inputs in our model. To do so, we will see the correlation matrix transposed in a heatmap. Since the experiments are independant, we can generate a randon number and use it to choose a specific experiment and then re-run that cell multiple times to see if there is a behavior that stands out."},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = randint(0,len(unique_profiles_id)) # Get a random index\n\ncorr=df[df['profile_id']==unique_profiles_id[profile]].drop('profile_id',axis=1).corr()\nprint('The correlation heatmap is for the profile ID %i and its is index %i'%(unique_profiles_id[profile], profile))\n\nf,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(corr, annot=True, linewidths=.5, fmt='.2f', mask= np.zeros_like(corr,dtype=np.bool), \n            cmap=sns.diverging_palette(100,200,as_cmap=True), square=True, ax=ax)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the obvious behaviors that keeps coming everytime we run the cell above :\n1. There is an almost perfect linear relation between the torque and i_q. This suggest that we can use linear regression model to estimate the torque usinq i_q.\n1. The temperatures in stator yoke, tooth and winding are highly correlated since they represent the temperature in the stator and they should be pretty similar (there is no isolation in the stator between those three parts). \n1. The coolant seems to be highly correlated with the stator yoke. It is understandable because the coolant runs through the stator yoke to cool it down.\n "},{"metadata":{},"cell_type":"markdown","source":"**Torque estimation**\n\nBased on the observation from the heatmap of the correlation matrix, we can use and linear regression model to estimate the torque using the measure of the current i_q. The pair plot between the torque and i_q demonstrate more that linear relation between those two variables. Again, we can run the cell below to go through multiple profiles."},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = randint(0,len(unique_profiles_id)) # Get a random index \nprint('The profile ID shown is %i and it has %i points' %(unique_profiles_id[profile],num_point_profile[profile]))\n\nsns.pairplot(df[df['profile_id']==unique_profiles_id[profile]][['i_q', 'torque']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now that we are pretty confident about the structure of the model linking i_q and torque (linear regression model). We will use the data to estimate the coefficient and the intercept of that model. Instead of splitting the values to a train and test dataset, i will try another approach. \nEvery data collected in a specific profile represent the operation of the motor. So if we estimate the parameters of the linear model (coefficient and intercept) for every profile then we should have relatively the same parameters.\nWe will verify that approach but collecting the coefficient, the intercept and the model's score for every profile and then comparing them. Basically, the criteria is the consistency of the estimated parameters and scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Torque model\n\n# Define vectors to collect the parameters and the score\nmodel_torque_scores = np.zeros(len(unique_profiles_id))\ncoef_torque = np.zeros(len(unique_profiles_id))\ninter_torque = np.zeros(len(unique_profiles_id))\n\nfor i in range (len(unique_profiles_id)) :\n\n    model_torque = LinearRegression()\n\n    X_torque_train = df[df['profile_id']==unique_profiles_id[i]][['i_q']].values\n    y_torque_train = df[df['profile_id']==unique_profiles_id[i]][['torque']].values\n\n    model_torque.fit(X_torque_train, y_torque_train)\n    \n    # Get parameters and the score\n    coef_torque[i] = model_torque.coef_\n    inter_torque[i] = model_torque.intercept_\n    model_torque_scores[i] = model_torque.score(X_torque_train, y_torque_train)\n\n# Representing the models parameters and scores for every profile    \nf, ax = plt.subplots(figsize=(18,10))\nplt.subplot(3,1,1)\nplt.bar(unique_profiles_id, coef_torque)\nplt.ylim((0.8,1.2))\nplt.ylabel('Coefficient of L.R.')\nplt.subplot(3,1,2)\nplt.bar(unique_profiles_id, inter_torque)\nplt.ylim((-0.1,0.1))\nplt.ylabel('Intercept of L.R.')\nplt.subplot(3,1,3)    \nplt.bar(unique_profiles_id, model_torque_scores)\nplt.ylim((0.95,1.05))\nplt.xlabel('Profile ID')\nplt.ylabel('Score of L.R.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graphs, we can see that for each profile the socres are very high (above 0.95) which means that models explains very well the interaction between i_q and the torque. Regarding the parameters, the estimated parameters are pretty similar and we can confidently say that there is consistency in the values of the estimated parameters. So, an easy/simple way would to get the averages of the estimated coefficients and intercepts and use them as a general model for the estimation of the torque using i_q."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The coefficient of the torque model is : %f' %np.mean(coef_torque))\nprint('The intercept of the torque model is : %f' %np.mean(inter_torque))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Stator Winding temperature**\n\nIf we go back to that correlation heatmap, then we can see that there is a strong correlation between the coolant, stator_yoke, stator_tooth and stator_winding. "},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = randint(0,len(unique_profiles_id)) # Get a random index \nprint('The profile ID shown is %i and it has %i points' %(unique_profiles_id[profile],num_point_profile[profile]))\n\nsns.pairplot(df[df['profile_id']==unique_profiles_id[profile]][['coolant', 'stator_yoke', 'stator_tooth', 'stator_winding']],\n            markers ='+' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The pair-plots show the conclusion that were drawn regarding the relationship between the coolant, stator_yoke, stator_tooth and stator_winding. So we consider using a multi-linear regression model to estimate the stator_winding using the three inputs coolant, stator_yoke and stator_tooth. We will follow the same approach used for the torque model estimation where we will compare the estimated paramters and scores from all the models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stator Temperature\n\n# Define vectors to collect the parameters and the score\nmodel_stator_scores = np.zeros(len(unique_profiles_id))\ncoef_stator = np.zeros((len(unique_profiles_id),3))\ninter_stator = np.zeros(len(unique_profiles_id))\n\nfor i in range (len(unique_profiles_id)) :\n\n    model_stator = LinearRegression()\n\n    X_stator_train = df[df['profile_id']==unique_profiles_id[i]][['coolant', 'stator_yoke', 'stator_tooth']].values\n    y_stator_train = df[df['profile_id']==unique_profiles_id[i]][['stator_winding']].values\n\n    model_stator.fit(X_stator_train, y_stator_train)\n    \n    # Get parameters and the score\n    coef_stator[i,:] = model_stator.coef_\n    inter_stator[i] = model_stator.intercept_\n    model_stator_scores[i] = model_stator.score(X_stator_train, y_stator_train)\n\n# Representing the models parameters and scores for every profile    \nf, ax = plt.subplots(figsize=(18,10))\nplt.subplot(5,1,1)\nplt.bar(unique_profiles_id, coef_stator[:,0])\nplt.ylabel('Coefficient 1 of \\n M.L.R.')\nplt.subplot(5,1,2)\nplt.bar(unique_profiles_id, coef_stator[:,1])\nplt.ylabel('Coefficient 2 of \\n M.L.R.')\nplt.subplot(5,1,3)\nplt.bar(unique_profiles_id, coef_stator[:,2])\nplt.ylabel('Coefficient 3 of \\n M.L.R.')\nplt.subplot(5,1,4)\nplt.bar(unique_profiles_id, inter_stator)\nplt.ylabel('Intercept of \\n M.L.R.')\nplt.subplot(5,1,5)\nplt.bar(unique_profiles_id, model_stator_scores)\nplt.ylim((0.75,1.05))\nplt.xlabel('Profile ID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The consistency of the estimated parameters and score of the multi linear regression model is less evident that the one we had during the estimation of the torque model. One thing that jumps to us when we look at those graphs is the parameters obtained for the profile ID number 46. Even though the score obtained for the profile is about 0.85 (which is still a good score), the value of the parameters is way different than the others. For that reason, we can remove that profile from the estimation of the mean of the parameters because it acts as an outlier profile compared to the other one. After that, we can investigate more about why that profile behaves that way and we did not see that behavior in the torque estimation but it is not the purpose here."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation the average of the parameters and don't taking into consideration\n# the outlier profile\nprint('The coefficient of the torque model is : %f' %np.mean(np.delete(coef_stator[:,0],16)))\nprint('The coefficient of the torque model is : %f' %np.mean(np.delete(coef_stator[:,1],16)))\nprint('The coefficient of the torque model is : %f' %np.mean(np.delete(coef_stator[:,2],16)))\nprint('The intercept of the torque model is : %f' %np.mean(np.delete(inter_stator,16)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One could argue that there is a little contradiction here if we compare the sign of the coefficient linking the stator_yoke and the stator_winding (which is coefficient 2) and the sign of the correlation between those two variables (you can see it in the correlation heatmap above). So using the correlation heatmap, it is showing a positive correlation which means that if the stator_tooth goes up then the stator_windin goes up too (that is an expected behavior). But the coefficient 2 says the opposite, if the stator_tooh goes up then the stator_winding will go down.\nThe explanation to that little contradiction is that the parameters estimated in the multi linear regression model have no physical meaning. All what it cares about is to find the correct parameters that describe, the best way it can, the behavior of the stator_winding without taking into consideration the physics behind the collected data.\n\nHope that you find this kernel interesting and it would give you some hints in whatever you are working on !"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}