{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Heart Failure Prediction ","metadata":{}},{"cell_type":"markdown","source":"![](https://viewmedica.com/images/thumbslarge/heartfailure_1280.jpg)\n\nsource : https://www.wkhs.com/heart/conditions-treated/congestive-heart-failure","metadata":{}},{"cell_type":"markdown","source":"### Hi there!ðŸ˜„ I am new to data science and this is my try on the Heart Failure Prediction dataset. Feel free to comment if you have any questions, insights or advice on this or any data science related :) Upvote if you find my work useful for you! Thank you!","metadata":{}},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">IMPORTING LIBRARIES</span>**\n","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#split train and test set\nfrom sklearn.model_selection import train_test_split\n\n#sklearn model\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">LOAD DATA</span>**\n","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\n\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:#6daa9f;\">EDA</span>**\n","metadata":{}},{"cell_type":"code","source":"#summary of variables in data\nprint(data.describe())\n\n#identify column names,column data type and shape of the dataset\nprint(np.shape(data))\n\nprint(data.columns.tolist())\n\ndata.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From here,we can see that the dataset contains 13 columns with 299 rows.\nThe datatype for every rows are also all numerics \n\nDetail About Data:\n\n- Age: age of patient\n- anaemia :whether the patient have a low red blood cell or hemoglobin (0 or 1)\n- creatinine_phosphokinase: an enzyme in our blood (the level of CPK enzyme in blood mcg/L),  \nhigh level of CPK indicate that there has been an injury or stress to muscle tissue, heart or brain\n- diabetes: if the patient has diabetes (type 2 diabetes patient is 4 times more likely  to develop heart failure than someone without)\n- ejection_fraction : percentage of blood pump out of the heart at each contraction (percentage)\n- high_blood_pressure: if the patient have hypertension\n- plateletes:the level of platelets in blood \n- serum_creatinine: the level of serum creatinine in patient's blood mg/dL- \n  give an estimation on how well the kidney filters\n- serum_sodium: level of serum sodium in the blood\n- sex:gender of patient (0 or 1) female/male\n- smoking : if the patient smokes or not\n- time:follow up period of patient\n- death_event:patient deceased during the follow up period\n","metadata":{}},{"cell_type":"code","source":"#identify missing values in dataset\ndata.isnull().sum()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The sum of missing values for every column.In this case,there are zero missing values for all columns","metadata":{}},{"cell_type":"code","source":"corrMatrix = data.corr()\nplt.subplots(figsize=(20,20))\n\nsns.heatmap(corrMatrix, annot=True)\nplt.figure(figsize=(100,100))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation between all features:\n- follow up time of patient have the highest correlation with death_event \n- followed by ejection fraction\n- linearly collerated age (higher age, more likely to death)\n- serum_creatinine level linearly collerated with death_event\n\nFrom the matrix, I decided to use age, time,ejection_fraction,serum_Creatinine and serum_Sodium\n","metadata":{}},{"cell_type":"markdown","source":"## Variable Analysis\nReference : https://towardsdatascience.com/data-exploration-and-analysis-using-python-e564473d7607\n\nUsing univariate analysis to highlight missing and outlier values.Our variable are categorical variables.\n\nHandling outliers\n\n\n### Data Analysis & Visualization\n\nvisualize every data \n\nAge \n-the number of death event according to age distribution\n\n\n","metadata":{}},{"cell_type":"code","source":"#check the data provided according to our target variable(death_event)\n\nprint(data['DEATH_EVENT'].value_counts())\ndata['DEATH_EVENT'].value_counts().plot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above clearly shows that our data is imbalanced with the data for '0' is 203 while for '1' is 96 samples.","metadata":{}},{"cell_type":"code","source":"sns.histplot(data,x='age',hue='DEATH_EVENT',multiple='stack')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(data,x='age',hue='sex',multiple=\"stack\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n- I will not get rid of outliers as these values are medical data which actually have meaning medically\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"markdown","source":"**Split train and test data**\n\n","metadata":{}},{"cell_type":"code","source":"col = ['time','ejection_fraction','serum_creatinine','age','serum_sodium']\npredictors = data[col]\ntarget = data[\"DEATH_EVENT\"]\n\nX_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.22, random_state = 0)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalize our data**\n\nSince we have many numerical columns in our data with different range of values, I decided to change the values to a common scale using normalization to bring it all in the same range.","metadata":{}},{"cell_type":"code","source":"# Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## 5 MODEL\n \n* Naive Bayes\n* Random Forest\n* Logistic Regression\n* SVM\n* Decision Trees\n","metadata":{}},{"cell_type":"code","source":"#gaussian naive bayes\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n  \n# making predictions on the testing set\ny_pred = gnb.predict(X_test)\n  \n# comparing actual response values (y_test) with predicted response values (y_pred)\nacc_naivebayes = metrics.accuracy_score(y_test, y_pred)*100\nprint(\"Gaussian Naive Bayes model accuracy(in %):\",acc_naivebayes )\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#logistic regression \n\nclassifier = LogisticRegression(random_state = 22)\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nsns.heatmap(cm, annot=True)\n\nacc_logisticregression = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint (\"Logistic Regression model Accuracy : \", acc_logisticregression) \nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random forest\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(\"Random Forest Model Accuracy : \",acc_randomforest)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SVM Classifier\n\nfrom sklearn.svm import SVC  \nclf = SVC(kernel='linear') \n  \n# fitting x samples and y classes \nclf.fit(X_train, y_train) \ny_pred = clf.predict(X_test)\n\nacc_SVM = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(\"SVM Model Accuracy : \",acc_SVM)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nmodeldt = DecisionTreeClassifier()\n\n# fit the model with the training data\nmodeldt.fit(X_train,y_train)\n\n# depth of the decision tree\nprint('Depth of the Decision Tree :', modeldt.get_depth())\n\n# predict the target on the train dataset\npredict_train = modeldt.predict(X_train)\n\n# Accuray Score on train dataset\naccuracy_train = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', accuracy_train)\n\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\n\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(y_test,predict_test)\nprint('accuracy_score on test dataset : ', accuracy_test*100)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}