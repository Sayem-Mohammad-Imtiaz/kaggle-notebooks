{"metadata":{"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","name":"python","mimetype":"text/x-python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"07d49039649fbb40339ef38fedf4d253ca34143b","_cell_guid":"f6556fac-2561-460d-8354-a80d9b3cfc93"},"source":"This is an example from the book \"Deep Learning with Python\" by Fran√ßois Chollet"},{"cell_type":"code","metadata":{"_uuid":"29d47466c4c4be5aeaf4394129e49845a31b2f3e","_cell_guid":"94afbc67-6232-4f93-b594-3136563f8b61"},"outputs":[],"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","metadata":{"_uuid":"a4fc11d815ed40a7af52e995e13496d25685d540","_cell_guid":"a432320f-a04f-467f-939f-961e5e4b9633"},"outputs":[],"execution_count":null,"source":"import keras\nkeras.__version__"},{"cell_type":"markdown","metadata":{"_uuid":"b08a38cbedca9cc1fb3a106790f4e3914ae7d5af","_cell_guid":"02da31fc-a91b-45ce-bca6-521d842ffbbe"},"source":"Load and inspect the data. At the same time it's an example of using \"Weather archive Jena\" dataset"},{"cell_type":"code","metadata":{"_uuid":"1bb0daf86868fd4b99e586e1d105611acc803a7c","_cell_guid":"df72e241-503e-42ab-a092-a72fc24bbdfd"},"outputs":[],"execution_count":null,"source":"import os\n\ndata_dir = '../input'\nfname = os.path.join(data_dir, 'jena_climate_2009_2016.csv')\n\nf = open(fname)\ndata = f.read()\nf.close()\n\nlines = data.split('\\n')\nheader = lines[0].split(',')\nlines = lines[1:]\n\nprint(header)\nprint(len(lines))"},{"cell_type":"code","metadata":{"_uuid":"ad77e518025849d2e5b9a2d4189ee327692a1180","_cell_guid":"ed432f2b-b2cb-4651-9906-e83d7c6f8e39"},"outputs":[],"execution_count":null,"source":"import numpy as np\n\n# Parse the data\n\nfloat_data = np.zeros((len(lines), len(header) - 1))\nfor i, line in enumerate(lines):\n    values = [float(x) for x in line.split(',')[1:]]\n    float_data[i, :] = values\nprint(float_data.shape)"},{"cell_type":"code","metadata":{"_uuid":"f7c9935baaeda6e837081acda9a9a789ed4ba229","_cell_guid":"d1a4daa4-ee7c-4f64-ba60-dc70e9833924"},"outputs":[],"execution_count":null,"source":"from matplotlib import pyplot as plt\n\n# Temperature over the full temporal range of the dataset. Yearly trends are clearly visible\n\ntemp = float_data[:, 1] # <1> temperature (in degrees Celsius)\nplt.plot(range(len(temp)), temp)\nplt.show()"},{"cell_type":"code","metadata":{"_uuid":"34d5d17e7df7085a983a0aab8753742df73f6d9b","_cell_guid":"f32e75f0-63a1-4de9-9b90-bae75546c41b"},"outputs":[],"execution_count":null,"source":"# The first 10 days of the temperature data\n\nplt.plot(range(1440), temp[:1440])\nplt.show()"},{"cell_type":"code","metadata":{"_uuid":"51424d83a01a148747c004180a2f613048c5ba42","_cell_guid":"a041adc9-9012-4352-98b5-f6c14c2d0333","collapsed":true},"outputs":[],"execution_count":null,"source":"# Normalizing the data\n\nmean = float_data[:200000].mean(axis=0)\nfloat_data -= mean\nstd = float_data[:200000].std(axis=0)\nfloat_data /= std"},{"cell_type":"code","metadata":{"_uuid":"0af7666997b7816cd2af67795789284814c317e3","_cell_guid":"5f866772-c6bf-4fde-86b9-34c696b96940","collapsed":true},"outputs":[],"execution_count":null,"source":"# generator function used to feed the training, validation and test data\n\ndef generator(data, lookback, delay, min_index, max_index,\n                shuffle=False, batch_size=128, step=6):\n    if max_index is None:\n        max_index = len(data) - delay - 1\n    i = min_index + lookback\n    while 1:\n        if shuffle:\n            rows = np.random.randint(\n                    min_index + lookback, max_index, size=batch_size)\n        else:\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += len(rows)\n\n        samples = np.zeros((len(rows),\n                            lookback // step,\n                            data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        for j, row in enumerate(rows):\n            indices = range(rows[j] - lookback, rows[j], step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j] + delay][1]\n        yield samples, targets"},{"cell_type":"code","metadata":{"_uuid":"09c799625bc9f4a71df760585f4963336763ab88","_cell_guid":"e6a77991-8ec6-43e4-b5f0-b14a9dbeb3ec","collapsed":true},"outputs":[],"execution_count":null,"source":"lookback = 1440\nstep = 6\ndelay = 144\nbatch_size = 128\n\ntrain_gen = generator(float_data,\n                        lookback=lookback,\n                        delay=delay,\n                        min_index=0,\n                        max_index=200000,\n                        shuffle=True,\n                        step=step,\n                        batch_size=batch_size)\nval_gen = generator(float_data,\n                        lookback=lookback,\n                        delay=delay,\n                        min_index=200001,\n                        max_index=300000,\n                        step=step,\n                        batch_size=batch_size)\ntest_gen = generator(float_data,\n                        lookback=lookback,\n                        delay=delay,\n                        min_index=300001,\n                        max_index=None,\n                        step=step,\n                        batch_size=batch_size)\n\nval_steps = (300000 - 200001 - lookback)  // batch_size # How many steps to draw from\n            # val_gen in order to see the entire validation set\ntest_steps = (len(float_data) - 300001 - lookback)  // batch_size # How many steps to draw\n        # from test_gen in order to see the entire test set \n"},{"cell_type":"markdown","metadata":{"_uuid":"a3cfa89328f6529edd59c925de416dd53a619aa1","_cell_guid":"a44f0fd9-436c-4c95-a852-3f8de38ae949"},"source":"Basic machine learning approach"},{"cell_type":"code","metadata":{"_uuid":"417e074686638ba38a92a883fd9ab032228843e3","_cell_guid":"085186ec-9497-4c00-93df-562a64a4bea7"},"outputs":[],"execution_count":null,"source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\nmodel = Sequential()\nmodel.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(1))\n# model.summary()\n\nmodel.compile(optimizer=RMSprop(), loss='mae')\nhistory = model.fit_generator(train_gen,\n                            steps_per_epoch=500,\n                            epochs=20,\n                            validation_data=val_gen,\n                            validation_steps=val_steps)\n"},{"cell_type":"code","metadata":{"_uuid":"0375db2a49cf65a489417ff4bd07a3b53235f861","_cell_guid":"b9394e50-70f8-4d70-a1b1-2544b265b068"},"outputs":[],"execution_count":null,"source":"import matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"},{"cell_type":"markdown","metadata":{"_uuid":"307510a47315e77155db5e04ea401dea306fbd7b","_cell_guid":"ac991dd9-58ec-4415-84e8-ee3a42a72efa"},"source":"First recurrent baseline"},{"cell_type":"code","metadata":{"_uuid":"6b90f14cafddd8401fdff660555ef5d5d3bbf081","_cell_guid":"199ec4fb-0ccf-4275-9f55-4b6070cedac8","collapsed":true},"outputs":[],"execution_count":null,"source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\nmodel = Sequential()\nmodel.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nmodel.summary()\nhistory = model.fit_generator(train_gen,\n                steps_per_epoch=500,\n                epochs=20,\n                validation_data=val_gen,\n                validation_steps=val_steps)"},{"cell_type":"code","metadata":{"_uuid":"79e6552aed6a3c236a78200f3b0150bd590f4b7d","_cell_guid":"aa5a2c4a-f5c5-4d47-a8c1-fe59fe183154","collapsed":true},"outputs":[],"execution_count":null,"source":"import matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"},{"cell_type":"code","metadata":{"_uuid":"7e978f90c60f8676ec1496f88b2bc132880a43ab","_cell_guid":"234ff9d2-7888-4932-a145-70999014bdd3"},"outputs":[],"execution_count":null,"source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\nmodel = Sequential()\nmodel.add(layers.Bidirectional(layers.GRU(32), input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer=RMSprop(), loss='mae')\nmodel.summary()\nhistory = model.fit_generator(train_gen,\n                                steps_per_epoch=500,\n                                epochs=10, # 40,\n                                validation_data=val_gen,\n                                validation_steps=val_steps)"},{"cell_type":"code","metadata":{"_uuid":"558871454ec0b91b73a7a7164ac7156523935f12","_cell_guid":"7b754523-2832-40d6-9815-2ce6f0a75527"},"outputs":[],"execution_count":null,"source":"# print(history.history)\nimport matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()"},{"cell_type":"markdown","metadata":{"_uuid":"7eb3c284aa14105abde71fc3ab7ae8668ea99c73","_cell_guid":"4aaedb0f-dca7-4d3b-ab87-0e364b6644a9"},"source":"# Combining CNNs and RNNs to process long sequences"},{"cell_type":"markdown","metadata":{"_uuid":"c6a7dbf1d07bd857c97372c65bca133907769413","_cell_guid":"b1acaf94-f34f-4ca1-9663-2ad783dc75ab"},"source":""},{"cell_type":"code","metadata":{"_uuid":"9570afd51d7ce54d5dc85148c03df3c56319277b","_cell_guid":"6ef7fe5a-b177-44af-bfbc-f64d348868f3","collapsed":true},"outputs":[],"execution_count":null,"source":"step = 3\nlookback = 720\ndelay = 144\n\ntrain_gen = generator(float_data,\n                lookback=lookback,\n                delay=delay,\n                min_index=0,\n                max_index=200000,\n                shuffle=True,\n                step=step)\nval_gen = generator(float_data,\n                lookback=lookback,\n                delay=delay,\n                min_index=200001,\n                max_index=300000,\n                step=step)\ntest_gen = generator(float_data,\n                lookback=lookback,\n                delay=delay,\n                min_index=300001,\n                max_index=None,\n                step=step)\n\nval_steps = (300000 - 200001 - lookback) // batch_size # 128\ntest_steps = (len(float_data) - 300001 - lookback) // batch_size # 128"},{"cell_type":"code","metadata":{"_uuid":"1a0f669e0e47c79f7db4c9cfd88841b756775c38","_cell_guid":"61cf2924-cbff-4ed2-81a4-08357a729d89"},"outputs":[],"execution_count":null,"source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\nmodel = Sequential()\nmodel.add(layers.Conv1D(32, 5, activation='relu',\n        input_shape=(None, float_data.shape[-1])))\nmodel.add(layers.MaxPooling1D(3))\nmodel.add(layers.Conv1D(32, 5, activation='relu'))\nmodel.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\nmodel.add(layers.Dense(1))\nmodel.summary()\n\nmodel.compile(optimizer=RMSprop(), loss='mae')"},{"cell_type":"code","metadata":{"_uuid":"96b1e46e35c4599f6674c3c1cf6f52935c06a0b4","_cell_guid":"0bb91811-f39e-4cb2-9797-c90268af4b25"},"outputs":[],"execution_count":null,"source":"history = model.fit_generator(train_gen,\n        steps_per_epoch=500,\n        epochs=20,\n        validation_data=val_gen,\n        validation_steps=val_steps)"},{"cell_type":"code","metadata":{"_uuid":"bbdd13d05c35bd74847506cef76bdf1c1609c93d","_cell_guid":"c575ac78-2e92-4f50-8381-90d7d5d97217"},"outputs":[],"execution_count":null,"source":"import matplotlib.pyplot as plt\n\nfor m in ['loss']:\n    loss = history.history[m]\n    val_loss = history.history['val_' + m]\n    epochs = range(1, len(loss) + 1)\n    plt.figure()\n    plt.plot(epochs, loss, 'bo', label='Training ' + m)\n    plt.plot(epochs, val_loss, 'b', label='Validation ' + m)\n    plt.title('Training and validation ' + m)\n    plt.legend()\n\nplt.show()"},{"cell_type":"code","metadata":{"_uuid":"2a43d2d8d3faae208b5b8a24d2a9c8e6effa59c5","_cell_guid":"18584f2d-8ca7-4d66-ad9f-c152cf434e8f","collapsed":true},"outputs":[],"execution_count":null,"source":"# Doesn't seem to work on Kaggle\n\n%%javascript\nJupyter.notebook.session.delete();"}],"nbformat_minor":1}