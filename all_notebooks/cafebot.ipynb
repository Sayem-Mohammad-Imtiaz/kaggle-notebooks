{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing the necessary libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import nltk\nimport numpy as np\nimport random\nimport string","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading in the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will read in the corpus.txt file and convert the entire corpus into a list of sentences and a list of words for further pre-processing.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"f=open('/kaggle/input/cafe-chatbot-dataset/conversationo.csv','r',errors = 'ignore')\nraw=f.read()\nraw=raw.lower()# converts to lowercase\nnltk.download('punkt') # first-time use only\nnltk.download('wordnet') # first-time use only\nsent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \nword_tokens = nltk.word_tokenize(raw)# converts to list of words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-processing the raw text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmer = nltk.stem.WordNetLemmatizer()\ndef LemTokens(tokens):\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nGREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\ndef greeting(sentence):\n \n    for word in sentence.split():\n        if word.lower() in GREETING_INPUTS:\n            return random.choice(GREETING_RESPONSES)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer # which is to convert a collection of raw documents to a matrix of TF-IDF features.\nfrom sklearn.metrics.pairwise import cosine_similarity #Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def response(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0):\n        robo_response=robo_response+\"I am sorry! I don't understand you\"\n        return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flag=True\nprint(\"Cafebot: My name is Cafebot. I will answer your queries about Cafe. If you want to exit, type Bye!\")\nwhile(flag==True):\n    user_response = input()\n    user_response=user_response.lower()\n    if(user_response!='bye'):\n        if(user_response=='thanks' or user_response=='thank you' ):\n            flag=False\n            print(\"Cafebot: You are welcome..\")\n        else:\n            if(greeting(user_response)!=None):\n                print(\"Cafebot: \"+greeting(user_response))\n            else:\n                print(\"Cafebot: \",end=\"\")\n                print(response(user_response))\n                sent_tokens.remove(user_response)\n    else:\n        flag=False\n        print(\"ROBO: Bye! take care..\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}