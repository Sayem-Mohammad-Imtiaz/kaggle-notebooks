{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading csv files"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Users\nu_cols = ['user_id', 'location', 'age']\nusers = pd.read_csv('../input/bookcrossing-dataset/Book reviews/BX-Users.csv', sep=';', names=u_cols, encoding='latin-1',low_memory=False)\n\n#Books\ni_cols = ['isbn', 'book_title' ,'book_author','year_of_publication', 'publisher', 'img_s', 'img_m', 'img_l']\nitems = pd.read_csv('../input/bookcrossing-dataset/Book reviews/BX-Books.csv', sep=';', names=i_cols, encoding='latin-1',low_memory=False)\n\n#Ratings\nr_cols = ['user_id', 'isbn', 'rating']\nratings = pd.read_csv('../input/bookcrossing-dataset/Book reviews/BX-Book-Ratings.csv', sep=';', names=r_cols, encoding='latin-1',low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What does the data look like?"},{"metadata":{"trusted":true},"cell_type":"code","source":"users.head(5)\nusers.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head(5)\nitems.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.head(5)\nratings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users = users.drop(users.index[0])\nitems = items.drop(items.index[0])\nratings = ratings.drop(ratings.index[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging the dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(users, ratings, on='user_id')\ndf = pd.merge(df, items, on='isbn')\ndf.head(5)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing The Dataframe chunk to 1 Lakh because I was running out of memory. you can work with original data which will give you better result."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[:102000]\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dropping null values and Unwanted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf.drop(['img_s','img_m','img_l'],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['age'] = df['age'].astype(int)\ndf['user_id'] = df['user_id'].astype(int)\ndf['rating'] = df['rating'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting location column into newer columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"location = df.location.str.split(', ', n=2, expand=True)\nlocation.columns=['city', 'state', 'country']\n\ndf['city'] = location['city']\ndf['state'] = location['state']\ndf['country'] = location['country']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see which books got highest ratings. As we can see here these 5 books from top got 10/10 rating. Bit suspicious, it is possible that only one user read it and rate it as 10."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('book_title')['rating'].mean().sort_values(ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now we use the count() function to see the number of user that rated the books. In this we can see 'Wild Animus' has the most users rated to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('book_title')['rating'].count().sort_values(ascending=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = pd.DataFrame(df.groupby('book_title')['rating'].mean())\nratings.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings['num of ratings'] = pd.DataFrame(df.groupby('book_title')['rating'].count())\nratings.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings['num of ratings'].hist(bins=80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings['rating'].hist(bins=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='rating',y='num of ratings',data=ratings,alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We now create a pivot table. From this table we use the same users who rated for different books. This is collaborative filtering based recommendation system(similarity between users). "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.pivot_table(index='user_id',columns='book_title',values='rating').fillna(0)\ndf1.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.sort_values('num of ratings',ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Collaborative Filtering Based Recommender\n\n### DV_rating - The Da Vinci Code, LP_rating - Life of Pi, HP_rating - Harry Potter. I'm using these three books for our recomendation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"DV_rating = df1['The Da Vinci Code']\nLP_rating = df1['Life of Pi']\nHP_rating = df1['Harry Potter and the Goblet of Fire (Book 4)']\nDV_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"similar_to_DV = df1.corrwith(DV_rating)\nsimilar_to_LP = df1.corrwith(LP_rating)\nsimilar_to_HP = df1.corrwith(HP_rating)\nsimilar_to_DV.sort_values(ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_DV = pd.DataFrame(similar_to_DV,columns=['correlation'])\ncorr_DV.dropna(inplace=True)\ncorr_DV = corr_DV.join(ratings['num of ratings'])\ncorr_DV.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see different books suggested whose number of ratings are less but has perfect correlation. So lets filter out the number of ratings to 200. This will improve our recommended books."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_DV[corr_DV['num of ratings']>200].sort_values('correlation',ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_LP = pd.DataFrame(similar_to_LP,columns=['correlation'])\ncorr_LP.dropna(inplace=True)\ncorr_LP = corr_LP.join(ratings['num of ratings'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_LP[corr_LP['num of ratings']>200].sort_values('correlation',ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_HP = pd.DataFrame(similar_to_HP,columns=['correlation'])\ncorr_HP.dropna(inplace=True)\ncorr_HP = corr_HP.join(ratings['num of ratings'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_HP[corr_HP['num of ratings']>200].sort_values('correlation',ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}