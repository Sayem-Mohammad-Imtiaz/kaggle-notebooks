{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import shutil\nimport glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('augmented')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd augmented","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir benign","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir malignant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getListOfFiles(dirName):\n    # create a list of file and sub directories \n    # names in the given directory \n    listOfFile = os.listdir(dirName)\n    allFiles = list()\n    # Iterate over all the entries\n    for entry in listOfFile:\n        # Create full path\n        fullPath = os.path.join(dirName, entry)\n        # If entry is a directory then get the list of files in this directory \n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n                \n    return allFiles","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files_benign=getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign')\nfor f in files_benign:\n    if f.endswith('.png'):\n        shutil.copy(f,'augmented/benign')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files_malignant=getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant')\nfor f in files_malignant:\n    if f.endswith('.png'):\n        shutil.copy(f,'augmented/malignant')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onlyfiles = next(os.walk('augmented/benign'))[2] \nbenign=len(onlyfiles)\nonlyfiles = next(os.walk('augmented/malignant'))[2] \nmalignant=len(onlyfiles)\nprint('Total no of files in both benign and malignant is :',malignant+benign)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D,Input,Dropout\nfrom tensorflow.keras.optimizers import Adam,RMSprop\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ig=ImageDataGenerator(rescale=1.0/255.0,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='augmented'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batches = ig.flow_from_directory(directory=path,\n                                       target_size=(224,224),\n                                       classes=['benign', 'malignant'],\n                                       batch_size=16,\n                                       subset='training')\nvalid_batches = ig.flow_from_directory(directory=path,\n                                       target_size=(224,224),\n                                       classes=['benign', 'malignant'],\n                                       batch_size=16,\n                                       subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_batches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs, labels = next(train_batches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(labels),type(imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs.shape,labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_metric(history, metric):\n    train_metrics = history.history[metric]\n    val_metrics = history.history['val_'+metric]\n    epochs = range(1, len(train_metrics) + 1)\n    plt.plot(epochs, train_metrics, 'bo--')\n    plt.plot(epochs, val_metrics, 'ro-')\n    plt.title('Training and validation '+ metric)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([\"train_\"+metric, 'val_'+metric])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotImages(imgs)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batches.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hand made neural net trained from scratch without any image preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    # I/P Layer\n    inputs=Input(batch_shape=(None,224,224,3),name='Input')\n\n    # Conv_1 Layer\n    x=Conv2D(filters=16,kernel_size=3,activation='relu',name='Conv_1')(inputs)\n\n    # Max_pool_1 layer\n    x=MaxPooling2D(name='Max_pool_1')(x)\n\n    # Conv_2 Layer\n    x=Conv2D(filters=32,kernel_size=3,activation='relu',name='Conv_2')(x)\n\n    # Max_pool_2 layer\n    x=MaxPooling2D(name='Max_pool_2')(x)\n    \n    # Conv_3 Layer\n    x=Conv2D(filters=64,kernel_size=3,activation='relu',name='Conv_3')(x)\n\n    # Max_pool_3 layer\n    x=MaxPooling2D(name='Max_pool_3')(x)\n    \n    # Conv_4 Layer\n    x=Conv2D(filters=128,kernel_size=3,activation='relu',name='Conv_4')(x)\n\n    # Max_pool_4 layer\n    x=MaxPooling2D(name='Max_pool_4')(x)\n\n    # Flatten layer\n    x=Flatten()(x)\n    \n    # Dense_1/FC layer\n    x=Dense(256,activation='relu',name='Dense_1')(x)\n    \n    # Droput Layer_1\n    x=Dropout(0.2,name='Dropout_1')(x)\n\n    # Output layer\n    output=Dense(2, activation='softmax',name='Softmax_layer')(x)\n\n    # Create model using Model class\n    model=Model(inputs=inputs,outputs=output)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_model=create_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=simple_model.fit(x=train_batches,\n    steps_per_epoch=len(train_batches),\n    validation_data=valid_batches,\n    validation_steps=len(valid_batches),\n    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metric(history, 'accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metric(history, 'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# At end of 3rd epoch best Cross val accurqcy of 83% has been achieved","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transfer learning without image preprocessing using VGG 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restnet = ResNet50()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"restnet.layers[-2].output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model=Model(inputs=restnet.inputs,outputs=restnet.layers[-2].output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for layer in base_model.layers:\n#     layer.trainable=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=Dense(units=1024,activation='relu',name='fc3')(base_model.output)\noutputs=x=Dense(units=2,activation='softmax',name='Output_layer')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model=Model(inputs=base_model.inputs,outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ig=ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batches = ig.flow_from_directory(directory=path,\n                                       target_size=(224,224),\n                                       classes=['benign', 'malignant'],\n                                       batch_size=16,\n                                       subset='training')\nvalid_batches = ig.flow_from_directory(directory=path,\n                                       target_size=(224,224),\n                                       classes=['benign', 'malignant'],\n                                       batch_size=16,\n                                       subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=final_model.fit(x=train_batches,\n    steps_per_epoch=len(train_batches),\n    validation_data=valid_batches,\n    validation_steps=len(valid_batches),\n    epochs=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metric(history, 'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_metric(history, 'accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# At end of 6th epoch best Cross val accurqcy of 85% has been achieved","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing the images.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bens_color(img):\n    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    image = cv2.resize(image, (224, 224))\n    image=cv2.addWeighted ( image, 4 , cv2.GaussianBlur( image , (0 ,0 ) , 30) ,-4 ,128)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ig=ImageDataGenerator(preprocessing_function=bens_color,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batches = ig.flow_from_directory(directory=path,\n                                       target_size=(224,224),\n                                       classes=['benign', 'malignant'],\n                                       batch_size=16,\n                                       subset='training')\nvalid_batches = ig.flow_from_directory(directory=path,\n                                       target_size=(224,224),\n                                       classes=['benign', 'malignant'],\n                                       batch_size=16,\n                                       subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"imgs, labels = next(train_batches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}