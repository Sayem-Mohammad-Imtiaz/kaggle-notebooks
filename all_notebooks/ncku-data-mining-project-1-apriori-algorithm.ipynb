{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv(\"../input/online-retail-ii-uci/online_retail_II.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display first 5 rows/transactions\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary stats\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for duplicate transactions\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of transactions before duplicates removal : %d \" % df.shape[0])\n# Dropping the duplicated transactions\ndf = df.drop(index=df[df.duplicated()].index)\nprint(\"Number of transactions after duplicates removal  : %d \" % df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for cancelled transactions\ndf[df['Invoice'].astype(str).str[0] == 'C'].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of transactions before dropping the cancelled transactions : %d \" % df.shape[0])\n# Dropping the cancelled transactions\ndf = df.drop(index=df[df['Invoice'].astype(str).str[0] == 'C'].index)\nprint(\"Number of transactions after dropping the cancelled transactions  : %d \" % df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove transactions with missing product description\ndf = df.drop(index=df[df['Description'].isnull()].index)\n# still any missing product descriptions ?\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping transactions with negative quantity \ndf = df.drop(index = df[df['Quantity'] <= 0].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary stats for feature 'Country'\ndf['Country'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transactions count by country\ndf['Country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We will analyse transactions from 'Japan' "},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'Japan'\ndf_country = df[df['Country'] == country]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of unique invoices : %d \" % len(df_country['Invoice'].value_counts()))\nprint(\"Number of unique products : %d \" % len(df_country['Description'].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Product sold quantity per invoice\nfreq = df_country.groupby(['Invoice', 'Description'])['Quantity'].sum()\nfreq.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_freq = freq.unstack().fillna(0).reset_index().set_index('Invoice')\nprod_freq.head(33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set value to 1 for postivie quantity. Anything else set to 0\nproduct_set = prod_freq.applymap(lambda x : 1 if x > 0 else 0 )\nproduct_set.head(33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item dictionary = {Description: Ordinal}\nitem_dict = dict()\nfor i in range(product_set.keys().size):\n    item_dict[product_set.keys()[i]] = 'item_'+str(i+1)\npd.DataFrame.from_dict(item_dict, orient='index').rename(columns={0:'Ordinal'}).head(300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"product_simple_set=product_set.rename(columns=lambda s: item_dict[s])\nproduct_simple_set.head(33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = product_simple_set.shape[0]\nprint (\"Total numer of transactions: %d\" % total)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Frequent Productsets via Apriori Algorithm"},{"metadata":{},"cell_type":"markdown","source":"## Provide Mini-support = 10%"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define mini support = 10%\nmini_sup = 0.1\nprint(\"Mini Support : %2f \" % mini_sup)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate C1\nC1_dict = product_simple_set.sum(axis=0).to_dict()\nC1_tmp = {}\nfor d in C1_dict:\n    C1_tmp[frozenset([d])]=C1_dict[d]/total\nC1 = pd.DataFrame.from_dict(C1_tmp, orient='index').rename(columns={0:'Support'})\nprint(\"Total number of candidate 1-itemsets  : %d \" % C1.shape[0])\nC1.head(300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Generate L1 by C1 and mini support\nL1 = C1[C1['Support']>=mini_sup]\nprint(\"Total number of frequent 1-itemsets  : %d \" % L1.shape[0])\nL1.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L = L1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Determin to prun or not\ndef prun(candidates, l):\n    for candidate in candidates:\n        sub = candidates - frozenset([candidate])\n        if sub not in l:\n            return True\n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate Support\ndef calc_support(candidates):\n    query = ' & '.join(['{}>0'.format(k) for k in candidates])\n    return product_simple_set.query(query).shape[0]/total\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join\ndef generate_ck(Lksub1, k):\n    Ck = {}\n    total_candidates = len(Lksub1.index)\n    candidates = list(Lksub1.index)\n    for i in range(total_candidates):\n        for j in range(1, total_candidates):\n            candidate1 = list(candidates[i])\n            candidate2 = list(candidates[j])\n            candidate1.sort()\n            candidate2.sort()\n            if candidate1[0:k-2]==candidate2[0:k-2]:\n                new_candidates = candidates[i] | candidates[j]\n                if prun(new_candidates, candidates)==False:\n                    Ck[new_candidates]=calc_support(new_candidates)\n    return pd.DataFrame.from_dict(Ck, orient='index').rename(columns={0:'Support'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate C2 by L1\nC2 = generate_ck(L1, 2)\nprint(\"Total number of candidate 2-itemsets  : %d \" % C2.shape[0])\nC2.head(105)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate L2 by C2\nL2 = C2[C2['Support']>=mini_sup]\nprint(\"Total number of frequent 2-itemset  : %d \" % L2.shape[0])\nL2.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L = L.append(L2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate C3 by L2\nC3 = generate_ck(L2, 3)\nprint(\"Total number of candidate 3-itemsets  : %d \" % C3.shape[0])\nC3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate L3 by C3\nL3 = C3[C3['Support']>=mini_sup]\nprint(\"Total number of frequent 3-itemsets  : %d \" % L3.shape[0])\nL3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L = L.append(L3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate C4 by L3\nC4 = generate_ck(L3, 4)\nprint(\"Total number of candidate 4-itemsets : %d \" % C4.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define My Apriori Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_C1(data_frame):\n    total = data_frame.shape[0]\n    C1_dict = product_simple_set.sum(axis=0).to_dict()\n    C1_tmp = {}\n    for d in C1_dict:\n        C1_tmp[frozenset([d])]=C1_dict[d]/total\n    C1 = pd.DataFrame.from_dict(C1_tmp, orient='index').rename(columns={0:'Support'})\n    print(\"Total number of candidate 1-itemsets  : %d \" % C1.shape[0])\n    return total, C1\n\ndef generate_Lk (mini_sup, Ck):\n    Lk = Ck[Ck['Support']>=mini_sup]\n    return Lk\n\n# Define my apriori functions\ndef my_apriori(mini_sup, data_frame, max_k):\n    total, C1 = generate_C1(data_frame)\n    Lksub1 = generate_Lk(mini_sup, C1)\n    print(\"Total number of frequent 1-itemsets  : %d \" % Lksub1.shape[0])\n    C_ALL = [C1]\n    L_ALL = [Lksub1]\n    for i in range(2, max_k+1):\n        Ck = generate_ck(Lksub1, i)\n        if (Ck.shape[0] == 0):\n            break\n        print(\"Total number of candidate %d-itemsets  : %d \" % (i, Ck.shape[0]))\n        Lksub1 = generate_Lk(mini_sup, Ck)\n        print(\"Total number of frequent %d-itemsets  : %d \" % (i, Lksub1.shape[0]))\n        C_ALL.append(Ck)\n        L_ALL.append(Lksub1)\n    return C_ALL, L_ALL","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate different mini-support"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test mini_sup = 18%\nC_18, L_18 = my_apriori(0.18, product_simple_set, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test mini_sup = 15%\nC_15, L_15 = my_apriori(0.15, product_simple_set, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test mini_sup = 10%\nC_10, L_10 = my_apriori(0.1, product_simple_set, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test mini_sup=8%\nC_8, L_8 = my_apriori(0.08, product_simple_set, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Association Rules generation from Frequent Productsets\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"L18 = L_18[0].copy()\nL18.shape[0]\nfor i in range(1, len(L_18)):\n    L18 = L18.append(L_18[i])\nprint(\"There are %d frequent itemsets with mini-support=0.18\" % L18.shape[0])\nL18.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L15 = L_15[0].copy()\nL15.shape[0]\nfor i in range(1, len(L_15)):\n    L15 = L15.append(L_15[i])\nprint(\"There are %d frequent itemsets with mini-support=0.15\" % L15.shape[0])\nL15.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L10 = L_10[0].copy()\nL10.shape[0]\nfor i in range(1, len(L_10)):\n    L10 = L10.append(L_10[i])\nprint(\"There are %d frequent itemsets with mini-support=0.1\" % L10.shape[0])\nL10.head(24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L8 = L_8[0].copy()\nL8.shape[0]\nfor i in range(1, len(L_8)):\n    L8 = L8.append(L_8[i])\nL8.shape[0]\nprint(\"There are %d frequent itemsets with mini-support=0.08\" % L8.shape[0])\nL8.head(803)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert item to product\ndef convert_to_product(items):\n    result = set()\n    for item in items:\n        for k, v in item_dict.items():\n            if (v == item):\n                result.add(k)\n    return frozenset(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CalCulate Confidents\ndef calculate_confident (frequent_df):\n    frequent_products = frequent_df.to_dict()['Support']\n    rules = []\n    sub_set_list = []\n    for product in frequent_products.keys():\n        for sub_set in sub_set_list:\n            if (sub_set.issubset(product)):\n                conf = frequent_products[product]/frequent_products[product - sub_set]\n                rule = (convert_to_product(product - sub_set), convert_to_product(sub_set), conf)\n                if (rule not in rules):\n                    rules.append(rule)\n        sub_set_list.append(product)\n    confident_df = pd.DataFrame(rules, columns=['Occurrence', 'Co-Occurrence', 'Confident'])\n    total = confident_df.shape[0]\n    return total, confident_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confident_10_total, confident_10 = calculate_confident(L10)\nconfident_10.head(confident_10_total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confident_8_total, confident_8 = calculate_confident(L8)\nconfident_8.head(confident_8_total)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mini Confident = 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"mini_conf = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rules_10 = confident_10[confident_10['Confident']>=mini_conf]\nprint (\"Total number of rules: %d\" % rules_10.shape[0])\nrules_10.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rules_8 = confident_8[confident_8['Confident']>=mini_conf]\nprint (\"Total number of rules: %d\" % rules_8.shape[0])\nrules_8.head(11632)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n1. When mini-support is too hight, there are only one-itemsets in frequent itemsets.\n2. When confidence is the same, there are much more association rules with lower mini-support.\n3. There will be too many association rules when mini-support is too low. It's hard to find out what we want."},{"metadata":{},"cell_type":"markdown","source":"# For Project 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"rules_10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nproj3Data = []\nfor item  in rules_8.to_numpy():\n    if (len(item[0]) == 1 and len(item[1]) == 1):\n        proj3Data.append([next(iter(item[0])), next(iter(item[1]))])\npd.DataFrame(proj3Data).to_csv('for_proj3.csv', index = False, header = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}