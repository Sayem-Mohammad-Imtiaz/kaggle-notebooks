{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Welcome simple tf.data experiments\n* [Click for the guide I followed here](https://www.tensorflow.org/tutorials/load_data/text)\n* [Also for keras tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)\n \n### Insights:\n* Don't use tf.data when keras preprocessing is enough\n\n(stopped this because all tensorflow.data.Dataset's will be deprecated for text)\n\n### Instead check this notebooks with keras:\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport os\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\nFILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']\n\nfor name in FILE_NAMES:\n    # get_file utility downloads dataset file from download link\n    # returns path to downloaded file\n    # name = name of downloaded file, cahe_dir = where temporary datasets dir will be downloaded\n    _ = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name, cache_dir = \".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect txt data\nwith open(\"./datasets/cowper.txt\", \"r\") as f:\n    for i in range(5):\n        print(f.readline())\n        \n# Seems like they are poet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parent_dir = os.path.dirname(_)\nlabeled_data_sets = []\n\ndef labeler(example, index):\n  return example, tf.cast(index, tf.int64)  \n\nfor i,file_name in enumerate(FILE_NAMES):\n    # Seems like thsi guy creates object tf.data.Dataset\n    lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name)) # What does this guy do actually?\n    # Apply tf.data.Dataset.map, do not confuse them with the python map function\n    # this is tf method, however behaviours are similar\n    # Took elements(lines) as input and returned tuples (line,i(0,1 or 2)) 2 len tuples\n    labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))\n    labeled_data_sets.append(labeled_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 50000\nBATCH_SIZE = 64\nTAKE_SIZE = 5000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatenate textline data's\nall_labeled_data = labeled_data_sets[0]\nfor labeled_dataset in labeled_data_sets[1:]:\n    all_labeled_data = all_labeled_data.concatenate(labeled_dataset)\n\n\nall_labeled_data = all_labeled_data.shuffle(\n    BUFFER_SIZE, reshuffle_each_iteration=False)\n\n# inspect some examples form dataset\nfor ex in all_labeled_data.take(5):\n    print(ex)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Some insights about dataset.shuffle #####\n\ndataset = tf.data.Dataset.range(10)\nprint(list(dataset.as_numpy_iterator()))\n# buffer size (=2 in this case) indicates that how many elements' position will be changed\ndataset = dataset.shuffle(2, reshuffle_each_iteration=False)\nprint(list(dataset.as_numpy_iterator()))\n\n##### Some insights about dataset.shuffle #####","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode dataset as index numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# build keras tokenizer instead of tensorflow deprecated tokenizer\ntokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True)\n\nvocabulary_set = set()\nfor text_tensor, _ in all_labeled_data:\n    some_tokens = tokenizer.(text_tensor.numpy())\n    print(some_tokens)\n    vocabulary_set.update(some_tokens)\n\nvocab_size = len(vocabulary_set)\nvocab_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# csv_file = tf.keras.utils.get_file('heart.csv', 'https://storage.googleapis.com/applied-dl/heart.csv', cache_dir = \".\") #dosyayı indir vve bir path oluştur\ncsv_file"},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}