{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import python dataset","metadata":{}},{"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# TensorFlow ≥2.0 is required\nimport tensorflow as tf\nfrom tensorflow import keras\nassert tf.__version__ >= \"2.0\"\n\n# Common imports\nimport numpy as np\nimport os\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\nimport pandas as pd\nimport time\nimport functools","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:32.79022Z","iopub.execute_input":"2021-08-23T02:51:32.790609Z","iopub.status.idle":"2021-08-23T02:51:39.090165Z","shell.execute_reply.started":"2021-08-23T02:51:32.790526Z","shell.execute_reply":"2021-08-23T02:51:39.088811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport functools\nimport time\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras.optimizers import Adam\nfrom tensorflow import reduce_mean\nimport gc\nfrom sklearn.preprocessing import *\n","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.091876Z","iopub.execute_input":"2021-08-23T02:51:39.092256Z","iopub.status.idle":"2021-08-23T02:51:39.183351Z","shell.execute_reply.started":"2021-08-23T02:51:39.092215Z","shell.execute_reply":"2021-08-23T02:51:39.182292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport numpy as np\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Reshape, Flatten\n#from keras.layers.merge import _Merge\nfrom keras.layers.convolutional import Convolution2D, Conv2DTranspose\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam\nfrom keras.datasets import mnist\nfrom keras import backend as K\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.185605Z","iopub.execute_input":"2021-08-23T02:51:39.186068Z","iopub.status.idle":"2021-08-23T02:51:39.192487Z","shell.execute_reply.started":"2021-08-23T02:51:39.186023Z","shell.execute_reply":"2021-08-23T02:51:39.191494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.193874Z","iopub.execute_input":"2021-08-23T02:51:39.194139Z","iopub.status.idle":"2021-08-23T02:51:39.216182Z","shell.execute_reply.started":"2021-08-23T02:51:39.194114Z","shell.execute_reply":"2021-08-23T02:51:39.214981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n\ndevice_name = tf.test.gpu_device_name()\nallow_pickle=True","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.217787Z","iopub.execute_input":"2021-08-23T02:51:39.218307Z","iopub.status.idle":"2021-08-23T02:51:39.232465Z","shell.execute_reply.started":"2021-08-23T02:51:39.218249Z","shell.execute_reply":"2021-08-23T02:51:39.231215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.234168Z","iopub.execute_input":"2021-08-23T02:51:39.234715Z","iopub.status.idle":"2021-08-23T02:51:39.248413Z","shell.execute_reply.started":"2021-08-23T02:51:39.234618Z","shell.execute_reply":"2021-08-23T02:51:39.247509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notebookName = 'WGAN.ipynb'\nk = 1","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.249852Z","iopub.execute_input":"2021-08-23T02:51:39.250336Z","iopub.status.idle":"2021-08-23T02:51:39.261661Z","shell.execute_reply.started":"2021-08-23T02:51:39.250293Z","shell.execute_reply":"2021-08-23T02:51:39.260897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.263632Z","iopub.execute_input":"2021-08-23T02:51:39.26402Z","iopub.status.idle":"2021-08-23T02:51:39.275028Z","shell.execute_reply.started":"2021-08-23T02:51:39.263992Z","shell.execute_reply":"2021-08-23T02:51:39.274059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./output/Figures/Individual')\nos.makedirs('./output/Figures/Result')\nos.makedirs('./output/Figures/Prediction')\nos.makedirs('./output/ganmodels')\nos.makedirs( './output/logs/WGAN/generator')\nos.makedirs('./output/logs/WGAN/critic')\nos.makedirs('./output/Figures/Loss')","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.277493Z","iopub.execute_input":"2021-08-23T02:51:39.277898Z","iopub.status.idle":"2021-08-23T02:51:39.2888Z","shell.execute_reply.started":"2021-08-23T02:51:39.277837Z","shell.execute_reply":"2021-08-23T02:51:39.287903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"n_features = 7","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.290378Z","iopub.execute_input":"2021-08-23T02:51:39.290879Z","iopub.status.idle":"2021-08-23T02:51:39.306262Z","shell.execute_reply.started":"2021-08-23T02:51:39.290802Z","shell.execute_reply":"2021-08-23T02:51:39.30523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data= np.loadtxt('../input/pollutant/01.txt') \nprint(data.shape)\n\ndata02= np.loadtxt('../input/pollutant/02.txt') \nprint(data02.shape)\n\ndata04= np.loadtxt('../input/pollutant/04.txt') \nprint(data04.shape)\n\n\ngroups = ['PM10','PM2_5', 'PM1', 'CO2' ,'Temeprature' ,'RH']\ngroups = np.array(groups)\nprint(groups.shape)\n\ngroups2 = ['times','PM10','PM2_5', 'PM1', 'CO2' ,'Temeprature' ,'RH']\ngroups2 = np.array(groups2)\nprint(groups2)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-08-23T02:51:39.307485Z","iopub.execute_input":"2021-08-23T02:51:39.307763Z","iopub.status.idle":"2021-08-23T02:51:39.382623Z","shell.execute_reply.started":"2021-08-23T02:51:39.307731Z","shell.execute_reply":"2021-08-23T02:51:39.381576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize=[20,10])\nax.plot(data[:,0], data[:,1], label='PM10')\nax.plot(data[:,0], data[:,2], label='PM2.5')\nax.plot(data[:,0], data[:,3], label='PM1')\nax.plot(data[:,0], data[:,4], label='CO2')\n\nax.grid()\nplt.ylabel(\"concentration (ppm)\")\nplt.xlabel(\"time (min)\")\nplt.title('Tube')\nplt.legend()\n\n\nfig, ax = plt.subplots(1,1, figsize=[10,5])\nax.plot(data[:,0], data[:,5],c='black', label='Temperature')\nax.grid()\nplt.ylabel(\"RH (%)\")\nplt.xlabel(\"time (min)\")\nplt.title('Humidity')\nplt.legend()\n\n\nfig, ax = plt.subplots(1,1, figsize=[10,5])\nax.plot(data[:,0], data[:,6],c='black', label='RH') #what is the unit?\nax.grid()\nplt.ylabel(\"Celsius\")\nplt.xlabel(\"time (min)\")\nplt.title('Tube')\nplt.legend()\n\nplt.savefig('./output/Figures/Sample_v'+str(k)+'.png')\nplt.show","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:39.386287Z","iopub.execute_input":"2021-08-23T02:51:39.386743Z","iopub.status.idle":"2021-08-23T02:51:40.220329Z","shell.execute_reply.started":"2021-08-23T02:51:39.386702Z","shell.execute_reply":"2021-08-23T02:51:40.219502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Dataset","metadata":{}},{"cell_type":"code","source":"codings_size = n_features\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=[-1,1])\nX_train_scaled = scaler.fit_transform(data)\n\nX_train_scaled.shape \n","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:40.221479Z","iopub.execute_input":"2021-08-23T02:51:40.221746Z","iopub.status.idle":"2021-08-23T02:51:40.229359Z","shell.execute_reply.started":"2021-08-23T02:51:40.22172Z","shell.execute_reply":"2021-08-23T02:51:40.228439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"#plot the original dataset\nfig, ax = plt.subplots(2,4, figsize=[20,10])\nfor i, group in enumerate(groups):\n    #a=i+1\n    ax.flatten()[i].plot(X_train_scaled[:,0], X_train_scaled[:,i+1])\n    ax.flatten()[i].set_title(group)\nplt.savefig('Figures/Individual/Sample'+'_v'+str(k)+'.png')","metadata":{}},{"cell_type":"code","source":"#scaler inverse_transform\nX_train = scaler.inverse_transform(((X_train_scaled)))\nX_train.shape \n\n#fig, ax = plt.subplots(2,4, figsize=[20,10])\n#for i, group in enumerate(groups):\n    #a=i+1\n#    ax.flatten()[i].plot(X_train[:,0], X_train[:,i+1])\n#    ax.flatten()[i].set_title(group)\n#plt.savefig('../output/Figures/Individual/Sample'+'_v'+str(k)+'.png')","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:40.230398Z","iopub.execute_input":"2021-08-23T02:51:40.230668Z","iopub.status.idle":"2021-08-23T02:51:40.244957Z","shell.execute_reply.started":"2021-08-23T02:51:40.230642Z","shell.execute_reply":"2021-08-23T02:51:40.243785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the GAN","metadata":{}},{"cell_type":"markdown","source":"### Preparing the training dataset","metadata":{}},{"cell_type":"code","source":"n = 500","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:40.24628Z","iopub.execute_input":"2021-08-23T02:51:40.246679Z","iopub.status.idle":"2021-08-23T02:51:40.259147Z","shell.execute_reply.started":"2021-08-23T02:51:40.246632Z","shell.execute_reply":"2021-08-23T02:51:40.258129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concat_timesteps(X_train_scaled, ntimes, step):\n    X_train_concat = []\n    for i in range(len(X_train_scaled) - ntimes*step):\n        X_train_concat.append(X_train_scaled[i:i+ntimes*step:step])\n    return np.array(X_train_concat)\n\nntimes = 100 # Consecutive times for the GAN\nstep = 1 # step between times (1 mins)\n\nX_train_concat = concat_timesteps(X_train_scaled, ntimes, step)#X_train_scaled\nX_train_concat = X_train_concat.reshape(X_train_concat.shape[0],ntimes,n_features,1)\nprint(X_train_concat.shape)\n#Individual sample dataset\n\n\nprint(X_train_concat[n].shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:40.260862Z","iopub.execute_input":"2021-08-23T02:51:40.261346Z","iopub.status.idle":"2021-08-23T02:51:40.278582Z","shell.execute_reply.started":"2021-08-23T02:51:40.261295Z","shell.execute_reply":"2021-08-23T02:51:40.277376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nlatent_space = 100\n\n# Create a tensorflow dataset and split it into batches\ntrain_dataset = X_train_concat.reshape(X_train_concat.shape[0], ntimes, n_features,1).astype('float32')\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\ntrain_dataset = train_dataset.shuffle(len(X_train_scaled))\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\n\nfor data in train_dataset:\n    print(data.shape)\n    break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-08-23T02:51:40.2801Z","iopub.execute_input":"2021-08-23T02:51:40.280556Z","iopub.status.idle":"2021-08-23T02:51:40.366931Z","shell.execute_reply.started":"2021-08-23T02:51:40.280513Z","shell.execute_reply":"2021-08-23T02:51:40.366276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wgan = keras.models.load_model('../input/wganmodels/v1_epoch_2700.h5').layers\ngenerator, critic = keras.models.load_model('../input/wganmodels/v1_epoch_2600.h5').layers","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:40.368067Z","iopub.execute_input":"2021-08-23T02:51:40.368323Z","iopub.status.idle":"2021-08-23T02:51:41.730469Z","shell.execute_reply.started":"2021-08-23T02:51:40.368297Z","shell.execute_reply":"2021-08-23T02:51:41.729661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wgan = keras.models.Sequential([generator, critic])","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:41.731414Z","iopub.execute_input":"2021-08-23T02:51:41.731785Z","iopub.status.idle":"2021-08-23T02:51:41.814535Z","shell.execute_reply.started":"2021-08-23T02:51:41.731759Z","shell.execute_reply":"2021-08-23T02:51:41.813814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generated Data","metadata":{}},{"cell_type":"code","source":"#generated data\nn_instances = X_train_concat.shape[0]\nnoise = tf.random.normal([n_instances, latent_space])\ngenerated_image = generator(noise, training=False)\ngenerated_image = generated_image.numpy()\ngenerated_image = generated_image.reshape(n_instances*ntimes*1, n_features)\ngenerated_image = scaler.inverse_transform(generated_image)\n\nprint(generated_image.shape)\n\nfig, ax = plt.subplots(2,4, figsize=[20,10])\n\nfor i, group in enumerate(groups):\n    ax.flatten()[i].plot(generated_image[:,0],generated_image[:,i+1],'o',c='orange')\n    ax.flatten()[i].set_title(group)\n    ax.flatten()[0].set_xlabel(\"time step\")\n    ax.flatten()[0].set_ylabel(\"concentration (ppm)\")\n    \nplt.savefig('./output/Figures/Result/result_v'+str(k)+'.png')\nprint('save generated image')\n\nX_train_concat_flatten2 = X_train_concat.reshape(X_train_concat.shape[0]*ntimes, n_features).astype('float32')\nX_train_concat_flatten2 = scaler.inverse_transform(X_train_concat_flatten2)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:41.943956Z","iopub.execute_input":"2021-08-23T02:51:41.944442Z","iopub.status.idle":"2021-08-23T02:51:57.539378Z","shell.execute_reply.started":"2021-08-23T02:51:41.944399Z","shell.execute_reply":"2021-08-23T02:51:57.538334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(2,4, figsize=[20,10])\nfor i, group in enumerate(groups):\n    ax.flatten()[i].plot(X_train_concat_flatten2[:,0],X_train_concat_flatten2[:,i+1],'o')\n    ax.flatten()[i].set_title(group)\n    ax.flatten()[0].set_xlabel(\"time step\")\n    ax.flatten()[0].set_ylabel(\"concentration (ppm)\")    \n    \nplt.savefig('./output/Figures/Result/sample_v'+str(k)+'.png')","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:51:57.540877Z","iopub.execute_input":"2021-08-23T02:51:57.541297Z","iopub.status.idle":"2021-08-23T02:52:02.799297Z","shell.execute_reply.started":"2021-08-23T02:51:57.541256Z","shell.execute_reply":"2021-08-23T02:52:02.798639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict with the GAN","metadata":{}},{"cell_type":"code","source":"epochs = 2000 \nn = 500\npredict_points = 600 #X_train.shape[0]-n-ntimes","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:52:04.379942Z","iopub.execute_input":"2021-08-23T02:52:04.380374Z","iopub.status.idle":"2021-08-23T02:52:04.385144Z","shell.execute_reply.started":"2021-08-23T02:52:04.380332Z","shell.execute_reply":"2021-08-23T02:52:04.384067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse = tf.keras.losses.MeanSquaredError()\noptimizer = tf.keras.optimizers.Adam(1e-2) \n\ndef mse_loss(inp, outp):\n    inp = tf.reshape(inp, [-1, n_features]) \n    outp = tf.reshape(outp, [-1, n_features])\n    print(\"input:\",inp.shape)\n    print(\"output:\",outp.shape)\n    \n    return mse(inp, outp)\n\n\n\ndef optimize_coding(latent_values, real_coding, epochs):\n    \n    for epoch in range(epochs):\n        opt_step(latent_values, real_coding)\n        \n    return latent_values  #returns the optimized input that generates the desired output\n\n\n@tf.function\ndef opt_step(latent_values, real_coding):\n    with tf.GradientTape() as tape:\n        tape.watch(latent_values)\n        gen_output = generator(latent_values, training=False)  #results from generator\n        loss = mse_loss(real_coding, gen_output[:,:(ntimes - 1),:])   #codings_size is size of each output, ntimes is number of time levels. \n        #If training for 9 time levels, it finds the loss between the first 8 outputs from the generator and 8 real outputs\n\n    gradient = tape.gradient(loss, latent_values)   #gradient of the loss ws to the input\n    optimizer.apply_gradients(zip([gradient], [latent_values]))   #applies gradients to the input\n    \n    return loss\n\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nreal_coding = X_train_concat[n].reshape(1,-1)\nreal_coding = real_coding[:,:n_features*(ntimes - 1)]\nreal_coding = tf.constant(real_coding)\nreal_coding = tf.cast(real_coding, dtype=tf.float32)\n\nlatent_values = tf.random.normal([len(real_coding), latent_space])  \nlatent_values = tf.Variable(latent_values)     #make input a tensorflow variable so it can be trained\nlatent_values = optimize_coding(latent_values, real_coding, epochs)\n\n\nX_predict = list(generator(latent_values).numpy().reshape(-1,codings_size))\ngen_predict = X_predict[-1]\nreal_coding = np.concatenate((real_coding, gen_predict.reshape(1,-1)), axis=1)[:,n_features:]\nreal_coding = tf.constant(real_coding)\nreal_coding = tf.cast(real_coding, dtype=tf.float32)\n\nfor i in range(predict_points): #range(2000,len(X_train_concat)-1):\n    latent_values = optimize_coding(latent_values, real_coding, epochs)\n    gen_predict = generator(latent_values)[:,(ntimes - 1):,:].numpy()\n    X_predict.append(gen_predict.flatten())\n    real_coding = np.concatenate((real_coding, gen_predict.reshape(1,-1)), axis=1)[:,n_features:]\n    real_coding = tf.constant(real_coding)\n    real_coding = tf.cast(real_coding, dtype=tf.float32)\n    \nX_predict = np.array(X_predict)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-08-23T02:52:04.386662Z","iopub.execute_input":"2021-08-23T02:52:04.386926Z","iopub.status.idle":"2021-08-23T02:52:04.732474Z","shell.execute_reply.started":"2021-08-23T02:52:04.386901Z","shell.execute_reply":"2021-08-23T02:52:04.73119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_generated = scaler.inverse_transform(X_predict)\nX_generated = X_generated.reshape(len(X_predict), n_features)\nX_generated[X_generated<0] = 0 \nnp.save('X_generatedall.npy',X_generated)\n        \n    \nfig, ax = plt.subplots(2,4, figsize=[20,10])\nfor i, group in enumerate(groups):\n    #ax.flatten()[i].plot(X_generated[:,i+1], '-',c='orange', label='generated')\n    ax.flatten()[i].plot(X_train[n:(n+ntimes+predict_points),i+1], '-', label='real')\n    ax.flatten()[i].plot(X_generated[:,i+1], '-',c='orange', label='generated')\n    ax.flatten()[i].set_title(group)\n    ax.flatten()[i].legend()\n    \nplt.savefig('./output/Figures/Prediction/00entire_v'+str(k)+'_epoch_'+str(epochs)+'.png')","metadata":{"execution":{"iopub.status.busy":"2021-08-23T02:52:04.733773Z","iopub.execute_input":"2021-08-23T02:52:04.734061Z","iopub.status.idle":"2021-08-23T02:52:06.37881Z","shell.execute_reply.started":"2021-08-23T02:52:04.734023Z","shell.execute_reply":"2021-08-23T02:52:06.378093Z"},"trusted":true},"execution_count":null,"outputs":[]}]}