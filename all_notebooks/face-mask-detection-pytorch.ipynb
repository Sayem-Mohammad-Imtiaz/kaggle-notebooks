{"cells":[{"metadata":{"_uuid":"3fe72c6b-c6cc-4bee-9849-94f7ccc386d4","_cell_guid":"bd8d95b2-578d-47d6-a08c-01b7f22d2a14","trusted":true},"cell_type":"markdown","source":"## Importing neccessary Libraries","execution_count":null},{"metadata":{"_uuid":"ce908569-e847-4358-b7ef-c8687567facb","_cell_guid":"dd35cce3-665d-4eb8-916b-6b87a6cde747","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport matplotlib.patches as patches\nfrom torchvision import torch,datasets,transforms,models\nfrom torch.utils.data import Dataset,DataLoader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the Data","execution_count":null},{"metadata":{"_uuid":"25707fc8-31b0-467f-9534-748f8c4d802a","_cell_guid":"022179d3-4c08-42c6-af42-b4a299f7c8ee","trusted":true},"cell_type":"code","source":"path_images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\ntrain=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"764a7ec0-bbb5-4c48-a137-2a41f829f0bc","_cell_guid":"370b863e-fdaa-41d0-b523-c131952fa6cc","trusted":true},"cell_type":"code","source":"train #quick look into dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab31559a-4172-4f2d-9da3-815acf8d2815","_cell_guid":"f1d73fee-2a98-42d2-92fd-c469ed99bf78","trusted":true},"cell_type":"code","source":"train=train[train.classname.str.contains(\"face_with_mask$|face_no_mask\")] # filtering the data to mask and no mask bales\ntrain.classname.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30d48e76-245e-4e51-b5a7-afddca632a41","_cell_guid":"7aa29647-9813-41fe-ba1c-cf5a6df08a21","trusted":true},"cell_type":"code","source":"#lets lookinto the data after filtering\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3607f05a-f56e-45b7-a4be-6b45e0cae348","_cell_guid":"7a0012fa-fc99-4dba-9641-4ebfbb87bc38","trusted":true},"cell_type":"code","source":"# creating the function to visualize images\ndef draw_box(image_name):\n    img=plt.imread(os.path.join(path_images,image_name))\n    temp=train[train.name==image_name]\n    fig,ax=plt.subplots(1)\n    fig.set_size_inches(10,5)\n    ax.imshow(img)\n    ax.axis('off')\n    edgecolor={\"face_no_mask\":\"r\",\"face_with_mask\":\"b\"}\n    for i in range(len(temp)):\n        a,b,c,d=temp.values[i][1:5]\n        patch=patches.Rectangle((a,b),c-a,d-b,linewidth=2, \n                                edgecolor=edgecolor[temp.values[i][5:6][0]],facecolor=\"none\",)\n        ax.text(a, b, temp.values[i][5:6][0], style='italic',bbox={'facecolor': 'yellow', 'alpha': 0.5, 'pad': 10})\n        ax.add_patch(patch)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"277041b1-8873-475e-a426-9014a3398156","_cell_guid":"4e786054-fd4a-4bda-8bda-aefcb1e591e7","trusted":true},"cell_type":"code","source":"draw_box(random.choice(train.name.values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the dataset for training...","execution_count":null},{"metadata":{"_uuid":"3cf5d61a-a5e6-448a-bbc4-2272a792a4c9","_cell_guid":"b63a0a60-f9c1-4183-9c34-8da392e4bb31","trusted":true},"cell_type":"code","source":"#defining sizes for testing and training the images\ntrain_size=int(len(train)*0.8)\ntest_size=int(len(train))-train_size","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00b91ea7-f960-46c7-990b-feada3d06dc9","_cell_guid":"92a92d24-392b-40f5-a8d5-f325386a0f0d","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlbl=LabelEncoder()\ntrain[\"labels\"]=lbl.fit_transform(train.classname)\ntrain.to_csv(\"new.csv\", header=False)\ntrain_new=pd.read_csv(\"./new.csv\",header=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6077794-69c7-4013-85b2-d0a6d8294536","_cell_guid":"943e8125-eb45-40ea-aa42-a5c34181d29c","trusted":true},"cell_type":"code","source":"class MaskAndNoMask(Dataset): \n    def __init__(self,dataframe,root_dir,transform=None):\n        self.annotation=dataframe\n        self.root_dir=root_dir\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.annotation)\n    \n    def __getitem__(self,index):\n        img_path=os.path.join(self.root_dir,self.annotation.iloc[index,1])\n        new_img=Image.open(img_path).crop((self.annotation.iloc[index,2:6]))\n        label=torch.tensor(int(self.annotation.iloc[index,7:8]))\n    \n        if self.transform:\n            image=self.transform(new_img)\n            return(image,label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6951986b-43d0-4285-968a-bcb1df48e7c4","_cell_guid":"d71a9a55-3a51-4e77-b1e5-5a62967c34b7","trusted":true},"cell_type":"code","source":"my_transform=transforms.Compose([transforms.Resize((224,224)),\n                                 transforms.RandomCrop((224,224)),\n                                 transforms.ToTensor()])\n\ndataset=MaskAndNoMask(dataframe=train_new,root_dir=path_images,transform=my_transform)\n\nbatch_size=32\n\ntrainset,testset=torch.utils.data.random_split(dataset,[train_size,test_size])\ntrain_loader=DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True)\ntest_loader=DataLoader(dataset=testset,batch_size=batch_size,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b631a08-477b-4295-84ed-a76217af4a66","_cell_guid":"cb3725d0-a48f-4131-94d2-866800f91cce","trusted":true},"cell_type":"code","source":"dataiter=iter(train_loader)\nimages,labels=dataiter.next()\nimages=images.numpy()\n\nfig=plt.figure(figsize=(25,4))\nfor idx in np.arange(20):\n    ax=fig.add_subplot(2,20/2,idx+1,xticks=[],yticks=[])\n    plt.imshow(np.transpose(images[idx],(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## downloading the Pretrained model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f401dfe5-81c5-4faa-b1dc-5676a11de856","_cell_guid":"4902f17e-b829-4049-a700-d31cbb25c6c9","trusted":true},"cell_type":"code","source":"resnet=models.resnet34(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e39166c-b93b-4edb-9d15-a15d27b05533","_cell_guid":"4270a0ae-1f47-44a2-a963-3be7de783808","trusted":true},"cell_type":"code","source":"for param in resnet.parameters():\n    param.requires_grad=False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"784eb1f0-ba4d-4756-9b75-781c47c2f7e0","_cell_guid":"fb64ebb6-5f7c-4d16-bc78-4c2133b3db8f","trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device(\"cuda\")\n    print(\"gpu available {}\".format(torch.cuda.device_count()))\n    print(\"device name {}\".format(torch.cuda.get_device_name(0)))\nelse:\n    device=torch.device(\"cpu\")\n    print(\"No gpu avalable,traing on cpu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8dcf634a-753c-4c97-84a4-2a942da2a2f6","_cell_guid":"a2f2d5e8-0ce5-43a6-abcd-f1825ad73755","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nn_inputs=resnet.fc.in_features\nlast_layer=nn.Linear(n_inputs,2)\nresnet.fc.out_features=last_layer\n\nif torch.cuda.is_available():\n    resnet.cuda()\n\nprint(resnet.fc.out_features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f2cae4c-9d99-4b4c-aa34-27c9ce44b8fc","_cell_guid":"7e160158-7f76-495c-aef7-247a93925aed","trusted":true},"cell_type":"code","source":"for param in resnet.parameters():\n    param.requires_grad=True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining Loss function and optimizer","execution_count":null},{"metadata":{"_uuid":"dffe04bb-1c0f-474c-a6ee-be8840d73ee1","_cell_guid":"03cc8e27-e428-443e-b68a-6397412affa8","trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\ncriterion=nn.CrossEntropyLoss()\noptimizer=optim.SGD(resnet.parameters(),lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model","execution_count":null},{"metadata":{"_uuid":"62e17db3-5669-491c-a9e5-bb03ec967cc7","_cell_guid":"3101a0e8-026c-466d-8a7c-17d66b78a831","trusted":true},"cell_type":"code","source":"n_epochs=3\nepochs=[]\ntraining_loss=[]\n\nfor epoch in range(1,n_epochs+1):\n    train_loss=0\n    epochs.append(epoch)\n    \n    \n    for batch,(data,target) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            data,target=data.cuda(),target.cuda()\n\n        optimizer.zero_grad()\n        output=resnet(data)\n        loss=criterion(output,target)\n        loss.backward()\n        optimizer.step()\n        train_loss+=loss.item()\n     \n        if batch%20==19:\n            print(\"Epoch {}, batch {}, training loss {}\".format(epoch,batch+1,train_loss/20))\n            training_loss.append(train_loss) \n            train_loss=0.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing the Model","execution_count":null},{"metadata":{"_uuid":"784e697e-c9eb-4b8d-ad47-e5eb76e1ef4c","_cell_guid":"419f7a22-2bc9-4c8e-a3f8-8927194f9937","trusted":true},"cell_type":"code","source":"test_loss=0\nacc=0\nresnet.eval()\n\nfor data,target in test_loader:\n    if torch.cuda.is_available():\n        data,target=data.cuda(),target.cuda()\n    output=resnet(data)\n    loss=criterion(output,target)\n    test_loss+=loss.item()\n    _,pred=torch.max(output,1)\n    predicted=pred.numpy()[:,np.newaxis] if not torch.cuda.is_available() else pred.cpu().numpy()[:,np.newaxis]\n    actual=target.numpy()[:,np.newaxis] if not torch.cuda.is_available() else target.cpu().numpy()[:,np.newaxis]    \n    acc+=np.sum(predicted==actual)/len(test_loader)\n    \navg_loss=test_loss/len(test_loader)\navg_acc=acc/len(test_loader)\n\nprint(\"Average total loss is {:.6f}\".format(avg_loss))\nprint(\"Average total accuracy is {:.6f}\".format(avg_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving and Loading the saved model","execution_count":null},{"metadata":{"_uuid":"fe0fa9f6-fc28-4caf-a4af-b08cfcbb6f9d","_cell_guid":"13e9ce32-5d53-4a94-ba2e-dff4a7d05ee9","trusted":true},"cell_type":"code","source":"torch.save(resnet,open(\"resnet_face_mask_detect\",\"wb\"))\nmodel=torch.load(open(\"./resnet_face_mask_detect\",\"rb\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3b3bf94-9dd3-49a8-b9fa-b6c8b6585fd8","_cell_guid":"93f78551-215c-4773-a124-d9375db7933b","trusted":true},"cell_type":"markdown","source":"## downloading facenet model for predicting faces,which would be the input for our current model.\nthis is neccessary for predicting the images other than this dataset,since image file will not have facial information.","execution_count":null},{"metadata":{"_uuid":"b4380b5f-ed91-420f-8d6d-eb94572207c8","_cell_guid":"a8a2f205-6816-4fce-b2b9-de9e176bf47d","trusted":true},"cell_type":"code","source":"!pip install facenet-pytorch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94bbe9c9-c32f-4680-b844-591aed64bc62","_cell_guid":"ece01d5f-9992-48f2-8df9-1068a17a231d","trusted":true},"cell_type":"code","source":"from facenet_pytorch import MTCNN\nmtcnn = MTCNN()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce69d373-2dd3-4c16-96a1-3d2a057fbe56","_cell_guid":"833abe24-ff20-4803-b8b6-ed884d089751","trusted":true},"cell_type":"code","source":"model=model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TagImages():\n    def __init__(self):\n        \n        self.filepath=filepath\n        img=Image.open(self.filepath)\n        boxes, _ = mtcnn.detect(img)\n        predictions=[]\n        for i in boxes:\n            im_pr=img.crop(i)\n            predict_im=my_transform(im_pr).unsqueeze(0)\n            output=model(predict_im.cuda())\n            _,pred=torch.max(output,1)\n            predicted=pred.numpy() if not torch.cuda.is_available() else pred.cpu().numpy()\n            predictions.append(predicted[0])\n        self.boxes=boxes\n        self.predictions=predictions\n        \n    def draw_box_predicted(self,filepath):\n        img=plt.imread(self.filepath)\n        fig,ax=plt.subplots(1)\n        fig.set_size_inches(10,5)\n        ax.imshow(img)\n        ax.axis('off')\n        configuration=[\"face_no_mask\", \"face_with_mask\"]\n        color={\"face_no_mask\":\"r\",\"face_with_mask\":\"b\"}\n        for i,j in zip(self.boxes,self.predictions):\n            a,b,c,d=i\n            patch=patches.Rectangle((a,b),c-a,d-b,linewidth=2, \n                                    edgecolor=color[configuration[j]],facecolor=\"none\",)\n            ax.text(a, b, configuration[j],\n                    style='italic',bbox={'facecolor': color[configuration[j]], 'alpha': 0.4, 'pad': 10})\n            ax.add_patch(patch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath=os.path.join(path_images,random.choice(train.name.values))\nTagImages().draw_box_predicted(filepath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I am a Beginner here, please feel free to comment.that will help me to move forward\n\n### Thanks in Advance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}