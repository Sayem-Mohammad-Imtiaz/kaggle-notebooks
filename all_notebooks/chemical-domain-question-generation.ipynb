{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-03T17:46:22.65501Z","iopub.execute_input":"2021-09-03T17:46:22.655345Z","iopub.status.idle":"2021-09-03T17:46:22.678506Z","shell.execute_reply.started":"2021-09-03T17:46:22.655266Z","shell.execute_reply":"2021-09-03T17:46:22.677616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U sentence-transformers ","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:46:22.679825Z","iopub.execute_input":"2021-09-03T17:46:22.680169Z","iopub.status.idle":"2021-09-03T17:46:32.377673Z","shell.execute_reply.started":"2021-09-03T17:46:22.680134Z","shell.execute_reply":"2021-09-03T17:46:32.376713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport gzip\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport torch\nimport tqdm\nimport os\nimport pandas as pd\nfrom sentence_transformers import util\n\nparagraphs = set()\n\n# Load Chemicals domain corpus\ncorpus_filepath = '/kaggle/input/industrial-chemical-domain-corpus/chemical_domain_corpus.csv'\nparagraphs = set(pd.read_csv(corpus_filepath).context.values)\nparagraphs = list(paragraphs)\nparagraphs = [paragraph for paragraph in paragraphs if len(paragraph)>100]\nparagraphs = [paragraph.replace(\"\\t\", \" \").replace(\"\\n\", \" \").strip() for paragraph in paragraphs if len(paragraph)>100 and ':' not in paragraph]\nlen(paragraphs)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:46:32.379643Z","iopub.execute_input":"2021-09-03T17:46:32.379971Z","iopub.status.idle":"2021-09-03T17:46:57.746209Z","shell.execute_reply.started":"2021-09-03T17:46:32.379933Z","shell.execute_reply":"2021-09-03T17:46:57.745437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# No we load the model that is able to generate queries given a paragraph.\n# This model was trained on the MS MARCO dataset, a dataset with 500k\n# queries from Bing and the respective relevant passage\ntokenizer = T5Tokenizer.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')\nmodel = T5ForConditionalGeneration.from_pretrained('BeIR/query-gen-msmarco-t5-large-v1')\nmodel.eval()\n\n#Select the device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel.to(device)\n\n# Parameters for generation\nbatch_size = 8 #Batch size\nnum_queries = 2 #Number of queries to generate for every paragraph\nmax_length_paragraph = 512 #Max length for paragraph\nmax_length_query = 64   #Max length for output query\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:46:57.747692Z","iopub.execute_input":"2021-09-03T17:46:57.74803Z","iopub.status.idle":"2021-09-03T17:48:33.314245Z","shell.execute_reply.started":"2021-09-03T17:46:57.747994Z","shell.execute_reply":"2021-09-03T17:48:33.313411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now for every paragraph in our corpus, we generate the queries\ndataset = []\n#with open('/kaggle/working/generated_queries.tsv', 'w') as fOut:\nfor start_idx in tqdm.trange(0, len(paragraphs), batch_size):\n    sub_paragraphs = paragraphs[start_idx:start_idx+batch_size]\n    inputs = tokenizer.prepare_seq2seq_batch(sub_paragraphs, max_length=max_length_paragraph, truncation=True, return_tensors='pt').to(device)\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length_query,\n        do_sample=True,\n        top_p=0.95,\n        num_return_sequences=num_queries)\n\n    for idx, out in enumerate(outputs):\n        query = tokenizer.decode(out, skip_special_tokens=True)\n        para = sub_paragraphs[int(idx/num_queries)]\n        query = query.replace(\"\\t\", \" \").strip()\n        para = para.replace(\"\\t\", \" \").replace(\"\\n\", \" \").strip()\n        dataset.append({\n            \"question\": query,\n            \"context\": para\n        })\n            #fOut.write(\"{} | {}\\n\".format(, ))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:48:33.315536Z","iopub.execute_input":"2021-09-03T17:48:33.315873Z","iopub.status.idle":"2021-09-03T17:48:38.684087Z","shell.execute_reply.started":"2021-09-03T17:48:33.315839Z","shell.execute_reply":"2021-09-03T17:48:38.681354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(dataset).to_csv('/kaggle/working/generated_queries.csv', index=False, encoding='utf-8-sig')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T17:48:38.685272Z","iopub.status.idle":"2021-09-03T17:48:38.685963Z"},"trusted":true},"execution_count":null,"outputs":[]}]}