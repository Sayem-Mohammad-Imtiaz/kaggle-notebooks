{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Learning Pytorch\nThis series would be taken from various tutorial available in youtube.\n\n## 1 : Creating a simple convolutional neural network\nThis one is taken from excellent channel Alladin Perrson : https://www.youtube.com/watch?v=Jy4wM2X21u0&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=3\n\n![](https://i.morioh.com/200620/5b0ea047.jpg)","metadata":{}},{"cell_type":"markdown","source":"## Handling imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## creating the model","metadata":{}},{"cell_type":"code","source":"class SimpleNN(nn.Module):\n    def __init__(self, model_size, num_of_classes):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(model_size, 48)\n        self.fc2 = nn.Linear(48, num_of_classes)\n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = F.relu(out)\n        out = self.fc2(out)\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, in_channels=1, classes=10):\n        super(SimpleCNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=8, \n            padding=(1,1), \n            kernel_size=(3,3), \n            stride=(1,1)) # same convolution, input will be same as output\n        \n        self.conv2 = nn.Conv2d(\n            in_channels=8, \n            out_channels=16, \n            padding=(1,1), \n            kernel_size=(3,3), \n            stride=(1,1))\n        \n        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n        self.fc1 = nn.Linear(16*7*7, classes)\n    \n    def forward(self, x):\n        out = F.relu(self.conv1(x))\n        out = self.pool(out)\n        out = F.relu(self.conv2(out))\n        out = self.pool(out)\n        out = out.reshape(out.shape[0], -1)\n        out = self.fc1(out)\n        return out\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, in_channels=1, num_classes=10):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=8,\n            kernel_size=(3, 3),\n            stride=(1, 1),\n            padding=(1, 1),\n        )\n        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        self.conv2 = nn.Conv2d(\n            in_channels=8,\n            out_channels=16,\n            kernel_size=(3, 3),\n            stride=(1, 1),\n            padding=(1, 1),\n        )\n        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc1(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting device information","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Putting in the hyper parameters","metadata":{}},{"cell_type":"code","source":"num_epochs = 5\nlearning_rate = 0.001\nbatch_size=64\n# input_size=784\nin_channels=1\nnum_of_classes=10\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the dataset","metadata":{}},{"cell_type":"code","source":"# try:\n#     train_dataset = datasets.MNIST(root='./dataset/', download=True, train=True, transform=transforms.ToTensor())\n#     test_dataset = datasets.MNIST(root='./dataset/', download=True, train=False, transform=transforms.ToTensor())\n#     train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n#     test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size, shuffle=True)\n# except Exception as e:\n#     print(e)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"since getting a from interenet isn't reliable lets try with a dataset from csv\n\n## Custom data set class\n\nwith help from https://www.youtube.com/watch?v=PXOzkkB5eH0","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"testing","metadata":{}},{"cell_type":"code","source":"# xy = np.loadtxt('../input/mnist-in-csv/mnist_train.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n# x = xy[:,1:]\n# y = xy[:,[0]]\n# print(x, y)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndd = pd.read_csv('../input/mnist-in-csv/mnist_train.csv', dtype=np.float)\ndd.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_dash = torch.from_numpy(dd.iloc[:,0].values) # y\ny_dash","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(y_dash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dd.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_dash = torch.from_numpy(dd.iloc[:,1:].values)\n\n# x_dash[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(x_dash)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_d = x_dash.reshape(x_dash.size(0), 1, 28,28)\nx_d.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"testing over","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass MnistDataset(Dataset):\n    def __init__(self, data_path):\n        # data loading\n        df = pd.read_csv(data_path, dtype=np.float)\n        self.x = torch.from_numpy(df.iloc[:,1:].values)\n        \n        self.x = self.x.reshape(self.x.size(0),1,28,28)\n        self.x = self.x.float() # why float?\n        \n        self.y = torch.from_numpy(df.iloc[:,0].values) \n        self.y = self.y.long() # why long?\n        \n        self.n_samples = df.shape[0]\n        \n    def __len__(self):\n        return self.n_samples\n    \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = MnistDataset(\"../input/mnist-in-csv/mnist_train.csv\")\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n\ntest_dataset = MnistDataset(\"../input/mnist-in-csv/mnist_test.csv\")\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also look at individual dataset that loaded","metadata":{}},{"cell_type":"code","source":"first = train_dataset[0]\nfeatures, label = first\n# print(features, label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## initialising the model","metadata":{}},{"cell_type":"code","source":"model = SimpleCNN().to(device=device) # to device?","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing\nx = torch.randn(64,1,28,28).to(device=device)\ny = model(x)\ny.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define loss criterion and optimizer","metadata":{}},{"cell_type":"code","source":"loss_criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train on data","metadata":{}},{"cell_type":"code","source":"current_loss = 0\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(train_dataloader):\n        # Get data to cuda if possible\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n        \n#         data = data.reshape((data.shape[0],1,28,28))\n#         print(f\"data shape: {data.shape}\")\n\n        # forward\n        scores = model(data)\n        loss = loss_criterion(scores, targets)\n        current_loss = loss\n        \n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # gradient descent or adam step\n        optimizer.step()\n    \n    print(f\"At epoch: {epoch}, loss: {current_loss}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_accuracy(model, dataloader):\n    \n    total_sample = 0\n    correct_sample = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        for x, y in dataloader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n#             x = x.reshape(x.shape[0], -1)\n            \n            scores = model(x)\n            _, predictions = scores.max(1)\n            correct_sample += (y==predictions).sum()\n            total_sample += predictions.size(0)\n            \n    model.train()\n    \n    print(f\"out of total sample : {total_sample}  correct sample : {correct_sample} accuracy : {float(correct_sample/total_sample)*100:.2f}\")\n            \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_accuracy(model, train_dataloader)\ncheck_accuracy(model, test_dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}