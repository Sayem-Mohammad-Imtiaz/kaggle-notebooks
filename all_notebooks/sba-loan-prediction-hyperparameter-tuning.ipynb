{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n\n\n\ndf = pd.read_csv(\"../input/sba-loans-case-data-set/SBAcase.11.13.17.csv\")\n\ndf = df.select_dtypes(exclude = 'object')\n#removes 'ChgOffDate' and 'BalanceGross' features\ndf = df.loc[:, df.columns != 'ChgOffDate']\ndf = df.loc[:, df.columns != 'BalanceGross']\ndf = df.loc[:, df.columns != 'Zip']\n#remove remaining NA values\ndf = df.dropna()\nx_train, x_test, y_train, y_test = train_test_split(df.iloc[:,0:df.shape[1]-1], df.iloc[:,df.shape[1]-1], test_size = .2)\nscaler = StandardScaler()\nscaler.fit(x_train)\n\nx_train_scaled = scaler.transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n\nprint('Loan Default percentage in training set: %.1f%%' % (100*np.mean(y_train)))\nprint('Loan Default percentage in test set: %.1f%%' % (100*np.mean(y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Learning Curve f1 score of various training sizes graphed\nSeaborn is used to graph the change in f1 over increasing training set sizes. The graph shows a small gap between the validation and training set f1 score, but both continue to converge with more training examples. F1 was used for its combination of both accuracy and percision, but similar results were found using balanced_accuracy and other metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings  \nwarnings.filterwarnings('ignore')\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, ShuffleSplit\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.neural_network import MLPClassifier\n\n# 1342 is max size of training set, with 20% removed for cross validation\nbigtrain_sizes = list(range(1,int(len(x_train)*.8)))\ntrain_sizes = [1]\nfor i in bigtrain_sizes:\n    if i % 100 == 0:\n        train_sizes.append(int(i))\ntrain_sizes.append(1342)\n\n\nclf = MLPClassifier(batch_size=10, verbose=False, early_stopping=True)\ncv = ShuffleSplit(n_splits=10, test_size=0.2)\ntrain_sizes, train_scores, validation_scores = learning_curve(estimator= clf, X = x_train_scaled, y = y_train, train_sizes = train_sizes, cv = cv, scoring = 'f1', verbose = 0)\ntrain_scores_mean = train_scores.mean(axis =1)\nvalidation_scores_mean = validation_scores.mean(axis = 1)\n\n\nplt.style.use('seaborn')\nplt.plot(train_sizes, train_scores_mean, label = \"Training Error\")\nplt.plot(train_sizes, validation_scores_mean, label = \"Validation Error\")\nplt.ylabel('f1', fontsize = 14)\nplt.xlabel('Training set size', fontsize = 14)\nplt.title(\"Learning curves\", fontsize = 14)\nplt.legend()\nplt.ylim(0,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation Curve used for hyperparameter tuning\nI experimented with various activation functions, learning rates, hidden layer sizes, and solver functions to try and find ideal hyperparameters. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import validation_curve\n\nx_train_, x_val, y_train_, y_val = train_test_split(x_train_scaled, y_train, test_size = .2)\n\n# hidden_layer_sizes params\nbighidden_sizes = list(range(1,501))\nhidden_param_range = [1]\nfor i in bighidden_sizes:\n    if i % 20 == 0:\n        hidden_param_range.append(int(i))\nparam_range_len = np.arange(len(hidden_param_range))\n\n# solver params\nsolver_param_range = ('lbfgs', 'sgd', 'adam')\n\n# activation params\nact_param_range = ('identity', 'logistic', 'tanh', 'relu')\n\n# learning_curve params\nlearn_param_range = ('constant', 'invscaling', 'adaptive')\n\nparam_range = act_param_range\n\nclf = MLPClassifier(batch_size=10, hidden_layer_sizes = [50], solver = 'lbfgs', activation = 'identity', verbose=False, early_stopping=True)\ncv = ShuffleSplit(n_splits=10, test_size=0.2)\ntrain_scores, validation_scores = validation_curve(estimator= clf, X = x_train_, y = y_train_, param_name = 'activation', param_range = param_range, cv = cv, scoring = 'accuracy', verbose = 0)\ntrain_scores_mean = train_scores.mean(axis =1)\nvalidation_scores_mean = validation_scores.mean(axis = 1)\n# print(pd.Series(train_scores_mean, index = train_sizes))\n# print(pd.Series(validation_scores_mean, index = train_sizes))\nprint(validation_scores_mean)\n\nplt.style.use('seaborn')\nplt.plot(param_range, train_scores_mean, label = \"Training Error\")\nplt.plot(param_range, validation_scores_mean, label = \"Validation Error\")\nplt.ylabel('F1 Score', fontsize = 14)\nplt.xlabel('Activation function', fontsize = 14)\nplt.title(\"Learning curves\", fontsize = 14)\nplt.legend()\nplt.ylim(.7,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MLPClassifier model with ideal parameters found using validation curves\nThe identity activation function, invscaling learning rate, and lbfgs solver were found to improve accuracy the most using various validation curves. Hidden layers sizes between 1 and 500 were also experimented with, but only using one hidden layer. I intend of incorporate tuning on multiple hidden layers in the future."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, log_loss, f1_score\nimport seaborn as sns\n\nx_train_, x_val, y_train_, y_val = train_test_split(x_train_scaled, y_train, test_size = .2)\n\n#dummy model accuracy (baseline)\ndummy_model = DummyClassifier(strategy = \"most_frequent\")\ndummy_model.fit(x_train_scaled,y_train)\ndummy_acc = dummy_model.score(x_test_scaled,y_test)*100\ndumb_pred = dummy_model.predict(x_test_scaled)\nprint('Dummy model accuracy: %.3f%%' % dummy_acc)\n\ndef getModel():\n    model = MLPClassifier(batch_size=10, solver = 'lbfgs', learning_rate = 'invscaling', activation = 'identity', hidden_layer_sizes = 1, verbose=False, early_stopping=True)\n    model.fit(x_train_,y_train_)\n    return model\n    \nmodel = getModel()\n\n# 10 fold cross validation score\ncv = ShuffleSplit(n_splits=10, test_size=0.2)\nresults = cross_val_score(model, x_train_, y_train_, cv=cv)\nprint('Training set k-fold cross validation mean accuracy: %.3f%%' % (100*np.mean(results)))\n\n#basic predict - validation set\ny_pred1 = model.predict(x_val)\npred_accuracy_percentage1 = 100 * accuracy_score(y_val,y_pred1)\nprint('Validation set accuracy: %.3f%%' % pred_accuracy_percentage1)\n\n#basic predict - test set\ny_pred = model.predict(x_test_scaled)\npred_accuracy_percentage = 100 * accuracy_score(y_test,y_pred)\nprint('Test set accuracy: %.3f%%' % pred_accuracy_percentage)\n\n#ROC AUC metric\n# pred_auc = model.predict(x_test)\npred_auc = model.predict_proba(x_test_scaled)[:,1]\nacc = roc_auc_score(y_test, pred_auc)\nprint('AUC: %.3f%%' % (100*acc))\n\n#log loss metric\nlloss = log_loss(y_test,pred_auc, normalize = True)\nprint('Log loss: %.3f' % lloss)\n\n#f1_score\nf1 = f1_score(y_test,y_pred)\nprint('F1 Score: %.3f' % f1)\n\n#Confusion Matrix\nplt.figure()\nax = plt.axes()\ncm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm, annot = True, fmt = 'd', ax = ax)\nax.set_title('Confusion Matrix of Loan Default Classifier')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}