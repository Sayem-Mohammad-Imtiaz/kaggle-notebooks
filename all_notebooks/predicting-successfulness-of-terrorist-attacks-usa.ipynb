{"cells":[{"metadata":{"_uuid":"ff3bc7d40459baa0a8b26d4294eec630ded00a5c"},"cell_type":"markdown","source":"**Predicting whether a terrorist attack in the USA would be successful**\n\nRecently, I stumbled upon a kernel by Jan Nordin that aimed to predict the successfulness of terrorist attacks in Europe. I found the kernel fascinating and so aim to replicate the procedure with a different region (North America) and a different y value. I will also try to extend it, for example by predicting the kill count of terrorist attacks as well as whether they are successul. As this is the first time I have ever used Pandas and ML it will largely be a copy of his work so I encourage you to look at his original version - it also has a very good version of some of the variables. \n\nThe Global Terrorism Database (GTD) is an open-source database including information on terrorist attacks around the world from 1970 through 2016. It includes systematic data on terrorist incidents that have occurred during this time period and now includes more than 170,000 cases (records).\n\nThis analysis focuses on terrorist attacks in the USA during this 46-year period, which includes 2758 incidents (records). Each incident in the GTD is described with almost 58 variables. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nimport plotly.graph_objs as go \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.externals.six import StringIO  \n#import pydotplus\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor as rfr\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.tree import DecisionTreeRegressor as dtr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fccc0edaf402602859134433c99cd9020fb1ab6"},"cell_type":"code","source":"input_file = \"../input/globalterrorismdb_shorter.csv\"\ndf = pd.read_csv(input_file, header = 0,usecols=['iyear', 'imonth', 'iday', 'extended', 'country', 'country_txt', 'region', 'latitude', 'longitude','success', 'suicide','attacktype1','attacktype1_txt', 'targtype1', 'targtype1_txt', 'natlty1','natlty1_txt','weaptype1', 'weaptype1_txt' ,'nkill','multiple', 'individual', 'claimed','nkill','nkillter', 'nwound', 'nwoundte'])\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dfe58c0829e0894b611eae501c1dce6adb3a05e"},"cell_type":"markdown","source":"We can see from the head of the data frame that the nkill, nkillter, nwound, nwoundte variables have many NaN values which will have to be removed or replaced."},{"metadata":{"trusted":true,"_uuid":"e431821f617428809c29fe137e2d3ec7899f53d5"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4db7209e2c130259be7fb428e5a6d912b5d89b54"},"cell_type":"markdown","source":"Next, we narrow down the data frame to only hold the terrorist attacks in the USA. "},{"metadata":{"trusted":true,"_uuid":"78fea67a699be9394bb791b4863d484f4d3dbad2"},"cell_type":"code","source":"df_USA = df[df.country == 217]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96828d4cc48b493dbb5f11053fd59ac34fc529a3"},"cell_type":"code","source":"df_USA.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29e429a3c2567186b4e9d13782b9ff8082e2ead5"},"cell_type":"code","source":"df_USA.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6fd584dc0d801443db57a1d616affd675ab999a"},"cell_type":"markdown","source":"We can see from the df_USA.info() command that there are too many missing values in nkillter, nwoundte and claimed so they should be removed. In addition, there is no need for the region, country, or country_txt fields anymore as all the terrorist attacks were in the USA. Though there are null values for many of the fields as well, particularly nkill and nwound, these are not as significant."},{"metadata":{"trusted":true,"_uuid":"c42d19797da13f4fbca8ff062017449f2ad53d23"},"cell_type":"code","source":"df_USA = df_USA.drop([ 'region', 'country', 'country_txt','claimed', 'nkillter', 'nwoundte'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8ba0dd4767ddb6a89fe55313169c5f486425e72"},"cell_type":"code","source":"df_USA.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"967405908afcb3c45e424fb6a2259a5013c4dbf2"},"cell_type":"code","source":"df_USA.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Statistical average of Attacks in USA**\n1. The average time for a terrorist attack was mid June \n2. The average terrorist attack was a successful, isolated hijacking against aircraft/airports carried out by someone not affiliated with a terrorist group. \n3. The average terrorist attack was less than 24 hours, involved fake weapons but still managed to kill 1.35 people and wound on average just less than 7. \n4. The average terrorist attack in the USA took place in West Plains, Missouri. \n5. The average intended victim was from Tuvalu.\n\nNaturally, please take these averages with a pinch of salt. They seem to get progressively more outlandish from top to bottom.\n\n**MAPPING**"},{"metadata":{"trusted":true,"_uuid":"57f0fafa30fc950d0971c350b81d95f7c143387e"},"cell_type":"code","source":"df_USA.plot(kind= 'scatter', x='longitude', y='latitude', alpha=0.4, figsize=(16,7))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"ba1728fd04d664219fafd9a3401caa2001d3b0ae"},"cell_type":"markdown","source":"**REMOVING ERRORS**\n\nQuite how it is possible that this is displaying terrorist attacks in Mongolia I do not know. I will now investigate this by sorting the dataset by latitude. Also to investigate other outliers that appear to be in areas like Hawaii and Alaska and Puerto Rico."},{"metadata":{"trusted":true,"_uuid":"9cca14897811171da51b96e72954183e0cc65bba"},"cell_type":"code","source":"df_USA.nsmallest(6,\"longitude\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29e1b79d85970c4393c3ceaf81411ced0ba6cbc2"},"cell_type":"markdown","source":"The first four sets of coordinates are all in Hawaii. The fifth is Alaska and the sixth is already mainland USA. This has confirmed my suspiscions and the records do not need to be removed. I will now check the outliers further East."},{"metadata":{"trusted":true,"_uuid":"e127c3eeb62fe58ebf5cb7cfc551141e828f35f1"},"cell_type":"code","source":"df_USA.nlargest(6,\"longitude\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"631d0d1c0f44c1b746d21f33c692b6d737cb177b"},"cell_type":"markdown","source":"So the first three are records are of attacks that have taken place in Inner Mongolia, China and the fourth is from Tibet. \nPuerto Rico is the lcoation for the next two which will remain in the data frame.\nI do not know why those four attacks had an incorrect nation label. "},{"metadata":{"trusted":true,"_uuid":"f32c053bb8c1149d4f367393359478490a03d716"},"cell_type":"code","source":"df_USA = df_USA[df_USA.longitude < 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24b03ad75754076d58566928c3529bff0a579fb6"},"cell_type":"code","source":"df_USA.nlargest(6,\"longitude\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a7c898425d97c8b1a295f3cb5df76efb4065ed6"},"cell_type":"markdown","source":"For some reason the code \"df_USA = df_USA.drop([\"2179\",\"15275\",\"33294\",\"69529\"], axis = 0)\" would not work so I used the code above to remove those errors in a different way: making the data frame equal to the all the records in the data frame as long as the longitude field in that record has a value less than 0. The value of 0 was completely arbitrary but I used it as the table above shows us that a value between -65 and 90 had to be used. "},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"25ad33cef297bde9af607fb773c5d9f109933337"},"cell_type":"code","source":"df_USA.plot(kind= 'scatter', x='longitude', y='latitude', alpha=0.4, figsize=(16,9))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d229b08521e9d8804239955dde673cc2cdccb86"},"cell_type":"code","source":"df_USA.plot(kind= 'scatter', x='longitude', y='latitude', alpha=1.0,  figsize=(18,6),  \n               s=df_USA['nkill']*3, label= 'Nr of casualties', fontsize=1, c='nkill', cmap=plt.get_cmap(\"jet\"), colorbar=True)\nplt.ylabel(\"Latitude\", fontsize=14)\nplt.xlabel(\"Longitude\", fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04ed82d0e11a96e667f997aa2036aecfb8225684"},"cell_type":"code","source":"terror_peryear = np.asarray(df_USA.groupby('iyear').iyear.count())\nsuccesses_peryear = np.asarray(df_USA.groupby('iyear').success.sum())\n\nterror_years = np.arange(1970, 2016)\n\ntrace1 = go.Bar(x = terror_years, y = terror_peryear, name = 'Nr of terrorist attacks')\n\ntrace2 = go.Scatter(x = terror_years, y = successes_peryear, name = 'Nr of succesful terrorist attacks', line = dict(color = ('rgb(205, 12, 24)'),width=5))\n\nlayout = go.Layout(title = 'Terrorist Attacks by Year in USA (1970-2016)', legend=dict(orientation=\"h\"),\n         barmode = 'group')\n\nfigure = dict(data = [trace1,trace2], layout = layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb87bee5cfb248b9fe1b42d4775d4349d9362905"},"cell_type":"code","source":"attacks_per_type = (df_USA.groupby('attacktype1_txt').attacktype1_txt.count())\nsuccesses_per_type = (df_USA.groupby('attacktype1_txt').success.sum())\nprint(attacks_per_type, successes_per_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f39d407d717af96d4a30a1194ab0221befd7367b"},"cell_type":"code","source":"trace2 = go.Bar(\n    y=['Unknown','Hijacking','Hostage Taking (Kidnapping)','Unarmed Assault','Hostage Taking (Barricade Incident)','Assassination','Armed Assault','Facility/Infrastructure Attack','Bombing/Explosion'],\n    x=[11,17,20,56,59,128,249,836,1377],\n    name='Nr of terrorist attacks',\n    orientation = 'h',\n    marker = dict(color = 'rgb(255,140,0)'))\n\ntrace1 = go.Bar(\n    y=['Unknown','Hijacking','Hostage Taking (Kidnapping)','Unarmed Assault','Hostage Taking (Barricade Incident)','Assassination','Armed Assault','Facility/Infrastructure Attack','Bombing/Explosion'],\n    x=[8,15,20,31,56,80,233,748,1080],\n    name='Nr of successful terrorist attacks',\n    orientation = 'h',\n    marker = dict(color = 'rgb(0,200,200)'))\ndata = [trace1, trace2]\nlayout = go.Layout(\n    legend=dict(x=0.5, y=0.5), # placing legend in the middle\n    title = 'Terrorist attacks in USA 1970-2016 <br>by Type',\n    barmode='group',\n    bargap=0.1,\n    bargroupgap=0,\n    autosize=False,\n    width=1000,\n    height=500,\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb4018d6a190f5a6431852988f820d39aa5efec3"},"cell_type":"code","source":"terror_peryear = np.asarray(df_USA.groupby('iyear').iyear.count())\naffiliated_attacks_peryear = np.asarray(df_USA.groupby('iyear').individual.sum())\npercentage = affiliated_attacks_peryear / terror_peryear * 100\n\nterror_years = np.arange(1970, 2016)\n\ntrace1 = go.Bar(x = terror_years, y = terror_peryear,name = 'Terrorist attacks')\n\ntrace2 = go.Scatter(x = terror_years, y = affiliated_attacks_peryear,name = 'Terrorist attacks by people affiliated with terrorist organisations',yaxis = \"y2\")\n\ntrace3 = go.Scatter(x = terror_years, y = percentage, name = \"Percentage of terrorist attacks carried out by people affiliated with terrorist organisations\", yaxis  = \"y3\")\n\ndata = [trace1,trace2,trace3]\n\nlayout = go.Layout(\n    title='Rise of Terrorist groups in the USA',\n    yaxis1=dict(title='Terrorist attacks',showline = False,showgrid=False),\n    yaxis2=dict(\n        titlefont=dict(\n            color='rgb(148, 103, 189)'\n        ),\n        showgrid=False,\n        zeroline= False,\n        showline=False,\n        ticks=\"\",\n        showticklabels=False,\n        overlaying='y',\n        autorange = True,\n        side='right'),\n    yaxis3 = dict(\n        titlefont = dict(\n            color = \"rgb(124,252,0)\"\n        ),\n        showgrid=False,\n        zeroline= False,\n        showline=False,\n        ticks = \"\",\n        showticklabels=False,\n        overlaying = \"y\",\n        autorange = True,\n        side = \"right\"\n    ),\n    legend=dict(orientation=\"h\")\n)\n\nfigure = go.Figure(data = data, layout = layout)\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94d0ec9be026ecf3d6a92a122155098afca956a1"},"cell_type":"markdown","source":"**Does anyone know why this displays the values of 0 for the percentage value at well above the x axis?**"},{"metadata":{"trusted":true,"_uuid":"36f0bbbb5aff4d2fa2a65222c6fcf4c11206371e"},"cell_type":"code","source":"df_USA.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e477c5709fe20d877bf1bb9e81d3979fe2458c5f"},"cell_type":"markdown","source":"There are still NaN values for latitude and longitude, natlty1, natlty1_txt, nkill and nwound. \nFor lat, long, nkill, nwound I will fill in the averages as I have no clue what the actual values are. \nFor natlty1 and natlty1_txt , I will fill in the corresponding values of USA as the vast majority of victims were american."},{"metadata":{"trusted":true,"_uuid":"320582849778cfb7605e79fbc2973902b6326f6c"},"cell_type":"code","source":"df_USA.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6778a3d3db4e81e4409325290548c52d75efa59"},"cell_type":"code","source":"df_USA['nkill'].fillna(1.361194, inplace=True)\ndf_USA['nwound'].fillna(6.802632, inplace=True)\ndf_USA['latitude'].fillna(36.683652, inplace=True)\ndf_USA['longitude'].fillna(-92.125972, inplace=True)\ndf_USA[\"natlty1\"].fillna(217, inplace=True)\ndf_USA[\"natlty1_txt\"].fillna(\"United States\", inplace=True)\ndf_USA.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11ec1b3d5eb04a9e5fa9654e7ff52c6d93aa239a"},"cell_type":"markdown","source":"Now we have absolutely no missing pieces of data. \n\n**Correlations**"},{"metadata":{"trusted":true,"_uuid":"13b3980e7c46eca720c7a49466208a3534ca7b32"},"cell_type":"code","source":"df_USA.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3bdb00c1f2f465c29bdfcf58c3fabf53427ec54"},"cell_type":"code","source":"corrmat = df_USA.corr()\nf, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(corrmat, vmax=1, square=True);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5771d0037b75f3e50ba5c151b41ebfc7487789b"},"cell_type":"markdown","source":"There are some obviuous correlations such as the attacktype1 variable correlating well with the weapon type variable. Another common sense correlation is that between the nkill and nwound variables. \n\nMost other correlations are minor. Interestingly, there is a corrrelation between whether the individual(s) carrying out the attack were affiliated with a group. That could be due to the rise of terrorist organisations from further afield such as Al-Qaeda and ISIS, or the decline of internal groups such as the KKK or black power. I am not sure which is which. However, it is interesting to note that being affiliated to a terror organisation does not correlate with killing more people. A thing that does correlate well with killing more people on the other hand is whether or not the attack was a suicide attack. \n\n**Train Test split**\n\nNow I need to split our data to a train set (80%) and test set (20%). The variable we're trying to predict is nkill.\n\nThe random_state variable will be set the value of 1 (arbitrary but must be kept constant). \n\nThe fields ending in 'txt' will be dropped as there are numerical equivalents in the data frame."},{"metadata":{"trusted":true,"_uuid":"9c67387dd21bc97a734ee15807771bf690159fc0"},"cell_type":"code","source":"df_USA = df_USA.drop([\"iyear\",\"attacktype1_txt\",\"targtype1_txt\", \"weaptype1_txt\", \"natlty1_txt\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4a48d691f67fc5bf634ad498de42854f2879e54"},"cell_type":"code","source":"y = df_USA[\"success\"]\nfeatures_success = ['imonth', 'iday', 'extended', 'latitude', 'longitude', 'multiple', 'suicide', 'attacktype1', 'targtype1', 'natlty1','individual', 'weaptype1', 'nkill', 'nwound']\nX = df_USA[features_success]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ff8e63ebbb198c53ad3ac2108e885d0be9e077f"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f7359b9b9e9c5024d2aaf61c7abef6560508fc8"},"cell_type":"markdown","source":"**Creating the classifier to predict successfulness**\n\nAs this is my introduction to using classifiers, I wanted to try out different possibilities. Therefore, I will create four different classifiers and compare the precision of each classifier by looking at values for FPs, FNs, TPs, TNs.\n\n> TN = The model predicts correctly a non-succesful attack\nTP = The model predicts correctly a succesful attack\nFN = The model predicts a succesful attack wrongfully to be non-succesful\nFP = The model predicts a non-succesful attack wrongfully to be succesful\n\n> The Precision(=accuracy of the positive predictions), Recall(=ratio of positive instances correctly detected by the classifier) and f1-score may be more concise metrics, however.\n\n> Precision for 'success' = TP/(TP+FP) \nPrecision for not 'success' = TN/(TN+FN) \n\n> Recall for 'success' = TP/(TP+FN) \nRecall for not 'success' = TN/(TN+FP) \n\n> The f1-score is the harmonic mean of Precision and Recall.\n\n**1. Using both max_depth and max_leaf_nodes**"},{"metadata":{"trusted":true,"_uuid":"aa766391a0b0f8440156dfa1a9ad871ccdfb2d1c"},"cell_type":"code","source":"terrorism_success_model_depth_leaves = tree.DecisionTreeClassifier(random_state = 1, max_depth = 3, max_leaf_nodes = 10)\nterrorism_success_model_depth_leaves.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8377c63bfa407440134659917d09929f40af09f9"},"cell_type":"code","source":"success_pred_depth_leaves = terrorism_success_model_depth_leaves.predict(X_val)\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_val,success_pred_depth_leaves))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b5c5764d6810ffaaf455576a02e44acdda26be3"},"cell_type":"code","source":"print(confusion_matrix(y_val,success_pred_depth_leaves))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd013caacb97668d90881083b8892042b926617e"},"cell_type":"markdown","source":"**2. Using just max_depth**"},{"metadata":{"trusted":true,"_uuid":"2591852124f8bdffc52e0eb0eff6a108d9a96b09"},"cell_type":"code","source":"terrorism_success_model_depth = tree.DecisionTreeClassifier(random_state = 1, max_depth = 3)\nterrorism_success_model_depth.fit(X_train, y_train)\nsuccess_pred_depth = terrorism_success_model_depth.predict(X_val)\nprint(classification_report(y_val,success_pred_depth))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e42de6df81db18c8bd59b77434a0ff0f6f19b3c8"},"cell_type":"code","source":"print(confusion_matrix(y_val,success_pred_depth))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99dc8058becc3482a458c1bdf169efb5e6e3a19c"},"cell_type":"markdown","source":"**3. Using just max_leaf_nodes**"},{"metadata":{"trusted":true,"_uuid":"38bef0a83a0d7029f9916562fe103360fa6d554a"},"cell_type":"code","source":"terrorism_success_model_leaves = tree.DecisionTreeClassifier(random_state = 1, max_leaf_nodes = 10)\nterrorism_success_model_leaves.fit(X_train, y_train)\nsuccess_pred_leaves = terrorism_success_model_leaves.predict(X_val)\nprint(classification_report(y_val,success_pred_leaves))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec7a0be68afdec912b5444f4d635989cb96468cc"},"cell_type":"code","source":"print(confusion_matrix(y_val,success_pred_leaves))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7161b177bee27f8ff708688220af36fea24d6158"},"cell_type":"markdown","source":"**4. WIthout max_leaf_nodes and max_depth**"},{"metadata":{"trusted":true,"_uuid":"6c030fab247c2e7a0d2a2ebac0bdef2a99b8a80c"},"cell_type":"code","source":"terrorism_success_model_bare = tree.DecisionTreeClassifier(random_state = 1)\nterrorism_success_model_bare.fit(X_train, y_train)\nsuccess_pred_bare = terrorism_success_model_bare.predict(X_val)\nprint(classification_report(y_val,success_pred_bare))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5075fe16f256203c762932d10d9395c5cc85d361"},"cell_type":"code","source":"print(confusion_matrix(y_val,success_pred_bare))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ae95e09cd88dc444f9c9af567290292d95129ea"},"cell_type":"markdown","source":"**5. Using Random Forests instead**"},{"metadata":{"trusted":true,"_uuid":"366544b52dd2ebd17cbf1a836f09ccff4bc25928"},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100) \nrf = rf.fit(X_train, y_train)\nrf_pred = rf.predict(X_val)\nprint(classification_report(y_val,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25ace358897af555def97ab649e4b218ba643ab8"},"cell_type":"code","source":"print(confusion_matrix(y_val,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f4b18fd16709c10eb2640e4c1a3404e9dd31100"},"cell_type":"markdown","source":"Clearly the random forest classifier is more precise than a decision tree classifier. This should be expected. Of the four decision tree classifier models I used, the max_leaf_nodes classifiers was the most precise, though the values for max_depth and max_leaf_nodes were selected rather arbitrarily out of intuition to balance underfitting and overfitting. "},{"metadata":{"_uuid":"9dc18949d1795c10defd9a895878e6424ad00b44"},"cell_type":"markdown","source":"**Feature Importance**"},{"metadata":{"trusted":true,"_uuid":"4a8419d683a2b47e786b94be55b112558842cfac"},"cell_type":"code","source":"for name, score in zip(X_train, rf.feature_importances_):\n    print(name, score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79f9cc037b1b1a939290da1934e4c4f3995aa16c"},"cell_type":"code","source":"data = go.Bar(\n    y=['extended','suicide', 'individual',  'multiple', 'nkill',\"nwound\",\"natlty1\",'weaptype1',  'attacktype1','targtype1', \n       'imonth', 'longitude', 'iday', 'latitude'],\n    x=[0.0008434176541557457, 0.0014349551050431954,0.01660395793541506,0.021650941814853716,\n       0.026608046715114467,0.032573556495003576,0.042784340039457504,0.046320397204197755,\n       0.0754779145247244,0.10563968568238052,0.1245681748749377,0.1588732207915285,\n       0.16474122932796273,0.18188016183522507],   \n    orientation = 'h',\n    marker = dict(color = 'rgba(255,0,0, 0.6)', line = dict(width = 0.5)))\n\ndata = [data]\nlayout = go.Layout(title = 'Relative Importance of the Features in the Random Forest',\n    barmode='group', bargap=0.1, width=800,height=500,)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c5f611d1008abb510a33f519c4ca482278254db"},"cell_type":"markdown","source":"**Predicting the number of kills**"},{"metadata":{"trusted":true,"_uuid":"fbdda6aa21da7dddfd2f0c443c411623908d2e1c"},"cell_type":"code","source":"features_nkill = ['imonth', 'iday', 'extended', 'latitude', 'longitude', 'multiple','success', 'suicide', 'attacktype1', 'targtype1', 'natlty1','individual', 'weaptype1', 'nwound']\nX_nkill = df_USA[features_nkill]\ny_nkill = df_USA[\"nkill\"]\nX_nkill_train, X_nkill_val, y_nkill_train, y_nkill_val = train_test_split(X_nkill, y_nkill, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd43e03231657a793ea53dd1737d8f4caa983dc8"},"cell_type":"markdown","source":"**1. No max depth or max leaf nodes**"},{"metadata":{"trusted":true,"_uuid":"d519ca8430da1a3deca0f473dde6c9411e586024"},"cell_type":"code","source":"nkill_model = dtr(random_state = 1)\nnkill_model.fit(X_nkill_train,y_nkill_train)\nnkill_pred = nkill_model.predict(X_nkill_val)\nprint(mae(y_nkill_val, nkill_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18b8e323dfe7de098649538d72dc48053f467ce6"},"cell_type":"markdown","source":"**2. Not max depth but max leaf nodes**"},{"metadata":{"trusted":true,"_uuid":"6eaa11c841e0d7f19b3f572f228eb68f6814f641"},"cell_type":"code","source":"nkill_model = dtr(random_state = 1, max_leaf_nodes = 27)\nnkill_model.fit(X_nkill_train,y_nkill_train)\nnkill_pred = nkill_model.predict(X_nkill_val)\nprint(mae(y_nkill_val, nkill_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bad5648a3cd4266c6261b7e9a6a775b981724f99"},"cell_type":"markdown","source":"**3. Max depth but not max leaf nodes** "},{"metadata":{"trusted":true,"_uuid":"0ed49f1fc59d153ef8b17e9f0ae3a1d30ae3e71c"},"cell_type":"code","source":"nkill_model = dtr(random_state = 1, max_depth = 15)\nnkill_model.fit(X_nkill_train,y_nkill_train)\nnkill_pred = nkill_model.predict(X_nkill_val)\nprint(mae(y_nkill_val, nkill_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e712a04d502ed1eecd2d1f7bb895e2972f26309f"},"cell_type":"markdown","source":"**4. Max depth and max leaf nodes**"},{"metadata":{"trusted":true,"_uuid":"cef2a93351e7b5fe1e6f1f225010d7e5e211213e"},"cell_type":"code","source":"nkill_model = dtr(random_state = 1, max_depth = 15, max_leaf_nodes = 27)\nnkill_model.fit(X_nkill_train,y_nkill_train)\nnkill_pred = nkill_model.predict(X_nkill_val)\nprint(mae(y_nkill_val, nkill_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5427a8f4aca7593780c02257dd292db6cd962405"},"cell_type":"markdown","source":"**5. Random forest regressor**"},{"metadata":{"trusted":true,"_uuid":"6dad5a65c6fa98a625ee95f236e3d1b4e5b2d4d9"},"cell_type":"code","source":"nkill_model = rfr(random_state = 1, n_estimators = 10)\nnkill_model.fit(X_nkill_train,y_nkill_train)\nnkill_pred = nkill_model.predict(X_nkill_val)\nprint(mae(y_nkill_val, nkill_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba14625c5710ca5e5a9e82dc77977aa17961db3c"},"cell_type":"markdown","source":"Clearly the random forest regressor is the most precise as on average it has the lowest absolute error. \nNow I will examine the feature importance as I had done with the successfulness classifier. "},{"metadata":{"trusted":true,"_uuid":"5f1694b171dcd3247abab01d51dee8926d7af96c"},"cell_type":"code","source":"for name, score in zip(X_nkill_train, nkill_model.feature_importances_):\n    print(name, score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13f02d10af10471fd7a1735a370569a3b6209f0f"},"cell_type":"code","source":"features_nkill = ['imonth', 'iday', 'extended', 'latitude', 'longitude', 'multiple','success', 'suicide', 'attacktype1', 'targtype1', 'natlty1','individual', 'weaptype1']\nX_nkill = df_USA[features_nkill]\ny_nkill = df_USA[\"nkill\"]\nX_nkill_train, X_nkill_val, y_nkill_train, y_nkill_val = train_test_split(X_nkill, y_nkill, test_size=0.20, random_state=1)\nnkill_model = rfr(random_state = 1, n_estimators = 100)\nnkill_model.fit(X_nkill_train,y_nkill_train)\nnkill_pred = nkill_model.predict(X_nkill_val)\nprint(mae(y_nkill_val, nkill_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ac256062261c230e8faa78606b9467b2808bc32"},"cell_type":"markdown","source":"Without the nwound variable the mae value is considerably higher, around 33% more. "},{"metadata":{"trusted":true,"_uuid":"08cbabaadef760fc9b3e317d72385493b0752b44"},"cell_type":"code","source":"sorted_importance_dict = sorted(zip(X_nkill_train, nkill_model.feature_importances_), key=lambda x: x[1])\nprint(sorted_importance_dict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2eecaa6b82a1f5d5c3aaf1902f2ebf4f8487904"},"cell_type":"code","source":"data = go.Bar(\n    y=['extended','multiple','success','weaptype1','natlty1','iday','imonth','attacktype1',\n       'individual','targtype1','latitude','suicide','longitude'],\n    x=[6.229373475964622e-06, 0.00018061437686766628,0.00022199675803425399,0.0007881470118179646,\n       0.0017783660577080336,0.00888759926303102,0.012838555852620923,0.018069844219501384,\n       0.06589093075573221,0.09836071796324783,0.10878349610841871,0.271867786077219,0.41232571618232533],   \n    orientation = 'h',\n    marker = dict(color = 'rgba(255,0,0, 0.6)', line = dict(width = 0.5)))\n\ndata = [data]\nlayout = go.Layout(title = 'Relative Importance of the Features in the Random Forest',\n    barmode='group', bargap=0.1, width=800,height=500,)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19d98ddb39961925468465fa33aaa92788f27fd4"},"cell_type":"markdown","source":"**Predicting for a new attack**"},{"metadata":{"trusted":true,"_uuid":"04fa6e1a814989d70faf6a6616ebd10996edac61"},"cell_type":"code","source":"nkill_model = rfr(random_state = 1, n_estimators = 10)\nnkill_model.fit(X_nkill,y_nkill)\n\nmonth = 9\nday = 11\nextended = 0\nlatitude = 40.711675 \nlongitude = -70.013285\nmultiple = 1\nsuccess = 1\nsuicide = 1\nattackType = 8\ntargetType = 11\nnatlty1 = 217\nindividual = 1\nweaponType = 12\n\nkill_count = nkill_model.predict([[month,day,extended,latitude,longitude,multiple,success,suicide,\n                                  attackType,targetType,individual,weaponType, natlty1]])\nprint(\"Unfortunately, this attack will kill \"+str(int(kill_count[0]))+\" people...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"094f3a26c92688b0bc2063ed5f24663c4222dc81"},"cell_type":"markdown","source":"Intuitively, I would say that this model is pretty awful. You would not expect an attack to kill 1124 people. Hoever, you never know, an UNARMED assault may be able to kill 1065 people, especially if the unarmed assaulter is jackie chan. \n\n**Final Questions**\n\n1. How can I improve these models (clearly they could do with some improvement)?\n2. Is there a way to visualise these models?\n3. Are there any models that work better than the random forests and decision trees?\n4. Is there a way to find the ideal value for max_depth, max_leaf_nodes and n_estimators?\n5. As someone new to this field, what advice would you have on learning the ins and outs of these and other models?\n6. What should my next steps be? Are there any models I should look at or should I learn some special maths before progressing? \n\nAs I say, this is the first time I have worked with data and models so any advice, feedback or suggestions would be greatly appreaciated. \n\nAG"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}