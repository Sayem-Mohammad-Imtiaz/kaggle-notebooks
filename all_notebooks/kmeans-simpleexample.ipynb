{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"#importing necessary libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#we can create own dataset. (gaussian distributation)\n\nx1 = np.random.normal(25,5,1000)\ny1 = np.random.normal(25,5,1000)\n\nx2 = np.random.normal(55,5,1000)\ny2 = np.random.normal(60,5,1000)\n\nx3 = np.random.normal(55,5,1000)\ny3 = np.random.normal(15,5,1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#almost dataset is ready.\nx = np.concatenate((x1,x2,x3), axis = 0)\ny = np.concatenate((y1,y2,y3), axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dictionary = {\"x\":x, \"y\":y}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.DataFrame(dictionary)\n#dataset is ready, it called df.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(x1,y1)\nplt.scatter(x2,y2)\nplt.scatter(x3,y3)\nplt.show()\n#Unsupervised learning, it does'nt know labels.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(x,y)\nplt.show()\n#Yes, this way.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.cluster import KMeans\nWCSS = [] #within clusters sum of squares","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#hey, i have a problem, how can i know optimum k value?\n#sure, i prefer elbow rules.\nfor k in range(1,15):\n    model = KMeans(n_clusters = k)\n    model.fit(df)\n    WCSS.append(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#can you see elbow point? i guess it is 3.\nplt.plot(range(1,15), WCSS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#yes we can do it, anymore.\nmodel = KMeans(n_clusters = 3)\nclusters = model.fit_predict(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# we can create new columns, labels!\ndf[\"labels\"] = clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(df.x[df.labels == 0], df.y[df.labels == 0], color=\"red\")\nplt.scatter(df.x[df.labels == 1], df.y[df.labels == 1], color=\"green\")\nplt.scatter(df.x[df.labels == 2], df.y[df.labels == 2], color=\"blue\")\nplt.show()\n#did you see, it is perfect example of unsupervised learning.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(model.cluster_centers_[:,0], model.cluster_centers_[:,1], color = \"black\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#if you wanna say that \"where is the cluster centers ???\" here you go.\nplt.scatter(df.x[df.labels == 0], df.y[df.labels == 0], color=\"red\")\nplt.scatter(df.x[df.labels == 1], df.y[df.labels == 1], color=\"green\")\nplt.scatter(df.x[df.labels == 2], df.y[df.labels == 2], color=\"blue\")\nplt.scatter(model.cluster_centers_[:,0], model.cluster_centers_[:,1], color = \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if you have any question or suggestion, i will be happy to hear it.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}