{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ECG Heartbeat Categorization\n> By Ebby\n\nThe goal is to be able to classify heart disease from heartbeat signal. There is a lot of data, let's try to make sens out of it."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nprint(os.listdir(\"../input\"))\n\nmit_test_data = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\nmit_train_data = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\n\nprint(\"MIT test dataset\")\nprint(mit_test_data.info())\nprint(\"MIT train dataset\")\nprint(mit_train_data.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mit_train_data[187].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mit_train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mit_train_data.iloc[19999].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random sample\n\nFor now let's take a random sample of the MIT train dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# take a random distribution\nsample = mit_test_data.sample(25)\n\n# remove the target column\nsampleX = sample.iloc[:,sample.columns != 187]\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\n# plt samples\nfor index, row in sampleX.iterrows():\n    plt.plot(np.array(range(0, 187)) ,row)\n\nplt.xlabel(\"time\")\nplt.ylabel(\"magnitude\")\nplt.title(\"heartbeat reccording \\nrandom sample\")\n\nplt.show()\n\nplt.style.use(\"ggplot\")\n\nplt.title(\"Number of record in each category\")\n\nplt.hist(sample.iloc[:,sample.columns == 187].transpose())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use the Seaborn library\nimport seaborn as sns\nsns.set()\n\n# Graphics in SVG format are more sharp and legible\n%config InlineBackend.figure_format = 'svg' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mit_train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [0,1,2,3,4,5,6,187]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# `pairplot()` may become very slow with the SVG format\n#%config InlineBackend.figure_format = 'png'\n#sns.pairplot(mit_train_data[columns]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How many date we have in each category?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train data\")\nprint(\"Type\\tCount\")\nprint((mit_train_data[187]).value_counts())\nprint(\"-------------------------\")\nprint(\"Test data\")\nprint(\"Type\\tCount\")\nprint((mit_test_data[187]).value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=187, data=mit_train_data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=187, data=mit_test_data);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Separate features and targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"mit_train_data = mit_train_data.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\nprint(\"--- X ---\")\nX = mit_train_data.loc[:, mit_train_data.columns != 187]\nprint(X.head())\nprint(X.info())\n\nprint(\"--- Y ---\")\ny = mit_train_data.loc[:, mit_train_data.columns == 187]\ny = to_categorical(y)\n\nprint(\"--- testX ---\")\ntestX = mit_test_data.loc[:, mit_test_data.columns != 187]\nprint(testX.head())\nprint(testX.info())\n\nprint(\"--- testy ---\")\ntesty = mit_test_data.loc[:, mit_test_data.columns == 187]\ntesty = to_categorical(testy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Keras model to make prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\n    \ndef f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n        Only computes a batch-wise average of recall.\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n \n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n        Only computes a batch-wise average of precision.\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 训练一个Base Model 确定BaseLine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation,BatchNormalization,Dropout\n\nmodel = Sequential()\n\nmodel.add(Dense(50, input_dim=187, init='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(30, init='normal', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['acc',f1])\n\nhistory = model.fit(X, y, validation_split=0.2,epochs=100,shuffle=True,class_weight='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Evaluation: \")\nmse, acc, F1 = model.evaluate(testX, testy)\nprint('mean_squared_error :', mse)\nprint('accuracy:', acc)\nprint('F1:', F1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This seems to work pretty well!\n\nWork in progress"},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.plot(history.history['f1'])\nplt.plot(history.history['val_f1'])\nplt.legend(labels=['loss','val_loss','f1','val_f1'],loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 使用CNN进一步优化"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.expand_dims(X,2)\ntestX = np.expand_dims(testX,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, Flatten, SeparableConv1D\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\n\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_obs, feature, depth = X.shape\nbatch_size = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    input_img = Input(shape=(feature, depth), name='ImageInput')\n    x = Conv1D(64, 3, activation='relu', padding='same', name='Conv1_1')(input_img)\n    x = Conv1D(64, 3, activation='relu', padding='same', name='Conv1_2')(x)\n    x = MaxPooling1D(2, name='pool1')(x)\n    \n    x = SeparableConv1D(64, 3, activation='relu', padding='same', name='Conv2_1')(x)\n    x = SeparableConv1D(64, 3, activation='relu', padding='same', name='Conv2_2')(x)\n    x = MaxPooling1D(2, name='pool2')(x)\n    \n    x = SeparableConv1D(128, 3, activation='relu', padding='same', name='Conv3_1')(x)\n    x = BatchNormalization(name='bn1')(x)\n    x = SeparableConv1D(128, 3, activation='relu', padding='same', name='Conv3_2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    \n    x = SeparableConv1D(256, 3, activation='relu', padding='same', name='Conv3_3')(x)\n    x = MaxPooling1D(2, name='pool3')(x)\n    x = Dropout(0.6, name='dropout0')(x)\n    \n    x = Flatten(name='flatten')(x)\n    x = Dense(256, activation='relu', name='fc1')(x)\n    x = Dropout(0.6, name='dropout1')(x)\n    x = Dense(128, activation='relu', name='fc2')(x)\n    x = Dropout(0.5, name='dropout2')(x)\n    x = Dense(5, activation='softmax', name='fc3')(x)\n    \n    model = Model(inputs=input_img, outputs=x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model =  build_model()\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['acc',f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\ncheckpointer = ModelCheckpoint(filepath=\"/tmp/weights.hdf5\", verbose=1, save_best_only=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X, y, validation_split=0.2,epochs=75,batch_size=batch_size,shuffle=True,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Evaluation: \")\nmse, acc, F1 = model.evaluate(testX, testy)\nprint('mean_squared_error :', mse)\nprint('accuracy:', acc)\nprint('F1:', F1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('cnn-0.985.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(testX, batch_size=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n\nprint(classification_report(testy.argmax(axis=1), y_pred.argmax(axis=1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(testy.argmax(axis=1), y_pred.argmax(axis=1))\nnp.set_printoptions(precision=1)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(7, 7))\nplot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n                      title='Confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 数据增强"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mit_train_data = mit_train_data.sample(frac=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\nprint(\"--- X ---\")\nX = mit_train_data.loc[:, mit_train_data.columns != 187]\nprint(X.head())\nprint(X.info())\n\nprint(\"--- Y ---\")\ny = mit_train_data.loc[:, mit_train_data.columns == 187]\n#y = to_categorical(y)\n\nprint(\"--- testX ---\")\ntestX = mit_test_data.loc[:, mit_test_data.columns != 187]\nprint(testX.head())\nprint(testX.info())\n\nprint(\"--- testy ---\")\ntesty = mit_test_data.loc[:, mit_test_data.columns == 187]\ntesty = to_categorical(testy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = y.values.squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C0 = np.argwhere(y == 0).flatten()\nC1 = np.argwhere(y == 1).flatten()\nC2 = np.argwhere(y == 2).flatten()\nC3 = np.argwhere(y == 3).flatten()\nC4 = np.argwhere(y == 4).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(C0.shape[0],C1.shape[0],C2.shape[0],C3.shape[0],C4.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 放大C1 C3 类，C1类放大4倍，C3类放大8倍"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfrom scipy.signal import resample\n\ndef stretch(x):\n    l = int(187 * (1 + (random.random()-0.5)/3))\n    y = resample(x, l)\n    if l < 187:\n        y_ = np.zeros(shape=(187, ))\n        y_[:l] = y\n    else:\n        y_ = y[:187]\n    return y_\n\ndef amplify(x):\n    alpha = (random.random()-0.5)\n    factor = -alpha*x + (1+alpha)\n    return x*factor\n\ndef augment(x):\n    result = np.zeros(shape= (5, 187))\n    for i in range(3):\n        if random.random() < 0.33:\n            new_y = stretch(x)\n        elif random.random() < 0.66:\n            new_y = amplify(x)\n        else:\n            new_y = stretch(x)\n            new_y = amplify(new_y)\n        result[i, :] = new_y\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport random\nplt.plot(X[0, :])\nplt.plot(amplify(X[0, :]))\nplt.plot(stretch(X[0, :]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_C1 = np.apply_along_axis(augment, axis=1, arr=X[C1]).reshape(-1, 187)\nclass_C1 = np.ones(shape=(result_C1.shape[0],), dtype=int)*3\n\nresult_C3 = np.apply_along_axis(augment, axis=1, arr=X[C3]).reshape(-1, 187)\nclass_C3 = np.ones(shape=(result_C3.shape[0],), dtype=int)*3\n\n# result_C32 = np.apply_along_axis(augment, axis=1, arr=X[C3]).reshape(-1, 187)\n# class_C32 = np.ones(shape=(result_C32.shape[0],), dtype=int)*3\n\n# X = np.vstack([X, result_C1, result_C3])\n# y = np.hstack([y, class_C1, class_C3])\n\nX = np.vstack([X,  result_C3])\ny = np.hstack([y,  class_C3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\nX, y = shuffle(X,y,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Try a network by using augmented data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.expand_dims(X,2)\ntestX = np.expand_dims(testX,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Input, Flatten, SeparableConv1D\nfrom keras.layers import GlobalMaxPooling1D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\n\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nn_obs, feature, depth = X.shape\nbatch_size = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    input_img = Input(shape=(feature, depth), name='ImageInput')\n    x = Conv1D(64, 3, activation='relu', padding='same', name='Conv1_1')(input_img)\n    x = Conv1D(64, 3, activation='relu', padding='same', name='Conv1_2')(x)\n    x = MaxPooling1D(2, name='pool1')(x)\n    \n    x = SeparableConv1D(128, 3, activation='relu', padding='same', name='Conv2_1')(x)\n    x = SeparableConv1D(128, 3, activation='relu', padding='same', name='Conv2_2')(x)\n    x = MaxPooling1D(2, name='pool2')(x)\n    \n    x = SeparableConv1D(256, 3, activation='relu', padding='same', name='Conv3_1')(x)\n    x = BatchNormalization(name='bn1')(x)\n    x = SeparableConv1D(256, 3, activation='relu', padding='same', name='Conv3_2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = Dropout(0.3, name='dropout3-2')(x)\n    \n    x = SeparableConv1D(512, 3, activation='relu', padding='same', name='Conv3_3')(x)\n    x = MaxPooling1D(2, name='pool3')(x)\n    x = Dropout(0.3, name='dropout3-3')(x)\n    \n    x = Flatten(name='flatten')(x)\n    x = Dense(512, activation='relu', name='fc1')(x)\n    x = Dropout(0.6, name='dropout1')(x)\n    x = Dense(256, activation='relu', name='fc2')(x)\n    x = Dropout(0.5, name='dropout2')(x)\n    x = Dense(5, activation='softmax', name='fc3')(x)\n    \n    model = Model(inputs=input_img, outputs=x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model =  build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['acc',f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\ncheckpointer = ModelCheckpoint(filepath=\"/tmp/weights-aug.hdf5\", monitor='val_f1', mode='max', verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X, y, validation_split=0.2,epochs=75,batch_size=batch_size*2,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('/tmp/weights-aug.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Evaluation: \")\nmse, acc, F1 = model.evaluate(testX, testy)\nprint('mean_squared_error :', mse)\nprint('accuracy:', acc)\nprint('F1:', F1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.set_value(model.optimizer.lr, 1e-4)\nmodel.fit(X, y, validation_split=0.2,epochs=30,batch_size=batch_size*2,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Change LR train more"},{"metadata":{"trusted":true},"cell_type":"code","source":"K.set_value(model.optimizer.lr, 1e-5)\nmodel.fit(X, y, validation_split=0.2,epochs=30,batch_size=batch_size,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('/tmp/weights-aug.hdf5')\nprint(\"Evaluation: \")\nmse, acc, F1 = model.evaluate(testX, testy)\nprint('mean_squared_error :', mse)\nprint('accuracy:', acc)\nprint('F1:', F1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(testX, batch_size=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(testy.argmax(axis=1), y_pred.argmax(axis=1))\n#np.set_printoptions(precision=0)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(5, 5))\nplot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n                      title='Confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The last Step: Using all the training data and fitting more epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#K.set_value(model.optimizer.lr, 1e-3)\nhistory = model.fit(X, y, validation_data=(testX,testy),epochs=150,batch_size=batch_size*2,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('/tmp/weights-aug.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.set_value(model.optimizer.lr, 1e-5)\nhistory = model.fit(X, y, validation_data=(testX,testy),epochs=30,batch_size=batch_size*2,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('/tmp/weights-aug.hdf5')\nprint(\"Evaluation: \")\nmse, acc, F1 = model.evaluate(testX, testy)\nprint('mean_squared_error :', mse)\nprint('accuracy:', acc)\nprint('F1:', F1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"0.98887.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.set_value(model.optimizer.lr, 1e-7)\nhistory = model.fit(X, y, validation_data=(testX,testy),epochs=30,batch_size=batch_size*2,class_weight='auto',callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(testX, batch_size=1000)\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(testy.argmax(axis=1), y_pred.argmax(axis=1))\n#np.set_printoptions(precision=0)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(5, 5))\nplot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n                      title='Confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}