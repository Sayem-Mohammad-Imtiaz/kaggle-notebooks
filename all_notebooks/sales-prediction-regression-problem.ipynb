{"cells":[{"metadata":{},"cell_type":"markdown","source":"# eCommerce Price Prediction\n\n## Problem Statement\nE-commerce platforms have been in existence for more than 2 decades now. The popularity and its preference as a common choice for buying and selling essential products have grown rapidly and exponentially over the past few years. E-commerce has impacted the lifestyle of common people to a huge extent. Many such platforms are competing over each other for dominance by providing consumer goods at a competitive price. In this hackathon, we challenge data science enthusiasts to predict the price of commodities on an e-commerce platform.\n\nGiven are **7 distinguishing factors** that can influence the price of a product on an e-commerce platform. Your objective as a data scientist is to build a machine learning model that can accurately predict the price of a product based on the given factors.\n\n## Input Data\n\nThe unzipped folder will have the following files.\n\nTrain.csv –  2452 observations\n\nTest.csv –  1051 observations\n\nTarget Variable: **Selling_Price**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n# Plot related libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Linear Regression Model\nfrom sklearn.linear_model import LinearRegression, RidgeCV\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the dataset\n\nThe eCommerce price prediction problem has set of data in Train and Test file as comma-separated file. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_FILE = \"/kaggle/input/E-Commerce_Participants_Data/Train.csv\"\nTEST_FILE = \"/kaggle/input/E-Commerce_Participants_Data/Test.csv\"\n\n# Using pandas read_csv method to import data\ntrain_ecomm_df = pd.read_csv(TRAIN_FILE, header=0)\ntest_ecomm_df = pd.read_csv(TEST_FILE, header=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us check the info of the given dataset.\n\n**Training Set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ecomm_df.info()\nprint(\"==\"*30)\ntrain_ecomm_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test Set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ecomm_df.info()\nprint(\"==\"*30)\ntest_ecomm_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ecomm_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check for null data**\n\nThe training set seems to have no null data. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ecomm_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='whitegrid', palette='muted')\nfig, ax = plt.subplots(1,2, figsize=(12,6))\n\nsns.distplot(train_ecomm_df['Selling_Price'], kde=True, ax=ax[0])\nsns.scatterplot(x='Item_Rating', y='Selling_Price', data=train_ecomm_df, marker='o', color='r', ax=ax[1])\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the target variable\ny_target = np.log1p(train_ecomm_df['Selling_Price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2,figsize=(10,5))\nsns.distplot(train_ecomm_df['Selling_Price'], kde=True, ax=axes[0])\nsns.distplot(y_target, kde=True, ax=axes[1])\naxes[0].set_title(\"Skewed Y-Values\")\naxes[1].set_title(\"Normalized Y-Values\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare data for model building\n\nThe dataset contains date and few categorical columns. We need to encode the categorical columns to number before building a model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge train and test data\ntempset = pd.concat([train_ecomm_df, test_ecomm_df], keys=[0,1])\n\n# Impute the 'unknown' values with Mode\ntempset['Subcategory_1'] = tempset['Subcategory_2'].replace('unknown', np.nan).bfill().ffill()\ntempset['Subcategory_2'] = tempset['Subcategory_2'].replace('unknown', np.nan).bfill().ffill()\n\ntempset['Subcategory_1'] = tempset['Subcategory_1'].fillna(tempset['Subcategory_1'].mode()[0])\ntempset['Subcategory_2'] = tempset['Subcategory_2'].fillna(tempset['Subcategory_2'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempset.drop(['Date', 'Product'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the categorical columns\ncat_data = tempset.select_dtypes(include=['object'])\n\n# One-hot encoding\nX_encode = pd.get_dummies(tempset, columns=cat_data.columns)\n\n# Getting back the Tran and Test data\nX_train, X_enc_test = X_encode.xs(0), X_encode.xs(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define X and Y ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare X and y for fitting the model\ny = X_train['Selling_Price'].values\nX = X_train.drop('Selling_Price', axis=1).values\n\nX_test = X_enc_test.drop('Selling_Price', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Linear Regression Model\n\n### Using TransformedTargetRegressor model\n\nThis model allows us to use cross-validation and regularizer functions such as Ridge and Lasso","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Ridge CV implementation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_cv = RidgeCV(normalize=True,cv=10,gcv_mode='svd',scoring='neg_mean_squared_error')\n\n#Initializing Linear Regression algorithm with Ridge regularizer(K-fold with 10 folds)\nridge_reg = TransformedTargetRegressor(regressor= ridge_cv,\n                                      func=np.log1p,\n                                      inverse_func=np.expm1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge_reg.fit(X, y)\n\n# Predict the test data\npredictions = ridge_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.DataFrame({'Selling_Price': predictions})\n\nfinal_df['Selling_Price'] = final_df.apply(lambda x: round(x, 2))\nfinal_df = pd.concat([test_ecomm_df, final_df['Selling_Price']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Learnings\n\n* The data is a mix of categorical, ordinal, numeric and date values\n* The **Y-Target** attribute **Selling Price** has got a skewed data when we visualize its distribution\n* We need to apply the transformation method to make it normal. Here, **np.log1p** method is used. [Click to know more about the method](https://numpy.org/doc/1.18/reference/generated/numpy.log1p.html#numpy.log1p)\n* It is always good to start with linear model rather than ensembles or neural network. \n* The indention was to get exposure to real time data not the leaderboard (pun indented) \n* First tried with LinearRegressor model with RidgeCV\n* During the iteration, applied the data with [QuantileTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html) of 300 estimators but the result was not converging towards 0.5, hence switched to [Log transformer](https://numpy.org/doc/1.18/reference/generated/numpy.log1p.html#numpy.log1p).\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nThe final submission score is as follows\n\n|Best Public Score | Final Score |\n|------------------|-------------|\n|0.67659\t|**0.65363**\t|\n\nThese scores stood **38th** position. The challenge was quite tough, solely because of the data.\n\nAlthough the feature scaling and engineering parts were not done extensively here, the **Linear Regressor** with RidgeCV seemed to have done pretty good job. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}