{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing the classes and functions we intend to use in this tutorial.\nfrom numpy import loadtxt\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import pyplot\nfrom xgboost import plot_importance","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load data\ndataset = pd.read_csv('../input/diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b614b90f67d1d3438c19b7e56f732098215dc4e"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07b9e59df0e2bb1f79398e9732bdb1f5accbbaba"},"cell_type":"code","source":"# split data into X and y\nX = dataset.iloc[:,0:8]\nY = dataset.iloc[:,8]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac400d3a5a9ad565d971946325135ca186f8c6de"},"cell_type":"code","source":"seed = 7\ntest_size = 0.33\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47a5a18cadbf92d3bb1fd70117c6d720c68154c6"},"cell_type":"code","source":"# fit model no training data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c38efcd9ebd329f2333210253b54ce3a7bc6566a"},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4c2d91a9a3cefe1eabb03dda09ef2059a586939"},"cell_type":"code","source":"# make predictions for test data\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27b22cc8534c9a9fdbc6c0c987886f0282011fac"},"cell_type":"code","source":"# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be078cdda9594b2b63de0ab2a1109c262b88a316"},"cell_type":"code","source":"\nprint(model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66217c95cb617b028cf53ef5df108acd4b8b7087"},"cell_type":"code","source":"#The XGBoost library provides a built-in function to plot features ordered by their importance.\nfrom xgboost import plot_importance\n#The function is called plot_importance() and can be used as follows:\n\nplot_importance(model)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c49f651f287ca4ad78692c72f638f895588bf7b"},"cell_type":"markdown","source":"## XGBoost Hyperparameter Tuning"},{"metadata":{"trusted":true,"_uuid":"d262db0d09b843e9fe8bc1d66387949e9869b316"},"cell_type":"code","source":"\n#The scikit-learn framework provides the capability to search combinations of parameters.\n\n#This capability is provided in the GridSearchCV class and can be used to discover the best way to configure the model for top performance on your problem.\n\n\n#The number and size of trees (n_estimators and max_depth).\n#The learning rate and number of trees (learning_rate and n_estimators).\n#The row and column subsampling rates (subsample, colsample_bytree and colsample_bylevel).\n#Below is a full example of tuning just the learning_rate on the Pima Indians Onset of Diabetes dataset.\n\n\n# Tune learning_rate\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\n\n# grid search\nmodel = XGBClassifier()\nlearning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\nparam_grid = dict(learning_rate=learning_rate)\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\ngrid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\ngrid_result = grid_search.fit(X, Y)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"863dbc59b3c6bc4e6286a333de7d6e91a265849e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}