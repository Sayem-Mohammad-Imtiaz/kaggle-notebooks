{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nIn this notebook I have tried consuming the `Flickr dataset` with `tf.data.Dataset`. This can act as the data pipeline for others to work their model on. The dataframe is built from scratch, so there is a lot of flexibility that the user can get.\n\nI have made the dataset such that each element of the dataset has two components.\n- Image - (height, width, channel)\n- Comments - (5, seq_length)"},{"metadata":{},"cell_type":"markdown","source":"# Imports\nThe global imports are as follows:\n- tensorflow\n- matplotlib\n- pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Util function\n- Load image: This helps in loading images from the path given\n- configure_dataset: Helps in caching and fetching the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ndef load_img(image_path):\n    '''\n    This function helps load the image from the path\n    inputs:\n    path_to_img = The path of the image\n    outputs:\n    the image itself in form of tf.tensor\n    '''\n    # parse image\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_image(image)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    return image\n\ndef configure_dataset(dataset):\n    return dataset.cache().prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/flickr-image-dataset/flickr30k_images'\nimage_dir = f'{data_dir}/flickr30k_images'\ncsv_file = f'{data_dir}/results.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataFrame\nLoad the `results.csv` in the form of a dataframe.\n\nWhile building the notebook I had come across a problem with the `csv` file. The entry at index `19999` was messed up. This is why you can see hard coded values for the respective indices. Doing this makes the code later simpler."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(csv_file, delimiter='|')\n# Under scrutiny I had found that 19999 had a messed up entry\ndf[' comment_number'][19999] = ' 4'\ndf[' comment'][19999] = ' A dog runs across the grass .'\ndf['image_name'] = image_dir+'/'+df['image_name']\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Let us get some information from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'[INFO] The shape of dataframe: {df.shape}')\nprint(f'[INFO] The columns in the dataframe: {df.columns}')\nprint(f'[INFO] Unique rows: {len(pd.unique(df[\"image_name\"]))}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The unique rows are `31,783` while there are `1,58,915` rows in the dataframe. On scrutiny we will find that each image has 5 comments. This is why there are 5 times the rows as there are unique images. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# A simple sanity check to figure the duplicacy issue\ndef duplicacy(index):\n    print(f\"There are `{len(df.loc[df['image_name'] == df['image_name'][index]])}` comments for image `{index}`\")\n\n# Change the index to see for yourself\nduplicacy(index=200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dividing data\nThe thought behind this section is to obtain a `tf.data.Dataset` which consists of elements in this format:\n```python\n{\n    image,\n    comment0,\n    comment1,\n    comment2,\n    comment3,\n    comment4\n}\n```\n\nWith that in mind these are the steps that I have taken to get the dataset done:\n- Make two dataframes. One for image_names and the other for comments.\n- Build two different `tf.data.Dataset` objects.\n- Proprocess the comments dataset.\n- Zip the two datasets together.\n- Map a function to obtain image from image_names and keep the comments as it is."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_name = {\n    'image_name':df[df[' comment_number'] == df[' comment_number'][0]]['image_name'].values,\n}\ncomments = {\n    'comment_0':df[df[' comment_number'] == df[' comment_number'][0]][' comment'].values,\n    'comment_1':df[df[' comment_number'] == df[' comment_number'][1]][' comment'].values,\n    'comment_2':df[df[' comment_number'] == df[' comment_number'][2]][' comment'].values,\n    'comment_3':df[df[' comment_number'] == df[' comment_number'][3]][' comment'].values,\n    'comment_4':df[df[' comment_number'] == df[' comment_number'][4]][' comment'].values,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_name_df = pd.DataFrame.from_dict(image_name)\ncomments_df = pd.DataFrame.from_dict(comments)\n\nimage_name_df_values = image_name_df[image_name_df.columns].astype(str).values\ncomments_df_values = comments_df[comments_df.columns].astype(str).values\n\nimage_name_ds = tf.data.Dataset.from_tensor_slices(image_name_df_values)\ncomments_ds = tf.data.Dataset.from_tensor_slices(comments_df_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TextVectorization\nHere we create a `TextVectorization` layer. As per the tf tutorial, this layer is capable of `Standardization`, `Tokenization` and `Vectorization` all at once."},{"metadata":{"trusted":true},"cell_type":"code","source":"VOCAB_SIZE = 10000\nMAX_SEQUENCE_LENGTH = 15\n\nint_vectorize_layer = TextVectorization(\n    max_tokens=VOCAB_SIZE,\n    output_mode='int',\n    output_sequence_length=MAX_SEQUENCE_LENGTH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adapt the state of the layer to the current data\nint_vectorize_layer.adapt(comments_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that will map text to the int embeds\ndef int_vectorize_text(text):\n    text = tf.expand_dims(text, -1)\n    return int_vectorize_layer(text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Sanity check with one caption"},{"metadata":{"trusted":true},"cell_type":"code","source":"text = next(iter(comments_ds))\nprint(\"[INFO] COMMENTS:\",text)\nprint(\"[INFO] `int` VECOTRIZED COMMENTS:\",int_vectorize_text(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the int comments dataset\nint_comments_ds = comments_ds.map(int_vectorize_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join the two datasets\n# Image name dataset + int vectorised comments dataset\nname_comments_ds = tf.data.Dataset.zip((image_name_ds, int_comments_ds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process(image_name,comments):\n    \"\"\"\n    This function takes image_name and comments\n    and returns the image and comments.\n    \n    Args:\n        image_name (tensor): The path name to the image\n        comments (tensor): The comments, preferably the int vectorised\n    \"\"\"\n    img = load_img(image_name[0])\n    return img, comments","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Joint Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = name_comments_ds.map(process)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, comments in train_ds.take(1):\n    print(image.shape)\n    print(comments.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor image, comments in train_ds.take(2):\n    plt.imshow(image)\n    plt.show()\n    print(comments)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}