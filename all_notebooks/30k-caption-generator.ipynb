{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"/kaggle/input/ecodedimg/encoded-img.pkl\", \"rb\") as pickle_in:\n    train_features = pickle.load(pickle_in)\nwith open(\"/kaggle/input/30kdata/caption-img.pkl\", \"rb\") as pickle_in:\n    captions = pickle.load(pickle_in)\nwith open(\"/kaggle/input/30kdata/vocab.pkl\", \"rb\") as pickle_in:\n    vocab = pickle.load(pickle_in)\nprint(\"Vocab : \" + str(len(vocab)))\nprint(\"train_features : \" + str(len(train_features)))\nprint(captions['1000523639.jpg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list of all training captions\nall_train_captions = []\nfor key, val in captions.items():\n    for caption in val:\n        all_train_captions.append(caption)\nlen(all_train_captions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the maximum length of a description in a dataset\nmax_length = max(len(des.split()) for des in all_train_captions)\nmax_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#word mapping to integers\nixtoword = {}\nwordtoix = {}\n\nix = 1\nfor word in vocab:\n    wordtoix[word] = ix\n    ixtoword[ix] = word\n    ix += 1\nlen(wordtoix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport string\nimport os\nfrom PIL import Image\nfrom time import time\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.layers.merge import add\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras import Input, layers\nfrom keras import optimizers\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_generator(descriptions, photos, wordtoix, max_length, num_photos_per_batch):\n    X1, X2, y = list(), list(), list()\n    n=0\n    # loop for ever over images\n    while 1:\n        for key, desc_list in descriptions.items():\n            n+=1\n            # retrieve the photo feature\n            photo = photos[key]\n            for desc in desc_list:\n                # encode the sequence\n                seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n                # split one sequence into multiple X, y pairs\n                for i in range(1, len(seq)):\n                    # split into input and output pair\n                    in_seq, out_seq = seq[:i], seq[i]\n                    # pad input sequence\n                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n                    # encode output sequence\n                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n                    # store\n                    X1.append(photo)\n                    X2.append(in_seq)\n                    y.append(out_seq)\n            # yield the batch data\n            if n==num_photos_per_batch:\n                yield [[array(X1), array(X2)], array(y)]\n                X1, X2, y = list(), list(), list()\n                n=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(ixtoword) + 1\nvocab_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(\"/kaggle/working/new-model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(captions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nnumber_pics_per_bath = 128\nsteps = len(captions)//number_pics_per_bath","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"wordtoix.pkl\", \"wb\") as pickle_out:\n    pickle.dump(wordtoix, pickle_out)\nwith open(\"ixtoword.pkl\", \"wb\") as pickle_out:\n    pickle.dump(ixtoword, pickle_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(epochs):\n    generator = data_generator(captions, train_features, wordtoix, max_length, number_pics_per_bath)\n    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n    if (i % 3 == 0) :\n        model.save('image-caption-30k-' + str(i) + '.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"new-model-1.h5\")\n#2.7085","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}