{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/metal-furnace-dataset/Train.csv\")\ndf_test = pd.read_csv(\"../input/metal-furnace-dataset/Test.csv\")\ndf_train[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,8)\nsns.countplot(x=df_train[\"f0\"],hue=df_train['grade'])\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop(['f9'],inplace = True,axis=1)\ndf_test.drop(['f9'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df_train.columns\nn_rows = 9\nn_cols = 3\n# plt.xlabel(fontsize=12\nfor i in range(n_rows):\n    fg,ax = plt.subplots(nrows=1,ncols = n_cols,figsize = (16,8))\n    for j in range(n_cols):\n        sns.violinplot(y = cols[i*n_cols+j],data  = df_train,ax = ax[j])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df_train.columns\nn_cols  = 2\nn_rows = 14\nfor i in range(n_rows):\n    fg,ax = plt.subplots(nrows = 1,ncols = n_cols,figsize = (17,6))\n    for j in range(n_cols):\n        sns.countplot(x = cols[i*n_cols+j],hue = 'grade',data = df_train,ax = ax[j])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split,cross_val_predict\nfrom sklearn.metrics import log_loss\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier,BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape,df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"df_test.drop(labels = \"\")","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.grade.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (14,8)\nsns.countplot(df_train[\"grade\"],hue = df_train[\"grade\"],palette = 'dark')\nplt.title(\"Grade Distribution\",fontsize = 20)\nplt.xlabel(\"Grade\",fontsize = 15)\nplt.ylabel(\"Count\",fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(set(df_train.columns)-set(['grade','f9']))\ntarget = 'grade'\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y,y0):\n    return log_loss(y,y0)\ndef cross_valid(model,train,features,target,cv):\n    results = cross_val_predict(model, train[features], train[target], method=\"predict_proba\",cv=cv)\n    return metric(train[target],results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodels = [lgb.LGBMClassifier(), xgb.XGBClassifier(), GradientBoostingClassifier(), LogisticRegression(), \n              RandomForestClassifier(), AdaBoostClassifier()\n             ]\nfor i in models:\n    error =  cross_valid(i,df_train,features,target,5)\n    print(str(i).split(\"(\")[0], error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_model(train, features, target, plot=True):    \n    evals_result = {}\n    trainX, validX, trainY, validY = train_test_split(train[features], train[target], test_size=0.2, random_state=13)\n    print(\"XGB Model\")\n    \n    dtrain = xgb.DMatrix(trainX, label=trainY)\n    dvalid = xgb.DMatrix(validX, label=validY)\n    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n    \n    MAX_ROUNDS=2000\n    early_stopping_rounds=100\n    params = {\n        'booster': 'gbtree',\n        'objective': 'multi:softprob',\n        'eval_metric': 'mlogloss',\n        'learning_rate': 0.01,\n        'num_round': MAX_ROUNDS,\n        'max_depth': 8,\n        'seed': 25,\n        'nthread': -1,\n        'num_class':5\n    }\n    \n    model = xgb.train(\n        params,\n        dtrain,\n        evals=watchlist,\n        num_boost_round=MAX_ROUNDS,\n        early_stopping_rounds=early_stopping_rounds,\n        verbose_eval=50\n        #feval=metric_xgb\n    \n    )\n    \n    print(\"Best Iteration :: {} \\n\".format(model.best_iteration))\n    \n    \n    if plot:\n        # Plotting Importances\n        fig, ax = plt.subplots(figsize=(24, 24))\n        xgb.plot_importance(model, height=0.4, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model(df_train, features, target, plot=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb1 = xgb.XGBClassifier(\n    booster='dart',\n    objective='multi:softprob',\n    learning_rate= 0.01,\n    num_round= 775,\n    max_depth=8,\n    seed=25,\n    nthread=3,\n    eval_metric='mlogloss',\n    num_class=5\n\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, validX, trainY, validY = train_test_split(df_train[features], df_train[target], test_size=0.2,stratify=df_train[target], random_state=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model  = xgb1\ncross_valid(model,df_train,features,target,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb1\nmodel.fit(trainX[features],trainY)\ny_pred_valid = model.predict_proba(validX[features])\nprint(\"Validation Score:\",metric(validY,y_pred_valid))\ny_pred_test = model.predict(df_test[features])\nresult1 = pd.DataFrame(y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result1[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = model.predict_proba(df_test[features])\nresult = pd.DataFrame(y_pred_test)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df_train[features]\ny = df_train[target]\ntrainX, validX, trainY, validY = train_test_split(df_train[features], df_train[target], test_size=0.2,stratify=df_train[target], random_state=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter optimization(RandomForest)\n* Grid Search CV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn import decomposition\nfrom sklearn import pipeline\n\n\nclassifier = ensemble.RandomForestClassifier(n_jobs = -1)\n\nparam_grid = {\n    \"n_estimators\":[100,200,300,400],\n    \"max_depth\":[1,3,5,7],\n    \"criterion\":[\"gini\",\"entropy\"]\n}\nmodel = model_selection.GridSearchCV(\n    estimator = classifier,\n    param_grid  = param_grid,\n    scoring = \"accuracy\",\n    verbose = 10,\n    n_jobs = 1,\n    cv=5\n)\n\nmodel.fit(trainX,trainY)\nprint(model.best_score_)\nprint(model.best_estimator_.get_params())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\npreds = model.predict(validX)\nprint(metrics.accuracy_score(preds,validY))\nprint(classification_report(preds,validY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Randomiazed Search CV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\npca = decomposition.PCA() \nrf  = ensemble.RandomForestClassifier(n_jobs = -1)\nscl = preprocessing.StandardScaler()\nclassifier1 = pipeline.Pipeline([(\"scaling\",scl),(\"pca\",pca),(\"rf\",rf)])\n\nparam_grid = {\n    \"pca__n_components\":np.arange(10,15),\n    \"rf__n_estimators\":np.arange(100,1500,100),\n    \"rf__max_depth\":np.arange(1,20),\n    \"rf__criterion\": [\"gini\",\"entropy\"]\n}\n\nmodel = model_selection.RandomizedSearchCV(\n    estimator = classifier1,\n    param_distributions = param_grid,\n    n_iter = 10,\n    scoring = 'accuracy',\n    verbose = 10,\n    n_jobs = 1,\n    cv = 5\n)\n\nmodel.fit(trainX,trainY)\nprint(model.best_score_)\nprint(model.best_estimator_.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\npreds = model.predict(validX)\nprint(metrics.accuracy_score(preds,validY))\nprint(classification_report(preds,validY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Sklearn Optimization  (Skopt)","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def optimize(params,param_name,x,y):\n    params = dict(zip(param_name,params))\n    model = ensemble.RandomForestClassifier(**params)\n    kf =model_selection.StratifiedKFold(n_splits=5)\n    accuracies = []\n    for idx in kf.split(X=x,y=y):\n        train_idx , test_idx = idx[0],idx[1]\n        xtrain = X[train_idx]\n        ytrain = y[train_idx]\n        \n        xtest = X[test_idx]\n        ytest = y[test_idx]\n        \n        model.fit(xtrain,ytrain)\n        preds = model.predict(xtest)\n        accuracies.append(metrics.accuracy_score(preds,ytest))\n    return -1.0 * np.mean(accuracies)  \n\nfrom functools import partial\nfrom skopt import space\nfrom skopt import gp_minimize\n\ntrainX, validX, trainY, validY = train_test_split(df_train[features], df_train[target], test_size=0.2,stratify=df_train[target], random_state=13)\n\nparam_space = [\n    space.Integer(3,15,name = \"max_depth\"),\n    space.Integer(100,600,name = \"n_estimators\"),\n    space.Categorical([\"gini\",\"entropy\"],name = \"criterion\"),\n    space.Real(0.01,1,prior = 'uniform', name = \"max_features\")\n    \n]\nparam_names = [\n    \"max_depth\",\n    \"n_estimators\",\n    \"criterion\",\n    \"max_features\"\n]\noptim_func = partial(\n    optimize,\n    param_name = param_names,\n    x=trainX,\n    y = trainY\n)\n\n\nresult = gp_minimize(\n            optim_func,\n            dimensions = param_space,\n            n_calls = 15,\n            n_random_starts = 10,\n            verbose = 10,\n)\n\nprint(dict(zip(param_names,result.x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}