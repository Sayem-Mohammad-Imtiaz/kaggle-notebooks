{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Predicting Heart Attacks With TensorFlow Deep Learning**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### About the Dataset\n\n**This dataset contains a series of recorded medical attributes from patients with varying likelihoods of heart attack.**\n\n*From the University California, Irvine Machine Learning Repository:*\n\n<br>\nCreators:\n1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.\n\nOf the four original datasets (Cleveland, Hungary, Switzerland, VA Long Beach), only the Cleveland dataset it used.\n\nThe original 76 attributes recorded in the study was narrowed down to 14 (13 features and a predicted value).\n\n<br>\nThe features used are:\n\n1) age<br>\n2) sex<br>\n3) chest pain type (4 values)<br>\n4) resting blood pressure<br>\n5) serum cholestoral in mg/dl<br>\n6) fasting blood sugar > 120 mg/dl<br>\n7) resting electrocardiographic results (values 0,1,2)<br>\n8) maximum heart rate achieved<br>\n9) exercise induced angina<br>\n10) oldpeak = ST depression induced by exercise relative to rest<br>\n11) the slope of the peak exercise ST segment<br>\n12) number of major vessels (0-3) colored by flourosopy<br>\n13) thal: 0 = normal; 1 = fixed defect; 2 = reversable defect<br>\n\n<br>\nThe predicted value is based on the likelihood of a heart attack occurring:\n- Value 0: < 50% diameter narrowing in any major vessel\n- Value 1: > 50% diameter narrowing in any major vessel","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Training a Deep Learning Model to Predict Heart Attack Likelihood\n\n#### *Brief Overview:*\nWe will use TensorFlow and Keras to train a model on the dataset.\n\n* To begin, we will load the .csv data in a Pandas DataFrame using the pd.read_csv() method.\n* We will then format the data into a numpy array in order to simplify the process.\n* From here, we will process the data and feed it into a TensorFlow ANN with a single hidden layer.\n* Finally, we will examine the prediction accuracy of the model.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Import dependencies","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading data\n\nWe being by loading the .csv file using pd.read_csv().\n\nAdditionally, we see some preliminary stats about the data.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"heart_df = pd.read_csv(\"../input/health-care-data-set-on-heart-attack-possibility/heart.csv\")\nheart_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preprocessing\n\nWe now convert the Pandas DataFrame into a numpy array, for easier use with TensorFlow.\n\nWe also shuffle the array to avoid any inherent bias in the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_np = heart_df.to_numpy()\n\nnp.random.shuffle(heart_np)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We allocate 80% of the data to the training set and 20% to the test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_split = .8\n\nnum_examples = heart_np.shape[0]\nnum_train_examples = int(np.floor(num_examples*train_test_split))\nnum_test_examples = int(np.ceil(num_examples*(1 - train_test_split)))\n\nprint(\"Training Examples:\", num_train_examples)\nprint(\"Test Examples:\", num_test_examples)\nprint(\"\\nTotal Examples:\", num_examples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We then split the dataset between train and test data, and separate the label column from each subset to obtain the necessary format for training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = heart_np[0:num_train_examples, :]\ntest_data = heart_np[num_train_examples:len(heart_np), :]\n\nX_train = train_data[:, 0:-1]\ny_train = train_data[:, -1]\n\nX_test = test_data[:, 0:-1]\ny_test = test_data[:, -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our training set contains 242 training examples.<br>\nOur input has 13 features and our output will be a single column used for binary classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building and compiling our model\n\nWe define our neural network model with a single hidden layer consisting on 16 activation nodes.<br>\nA simple design like this works best for a smaller dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = keras.Input(shape=(13), name=\"features\")\nx = layers.Dense(16, activation=\"relu\", name=\"dense_1\")(inputs)\noutputs = layers.Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will train our model with a batch size of 64 and train for 300 epochs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCHS = 300","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use the Adam optimization algorithm with the standard (recommended) parameter values for $\\beta_1$, $\\beta_2$, and $\\epsilon$.<br>\nOur learning rate will be 0.001.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile the model using Keras' SparseCategoricalCrossentropy loss function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=optimizer,\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the model\n\nWe are ready to train our model.<br>\nWe pass in X_train as our array of features, and use y_train as our label column.\n\nWe enable shuffling to further reduce any bias in the ordering of the training examples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    X_train,\n    y_train,\n    shuffle=True,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Post-training evaluation\n\nWe will now examine the performance of the model on the test set.<br>\nLet's create an array of predictions for the data in X_test.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quickly define a function for comparing our model's predictions to the actual values in y_test.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_prediction_array(predictions, y):\n    pred_arr = (predictions[:, 0] < 0.5)\n    pred_arr = np.column_stack((pred_arr, y))\n    return pred_arr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We tally up the number of correct predictions and obtain a percentage for accuracy of the model.\n\nWe obtain an accuracy in the 80-90% range.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = get_prediction_array(predictions, y_test)\n\nnum_correct = 0\n\nfor i in range(num_test_examples):\n    if results[i, 0] == results[i, 1]:\n        num_correct += 1\n\nprint(\"Accuracy:\", num_correct/num_test_examples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that TensorFlow's evaluate() function gives us the same value.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test)\nprint(\"\\nAccuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create an array for prediction success (1 = Correct, 0 = Incorrect).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"performance = (results[:, 0] == results[:, 1]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the bar chart that our model performed fairly well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Model Performance (Correct vs. Incorrect)\")\nplt.xlabel(\"1 = Correct  0 = Incorrect\")\nplt.ylabel(\"Count\")\nplt.xticks([1, 0])\nplt.xlim(1.25, -0.25)\n\nplt.hist(performance)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}