{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Automation_of_occupations_consequences_for_the_USA"},{"metadata":{},"cell_type":"markdown","source":"Nobody has a crystal ball that can tell the future, but some people don’t need an ancient relic to foresee what’s going to haven, because they are currently building the future in which we will all live.\n\nIt’s true that AI and Automation will wreak havoc among the workforce rending a large part of the population useless and without economic value.\n\nNot only they will take your jobs, but they will make the rich even richer.\n\nIf you are looking for job opportunities which are less likely to be affected by AI or automation, well you’re in the right place.\n\nThat said, it might be wise to consider some of the fields which will see an uptick in productivity in the following years."},{"metadata":{},"cell_type":"markdown","source":"Questions to analyse:\n\n1. Which occupatios are the most sensitive and the most robust to automatisation (computerisation)?\n2. See, how looks data distribution\n3. What is the jobs loss in the US, if automatisation take out occupations with automatisation probability equal to 0.7 or higher?\n4. Which US states are the most sensitive and the most robust to automatisation?\n5. Compare most common occupations or automatisation"},{"metadata":{},"cell_type":"markdown","source":"# I. Data import and functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport os\nfrom textwrap import wrap\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\nsns.set(font_scale=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_heatmap(data_in, title_in, number):\n    '''\n    Inputs:\n        data_in: Data Frame of objects and floats;\n        title_in: string, chart title;\n        number: boolean, for showing or not showing number values in heatmap.\n    Output: \n        heatmap chart.\n    '''\n    plt.figure(figsize=(30,20))\n    sns.heatmap(data=data_in, annot=number) \n    plt.title('\\n'.join(wrap(title_in)), fontsize=40, fontweight=\"bold\", pad=40)\n    plt.ylabel(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def barplot(data_in, x_data, y_data, title_in, hue_in, line):\n   '''\n    Inputs:\n        data_in: Data Frame of objects and floats;\n        x_data: float, x axis, number of jobs positions\n        y_data: object, states names\n        title_in: string, chart title (string);\n        hue_in: float, used values threshhold or None\n        line: float, mean value line for bars.\n    Output: \n        bar chart.\n    '''\n    plt.figure(figsize=(15,14))\n    graph = sns.barplot(x=x_data, y=y_data, hue=hue_in, data=data_in, palette=\"twilight\")\n    plt.title('\\n'.join(wrap(title_in)), fontsize=20, fontweight=\"bold\", pad=20)\n    plt.xlabel(\"Number of jobs positions\")\n    graph.axvline(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of colors (from iWantHue)\ncolors = [\"#E13F29\", \"#D69A80\", \"#D63B59\", \"#AE5552\", \"#CB5C3B\", \"#EB8076\", \"#96624E\"]\n\ndef plot_pie(data_in, title_in, labels_in):\n    '''\n    Inputs:\n        data_in: Data Frame of objects and floats;\n        title_in: string, chart title;\n        labels_in: object, occupation name.\n    Output: \n        pie chart.\n    '''\n    plt.pie(\n        # using data total arrests\n        data_in,\n        # with the labels being officer names\n        labels=labels_in,\n        # with no shadows\n        shadow=True,\n        # with colors\n        colors=colors,\n        # with one slide exploded out\n        explode=(0.15, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n        # with the start angle at 90%\n        startangle=90,\n        # with the percent listed as a fraction\n        autopct='%1.1f%%',\n        )\n    plt.title(label='\\n'.join(wrap(title_in, 40)), fontsize=20, fontweight=\"bold\", loc=\"center\", pad=20)\n#     sns.set(font_scale=1.3)\n    # View the plot drop above\n    plt.axis('equal')\n\n    # View the plot\n    plt.tight_layout()\n#     plt.savefig('Dakota pie.svg', bbox_inches=\"tight\")\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import \"Automation data by state\""},{"metadata":{"trusted":true},"cell_type":"code","source":"Automation_data = \"../input/occupation-salary-and-likelihood-of-automation/automation_data_by_state.csv\"\nA_data = pd.read_csv(Automation_data, encoding = \"ISO-8859-1\")\nstate_names = A_data.columns[3:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import \"Occupation salary\""},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_data = \"../input/occupation-salary-and-likelihood-of-automation/occupation_salary.xlsx\"\nS_data = pd.read_excel(salary_data, index_col=\"OCC_CODE\")\n# S_data.shape\n# S_data.isnull().sum() #only in ANNUAL, HOURLY columns a lot of null values.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To compare occupation numbers in percentage, I need USA population data.\nI couldn't read html in the Kaggle platorm, so I made csv data file in pycharm. The code here:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# link = 'https://www.infoplease.com/us/states/state-population-by-rank'\n# w = pd.read_html(link, header=0)\n# w[0].columns\n# df_1 = w[0]\n# condition = df_1['State'].isin(state_names)\n# population_0 = df_1[condition]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then I opened the US_population csv here:"},{"metadata":{"trusted":true},"cell_type":"code","source":"link = '../input/uspopulation/US_population_2.csv'\npopulation = pd.read_csv(link, header=0)\npopulation.head() #- Census population - valstijos visos pupuliacijos skaičiai.\n# null verčių stulpeliuose nėra","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II. Data cleaning and preparation for visualisations"},{"metadata":{},"cell_type":"markdown","source":"## ????Salary data (S_data)"},{"metadata":{},"cell_type":"markdown","source":"Drop emty columns: ANNUAL, HOURLY"},{"metadata":{"trusted":true},"cell_type":"code","source":"S_data_clean = S_data.drop(['ANNUAL', 'HOURLY'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Population data"},{"metadata":{},"cell_type":"markdown","source":"Sort data by states and take only state and population columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"population_sort = population.sort_values(by=['State'])\nstates_pop = population_sort.loc[:, ['State', 'July 2019 Estimate']].reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Automations data (A_data) preparation"},{"metadata":{},"cell_type":"markdown","source":"Sum up all occupation workers for the US. After that I drop occupation lines, where are zero workers in all states. Then I sort data by US workers' numbers and by probability. Take 5 occupations with highest and 5 occupations with lowest automation probabilities."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_sum = A_data[state_names].sum(axis=1)\nus_sum_DF = pd.DataFrame({'US_workers':us_sum.values})\nOccupation_proba = A_data[['Occupation', 'Probability']]\nUS_O_proba = Occupation_proba.join(us_sum_DF)\nindex_names = US_O_proba[ US_O_proba['US_workers'] == 0 ].index\nUS_worker = US_O_proba.drop(index_names).reset_index()\ncommon_US_work = US_worker.drop(['index'], axis=1)\n\nUS_work = common_US_work.sort_values(by=['US_workers'], ascending=False).reset_index(drop=True)\nUS_sort_probability = common_US_work.sort_values(by=['Probability'], ascending=False).reset_index(drop=True)\n\nA_head = US_sort_probability.head()\nA_tail = US_sort_probability.tail()\nhighest_lowest_prob = pd.concat([A_head, A_tail])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop zero lines from (A_data) and set column \"SOC\" as index."},{"metadata":{"trusted":true},"cell_type":"code","source":"A_data_clean = A_data.drop(index_names).reset_index()\nA_data_SOC = A_data_clean.set_index('SOC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5 occupations with highest probability for automatisation, and 5 with lowest probability for automatisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"A_data_prob_sort = A_data_clean.sort_values(by=['Probability'], ascending=False).reset_index()\nA_head_clean = A_data_prob_sort.head()\nA_tail_clean = A_data_prob_sort.tail()\n\nA_data_highest_lowest_prob = pd.concat([A_head_clean, A_tail_clean])\nA_data_highest_lowest_prob_present = A_data_highest_lowest_prob.drop(['level_0', 'index'], axis=1).set_index('Occupation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transform occupation workers numbers per state to occupation workers population ratio. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform A_data\ncol_names = A_data_clean.columns\nA_trans = pd.DataFrame(A_data_clean.values.T, columns=A_data_clean['SOC'], index=col_names)\nA_tr = A_trans.iloc[4:]\n\n# Number of occupations jobs in states divided by population of state. Then the data frame transformed back\nreliative_popul = A_tr.div(states_pop['July 2019 Estimate'].values,axis=0)\nreliative_popul = reliative_popul.fillna(0)\nA_double_T = reliative_popul.T\n\n# Join occupation and probability coulumns back to transformed data frame.\nA_data_double_T = A_data_SOC[['Occupation', 'Probability']].join(A_double_T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Group occupation to categories by mean probability and occupations groups ratio to population per state."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split SOC column to 'Occupation_group_no' and 'Occupation_no'\nSOC_column = A_data_double_T.reset_index()\nSOC_column['SOC'] = SOC_column.SOC.astype(str)\nSOC_column[['Occupation_group_no','Occupation_no']] = SOC_column.SOC.str.split(\"-\",expand=True,)\nGroup_data = SOC_column.copy()\n\n# Group occupation categories by mean probability and occupations groups ratio to population per state\nGroup = Group_data.groupby(['Occupation_group_no']).Probability.mean()\nGroup_states = Group_data.groupby(['Occupation_group_no'])[state_names].sum()\n\n# Titles of occupation groups\ns = pd.Series(['Management', 'Business Operations', 'Computer and Mathematical', 'Architecture and Engineering', 'Life, Physical, and Social Science', 'Community and Social Service', 'Legal', 'Education, Training, and Library', 'Design, Entertainment and Sports', 'Healthcare Practitioners', 'Healthcare Support', 'Protective Service', 'Food Serving Related', 'Cleaning and Maintenance', 'Personal Care and Service', 'Sales and Related', 'Administrative Support', 'Farming, Fishing, and Forestry', 'Construction and Extraction', 'Installation and Repair', 'Production', 'Transportation'], index=['11', '13', '15', '17', '19', '21', '23', '25', '27', '29', '31', '33', '35', '37', '39', '41', '43', '45', '47', '49', '51', '53'])\n\nOccupations_groups_pd = pd.DataFrame({'index':s.index, 'Occupations groups':s.values}) # Make data frame from series\nOccupations_groups = Occupations_groups_pd.set_index('index')\n\n# Join data to one table and sort by probability\nOccupations_groups_join1 = Occupations_groups.join(Group)\nOccupations_groups_join2 = Occupations_groups_join1.join(Group_states)\nOccupations_groups_prob_sort1 = Occupations_groups_join2.sort_values(by=['Probability'], ascending=False).reset_index()\nOccupations_groups_prob_sort = Occupations_groups_prob_sort1.fillna(0)\nOccupations_groups_prob_sort.head()\n\n# Merge Occupations groups and probability columns to one\nOccupations_groups_prob_round = Occupations_groups_prob_sort['Probability'].round(2)\nOccupations_groups_prob_round_df = pd.DataFrame({'Probability':Occupations_groups_prob_round.values})\nOccupations_groups_prob_sort[\"Occupations groups and Probability\"] = Occupations_groups_prob_sort[\"Occupations groups\"] + \" \" + Occupations_groups_prob_round_df[\"Probability\"].astype(str)\nOccupations_groups_plot = Occupations_groups_prob_sort.copy().set_index('Occupations groups and Probability')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# III. Data analysis topic\n# IV. Data analysis topic2"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Heat map plot function\n# Barplot function\n# plt.pie function"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot heat map"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heatmap(Occupations_groups_plot[state_names], 'Occupation categories and the probability of automation by states', False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heatmap(Occupations_groups_plot[['South Dakota', 'Nevada', 'District of Columbia', 'Massachusetts']],'Occupation categories and probability of automatisation in S. Dakota, Nevada, DC and Massachusetts', True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# patrumpint ilgiausiu spec pav. su kodu\nsurast reikiamas specialybes ir jas replace."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_heatmap(A_data_highest_lowest_prob_present[state_names], 'Workers numbers in occupations with 5 highest and 5 lowest probabilities for automation', False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Ar sita distribution grafika palikt**\nPo to pasinaudot atrnkant didelės automatizavimo specialybes ir turincias dideli skaiciu darbuotoju\nUS occupations number ant accupations probabilities distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.title(\"US workers numbers and Occupations automatisation probabilities distribution\")\nsns.set_style(\"dark\")\nplt.figure(figsize=(20,20))\nfig = sns.jointplot(x=US_work['Probability'], y=US_work['US_workers'], kind=\"kde\")\n# plt.ylabel(\"Occupations numbers\")\nsns.set(font_scale=1.2)\n# ax.set_ylim(1,31)\n# ax.set_yticks(range(1,32))\n# g.despine(bottom=True, left=True)\nplt.gcf().set_size_inches(12, 8)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Probability higher than 0.7  representing a \"high risk category, meaning that associated occupations are potentially automatable over some unspecified number of years, perhaps a decade or two\" according to the original research paper. We can look to this probability as to a time frame, where higher propabilty occupations are likely to be automated sooner."},{"metadata":{},"cell_type":"markdown","source":"The lost work positions and state population ratio. I take lost work position, when work automation probability ir equal to 0.7 or higher (threshhold >= 0.7)."},{"metadata":{"trusted":true},"cell_type":"code","source":"threshhold = 0.7 # accupations automation probability threshhold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total number of jobs positions per state"},{"metadata":{},"cell_type":"markdown","source":"I estimated, that these total job numbers are about 10%, due to jabs position not included. I got data with all jobs where data was not available or there were less than 10 employees were marked as zero."},{"metadata":{"trusted":true},"cell_type":"code","source":"p = A_data_clean.sort_values(by=['Probability'], ascending=False)\nsum_work_per_state = p[state_names].sum()\nStates_sum_DF = pd.DataFrame({'States':sum_work_per_state.index, 'sum_work_positions':sum_work_per_state.values})\nStates_sum_sort =  States_sum_DF.sort_values(by=['sum_work_positions'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"barplot(States_sum_sort, 'sum_work_positions', 'States', \"Total number of jobs positions per state\", None, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot second bar to every state - left absolute occupation positions when threshhold < 0.7."},{"metadata":{"trusted":true},"cell_type":"code","source":"p_index = p.reset_index().drop(['level_0', 'index', 'SOC'], axis=1)\np05 = p_index.loc[(p_index.Probability < threshhold)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum_work_per_state05 = p05[state_names].sum()\nStates_sum_DF05 = pd.DataFrame({'States':sum_work_per_state05.index, 'sum_work_positions':sum_work_per_state05.values})\nStates_sum_sort05 =  States_sum_DF05.sort_values(by=['sum_work_positions'], ascending=False)\nStates_sum_sort05.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"barplot(States_sum_sort05, 'sum_work_positions', 'States', \"Total number of jobs positions per state\", None, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How many jobs positions would be lost in States, if we lost accupations which have automation probability equal to 0.7 or higher."},{"metadata":{"trusted":true},"cell_type":"code","source":"States_sum_DF['Threshhold'] = 1.0\nStates_sum_DF05['Threshhold'] = threshhold\nStates_sum_DF05.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Compare_sums = pd.concat([States_sum_DF, States_sum_DF05])\nCompare_sums_sort = Compare_sums.sort_values(by=['sum_work_positions'], ascending=False)\nCompare_sums_sort","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"barplot(Compare_sums_sort, 'sum_work_positions', 'States', \"Total number of jobs positions per state now (Threshhold=1.0) and when higher automation probability accupations lost (Threshhold=threshhold)\", 'Threshhold', 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets look, what are reliative loss numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"States_sum_join = States_sum_DF.join(States_sum_DF05, lsuffix='', rsuffix='0.5')\nStates_sum_drop = States_sum_join.drop(['Threshhold', 'States0.5', 'Threshhold0.5'], axis=1)\nRelative_jobs_drop = ((States_sum_drop['sum_work_positions']-States_sum_drop['sum_work_positions0.5'])/States_sum_drop['sum_work_positions'])*100\nStates_sum_drop.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Relative_jobs_drop_DF = pd.DataFrame({'Lost jobs ratio':Relative_jobs_drop.values})\nRelative_jobs_drop_States = States_sum_drop.join(Relative_jobs_drop_DF)\nRelative_jobs_drop_States_sort = Relative_jobs_drop_States.sort_values(by=['sum_work_positions'], ascending=False)\nRelative_jobs_drop_mean = Relative_jobs_drop_States_sort['Lost jobs ratio'].mean()\nRelative_jobs_drop_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"barplot(Relative_jobs_drop_States_sort, 'Lost jobs ratio', 'States', \"Lost jobs ratio per state when we lost jobs with automatisation probability equal to 0.7 (Threshhold) or higher\", None, Relative_jobs_drop_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Relative_jobs_drop_States_highest = Relative_jobs_drop_States.sort_values(by=['Lost jobs ratio'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"barplot(Relative_jobs_drop_States_highest, 'Lost jobs ratio', 'States', \"Lost jobs ratio per state when we lost jobs with automatisation probability equal to 0.7 (Threshhold) or higher\", None, Relative_jobs_drop_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# South Dakota and Nevada have most jobs losses. Lets look, what are biggest occupations they lost"},{"metadata":{},"cell_type":"markdown","source":"Let's start with Nevada data"},{"metadata":{"trusted":true},"cell_type":"code","source":"nevada = A_data_clean[['Occupation', 'Probability', 'South Dakota', 'Nevada']].sort_values(by=['Probability'], ascending=False)\nnevada07_full = nevada.loc[(nevada.Probability >= threshhold)].sort_values(by=['Nevada'], ascending=False).reset_index()\nnevada07 = nevada07_full.head(9)\nnevada07_tail = nevada07_full.tail(308).Nevada.sum()\ndf2 = {'Occupation': 'Other', 'Probability': 0, 'South Dakota': 0, 'Nevada': nevada07_tail} \nnevada07 = nevada07.append(df2, ignore_index = True) \nnevada07","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot pie chart of Nevada data"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie(nevada07['Nevada'], \"The largest most likely automatable occupations in Nevada\", nevada07['Occupation'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's look to South Dakota"},{"metadata":{"trusted":true},"cell_type":"code","source":"dakota = A_data_clean[['Occupation', 'Probability', 'South Dakota']].sort_values(by=['Probability'], ascending=False)\ndakota07_full = dakota.loc[(dakota.Probability >= threshhold)].sort_values(by=['South Dakota'], ascending=False).reset_index()\ndakota07 = dakota07_full.head(9)\ndakota07_tail = dakota07_full.tail(308)['South Dakota'].sum()\ndf2 = {'Occupation': 'Other', 'Probability': 0, 'South Dakota': dakota07_tail} \ndakota07 = dakota07.append(df2, ignore_index = True) \ndakota07","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot pie chart of South Dakota data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie(dakota07['South Dakota'], \"The largest most likely automatable occupations in South Dakota\", dakota07['Occupation'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"District of Columbia has lowest sensitivity for automation. Let's check the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"DC = A_data_clean[['Occupation', 'Probability', 'District of Columbia']].sort_values(by=['Probability'], ascending=False)\nDC07_full = DC.loc[(DC.Probability >= threshhold)].sort_values(by=['District of Columbia'], ascending=False).reset_index()\nDC07 = DC07_full.head(9)\nDC07_tail = DC07_full.tail(308)['District of Columbia'].sum()\ndf2 = {'Occupation': 'Other', 'Probability': 0, 'District of Columbia': DC07_tail} \nDC07 = DC07.append(df2, ignore_index = True) \nDC07","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"District of Columbia pie chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie(DC07['District of Columbia'], \"The largest most likely automatable occupations in District of Columbia\", DC07['Occupation'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Massachusetts data"},{"metadata":{"trusted":true},"cell_type":"code","source":"massachusetts = A_data_clean[['Occupation', 'Probability', 'Massachusetts']].sort_values(by=['Probability'], ascending=False)\nmassachusetts07_full = massachusetts.loc[(nevada.Probability >= threshhold)].sort_values(by=['Massachusetts'], ascending=False).reset_index()\nmassachusetts07 = massachusetts07_full.head(9)\nmassachusetts07_tail = massachusetts07_full.tail(308).Massachusetts.sum()\ndf2 = {'Occupation': 'Other', 'Probability': 0, 'Massachusetts': massachusetts07_tail} \nmassachusetts07 = massachusetts07.append(df2, ignore_index = True) \nmassachusetts07","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Massachusetts pie chart**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie(massachusetts07['Massachusetts'], \"The largest most likely automatable occupations in Massachusetts\", massachusetts07['Occupation'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions"},{"metadata":{},"cell_type":"markdown","source":"1. The most robust occupations for automatisations: Saugiausios specialybės nuo automatizacijos: social service, management, computer and mathematical and medicine. The most sensitive: administrative support, production, farming, fishing, forestry, food serving related.\n2. A bit more occupations have higher probability for automatisation\n3. US would loss around half of all jobs, if automatisation take out occupations with automatisation probability equal to 0.7 or higher?\n4. South Dakota and Nevada are the most sensitive and District of Columbia and Massachusetts are the most robust to automatisation.\n5. Nevada and South Dakota have most occupations with high probability for automation. District of Columbia also has many occupations with low probability for automatisation like management, arts and protective service."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}