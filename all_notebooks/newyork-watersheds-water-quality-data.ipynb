{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# Here is NY Watersheds which shows water quality values sampled from many locations. \n# This analysis is to show the healtiness level of surface water bodies in NY \n# Data includes 4-hour-Turbidity values (six times a day), Daily Average Turbidity\n# and Fecal Coliform level of the sample as well as with the date and location info.\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# I, first start by importing necessary py libs and opening the data \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\nimport os\nwqdata = pd.read_csv('../input/watershed-water-quality-data.csv')\nwqdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6609842302cee920f4a5a74d438c4a1ff574cd63"},"cell_type":"code","source":"# Here we look at the descriptive statistics on the data exploring the \n# data range, averages and sample counts of only numeric data (so it excludes date and location)\nwqdata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2891d9a1540243daa33133ac9703a2f9cf7b4fa7"},"cell_type":"code","source":"# To examine data, we could use .head() or .tail() for instance\nwqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# .info shows data types and names of the columns with data range\n# it is also possible to see the missing data in each data attribute (columns)\nwqdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c54852eb84e192b3d551a10a350d38da715ffe4"},"cell_type":"code","source":"# Here, we produce a correlation matrix of each attribute to see \n# if there is a direct relationship among turbidity and fecal coliform (FC) levels\n\nwqdata.corr()\n\n# We can say that 4-hour-turbidity samples shows high correlation with previous and next samples\n# All 4-hour-turbidity samples also highly correlated with daily turbidity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"411e8155ba58bdefb050337d306e768927bd571a"},"cell_type":"code","source":"# By using seaborn library's correlation map function we build a color - coded correlation matrix \n\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(wqdata.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()\n\n# Here we have 4-hour-turbidity (interval) samples and daily turbidity average\n# It is possible to say the 4PM has the least effect on daily turbidity average \n# and other interval samplings since it has the lowest correlation with the others","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c12c88a572a558b4fc5682e81dfdebba96f36af"},"cell_type":"code","source":"wqdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b827cc7d5863c3181bd4b2f36ce6458f31be465"},"cell_type":"code","source":"# To see that better we will look at the scatter plots of interval \n# samples against daily average of turbidity\n\n# Scatter Plots will be set as x = Daily Turbidity Average and y = interval sampling \n\nwqdata.plot(kind='scatter', marker='+', grid=True, x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 12AM',alpha = 0.5,color = 'orange')\nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('Turbidity(NTU) at 12AM')\nplt.title('12 AM vs Daily Turbidity Scatter Plot')\n\nwqdata.plot(kind='scatter', marker='+', grid=True, x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 4AM',alpha = 0.5,color = 'orange')\nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('Turbidity(NTU) at 4AM')\nplt.title('4 AM vs Daily Turbidity Scatter Plot')\n\nwqdata.plot(kind='scatter', marker='+', grid=True, x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 8AM',alpha = 0.5,color = 'orange')\nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('Turbidity(NTU) at 8AM')\nplt.title('8 AM vs Daily Turbidity Scatter Plot')\n\nwqdata.plot(kind='scatter', marker='+', grid=True, x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 12PM',alpha = 0.5,color = 'orange')\nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('Turbidity(NTU) at 12PM')\nplt.title('12 PM vs Daily Turbidity Scatter Plot')\n\nwqdata.plot(kind='scatter', marker='+', grid=True, x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 4PM',alpha = 0.5,color = 'orange')\nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('Turbidity(NTU) at 4PM')\nplt.title('4 PM vs Daily Turbidity Scatter Plot')\n\nwqdata.plot(kind='scatter', marker='+', grid=True, x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 8PM',alpha = 0.5,color = 'orange')\nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('Turbidity(NTU) at 8PM')\nplt.title('8 PM vs Daily Turbidity Scatter Plot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8660adeb06e25fc943baa60e0ab11e2c6db4769"},"cell_type":"markdown","source":"**Bu kısmı düzenleyerek tüm veri serilerini tek plota çizdirelim**\n\nindex = [0,1,2,3,4,5]\nmarkers=['.','x','+','-','*','~',]\ncolors=['orange','blue','green','purple','red','yellow']\nintervals = ['Turbidity(NTU) at 12AM', 'Turbidity(NTU) at 4AM','Turbidity(NTU) at 8AM','Turbidity(NTU) at 12PM','Turbidity(NTU) at 4PM', 'Turbidity(NTU) at 8PM']\n\nfor i in index:\n    data.plot(kind='scatter', marker=markers[i], grid=True, x='Average 24hrTurbidity(NTU)', y=intervals[i], alpha = 0.5,color = colors[index]\n              \nplt.xlabel('Average 24hrTurbidity(NTU)') \nplt.ylabel('4-hour-Turbidity(NTU)')\nplt.title('4 PM vs Daily Turbidity Scatter Plot')"},{"metadata":{"trusted":true,"_uuid":"37a7087da3e1d37e9a213ed74f0bf85030debfb8"},"cell_type":"code","source":"# This section covers some plots by using Matplotlib library\n# such as line, scatter and histogram plots\n\n# Line Plot \nwqdata['Average 24hrTurbidity(NTU)'].plot(kind='line', y='Average 24hrTurbidity(NTU)', x='Date', color='r', label='Turbidity Daily Avg.', linewidth=1, alpha=0.7, grid=True, linestyle='-')\nwqdata['Turbidity(NTU) at 12PM'].plot(color='b', y='Turbidity(NTU) at 12PM', x='Date', label='Turbidity at 12PM', linewidth=1, alpha=0.7, grid=True, linestyle='-')\n\nplt.legend(loc='upper right')     # legend = puts label into plot\n#plt.xlabel('Date')              # label = name of label\n#plt.ylabel('Turbidity (NTU)')\nplt.title('Line Plot')            # title = title of plot\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a5ec4cfcc4b18c0b75efa42161f034fd61af1e6"},"cell_type":"code","source":"wqdata.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1ba1909af855b2a6fa9f1cf0fe2dcd40d460cfe","trusted":true},"cell_type":"code","source":"wqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09d5ea39ba156f86d0ab767d7f919cc2a9be8dd6"},"cell_type":"code","source":"wqdata.plot(kind='scatter', x='Average 24hrTurbidity(NTU)', y='Turbidity(NTU) at 12PM', color='red', alpha=0.2, grid=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2d675a5071ca8dedc1500699b19b10e6ffbf5fcc"},"cell_type":"code","source":"wqdata['Average 24hrTurbidity(NTU)'].plot(kind='hist', color='blue', label='Turbidity Daily Avg.', bins=50, figsize=(15,15), alpha=0.7, grid=True)\n\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38636c66560bf163d2011e328d464bd37720b275"},"cell_type":"code","source":"# We will create and play with pandas library using our data \nwqdata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b57ae9434758159185743e63d9b8ed07f68dfd75"},"cell_type":"code","source":"wqdata[:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14da5f6ddf86df875b6a51bb19debe72409651d1"},"cell_type":"code","source":"wqdata[2:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"816d3d6952478e434dc358607922dbbcd90420bc"},"cell_type":"code","source":"import pandas as pd \nwqdata = pd.read_csv('../input/watershed-water-quality-data.csv')\n\n# We'll define two columns as separate data series \n# which are dates and corresponding turbidity avegare values\ndates=wqdata['Date']\nturbidity=wqdata['Average 24hrTurbidity(NTU)']\n\nprint(dates)\nprint(turbidity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baa527bf98e7084468090953b0c8cece1cb9836b"},"cell_type":"code","source":"print(dates>'2018-12-12T00:00:00')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b8f232ad723aff6936098b657f29672cee997b8"},"cell_type":"code","source":"print(turbidity<0.85)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4e90370d39e89b4f53f7f757a99c41188ceefeb2"},"cell_type":"code","source":"# Now we define a filter to see the data exactly we wanted to see\ndate_filter = wqdata['Date']>'2018-12-27T00:00:00' # Last four days of the dataset\nwqdata[date_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbd1ce01a942bddc0f646b6fc3923eeac289569d"},"cell_type":"code","source":"val_filter = wqdata['Average 24hrTurbidity(NTU)']>0.55\nwqdata[val_filter]\n# Now we got the turbidity values which are greater than 0.95\n# 1440 rows to be exact, as noted in the bottom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ea8a8362999dae86de1b1c204cb5f31e9bb59d42"},"cell_type":"code","source":"# Now we use numpy logical_and operator to combine both filter \nwqdata[np.logical_and(wqdata['Date']>'2018-12-27T00:00:00', wqdata['Average 24hrTurbidity(NTU)']>0.55)]\n# We combined the filters and got data collected after specified date \n# and having values higher than 0.55","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4eaacaf09400b05011206f2a05150b523e24e4e"},"cell_type":"code","source":"#gives same output \nwqdata[(wqdata['Date']>'2018-12-27T00:00:00')&(wqdata['Average 24hrTurbidity(NTU)']>0.55)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8007370b6afe927e17cd40aa9cdd060ebd47162f"},"cell_type":"code","source":"wqdata.loc[3:10, 'Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ab39d4db6d63ca8134559da30a864809c4d1f38"},"cell_type":"code","source":"wqdata.loc[3:10, ['Date','Turbidity(NTU) at 8AM', 'Turbidity(NTU) at 8PM']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b52f4a48cfd54bcbdebf66de33390231f328dff6"},"cell_type":"code","source":"# Data Cleaning\nwqdata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ddcd90a46da4b67e3662fe283164c44c88ebf9a"},"cell_type":"code","source":"wqdata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eafe7ceeda02cbc8d08eac92d600ee11a2fd3e5e"},"cell_type":"code","source":"wqdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a9bd50a3d822707c44e32af7a673c33e24682ed"},"cell_type":"code","source":"# We'd like to know the frequency of different values for a data column (attribute).\n# This is why we'd use .value_counts() method \n# This method is good to produce data frequency and visualize it by using histogram plot\nprint(wqdata['Average 24hrTurbidity(NTU)'].value_counts(dropna=False)) #dropna property is for considering NaN / null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5af0499c37cb70b0f1a3060203ae06fcfa940591"},"cell_type":"code","source":"wqdata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34d8aa71368e284374310ad33590e5f7fb840e79"},"cell_type":"code","source":"wqdata.boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de1fd2cd37d64ff3ad17f6e9b3438044f88dade0"},"cell_type":"code","source":"wqdata.boxplot(column='Average 24hrTurbidity(NTU)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d91125332e2821d4ef82edab248cfb3301a8578"},"cell_type":"code","source":"# Data Melting \n\n# Melting a dataset actually unpivots it. This means, by melting a data, \n# we create a new dataset, insert entries by using the identifier value (ID column).\n# Identifier value is used in a new entry for each of the value column we choose. \n# For instance, we melt wqdata dataframe around 'Date' column and choose \n# 'Turbidity(NTU) at 12AM', 'Turbidity(NTU) at 12PM', and 'Average 24hrTurbidity(NTU)'\n# columns as value columns, we'll get 3x rows for the new dataframe since we'll see\n# a new row of Turbidity values of a date.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"784c08c418816352ce1f37b5d13f8acf39c57eee"},"cell_type":"code","source":"wqdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bc7a283f287988d245f2c9437f191bd05f6cd2e"},"cell_type":"code","source":"melted = pd.melt(frame=wqdata, id_vars='Date', value_vars=['Turbidity(NTU) at 12AM', 'Turbidity(NTU) at 12PM', 'Average 24hrTurbidity(NTU)'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d61630053913a35347234b00511804facca2ca78"},"cell_type":"code","source":"melted.pivot(index='Date', columns='variable', values='value') \n\n# this code should re-pivot selected four columns though it throws the error below\n# the reason is index column in our data has duplicates which should not be. \n# there is no way to build a column with unique values within this dataset right now \n# without changing the values or combining columns etc. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe5dc9be1b1a36b063a2c903e1bb51ac91ba7792"},"cell_type":"code","source":"# Data Concatenation \n\n# This can bw done in two ways: \n# 1) Vertical which glues rows of two datasets with same number of columns,  pd.concat([dataset1, dataset2], axis=0, ignore_index=True)\n# 2) Horizontal which glues columns of two datasets with same number of rows,  pd.concat([dataset1, dataset2], axis=1)\n\ndataset1 = wqdata.head()\ndataset2 = wqdata.tail()\n\nvconcat = pd.concat([dataset1, dataset2], axis=0, ignore_index=True) # ignore_index=True re-index all data rows\nvconcat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"094733eabe33858f341b2f38772a9d30bd56b504"},"cell_type":"code","source":"dataset1 = wqdata.head()\ndataset2 = wqdata.tail()\n\nhconcat = pd.concat([dataset1.Date, dataset1['Turbidity(NTU) at 12AM'], dataset1['Turbidity(NTU) at 12PM']], axis=1)\nhconcat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"196814113a4385b2643434946824f9daea4f8555"},"cell_type":"code","source":"# Our data could have columns with wrong data types\n# When we examine it with .dtypes attribute we see that\n# Coliform data is inputted as string\n\nwqdata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"484b94e05ac90ac2ef42b535f1fc292a7e7d300b"},"cell_type":"code","source":"wqdata.head()\n# We can transform data types between object - categorical and float - integer\n# False definitions such as string-integer data could be transformed by using astype('integer') as well ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"071396444f734ef327a89a8384e45eb624349471"},"cell_type":"code","source":"wqdata['Site'] = wqdata['Site'].astype('category')\nwqdata['NewAvg'] = wqdata['Average 24hrTurbidity(NTU)'].astype('int32')\n#wqdata.dtypes\nwqdata['NewAvg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32dd76b1a396123f5cf7611789507a63fc4253f8"},"cell_type":"code","source":"# Missing Data Problem \n\n# 1. Leave 2.dropna(), 3.fillna(), 4.fill with statistics\n\nwqdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78d9cbf26d77897b0d61228017c20c718f6e87a9"},"cell_type":"code","source":"wqdata['Turbidity(NTU) at 12AM'].value_counts(dropna=False) \n# We check value counts of each unique value in 'Turbidity(NTU) at 12AM' dataset \n# We DO count NaN / null values also since dropna=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"782543dc5a954702c35d13da51bbff900aa9615f"},"cell_type":"code","source":"# Creating a new dataset by eliminating NaN values\nwqdataComplete=wqdata.copy()\nwqdataComplete['Turbidity(NTU) at 12AM'].dropna(inplace=True)\nwqdataComplete['Turbidity(NTU) at 12AM'].value_counts(dropna=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b54426157a84da39b3cf95c08d54c94943da7de"},"cell_type":"code","source":"assert wqdata['Turbidity(NTU) at 12AM'].notnull().all() # Returns error since wqdata has NaN values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6229f0552782947ebc097f356911c5dd2281ccd2"},"cell_type":"code","source":"assert wqdataComplete['Turbidity(NTU) at 12AM'].notnull().all() # Returns nothing (which means it is true) since wqdataComplete has no NaN values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a48eeee5d0f01b327c9bc31053bbcb7a9c380058"},"cell_type":"code","source":"wqdataComplete['Turbidity(NTU) at 12AM'].fillna('empty', inplace=True)\nwqdataComplete['Turbidity(NTU) at 12AM'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5102ec0af1761665fdb3570b13ee68587d60cf83"},"cell_type":"code","source":"wqdataCompleteNan = wqdata.copy()\nwqdataCompleteNan['Turbidity(NTU) at 12AM'].fillna('empty', inplace=True)\nwqdataCompleteNan['Turbidity(NTU) at 12AM'].value_counts() \n\n# Now we copied a new dataframe and replace NaN values with 'empty'\n# Value_counts() gives us the count of new 'empty' rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5daab3b67283c802b96bb7229b681a5f8ea65232"},"cell_type":"code","source":"# Now we create to lists called \"Months\" and \"Seasons\"\nMonths = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\nSeasons = [\"Winter\", \"Spring\", \"Summer\", \"Autumn\"]\n\nMonthNum = []\nfor i in range(12):\n    MonthNum.append(i)\nzipMonths = dict(zip(MonthNum, Months))\nzipMonths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9d5112353adfcebcfdf080383e47007f5d4ccf6"},"cell_type":"code","source":"Seasons = [\"Winter\", \"Spring\", \"Summer\", \"Autumn\"]\nSeasons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e578c1194ea0a5c4dabe1cc5cc798b06edc2884a"},"cell_type":"code","source":"Seasons = [\"Winter\", \"Spring\", \"Summer\", \"Autumn\"]\nNewSeasons = []\ni = 0 #Season[i]\nwhile i < len(Seasons):\n    j = 0 #InsertPos\n    while j < 3:\n        NewSeasons.insert(3*i+j, Seasons[i])\n        j += 1\n    i += 1\nNewSeasons\nNewSeasons.append(NewSeasons[0])\nNewSeasons.pop(0)\nNewSeasons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb2fcc6b79ace50eb09e5e3027128b0aee544f8c"},"cell_type":"code","source":"MonthsSeason = dict(zip(Months, NewSeasons))\nMonthsSeason","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5127f79ca955faa4430e6c6b0f8d5e08cdd83526"},"cell_type":"code","source":"# Now we create a new column called \"Sampling Season\" and assign a default value \"Winter\" to the whole column\nwqdata['Sampling Season']=\"Winter\"\nwqdata['Sampling Month']=wqdata.Date[:3]\nwqdata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d341864f20c38cde30461d16faec3b9f742f92d6"},"cell_type":"code","source":"# Subplots \n\nwqdata.plot(subplots=True, figsize=(30,30))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f133c4fbb1779572b8a7113b87996e4d7c181ffb"},"cell_type":"code","source":"wqdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"962a65bd1256bff6387341033c577677f4131bba"},"cell_type":"code","source":"# Renaming column names\n\nwqdata.rename(columns={'Site':'site', 'Date':'date', 'Turbidity(NTU) at 12AM':'turb12am', 'Turbidity(NTU) at 4AM':'turb4am',\n                       'Turbidity(NTU) at 8AM':'turb8am', 'Turbidity(NTU) at 12PM':'turb12pm','Turbidity(NTU) at 4PM':'turb4pm', \n                       'Turbidity(NTU) at 8PM':'turb8pm', 'Average 24hrTurbidity(NTU)':'turbavg', 'Coliform, Fecal(fc/100mL)':'coliform',\n                       'Sampling Season':'samplingseason', 'Sampling Month':'samplingmonth'}, inplace=True)\nwqdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"533025b7e6a3f36309a9bc4d46ba5a68de03b090"},"cell_type":"code","source":"# Changing date column's data type to 'datetime'\n\nwqdata.date = pd.to_datetime(wqdata.date)\nwqdata = wqdata.set_index(\"date\")\nwqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c1c9a32610d4a54dd226c794a2fd8b5d121c774"},"cell_type":"code","source":"print(wqdata.loc['2015-05-11':'2015-05-30'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3db32dc1f10f986149d4bda0e2798850a9b4965d"},"cell_type":"code","source":"wqdata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd589f9bcdc7ee2fa846685bbc59b9fba95fb43f"},"cell_type":"code","source":"wqdata.resample('M').mean().head(15) # Shows a monthly mean values (limited with the first 15 months) of each column in the dataframe ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24bb6fd576943e716496767d3d32a071b2643232"},"cell_type":"code","source":"wqdata.resample('A').max() # Shows a annual mean values of each column in the dataframe ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc1b4b2fead52f18db7ebfe84fff8a1bf72aca1e"},"cell_type":"markdown","source":"**Indexing Data Frames**\n\n#1. Indexing using square brackets // *wqdata['turb12am'][2:12]*\n#2. Using column attribute and row label\n#3. Using loc accessor\n#4. Selecting only some columns\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a3949d9653fbfcb93d76d1d301871ac9fca6772e"},"cell_type":"code","source":"df1 = wqdata['turb12am'][2:12]\ndf1 = wqdata.reset_index()\n#df1 = wqdata.set_index(\"date\")\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07cbe2e8cc2b2f67305b17cb0059496bd088c4e9"},"cell_type":"code","source":"df2 = wqdata.turb12am[2:12]\ndf2 = wqdata.reset_index()\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80cfc929cb6656af0ea322206dbbd6ebbbef47b7"},"cell_type":"code","source":"df3 = wqdata.loc['2018-12-31', ['turb12am']]\ndf3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af64adeb02da0b09c7f6dd20399692437575dccd"},"cell_type":"code","source":"df4 = wqdata[['turb4am', 'turb4pm']]\ndf4\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"097ebcaf8b18dea44d043d2e5cc8fbbf51154828"},"cell_type":"code","source":"df6=wqdata.loc['2018-12-27':,'turb4am':'turb4pm']\ndf6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58d143a2dbc433180f8dd35cc7591bb68f75365d"},"cell_type":"code","source":"df7=wqdata.loc['2018-12-27'::-1,'turb4am':'turb4pm'] #reverse\ndf7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5cc3fdb1438200ff42f60a8119f0b2743fb4aa0"},"cell_type":"code","source":"# Filtering Data Frame \n\nflt1 = wqdata.turb4am > 1.20\ndf11 = wqdata[flt1]\ndf11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ea48b43eb851c5b67479f8f0daeb8c0e471b65de"},"cell_type":"code","source":"flt1 = wqdata.turb4am > 1.20\nflt2 = wqdata.turb8am > 1.30\ndf12 = wqdata[flt1 & flt2]\ndf12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9e4c23f3030b40eb7dbf72fd9345155cec36f06"},"cell_type":"code","source":"flt1 = wqdata.turb4am > 1.20\ndf13 = wqdata.turb4am[wqdata.turb4am > 1.20]\ndf13\n# df14 = wqdata.turb4am[flt1]\n# df14 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"916c9812b217f61bf442af3dea361b6b13e2d153"},"cell_type":"code","source":"# Transformation Function \n\n# We define a function that makes a unit conversion here \n# Create a new column and assigned each cell the value calculated with the defined function \n\ndef turbidity_unittransf(x):\n    return x**2+0.33\nwqdata['mew_turb4am'] = wqdata.turb4am.apply(turbidity_unittransf)\nwqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed192d484def4ac72c35c47b5090bce680537ccb"},"cell_type":"code","source":"# Lambda function definition is a shorter way to do the same thing\n\nwqdata['mew_turb8am'] = wqdata.turb8am.apply(lambda z : z**2+0.33)\nwqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4c65dcc73e1dfe99e2b388c1975a346b43fab1c"},"cell_type":"code","source":"print(wqdata.index.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5fabfa197b49cdc0ee825562d89636d6469e176"},"cell_type":"code","source":"wqdata.index.name = 'index_date'\nwqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e51c299cbe090404590ea71e4365389b974e73dc"},"cell_type":"code","source":"wqdata.turb12am.rename = 'turb_12am'\nwqdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d08dba381a10efa5bc8f357919f307eed25ee1d"},"cell_type":"code","source":"x = range(3, 20, 3)\n         \nfor n in x:\n  print(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"208339c0f11cb01784dd02402fa0a96d2858aee0"},"cell_type":"code","source":"wqdata['no']=range(1,1459,1)\nwqdata=wqdata.set_index('no')\nwqdata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcb27e7ff90034ed8398ac8bda36920dc8e5210f"},"cell_type":"code","source":"# Group By \nwqdata.describe()\n\n# turbavg column has changing values between 0.45 and 1.43\n# lets create three intervals called low (<= 0.8), mid (0.8 - 1.2) and high (=>1.2)\n\ndef classify(x):\n    level=''\n    if (x<=0.8):\n        level='low'\n    elif (x>0.8 and x<1.2):\n        level='mid'\n    else:\n        level='high'\n    return level\n\nwqdata['turbiditylevel'] = wqdata.turbavg.apply(classify)\nwqdata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7371c5fbdf55e7d73a4d28bd4a00ad5dd72d7fd5"},"cell_type":"code","source":"# After classified our data by adding turbidity level column, we can use it for\n# aggregating and producing further statistics based on the 'group by'\n\nwqdata.groupby('turbiditylevel').mean() # We found mean of each turbidity level. We cam even find using min, max or std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31c4144d6224117e5db3dd53ec1fb5be5a022ad5"},"cell_type":"code","source":"# We filter the previous output with one column\nwqdata.groupby('turbiditylevel').turb12pm.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d5a2a3d34561fb949b3dc957348e66037e375e5"},"cell_type":"code","source":"# ...or more columns\nwqdata.groupby('turbiditylevel')[[\"turb12am\",\"turb12pm\"]].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"242e20fd27605e0907d4e78bab3341ff4f729942"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}