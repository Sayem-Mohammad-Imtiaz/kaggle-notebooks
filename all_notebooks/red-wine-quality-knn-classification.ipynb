{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#%%\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing\n%matplotlib inline\n\n#%%\n\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\n\n#%% md\n\n### Load data\n\n#%%\n\ndf = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head()\n\n#%% md\n\n### Visualize data\n\n#%%\n\nplt.figure(figsize=(16, 8))\nsns.distplot(df.quality,bins=20)\n\n#%%\n\nplt.figure(figsize=(16, 8))\nax = sns.jointplot(x=df.quality,y=df[\"alcohol\"],data=df)\n\n#%%\n\nplt.figure(figsize=(16, 8))\nsns.set(style=\"whitegrid\")\ncorr = df.corr()\nsns.heatmap(corr,annot=True,cmap=\"coolwarm\")\n\n#%%\n\nsns.clustermap(corr,cmap=\"coolwarm\")\n\n#%%\n\nplt.figure(figsize=(16, 8))\nsns.set(style=\"whitegrid\")\ncolumns = [\"volatile acidity\", \"citric acid\", \"sulphates\", \"alcohol\"]\nfor col in columns:\n    x = df.groupby(\"quality\")[col].mean()\n    ax= sns.lineplot(x=x.index,y=x,label=col)\nax.set_title('Wine characteristics over quality - closest correlation features')\nax.set_ylabel('Measure')\nax.set_xlabel('quality')\n\n#%%\n\nplt.figure(figsize=(16, 8))\nsns.set(style=\"whitegrid\")\ncolumns = [\"residual sugar\",\"chlorides\",\"density\",\"pH\", \"fixed acidity\",\"free sulfur dioxide\",\"total sulfur dioxide\"]\nfor col in columns:\n    x = df.groupby(\"quality\")[col].mean()\n    ax= sns.lineplot(x=x.index,y=x,label=col)\nax.set_title('Wine characteristics over quality - furthest correlation features')\nax.set_ylabel('Measure')\nax.set_xlabel('quality')\n\n#%% md\n### Data Analysis\n\n#### Filter Method - Pearson Correlation\n\n#%%\ncorr_cutoff = -0.25\n\nprint(\"Close correlation defined as values close to 1 or -1 on the heat map above with target feature.\\n\"\n      \"Feature correlation cutoff: \", corr_cutoff, \" \", -corr_cutoff)\n\nquality_corr = df.corr()[\"quality\"]\n\ncorr_features = quality_corr[(quality_corr < corr_cutoff) | (quality_corr > -corr_cutoff)]\ncorr_features.pop(\"quality\")\ncorr_features.keys()\n\n#%% md\n### Pre-process data\n\n#### Split labels for good and bad\n\n#%%\n\nquality_threshold = 6\ndf['quality'] = df['quality'].apply(lambda x: \"good\" if (x > quality_threshold)  else \"bad\")\ndf['quality'].value_counts()\n\n#%% md\n\n#### Normalize features\n\n#%%\n\nfeatures = df[corr_features.keys()]\nfeatures = preprocessing.StandardScaler().fit(features).transform(features)\nfeatures[0:5]\n\n#%%\n\nX = features\ny = df['quality'].values\n\n#%% md\n\n### Prepare algorithm\n\n#### Create hold-out train/cv/test sets\n\n#%%\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_rest, y_train, y_rest = train_test_split( X, y, test_size=0.3, shuffle=True, random_state=4)\nX_cv, X_test, y_cv, y_test = train_test_split( X_rest, y_rest, test_size=0.4, shuffle=True, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('CV set:', X_cv.shape,  y_cv.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\n\n#%% md\n\n#### Pick best K\n\n#%%\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\n\nfor n in range(1,Ks):\n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_cv)\n    mean_acc[n-1] = metrics.accuracy_score(y_cv, yhat)\n    std_acc[n-1]=np.std(yhat==y_cv)/np.sqrt(yhat.shape[0])\n\nmean_acc\n\n#%%\n\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.fill_between(range(1,Ks),mean_acc - 3 * std_acc,mean_acc + 3 * std_acc, alpha=0.10,color=\"green\")\nplt.legend(('Accuracy ', '+/- 1xstd','+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.tight_layout()\nplt.show()\n\n#%%\n\nk = mean_acc.argmax()+1\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", k)\n\n#%% md\n\n### Train\n\n#%%\n\nmodel = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n\nyhat_cv = model.predict(X_cv)\nprint( \"Accuracy on Train set: \", metrics.accuracy_score(y_cv, yhat_cv))\nprint( \"Accuracy on CV set: \", metrics.accuracy_score(y_cv, yhat_cv))\n\n#%% md\n\n### Evaluation\n\n#### Prepare functions\n\n#%%\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\ndef compute_and_plot_confusion_matrix(y_true, y_pred, labels):\n    cnf_matrix = confusion_matrix(y_true, y_pred, labels=labels)\n    np.set_printoptions(precision=2)\n\n    print (classification_report(y_true, y_pred))\n\n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,  title='Confusion matrix')\n\n#%% md\n\n#### Predict\n\n#%%\n\nyhat = model.predict(X_test)\n\n#%% md\n\n#### Calculate Scores\n\n#%%\n\njaccard = jaccard_score(y_test, yhat, pos_label=\"good\")\nf1 = f1_score(y_test, yhat, average='weighted')\n\nprint( \"Jaccard Score\", jaccard)\nprint( \"F1\", f1)\nprint( \"Accuracy on test set: \", metrics.accuracy_score(y_cv, yhat_cv))\n\n#%%\n\ncompute_and_plot_confusion_matrix(y_true=y_test, y_pred=yhat, labels=pd.unique(y))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}