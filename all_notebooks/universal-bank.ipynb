{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OBJECTIVE:\nTo predict whether a customer will buy a credit card or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING PACKAGES\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing file\ndf = pd.read_csv(\"../input/svm-classification/UniversalBank.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To display the top 5 rows.\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total number of rows and columns.\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset contains 5000 rows and 14 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display column names.\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)The column names are displayed above."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics.\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the null values.\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspecting unique values in each column.\ndf.nunique(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# UNIVARIATE ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram\ndf.hist(figsize=(20, 20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_num=df.loc[:,'ID':'Mortgage']\nfor i in df_num.columns:\n    sns.distplot(df_num[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OBSERVATION :       \n1) Personal Loan, Securities Account, CD Account, Online, CreditCard are binary features.    \n2) Age and Experience show normal distribution.       \n3) CCAvg, Income, Mortage are right skewed.    \n4) ID and ZIP Code do not provide any relevant information.     "},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['ID']\ndel df[\"ZIP Code\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BIVARIATE ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data = df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot is difficult to understand. Pairplot is not suitable when many features are present."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.heatmap(df.corr());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) Maximum correlation can be seen between Age & Experience.      \n2) CCAvg and Income show correlation of around 0.60.     \n3) Personal Loan and Income also show correlation of around 0.50.       "},{"metadata":{},"cell_type":"markdown","source":"# MODELLING"},{"metadata":{},"cell_type":"markdown","source":"****Decision Tree Model****"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,:-2].values\ny = df.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainx, testx, trainy, testy = train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.metrics import accuracy_score, mean_absolute_error\n\n# Fit / train the model\ndtc = tree.DecisionTreeClassifier()\ndtc.fit(trainx,trainy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the prediction for both train and test\npred_train = dtc.predict(trainx)\npred_test = dtc.predict(testx)\n\n# Measure the accuracy of the model for both train and test sets\nprint(\"Accuracy on train is:\",accuracy_score(trainy,pred_train))\nprint(\"Accuracy on test is:\",accuracy_score(testy,pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Max_depth = 3\n\ndtc_2 = tree.DecisionTreeClassifier(max_depth=3)\ndtc_2.fit(trainx,trainy)\n\npred_train2 = dtc_2.predict(trainx)\npred_test2 = dtc_2.predict(testx)\n\nprint(\"Accuracy on train is:\",accuracy_score(trainy,pred_train2))\nprint(\"Accuracy on test is:\",accuracy_score(testy,pred_test2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy obtained on test-set is 76%."},{"metadata":{},"cell_type":"markdown","source":"****SVM****"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n# Fit\nsvc.fit(trainx,trainy)\n\n# Get the prediction for both train and test\ntrain_predictions = svc.predict(trainx)\ntest_predictions = svc.predict(testx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Measure the accuracy of the model for both train and test sets\nprint(accuracy_score(trainy,train_predictions))\nprint(accuracy_score(testy,test_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy obtained on test-set is 71.9%."},{"metadata":{},"cell_type":"markdown","source":"COMPARISON :      \nDecision Tree Model is better suited for modelling as compared to SVM."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}