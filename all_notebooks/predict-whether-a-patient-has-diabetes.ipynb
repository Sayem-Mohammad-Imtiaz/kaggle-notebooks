{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict Whether A Patient Has Diabetes\n\nI will create a model to predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\n\nAll patients in this dataset are females at least 21 years old of Pima Indian heritage."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\nprint(df.info())\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Replace 0 to NaN\n\nThe following columns that contains value 0 will be replaced with Null value as there is no way to get 0 in reality:\n\n* Glucose\n* BloodPressure\n* SkinThickness\n* Insulin\n* BMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ndf['Glucose'].replace(0, np.nan, inplace=True)\ndf['BloodPressure'].replace(0, np.nan, inplace=True)\ndf['SkinThickness'].replace(0, np.nan, inplace=True)\ndf['Insulin'].replace(0, np.nan, inplace=True)\ndf['BMI'].replace(0, np.nan, inplace=True)\n\nprint(df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Drop Correlated Feature Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(abs(df.corr()))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['SkinThickness' ,'Insulin'], axis=1, inplace=True)\n\nsns.heatmap(abs(df.corr()))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Balance Dataset To Prevent Model Being Biased Toward Dominant Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outcome'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Balance dataset\ndf_outcome_1 = df[df['Outcome'] == 1].copy()\ni = len(df_outcome_1)\ndf_outcome_0 = df[df['Outcome'] == 0].sample(i, random_state=1)\ndf_balanced = df_outcome_0.append(df_outcome_1)\n\n# Display class value counts\ndf_balanced['Outcome'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Create training and test set\ny = df_balanced['Outcome']\nX = df_balanced.drop('Outcome', axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2\n                                                    , stratify=y, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Select Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\n\n# Create pipeline\nsteps = [('imputer', SimpleImputer())\n         , ('scaler', StandardScaler())\n         , ('model', LogisticRegression(random_state=1, solver='liblinear'))]\npipeline = Pipeline(steps)\n\ncv_auc = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\nprint('LogisticRegression AUC: {:.3f}'.format(np.mean(cv_auc)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\n# Create pipeline\nsteps = [('imputer', SimpleImputer())\n         , ('scaler', StandardScaler())\n         , ('model', LinearSVC(random_state=1, dual=False))]\npipeline = Pipeline(steps)\n\ncv_auc = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\nprint('LinearSVC AUC: {:.3f}'.format(np.mean(cv_auc)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Create pipeline\nsteps = [('imputer', SimpleImputer())\n         , ('scaler', StandardScaler())\n         , ('model', SVC(random_state=1))]\npipeline = Pipeline(steps)\n\ncv_auc = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\nprint('SVC AUC: {:.3f}'.format(np.mean(cv_auc)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create pipeline\nsteps = [('imputer', SimpleImputer())\n         , ('scaler', StandardScaler())\n         , ('model', RandomForestClassifier(random_state=1))]\npipeline = Pipeline(steps)\n\ncv_auc = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\nprint('RandomForestClassifier AUC: {:.3f}'.format(np.mean(cv_auc)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selected LogisticRegression as it has the highest AUC score.\n\n# Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Create pipeline\nsteps = [('imputer', SimpleImputer())\n         , ('scaler', StandardScaler())\n         , ('model', LogisticRegression(random_state=1, solver='liblinear'))]\npipeline = Pipeline(steps)\n\n# Tune hyperparameters on the training set \nparam_grid = {'model__penalty': ['l1', 'l2']\n              , 'model__C': [0.1, 0.5, 1, 1.5, 2, 2.5]}\nsearcher_cv = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc')\nsearcher_cv.fit(X_train, y_train)\n\n# Print the optimal parameters\nprint(\"Tuned Parameter: {}\".format(searcher_cv.best_params_))\nprint('Best score: {:.3f}'.format(searcher_cv.best_score_))\n\nbest_estimator = searcher_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate Model On A Hold-Out Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, roc_curve\nfrom sklearn.metrics import roc_auc_score\n\n# Plot ROC curve\nconfidence_scores = best_estimator.decision_function(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, confidence_scores)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\ntitle = 'ROC Curve (AUC: {:.3f})'.format(roc_auc_score(y_test, confidence_scores))\nplt.style.use('fivethirtyeight')\nplt.plot([0,1], [0,1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(title)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the confusion matrix\ny_pred = best_estimator.predict(X_test)\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred)\n                     , index=[0, 1]\n                     , columns=[0, 1])\n\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nax = sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues')\nax.set_title('Confusion matrix')\nax.set_xlabel('Predicted label')\nax.set_ylabel('Actual label')\nax.tick_params(axis='y', labelrotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the classification report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}