{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":114,"outputs":[{"output_type":"stream","text":"['imdb-review-dataset', 'kumarmanoj-bag-of-words-meets-bags-of-popcorn']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import backend as K\nK.tensorflow_backend._get_available_gpus()","execution_count":115,"outputs":[{"output_type":"execute_result","execution_count":115,"data":{"text/plain":"['/job:localhost/replica:0/task:0/device:GPU:0']"},"metadata":{}}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/imdb-review-dataset/imdb_master.csv',encoding=\"latin-1\")\ndf.head()","execution_count":116,"outputs":[{"output_type":"execute_result","execution_count":116,"data":{"text/plain":"   Unnamed: 0  type     ...      label         file\n0           0  test     ...        neg      0_2.txt\n1           1  test     ...        neg  10000_4.txt\n2           2  test     ...        neg  10001_1.txt\n3           3  test     ...        neg  10002_3.txt\n4           4  test     ...        neg  10003_3.txt\n\n[5 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>type</th>\n      <th>review</th>\n      <th>label</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>test</td>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>neg</td>\n      <td>0_2.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>test</td>\n      <td>This is an example of why the majority of acti...</td>\n      <td>neg</td>\n      <td>10000_4.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>test</td>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>neg</td>\n      <td>10001_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>test</td>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>neg</td>\n      <td>10002_3.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>test</td>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>neg</td>\n      <td>10003_3.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Unnamed: 0','file'],axis=1)\ndf.columns = ['type',\"review\",\"sentiment\"]\ndf.head()","execution_count":117,"outputs":[{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"   type                                             review sentiment\n0  test  Once again Mr. Costner has dragged out a movie...       neg\n1  test  This is an example of why the majority of acti...       neg\n2  test  First of all I hate those moronic rappers, who...       neg\n3  test  Not even the Beatles could write songs everyon...       neg\n4  test  Brass pictures (movies is not a fitting word f...       neg","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test</td>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test</td>\n      <td>This is an example of why the majority of acti...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test</td>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test</td>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test</td>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>neg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.sentiment != 'unsup']\ndf['sentiment'] = df['sentiment'].map({'pos': 1, 'neg': 0})\ndf.head()","execution_count":118,"outputs":[{"output_type":"execute_result","execution_count":118,"data":{"text/plain":"   type                                             review  sentiment\n0  test  Once again Mr. Costner has dragged out a movie...          0\n1  test  This is an example of why the majority of acti...          0\n2  test  First of all I hate those moronic rappers, who...          0\n3  test  Not even the Beatles could write songs everyon...          0\n4  test  Brass pictures (movies is not a fitting word f...          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test</td>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test</td>\n      <td>This is an example of why the majority of acti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test</td>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test</td>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test</td>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\n#stop_words = set(stopwords.words(\"english\")) \n#lemmatizer = WordNetLemmatizer()\n\n\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n    text = text.lower()\n    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n    text = [word for word in text if not word in stop_words]\n    text = \" \".join(text)\n    return text\n\n#df['Processed_Reviews'] = df.review.apply(lambda x: clean_text(x))\n","execution_count":119,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.head()","execution_count":120,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.Processed_Reviews.apply(lambda x: len(x.split(\" \"))).mean()","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D, SpatialDropout1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras import callbacks","execution_count":131,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df[df.type == 'train']\ndf_test = df[df.type == 'test']","execution_count":123,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# max_features = 6000\n# tokenizer = Tokenizer(num_words=max_features)\n# tokenizer.fit_on_texts(df['Processed_Reviews'])\n# list_tokenized_train = tokenizer.texts_to_sequences(df_train['Processed_Reviews'])\n# list_tokenized_test = tokenizer.texts_to_sequences(df_test['Processed_Reviews'])\n","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features = 6000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(df['review'])\nlist_tokenized_train = tokenizer.texts_to_sequences(df_train['review'])\nlist_tokenized_test = tokenizer.texts_to_sequences(df_test['review'])","execution_count":125,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 130\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\ny = df_train['sentiment']","execution_count":126,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_size = 128\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_size))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(Bidirectional(LSTM(100, return_sequences = True)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(100, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":139,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 10\ncb = []\ncb.append(callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=True))\nmodel.fit(X_t, y, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks = cb)","execution_count":140,"outputs":[{"output_type":"stream","text":"Train on 20000 samples, validate on 5000 samples\nEpoch 1/10\n20000/20000 [==============================] - 54s 3ms/step - loss: 0.4983 - acc: 0.7527 - val_loss: 0.4500 - val_acc: 0.8006\nEpoch 2/10\n20000/20000 [==============================] - 50s 2ms/step - loss: 0.2731 - acc: 0.8890 - val_loss: 0.5317 - val_acc: 0.7502\nEpoch 3/10\n20000/20000 [==============================] - 51s 3ms/step - loss: 0.2150 - acc: 0.9166 - val_loss: 0.4097 - val_acc: 0.8298\nEpoch 4/10\n20000/20000 [==============================] - 49s 2ms/step - loss: 0.1782 - acc: 0.9340 - val_loss: 0.4858 - val_acc: 0.8080\nEpoch 5/10\n20000/20000 [==============================] - 49s 2ms/step - loss: 0.1428 - acc: 0.9482 - val_loss: 0.6053 - val_acc: 0.7798\nEpoch 6/10\n20000/20000 [==============================] - 49s 2ms/step - loss: 0.1146 - acc: 0.9601 - val_loss: 0.7851 - val_acc: 0.7628\n","name":"stdout"},{"output_type":"execute_result","execution_count":140,"data":{"text/plain":"<keras.callbacks.History at 0x7fcaa512ceb8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test['sentiment']\ny_test.head()","execution_count":141,"outputs":[{"output_type":"execute_result","execution_count":141,"data":{"text/plain":"0    0\n1    0\n2    0\n3    0\n4    0\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\nprediction = model.predict(X_te)\ny_pred = (prediction > 0.5)","execution_count":142,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\nprint(classification_report(y_test, y_pred))\ncm = confusion_matrix(y_pred, y_test)\nprint('Accuracy ',accuracy_score(y_test, y_pred))\npd.DataFrame(cm)","execution_count":138,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.88      0.84      0.86     12500\n           1       0.84      0.88      0.86     12500\n\n   micro avg       0.86      0.86      0.86     25000\n   macro avg       0.86      0.86      0.86     25000\nweighted avg       0.86      0.86      0.86     25000\n\nAccuracy  0.85976\n","name":"stdout"},{"output_type":"execute_result","execution_count":138,"data":{"text/plain":"       0      1\n0  10455   1461\n1   2045  11039","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10455</td>\n      <td>1461</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2045</td>\n      <td>11039</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ngram_vectorize(train_texts, train_labels, val_texts):\n    kwargs = {\n        'ngram_range' : (1, 2),\n        'dtype' : 'int32',\n        'strip_accents' : 'unicode',\n        'decode_error' : 'replace',\n        'analyzer' : 'word',\n        'min_df' : 2,\n    }\n    \n    tfidf_vectorizer = TfidfVectorizer(**kwargs)\n    x_train = tfidf_vectorizer.fit_transform(train_texts)\n    x_val = tfidf_vectorizer.transform(val_texts)\n    \n    selector = SelectKBest(f_classif, k=min(6000, x_train.shape[1]))\n    selector.fit(x_train, train_labels)\n    x_train = selector.transform(x_train).astype('float32')\n    x_val = selector.transform(x_val).astype('float32')\n    return x_train, x_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bag_train, df_bag_test = ngram_vectorize(df_test['review'], df_test['sentiment'], df_train['review'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = MultinomialNB()\nnb.fit(df_bag_train, y)\nnb_pred = nb.predict(df_bag_test)\nprint(classification_report(y_test, nb_pred))\ncm = confusion_matrix(nb_pred, y_test)\nprint('Accuracy ',accuracy_score(y_test, nb_pred))\npd.DataFrame(cm)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}