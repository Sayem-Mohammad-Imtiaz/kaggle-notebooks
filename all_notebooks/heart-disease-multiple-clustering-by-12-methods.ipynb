{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n\n# The Multiple Clustering by 12 methods for data from the dataset [Heart Disease UCI data](https://www.kaggle.com/ronitf/heart-disease-uci):\n### Methods with automatic determination of the number of clusters:\n* MeanShift\n* DBSCAN\n* OPTICS\n* AffinityPropagation\n\n### Methods that require the number of clusters as an input parameter:\n* KMeans\n* MiniBatchKMeans\n* AgglomerativeClustering_ward\n* AgglomerativeClustering_average\n* AgglomerativeClustering_complete\n* Birch\n* GaussianMixture\n* SpectralClustering","metadata":{}},{"cell_type":"markdown","source":"## Acknowledgements\n* [Heart Disease - Automatic AdvEDA & FE & 20 models](https://www.kaggle.com/vbmokin/heart-disease-automatic-adveda-fe-20-models)\n* [Titanic Top 3% : cluster analysis](https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis)\n* [Clustering & Visualization of Clusters using PCA](https://www.kaggle.com/sabanasimbutt/clustering-visualization-of-clusters-using-pca)\n* https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [EDA & FE](#3)\n1. [Clustering](#4)\n1. [Conclusion](#5)","metadata":{}},{"cell_type":"markdown","source":"## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport pandas_profiling as pp\n\nfrom sklearn import cluster, mixture\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, DBSCAN, OPTICS\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.neighbors import kneighbors_graph\nfrom itertools import cycle, islice\n\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\nimport warnings\nwarnings.simplefilter('ignore')\n\npd.set_option('max_columns', 200)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:40.922342Z","iopub.execute_input":"2021-05-23T14:03:40.922712Z","iopub.status.idle":"2021-05-23T14:03:40.93358Z","shell.execute_reply.started":"2021-05-23T14:03:40.922682Z","shell.execute_reply":"2021-05-23T14:03:40.932882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Download datasets <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndata = data.drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:40.965297Z","iopub.execute_input":"2021-05-23T14:03:40.965621Z","iopub.status.idle":"2021-05-23T14:03:40.977953Z","shell.execute_reply.started":"2021-05-23T14:03:40.965592Z","shell.execute_reply":"2021-05-23T14:03:40.976927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:40.992953Z","iopub.execute_input":"2021-05-23T14:03:40.993235Z","iopub.status.idle":"2021-05-23T14:03:41.006661Z","shell.execute_reply.started":"2021-05-23T14:03:40.993209Z","shell.execute_reply":"2021-05-23T14:03:41.005834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. EDA & FE <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.028196Z","iopub.execute_input":"2021-05-23T14:03:41.028561Z","iopub.status.idle":"2021-05-23T14:03:41.086969Z","shell.execute_reply.started":"2021-05-23T14:03:41.028526Z","shell.execute_reply":"2021-05-23T14:03:41.086067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data format optimization\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\ndata = reduce_mem_usage(data)","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-23T14:03:41.088479Z","iopub.execute_input":"2021-05-23T14:03:41.088759Z","iopub.status.idle":"2021-05-23T14:03:41.114442Z","shell.execute_reply.started":"2021-05-23T14:03:41.088732Z","shell.execute_reply":"2021-05-23T14:03:41.113389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.11598Z","iopub.execute_input":"2021-05-23T14:03:41.116332Z","iopub.status.idle":"2021-05-23T14:03:41.138266Z","shell.execute_reply.started":"2021-05-23T14:03:41.116306Z","shell.execute_reply":"2021-05-23T14:03:41.137344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.139842Z","iopub.execute_input":"2021-05-23T14:03:41.140278Z","iopub.status.idle":"2021-05-23T14:03:41.157509Z","shell.execute_reply.started":"2021-05-23T14:03:41.140236Z","shell.execute_reply":"2021-05-23T14:03:41.156434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Clustering <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"# Thanks to https://www.kaggle.com/vbmokin/titanic-top-3-cluster-analysis\n\ndef generate_clustering_algorithms(Z, n_clusters, m):\n    # Generate clustering algorithms:\n    # m = 'MeanShift', 'KMeans', 'MiniBatchKMeans', 'AgglomerativeClustering_ward',\n    # 'SpectralClustering', 'DBSCAN', 'OPTICS', 'AffinityPropagation',\n    # 'AgglomerativeClustering_average', 'Birch', 'GaussianMixture'\n    \n    # The minimal percentage of similarity of the clustered feature with \"Survived\" for inclusion in the final dataset\n    limit_opt = 0.7\n    \n    # Thanks to: https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py\n    params = {'quantile': .2,\n              'eps': .3,\n              'damping': .9,\n              'preference': -200,\n              'n_neighbors': 10,\n              'n_clusters': n_clusters,\n              'min_samples': 3,\n              'xi': 0.05,\n              'min_cluster_size': 0.05}\n    \n    # estimate bandwidth for mean shift\n    bandwidth = cluster.estimate_bandwidth(Z, quantile=params['quantile'])\n\n    # connectivity matrix for structured Ward\n    connectivity = kneighbors_graph(\n        Z, n_neighbors=params['n_neighbors'], include_self=False)\n    \n    # make connectivity symmetric\n    connectivity = 0.5 * (connectivity + connectivity.T)\n\n    # ============\n    # Create cluster objects\n    # ============\n    if m == 'MeanShift':\n        cl = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n    elif m == 'KMeans':\n        cl = cluster.KMeans(n_clusters=n_clusters, random_state = 1000)\n    elif m == 'MiniBatchKMeans':\n        cl = cluster.MiniBatchKMeans(n_clusters=n_clusters)\n    elif m == 'AgglomerativeClustering_ward':\n        cl = cluster.AgglomerativeClustering(n_clusters=n_clusters, linkage='ward',\n                                    connectivity=connectivity)\n    elif m == 'SpectralClustering':\n        cl = cluster.SpectralClustering(n_clusters=n_clusters, eigen_solver='arpack',\n                                        affinity=\"nearest_neighbors\")\n    elif m == 'DBSCAN':\n        cl = cluster.DBSCAN(eps=params['eps'])\n    elif m == 'OPTICS':\n        cl = cluster.OPTICS(min_samples=params['min_samples'],\n                            xi=params['xi'],\n                            min_cluster_size=params['min_cluster_size'])\n    elif m == 'AffinityPropagation':\n        cl = cluster.AffinityPropagation(damping=params['damping'])\n    elif m == 'AgglomerativeClustering_average':\n        cl = cluster.AgglomerativeClustering(linkage=\"average\", affinity=\"cityblock\",\n                    n_clusters=params['n_clusters'], connectivity=connectivity)\n    elif m == 'AgglomerativeClustering_complete':\n        cl = cluster.AgglomerativeClustering(linkage=\"complete\", affinity=\"cityblock\",\n                    n_clusters=params['n_clusters'], connectivity=connectivity)        \n    elif m == 'Birch':\n        cl = cluster.Birch(n_clusters=params['n_clusters'])\n    elif m == 'GaussianMixture':\n        cl = mixture.GaussianMixture(n_components=n_clusters, covariance_type='full')\n        \n    return cl","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.169081Z","iopub.execute_input":"2021-05-23T14:03:41.169395Z","iopub.status.idle":"2021-05-23T14:03:41.181617Z","shell.execute_reply.started":"2021-05-23T14:03:41.169366Z","shell.execute_reply":"2021-05-23T14:03:41.18099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clustering_df(X, n, m, output_hist):\n    \n    # Standardization\n    X_columns = X.columns\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X = pd.DataFrame(scaler.transform(X), columns = X_columns)\n    cl = generate_clustering_algorithms(X, n, m)\n    cl.fit(X)\n    if hasattr(cl, 'labels_'):\n        labels = cl.labels_.astype(np.int)\n    else:\n        labels = cl.predict(X) \n    clusters=pd.concat([X, pd.DataFrame({'cluster':labels})], axis=1)\n    \n    # Inverse Standardization\n    X_inv = pd.DataFrame(scaler.inverse_transform(X), columns = X_columns)    \n    clusters_inv=pd.concat([X_inv, pd.DataFrame({'cluster':labels})], axis=1)\n    \n    # Number of points in clusters\n    print(\"Number of points in clusters:\\n\", clusters['cluster'].value_counts())\n    \n    # Data in clusters - thanks to https://www.kaggle.com/sabanasimbutt/clustering-visualization-of-clusters-using-pca    \n    if output_hist:\n        for c in clusters:\n            grid = sns.FacetGrid(clusters_inv, col='cluster')\n            grid.map(plt.hist, c)\n        \n    return clusters, clusters_inv","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.21416Z","iopub.execute_input":"2021-05-23T14:03:41.214645Z","iopub.status.idle":"2021-05-23T14:03:41.223051Z","shell.execute_reply.started":"2021-05-23T14:03:41.214612Z","shell.execute_reply":"2021-05-23T14:03:41.222196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Methods with automatic determination of the number of clusters:\n* MeanShift\n* DBSCAN\n* OPTICS\n* AffinityPropagation\n\n## Methods that require the number of clusters as an input parameter:\n* KMeans\n* MiniBatchKMeans\n* AgglomerativeClustering_ward\n* AgglomerativeClustering_average\n* AgglomerativeClustering_complete\n* Birch\n* GaussianMixture\n* SpectralClustering","metadata":{}},{"cell_type":"code","source":"# All 12 methods\nmethods_all = ['KMeans', 'MiniBatchKMeans', 'MeanShift', \n               'DBSCAN', 'OPTICS', \n               'AffinityPropagation',               \n               'AgglomerativeClustering_ward',\n               'AgglomerativeClustering_average',\n               'AgglomerativeClustering_complete',\n               'Birch', \n               'GaussianMixture',\n               'SpectralClustering'\n              ]","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.237252Z","iopub.execute_input":"2021-05-23T14:03:41.237579Z","iopub.status.idle":"2021-05-23T14:03:41.24169Z","shell.execute_reply.started":"2021-05-23T14:03:41.237549Z","shell.execute_reply":"2021-05-23T14:03:41.240845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The number of default clusters in methods where such a parameter is required\nn_default = 6","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.293365Z","iopub.execute_input":"2021-05-23T14:03:41.293854Z","iopub.status.idle":"2021-05-23T14:03:41.297255Z","shell.execute_reply.started":"2021-05-23T14:03:41.293798Z","shell.execute_reply":"2021-05-23T14:03:41.296306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_draw(X, title, m):\n    # Drawing a plot with clusters on the plane (using PCA transformation)\n    # Thanks to https://www.kaggle.com/sabanasimbutt/clustering-visualization-of-clusters-using-pca\n    \n    dist = 1 - cosine_similarity(X)\n    \n    # PCA transform\n    pca = PCA(2)\n    pca.fit(dist)\n    X_PCA = pca.transform(dist)\n    \n    # Generate point numbers and colors for clusters\n    hsv = plt.get_cmap('hsv')\n    n_clusters = max(X['cluster'].value_counts().index)-min(X['cluster'].value_counts().index)+2\n    colors = list(hsv(np.linspace(0, 1, n_clusters)))\n    colors_num = list(np.linspace(min(X['cluster'].value_counts().index), max(X['cluster'].value_counts().index), n_clusters))\n    colors_num = [int(x) for x in colors_num]\n    colors_str = [str(x) for x in colors_num]\n    names_dict = dict(zip(colors_num, colors_str))\n    colors_dict = dict(zip(colors_num, colors))\n    \n    # Visualization\n    x, y = X_PCA[:, 0], X_PCA[:, 1]\n\n    df = pd.DataFrame({'x': x, 'y':y, 'label':X['cluster'].tolist()}) \n    groups = df.groupby('label')\n\n    fig, ax = plt.subplots(figsize=(12, 8)) \n\n    for name, group in groups:\n        ax.plot(group.x, group.y, marker='o', linestyle='', ms=10,\n                color=colors_dict[name],\n                label=names_dict[name], \n                mec='none')\n        ax.set_aspect('auto')\n        ax.tick_params(axis='x',which='both',bottom='off',top='off',labelbottom='off')\n        ax.tick_params(axis= 'y',which='both',left='off',top='off',labelleft='off')\n\n    ax.legend(loc='upper right')\n    ax.set_title(f\"{title} by method {m}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.320171Z","iopub.execute_input":"2021-05-23T14:03:41.320606Z","iopub.status.idle":"2021-05-23T14:03:41.332745Z","shell.execute_reply.started":"2021-05-23T14:03:41.320576Z","shell.execute_reply":"2021-05-23T14:03:41.332075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = dict(zip(methods_all, [False]*len(methods_all)))\nn_clust = dict(zip(methods_all, [1]*len(methods_all)))\nfor method in methods_all:\n    print(f\"Method - {method}\")\n    Y, Y_inv = clustering_df(data.copy(), n_default, method, True)\n    \n    # If the number of clusters is less than 2, then the clustering is not successful\n    n_cl = len(Y['cluster'].value_counts())\n    if n_cl > 1:\n        res[method] = True\n        n_clust[method] = n_cl\n        plot_draw(Y, \"Data clustering\", method)\n    else:\n        print('Clustering is not successful because all data is in one cluster!\\n')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:41.334005Z","iopub.execute_input":"2021-05-23T14:03:41.33449Z","iopub.status.idle":"2021-05-23T14:03:45.901687Z","shell.execute_reply.started":"2021-05-23T14:03:41.334457Z","shell.execute_reply":"2021-05-23T14:03:45.900756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Conclusion <a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"# Results: optimal clustering methods\nmethods_bad = []\nprint('Optimal clustering methods:\\n')\nfor (k, v) in res.items():\n    if v:\n        print(f\"- {k} with number of clusters = {n_clust[k]}\")\n    else: \n        methods_bad.append(k)","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:45.903628Z","iopub.execute_input":"2021-05-23T14:03:45.904087Z","iopub.status.idle":"2021-05-23T14:03:45.911898Z","shell.execute_reply.started":"2021-05-23T14:03:45.904044Z","shell.execute_reply":"2021-05-23T14:03:45.910801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results: methods in which all data are in one cluster\nif len(methods_bad) > 0:\n    print('Methods in which all data are in one cluster:\\n')\n    for method in methods_bad:\n        print(f'- {method}')","metadata":{"execution":{"iopub.status.busy":"2021-05-23T14:03:45.913791Z","iopub.execute_input":"2021-05-23T14:03:45.914459Z","iopub.status.idle":"2021-05-23T14:03:45.922756Z","shell.execute_reply.started":"2021-05-23T14:03:45.914417Z","shell.execute_reply":"2021-05-23T14:03:45.921869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","metadata":{}}]}