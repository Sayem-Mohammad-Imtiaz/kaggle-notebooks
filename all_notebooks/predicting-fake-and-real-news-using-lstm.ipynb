{"cells":[{"metadata":{},"cell_type":"markdown","source":"***PROBLEM STATEMENT***"},{"metadata":{},"cell_type":"markdown","source":"# Can you use this data set to make an algorithm able to determine if an article is fake news or not?"},{"metadata":{},"cell_type":"markdown","source":"**Dataset Link - https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Bidirectional","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_data = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\nfake_data = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(true_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(fake_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_data['label'] = 1\ntrue_data['label'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8, 8))\nsns.countplot(y = \"subject\", data = data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install WordCloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download(\"stopwords\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([true_data,fake_data],axis=0,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The dataset has 44898 observations and 5 features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop('label',axis = 1)\ny = data['label']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning the review feature with different transformations and stemming using Porter Stemmer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ps = PorterStemmer()\ncorpus = []\nfor i in range(len(x['title'])):\n    review = re.sub('[^a-zA-Z]', ' ', x['title'][i])\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voc_size = 10000\nonehot_repr = [one_hot(word,voc_size) for word in corpus]\nonehot_repr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Padding the document using pre and applying one hot encoding to the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentlen = 20\nembedding_doc = pad_sequences(onehot_repr,padding = 'pre',maxlen=sentlen)\nembedding_doc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_feature = 60\nmodel = Sequential()\nmodel.add(Embedding(voc_size,embedding_feature,input_length=sentlen))\nmodel.add(LSTM(64,return_sequences=True))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(LSTM(32))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(Dense(1,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SPLITTING THE DATASET INTO 70% TRAIN SET AND 30% VALIDATION SET**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_final = np.array(embedding_doc)\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x_final,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EARLY STOPPING AFTER REACHING THE OPTIMUM EPOCH WHILE FITTING WHERE BOTH THE TRAINING SET AND VALIDATION SET GENERALIZES TOGETHER AND RESTORING THE WEIGHTS FROM THAT EPOCH.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(patience=5,min_delta=0.001,restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FITTING THE MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,\n                    batch_size=128,\n                    callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VALIDATION CURVE FOR LSTM MODEL BETWEEN NUMBER OF EPOCHS ON X-AXIS AND ACCURACY ON Y-AXIS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title = 'validation curve')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.evaluate(x_test, y_test)\n\nloss = result[0]\naccuracy = result[1]\nprint(f\"[+] Accuracy: {accuracy*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = []\nfor i in range(len(pred)):\n    if pred[i].item() > 0.5:\n        prediction.append(1)\n    else:\n        prediction.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(list(y_test), prediction)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Birectional LSTM Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_feature = 60\nmodel = Sequential()\nmodel.add(Embedding(voc_size,embedding_feature,input_length=sentlen))\nmodel.add(Bidirectional(LSTM(64 ,return_sequences=True)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(Dense(1,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(patience=5,min_delta=0.001,restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train,y_train,validation_data=(x_test,y_test),\n                    epochs=10,batch_size=128,\n                    callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VALIDATION CURVE FOR BIDIRECTIONAL LSTM MODEL BETWEEN NUMBER OF EPOCHS ON X-AXIS AND ACCURACY ON Y-AXIS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title = 'validation curve')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.evaluate(x_test, y_test)\n\nloss = result[0]\naccuracy = result[1]\nprint(f\"[+] Accuracy: {accuracy*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = []\nfor i in range(len(pred)):\n    if pred[i].item() > 0.5:\n        prediction.append(1)\n    else:\n        prediction.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(list(y_test), prediction)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We have applied two models for this dataset LSTM and Birectional LSTM, and Birectional LSTM is giving us a better accuracy of 92.43% as compared to LSTM model which was giving us an accuracy of 89.84%."},{"metadata":{},"cell_type":"markdown","source":"> # **Predicted class distribution(True Positive and True Negative)**"},{"metadata":{},"cell_type":"markdown","source":"# **12450 records are correctly classfied out of 13470. (obtained from confusion matrix of Birectional LSTM model.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}