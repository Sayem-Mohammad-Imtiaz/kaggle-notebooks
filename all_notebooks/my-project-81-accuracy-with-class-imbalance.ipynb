{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ****Hi everyone!****"},{"metadata":{},"cell_type":"markdown","source":"This is my first public notebook in which I will analyse [Telco Dataset](https://www.kaggle.com/blastchar/telco-customer-churn). Based on the available data, it is necessary to predict the behavior of the customers - whether they will stay with the operator or leave."},{"metadata":{},"cell_type":"markdown","source":"References: special thanks to Janio Martinez and his [notebook](https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets)!"},{"metadata":{},"cell_type":"markdown","source":"# 0. Libraries!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# plotting\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n# data encoding\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.pipeline import make_pipeline\nfrom imblearn.pipeline import Pipeline as imb_pipeline\n\n# classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Primary analysis"},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at our data:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv',usecols = lambda column : column not in \n[\"customerID\"])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there's no empty cells - that's amazing! We don`t need to think how to fill the gaps. **But there are a couple of nuances**  - almost all columns are in the \"object\" format, which is inconvenient for processing. Especially the column \"TotalCharges\", which alone contains numerical characteristics, while others are categorical. We are going to fix it:"},{"metadata":{},"cell_type":"markdown","source":"At first, we need to convert \"TotalCharges\" to float:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oops! Looks like we have empty values - lets count them:"},{"metadata":{"trusted":true},"cell_type":"code","source":"empty_values = []\nfor i in range(len(df['TotalCharges'])):\n    if df['TotalCharges'].iloc[i] == ' ':\n        empty_values.append(i)\nprint(\"There are empty indexes found:\", end=' ')\nprint(empty_values)\nfor i in range(len(empty_values)):\n    print(df.iloc[empty_values[i]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interesting fact:** for all rows with an empty value in the \"TotalCharges\" cell, the \"tenure\" cell has a value of zero, which means that these are *new* users, and we can replace the empty value with zero:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"TotalCharges\"] =  df[\"TotalCharges\"].replace(r' ', '0')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"New attempt to change data format:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yay! We will return to proccesing later."},{"metadata":{},"cell_type":"markdown","source":"Let's see how many unique values each categorial column contains:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n    if i not in ['tenure','MonthlyCharges','TotalCharges']:\n        print(i,'column has',len(pd.unique(df[i])),'unique values or rather:')\n        print(pd.unique(df[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's take a look at target feature - \"Churn\""},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\nplt.title(\"Churn chart\")\n\nsns.countplot(df['Churn'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! ****Our classes are very disbalanced.**** In numbers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_yes = df[df.Churn == \"Yes\"].shape[0]\nchurn_no = df[df.Churn == \"No\"].shape[0]\n\nchurn_yes_percent = round((churn_yes / (churn_yes + churn_no) * 100),2)\nchurn_no_percent = round((churn_no / (churn_yes + churn_no) * 100 ),2)\n\nprint('There are',churn_yes_percent,'percent of customers that will churn and',churn_no_percent,'percent of customers that will not churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The conclusion suggests itself: it is necessary to somehow **\"normalize\" the data** so that the model does not retrain on the prevailing data or does not fail to learn on the data that are in the minority. To do this, you can use the methods of **artificial data normalization**, which will be described below, but first, we will create a test sample (which we will normalize) and a validation sample:"},{"metadata":{},"cell_type":"markdown","source":"Good! Now we are going to transform all categorial values using [One Hot Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html):"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorial_columns = [cname for cname in df.columns if cname not in ['tenure','MonthlyCharges','TotalCharges','Churn']]\n\nprint(\"Our categorial columns:\", categorial_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create train and validation datasets; we should make One Hot Encoding after splitting, not before, because our model must at the testing stage work with \"raw data\" that it sees for the first time; if you process the entire dataset, then data leakage may occur during splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Churn', axis=1)\ny = df['Churn']\n\n# Creating train and test subsets\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# One Hot Encoding\nX_train = pd.get_dummies(X_train_full)\nX_valid = pd.get_dummies(X_valid_full)\n\n# For y-values we will use LabelEncoder\n\nlabel_enc  = LabelEncoder()\ny_train = label_enc.fit_transform(y_train)\ny_valid = label_enc.fit_transform(y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now our data looks like this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Amazing! Now we normalize the data, more precisely, columns \"tenure\", \"MonthlyCharges\" and \"TotalCharges\" so that the model can quickly establish dependencies between the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\n# I use RobustScaler because it's quite robust to outliers\n\nrob_scaler = RobustScaler()\n\ncolumns_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n\nX_train[columns_to_scale] = rob_scaler.fit_transform(X_train[columns_to_scale])\nX_valid[columns_to_scale] = rob_scaler.fit_transform(X_valid[columns_to_scale])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Base model"},{"metadata":{},"cell_type":"markdown","source":"Our data is ready to implement basic algorithm - let's use linear regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use GridSearchCV to find the best parameters.\n# from sklearn.model_selection import GridSearchCV\n\n# Logistic Regression \nlog_reg = LogisticRegression()\n\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = log_reg.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate accuracy\nACC = accuracy_score(y_valid, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ACC)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! Our algotithm is pretty accurate - let's take a look at confusion matrix:"},{"metadata":{},"cell_type":"markdown","source":"Note: to get acquainted with the confusion matrix, I recommend [this article](https://en.wikipedia.org/wiki/Confusion_matrix)"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_cf = confusion_matrix(y_valid, predictions)\n\nfig, axes = plt.subplots(1, 1, figsize=(12, 6))\n\nsns.heatmap(log_reg_cf, annot=True, cmap=plt.cm.Pastel1)\nplt.title(\"Logistic Regression Confusion Matrix\", fontsize=14)\nplt.xlabel(\"Predicted classes\")\nplt.ylabel(\"Actual classes\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, our model has big False Positive value (160 values) and (relatively) small False Negative value (94 value) - it means that our model is good at detecting 'non-churn' customers and bad at detecting 'churn' customers. This is quite to be expected, since the dataset is dominated by rows with information about customers who are not going to leave. That is, **our model was retrained on the original data**. Let's try to fix it."},{"metadata":{},"cell_type":"markdown","source":"# 3. Undersampling data"},{"metadata":{},"cell_type":"markdown","source":"For starters, you can shrink the original dataset by reducing the number of rows with a predominant target variable. This can be done with [NearMiss technique](https://imbalanced-learn.org/stable/generated/imblearn.under_sampling.NearMiss.html):"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import NearMiss\n\nundersample_pipeline = make_pipeline(NearMiss(sampling_strategy='majority'), log_reg)\nundersample_model = undersample_pipeline.fit(X_train, y_train)\nundersample_predictions = undersample_model.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate accuracy\nACC = accuracy_score(y_valid, undersample_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ACC)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well... Looks like accuracy has decreased markedly. But this is not a reason to be upset - let's take a look at confusion matrix:"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_cf = confusion_matrix(y_valid, undersample_predictions)\n\nfig, axes = plt.subplots(1, 1, figsize=(12, 6))\n\nsns.heatmap(log_reg_cf, annot=True, cmap=plt.cm.Pastel1)\nplt.title(\"Logistic Regression Confusion Matrix\", fontsize=14)\nplt.xlabel(\"Predicted classes\")\nplt.ylabel(\"Actual classes\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тow everything is exactly the opposite: our model has small False Positive value (68 values) and very big False Negative velue (440 value) - it means that our model is very bad at detecting 'non-churn' customers and quite good at detecting 'churn' customers. \n\nHere a little philosophical question already arises - which is more profitable, poorly recognizing clients who are going to leave, or spamming a bunch of clients who are definitely not going to leave? I would love to participate in the discussion :)"},{"metadata":{},"cell_type":"markdown","source":"But that's not all - let's try to oversmaple our data (that is, we will artificially increase the number of customers who are going to leave)!"},{"metadata":{},"cell_type":"markdown","source":"# 4. Oversampling data"},{"metadata":{},"cell_type":"markdown","source":"This can be done with [SMOTE](https://www.geeksforgeeks.org/ml-handling-imbalanced-data-with-smote-and-near-miss-algorithm-in-python/) technique:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# I use other solver and increase numer of iterations because our dataset will become larger\noversample_pipeline = make_pipeline(SMOTE(sampling_strategy='minority'), LogisticRegression(solver = 'saga', max_iter=10000))\noversample_model = oversample_pipeline.fit(X_train, y_train)\noversample_predictions = oversample_model.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate accuracy\nACC = accuracy_score(y_valid, oversample_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ACC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg_cf = confusion_matrix(y_valid, oversample_predictions)\n\nfig, axes = plt.subplots(1, 1, figsize=(12, 6))\n\nsns.heatmap(log_reg_cf, annot=True, cmap=plt.cm.Pastel1)\nplt.title(\"Logistic Regression Confusion Matrix\", fontsize=14)\nplt.xlabel(\"Predicted classes\")\nplt.ylabel(\"Actual classes\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! We got something in between the first and second options - we can say that it is \"in the neutral zone\" - according to the predictions of clients who are going to leave, it is better than the first algorithm, but worse than the second, and vice versa with clients who are going to stay."},{"metadata":{},"cell_type":"markdown","source":"# 5. Deep look into oversampled model"},{"metadata":{},"cell_type":"markdown","source":"For example, you decided to choose third model - we want to get acceptable results on average, let's try to improve it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# I use Grid Search to find best parameters for our model\nfrom sklearn.model_selection import GridSearchCV\n\n#Creating pipeline with data augmentation and subsequent regression\npipeline = imb_pipeline(\n                    [('nearmiss', SMOTE(sampling_strategy='minority')),\n                     ('logreg', LogisticRegression(solver = 'saga', max_iter=10000))\n                     \n])\n\nparameters = {}\nparameters['logreg__penalty'] = ['l1', 'l2']\nparameters['logreg__C'] = [i for i in range(80,420,40)]\n\nCV = GridSearchCV(pipeline, parameters, scoring = 'accuracy', n_jobs= 1)\nCV.fit(X_train, y_train)   \n\nprint('Best parameter combination for linear regression is:', CV.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversample_pipeline = make_pipeline(SMOTE(sampling_strategy='minority'), LogisticRegression(solver = 'saga', penalty = 'l1', C=80, max_iter=10000))\noversample_model = oversample_pipeline.fit(X_train, y_train)\noversample_predictions = oversample_model.predict(X_valid)\n\nprint('Accuracy on validation set: %s' % (accuracy_score(y_valid, oversample_predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, looks like we achieved good accuracy - 81%! You can adjust the parameters and improve the result by yourself, but I that's all for the moment. Thank you for watching! I would be glad to receive feedback and interesting suggestions! Also, I'm ready to listen to criticism and different opinions. See you later!"},{"metadata":{},"cell_type":"markdown","source":"*Contacts:*\ntelegramm - @univanxx, instagram - @univanxx"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}