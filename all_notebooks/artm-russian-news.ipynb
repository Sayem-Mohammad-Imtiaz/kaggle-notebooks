{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pymorphy2[fast]\n!pip install bigartm10\n!pip install razdel","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nfrom collections import Counter\n\nimport pandas as pd\nimport numpy as np\n\nimport artm\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport pymorphy2\nimport razdel\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df = pd.read_csv('/kaggle/input/russian-news-2020/news.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.loc[news_df['source'] == 'ria.ru', 'publication_date'] = (news_df.loc[news_df['source'] == 'ria.ru', 'publication_date'].str\n                                                              .extract(r'(?P<date>\\d{2}\\.\\d{2}\\.\\d{4})', expand=False)\n                                                              .apply(lambda x: '-'.join(reversed(x.split('.'))) if type(x) is str else x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.loc[news_df['source'] == 'lenta.ru', 'publication_date'] = news_df.loc[news_df['source'] == 'lenta.ru', 'publication_date'].str.split('T').str.get(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month_mapper = {\n    'января': '01',\n    'февраля': '02',\n    'марта': '03',\n    'апреля': '04',\n    'мая': '05',\n    'июня': '06',\n    'июля': '07',\n    'августа': '08',\n    'сентября': '09',\n    'октября': '10',\n    'ноября': '11',\n    'декабря': '12'\n}\nnews_df.loc[news_df['source'] == 'meduza.io', 'publication_date'] = (news_df.loc[news_df['source'] == 'meduza.io', 'publication_date']\n                                                                     .apply(lambda x: f'{x.split()[3]}-{month_mapper[x.split()[2]]}-{x.split()[1].zfill(2)}' if type(x) is str else x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.loc[news_df['source'] == 'tjournal.ru', 'publication_date'] = pd.to_datetime(news_df.loc[news_df['source'] == 'tjournal.ru', 'publication_date'], unit='s').dt.strftime('%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.loc[news_df['source'] == 'tjournal.ru', 'text'] = news_df.loc[news_df['source'] == 'tjournal.ru', 'text'].str.replace('\\n', '').str.replace(r'\\s+', ' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.loc[news_df['source'] == 'tjournal.ru', 'tags'] = news_df.loc[news_df['source'] == 'tjournal.ru', 'text'].str.findall(r'#\\w+').str.join(', ').str.replace('#', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df.loc[news_df['source'] == 'tjournal.ru', 'text'] = news_df.loc[news_df['source'] == 'tjournal.ru', 'text'].apply(lambda x: x[:x.find('#')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"documents = news_df.text.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Preprocessing\nSplit the text into tokens, bring the tokens to normal form and take only tokens longer than two characters.\nLet's create a dictionary of words from our texts. Let's leave only words that occur at least 5 times and no more than 25% of documents."},{"metadata":{"trusted":true},"cell_type":"code","source":"morph = pymorphy2.MorphAnalyzer()\n\ndef lemmatize(token):\n    return morph.parse(token)[0].normal_form\n\ndef tokenize(text):\n    return [lemmatize(token.text) for token in razdel.tokenize(text) if len(token.text) > 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(max_features=25000, min_df=5, max_df=0.25, tokenizer=tokenize)\nn_wd = np.array(cv.fit_transform(documents).todense()).T\nvocabulary = cv.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bv = artm.BatchVectorizer(data_format='bow_n_wd',\n                          n_wd=n_wd,\n                          vocabulary=vocabulary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training model\n![topic_modeling](https://miro.medium.com/max/1200/1*IJw8N-HSEzLpwJDS6JVs-w.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = artm.ARTM(\n    num_topics=100, dictionary=bv.dictionary,\n    scores=[\n        artm.PerplexityScore(name='PerplexityScore', dictionary=bv.dictionary),\n        artm.TopTokensScore(name='Top10TokensScore', num_tokens=10),\n        artm.TopTokensScore(name='Top100TokensScore', num_tokens=100),\n        artm.SparsityPhiScore(name='SparsityPhiScore'),\n        artm.SparsityPhiScore(name='SparsityThetaScore'),\n    ],\n    regularizers=[\n        artm.SmoothSparseThetaRegularizer(name='SmoothSparseThetaRegularizer', tau=-1e-4),\n        artm.SmoothSparsePhiRegularizer(name='SmoothSparsePhiRegularizer', tau=-1e-4),\n    ]\n)\nmodel.fit_offline(bv, num_collection_passes=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Perplexity\n\n\n![perplexity](https://wikimedia.org/api/rest_v1/media/math/render/svg/fc7974a9bf394db8698fb76c0fa060c6c21068ed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_score('PerplexityScore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(model.score_tracker['PerplexityScore'].value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sparsity\n\nEstimate the sparsity of the matrices phi and theta"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_score('SparsityPhiScore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(model.score_tracker['SparsityPhiScore'].value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_score('SparsityThetaScore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(model.score_tracker['SparsityThetaScore'].value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis of the resulting topics\nLet's see the resulting topics and their most frequent words."},{"metadata":{"trusted":true},"cell_type":"code","source":"for topic_name in model.topic_names:\n    print(topic_name + ': ',)\n    print(model.score_tracker['Top10TokensScore'].last_tokens[topic_name])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the distribution of rubrics, subrubrics and tags by topics"},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df['topic'] = model.transform(bv).idxmax(axis=0).str.replace('topic_', '').sort_index().astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(news_df.topic.max()):\n    print(f'Topic: {i}')\n    counts = news_df[news_df.topic == i].rubric.value_counts()\n    print(counts[counts > 2])\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(news_df.topic.max()):\n    print(f'Topic: {i}')\n    counts = news_df[news_df.topic == i].subrubric.value_counts()\n    print(counts[counts > 2])\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(news_df.topic.max()):\n    print(f'Topic: {i}')\n    tags = []\n    for i in news_df[news_df.topic == i].tags.dropna():\n        tags += i.split(', ')\n    counts = Counter(tags)\n    print('\\n'.join(map(str, counts.most_common()[:5])))\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wordcloud\n\n\nVisualizing each topic with a word cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"for topic_name in model.topic_names:\n    print(topic_name)\n    top_tokens = set(model.score_tracker['Top100TokensScore'].last_tokens[topic_name])\n    frequencies = Counter()\n    for text in news_df[news_df.topic == int(topic_name.replace('topic_', ''))].text:\n        frequencies.update([token for token in tokenize(text) if token in top_tokens])\n    \n    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate_from_frequencies(frequencies)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of topics over time"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure()\nf, ax = plt.subplots(100, 1, figsize=(75, 900))\n\nfor i, topic_name in enumerate(model.topic_names):\n    counts = news_df[news_df.topic == int(topic_name.replace('topic_', ''))]['publication_date'].dropna().value_counts().to_dict()\n    ax[i].bar(news_df['publication_date'].dropna().drop_duplicates().sort_values(), news_df['publication_date'].dropna().drop_duplicates().sort_values().map(counts))\n    ax[i].set_title(topic_name)\n    ax[i].tick_params(labelrotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}