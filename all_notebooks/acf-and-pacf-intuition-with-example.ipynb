{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font color=blue>Table of Contents</font>\n\n[<font color=green>1. What is ACF and PACF</font>](#1)   \n[<font color=green>2. Application of ACF and PACF</font>](#2)     \n[<font color=green>3. When which one should be used</font>](#3)     \n[<font color=green>4. Plotting ACF and PACF(Example- Icecream Production)</font>](#4)  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<font color=green>4.1. Importing necessary modules along with dataset</font>](#4.1)  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<font color=green>4.2. Data Reconnaissance</font>](#4.2)    \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<font color=green>4.3. Plot the data</font>](#4.3)    \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<font color=green>4.4. ACF plot</font>](#4.4)    \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [<font color=green>4.5. PACF Plot</font>](#4.5)    \n[<font color=green>5. Important Notes</font>](#5)    \n\n\n<br/>\n<br/>"},{"metadata":{},"cell_type":"markdown","source":"<a id =1> </a> \n## <font color=red> 1. What is ACF and PACF</font>\n\nACF stands for **Auto Correlation** where PACF stands for **Partial Auto Correlation**. Before diving into the deep, let's first understand what is **Correlation** which stays both in the ACF and PACF.  \n<br/>\n\nCorrelation is basically the relationship between two variables or features as well. Say, we have two features to work with : **Weight** and **BMI**. If we plot them in a scatterplot, we will see that the BMI will be increased with the increment of Weight. Then we can say that Weight and BMI are correlated with each other or they have a strong correlation.  \nWe measure this correlation by **Pearson Correlation Factor** which value lies between **<font color=blue>-1</font>** to **<font color=blue>1</font>**. Value close to **<font color=blue>1</font>** means **<font color=blue>strong positive correlation</font>** while close to **<font color=blue>-1</font>** means **<font color=blue>negative positive correlation</font>**.\n<br/>\n<br/>\n\nBut in **Time Series Analysis** we often have to work with a single feature. We Observe the historical data to find out a pattern and use the pattern to forecast what can be happened in future. And here comes up **ACF** and **PACF**. This two terms indicate the correlation between the values of a single feature while correlation does it between two features.\n<br/>\n\n**<font color=blue>ACF</font>**  \nNow let's explore ACF in a more detailed manner. Say, we are working with a stock price datasaet. Then the correlation between the stock price of current time and the stock price of the previous time is called ACF. ACF tells us how strong they are correlated with each other.\n<br/>\n\n**<font color=blue>PACF</font>**  \nBut what if the correlation between two data points of different two times are influenced by other data points? Here comes up PACF as a saviour. Let's understand it with an example.\n<br/>\n\nSay, **t**, **t-1** and **t-2** are the stock prices of today, yesterday and the day before yesterday respectively.  \nNow **t** can be correlated with **t-2** and **t-1** can also be correlated with **t-2**. Then PACF of **t-1** is the real correlation between **t** and **t-1** after taking out the influence of **t-2**."},{"metadata":{},"cell_type":"markdown","source":"<a id =2> </a> \n<br/>\n<br/>\n\n## <font color=red> 2. Application of ACF and PACF</font>\n\nIn **Machine Learning**, selecting a perfect model is a very tedious job. Though we have to do **Trial and Error** method to find out the best model, it would be better if we could assume first which model could perfom better with our specific dataset.\n<br/>\n\nAnd here comes up **ACF** and **PACF** as saviour. They are mostly used to choose the model between **Auto regressive (AR)** and **Moving Average (MA)**. ACF and PACF not only help us choosing the model, but also tell us which **lagged value** will perform better."},{"metadata":{},"cell_type":"markdown","source":"<a id =3> </a> \n<br/>\n<br/>\n\n## <font color=red>3.When which one should be used</font>\n\n####  <font color=blue>ACF</font>  \nIf we work with **Moving Average Model**, we will determine our lagged value by ACF. In the ACF plot, there will a **Horizontal Threshold Line** which indicates the significance level. The vertical lines which cross this horizontal line have a significant relationship and better to be used.  \n[<font color=purple>[We will learn this in a more detailed manner in the example section.]</font>](#4.4)\n<br/>\n\n####  <font color=blue>PACF</font>  \nPACF will be used to find the lagged value of **Auto Regressive Model**. The selection process is same as the ACF.  \n[<font color=purple>[Details.]</font>](#10)\n<br/>\n\n####  <font color=blue>Model selection</font>  \nPlot the ACF and PACF together and compare with one another. If ACF gives us better result, then we will select Moving Average Model. On the other hand, if PACF performs well, then Auto Regressive Model will be prefferable.  \nBut what if two model give us nearly the same result? Then we will go for the **simple** one.  \n[<font color=purple>[Details.]</font>](#11)"},{"metadata":{},"cell_type":"markdown","source":"<a id =4> </a>\n<br/>\n<br/>\n<br/>\n\n## <font color=red>4. Plotting ACF and PACF (Example- Icecream Production)</font>"},{"metadata":{},"cell_type":"markdown","source":"<a id =4.1> </a>\n#### 4.1. Importing necessary modules along with dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Necessary modules\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset\n\ndf = pd.read_csv('../input/icecream-production/ice.csv', parse_dates = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id =4.2> </a>\n<br/>\n\n#### 4.2. Data Reconnaissance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First few Rows\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Last few Rows\n\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shape\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data type\n\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the data type of date column\n\ndf['DATE'] = pd.to_datetime(df['DATE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the date column as Index\n\ndf.set_index('DATE', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id =4.3> </a>\n<br/>\n\n#### 4.3. Plot the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 5))\n\nplt.plot(df['Icecream'], color = 'red')\n\nplt.title(\"Icecream Production over Time\\n\", fontsize = 15)\nplt.ylabel(\"Production\\n\", fontsize = 12)\n\nfor i in range(1972, 2021):\n    plt.axvline(pd.to_datetime(str(i) + '-01-01'), color = 'black', linestyle = '--', alpha = 0.5)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id =4.4> </a>\n<br/>\n\n#### 4.4. ACF Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"acf_plot = plot_acf(df.Icecream, lags = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id =10> </a>\n<font color=blue>Note:</font>  \n<font color=purple>**1.** To observe the long-term effect, we will have to set the **lags** parameter a higher value.  \n**2.** The**Blue shade area** is called the **Error Band**. Anything inside the error band isn't statistically significant.</font>"},{"metadata":{},"cell_type":"markdown","source":"<a id =4.5> </a>\n<br/>\n\n#### Plot the PACF"},{"metadata":{"trusted":true},"cell_type":"code","source":"pacf_plot = plot_pacf(df.Icecream)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id =11> </a>\n<font color=blue>Note:</font>  \n<font color=purple> **1.** There's a strong lags at **1**. As it's just the time series with itself tha's why it will always be 1  \n**2.** Based on PACF, we can build an Auto Regressive Model with lagged value **1**, **2**, **3**, **8** and **13**.</font>"},{"metadata":{},"cell_type":"markdown","source":"<a id =5> </a>\n<br/>\n<br/>\n\n## <font color=red>Important Notes</font>"},{"metadata":{},"cell_type":"markdown","source":"**1.** If there is an **obvious trend** in the dataset, first we will have to **Detrend** it using differencing. Normally **One-lag differencing** is used in this regard.\n<br/>\n\n**2.** If there is no significant auto-correlation, then the series will be called **Random (White Noise)**. We will have to apply **differencing** before the analysis.\n<br/>\n\n**3.** If you find no significant auto-correlation even after the first **differencing**, then it will be called a **Random walk** and **AR** and **MA** can't be applied here. We will then have to go for other models for the analysis."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}