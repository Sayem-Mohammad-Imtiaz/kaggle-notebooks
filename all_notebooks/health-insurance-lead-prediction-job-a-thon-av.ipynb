{"cells":[{"metadata":{"papermill":{"duration":0.025636,"end_time":"2021-01-28T12:28:33.106602","exception":false,"start_time":"2021-01-28T12:28:33.080966","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Health Insurance Lead Prediction - JOB-A-THON"},{"metadata":{"papermill":{"duration":0.024333,"end_time":"2021-01-28T12:28:33.155569","exception":false,"start_time":"2021-01-28T12:28:33.131236","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Step 1: Reading and Understanding the Data"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:33.223183Z","iopub.status.busy":"2021-01-28T12:28:33.222562Z","iopub.status.idle":"2021-01-28T12:28:34.191619Z","shell.execute_reply":"2021-01-28T12:28:34.191032Z"},"papermill":{"duration":1.011487,"end_time":"2021-01-28T12:28:34.191727","exception":false,"start_time":"2021-01-28T12:28:33.18024","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.base as skb\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nimport sklearn.linear_model as sklm\nimport sklearn.neighbors as skn\nimport sklearn.ensemble as ske\nimport catboost as cb\nimport scipy.stats as sstats\nimport random\nseed = 12\nnp.random.seed(seed)\n\nfrom datetime import date","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install pandas-profiling\nimport pandas_profiling as pp","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:34.247924Z","iopub.status.busy":"2021-01-28T12:28:34.247226Z","iopub.status.idle":"2021-01-28T12:28:34.250107Z","shell.execute_reply":"2021-01-28T12:28:34.249553Z"},"papermill":{"duration":0.032766,"end_time":"2021-01-28T12:28:34.250196","exception":false,"start_time":"2021-01-28T12:28:34.21743","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# important funtions\ndef datasetShape(df):\n    rows, cols = df.shape\n    print(\"The dataframe has\",rows,\"rows and\",cols,\"columns.\")\n    \n# select numerical and categorical features\ndef divideFeatures(df):\n    numerical_features = df.select_dtypes(include=[np.number])\n    categorical_features = df.select_dtypes(include=[np.object])\n    return numerical_features, categorical_features","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:34.30632Z","iopub.status.busy":"2021-01-28T12:28:34.305762Z","iopub.status.idle":"2021-01-28T12:28:36.249638Z","shell.execute_reply":"2021-01-28T12:28:36.248711Z"},"papermill":{"duration":1.974819,"end_time":"2021-01-28T12:28:36.249747","exception":false,"start_time":"2021-01-28T12:28:34.274928","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"base = '/kaggle/input/jobathon-analytics-vidhya/'\ndata_file = base + \"train.csv\"\ndf = pd.read_csv(data_file)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:36.308188Z","iopub.status.busy":"2021-01-28T12:28:36.307625Z","iopub.status.idle":"2021-01-28T12:28:37.449588Z","shell.execute_reply":"2021-01-28T12:28:37.450333Z"},"papermill":{"duration":1.174555,"end_time":"2021-01-28T12:28:37.450472","exception":false,"start_time":"2021-01-28T12:28:36.275917","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data_file = base + \"test.csv\"\ndf_test = pd.read_csv(data_file)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set target feature\ntargetFeature='Response'","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:37.509063Z","iopub.status.busy":"2021-01-28T12:28:37.506615Z","iopub.status.idle":"2021-01-28T12:28:37.511363Z","shell.execute_reply":"2021-01-28T12:28:37.510884Z"},"papermill":{"duration":0.034416,"end_time":"2021-01-28T12:28:37.511455","exception":false,"start_time":"2021-01-28T12:28:37.477039","status":"completed"},"scrolled":false,"tags":[],"trusted":true},"cell_type":"code","source":"# check dataset shape\ndatasetShape(df)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:37.616085Z","iopub.status.busy":"2021-01-28T12:28:37.615357Z","iopub.status.idle":"2021-01-28T12:28:37.619068Z","shell.execute_reply":"2021-01-28T12:28:37.618125Z"},"papermill":{"duration":0.050593,"end_time":"2021-01-28T12:28:37.619185","exception":false,"start_time":"2021-01-28T12:28:37.568592","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# remove ID from train data\ndf.drop(['ID'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:37.678566Z","iopub.status.busy":"2021-01-28T12:28:37.678039Z","iopub.status.idle":"2021-01-28T12:28:37.957384Z","shell.execute_reply":"2021-01-28T12:28:37.956735Z"},"papermill":{"duration":0.310883,"end_time":"2021-01-28T12:28:37.95752","exception":false,"start_time":"2021-01-28T12:28:37.646637","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# check for duplicates\nprint(df.shape)\ndf.drop_duplicates(inplace=True)\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.026981,"end_time":"2021-01-28T12:28:38.012876","exception":false,"start_time":"2021-01-28T12:28:37.985895","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Step 2: EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features, cat_features = divideFeatures(df)\ncat_features.head()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.026553,"end_time":"2021-01-28T12:28:38.067161","exception":false,"start_time":"2021-01-28T12:28:38.040608","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Univariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check target feature distribution\ndf[targetFeature].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:38.127273Z","iopub.status.busy":"2021-01-28T12:28:38.126532Z","iopub.status.idle":"2021-01-28T12:28:40.323942Z","shell.execute_reply":"2021-01-28T12:28:40.324395Z"},"papermill":{"duration":2.230498,"end_time":"2021-01-28T12:28:40.324521","exception":false,"start_time":"2021-01-28T12:28:38.094023","status":"completed"},"scrolled":false,"tags":[],"trusted":true},"cell_type":"code","source":"# boxplots of numerical features for outlier detection\n\nfig = plt.figure(figsize=(16,16))\nfor i in range(len(cont_features.columns)):\n    fig.add_subplot(3, 3, i+1)\n    sns.boxplot(y=cont_features.iloc[:,i])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distplots for categorical data\n\nfig = plt.figure(figsize=(16,20))\nfor i in range(len(cat_features.columns)):\n    fig.add_subplot(3, 3, i+1)\n    cat_features.iloc[:,i].hist()\n    plt.xlabel(cat_features.columns[i])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot missing values\n\ndef calc_missing(df):\n    missing = df.isna().sum().sort_values(ascending=False)\n    missing = missing[missing != 0]\n    missing_perc = missing/df.shape[0]*100\n    return missing, missing_perc\n\nif df.isna().any().sum()>0:\n    missing, missing_perc = calc_missing(df)\n    missing.plot(kind='bar',figsize=(16,6))\n    plt.title('Missing Values')\n    plt.show()\nelse:\n    print(\"No missing values\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:28:41.155764Z","iopub.status.busy":"2021-01-28T12:28:41.154759Z","iopub.status.idle":"2021-01-28T12:31:52.208396Z","shell.execute_reply":"2021-01-28T12:31:52.207943Z"},"papermill":{"duration":191.089277,"end_time":"2021-01-28T12:31:52.208505","exception":false,"start_time":"2021-01-28T12:28:41.119228","status":"completed"},"scrolled":false,"tags":[],"trusted":true},"cell_type":"code","source":"sns.pairplot(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation heatmap for all features\ncorr = df.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, mask = mask, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Profiling for Whole Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = pp.ProfileReport(df, title='Pandas Profiling Report', explorative=True)\nprofile.to_file(\"profile.html\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile.to_notebook_iframe()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.209107,"end_time":"2021-01-28T12:31:53.050029","exception":false,"start_time":"2021-01-28T12:31:52.840922","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Step 3: Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"### Skewness"},{"metadata":{"trusted":true},"cell_type":"code","source":"skewed_features = cont_features.apply(lambda x: x.skew()).sort_values(ascending=False)\nskewed_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handle Missing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot missing values\n\ndef calc_missing(df):\n    missing = df.isna().sum().sort_values(ascending=False)\n    missing = missing[missing != 0]\n    missing_perc = missing/df.shape[0]*100\n    return missing, missing_perc\n\nif df.isna().any().sum()>0:\n    missing, missing_perc = calc_missing(df)\n    missing.plot(kind='bar',figsize=(14,5))\n    plt.title('Missing Values')\n    plt.show()\nelse:\n    print(\"No Missing Values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all columns having no values\ndf.dropna(axis=1, how=\"all\", inplace=True)\ndf.dropna(axis=0, how=\"all\", inplace=True)\ndatasetShape(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def fillNan(df, col, value):\n#     df[col].fillna(value, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # setting missing values to most occurring values\n# fillNan(df, 'Health Indicator', df['Health Indicator'].mode()[0])\n# fillNan(df_test, 'Health Indicator', df['Health Indicator'].mode()[0])\n# df['Health Indicator'].isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # setting missing values to most occurring values\n# # try changing with ML algo for missing\n# fillNan(df, 'Holding_Policy_Duration', df['Holding_Policy_Duration'].mode()[0])\n# fillNan(df_test, 'Holding_Policy_Duration', df['Holding_Policy_Duration'].mode()[0])\n# df['Holding_Policy_Duration'].isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # setting missing values to most occurring values\n# # try changing with ML algo for missing\n# fillNan(df, 'Holding_Policy_Type', df['Holding_Policy_Type'].mode()[0])\n# fillNan(df_test, 'Holding_Policy_Type', df['Holding_Policy_Type'].mode()[0])\n# df['Holding_Policy_Type'].isna().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Health Indicator Missing Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # convert city code to int after removing C from it\n# df['City_Code'] = pd.to_numeric(df['City_Code'].map(lambda x:x[1:]))\n# df_test['City_Code'] = pd.to_numeric(df_test['City_Code'].map(lambda x:x[1:]))\n# df['City_Code'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features, cat_features = divideFeatures(df)\ncont_features.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all not null records for imputing\nX_impute = df[df['Health Indicator'].isna()==False]\ny_impute = X_impute.pop('Health Indicator')\n\n# remove categorical cols and targetFeature from X_impute\nX_impute = X_impute[cont_features.columns.tolist()]\nX_impute.drop(['Holding_Policy_Type', targetFeature], inplace=True, axis=1)\n\n# impute with CatBoostClassifier\nimputer_model = cb.CatBoostClassifier(random_state=seed, verbose=0)\nimputer_model.fit(X_impute, y_impute)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict values for train section\nX_test_impute = df[df['Health Indicator'].isna()==True]\nX_test_impute = X_test_impute[X_impute.columns.tolist()]\ny_test_impute = imputer_model.predict(X_test_impute)\n\n# setting value after prediction in df\nfor i,x in enumerate(X_test_impute.index):\n    df.loc[x,'Health Indicator'] = y_test_impute[i]\n    \n# predict values for test section\nX_test_impute = df_test[df_test['Health Indicator'].isna()==True]\nX_test_impute = X_test_impute[X_impute.columns.tolist()]\ny_test_impute = imputer_model.predict(X_test_impute)\n\n# setting value after prediction in df\nfor i,x in enumerate(X_test_impute.index):\n    df_test.loc[x,'Health Indicator'] = y_test_impute[i]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Holding_Policy_Duration Missing Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # convert Health Indicator to int after removing X from it\n# df['Health Indicator'] = pd.to_numeric(df['Health Indicator'].map(lambda x:x[1:]))\n# df_test['Health Indicator'] = pd.to_numeric(df_test['Health Indicator'].map(lambda x:x[1:]))\n# df['Health Indicator'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features, cat_features = divideFeatures(df)\ncont_features.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all not null records for imputing\nX_impute = df[df['Holding_Policy_Duration'].isna()==False]\ny_impute = X_impute.pop('Holding_Policy_Duration')\n\n# remove categorical cols and targetFeature from X_impute\nX_impute = X_impute[cont_features.columns.tolist()]\nX_impute.drop(['Holding_Policy_Type', targetFeature], inplace=True, axis=1)\n\n# impute with RandomForestClassifier\nimputer_model = cb.CatBoostClassifier(random_state=seed, verbose=0)\nimputer_model.fit(X_impute, y_impute)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict values for train section\nX_test_impute = df[df['Holding_Policy_Duration'].isna()==True]\nX_test_impute = X_test_impute[X_impute.columns.tolist()]\ny_test_impute = imputer_model.predict(X_test_impute)\n\n# setting value after prediction in df\nfor i,x in enumerate(X_test_impute.index):\n    df.loc[x,'Holding_Policy_Duration'] = y_test_impute[i]\n    \n# predict values for test section\nX_test_impute = df_test[df_test['Holding_Policy_Duration'].isna()==True]\nX_test_impute = X_test_impute[X_impute.columns.tolist()]\ny_test_impute = imputer_model.predict(X_test_impute)\n\n# setting value after prediction in df\nfor i,x in enumerate(X_test_impute.index):\n    df_test.loc[x,'Holding_Policy_Duration'] = y_test_impute[i]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Holding_Policy_Type Missing Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all not null records for imputing\nX_impute = df[df['Holding_Policy_Type'].isna()==False]\ny_impute = X_impute.pop('Holding_Policy_Type')\n\n# remove categorical cols and targetFeature from X_impute\ncols_impute = cont_features.columns.tolist()\ncols_impute.remove('Holding_Policy_Type')\nX_impute = X_impute[cols_impute]\nX_impute.drop([targetFeature], inplace=True, axis=1)\n\n# impute with RandomForestClassifier\nimputer_model = cb.CatBoostClassifier(random_state=seed, verbose=0)\nimputer_model.fit(X_impute, y_impute)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict values for train section\nX_test_impute = df[df['Holding_Policy_Type'].isna()==True]\nX_test_impute = X_test_impute[X_impute.columns.tolist()]\ny_test_impute = imputer_model.predict(X_test_impute)\n\n# setting value after prediction in df\nfor i,x in enumerate(X_test_impute.index):\n    df.loc[x,'Holding_Policy_Type'] = y_test_impute[i]\n    \n# predict values for test section\nX_test_impute = df_test[df_test['Holding_Policy_Type'].isna()==True]\nX_test_impute = X_test_impute[X_impute.columns.tolist()]\ny_test_impute = imputer_model.predict(X_test_impute)\n\n# setting value after prediction in df\nfor i,x in enumerate(X_test_impute.index):\n    df_test.loc[x,'Holding_Policy_Type'] = y_test_impute[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train Missing:\",df.isna().any().sum())\nprint(\"Test Missing:\",df_test.isna().any().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Derive Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature for age difference between Upper_Age and Lower_Age\ndf['age_diff'] = abs(df['Upper_Age'] - df['Lower_Age'])\ndf_test['age_diff'] = abs(df_test['Upper_Age'] - df_test['Lower_Age'])\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop Lower_Age column as it is highly correlated with Upper_age and we also have its info in age_diff\ndf.drop('Lower_Age', axis=1, inplace=True)\ndf_test.drop('Lower_Age', axis=1, inplace=True)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Dummy Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Holding_Policy_Duration'] = pd.to_numeric(df['Holding_Policy_Duration'].map(lambda x:'15' if x == '14+' else x))\ndf_test['Holding_Policy_Duration'] = pd.to_numeric(df_test['Holding_Policy_Duration'].map(lambda x:'15' if x == '14+' else x))\ndf_test['Holding_Policy_Duration'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_features, cat_features = divideFeatures(df)\ncat_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encoding on categorical features\ndef mapFeature(data, f, data_test=None):\n    feat = data[f].unique()\n    feat_idx = [x for x in range(len(feat))]\n\n    data[f].replace(feat, feat_idx, inplace=True)\n    if data_test is not None:\n        data_test[f].replace(feat, feat_idx, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_features.columns:\n    mapFeature(df, col, df_test)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract numerical and categorical for dummy and scaling later\ncustom_feat = ['City_Code', 'Health Indicator']\n# custom_feat = ['Health Indicator']\nfor feat in cat_features.columns:\n    if len(df[feat].unique()) > 2 and feat in custom_feat:\n        dummyVars = pd.get_dummies(df[feat], drop_first=True, prefix=feat+\"_\")\n        df = pd.concat([df, dummyVars], axis=1)\n        df.drop(feat, axis=1, inplace=True)\ndatasetShape(df)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract numerical and categorical for dummy and scaling later\ncustom_feat = ['City_Code', 'Health Indicator']\n# custom_feat = ['Health Indicator']\nfor feat in cat_features.columns:\n    if len(df_test[feat].unique()) > 2 and feat in custom_feat:\n        dummyVars = pd.get_dummies(df_test[feat], drop_first=True, prefix=feat+\"_\")\n        df_test = pd.concat([df_test, dummyVars], axis=1)\n        df_test.drop(feat, axis=1, inplace=True)\ndatasetShape(df_test)\n\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # dropping holding policy features\n# df.drop(['Holding_Policy_Duration', 'Holding_Policy_Type'], inplace=True, axis=1)\n# df_test.drop(['Holding_Policy_Duration', 'Holding_Policy_Type'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.212855,"end_time":"2021-01-28T12:31:56.491567","exception":false,"start_time":"2021-01-28T12:31:56.278712","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Step 4: Data Modelling\n\n### Split Train-Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper functions\n\ndef log1p(vec):\n    return np.log1p(abs(vec))\n\ndef expm1(x):\n    return np.expm1(x)\n\ndef clipExp(vec):\n    return np.clip(expm1(vec), 0, None)\n\ndef printScore(y_train, y_train_pred):\n    print(skm.roc_auc_score(y_train, y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:31:57.277171Z","iopub.status.busy":"2021-01-28T12:31:57.276357Z","iopub.status.idle":"2021-01-28T12:31:57.408985Z","shell.execute_reply":"2021-01-28T12:31:57.408299Z"},"papermill":{"duration":0.510201,"end_time":"2021-01-28T12:31:57.409111","exception":false,"start_time":"2021-01-28T12:31:56.89891","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# shuffle samples\ndf_shuffle = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n\ndf_y = df_shuffle.pop(targetFeature)\ndf_X = df_shuffle\n\n# split into train dev and test\nX_train, X_test, y_train, y_test = skms.train_test_split(df_X, df_y, train_size=0.8, random_state=seed)\nprint(f\"Train set has {X_train.shape[0]} records out of {len(df_shuffle)} which is {round(X_train.shape[0]/len(df_shuffle)*100)}%\")\nprint(f\"Test set has {X_test.shape[0]} records out of {len(df_shuffle)} which is {round(X_test.shape[0]/len(df_shuffle)*100)}%\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.302636,"end_time":"2021-01-28T12:31:58.022095","exception":false,"start_time":"2021-01-28T12:31:57.719459","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Feature Scaling"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:31:58.962368Z","iopub.status.busy":"2021-01-28T12:31:58.961352Z","iopub.status.idle":"2021-01-28T12:31:59.137173Z","shell.execute_reply":"2021-01-28T12:31:59.1376Z"},"papermill":{"duration":0.40265,"end_time":"2021-01-28T12:31:59.137721","exception":false,"start_time":"2021-01-28T12:31:58.735071","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# scaler = skp.RobustScaler()\n# scaler = skp.MinMaxScaler()\nscaler = skp.StandardScaler()\n\n# apply scaling to all numerical variables except dummy variables as they are already between 0 and 1\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n\n# scale test data with transform()\nX_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)\n\n# view sample data\nX_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.212203,"end_time":"2021-01-28T12:31:59.562164","exception":false,"start_time":"2021-01-28T12:31:59.349961","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train_small = X_train.sample(frac=0.3)\n# y_train_small = y_train.iloc[X_train_small.index.tolist()]\n# X_train_small.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = sku.class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\nclass_weights = dict(enumerate(class_weights))\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_weights = sku.class_weight.compute_sample_weight('balanced', y_train)\nsample_weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = skn.KNeighborsClassifier(n_neighbors = 5, n_jobs=-1)\nknn.fit(X_train, y_train)\n\n# predict\ny_train_pred = knn.predict(X_train)\ny_test_pred = knn.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model = sklm.LogisticRegression()\nlog_model.fit(X_train, y_train, sample_weight=sample_weights)\n\n# predict\ny_train_pred = log_model.predict(X_train)\ny_test_pred = log_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enet_model = sklm.ElasticNetCV(l1_ratio = [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n                    alphas = [1, 0.1, 0.01, 0.001, 0.0005], cv=10)\nenet_model.fit(X_train, y_train)\n\n# predict\ny_train_pred = enet_model.predict(X_train)\ny_test_pred = enet_model.predict(X_test)\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:32:01.357056Z","iopub.status.busy":"2021-01-28T12:32:01.356392Z","iopub.status.idle":"2021-01-28T12:32:06.089243Z","shell.execute_reply":"2021-01-28T12:32:06.088746Z"},"papermill":{"duration":4.958103,"end_time":"2021-01-28T12:32:06.089369","exception":false,"start_time":"2021-01-28T12:32:01.131266","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"ridge_model = sklm.RidgeCV(scoring = \"neg_mean_squared_error\", \n                    alphas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1, 1.0, 10], cv=5\n                   )\nridge_model.fit(X_train, y_train)\n\n# predict\ny_train_pred = ridge_model.predict(X_train)\ny_test_pred = ridge_model.predict(X_test)\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.225189,"end_time":"2021-01-28T12:32:06.531007","exception":false,"start_time":"2021-01-28T12:32:06.305818","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### CatBoost"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:32:06.976588Z","iopub.status.busy":"2021-01-28T12:32:06.975818Z","iopub.status.idle":"2021-01-28T12:32:52.555823Z","shell.execute_reply":"2021-01-28T12:32:52.55508Z"},"papermill":{"duration":45.805459,"end_time":"2021-01-28T12:32:52.555987","exception":false,"start_time":"2021-01-28T12:32:06.750528","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import catboost as cb\n\ncat_model = cb.CatBoostClassifier(loss_function='Logloss', verbose=0, eval_metric='AUC', class_weights=class_weights,\n                           use_best_model=True, iterations=500)\ncat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\nprint(cat_model.best_score_)\n\ny_train_pred = cat_model.predict(X_train)\ny_test_pred = cat_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.394135,"end_time":"2021-01-28T12:32:53.265497","exception":false,"start_time":"2021-01-28T12:32:52.871362","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Grid used\n# param_test1 = {\n#     'n_estimators': [10, 50, 100, 500],\n#     'max_depth': np.arange(2, 12, 2)\n# }\n# gb_cv1 = skms.GridSearchCV(estimator = ske.GradientBoostingClassifier(loss='deviance', random_state=seed), \n#                              param_grid = param_test1, n_jobs=-1, \n#                              cv=5, verbose=1)\n# # gb_cv1.fit(X_train_small, y_train_small)\n# gb_cv1.fit(X_train, y_train, sample_weight=sample_weights)\n# print(gb_cv1.best_params_, gb_cv1.best_score_)\n# # n_estimators = 1000\n# # max_depth = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Grid used\n# param_test2 = {\n#     'min_samples_split': np.arange(2, 12, 3),\n#     'min_samples_leaf': np.arange(1, 10, 3)\n# }\n# gb_cv2 = skms.GridSearchCV(estimator = ske.GradientBoostingClassifier(loss='deviance', random_state=seed,\n#                                                                  n_estimators=50,\n#                                                                  max_depth=7), \n#                              param_grid = param_test2, n_jobs=-1, \n#                              cv=5, verbose=1)\n# gb_cv2.fit(X_train, y_train)\n# print(gb_cv2.best_params_, gb_cv2.best_score_)\n# print(gb_cv2.best_estimator_)\n# # min_samples_split = 8\n# # min_samples_leaf = 1","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:32:54.076653Z","iopub.status.busy":"2021-01-28T12:32:54.075843Z","iopub.status.idle":"2021-01-28T12:35:43.851524Z","shell.execute_reply":"2021-01-28T12:35:43.852269Z"},"papermill":{"duration":170.221997,"end_time":"2021-01-28T12:35:43.852473","exception":false,"start_time":"2021-01-28T12:32:53.630476","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"gb_model = ske.GradientBoostingClassifier(loss='deviance', random_state=seed, verbose=0,\n                                    n_estimators=50, max_depth=7,\n                                    min_samples_leaf=1, min_samples_split=8)\ngb_model.fit(X_train, y_train, sample_weight=sample_weights)\n\n# predict\ny_train_pred = gb_model.predict(X_train)\ny_test_pred = gb_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.212933,"end_time":"2021-01-28T12:35:44.278333","exception":false,"start_time":"2021-01-28T12:35:44.0654","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Extra Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Grid used\n# param_test1 = {\n#     'n_estimators': [10, 50, 100, 500, 1000],\n#     'max_depth': np.arange(2, 12, 2)\n# }\n# extra_cv1 = skms.GridSearchCV(estimator = ske.ExtraTreesClassifier(criterion='gini', random_state=seed), \n#                              param_grid = param_test1, scoring='neg_mean_squared_error', n_jobs=-1, \n#                              cv=5, verbose=1)\n# # extra_cv1.fit(X_train_small, y_train_small)\n# extra_cv1.fit(X_train, y_train)\n# print(extra_cv1.best_params_, extra_cv1.best_score_)\n# # n_estimators = 200\n# # max_depth = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Grid used\n# param_test2 = {\n#     'min_samples_split': np.arange(5, 18, 3),\n#     'min_samples_leaf': np.arange(1, 10, 2)\n# }\n# extra_cv2 = skms.GridSearchCV(estimator = ske.ExtraTreesClassifier(criterion='gini', random_state=seed,\n#                                                                  n_estimators=200,\n#                                                                  max_depth=10), \n#                               param_grid = param_test2, scoring='neg_mean_squared_error', n_jobs=-1, \n#                               cv=5, verbose=1)\n# extra_cv2.fit(X_train, y_train)\n# print(extra_cv2.best_params_, extra_cv2.best_score_)\n# print(extra_cv2.best_estimator_)\n# # min_samples_split = 5\n# # min_samples_leaf = 1","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:35:44.718198Z","iopub.status.busy":"2021-01-28T12:35:44.717172Z","iopub.status.idle":"2021-01-28T12:38:01.719202Z","shell.execute_reply":"2021-01-28T12:38:01.720101Z"},"papermill":{"duration":137.22838,"end_time":"2021-01-28T12:38:01.720305","exception":false,"start_time":"2021-01-28T12:35:44.491925","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"extra_model = ske.ExtraTreesClassifier(criterion='gini', random_state=1, verbose=0, n_jobs=-1,\n                              n_estimators=200,max_depth=10,\n                              min_samples_split = 5, min_samples_leaf = 1)\nextra_model.fit(X_train, y_train, sample_weight=sample_weights)\n\n# predict\ny_train_pred = extra_model.predict(X_train)\ny_test_pred = extra_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_model = ske.AdaBoostClassifier(random_state=1)\nada_model.fit(X_train, y_train, sample_weight=sample_weights)\n\n# predict\ny_train_pred = ada_model.predict(X_train)\ny_test_pred = ada_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.214758,"end_time":"2021-01-28T12:38:02.149293","exception":false,"start_time":"2021-01-28T12:38:01.934535","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### RandomForest"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:38:02.68701Z","iopub.status.busy":"2021-01-28T12:38:02.685896Z","iopub.status.idle":"2021-01-28T12:47:59.913941Z","shell.execute_reply":"2021-01-28T12:47:59.91466Z"},"papermill":{"duration":597.551705,"end_time":"2021-01-28T12:47:59.914909","exception":false,"start_time":"2021-01-28T12:38:02.363204","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"rf_model = ske.RandomForestClassifier(verbose=0, random_state=1, n_jobs=-1, class_weight='balanced_subsample',\n                                 n_estimators=200,max_depth=10, \n                                 min_samples_split = 7, min_samples_leaf = 1\n                                )\nrf_model.fit(X_train, y_train)\n\n# predict\ny_train_pred = rf_model.predict(X_train)\ny_test_pred = rf_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.366142,"end_time":"2021-01-28T12:48:00.698932","exception":false,"start_time":"2021-01-28T12:48:00.33279","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Grid used\n# param_test1 = {\n#     'max_depth': np.arange(5, 12, 2),\n#     'learning_rate': np.arange(0.04, 0.07, 0.01)\n# }\n# xgb_cv1 = skms.GridSearchCV(estimator = xg.XGBClassifier(n_estimators=100, objective='reg:squarederror', nthread=4, seed=seed), \n#                              param_grid = param_test1, scoring='neg_mean_squared_error', n_jobs=4, \n#                              iid=False, cv=5, verbose=1)\n# xgb_cv1.fit(X_train_small, y_train_small)\n# print(xgb_cv1.best_params_, xgb_cv1.best_score_)\n# # max_depth = 10\n# # learning_rate = 0.04","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_test2 = {\n#  'subsample': np.arange(0.5, 1, 0.1),\n#  'min_child_weight': range(1, 6, 1)\n# }\n# xgb_cv2 = skms.GridSearchCV(estimator = xg.XGBClassifier(n_estimators=500, max_depth = 10, \n#                                                      objective= 'reg:squarederror', nthread=4, seed=seed), \n#                             param_grid = param_test2, scoring='neg_mean_squared_error', n_jobs=4,\n#                             cv=5, verbose=1)\n# xgb_cv2.fit(X_train_small, y_train_small)\n# print(xgb_cv2.best_params_, xgb_cv2.best_score_)\n# print(xgb_cv2.best_estimator_)\n# # subsample = 0.5\n# # min_child_weight = 2","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:48:01.13967Z","iopub.status.busy":"2021-01-28T12:48:01.139126Z","iopub.status.idle":"2021-01-28T12:49:01.938946Z","shell.execute_reply":"2021-01-28T12:49:01.93961Z"},"papermill":{"duration":61.024382,"end_time":"2021-01-28T12:49:01.93978","exception":false,"start_time":"2021-01-28T12:48:00.915398","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# working without scaling\nxgb_model = xg.XGBClassifier(objective ='binary:logistic', random_state=seed, verbose=0,\n                      n_estimators=500, max_depth = 10)\nxgb_model.fit(X_train, y_train)\n\n# predict\ny_train_pred = xgb_model.predict(X_train)\ny_test_pred = xgb_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nlgb_model = lgb.LGBMClassifier(objective='binary', class_weight=class_weights, random_state=1, n_jobs=-1,\n                         n_estimators=50)\nlgb_model.fit(X_train, y_train)\n\n# predict\ny_train_pred = lgb_model.predict(X_train)\ny_test_pred = lgb_model.predict(X_test)\nprint(skm.accuracy_score(y_train, y_train_pred))\nprint(skm.accuracy_score(y_test, y_test_pred))\nprintScore(y_train, y_train_pred)\nprintScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.216984,"end_time":"2021-01-28T12:49:02.389444","exception":false,"start_time":"2021-01-28T12:49:02.17246","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Deep Learning Model"},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:49:02.834764Z","iopub.status.busy":"2021-01-28T12:49:02.834227Z","iopub.status.idle":"2021-01-28T12:49:07.863352Z","shell.execute_reply":"2021-01-28T12:49:07.863981Z"},"papermill":{"duration":5.258294,"end_time":"2021-01-28T12:49:07.864158","exception":false,"start_time":"2021-01-28T12:49:02.605864","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\ntf.random.set_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T12:49:08.310713Z","iopub.status.busy":"2021-01-28T12:49:08.309867Z","iopub.status.idle":"2021-01-28T12:49:08.312685Z","shell.execute_reply":"2021-01-28T12:49:08.312256Z"},"papermill":{"duration":0.229066,"end_time":"2021-01-28T12:49:08.312785","exception":false,"start_time":"2021-01-28T12:49:08.083719","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"THRESHOLD = .999\nbestModelPath = './best_model.hdf5'\n\nclass myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached our goal.\")   \n            self.model.stop_training = True\n\nmycb = myCallback()\ncheckpoint = k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n\ncallbacks_list = [mycb,\n                  checkpoint\n                 ]\n            \ndef plotHistory(history):\n    print(\"Min. Validation ACC Score\",min(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"epochs = 40\n\nmodel_1 = k.models.Sequential([\n    k.layers.Dense(2048, activation='relu', input_shape=(X_train.shape[1],)),\n#     k.layers.Dropout(0.3),\n    \n    k.layers.Dense(1024, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(512, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(128, activation='relu'),\n    k.layers.Dropout(0.2),\n\n    k.layers.Dense(1, activation='sigmoid'),\n])\nprint(model_1.summary())\n\nmodel_1.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=[\n#                   tfa.metrics.F1Score(num_classes=1),\n                  'accuracy'\n              ]\n)\nhistory = model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, \n                      batch_size=2048, \n#                       class_weight=class_weights,\n                      callbacks=[callbacks_list]\n                     )\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T13:01:56.943714Z","iopub.status.busy":"2021-01-28T13:01:56.943181Z","iopub.status.idle":"2021-01-28T13:01:57.252905Z","shell.execute_reply":"2021-01-28T13:01:57.25243Z"},"papermill":{"duration":4.885484,"end_time":"2021-01-28T13:01:57.253014","exception":false,"start_time":"2021-01-28T13:01:52.36753","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"plotHistory(history)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# y_train_pred = model_1.predict(X_train)\n# y_test_pred = model_1.predict(X_test)\n# print(skm.accuracy_score(y_train, y_train_pred))\n# print(skm.accuracy_score(y_test, y_test_pred))\n# printScore(y_train, y_train_pred)\n# printScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":4.086657,"end_time":"2021-01-28T13:02:05.649179","exception":false,"start_time":"2021-01-28T13:02:01.562522","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Test Evaluation & Submission"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Generate Ensembles\n\n# def rmse_cv(model):\n#     '''\n#     Use this function to get quickly the rmse score over a cv\n#     '''\n#     rmse = np.sqrt(-skms.cross_val_score(model, X_train, y_train, \n#                                          scoring=\"neg_mean_squared_error\", cv = 5, n_jobs=-1))\n#     return rmse\n\n# class MixModel(skb.BaseEstimator, skb.RegressorMixin, skb.TransformerMixin):\n#     '''\n#     Here we will get a set of models as parameter already trained and \n#     will calculate the mean of the predictions for using each model predictions\n#     '''\n#     def __init__(self, algs):\n#         self.algs = algs\n\n#     # Define clones of parameters models\n#     def fit(self, X, y):\n#         self.algs_ = [skb.clone(x) for x in self.algs]\n        \n#         # Train cloned base models\n#         for alg in self.algs_:\n#             alg.fit(X, y)\n\n#         return self\n    \n#     # Average predictions of all cloned models\n#     def predict(self, X):\n#         predictions = np.column_stack([\n#             stacked_model.predict(X) for stacked_model in self.algs_\n#         ])\n#         return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=predictions)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# mixed_model = MixModel(algs = [\n# #     ridge_model, \n# #     enet_model, \n# #     extra_model, \n# #     cat_model,\n# #     rf_model,\n# #     xgb_model,\n# #     gb_model,\n# #     lgb_model,\n#     ada_model\n# ])\n# # score = rmse_cv(mixed_model)\n# # print(\"\\nAveraged base algs score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n\n# mixed_model.fit(X_train, y_train)\n\n# # predict\n# y_train_pred = mixed_model.predict(X_train)\n# y_test_pred = mixed_model.predict(X_test)\n# printScore(y_train, y_train_pred)\n# printScore(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T13:02:14.087217Z","iopub.status.busy":"2021-01-28T13:02:14.086444Z","iopub.status.idle":"2021-01-28T13:03:03.327472Z","shell.execute_reply":"2021-01-28T13:03:03.327883Z"},"papermill":{"duration":53.59525,"end_time":"2021-01-28T13:03:03.328016","exception":false,"start_time":"2021-01-28T13:02:09.732766","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"cell_type":"code","source":"def getTestResults(m=None):\n    df_final = df.sample(frac=1, random_state=1).reset_index(drop=True)\n    test_cols = [x for x in df_final.columns if targetFeature not in x]\n    df_final_test = df_test[test_cols]\n    df_y = df_final.pop(targetFeature)\n    df_X = df_final\n\n#     scaler = skp.RobustScaler()\n#     scaler = skp.MinMaxScaler()\n    scaler = skp.StandardScaler()\n\n    df_X = pd.DataFrame(scaler.fit_transform(df_X), columns=df_X.columns)\n    df_final_test = pd.DataFrame(scaler.transform(df_final_test), columns=df_X.columns)\n\n    sample_weights = sku.class_weight.compute_sample_weight('balanced', df_y)\n    \n    if m is None:\n\n#         lmr = sklm.LogisticRegression()\n#         lmr.fit(df_X, df_y)\n\n        lmr = cb.CatBoostClassifier(loss_function='Logloss', verbose=0, eval_metric='AUC', class_weights=class_weights)\n        lmr.fit(df_X, df_y)\n\n#         lmr = ske.ExtraTreesClassifier(criterion='gini', random_state=1, verbose=0, n_jobs=-1,\n#                               n_estimators=200,max_depth=10, min_samples_split = 5, min_samples_leaf = 1)\n#         lmr.fit(df_X, df_y, sample_weight=sample_weights)\n\n#         lmr = ske.AdaBoostClassifier(random_state=seed)\n#         lmr.fit(df_X, df_y, sample_weight=sample_weights)\n\n#         lmr = ske.GradientBoostingClassifier(loss='deviance', random_state=seed, verbose=0,\n#                                     n_estimators=50, max_depth=7,min_samples_leaf=1, min_samples_split=8)\n#         lmr.fit(df_X, df_y, sample_weight=sample_weights)\n\n#         lmr = ske.RandomForestClassifier(verbose=0, random_state=1, n_jobs=-1, class_weight='balanced_subsample',\n#                                  n_estimators=200,max_depth=10, min_samples_split = 7, min_samples_leaf = 1)\n#         lmr.fit(df_X, df_y)\n\n#         lmr = xg.XGBClassifier(objective ='binary:logistic', random_state=seed, verbose=0,\n#                       n_estimators=500, max_depth = 10)\n#         lmr.fit(df_X, df_y)\n\n#         lmr = lgb.LGBMClassifier(objective='binary', class_weight=class_weights, random_state=1, n_jobs=-1, n_estimators=50)\n#         lmr.fit(df_X, df_y)\n\n    else:\n        lmr = m\n\n    # predict\n    y_train_pred = lmr.predict(df_X)\n    y_test_pred = lmr.predict(df_final_test)\n    if m is not None:\n        y_train_pred = [round(y[0]) for y in y_train_pred]\n        y_test_pred = [round(y[0]) for y in y_test_pred]\n    print(skm.accuracy_score(df_y, y_train_pred))\n    printScore(df_y, y_train_pred)\n    return y_test_pred\n\n# ML models\nresults = getTestResults()\n\n# Neural Network model\n# results = getTestResults(k.models.load_model(bestModelPath))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T13:03:11.692631Z","iopub.status.busy":"2021-01-28T13:03:11.691727Z","iopub.status.idle":"2021-01-28T13:03:11.699727Z","shell.execute_reply":"2021-01-28T13:03:11.700169Z"},"papermill":{"duration":4.069753,"end_time":"2021-01-28T13:03:11.700294","exception":false,"start_time":"2021-01-28T13:03:07.630541","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n    'ID': df_test['ID'],\n    targetFeature: results,\n})\nprint(submission.Response.value_counts())\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-01-28T13:03:20.003211Z","iopub.status.busy":"2021-01-28T13:03:20.002574Z","iopub.status.idle":"2021-01-28T13:03:20.845785Z","shell.execute_reply":"2021-01-28T13:03:20.845279Z"},"papermill":{"duration":5.107375,"end_time":"2021-01-28T13:03:20.845923","exception":false,"start_time":"2021-01-28T13:03:15.738548","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submission.to_csv('./submission_Cat-robust.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}