{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sign Language Classification Problem\n\nThe dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z. The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, \n\npixel1,pixel2â€¦.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom IPython.display import Image\nImage(filename=\"../input/sign-language-mnist/amer_sign2.png\", width= 800, height=500)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:18:52.891228Z","iopub.execute_input":"2021-06-25T08:18:52.891565Z","iopub.status.idle":"2021-06-25T08:18:52.959861Z","shell.execute_reply.started":"2021-06-25T08:18:52.891536Z","shell.execute_reply":"2021-06-25T08:18:52.958722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 0. List the Directory </h1>","metadata":{}},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T08:18:52.961779Z","iopub.execute_input":"2021-06-25T08:18:52.965896Z","iopub.status.idle":"2021-06-25T08:18:52.991834Z","shell.execute_reply.started":"2021-06-25T08:18:52.965844Z","shell.execute_reply":"2021-06-25T08:18:52.990799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 1. Importing important Libraries </h1>","metadata":{}},{"cell_type":"code","source":"import csv\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:18:52.992879Z","iopub.execute_input":"2021-06-25T08:18:52.993202Z","iopub.status.idle":"2021-06-25T08:18:58.72586Z","shell.execute_reply.started":"2021-06-25T08:18:52.99315Z","shell.execute_reply":"2021-06-25T08:18:58.725105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need to read the csv train and test inputs. Since we are training these as images, so we need to convert them to images and extract labels from it.\n\nThe 1st column of the csv has the label information and the rest are the image pixels.\nWe'll return the images and labels as numpy array.","metadata":{}},{"cell_type":"markdown","source":"<h1> 2. Reading the dataset </h1>","metadata":{}},{"cell_type":"code","source":"def get_data(filename):\n    with open(filename) as training_file:\n        training_reader = csv.reader(training_file, delimiter=',')\n        image = []\n        labels = []\n        line_count = 0\n        for row in training_reader:\n            if line_count == 0:\n                line_count +=1\n            else:\n                labels.append(row[0])\n                temp_image = row[1:785]\n                image_data_as_array = np.array_split(temp_image, 28)\n                image.append(image_data_as_array)\n                line_count += 1\n        images = np.array(image).astype('float')\n        labels = np.array(labels).astype('float')\n        print(f'Processed {line_count} lines.')\n\n    return images, labels\n\n\ntraining_images, training_labels = get_data(\"../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\")\ntesting_images, testing_labels = get_data(\"../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\")\n\nprint(\"Total Training images\", training_images.shape)\nprint(\"Total Training labels\",training_labels.shape)\nprint(\"Total Testing images\",testing_images.shape)\nprint(\"Total Testing labels\",testing_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:18:58.727025Z","iopub.execute_input":"2021-06-25T08:18:58.727377Z","iopub.status.idle":"2021-06-25T08:19:27.338548Z","shell.execute_reply.started":"2021-06-25T08:18:58.727342Z","shell.execute_reply":"2021-06-25T08:19:27.336555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>3. EDA and Data Visualization </h1>","metadata":{}},{"cell_type":"code","source":"alphabets = 'abcdefghijklmnopqrstuvwxyz'\nmapping_letter = {}\n\nfor i,l in enumerate(alphabets):\n    mapping_letter[l] = i\nmapping_letter = {v:k for k,v in mapping_letter.items()}","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:19:27.342008Z","iopub.execute_input":"2021-06-25T08:19:27.342272Z","iopub.status.idle":"2021-06-25T08:19:27.346562Z","shell.execute_reply.started":"2021-06-25T08:19:27.342245Z","shell.execute_reply":"2021-06-25T08:19:27.345729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some pictures of the dataset\nfig, axes = plt.subplots(nrows=4, ncols=6, figsize=(8, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    img = training_images[i].reshape(28,28)\n    ax.imshow(img, cmap = 'gray')\n    title = mapping_letter[training_labels[i]]\n    ax.set_title(title, fontsize = 15)\nplt.tight_layout(pad=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:19:27.348728Z","iopub.execute_input":"2021-06-25T08:19:27.349297Z","iopub.status.idle":"2021-06-25T08:19:28.592153Z","shell.execute_reply.started":"2021-06-25T08:19:27.34926Z","shell.execute_reply":"2021-06-25T08:19:28.591352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the distribution of each letter\n\nvc = pd.Series(training_labels).value_counts()\nplt.figure(figsize=(20,5))\nsns.barplot(x = sorted(vc.index), y = vc, palette = \"rocket\")\nplt.title(\"Number of pictures of each category\", fontsize = 15)\nplt.xticks(fontsize = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:19:28.593484Z","iopub.execute_input":"2021-06-25T08:19:28.593853Z","iopub.status.idle":"2021-06-25T08:19:28.888571Z","shell.execute_reply.started":"2021-06-25T08:19:28.593801Z","shell.execute_reply":"2021-06-25T08:19:28.887723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see that there are 25 categories present in the labels, On careful observation we find that **Z** is not present in the dataset.\n\nNow we need to add another dimension in our images so that we can process it for the **ImageDataGenerator** and do the **Image Augmentation**\nRead more [here](https://keras.io/api/preprocessing/image/)","metadata":{}},{"cell_type":"markdown","source":"<h1> 4. Data Augmentation </h1> ","metadata":{}},{"cell_type":"code","source":"training_images = np.expand_dims(training_images, axis = 3)\ntesting_images = np.expand_dims(testing_images, axis = 3)\n\nprint(training_images.shape)\nprint(testing_images.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:19:28.890256Z","iopub.execute_input":"2021-06-25T08:19:28.890586Z","iopub.status.idle":"2021-06-25T08:19:28.896342Z","shell.execute_reply.started":"2021-06-25T08:19:28.890549Z","shell.execute_reply":"2021-06-25T08:19:28.895466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an ImageDataGenerator and do Image Augmentation\n\ntrain_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n                                   height_shift_range=0.1,\n                                   width_shift_range=0.1,\n                                   zoom_range=0.1,\n                                   shear_range=0.1,\n                                   rotation_range=10,\n                                   fill_mode='nearest',\n                                   horizontal_flip=True)\n\n#Image Augmentation is not done on the testing data\n\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_datagenerator = train_datagen.flow(training_images,\n                                         training_labels,\n                                         batch_size = 32)\n\nvalidation_datagenerator = validation_datagen.flow(testing_images,\n                                                   testing_labels, \n                                                   batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:19:28.897671Z","iopub.execute_input":"2021-06-25T08:19:28.89811Z","iopub.status.idle":"2021-06-25T08:19:28.938852Z","shell.execute_reply.started":"2021-06-25T08:19:28.898074Z","shell.execute_reply":"2021-06-25T08:19:28.93806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets define a callback for avoiding the excess training and stopping the training based on the predefined condition, in our case, we want training to stop once the **accuracy** is reached above **99%**.","metadata":{}},{"cell_type":"markdown","source":"<h1>5.  Define a Callback </h1>","metadata":{}},{"cell_type":"code","source":"# Define a Callback class that stops training once accuracy reaches 99.8%\n\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>0.998):\n      print(\"\\nReached 99.8% accuracy so cancelling training!\")\n      self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:37:10.939843Z","iopub.execute_input":"2021-06-25T08:37:10.9402Z","iopub.status.idle":"2021-06-25T08:37:10.945494Z","shell.execute_reply.started":"2021-06-25T08:37:10.94015Z","shell.execute_reply":"2021-06-25T08:37:10.94426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 6. Defining the model </h1>","metadata":{}},{"cell_type":"code","source":"# Define the model\n\nmodel = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape = (28,28,1)),\n                                    tf.keras.layers.MaxPool2D(2,2),\n                                    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n                                    tf.keras.layers.MaxPool2D(2,2),\n                                    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n                                    tf.keras.layers.MaxPool2D(2,2),\n                                    tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(1024, activation = 'relu'),\n                                    tf.keras.layers.Dropout(0.2),\n                                    tf.keras.layers.Dense(512, activation = 'relu'),\n                                    tf.keras.layers.Dropout(0.2),\n                                    tf.keras.layers.Dense(25, activation = 'softmax')])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:27:05.800955Z","iopub.execute_input":"2021-06-25T08:27:05.801312Z","iopub.status.idle":"2021-06-25T08:27:05.87618Z","shell.execute_reply.started":"2021-06-25T08:27:05.801279Z","shell.execute_reply":"2021-06-25T08:27:05.875382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:27:08.769752Z","iopub.execute_input":"2021-06-25T08:27:08.77009Z","iopub.status.idle":"2021-06-25T08:27:08.778729Z","shell.execute_reply.started":"2021-06-25T08:27:08.770059Z","shell.execute_reply":"2021-06-25T08:27:08.77681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have used 3 Conv2D and 3 MaxPooling2D and the dropout of 0.2","metadata":{}},{"cell_type":"code","source":"# Compiling the Model. \nmodel.compile(loss = 'sparse_categorical_crossentropy',\n             optimizer = tf.keras.optimizers.Adam(),\n              metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:37:21.338527Z","iopub.execute_input":"2021-06-25T08:37:21.338847Z","iopub.status.idle":"2021-06-25T08:37:21.353522Z","shell.execute_reply.started":"2021-06-25T08:37:21.338818Z","shell.execute_reply":"2021-06-25T08:37:21.352662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>7. Learning Rate modification </h1>","metadata":{}},{"cell_type":"code","source":"learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience = 2, \n                                            verbose=1,factor=0.25, \n                                            min_lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:37:23.890271Z","iopub.execute_input":"2021-06-25T08:37:23.890591Z","iopub.status.idle":"2021-06-25T08:37:23.896114Z","shell.execute_reply.started":"2021-06-25T08:37:23.89056Z","shell.execute_reply":"2021-06-25T08:37:23.895208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 8. Training Model </h1>","metadata":{}},{"cell_type":"code","source":"# Train the Model\ncallbacks = myCallback()\nhistory = model.fit(train_datagenerator,\n                    validation_data = validation_datagenerator,\n                    steps_per_epoch = len(training_labels)//32,\n                    epochs = 100,\n                    validation_steps = len(testing_labels)//32,\n                    callbacks = [callbacks, learning_rate_reduction])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:37:25.532225Z","iopub.execute_input":"2021-06-25T08:37:25.532557Z","iopub.status.idle":"2021-06-25T08:39:36.50121Z","shell.execute_reply.started":"2021-06-25T08:37:25.532525Z","shell.execute_reply":"2021-06-25T08:39:36.500098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 9. Plotiing the losses </h1>","metadata":{}},{"cell_type":"code","source":"# Plot the chart for accuracy and loss on both training and validation\n\nimport matplotlib.pyplot as plt\nfig.set_size_inches(16,9)\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:39:44.369214Z","iopub.execute_input":"2021-06-25T08:39:44.369537Z","iopub.status.idle":"2021-06-25T08:39:44.664162Z","shell.execute_reply.started":"2021-06-25T08:39:44.369506Z","shell.execute_reply":"2021-06-25T08:39:44.663335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(testing_images, testing_labels, verbose=0)\n\n# model.save('sign_language.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:39:54.505944Z","iopub.execute_input":"2021-06-25T08:39:54.506286Z","iopub.status.idle":"2021-06-25T08:39:55.117521Z","shell.execute_reply.started":"2021-06-25T08:39:54.506254Z","shell.execute_reply":"2021-06-25T08:39:55.116792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> 10. Visualise the model </h1>","metadata":{}},{"cell_type":"code","source":"tf.keras.utils.plot_model(model,\n                          to_file=\"model.png\",\n                          show_shapes=True,\n                          show_dtype=False,\n                          show_layer_names=True,\n                          rankdir=\"TB\",                          \n                          expand_nested=True,\n                          dpi=96)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:39:58.278328Z","iopub.execute_input":"2021-06-25T08:39:58.278655Z","iopub.status.idle":"2021-06-25T08:39:58.463814Z","shell.execute_reply.started":"2021-06-25T08:39:58.278624Z","shell.execute_reply":"2021-06-25T08:39:58.46287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>11. Evaluating Model </h1>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n# Predict the label of the test_images\npred = model.predict(testing_images)\npred = np.argmax(pred,axis=1)\n\n# Get the accuracy score\nacc = accuracy_score(testing_labels,pred)\n\n# Display the results\nprint(f'## {acc*100:.2f}% accuracy on the test set')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:40:02.560372Z","iopub.execute_input":"2021-06-25T08:40:02.560729Z","iopub.status.idle":"2021-06-25T08:40:02.894232Z","shell.execute_reply.started":"2021-06-25T08:40:02.560696Z","shell.execute_reply":"2021-06-25T08:40:02.892416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map the numbers into letters\ny_test_letters = [mapping_letter[x] for x in testing_labels]\npred_letters = [mapping_letter[x] for x in pred]\n\nprint(classification_report(y_test_letters, pred_letters))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:40:13.685785Z","iopub.execute_input":"2021-06-25T08:40:13.68611Z","iopub.status.idle":"2021-06-25T08:40:13.778957Z","shell.execute_reply.started":"2021-06-25T08:40:13.68608Z","shell.execute_reply":"2021-06-25T08:40:13.778306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a confusion matrix\ncf_matrix = confusion_matrix(y_test_letters, pred_letters, normalize='true')\nplt.figure(figsize = (20,15))\nsns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test_letters)), yticklabels = sorted(set(y_test_letters)),cbar=False)\nplt.title('Normalized Confusion Matrix\\n', fontsize = 23)\nplt.xlabel(\"Predicted Classes\",fontsize=15)\nplt.ylabel(\"True Classes\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15,rotation=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:40:22.151336Z","iopub.execute_input":"2021-06-25T08:40:22.151736Z","iopub.status.idle":"2021-06-25T08:40:24.033681Z","shell.execute_reply.started":"2021-06-25T08:40:22.151692Z","shell.execute_reply":"2021-06-25T08:40:24.032771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>12. Outputs sample</h1>","metadata":{}},{"cell_type":"code","source":"correct = np.nonzero(pred == testing_labels)[0]\nplt.figure(figsize=(6, 6))\ni = 0\nfor c in correct[:9]:\n    plt.subplot(3,3,i+1)\n    plt.imshow(testing_images[c].reshape(28,28), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted:{}, Actual:{}\".format(pred_letters[c], y_test_letters[c]))\n    plt.tight_layout()\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:40:29.26137Z","iopub.execute_input":"2021-06-25T08:40:29.261692Z","iopub.status.idle":"2021-06-25T08:40:30.434187Z","shell.execute_reply.started":"2021-06-25T08:40:29.261661Z","shell.execute_reply":"2021-06-25T08:40:30.433477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}