{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **An Evaluation on Student's Performance in Exams**\n\nI downloaded a csv data from the internet and created my classifiers evaluation as a submission requirement for the class Advance Database Management System MIT504.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Overview**\n\nThe classification task is to determine the performance of the student based on gender, ethnicity, highest educational attainment of parents and so on. Since it has different factors, I will focus more on the gender class.\n\nThis dataset is composed of basic student information such as gender, ethnicity and parental highest education attainment. It serves as guide in determining if these factors really affects the performance of the student. With these factors or columns, we can identify what factor must be consider when enghancing the performance of our students in the future. \n\nAcknowledgement to my classmates who offered help in utilizing this type of \"project repository or kernels\" or \"notebook\" where I really don't have a firm knowledge in creating my own \"kernel\" from scatch. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# About this Dataset\nAttribute Information: \n\n* **gender**: male, female\n\n* **race/ethnicity**: group A, group B, group C, group D, group E \n\n* **parental level of education**: some college, associate degree, high school, some high school, bachelor's degree\n\n* **lunch**: standard, free/reduced\n\n* **test preparation**: none, completed\n\n* **math score**: (student's score range from 1-100)\n\n* **reading score:** (student's score range from 1-100)\n\n* **writing score:** (student's score range from 1-100)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# I. Initialization\nLets try to load our dataset csv file","execution_count":null},{"metadata":{"_uuid":"76e3ee2fb0696230f0873d1cd9915fe58b94b2c9","_cell_guid":"2ea3e1b2-19e3-4a34-b624-e514c055d141","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nstud_perf = pd.read_csv('../input/studentsperformance/datasets_74977_169835_StudentsPerformance.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# II. Visualization or Data Analysis Expolaration","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1) Select the columns that describes the student (gender,race/ethnicity,parental level of education,test preparation course)\n\n2) Run some statistical analysis\n\n3) Assign numerical values to the letter values in order to feed the Logistic Regression Algo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# A. To identify and visualize the count of distinct the different race or ethnicity.\n    \n    a. Using the column data: \"race/ethnicity\"","execution_count":null},{"metadata":{"scrolled":false,"_uuid":"31df5780d5f2083b7aa3e3f25f3647f5072b34ae","_cell_guid":"80cc8edc-5fbc-450b-935f-1aae05891568","trusted":true},"cell_type":"code","source":"#Obtain total number of students for each 'gender' (Entire DataFrame)\np_race = stud_perf['race/ethnicity'].value_counts()\np_race_height = p_race.values.tolist() #Provides numerical values\np_race.axes #Provides row labels\np_race_labels = p_race.axes[0].tolist() #Converts index object to list\n\n#=====PLOT Preparations and Plotting====#\nind = np.arange(5)  # the x locations for the groups\nwidth = 0.7        # the width of the bars\ncolors = ['#FD1414','#FFF012','#11F237','#1155F2','#B611F2']\nfig, ax = plt.subplots(figsize=(5,7))\nstud_perf_bars = ax.bar(ind, p_race_height , width, color=colors)\n\n#Add some text for labels, title and axes ticks\nax.set_xlabel(\"Ethnity Group\",fontsize=20)\nax.set_ylabel('Count',fontsize=20)\nax.set_title('Race/Ethnicity',fontsize=22)\nax.set_xticks(ind) #Positioning on the x axis\nax.set_xticklabels(('group C', 'group D','group B','group E','group A'),\n                  fontsize = 12)\n\n#Auto-labels the number of mushrooms for each bar color.\ndef autolabel(rects,fontsize=14):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2., 1*height,'%d' % int(height),\n                ha='center', va='bottom',fontsize=fontsize)\nautolabel(stud_perf_bars)        \nplt.show() #Display bars. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B. To discover the distinct values student gender by ethnicity.\n     \n     a. Using the column data: \"gender\"","execution_count":null},{"metadata":{"_uuid":"dfa67188058f4993a273edc7b145fbf0d4816d94","_cell_guid":"4af9dd1c-aece-4b89-8333-55ef6c6f14b1","trusted":true},"cell_type":"code","source":"female_count = [] #female\nmale_count = []    #male\nfor genCount in p_race_labels:\n    size = len(stud_perf[stud_perf['race/ethnicity'] == genCount].index)\n    f_c = len(stud_perf[(stud_perf['race/ethnicity'] == genCount) & (stud_perf['gender'] == 'female')].index)\n    female_count.append(f_c)\n    male_count.append(size-f_c)\n                        \n#=====PLOT Preparations and Plotting====#\nwidth = 0.40\nfig, ax = plt.subplots(figsize=(12,7))\nfemale_bar_value = ax.bar(ind, female_count , width, color='#FF3A75')\nmale_bar_value = ax.bar(ind+width, male_count , width, color='#0A0AFF')\n\n#Add some text for labels, title and axes ticks\nax.set_xlabel(\"Ethnicity Group\",fontsize=20)\nax.set_ylabel('Count',fontsize=20)\nax.set_title('Gender Comparison By Group',fontsize=22)\nax.set_xticks(ind + width / 2) #Positioning on the x axis\nax.set_xticklabels(('group C', 'group D','group B','group E','group A'),\n                  fontsize = 12)\nax.legend((female_bar_value,male_bar_value),('Female Count','Male Count'),fontsize=17)\nautolabel(female_bar_value, 10)\nautolabel(male_bar_value, 10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **C. To Visualize the differences of the scores of the students in math, reading and writing scores**\n* Using the columns 'gender', 'test preparation course','math scores','reading scores' and 'writing scores'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.subplot(1, 3, 1)\nsns.barplot(x='test preparation course',y='math score',data=stud_perf,hue='gender',palette='summer')\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.barplot(x='test preparation course',y='reading score',data=stud_perf,hue='gender',palette='summer')\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.barplot(x='test preparation course',y='writing score',data=stud_perf,hue='gender',palette='summer')\nplt.title('WRITING SCORES')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D. To visualize the relevance of the parental educational level to the math, reading and writing scores of the students.\n    \n    a. Using the column data: \"parental level of education\", \"math scores\", \"reading scores\", \"writing scores\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stud_perf['Total Score']=stud_perf['math score']+stud_perf['reading score']+stud_perf['writing score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.barplot(x=stud_perf['parental level of education'],y='Total Score',data=stud_perf,palette='Wistia')\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When interpreting the graph above, we could say that students with high level of parental education gets higher scores in math, reading and writing.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# A comparison of scores: male vs female based on test preparation course","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nplt.subplot(1, 3, 1)\nsns.barplot(x='test preparation course',y='math score',data=stud_perf,hue='gender',palette='summer')\nplt.title('MATH SCORES')\nplt.subplot(1, 3, 2)\nsns.barplot(x='test preparation course',y='reading score',data=stud_perf,hue='gender',palette='summer')\nplt.title('READING SCORES')\nplt.subplot(1, 3, 3)\nsns.barplot(x='test preparation course',y='writing score',data=stud_perf,hue='gender',palette='summer')\nplt.title('WRITING SCORES')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After generating the graph, we can say that:\n|* the first plot says that the math scores of boys are better irrespective of wether they completed the course or no.\n* the next two plots says that girls perform more better in reading and writing\n* Lastly, from all three graphs its clear that if the course is completed we can achieve higher scores","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Testing a random sample of the dataset of 500 students","execution_count":null},{"metadata":{"_uuid":"d22c308a428d34946bdaf309a8f7f32711b5b08c","_cell_guid":"ab581739-44ec-4e23-a390-e09704e95873","trusted":true},"cell_type":"code","source":"stud_perf_sample = stud_perf.loc[np.random.choice(stud_perf.index, 1000, False)]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"714ff4766889709fcb30955c31fb29c22ea2cb0c","_cell_guid":"b487a371-5703-4e49-a564-3c2f493ecade","trusted":true},"cell_type":"code","source":"#Get all unique race/ethnicity\nstud_perf_sample['race/ethnicity'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e643f2b5d8336c238a2c9f348d96bbbe8b8e3267","_cell_guid":"52e0b085-dcd7-4956-9aaf-a075943922d7","trusted":true},"cell_type":"code","source":"#mushrooms_sample.groupby('cap-color', 0).nunique()\n\n#Get 'race/ethnicity' Series\ngenCount = stud_perf_sample['race/ethnicity']\n\n#Get the total number of mushrooms for each unique cap color. \ngenCount.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Balancing / Cleanup\n\nTo test if my datasheet is balance, two classes must be compared.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nstud_perf = pd.read_csv('../input/studentsperformance/datasets_74977_169835_StudentsPerformance.csv')\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n #       print(os.path.join(dirname, filename))\n        \n\n#df = pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv') # df usually is used to abbreviate \"Data Frame\" from pandas library\n\n#print(f'Data Frame Shape (rows, columns): {df.shape}') \n\nsns.countplot(data=stud_perf, x=\"gender\").set_title(\"Class Outcome - Female-F/Male-M\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the graph illustrated above, we could say that the population for genders female and male is not balanced. Though, this class is not the main basis for this dataset but just a supplimentary factor that must be considered. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# III. Classifier Setups and Build Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The next procedure is to create classifier setups and build model as indicated on the instructions.\n\nLogistic Regression\nSupport Vector machines (SVC)\nK-Nearest Neighbours(K-NN)\nNaive Bayes classifier\nDecision Tree Classifier\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# A. Importing the Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B. Checking for nulls","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stud_perf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Description of Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stud_perf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"Class\" column is response and rest columns are predictors.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> **Seprating Predictors and Response**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=stud_perf.drop('gender',axis=1) #Predictors\ny=stud_perf['gender'] #Response\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C. Encoding categorical data > Label encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nEncoder_X = LabelEncoder() \nfor col in X.columns:\n    X[col] = Encoder_X.fit_transform(X[col])\nEncoder_y=LabelEncoder()\ny = Encoder_y.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Poisonous = 1\n\n# Edible = 0","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# D. Getting dummy variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.get_dummies(X,columns=X.columns,drop_first=True)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# E. Splitting the dataset into the Training set and Test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# F. Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# G. Applying PCA with n_components = 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\n\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# H. Functions to visualize Training & Test Set Results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualization_train(model):\n    sns.set_context(context='notebook',font_scale=2)\n    plt.figure(figsize=(16,9))\n    from matplotlib.colors import ListedColormap\n    X_set, y_set = X_train, y_train\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.6, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    plt.title(\"%s Training Set\" %(model))\n    plt.xlabel('PC 1')\n    plt.ylabel('PC 2')\n    plt.legend()\ndef visualization_test(model):\n    sns.set_context(context='notebook',font_scale=2)\n    plt.figure(figsize=(16,9))\n    from matplotlib.colors import ListedColormap\n    X_set, y_set = X_test, y_test\n    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n                 alpha = 0.6, cmap = ListedColormap(('red', 'green')))\n    plt.xlim(X1.min(), X1.max())\n    plt.ylim(X2.min(), X2.max())\n    for i, j in enumerate(np.unique(y_set)):\n        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                    c = ListedColormap(('red', 'green'))(i), label = j)\n    plt.title(\"%s Test Set\" %(model))\n    plt.xlabel('PC 1')\n    plt.ylabel('PC 2')\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IV. Integrating Artificial Neural Networks (ANN)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A. Initializing ANN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# ARTIFICIAL NEURAL NETWORK","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To perdict whether a mushroom is poisonous or edible, I use ANN classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B. Adding Layers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(8, kernel_initializer='uniform', activation= 'relu', input_dim = 2))\nclassifier.add(Dense(6, kernel_initializer='uniform', activation= 'relu'))\nclassifier.add(Dense(5, kernel_initializer='uniform', activation= 'relu'))\nclassifier.add(Dense(4, kernel_initializer='uniform', activation= 'relu'))\nclassifier.add(Dense(1, kernel_initializer= 'uniform', activation= 'sigmoid'))\nclassifier.compile(optimizer= 'adam',loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C. Fitting ANN to Training Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train,y_train,batch_size=10,epochs=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D. Predicting the Test Set Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=classifier.predict(X_test)\ny_pred=(y_pred>0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# E. Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,classification_report\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# F. Classification Report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# G. Visualizing ANN Training Set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_train(model='ANN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# H. Creating a function to evaluate model's performance.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Creating a func to evaluate model's performance.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict, cross_val_score\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_score(classifier,X_train,y_train,X_test,y_test,train=True):\n    if train == True:\n        print(\"Training results:\\n\")\n        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_train,classifier.predict(X_train))))\n        print('Classification Report:\\n{}\\n'.format(classification_report(y_train,classifier.predict(X_train))))\n        print('Confusion Matrix:\\n{}\\n'.format(confusion_matrix(y_train,classifier.predict(X_train))))\n        res = cross_val_score(classifier, X_train, y_train, cv=10, n_jobs=-1, scoring='accuracy')\n        print('Average Accuracy:\\t{0:.4f}\\n'.format(res.mean()))\n        print('Standard Deviation:\\t{0:.4f}'.format(res.std()))\n    elif train == False:\n        print(\"Test results:\\n\")\n        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_test,classifier.predict(X_test))))\n        print('Classification Report:\\n{}\\n'.format(classification_report(y_test,classifier.predict(X_test))))\n        print('Confusion Matrix:\\n{}\\n'.format(confusion_matrix(y_test,classifier.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V. Classifiers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# A. Logistic Regression Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Fitting Logistic Regression model to the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression()\n\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Training Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Test Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the Logistic Regression Training set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_train('Logistic Reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the Logistic Regression Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_test('Logistic Reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# B. Support Vecor (SVC) Classification Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Fitting SVC to the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel='rbf',random_state=42)\n\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVC Training Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVC Test Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the SVC Training set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_train('SVC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Visualising the SVC Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_test('SVC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# C. K Nearest Neighbors (K-NN) Classification Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Fitting K-NN to the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier as KNN\n\nclassifier = KNN()\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-NN Training Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-NN Test Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the K-NN Training set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_train('K-NN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the K-NN Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_test('K-NN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# D. Naive Bayes Classification Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Fitting Naive Bayes classifier to the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB as NB\n\nclassifier = NB()\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Training Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Test Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the Naive Bayes Training set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_train('Naive Bayes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the Naive bayes Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_test('Naive Bayes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# E. Decision Tree Classification Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Fitting Decision Tree classifier to the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier as DT\n\nclassifier = DT(criterion='entropy',random_state=42)\nclassifier.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Training Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Test Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(classifier,X_train,y_train,X_test,y_test,train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the Decision tree Training set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_train('Decision Tree')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising the Decision Tree Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_test('Decision Tree')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results :\n\n\nClassifier | Logistic Reg| SVC | K-NN | Naive Bayes | Decision Tree |\n\nTrain accuracy score | 0.9057 | 0.9289 | 0.9430 | 0.8980 | 1.0000 |\n\nAverage accuracy score | 0.9057 | 0.9281 | 0.9314 | 0.8982 | 0.8920 | \n\nSD | 0.0097 | 0.0112 | 0.0097 | 0.0114 | 0.0128 | \n\nTest accuary score | 0.9028 | 0.9258 | 0.9307 | 0.8966 | 0.9016 |","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Results :\n| Classifier | Logistic Reg| SVC | K-NN | Naive Bayes | Decision Tree |\n| --- | --- | --- | --- | --- | --- |\n| Train accuracy score | 0.9057 | 0.9289 | 0.9430 | 0.8980 | 1.0000 |\n| Average accuracy score | 0.9057 | 0.9281 | 0.9314 | 0.8982 | 0.8920 |\n| SD | 0.0097 | 0.0112 | 0.0097 | 0.0114 | 0.0128 |\n| Test accuary score | 0.9028 | 0.9258 | 0.9307 | 0.8966 | 0.9016 |","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}