{"cells":[{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nfrom scipy import stats\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notebook explores different approaches in classifying breast cancer using different types of SVM i.e using linear kernel, radial basis function, and margin adjustment."},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"########## Import data and preprocess\ndf = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# drop bad data\ndf.dropna()\ndf.isnull().sum()\n\n# clean unwanted data\ndf.drop('id',axis=1,inplace=True)\ndf.drop('Unnamed: 32',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Convert Malignant diagnosis into 1 and Benign into 0\ndf['diagnosis'].astype(str)\ndf['diagnosis'] = [1 if val == 'M' else 0 for val in df['diagnosis'].values ]\n########## Select data and labels\nx = df.iloc[:,2:len(df.columns)]\ny = df['diagnosis'].values\n########## Data train test split\n(x_train,x_test,y_train,y_test) = train_test_split(x, y, test_size=0.3)\n########## Data scaling and normalization\nscaler = StandardScaler()\nx_train = scaler.fit_transform(x_train) #fit is done for train set after split to prevent leak\nx_test = scaler.transform(x_test) # Using the same fit as in train ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM1 with linear kernel"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"########## Initialize containers\nSVM1AccTrain = []\nSVM1AccTest = []\nSVM1Precision = []\nSVM1Recall = []\n\n########## SVM1 with linear kernel\nfor i in range (0, 20):\n    clf = SVC(kernel='linear', C=10**(10))\n    clf.fit(x_train, y_train)\n\n    y_test_pred = clf.predict(x_test)\n    y_train_pred = clf.predict(x_train)\n    \n    SVM1AccTrain.append(accuracy_score(y_train, y_train_pred))\n    SVM1AccTest.append(accuracy_score(y_test, y_test_pred))\n    SVM1Precision.append(precision_score(y_test, y_test_pred))\n    SVM1Recall.append(recall_score(y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"########## Print average stats of SVM1\nprint ('''\n        Average Statistics for SVM1\n        \\n SVM1AccTrainAvg = {}\n        \\n SVM1AccTestAvg = {}\n        \\n SVM1PrecisionAvg = {}\n        \\n SVM1RecallAvg = {}\n        '''.format(\n        np.mean(SVM1AccTrain),\n        np.mean(SVM1AccTest),\n        np.mean(SVM1Precision),\n        np.mean(SVM1Recall)\n        ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM2 with RBF kernel"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"########## Initialize containers\nSVM2AccTrain = []\nSVM2AccTest = []\nSVM2Precision = []\nSVM2Recall = []\n\n########## SVM2 with RBF kernel\nfor i in range (0, 20):\n    clf = SVC(kernel='rbf', C=10**(10))\n    clf.fit(x_train, y_train)\n\n    y_test_pred = clf.predict(x_test)\n    y_train_pred = clf.predict(x_train)\n    \n    SVM2AccTrain.append(accuracy_score(y_train, y_train_pred))\n    SVM2AccTest.append(accuracy_score(y_test, y_test_pred))\n    SVM2Precision.append(precision_score(y_test, y_test_pred))\n    SVM2Recall.append(recall_score(y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"########## Print average stats of SVM2\nprint ('''\n        Average Statistics for SVM2\n        \\n SVM2AccTrainAvg = {}\n        \\n SVM2AccTestAvg = {}\n        \\n SVM2PrecisionAvg = {}\n        \\n SVM2RecallAvg = {}\n        '''.format(\n        np.mean(SVM2AccTrain),\n        np.mean(SVM2AccTest),\n        np.mean(SVM2Precision),\n        np.mean(SVM2Recall)\n        ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM3 RBF kernel with regularization (soft margin)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"CList = [10**(n) for n in range (-30,30)]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"########## Initialize containers\nSVM3MeanAccTrainList = []\nSVM3MeanAccTestList = []\nSVM3MeanPrecisionList = []\nSVM3MeanRecallList = []\n\n########## SVM3 RBF kernel with regularization (soft margin)\nfor CVal_i, CVal in enumerate(CList):\n    SVM3AccTrain = []\n    SVM3AccTest = []\n    SVM3Precision = []\n    SVM3Recall = []\n    for i in range(0, 20):\n        clf = SVC(kernel='linear', C=CVal)\n        clf.fit(x_train, y_train)\n\n        y_test_pred = clf.predict(x_test)\n        y_train_pred = clf.predict(x_train)\n\n        SVM3AccTrain.append(accuracy_score(y_train, y_train_pred))\n        SVM3AccTest.append(accuracy_score(y_test, y_test_pred))\n        SVM3Precision.append(precision_score(y_test, y_test_pred))\n        SVM3Recall.append(recall_score(y_test, y_test_pred))\n        \n    SVM3MeanAccTrainList.append(np.mean(SVM3AccTrain))\n    SVM3MeanAccTestList.append(np.mean(SVM3AccTest))\n    SVM3MeanPrecisionList.append(np.mean(SVM3Precision))\n    SVM3MeanRecallList.append(np.mean(SVM3Recall))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bestAccIndex = SVM3MeanAccTestList.index(max(SVM3MeanAccTestList))\nprint ('''\n             Statistics for SVM3\n        \\n bestSVM3AccTrainAvg = {}\n        \\n bestSVM3AccTestAvg = {}\n        \\n bestSVM3PrecisionAvg = {}\n        \\n bestSVM3RecallAvg = {}\n        \\n\n        \\n bestCParameter = {}\n        '''.format(\n        SVM3MeanAccTrainList[bestAccIndex],\n        SVM3MeanAccTestList[bestAccIndex],\n        SVM3MeanPrecisionList[bestAccIndex],\n        SVM3MeanRecallList[bestAccIndex],\n        CList[bestAccIndex] #index of CList and SVM3MeanAccTestList corresponds\n        ))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"########## Plot grapth of average test accuracy over tree depth \nfig = plt.figure()\nplt.title(\"Average test accuracy with different regularization C\")\nplt.xlabel(\"value of regularization C\")\nplt.ylabel(\"average test accuracy\")\nplt.xscale('log')\nplt.plot(CList, SVM3MeanAccTestList)\n\nnow = datetime.now()\ndt_string = now.strftime(\"%d-%m-%Y-%H:%M:%S\")\nplt.savefig('avgTestAccSVM3Norm_{}'.format(dt_string), format='png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In SVM3, the C parameter is varied from 1e-50 to 1e50. After plotting and comparing the resulting average test accuracy over 20 trials, it is concluded that SVM3 works best with a relatively small C parameter of 0.01, which means that it is a soft margin classifier."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}