{"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Cuss words! \nSohier, who posted this dataset, mentioned that there was some profanity in these data. When I read that, I couldn't help but wonder just how much profanity there was...\n<br><br>\n\nLet's find out.\n<br><br>\n\n![Shit fuck damn!][1]\n\n\n  [1]: http://static.fjcdn.com/gifs/Shit_2dde75_715622.gif","metadata":{"_execution_state":"idle","_uuid":"3246894adc57cd39dbbbcb114adfb0a36b0da1ea","_cell_guid":"d205fc69-ae14-4bf7-a7a3-8e8d1644f6e6"}},{"cell_type":"code","source":"# import import import I love import\nimport numpy as np\nimport pandas as pd\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_execution_state":"idle","_uuid":"557c3479b3d1e71cbf41cb1e479eab960a266166","_cell_guid":"4d645596-de2d-4a16-ae10-67716896ff16","collapsed":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Read in CSV to dataframe\ndf = pd.read_csv('../input/hacker_news_sample.csv')","metadata":{"_execution_state":"idle","_uuid":"11bd53448571ea74c16b6f95ce9f2f20dd2b3f47","_cell_guid":"086e3b27-015e-43bf-a58b-4b4c1bcfdd0a","collapsed":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Examine the fields\ndf.columns","metadata":{"_execution_state":"idle","_uuid":"9ed05dcabd948030ec194548f78e8747c5e8c4e0","_cell_guid":"e4a53da8-82ea-4483-bacd-e349d227b241"},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"We need to find all the text that contains cuss words. These are my three favorite cuss words: shit, fuck, damn, so we'll be searching for those. Anything more would be uncivilized. To do that, I'll need to search each row's \"text\" field for those cuss words and also keep track of the authors and the number of their posts which contain such nasty words.","metadata":{"_execution_state":"idle","_uuid":"e98c93dfd851d27a40f69255d777006cba221664","_cell_guid":"e7637382-1f1b-4fdf-a614-e3460318615c"}},{"cell_type":"code","source":"# Use regex to get the posts with cuss words\nnum = len(df[\"text\"])\ncuss_post = 0\nauthors = {}\nfor i in range(0,num):\n    has_cuss = re.search(r\"shit|fuck|damn\", str(df[\"text\"][i]))\n    if has_cuss:\n        cuss_post += 1\n        author = str(df[\"by\"][i])\n        if author in authors.keys():\n            authors[author] += 1\n        else:\n            authors[author] = 1","metadata":{"_execution_state":"idle","_uuid":"75d00f2e74c0952d63b0411c8bcbe79d3abc999c","_cell_guid":"634870a0-2065-4e84-8005-b552d65db1b9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Out of\", num, \"posts,\", cuss_post, \"posts have cuss words\", '(' + str(round(cuss_post/num*100, 2)) + '%)')","metadata":{"_execution_state":"idle","_uuid":"f4bcd46baa78d27da635173c7b06cb35b0c3e9fd","_cell_guid":"49290963-f760-45c0-91e3-5dba726980fe","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dff = pd.DataFrame.from_dict(authors, orient=\"index\").reset_index()\ndff.columns=['authors', 'num_posts']\ndff.head(20)","metadata":{"_execution_state":"idle","_uuid":"af0434f8dc5ddd893745508670ba0916020d9105","_cell_guid":"83dd9d3d-909b-453e-9b74-5c3794f825f9","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This looks good. We're seeing some good cussing going on.  Now let's take a look at the top 10 cussers. Who has the most cuss-containing posts on Hacker News?","metadata":{"_execution_state":"idle","_uuid":"774c850ffd06d0362c71ec9b11742b49a5f91e6b","_cell_guid":"9c80391d-2e32-4b0e-b8f1-c60f996aa7ae"}},{"cell_type":"code","source":"dff.loc[dff[\"num_posts\"].max()]\ndata = dff.sort_values(\"num_posts\", ascending=False).head(10)\ndata","metadata":{"_execution_state":"idle","_uuid":"f592b43923e7da65987b62f4c77f5c179029b542","_cell_guid":"b1447b15-d6f7-4975-ba85-b57427cc0902","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"viz = sns.barplot(y=data.authors, x=data.num_posts, orient=\"h\", palette=\"Set1\")\nviz.set(xlabel=\"Number of posts with cuss words\", ylabel=\"Author\")\nplt.show()","metadata":{"_execution_state":"idle","_uuid":"2404d30eea92ebbe4e1e73afbeb0cc737e3a7749","_cell_guid":"7e66291f-28ae-4610-ac4b-75bf16764d18","scrolled":true,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Evidently, **michaelochurch** has quite the potty mouth with over 300 posts to Hacker News containing cuss words. Well done!  ","metadata":{"_uuid":"fa06e22f9809979366e0dff2c0da119337d3bf65","_cell_guid":"eaea889c-1c3f-445b-8ff1-88637e917de0"}},{"cell_type":"markdown","source":"# Part 2:\n\nFrom the comments, Matt wonders \"How would the results change if it looked at the number of cuss words per post?\"\n<br><br>\nLets do a little more work and actually keep track of the cuss words in each post","metadata":{"_uuid":"c657f559071a61e0a8c7ce4e64715d43e5ec48e4","_cell_guid":"146856c3-d61b-4efb-b95d-201eaf3a5eac"}},{"cell_type":"code","source":"cuss_list = [\"shit\", \"shitter\", \"fuck\", \"fucked\", \"fucking\", \"fucker\", \"damn\", \"damnit\", \"ass\", \"asshole\"]\n\ndf_cuss = pd.DataFrame({\"by\": df.by, \"text\": df.text})\ndf_cuss.head()","metadata":{"_uuid":"6a51d9ca1a26fd8d671ae73d6c984498544a7e19","_cell_guid":"73e57271-9cdf-492d-b188-2cc92cfe0e49","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Adding a new column,  a count of the cuss words in each post","metadata":{"_uuid":"1153455cc30cceb0f21b3c74bef45efbb077bfc1","_cell_guid":"b061f38a-6e24-4f25-bd0a-08f736a8cb3a"}},{"cell_type":"code","source":"# This method isn't perfect. I should change this to use regex instead \ndef count_cusses(text):\n    cuss_list = [\"shit\", \"shitter\", \"fuck\", \"fucked\", \"fucking\", \"fucker\", \"damn\", \"damnit\", \"ass\", \"asshole\"]\n    text = str(text)\n    count = 0\n    for word in text.split(\" \"):\n        if word in cuss_list:\n            count += 1\n    return count\n\n# Count the cusses in each post\ndf_cuss[\"total_cusses\"] = df_cuss.text.apply(count_cusses)\n\n# Only want posts with cuss words\ndf_cuss = df_cuss[df_cuss.total_cusses > 0]","metadata":{"_uuid":"5b1303e0b1c7da076c800fedab5e88a8a5777001","_cell_guid":"7631eadd-1d38-484f-8a3d-8d518a1938db","scrolled":false,"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Authors with the most cusses total\ndf_cuss.groupby(\"by\").sum().sort_values(\"total_cusses\", ascending=False)[:20]","metadata":{"_uuid":"a1e529045de33d932803761959a34ffcd6611b47","_cell_guid":"9efbb81e-38fe-4dfe-8093-eb54a7b8af43","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Top 20 posts with the most cusses\ndf_cuss.sort_values(\"total_cusses\", ascending=False)[:20]","metadata":{"_uuid":"5508d854a1dc53ab5c3d3b54a1bbff36afaab04c","_cell_guid":"3a940989-1c8d-4382-a57d-227fbba7c419","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Top 20 posts with the most cusses per word\ndef cusses_per_word(text):\n    text = str(text)\n    words_in_text = len(text.split(\" \"))\n    num_cusses = count_cusses(text)\n    return (num_cusses/words_in_text)\n\ndf_cuss[\"cusses_per_word\"] = df_cuss.text.apply(cusses_per_word)\n\ndf_cuss.sort_values(\"cusses_per_word\", ascending=False)[:20]","metadata":{"_uuid":"7fcd40818956bb800975b5ef4aa211c689c69377","_cell_guid":"66adb1fe-c261-4d06-b9ed-a76c8ef64d41","collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To do list:\n* Change count_cusses() to use regex instead of looking for matches in cuss_list\n* Get each authors average cuss/word ratio, show top 20","metadata":{"_uuid":"044342a44b074626396829ffe918a2b0e07f22a9","_cell_guid":"a58a80b4-9969-45a5-afae-f7eace40fc69"}}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3","version":"3.6.3","nbconvert_exporter":"python","name":"python","mimetype":"text/x-python"}},"nbformat_minor":1}