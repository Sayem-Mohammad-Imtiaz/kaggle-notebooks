{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Irish Weather Data analysis","metadata":{}},{"cell_type":"markdown","source":"Exploratory Data Analysis (EDA) will be used to help provide initial discoveries about the key aspects of the dataset\n\nTasks\n* Preview the data\n* Variable types\n* Summary stats\n* Missing value and outliers\n* Visualisations","metadata":{}},{"cell_type":"markdown","source":"## 1. Pre-processing","metadata":{}},{"cell_type":"code","source":"# Import packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport sys\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T15:26:24.188687Z","iopub.execute_input":"2021-05-26T15:26:24.189121Z","iopub.status.idle":"2021-05-26T15:26:25.001129Z","shell.execute_reply.started":"2021-05-26T15:26:24.189028Z","shell.execute_reply":"2021-05-26T15:26:25.000102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review the files in the folder\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        # With only one file we can create the variable containing the file path\n        input_data = str(os.path.join(dirname, filename))\n        print(input_data)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:26:28.194141Z","iopub.execute_input":"2021-05-26T15:26:28.194499Z","iopub.status.idle":"2021-05-26T15:26:28.20918Z","shell.execute_reply.started":"2021-05-26T15:26:28.194464Z","shell.execute_reply":"2021-05-26T15:26:28.208196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/irish-weather-hourly-data/hrly_Irish_weather.csv', parse_dates=['date'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:31:52.360294Z","iopub.execute_input":"2021-05-26T15:31:52.361022Z","iopub.status.idle":"2021-05-26T15:40:07.837061Z","shell.execute_reply.started":"2021-05-26T15:31:52.360972Z","shell.execute_reply":"2021-05-26T15:40:07.836044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:42:45.571783Z","iopub.execute_input":"2021-05-26T15:42:45.572123Z","iopub.status.idle":"2021-05-26T15:42:45.590937Z","shell.execute_reply.started":"2021-05-26T15:42:45.572095Z","shell.execute_reply":"2021-05-26T15:42:45.590162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review a random sample of records from the dataframe. The n value inside the parenthesis represents the number of records to review\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:43:19.672125Z","iopub.execute_input":"2021-05-26T15:43:19.672526Z","iopub.status.idle":"2021-05-26T15:43:19.888085Z","shell.execute_reply.started":"2021-05-26T15:43:19.672492Z","shell.execute_reply":"2021-05-26T15:43:19.887338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the dataframe\nprint(df.shape)\n# Find the number of rows within a dataframe\nprint(len(df))\n# Extracting information from the shape tuple\nprint(f'Number of rows: {df.shape[0]} \\nNumber of columns: {df.shape[1]}')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:43:22.434457Z","iopub.execute_input":"2021-05-26T15:43:22.436085Z","iopub.status.idle":"2021-05-26T15:43:22.44303Z","shell.execute_reply.started":"2021-05-26T15:43:22.436035Z","shell.execute_reply":"2021-05-26T15:43:22.441884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1b. Variable types","metadata":{}},{"cell_type":"markdown","source":"Aiming to understand if any datatype conversion is required to ensure that variables are in the correct format for further data analysis","metadata":{}},{"cell_type":"code","source":"# Gain high level view of the datatypes for each variable\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:43:25.114678Z","iopub.execute_input":"2021-05-26T15:43:25.115049Z","iopub.status.idle":"2021-05-26T15:43:25.123697Z","shell.execute_reply.started":"2021-05-26T15:43:25.115018Z","shell.execute_reply":"2021-05-26T15:43:25.122745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Information about the dataframe. The memory_usage parameter provides a more in-depth review of the size of the dataframe\ndf.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:43:27.828877Z","iopub.execute_input":"2021-05-26T15:43:27.829214Z","iopub.status.idle":"2021-05-26T15:43:39.522677Z","shell.execute_reply.started":"2021-05-26T15:43:27.829186Z","shell.execute_reply":"2021-05-26T15:43:39.521668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review memory usage by variable\ndf.memory_usage(deep='True')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:43:45.54229Z","iopub.execute_input":"2021-05-26T15:43:45.542651Z","iopub.status.idle":"2021-05-26T15:43:57.241602Z","shell.execute_reply.started":"2021-05-26T15:43:45.542618Z","shell.execute_reply":"2021-05-26T15:43:57.240733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As object variables consume the most memory, converting to an appropriate data type can really help with processing as the overall memory footprint is reduced. By default pandas will set variables with mixed datatypes to an object value. In this case mixed data types can contain string, date, integer or float values. If we understand what elements make up the variable, then data type conversions to the appropriate numeric or categorical type can take place. ","metadata":{}},{"cell_type":"markdown","source":"##### Categorical","metadata":{}},{"cell_type":"markdown","source":"From the dataframe summary we can see that the first two variables are categorical. Therefore understanding the cardinality (number of unique segments) of the variable can help to understand if a data type conversion makes sense.","metadata":{}},{"cell_type":"code","source":"# Review the first few categorical variables\ncat_list = ['county', 'station']\ndf.groupby('county')['county'].count()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:44:01.972222Z","iopub.execute_input":"2021-05-26T15:44:01.972579Z","iopub.status.idle":"2021-05-26T15:44:02.725039Z","shell.execute_reply.started":"2021-05-26T15:44:01.972551Z","shell.execute_reply":"2021-05-26T15:44:02.72406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count for the station\ndf.groupby('station')['station'].count()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:44:04.823072Z","iopub.execute_input":"2021-05-26T15:44:04.823404Z","iopub.status.idle":"2021-05-26T15:44:05.626019Z","shell.execute_reply.started":"2021-05-26T15:44:04.823375Z","shell.execute_reply":"2021-05-26T15:44:05.625053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert both of these variables into category data types\n# Create a conversion dictionary to allow for easier maintenance\ncat_type = {'county':'category',\n            'station':'category'\n           }\ndf = df.astype(cat_type)\n# Review the new memory consumption\ndf[cat_list].memory_usage(deep='True')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:44:42.498634Z","iopub.execute_input":"2021-05-26T15:44:42.498994Z","iopub.status.idle":"2021-05-26T15:44:44.497977Z","shell.execute_reply.started":"2021-05-26T15:44:42.498965Z","shell.execute_reply":"2021-05-26T15:44:44.496948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirm that the data types have changed\ndf[cat_list].dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:44:46.697166Z","iopub.execute_input":"2021-05-26T15:44:46.697494Z","iopub.status.idle":"2021-05-26T15:44:46.707501Z","shell.execute_reply.started":"2021-05-26T15:44:46.697467Z","shell.execute_reply":"2021-05-26T15:44:46.706584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most efficient method to convert data types is to apply the changes within the data import step. For csv files that are being used as dataframes, the dtype= parameter of pd.read_csv() can be updated.","metadata":{}},{"cell_type":"markdown","source":"##### Numeric","metadata":{}},{"cell_type":"markdown","source":"There will be a number of choices for numeric variables. Applying floats for values with decimal places. Integers for whole numbers. Finally, converting a date variable from string to datetime.","metadata":{}},{"cell_type":"code","source":"df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:23:16.329894Z","iopub.execute_input":"2021-05-24T16:23:16.330324Z","iopub.status.idle":"2021-05-24T16:23:16.654188Z","shell.execute_reply.started":"2021-05-24T16:23:16.33028Z","shell.execute_reply":"2021-05-24T16:23:16.653132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert all values except the categorical variables into float values\n# Create two lists (1. Float, 2. Integers)\n# Errors emerged when applying blindly to all remaining variables. More investigations required\nfloat_vars = [i for i in df.columns[~df.columns.isin(['county','station','date','sun','vis','clht','clamt'])]]\n\nfloat_cols = ['latitude','longitude']\n\n# df[float_vars] = df[float_vars].apply(pd.to_numeric, downcast='float')\ndf[float_cols] = df[float_cols].apply(pd.to_numeric, downcast='float')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:44:55.106259Z","iopub.execute_input":"2021-05-26T15:44:55.106609Z","iopub.status.idle":"2021-05-26T15:44:55.167587Z","shell.execute_reply.started":"2021-05-26T15:44:55.106576Z","shell.execute_reply":"2021-05-26T15:44:55.166698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the date to date format\ndf['date'] = pd.to_datetime(df['date'], format='%d-%b-%Y %H:%M')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:44:58.444288Z","iopub.execute_input":"2021-05-26T15:44:58.444628Z","iopub.status.idle":"2021-05-26T15:44:58.476138Z","shell.execute_reply.started":"2021-05-26T15:44:58.4446Z","shell.execute_reply":"2021-05-26T15:44:58.475413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[float_cols].dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:45:00.468101Z","iopub.execute_input":"2021-05-26T15:45:00.468594Z","iopub.status.idle":"2021-05-26T15:45:00.499918Z","shell.execute_reply.started":"2021-05-26T15:45:00.468563Z","shell.execute_reply":"2021-05-26T15:45:00.499053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[float_cols].memory_usage(deep='True')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:45:02.192208Z","iopub.execute_input":"2021-05-26T15:45:02.192554Z","iopub.status.idle":"2021-05-26T15:45:02.209281Z","shell.execute_reply.started":"2021-05-26T15:45:02.192525Z","shell.execute_reply":"2021-05-26T15:45:02.208207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:45:04.060166Z","iopub.execute_input":"2021-05-26T15:45:04.060514Z","iopub.status.idle":"2021-05-26T15:45:14.287734Z","shell.execute_reply.started":"2021-05-26T15:45:04.060484Z","shell.execute_reply":"2021-05-26T15:45:14.286617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1c. Summary stats","metadata":{}},{"cell_type":"code","source":"# Review the high level summary details for each variable\ndf.describe(include=\"all\", datetime_is_numeric=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:45:25.488133Z","iopub.execute_input":"2021-05-26T15:45:25.488544Z","iopub.status.idle":"2021-05-26T15:45:40.347092Z","shell.execute_reply.started":"2021-05-26T15:45:25.488511Z","shell.execute_reply":"2021-05-26T15:45:40.346085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1d. Missing values and outliers","metadata":{}},{"cell_type":"code","source":"# Check for the missing values by columns\ndf.isnull().sum()\n\n# Proportion of missing values by column\ndef isnull_prop(df):\n    total_rows = df.shape[0]\n    missing_val_dict = {}\n    for col in df.columns:\n        missing_val_dict[col] = [df[col].isnull().sum(), (df[col].isnull().sum() / total_rows)]\n    return missing_val_dict\n\n# Apply the missing value method\nnull_dict = isnull_prop(df)\nprint(null_dict.items())","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:45:49.212427Z","iopub.execute_input":"2021-05-26T15:45:49.212787Z","iopub.status.idle":"2021-05-26T15:46:00.838335Z","shell.execute_reply.started":"2021-05-26T15:45:49.212754Z","shell.execute_reply":"2021-05-26T15:46:00.837304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display missing values using a heatmap to understand if any patterns are present\nsns.heatmap(df.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:46:05.589879Z","iopub.execute_input":"2021-05-26T15:46:05.590428Z","iopub.status.idle":"2021-05-26T15:47:20.43921Z","shell.execute_reply.started":"2021-05-26T15:46:05.590396Z","shell.execute_reply":"2021-05-26T15:47:20.437923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Appears to be certain stations are not collecting data for the final four variables.","metadata":{}},{"cell_type":"code","source":"df_miss = df.loc[(df['sun'].isnull()), ['county','station','date','sun']]\ndf_miss.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:08:30.687679Z","iopub.execute_input":"2021-05-26T16:08:30.688089Z","iopub.status.idle":"2021-05-26T16:08:31.433641Z","shell.execute_reply.started":"2021-05-26T16:08:30.688055Z","shell.execute_reply":"2021-05-26T16:08:31.432749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values by station\ndf_miss.groupby(['station'])['date'].count()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:11:02.926308Z","iopub.execute_input":"2021-05-26T16:11:02.926711Z","iopub.status.idle":"2021-05-26T16:11:02.958502Z","shell.execute_reply.started":"2021-05-26T16:11:02.92668Z","shell.execute_reply":"2021-05-26T16:11:02.957559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the index to date and check for missing values across time\ndf.index = df['date']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T15:57:27.118503Z","iopub.execute_input":"2021-05-26T15:57:27.118889Z","iopub.status.idle":"2021-05-26T15:57:27.145998Z","shell.execute_reply.started":"2021-05-26T15:57:27.118857Z","shell.execute_reply":"2021-05-26T15:57:27.144946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping of stations by county\ndf_g = df.groupby(['county','station']).size().unstack(level=0)\ndf_g","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:12:24.749592Z","iopub.execute_input":"2021-05-26T16:12:24.749972Z","iopub.status.idle":"2021-05-26T16:12:24.926836Z","shell.execute_reply.started":"2021-05-26T16:12:24.749934Z","shell.execute_reply":"2021-05-26T16:12:24.925825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Visualisations","metadata":{}},{"cell_type":"code","source":"# Unique list of values\ndf_unq_loc = df.drop_duplicates(subset=['station','county'])\ndf_unq_loc","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:22:54.628528Z","iopub.execute_input":"2021-05-26T16:22:54.628991Z","iopub.status.idle":"2021-05-26T16:22:54.851437Z","shell.execute_reply.started":"2021-05-26T16:22:54.628953Z","shell.execute_reply":"2021-05-26T16:22:54.850576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clustering on the listings\nimport folium\nfrom folium.plugins import FastMarkerCluster\n\nLat = 53.390862\nLong = -6.158100\n\nlocations = list(zip(df_unq_loc.latitude, df_unq_loc.longitude))\n\nmap1 = folium.Map(location=[Lat,Long], zoom_start=7)\n# FastMarkerCluster(data=locations).add_to(map1)\n# map1\n\n# add marker one by one on the map\nfor i in range(0,len(df_unq_loc)):\n    folium.Marker(\n        location=[df_unq_loc.iloc[i]['latitude'], df_unq_loc.iloc[i]['longitude']],\n        popup=df_unq_loc.iloc[i]['station']+',\\n'+df_unq_loc.iloc[i]['county'],\n    ).add_to(map1)\nmap1","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:49:41.192548Z","iopub.execute_input":"2021-05-26T16:49:41.192951Z","iopub.status.idle":"2021-05-26T16:49:41.306505Z","shell.execute_reply.started":"2021-05-26T16:49:41.192915Z","shell.execute_reply":"2021-05-26T16:49:41.305241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the temperatures to the graph to understand differences\ndf['temp'] = pd.to_numeric(df['temp'], errors='coerce')\ndf_s = df.groupby(['station'])['temp'].agg(['min','mean','max'])\ndf_s","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:49:17.071248Z","iopub.execute_input":"2021-05-26T16:49:17.07183Z","iopub.status.idle":"2021-05-26T16:49:17.172828Z","shell.execute_reply.started":"2021-05-26T16:49:17.071775Z","shell.execute_reply":"2021-05-26T16:49:17.171716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge the unique locations and temperatures\ndf_s = df_s.reset_index()\ndf_unq_temp = pd.merge(df_unq_loc.loc[:,['station','county','latitude','longitude']],\n                       df_s,\n                       how='left',\n                       on=['station']\n                      )\ndf_unq_temp","metadata":{"execution":{"iopub.status.busy":"2021-05-26T16:53:42.292446Z","iopub.execute_input":"2021-05-26T16:53:42.292995Z","iopub.status.idle":"2021-05-26T16:53:42.332242Z","shell.execute_reply.started":"2021-05-26T16:53:42.292959Z","shell.execute_reply":"2021-05-26T16:53:42.331394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add more details to the output\n# Use the temperature to display difference in average temperatures\ndef colour_temp(temp):\n    if temp < 9:\n        return \"purple\"\n    elif temp < 10:\n        return \"blue\"\n    elif temp < 11:\n        return \"green\"\n    else:\n        return \"red\"\n\nLat = 53.390862\nLong = -6.158100\n\nlocations = list(zip(df_unq_temp.latitude, df_unq_temp.longitude))\n\nmap2 = folium.Map(location=[Lat,Long], zoom_start=7)\n\n# Add Details to the markers\nfor i in range(len(locations)):\n    folium.Marker(locations[i]\n                  ,popup=df_unq_temp.iloc[i]['station']+',\\n'+df_unq_temp.iloc[i]['county']+' '+str(df_unq_temp.iloc[i]['mean'])\n                  ,icon=folium.Icon(color=colour_temp(df_unq_temp.iloc[i]['mean']))\n                 ).add_to(map2)\nmap2","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:00:49.715282Z","iopub.execute_input":"2021-05-26T17:00:49.715696Z","iopub.status.idle":"2021-05-26T17:00:49.837083Z","shell.execute_reply.started":"2021-05-26T17:00:49.715658Z","shell.execute_reply":"2021-05-26T17:00:49.836003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}