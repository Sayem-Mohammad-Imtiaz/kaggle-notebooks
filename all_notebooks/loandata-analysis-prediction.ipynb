{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Banking - Loan Payment Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Are people going to pay the money back? Lets See!\n\n<img align=\"Centre\" src=\"https://images.unsplash.com/photo-1580722434936-3d175913fbdc?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=500&q=60\" width=\"600px\"> <br />\n\nPhoto Credits: Jules Bss on Unsplash","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br>The current data set includes details of the 500 people who have opted for loan. Also, the data mentions whether the person has paid back the loan or not and if paid, in how many days they have paid.\nIn this project, we will try to draw few insights on sample Loan data.\n\n<br>Please find the details of dataset below which can help to understand the features in it.\n\n<br>Loan_id : A unique loan (ID) assigned to each loan customers- system generated\n<br>Loan_status : Tell us if a loan is paid off, in collection process - customer is yet to payoff, or paid off after the collection efforts\n<br>Principal : Principal loan amount at the case origination OR Amount of Loan Applied\n<br>terms : Schedule(time period to repay)\n<br>Effective_date : When the loan got originated (started)\n<br>Due_date : Due date by which loan should be paid off\n<br>Paidoff_time : Actual time when loan was paid off , null means yet to be paid\n<br>Past_due_days : How many days a loan has past due date\n<br>Age : Age of customer\n<br>Education : Education level of customer applied for loan\n<br>Gender : Customer Gender (Male/Female)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Libraries used in the project\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly_express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the input dataset \ndata = pd.read_csv('../input/loandata/Loan payments data.csv')\n\n# pd.options.display.max_columns = None\n# pd.options.display.max_rows = None\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checkpoint 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spelling Correction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Changed the name of a value in 'education' column from 'Bechalor' to 'Bachelor'\ndf['education']= df['education'].replace('Bechalor','Bachelor')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling Missing Values / Data Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the number of missing values in each columns\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Temporarily Filling the empty values in 'past_due_days' as '0'\ndf['past_due_days'] = df['past_due_days'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filling the empty values in 'paid_off_time' as '-1'\ndf['paid_off_time'] = df['paid_off_time'].fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the number of missing values in each columns\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of unique values in each column\nfor cat in data.columns:\n    print(\"Number of levels in category '{0}': \\b  {1:2.0f} \".format(cat, df[cat].unique().size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Coverting the following columns to 'datetime'\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf['due_date'] = pd.to_datetime(df['due_date'])\ndf['paid_off_time'] = pd.to_datetime(df['paid_off_time']).dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To Convert the 'paid_off_time' column to datetime64 type\ndf['paid_off_time'] = pd.to_datetime(df['paid_off_time'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CheckPoint 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Replacing values in past_due_days column for PAIDOFF class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(df_fe[df_fe['loan_status']==\"PAIDOFF\"])):\n    df_fe['past_due_days'][i] = (df_fe['paid_off_time'][i] - df_fe['effective_date'][i] + pd.Timedelta(days=1)).days - df_fe['terms'][i]\ndf_fe.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Records where the difference in the paid_off_time and effective_date is greater than the terms\ndf_fe[(df_fe['past_due_days']>0)&(df_fe['loan_status']=='PAIDOFF')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loan Status Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"a = df_fe['loan_status'].value_counts()\npd.DataFrame(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(df_fe['loan_status'].value_counts(),labels=df_fe['loan_status'].unique(),explode=[0,0.1,0],startangle=144,autopct='%1.f%%')\nplt.title('Loan Status Distribution',fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*<b>**20%**</b> of the people have <b>**not repaid**</b> the loan <b>**(COLLECTION)**</b><br>\n*<b>**20%**</b> of the people have <b>**repaid**</b> the loan but <b>lately</b> after due date <b>**(COLLECTION_PAIDOFF)**</b><br>\n*<b>**60%**</b> of the people have <b>**repaid**</b> the loan <b>**on time**</b> <b>**(PAIDOFF)**</b><br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Gender Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"b= df_fe['Gender'].value_counts()\npd.DataFrame(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = df_fe.groupby(['Gender'])['loan_status'].value_counts()\npd.DataFrame(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['Gender'],hue=df_fe['loan_status'])\nplt.legend(loc='upper right')\nplt.title('Gender vs Loan Status',fontsize=20)\nplt.xlabel('Gender', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*Around <b>40%</b> of <b>male</b> population have <b>repaid</b> their loan <b>lately (or yet to pay)</b> <br>\n*Around <b>30%</b> of <b>female</b> population have <b>repaid</b> their loan <b>lately (or yet to pay)</b> <br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Education Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"d = df_fe['education'].value_counts()\npd.DataFrame(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['education'],hue=df_fe['loan_status'])\nplt.legend(loc='upper right')\nplt.title('Education vs Loan Status',fontsize=20)\nplt.xlabel('Education', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* <b>Majority</b> of the loan takers are from <b>High School</b> or <b>College</b> background<br>\n* <b>Very few</b> people from <b>Masters or above</b> background took loan.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Age Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df_fe['loan_status'].unique():\n    agemean=df_fe[df_fe['loan_status']==i]['age'].mean()\n    agemode=df_fe[df_fe['loan_status']==i]['age'].mode()\n    print(\"average age of people whose loan status is'{0}': \\b {1:2.2f} and mode is {2}\".format(i,agemean, agemode[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = [14,5])\nsns.countplot(df_fe['age'],hue=df_fe['loan_status'])\nplt.legend(loc='upper left')\nplt.title('Age vs Loan Status',fontsize=20)\nplt.xlabel('Age', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n* <b>Majority</b> of the people who took loan have <b>age</b> ranging from <b>24 years</b> to <b>38 years</b><br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Principal Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"e = df_fe['Principal'].value_counts()\npd.DataFrame(e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['Principal'],hue=df_fe['loan_status'])\nplt.legend(loc='upper left')\nplt.title('Principal vs Loan Status',fontsize=20)\nplt.xlabel('Principal', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*<b>Majority</b> of the people have opted for <b>Principal</b> of $\\$800$ and $\\$1000$ <br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Term Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = [10,5])\nsns.countplot(df_fe['terms'],hue=df_fe['loan_status'])\nplt.legend(loc='upper left')\nplt.title('Terms vs Loan Status',fontsize=20)\nplt.xlabel('Terms', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*Only <b>few people</b> have opted loan for <b>7 days term</b> <br>\n*Majority of the <b>late payments</b> are from people who have their loan terms as <b>15 days</b> and <b>30 days</b> </b><br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loan Effective Date Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = df_fe.groupby(['effective_date'])['loan_status'].value_counts()\npd.DataFrame(g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = [10,5])\ndates = df_fe['effective_date'].dt.date\nsns.countplot(x=dates, hue=df_fe['loan_status'])\nplt.legend(loc='upper right')\nplt.title('Effective Date vs Loan Status',fontsize=20)\nplt.xlabel('Effective Date', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*On <b>11th and 12th September</b>, loan was given to <b>many people</b> maybe as part of a drive.<br>\n*Most of people who <b>paid latety(or yet to pay)</b> are from these <b>2 days</b>.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loan Status Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# specifies the parameters of our graphs\nfig = plt.figure(figsize=(18,8), dpi=1600)\nalpha_bar_chart = 0.55\n\n# lets us plot many diffrent shaped graphs together \nax1 = plt.subplot2grid((2,3),(0,0))\nsns.countplot(df_fe['loan_status'],hue=df_fe['education'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Education',fontsize=15)\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=14)\n\nplt.subplot2grid((2,3),(0,1),rowspan=2)\nplt.pie(df_fe['loan_status'].value_counts(),labels=df_fe['loan_status'].unique(),explode=[0,0.1,0],startangle=165,autopct='%1.f%%',)\nplt.grid(b=True, which='major', axis='y')\nplt.title(\"Loan Status Distribution\",fontsize=20)\n\nax3 = plt.subplot2grid((2,3),(0,2))\nsns.countplot(df_fe['loan_status'],hue=df_fe['terms'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Terms',fontsize=15)\nplt.xlabel(None)\nplt.ylabel('Count',fontsize=14)\n\nax4 = plt.subplot2grid((2,3),(1,0))\nsns.countplot(df_fe['loan_status'],hue=df_fe['Principal'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Principal',fontsize=15)\nplt.xlabel('Loan Status',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\nax5 = plt.subplot2grid((2,3),(1,2))\nsns.countplot(df_fe['loan_status'],hue=df_fe['Gender'])\nplt.legend(loc='upper right')\nplt.title('Loan Status vs Gender',fontsize=15)\nplt.xlabel('Loan Status',fontsize=14)\nplt.ylabel('Count',fontsize=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age vs Past Due Days","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(df_fe, x=\"age\", y=\"past_due_days\", size =\"terms\" ,color=\"loan_status\",\n           hover_data=['Gender','Principal'], log_x=True, size_max=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*Most of the <b>Elder people</b> (35 - 50 years) have paid back loan <b>on time.</b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loan Status vs Past Due Days","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relation between loan_status and past_due_days\n%matplotlib inline\nplt.figure(figsize = [9,5])\nsns.boxplot(x='loan_status', y='past_due_days', data=df_fe)\nplt.xlabel('Loan Status', fontsize=16)\nplt.ylabel('Past Due Days', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations:\n*We can infer that if people take <b>more than 25 days after due date</b>, they might end up in taking <b>even more time.</b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe = df_fe.drop(['Loan_ID','effective_date','due_date','paid_off_time'],axis = 1)\ndf_fe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = df_fe.groupby(['loan_status'])['Principal'].value_counts()\npd.DataFrame(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CheckPoint 3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe_Pri = df_fe.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe_Pri.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping Principal Values [300, 500, 700, 900] & 'terms' = 7 days","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe_Pri[df_fe_Pri['terms']==7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe_Pri[(df_fe_Pri['Principal']!=800) &(df_fe_Pri['Principal']!=1000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping rows where 'Principal' is not equal to 800 and 1000 [12 rows]\ndf_fe_Pri = df_fe_Pri[(df_fe_Pri['Principal']==800) | (df_fe_Pri['Principal']==1000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping rows where 'terms' = 7 days [21 rows]\ndf_fe_Pri = df_fe_Pri[df_fe_Pri['terms']!=7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe_Pri.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fe_Pri.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CheckPoint 4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df_fe_Pri.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def age_classification(age):\n    if age.item()<21:\n        return 'Young'\n    elif age.item()>=21 and age.item()<31:\n        return 'MidAge'\n    elif age.item()>=31 and age.item()<41:\n        return 'Senior'\n    else:\n        return 'Older'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorizing age column\ndf_clean['age'] = df_clean[['age']].apply(age_classification,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One hot encoding - 'terms', 'education', 'Principal', 'age' & 'Gender'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['terms'] = df_clean['terms'].astype('object')\ndf_clean['Principal'] = df_clean['Principal'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select the variables to be one-hot encoded\none_hot_features = ['education','Gender','Principal','age','terms']\n# Convert categorical variables into dummy/indicator variables (i.e. one-hot encoding).\none_hot_encoded = pd.get_dummies(df_clean[one_hot_features],drop_first=True)\none_hot_encoded.info(verbose=True, memory_usage=True, null_counts=True)\n# Convert Categorical to Numerical for default column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_encoded = pd.concat([df_clean,one_hot_encoded],axis=1)\ndf_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_encoded.drop(['terms','education','Gender','age','Principal'],axis=1,inplace = True)\ndf_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encoding - 'loan_status'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean['loan_status'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loan_status_dict = {'PAIDOFF':1,'COLLECTION':2,'COLLECTION_PAIDOFF':3}\ndf_encoded['loan_status'] = df_encoded.loan_status.map(loan_status_dict)\ndf_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CheckPoint 5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model = df_encoded.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation = df_model[df_model.columns].corr()\nplt.figure(figsize=(12, 10))\nplot = sns.heatmap(correlation, vmin = -1, vmax = 1,annot=True, annot_kws={\"size\": 10})\nplot.set_xticklabels(plot.get_xticklabels(), rotation=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split   #splitting data\n\n#Standardize rows into uniform scale\n\nX = df_model.drop(['loan_status','past_due_days'],axis=1)\ny = df_model['loan_status']\n\n# scaler = MinMaxScaler()#StandardScaler,MinMaxScaler\n# scaler.fit(X_Act)#df_model[cols_to_norm]\n\n# # Scale and center the data\n# fdf_normalized = scaler.fit_transform(X_Act)\n\n# # # Create a pandas DataFrame\n# fdf_normalized_df = pd.DataFrame(data=fdf_normalized, index=X_Act.index, columns=X_Act.columns)\n\n# X = fdf_normalized_df\n\n##Note: In this case, Scaling is not required\n\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=400,test_size=0.30,stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nprint(\"y : \",Counter(y))\nprint(\"y_train : \",Counter(y_train))\nprint(\"y_test : \",Counter(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual Values(of Majority Class) of y_test\ny_test.value_counts()\ny_test.value_counts().head(1) / len(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function To Run Different Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_train(model, name):\n    model.fit(X_train, y_train)                                          # Fitting the model\n    y_pred = model.predict(X_test)                                       # Making prediction from the trained model\n    cm = confusion_matrix(y_test, y_pred)                               \n    print(\"Grid Search Confusion Matrix \" +\" Validation Data\")                # Displaying the Confusion Matrix\n    print(cm)\n    print('-----------------------')\n    print('-----------------------')\n    cr = classification_report(y_test, y_pred)\n    print(name +\" Classification Report \" +\" Validation Data\")           # Displaying the Classification Report\n    print(cr)\n    print('------------------------')\n    print(name + \" Bias\")                                                 # Calculating bias\n    bias = y_pred - y_test.mean()\n    print(\"Bias \"+ str(bias.mean()))\n    \n    print(name + \" Variance\")                                             # Calculate Variance\n    var = np.var([y_test, y_pred], axis=0)\n    print(\"Variance \" + str(var.mean()) )\n#     return auc, rec, model\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's try to check the metrics with couple of models.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=1000,max_iter=500,class_weight='balanced')    # Set Large C value for low regularization to prevent overfitting\n# logreg.fit(X_train, y_train)\n\ndt_model = model_train(logreg, \"Logistic Regression\")\nprint('_________________________')\nprint(\"Coefficients: \",logreg.coef_)                                            # Coefficients for Logistic Regression\nprint(\"Intercepts: \",logreg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'gini',max_depth = 4, min_samples_leaf =2,random_state=101,class_weight='balanced')\n\ndt_model = model_train(dt, \"Decision Tree\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From the above results, we can observe that:\n<br>1.F1 Score using Logistic regression = 0.26\n<br>2.F1 Score using Decision Tree = 0.28\n\nThe results are low due to the <b>imbalance</b> in the class categories.\n\nLet's try to apply sampling methods to overcome this issue","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install imbalanced-learn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SMOTE - OverSampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us try some sampling technique to remove class imbalance\nfrom imblearn.over_sampling import SMOTE,KMeansSMOTE,SVMSMOTE\n#Over-sampling: SMOTE\n#SMOTE (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, \n#based on those that already exist. It works randomly picking a point from the minority class and computing \n#the k-nearest neighbors for this point.The synthetic points are added between the chosen point and its neighbors.\nsmote = KMeansSMOTE(sampling_strategy='auto')\n\nX_sm, y_sm = smote.fit_sample(X, y)\nprint(X_sm.shape, y_sm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_sm,y_sm,random_state=400,test_size=0.30,stratify = y_sm)#,stratify = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nprint(\"y : \",Counter(y))\nprint(\"y_train : \",Counter(y_train))\nprint(\"y_test : \",Counter(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Actual Values(of Majority Class) of y_test\ny_test.value_counts()\ny_test.value_counts().head(1) / len(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(C=1000,max_iter=500,class_weight='balanced')#solver ='lbfgs',class_weight='balanced'    # Set Large C value for low regularization to prevent overfitting\n# logreg.fit(X_train, y_train)\n\ndt_model = model_train(logreg, \"Logistic Regression\")\nprint('_________________________')\nprint(\"Coefficients: \",logreg.coef_)                                            # Coefficients for Logistic Regression\nprint(\"Intercepts: \",logreg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'gini',max_depth = 4, min_samples_leaf =2,random_state=101)\n\ndt_model = model_train(dt, \"Decision Tree\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Seach","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nrandom_grid = {'n_estimators': range(5,20),\n              'max_features' : ['auto', 'sqrt'],\n              'max_depth' : [10,20,30,40],\n              'min_samples_split':[2,5,10],\n              'min_samples_leaf':[1,2,4]}\n\nrf = RandomForestClassifier()\n\nrf_gs = GridSearchCV(rf, random_grid, cv = 3, n_jobs=1, verbose=2)\n\nrf_gs.fit(X_train, y_train)\ny_pred = rf_gs.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rf_gs.best_estimator_)\nprint('-----------------------')\nprint(\"Grid Search Validation Data\")\ncm = confusion_matrix(y_test, y_pred)                               \nprint(\"Grid Search Confusion Matrix \" +\" Validation Data\")                # Displaying the Confusion Matrix\nprint(cm)\nprint('-----------------------')\ncr = classification_report(y_test, y_pred)\nprint(\"Grid Search Classification Report \" +\" Validation Data\")           # Displaying the Classification Report\nprint(cr)\nprint('------------------------')\nprint(\"Grid Search Bias\")                                                 # Calculating bias\nbias = y_pred - y_test.mean()\nprint(\"Bias \"+ str(bias.mean()))\n    \nprint(\"Grid Search Variance\")                                             # Calculate Variance\nvar = np.var([y_test, y_pred], axis=0)\nprint(\"Variance \" + str(var.mean()) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Explainability","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Eli5 package\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# Find the importance of columns for prediction\nperm = PermutationImportance(dt, random_state=10).fit(X_test,dt.predict(X_test))\neli5.show_weights(perm, feature_names = X.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Conclusion**\n## From the Decision tree model, we have acheived an accuracy of 72% after applying SMOTE technique on the imbalanced target class.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Thank You**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}