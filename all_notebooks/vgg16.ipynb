{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2                 # working with, mainly resizing, images\nimport numpy as np         # dealing with arrays\nimport os                  # dealing with directories\nfrom random import shuffle # mixing up ordered data\nfrom tqdm import tqdm      # percentage bar for tasks.\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras,os\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trdata = ImageDataGenerator()\n\ntraindata = trdata.flow_from_directory(directory=\"../input/chest-xray-covid19-pneumonia/Data/train\",target_size=(224,224))\ntsdata = ImageDataGenerator()\ntestdata = tsdata.flow_from_directory(directory=\"../input/chest-xray-covid19-pneumonia/Data/test\", target_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=3, activation=\"softmax\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam,SGD\n#opt = Adam(lr=0.001)\nopt = SGD(learning_rate=0.001)\nmodel.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n\nhist = model.fit_generator(steps_per_epoch=20,generator=traindata, validation_data= testdata,epochs=50,callbacks=[checkpoint,early])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50 \nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n\n# create the base pre-trained model\nbase_model2 = ResNet50(weights=None, include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model2.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions2 = Dense(units=3, activation='softmax')(x)\n\n# this is the model we will train\nmodel2 = Model(inputs=base_model2.input, outputs=predictions2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD, Adam\n# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nadam = Adam(lr=0.0001)\nmodel2.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel2.summary()\n#model.fit(X_train, Y_train, epochs = 100, batch_size = 64)\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint = ModelCheckpoint('inception', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n\nhist2 = model2.fit_generator(steps_per_epoch=20,generator=traindata, validation_data= testdata,epochs=30,callbacks=[checkpoint,early])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n\n# create the base pre-trained model\nbase_model3 = InceptionV3(weights=None, include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model3.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions3 = Dense(units=3, activation='softmax')(x)\n\n# this is the model we will train\nmodel3 = Model(inputs=base_model3.input, outputs=predictions3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD, Adam\n# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nadam = Adam(lr=0.0001)\nmodel3.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel3.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint = ModelCheckpoint('inception', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n\nearly = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n\nhist3 = model3.fit_generator(steps_per_epoch=20,generator=traindata, validation_data= testdata,epochs=30,callbacks=[checkpoint,early])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\"])\nplt.show()\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title(\"model loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Loss\",\"Validation Loss\"])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(accu)\nplt.plot(hist2.history['accuracy'])\nplt.plot(hist3.history['accuracy'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"ResNet50\",\"InceptionV3\",\"VGG16\"])\nplt.show()\nplt.plot(loss)\nplt.plot(hist2.history['loss'])\nplt.plot(hist3.history['loss'])\nplt.title(\"model loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"ResNet50\",\"InceptionV3\",\"VGG16\"])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nimg = image.load_img(\"../input/chest-xray-covid19-pneumonia/Data/test/PNEUMONIA/PNEUMONIA(3421).jpg\",target_size=(224,224))\nimg = np.asarray(img)\nplt.imshow(img)\nimg = np.expand_dims(img, axis=0)\nfrom keras.models import load_model\n#saved_model = load_model(\"vgg16_1.h5\")\nmodel.save('covid_model.pkl')\noutput = model.predict(img)\nif output[0][0] > output[0][1] and output[0][0] > output[0][2]:\n    print(\"covid\")\nelif output[0][1]>output[0][2] and output[0][1]>output[0][2]:\n    print(\"Normal\")\nelse:\n    print(\"pneumonia\")\n    \nprint(output)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_generator(testdata, steps = np.ceil(testdata.samples / testdata.batch_size), verbose=1, workers=0)\ny_pred = np.argmax(predictions, axis=1)\nprint(y_pred)\npredictions1 = model2.predict_generator(testdata, steps = np.ceil(testdata.samples / testdata.batch_size), verbose=1, workers=0)\ny_pred1 = np.argmax(predictions, axis=1)\nprint(y_pred1)\npredictions2 = model3.predict_generator(testdata, steps = np.ceil(testdata.samples / testdata.batch_size), verbose=1, workers=0)\ny_pred2 = np.argmax(predictions, axis=1)\nprint(y_pred2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(testdata)\npred1=model2.predict(testdata)\npred2=model3.predict(testdata)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import metrics\ncmm =[]\ncm = metrics.confusion_matrix(testdata, pred)\ncmm.append(cm)\nprint(cmm)\nplt.imshow(cm, cmap=plt.cm.Blues)\nplt.xlabel(\"Predicted labels\")\nplt.ylabel(\"True labels\")\nplt.xticks([], [])\nplt.yticks([], [])\nplt.title('Confusion matrix ')\nplt.colorbar()\nplt.show()\ncm1 = metrics.confusion_matrix(testdata,pred1)\nplt.imshow(cm1, cmap=plt.cm.Blues)\nplt.xlabel(\"Predicted labels\")\nplt.ylabel(\"True labels\")\nplt.xticks([], [])\nplt.yticks([], [])\nplt.title('Confusion matrix ')\nplt.colorbar()\nplt.show()\ncm2 = metrics.confusion_matrix(testdata, pred2)\nplt.imshow(cm2, cmap=plt.cm.Blues)\nplt.xlabel(\"Predicted labels\")\nplt.ylabel(\"True labels\")\nplt.xticks([], [])\nplt.yticks([], [])\nplt.title('Confusion matrix ')\nplt.colorbar()\nplt.show()\n# or\n#cm = np.array([[1401,    0],[1112, 0]])\n\nprint(metrics.classification_report(testdata.classes, pred))\nprint(metrics.classification_report(testdata.classes, pred1))\nprint(metrics.classification_report(testdata.classes, pred2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(testdata.classes)\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"los = hist.history['loss']\nloss= []\nfor i in range(30):\n    loss.append(los[i])\n\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./covid_model.pkl/saved_model.pb')\n#FileLink(r'covid_model.joblib')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}