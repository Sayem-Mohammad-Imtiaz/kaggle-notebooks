{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Janatahack: Independence Day 2020 ML Hackathon\n## Topic Modeling for Research Articles","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Researchers have access to large online archives of scientific articles. As a consequence, finding relevant articles has become more difficult. Tagging or topic modelling provides a way to give token of identification to research articles which facilitates recommendation and search process.\n\nGiven the abstract and title for a set of research articles, predict the topics for each article included in the test set.\n\nNote that a research article can possibly have more than 1 topic. The research article abstracts and titles are sourced from the following 6 topics:\n\n1. Computer Science\n2. Physics\n3. Mathematics\n4. Statistics\n5. Quantitative Biology\n6. Quantitative Finance","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/train.csv')\ntest = pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/sample_submission_UVKGLZE.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are there any rows which have multiple topics?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = df.columns\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['No. of topics'] = (df['Computer Science'] + df['Physics'] + df['Mathematics'] + \n                       df['Statistics'] + df['Quantitative Biology'] + df['Quantitative Finance'])\n\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['No. of topics'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many research articles with multiple topics. This is an example of multi-label classification. I am handling this type of a problem for the first time. \n\nNLP and a multi-label classification.. This will be fun!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nresults = Counter()\ndf['ABSTRACT'].str.lower().str.split().apply(results.update)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_timers = []\n\nfor k,v in results.items():\n    if v == 1:\n        one_timers.append(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nnew_stopwords = ['based', 'paper', 'we', 'the', 'model', 'using', 'show', 'that' 'used', \n                 'use', '!', '$', '%', '&', ',', '.', 'we', 'method', 'problem', 'models']\nSTOPWORDS.update(new_stopwords)\nSTOPWORDS.update(one_timers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopwords(text):\n    from nltk.tokenize import word_tokenize\n\n    text_tokens = word_tokenize(text)\n\n    tokens_without_sw = [word for word in text_tokens if not word in STOPWORDS]\n    \n    filtered_sentence = (\" \").join(tokens_without_sw)\n\n    return filtered_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_clean(df):\n    df['text'] = df['TITLE'] + df['ABSTRACT']\n    df['text'] = df['text'].apply(remove_stopwords)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some visualisations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data = data_clean(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nresults = Counter()\ncleaned_data['text'].str.lower().str.split().apply(results.update)\ncounter_df = pd.DataFrame.from_dict(results, orient='index')\ncounter_df['Total'] = counter_df[0]\ncounter_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\n\n\nfor label in labels:\n    from collections import Counter\n    results = Counter()\n    cleaned_data[cleaned_data[label]==1]['text'].str.lower().str.split().apply(results.update)\n    temp_counter_df = pd.DataFrame.from_dict(results, orient='index')\n    temp_counter_df[label] = temp_counter_df[0]\n    counter_df = counter_df.merge(how='outer', left_index=True, right_index=True, right=temp_counter_df[label])\n\n    \ncounter_df.sort_values(by='Total', axis=0, ascending=False).head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nword_string=\" \".join(cleaned_data['text'].str.lower())\nwordcloud = WordCloud(stopwords=STOPWORDS).generate(word_string)\n\nplt.subplots(figsize=(15,15))\nplt.clf()\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\nfor label in labels:\n    print(label)\n    word_string=\" \".join(cleaned_data[cleaned_data[label]==1]['text'].str.lower())\n    wordcloud = WordCloud(stopwords=STOPWORDS).generate(word_string)\n\n    \n\n    plt.subplots(figsize=(15,15))\n    plt.title(label)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Six single label classification..\n\nThe initial approach I will use for this problem is to think of this as six single label classification. Will it work? Only one way to find out..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will combine Title and abstract into one column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['ID','TITLE', 'ABSTRACT']]\ny = df[['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']] \n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.33)\n\nsubmission = pd.DataFrame(X_test['ID'])\n\nX_train = data_clean(X_train)['text']\nX_test = data_clean(X_test)['text']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics\n\nlabels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\n\nfor label in labels:\n    \n    print(y_test[label].value_counts())\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n                         ('clf', LinearSVC(random_state=0)),\n    ])\n\n    text_clf.fit(X_train, y_train[label])  \n\n    predictions = text_clf.predict(X_test)\n\n    submission[label] = predictions\n\n    print('')\n    print(metrics.confusion_matrix(y_test[label],predictions))\n    print('')\n    print(metrics.classification_report(y_test[label],predictions))\n    print('')\n    print('')\n    print('')\n    print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['ID','TITLE', 'ABSTRACT']]\ny = df[['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']] \n\n\nsubmission = pd.DataFrame(test['ID'])\n#submission = test\n\nX = data_clean(X)['text']\ntest = data_clean(test)['text']\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics\n\nlabels = ['Computer Science', 'Physics', 'Mathematics','Statistics', \n          'Quantitative Biology', 'Quantitative Finance']\n\nfor label in labels:\n    \n    text_clf = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n                         ('clf', LinearSVC(random_state=0)),\n    ])\n\n    text_clf.fit(X, y[label])  \n\n    predictions = text_clf.predict(test)\n\n    submission[label] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'submission.csv'\nsubmission.to_csv(filename,index=False)\nprint('Saved file: ' + filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I know that there is a lot and I can improve on.. But time to move on now..","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}