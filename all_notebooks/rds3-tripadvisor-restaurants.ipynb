{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Предсказание рейтинга ресторана на сайте TripAdvisor\nЕсть сведения о 50 000 ресторанах Европы, взятые с сайта TripAdvisor\n\n**Цель**: самостоятельно очистить довольно сильно загрязнённый датасет, извлечь из него несколько новых признаков и подготовить данные для обучения модель.  Есть уже готовая модель, которая будет предсказывать рейтинг ресторана по данным сайта TripAdvisor на основе имеющихся в датасете данных.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# import","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#нашла датасет со столицами стран на kaggle, буду использовать для создания нового признака - является ли город столицей\ncapital = pd.read_csv('/kaggle/input/world-capitals-gps/concap.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#посмотрим на типы данных и количество пропусков\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,12))\nsns_heatmap = sns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Целевая переменная (Rating)** - без пропусков\n\n**Признаки без пропусков:**\n* Restaurant_id\n* City\n* Ranking\n* Reviews\n* URL_TA\n* ID_TA\n\n**Числовой формат данных:**\n* Ranking\n* Rating - *целевая переменная*\n* Number of Reviews\n\n**Данные в смешанном формате** (похоже на список,но по факту - строка, есть дата и т.д.)\n* Cuisine Style\n* Reviews","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Reviews[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and Prepping Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Обработка NAN \nУ наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \nПо этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# В датасете 3 признака с пропусками, по всем 3м вынесем отсутствие информации в отдельный признак\ndata['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')\ndata['Cuisine_Style_isNAN'] = pd.isna(data['Cuisine Style']).astype('uint8')\ndata['Price_Range_isNAN'] = pd.isna(data['Price Range']).astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of Reviews** - пробовала заполнять пропуски модой, медианой, средним и нулем, лучшее значение МАЕ при заполнении нулем. Предположительно, пропуски - это случаи, когда клиент не написал отзыв, только поставил оценку","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Number of Reviews'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Price Range** посмотрим на этот признак, какие он принимает значения и сколько пропусков","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].value_counts(dropna = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак ординальный (последовательный), нулем/средним заполнить не получится, заполним самым часто встречающимся значением, то есть средним ценовым диапазоном","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'] = data['Price Range'].fillna(data['Price Range'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cuisine Style** сложный признак, тип данных строка, а по факту это список. Заполним пропуски значением Other, позднее разберем на составляющие","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cuisine Style'] = data['Cuisine Style'].fillna(\"['Other']\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Обработка признаков\nДля начала посмотрим какие признаки у нас могут быть категориальными.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**интересное наблюдение** - Restaurant_id не уникальный признак и видимо не несет никакой ценной информации, удалим его","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Restaurant_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак Столица (бинарный) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#сделаем из колонки в найденном на kaggle датафрейме (сериз) - список, так удобнее искать\ncaplist = capital.CapitalName.to_list()\ncaplist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['is_capital'] = data.City.apply(lambda x: 1 if x in caplist else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак - кол-во ресторанов в городе","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"посмотрим, сколько ресторанов в каждом из 31 городе","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['City'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_in_city = data['City'].value_counts()\ndata['Rest_in_city'] = data['City'].apply(lambda x: rest_in_city[x])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак - Население в городе\nгородов всего 31 штука, на kaggle не нашла датасета с населением, пришлось воспользоваться википедией и гуглом","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"population = {\n    'London': 8173900,\n    'Paris': 2240621,\n    'Madrid': 3155360,\n    'Barcelona': 1593075,\n    'Berlin': 3326002,\n    'Milan': 1331586,\n    'Rome': 2870493,\n    'Prague': 1272690,\n    'Lisbon': 547733,\n    'Vienna': 1765649,\n    'Amsterdam': 825080,\n    'Brussels': 144784,\n    'Hamburg': 1718187,\n    'Munich': 1364920,\n    'Lyon': 496343,\n    'Stockholm': 1981263,\n    'Budapest': 1744665,\n    'Warsaw': 1720398,\n    'Dublin': 506211 ,\n    'Copenhagen': 1246611,\n    'Athens': 3168846,\n    'Edinburgh': 476100,\n    'Zurich': 402275,\n    'Oporto': 221800,\n    'Geneva': 196150,\n    'Krakow': 756183,\n    'Oslo': 673469,\n    'Helsinki': 574579,\n    'Bratislava': 413192,\n    'Luxembourg': 576249,\n    'Ljubljana': 277554\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Population'] = data['City'].map(population)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак - рестораннообеспеченность или кол-во ресторанов на человека","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Rest_per_man'] = data['Population'] / data['Rest_in_city']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак - Country\nгородов немного, создала словарь руками, сокращенные названия стран добавила отсюда\nhttps://www.acex.net/ru/useful_information/ISO_country_codes.php","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country = {\n    'London': 'GB',\n    'Paris': 'FR',\n    'Madrid': 'ES',\n    'Barcelona': 'ES',\n    'Berlin': 'DE',\n    'Milan': 'IT',\n    'Rome': 'IT',\n    'Prague': 'CZ',\n    'Lisbon': 'PT',\n    'Vienna': 'AT',\n    'Amsterdam': 'NL',\n    'Brussels': 'BE',\n    'Hamburg': 'DE',\n    'Munich': 'DE',\n    'Lyon': 'FR',\n    'Stockholm': 'SE',\n    'Budapest': 'HU',\n    'Warsaw': 'PL',\n    'Dublin': 'IE',\n    'Copenhagen': 'DK',\n    'Athens': 'GR',\n    'Edinburgh': 'GB',\n    'Zurich': 'CH',\n    'Oporto': 'PT',\n    'Geneva': 'CH',\n    'Krakow': 'PL',\n    'Oslo': 'NO',\n    'Helsinki': 'FI',\n    'Bratislava': 'SK',\n    'Luxembourg': 'LU',\n    'Ljubljana': 'SI'\n}\n\ndata['Country'] = data['City'].apply(lambda x: country[x])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"посмотрим, сколько получилось стран","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Country'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"и сколько ресторанов в каждой стране","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак - кол-во ресторанов в стране","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rest_in_country = data['Country'].value_counts()\ndata['Rest_in_country'] = data['Country'].apply(lambda x: rest_in_country[x])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак, точней 31 новый признак по городам","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\n#Add a column to indicate NaNs, if False NaNs are ignored.\ndata = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак, точней 22 новых признака по странам","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data, columns=[ 'Country',], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Возьмем следующий признак \"Price Range\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак (бинарный) - цены средние или нет\nдобавление признака ухудшило МАЕ, закомментируем его","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#data['Price Category'] = data['Price Range'].apply(lambda x: x!= '$$ - $$$') \n#data['Price Category'] = data['Price Category'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак, точней 3 признака для каждого диапазона цен","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**1й вариант - One hot encoding** Этот вариант ухудшил МАЕ, закомментируем его","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dummy_na=True убрала, так как уже все пропуски ранее заполнила\n#data = pd.get_dummies(data, columns=[ 'Price Range',])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2й вариант - LabelEncoding**\nМАЕ для второго вариант лучше","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ndata['Price Range_Cat'] = labelencoder.fit_transform(data['Price Range'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### рассмотрим следующий признак Reviews\nвнутри этот признак содержит дату отзывов, попробуем ее достать","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак - кол-во дней между отзывами","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#заполняем пропуски\ndata['Reviews'] = data['Reviews'].fillna(\"['no_Reviews']\")\n#создаем новую колонку и туда кладем только данные, ктр содержат дату\ndata['date_of_Review'] = data['Reviews'].str.findall('\\d+/\\d+/\\d+')\n#создаем новую колонку, ктр содержит разницу между значениями колонки date_of_Review и превращаем ее в дни\ndata['day_between_Reviews'] = data.apply(lambda x: pd.to_datetime(x['date_of_Review']).max() - pd.to_datetime(x['date_of_Review']).min(), axis = 1).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#проверяем, что получилось\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"не все отзывы содержат дату, поэтому незаполненные значения заполним нулем","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['day_between_Reviews'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Создадим новый признак - разница между отзывами больше/меньше год \nдобавление признака ухудшило МАЕ, закомментируем его","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#сравниваем сроки между отзывами с годом\n#data['Old']=data['day_between_Reviews'].apply(lambda x: float(x)>float(365)) \n#конвертируем буллево значение в 0/1\n#data['Old'] = data['Old'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак - кол-во прошедших дней с последнего отзыва","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['day_from_last_review'] = data.apply(lambda x: pd.datetime.now() - pd.to_datetime(x['date_of_Review']).max(), axis = 1).dt.days","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"проверяем, что получилось","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"и опять есть пропуски, заполним их нулем","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['day_from_last_review'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### рассмотрим следующий признак Cuisine Style ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"пропуски на other мы уже заменили, посмотрим, сколько всего разных кухонь, много ли уникальных значений","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#копируем датафрейм\ndata_copy = data.copy()\n#создаем новую колонку в копии датафрейма - в каждой строке новой колонки список из рассплитованных  значений\ndata_copy['Cuisine'] = data['Cuisine Style'].str.findall(r\"'(\\b.*?\\b)'\")\n# 'раздвигаем' исходный датасет, чтобы внутри признака было только одно значение вида кухни, а не список\ndata_copy = data_copy.explode('Cuisine')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_copy['Cuisine'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"уникальных значений (кухонь, ктр встречаются только в одном ресторане) не так уж и много, всего 4. Поэтому не будем выносить это в отдельный признак","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак - кол-во кухонь в одном ресторане","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Number_of_cuisines'] = data['Cuisine Style'].apply(lambda x: len(x.split(',')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"посчитаем среднее значение для кол-ва кухонь в одном ресторане","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aver_cuis = data['Cuisine Style'].apply(lambda x: len(x.split(','))).sum()/len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### создадим новый признак больше или меньше среднего значения кухонь в одном ресторане\nдобавление признака ухудшило МАЕ, закомментируем его","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#сравниваем кол-во кухонь в ресторане со средним значением\n#data['More/less_aver_cuis']=data['Number_of_cuisines'].apply(lambda x: x > aver_cuis) \n#конвертируем буллево значение в 0/1\n#data['More/less_aver_cuis'] = data['More/less_aver_cuis'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA \n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение признака Ranking","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['City'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим, как изменится распределение в большом городе:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Получаается, что признак Ranking несколько субъективен и зависит от количества ресторанов в городе, а много ресторанов именно в большом городе, потому что если ресторан занимает 10е место из 10000, то он отличный, а если 10е место из 20, то он может быть и средним, и вообще плохим, так как в в маленьком городе мало выбора.\n\nВведем параметр Comp_Ranking - сравнительный ранг = ранг / кол-во ресторанов в городе.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### добавим новый признак  - сравнительный ранг ресторана в городе","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Comp_Ranking'] = data['Ranking'] / data['Rest_in_city']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"сделаем аналогичный анализ, но уже по странам","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Country'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"посмотрим на распределение в стране с самым большим кол-вом ресторанов","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Ranking'][data['Country'] =='GB'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"есть перепад в самом начале","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на топ 10 стран\nfor x in (data['Country'].value_counts())[0:10].index:\n    data['Ranking'][data['Country'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Распределение по странам похоже на экспоненциальное, в качестве улучшения признаков можно попробовать прологарифмировать или извлечь корень из  Ranking по странам и если будет распределен нормально, то создать новый признак. Пока этого делать не будем, просто обозначим возможность улучшения модели","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной относительно признака","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Корреляция","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"перед тем, как вывести тепловую карту с корреляцией, удалим все категориальные признаки","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Cuisine Style', 'Price Range', 'Reviews', 'URL_TA', 'ID_TA', 'date_of_Review'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (25,20)\nsns.heatmap(data.drop(['sample'], axis=1).corr(),)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть сильно скоррелированные параметры, но поскольку модель у нас уже выбрана и это случайный лес, то удалять ничего не будем, так как для случайного леса мультиколлинеарность не проблема, как и не проблема распределение, не являющееся нормальным","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.round(y_pred*2)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = np.round(predict_submission*2)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}