{"cells":[{"metadata":{"_uuid":"6eadac32aa063422945860337d200c7e1639c54d"},"cell_type":"markdown","source":"# Kiva Crowdfunding - Targeting Poverty at a Sub-national Level\n***\n\nKiva is an online crowdfunding platform to extend financial services to poor and financially excluded people around the world. More information can be found at https://www.kiva.org/.\n\nThis notebook series is my contribution to the Data Science for Good: Kiva Crowdfunding challenge. The objective is to help Kiva to better understand their borrowers and build more localized models to estimate the poverty levels in the regions where Kiva has active loans.\n\nKive Crowdfunding notebook series:\n  - [Part I - Understanding Poverty]\n  - [Part II - Targeting Poverty at a National Level]\n  - [Part III - Targeting Poverty at a Subnational Level]\n\n[Part I - Understanding Poverty]: https://www.kaggle.com/taniaj/kiva-crowdfunding-understanding-poverty\n[Part II - Targeting Poverty at a National Level]: https://www.kaggle.com/taniaj/kiva-crowdfunding-targeting-poverty-national\n[Part III - Targeting Poverty at a Subnational Level]: https://www.kaggle.com/taniaj/kiva-crowdfunding-targeting-poverty-sub-nat\n\nThe series in broken down into three notebooks. The first notebook is an exploratory analysis of the data to get a feeling for what we are working with. The second notebook examines external datasets and looks at how MPI and other indicators can be used to get a better understanding of poverty levels of Kiva borrowers at a national level. The third notebook examines external data at a subnational level to see how Kiva can get a more accurate prediction of poverty level based on location.\n\nThis is the third notebook of the series, and probably the most relevant to directly addressing the Kiva challenge.\nThe notebook focuses on the Demographic and Health Surveys (DHS) dataset, which is the result of the DHS Program funded by the U.S. Agency for International Development (USAID). This is the only dataset that the author has found, that has extensive data at a very granular level across many countries. The dataset is used to reproduce the MPI at a more granular level than is currently available to Kiva (ie: more granualar than the Kiva sub_national data).\n\nThe problem of finding a better poverty estimate is approached in two ways. \nThe first is an attempt to reproduce the index by following the methodology used by the United Nations Development Program (UNDP) to build the MPI. Because we have raw data available at a very granular level, we can thus calculate MPI scores at, for example a county level, or any other even more granular groupings as required.\nThe second section (TBC) combines features which are not currently used as part of the UNDP MPI method to add other dimensions to the MPI and build an index which could be more useful to Kiva.\n\nNote: The code has been written with a focus on understandability rather than optimization, although optimization is also a secondary aim.\n\n### Contents\n   1. [Data Gathering](#data_gathering)\n   2. [Preprocessing](#preprocessing)\n   3. [Extrating MPI Features from DHS Data](#extracting_mpi_features)\n       * [Definition of MPI (UNDP)](#mpi_def)\n       * [Household Data](#household_data)\n       * [Household Member Data](#household_member_data)\n       * [Child Data](#child_data)\n   4. [Treatment of households with missing observations in at least one indicator](#missing_observations)\n   5. [Treatment of households with non-eligible population](#non_eligible_popluation)\n   6. [Calculating MPI with DHS Data](#calculating_mpi)\n       * [Kenya](#kenya)\n           * [Figure: UNDP Province (Sub-national) MPI - Kenya](#fig_undp_admin1_mpi_kenya)\n           * [Figure: Calculated Province (Sub-national) MPI - Kenya](#fig_calc_admin1_mpi_kenya)\n           * [Figure: Calculated Administration Level 1 (County) MPI - Kenya](#fig_calc_admin2_mpi_kenya)\n           * [Figure: Calculated Administration Level 2 MPI - Kenya](#fig_calc_admin3_mpi_kenya)\n   7. [Comparing Calculated MPI to UNDP MPI](#compare_dhs_undp_mpi)\n           * [Figure: Kiva Loans + Calculated County MPI - Kenya](#fig_loans_vs_calc_admin2_mpi_kenya)\n   8. [Scalability Testing](#scalability_testing)\n       * [Zimbabwe](#zimbabwe)\n           * [Figure: UNDP Province (Sub-national) MPI - Zimbabwe](#fig_undp_admin1_mpi_zimbabwe)\n           * [Figure: Calculated Province (Sub-national) MPI - Zimbabwe](#fig_calc_admin1_mpi_zimbabwe)\n           * [Figure: Calculated Administration Level 2 MPI - Zimbabwe](#fig_calc_admin2_mpi_zimbabwe)\n       * [Cambodia](#cambodia)\n           * [Figure: UNDP Province (Sub-national) MPI - Cambodia](#fig_undp_admin1_mpi_cambodia)\n           * [Figure: Calculated Province (Sub-national) MPI - Cambodia](#fig_calc_admin1_mpi_cambodia)\n           * [Figure: Calculated Administration Level 2 MPI - Cambodia](#fig_calc_admin2_mpi_cambodia)\n       * [Summary](#summary)\n   9.  [TO BE CONTINUED]() \n   10. [References](#references)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1ef726852827cfb535ca8cd137da7b53849f0bdf"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport seaborn as sns\nfrom scipy.stats.mstats import gmean\nimport math\n\n#from geopandas.tools import sjoin\nimport folium\nfrom folium.plugins import MarkerCluster\nfrom folium import IFrame\nimport shapely\nfrom shapely.geometry import Point, Polygon\nimport unicodedata\nimport pysal as ps\nimport geopandas as gpd\nfrom mpl_toolkits.basemap import Basemap\nimport geojson\n\n%matplotlib inline\n\nsns.set(rc={\"figure.figsize\": (20,10), \"axes.titlesize\" : 18, \"axes.labelsize\" : 12, \n            \"xtick.labelsize\" : 14, \"ytick.labelsize\" : 14 }, \n        palette=sns.color_palette(\"OrRd_d\", 20))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n!cp ../input/images/kenya_county_mpi_loans.png .","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"02b1feedee9d81d993459060c23c9e262dd23e2f"},"cell_type":"markdown","source":"## 1. Data Gathering <a class=\"anchor\" id=\"data_gathering\"/>\n***\n\nDescription to be Completed."},{"metadata":{"_uuid":"c6264ff5a4054951127c110bbe09c023310e15aa"},"cell_type":"markdown","source":"## 2. Preprocessing <a class=\"anchor\" id=\"preprocessing\"/>\n***\nEven the Kenya datasets alone were too large to upload as private datasets to Kaggle, so it was necessary to trim them down to the necessary data before uploading. "},{"metadata":{"collapsed":true,"trusted":true,"_kg_hide-input":true,"_uuid":"8006daf50ecb563e78fca8a98cd61a79f3ea9ffb"},"cell_type":"code","source":"def preprocess_dhs_data(country, household_file, househole_member_file, births_file, cluster_file):\n    # Load original DHS data \n    # The following error occurrs if we do not set convert_categoricals=False: ValueError: Categorical categories must be unique\n    household_dhs_df = pd.read_stata('../input/'+country+'-dhs-household/'+household_file, convert_categoricals=False)\n    household_member_dhs_df = pd.read_stata('../input/'+country+'-dhs-household-member/'+househole_member_file, convert_categoricals=False)\n    births_dhs_df = pd.read_stata('../input/'+country+'-dhs-births/'+births_file, convert_categoricals=False)\n    dhs_cluster_df = pd.read_csv('../input/'+country+'-dhs-cluster/'+cluster_file)\n\n    # Keep only relevant features from each dataset\n    household_dhs_df = household_dhs_df[['hv001', 'hv002', 'hv009', 'hv010',  'hv011',  'hv012',  'hv014',  \n                                         'hv024',  'hv025', 'hv027',\n                                         'hv206','hv201','hv204','hv205','hv225', 'hv226','hv213',\n                                         'hv207', 'hv208', 'hv243a', 'hv221',\n                                        'hv210', 'hv211', 'hv212', 'hv243c', 'hv243d',\n                                         'hv209', 'hv244', 'hv245', 'hv246', \n                                         'hv247']]\n    household_member_dhs_df = household_member_dhs_df[['hv001', 'hv002', 'hc31', 'hc70', 'hc73', 'hc2', 'hc3','ha1', \n                                                       'ha40', 'hv105', 'hv108', 'hv121']]\n    births_dhs_df = births_dhs_df[['v001', 'v002',  'b2', 'b3', 'b5', 'b7']]\n\n    # Save the resulting dataframes\n    household_dhs_df.to_csv(country+'_household_dhs.csv', index = False)\n    household_member_dhs_df.to_csv(country+'_household_member_dhs.csv', index = False)\n    births_dhs_df.to_csv(country+'_births_dhs.csv', index = False)\n\n    # DHS Cluster data preprocessing\n    # drop irrelevant columns\n    dhs_cluster_df.drop(columns=['GPS_Dataset', 'DHSCC', 'DHSYEAR', 'SurveyID'], inplace=True)\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='1985')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='1990')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='1995')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='2000')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='2005')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='UN_Population')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='SMOD')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='Slope')))]\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='Temperature')))]\n    dhs_cluster_df.to_csv(country+'_dhs_cluster.csv', index = False)\n\n# Uncomment the line below to run pre-processing of original DHS files\n#preprocess_dhs_data('kenya', 'KEHR71FL.DTA', 'KEPR71FL.DTA', 'KEBR71FL.DTA', 'KEGC71FL.csv')","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_kg_hide-input":true,"_uuid":"7c49dbeae0ea34600f4c96f1385f7a1c8297e762"},"cell_type":"code","source":"# States-Provinces shapefile\nstates_provinces_gdf = gpd.read_file('../input/world-geo-data/ne_10m_admin_1_states_provinces.shp')\n# Kiva subnational MPI dataset\nmpi_subnational_df = pd.read_csv('../input/kiva-mpi-subnational-with-coordinates/mpi_subnational_coords.csv')\n\n# This step is just to ensure we have matches where possible between the two datasets\n#from string import punctuation\nstates_provinces_gdf['name'] = states_provinces_gdf['name'].str.replace('-',' ')\nmpi_subnational_df['Sub-national region'] = mpi_subnational_df['Sub-national region'].str.replace('-',' ')","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_kg_hide-input":true,"_uuid":"d7366f8437a1a164dbdf2c916e1cfa6dd870e6dd"},"cell_type":"code","source":"def read_data(country, household_path, household_member_path, births_path, dhs_cluster_path, dhs_geo_path, \n              admin1_geo_path, admin2_geo_path):\n    global household_dhs_df\n    global household_member_dhs_df\n    global births_dhs_df\n    global dhs_cluster_df\n    global dhs_geo_gdf\n    global admin1_geo_gdf\n    global admin2_geo_gdf\n    \n    # Read in preprocessed DHS datasets\n    household_dhs_df = pd.read_csv(household_path)\n    household_member_dhs_df = pd.read_csv(household_member_path)\n    births_dhs_df = pd.read_csv(births_path)\n    dhs_cluster_df = pd.read_csv(dhs_cluster_path)\n    # DHS shapefile\n    dhs_geo_gdf = gpd.read_file(dhs_geo_path)\n\n    # Admin1 boundaries shapefile\n    admin1_geo_gdf = gpd.read_file(admin1_geo_path)\n\n    # Admin2 boundaries shapefile\n    admin2_geo_gdf = gpd.read_file(admin2_geo_path)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"37e2c224228340e98c7526d193a5a9aac845cbdd"},"cell_type":"markdown","source":"## 3. Extrating MPI Features from DHS Data <a class=\"anchor\" id=\"extracting_mpi_features\"/>\n***\nIn this section the DHS datasets are preprocessed in order to extract the features relevant to calculation a MPI according to the UNDP method, as well as other features which are deemed to be interesting for our problem."},{"metadata":{"_uuid":"8dd09d64de229a15196004e957ce02e645257eed"},"cell_type":"markdown","source":"### Definition of MPI (UNDP) <a class=\"anchor\" id=\"mpi_def\"/>\n***\n\nThe following are features included in the MPI as defined by the Human Development Report. http://dev-hdr.pantheonsite.io/sites/default/files/hdr2016_technical_notes_0.pdf\n\n\n**Definitions of poverty states**\n1. A household is considered **multidimensionally poor** (or MPI poor) if the total of weighted\ndeprivations (deprivation score) is equal to 1/3 or more.\n2. A household is considered **severely multidimensionally poor** if the deprivation score is 1/2 or\nmore.\n3. A household is considered **near-MPI poor** if the deprivation score is 1/5 or more but less than\n1/3.\n4. A household is considered **deprived but not near-MPI poor** if the deprivation score is positive\nbut less than 1/5.\n5. If a household is deprived, then all its members are deprived.\n6. Dimensions included in the MPI are education, health, and living standards; all are equally\nweighted by 1/3 each.\n\n**Education:**\n    - School attainment: no household member has completed at least six years of schooling.\n    - School attendance: a school-age child (up to grade 8) is not attending school.\n\n\n**Health:**\n    - Nutrition: a household member (for whom there is nutrition information) is malnourished, as measured by the body mass index for adults (women ages 15–49 in most of the surveys) and by the height-for-age z-score calculated based on World Health Organization standards for children under age 5.\n    - Child mortality: a child has died in the household within the five years prior to the survey.\n\n\n**Standard of living:**\n    - Electricity: not having access to electricity.\n    - Drinking water: not having access to clean drinking water or having access to clean drinking water through a source that is located 30 minutes away or more by walking.\n    - Sanitation: not having access to improved sanitation facilities or having access only to shared improved sanitation facilities.\n    - Cooking fuel: using “dirty” cooking fuel (dung, wood or charcoal).\n    - Having a home with dirt, sand or dung floor.\n    - Assets:\n        - not having at least one asset related to access to information (radio, television or telephone) or \n        - having at least one asset related to information but not having at least one asset related to mobility (bike, motorbike, car, truck, animal cart or motorboat) or\n        - at least one asset related to livelihood (refrigerator, arable land or livestock).\n        "},{"metadata":{"_uuid":"b3bc0078f5ef66b9129f54517d6837514b7d38cd"},"cell_type":"markdown","source":"### Household Data <a class=\"anchor\" id=\"household_data\"/>"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8266c50929d246317181ea45f6d381a2fa3e73a3"},"cell_type":"code","source":"# Determine drinking water deprivation given features hv201 and hv204\n# Drinking water: not having access to clean drinking water or having access to clean drinking water through a source that is\n# located 30 minutes away or more by walking\n# hv201 - source of drinking water\n# hv204 - time to water and back (in minutes) \n# *Slightly different logic used compared to undp calc but should work out the same\nclean_water_source = [10, 11, 12, 13, 20, 21, 30, 31, 41, 51, 71]\ndef determine_water_depriv(row):\n    if row.hv201 in clean_water_source:\n        if (row.hv204 != 996) & (row.hv204 >= 30):\n            return 1\n        else:\n            return 0\n    else:\n        return 1\n\n# Determine asset deprivation given information_asset, mobility_asset and livelihood_asset features\n# TODO: Is this logic correct? can it be simplified? \n# A household is not deprived in assets if it has at least one asset from group (1) and at least one asset from groups (2) or (3).\ndef determine_asset_depriv(row):\n    if row.information_asset == 0:\n        return 1\n    if (row.mobility_asset == 0) & (row.livelihood_asset == 0):\n        return 1\n    return 0\n    \ndef process_household_data(df):\n    # hv009 : total members in household, rename col\n    df.rename(columns={'hv009':'total_household_members'}, inplace=True)\n    # hv206 - electricity, map to electricity_depriv\n    df['electricity_depriv'] = np.where(df['hv206'] == 0, 1, 0)\n    # hv201, hv 204 - map to water_depriv\n    df['water_depriv'] = df.apply(determine_water_depriv, axis=1)\n    # Sanitation: not having access to improved sanitation facilities or having access only to shared improved sanitation facilities.\n    # hv05 - type of toilet facility\n    # hv25 - shared sanitation \n    # *Including 14, 15 as improved sanitation, undp calculation does not.\n    improved_sanitation =  [10, 11, 12, 13, 14, 15, 21, 22, 41]\n    df['sanitation_depriv'] = np.where((df.hv225 == 0) & (df['hv205'].isin(improved_sanitation)), 0, 1)\n    # Cooking fuel: using “dirty” cooking fuel (dung, wood or charcoal).\n    # hv26 - map to cooking_fuel_depriv\n    df['cooking_fuel_depriv'] = np.where(df['hv226'].isin([6, 7, 8, 9, 10, 11, 95, 96]), 1, 0)\n    # Having a home with dirt, sand or dung floor.\n    # hv213 - floor type, map to floor_depriv\n    df['floor_depriv'] = np.where(df['hv213'].isin([11, 12, 13, 96]), 1, 0)\n    \n    # Assets: not having at least one asset related to access to information (radio, television or telephone5) \n    # or having at least one asset related to information but not having at least one asset related to mobility (bike, motorbike, car, truck, animal cart or motorboat) \n    # or at least one asset related to livelihood (refrigerator, arable land or livestock).\n    # hv207 Radio, HV208 - Television, hv243a - Mobile telephone, hv221 - Telephone (non-mobile)\n    # hv210 Bicycle, HV211 Motorcycle or Scooter, HV212 Car or Truck, HV243C : Animal-drawn cart, HV243D : Boat with a motor\n    # hv209 - Refrigerator, HV244 : Own land usable for agriculture, HV245 : Hectares for agricultural land\n    # hv246 - Livestock, herds or farm animals\n    # hv246a - cattle, hv246c - horses, hv246d - goats, hv246e - sheep, hv246f - chickens\n    # * Note: I have used the simplified hv246 instead of individual livestock, slight deviation from UNDP calculation.\n    df['information_asset'] =  np.where((df.hv207 == 1) | (df.hv208 == 1) | (df.hv243a == 1) | (df.hv221 == 1), 1, 0)\n    df['mobility_asset'] =  np.where((df.hv210 == 1) | (df.hv211 == 1) | (df.hv212 == 1) | (df.hv243c == 1) | (df.hv243d == 1), 1, 0)\n    df['livelihood_asset'] =  np.where((df.hv209 == 1) | (df.hv244 == 1) | (df.hv245 == 1) | (df.hv246 == 1), 1, 0)\n    # determine asset_depriv\n    df['asset_depriv'] = df.apply(determine_asset_depriv, axis=1)\n    return df\n    ","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"873eb2ad1f437d754f32b20ff3cefbceb0c1584a"},"cell_type":"markdown","source":"### Household Member Data <a class=\"anchor\" id=\"household_member_data\"/>"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"a5abf565be8e2b22f469c4bdf1526c8b8373fbd2"},"cell_type":"code","source":"# Nutrition: a household member (for whom there is nutrition information) is malnourished, as measured by the BMI for adults\n# and by the height-for-age z-score calculated based on WHO standards for children under age 5.\n\n# Determine whether individual is malnourished\n\n# hc73: The measures are presented with two implied decimal places (no decimal points are included in the data file). \n# To produce the actual measure, divide the variable by 100. If either the weight or the height of the child is \n# missing then all of the above measures are set to the missing code 9999 or 99999. If either the height or the \n# weight is outside of the acceptable range for the calculation of these measures then all of the above measures \n# is set to code 9998 or 99998.\nz_cutoff_malnourished = -200 # Below -2 Std deviations is considered malnourished (UNDP documentation)\nbmi_cutoff_malnourished = 1850 # Cutoff according is 18.5 (UNDP documentation)\n\ndef malnourished(row):\n    if not math.isnan(row['hc31']):\n        if (row['hv105'] < 5): # < 5 years old\n            if(row['hc70'] <= z_cutoff_malnourished): # use Ht/A Std deviations\n                return 1\n            else:\n                return 0\n    elif not math.isnan(row['ha1']):\n        if (row['hv105'] >= 15) & (row['hv105'] <= 49) & (row['ha40'] <= bmi_cutoff_malnourished): # use BMI for adults\n            return 1\n        else:\n            return 0\n    else:\n        return np.nan\n    \ndef process_household_member_data(df):\n    # determine if household member is malnourished\n    df['malnourished'] = df.apply(malnourished, axis=1)\n    \n    # Education\n    # A household is deprived in school attendance1 if at least one child of age between the primary school entering age +1 \n    # and the primary school entering age +8 is not attending school.\n    # Entrance age of primary: 6 years (http://stats.uis.unesco.org/unesco/TableViewer/tableView.aspx?ReportId=163)\n    # hv121 - Household member attended school during current school year\n    # hv105 - age\n    df['child_not_in_school'] = np.where((df['hv105'] >= 7) & (df['hv105'] <= 14) & (df['hv121'] == 0), 1, 0)\n    \n    # Whether there is a child under 5 in a household or a woman between 15 and 49 are features required later on \n    # to determine whether a household is eligible for inclusion.\n    df['child_under_5'] = np.where(df['hv105'] < 5, 1, 0)\n    df['woman_15_to_49'] = np.where((df['ha1'] >= 15) & (df['ha1'] <=49), 1, 0)\n    \n    # Note: number of years of school is obtained slightly differently to the UNDP method.\n    # Get summary stats per household\n    aggregations = {\n        'hv108':lambda x: x.ge(6).sum(), # count number in houseold with >= 6 years of school\n        'malnourished': 'sum',\n        'child_under_5': 'max',\n        'woman_15_to_49': 'max',\n        'child_not_in_school': 'max'\n    }\n    summary_df = df.groupby(['hv001', 'hv002']).agg(aggregations).reset_index()\n    summary_df['school_attainment_depriv'] = np.where(summary_df['hv108'] == 0, 1, 0)\n    summary_df['school_attendance_depriv'] = np.where(summary_df['child_not_in_school'] == 0, 0, 1)\n    return summary_df","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"1a5fd0dc53caac9721a4eb3c47b64d923d43e31c"},"cell_type":"markdown","source":"### Births Data<a class=\"anchor\" id=\"births_data\"/>"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8322b264a892d460b8c27bd527c10814bb6c7ed9"},"cell_type":"code","source":"# V206 - Total number of sons who have died (children)\n# V207 - Total number of daughters who have died  (children)\n# b7 - Age at death of the child in completed months g (children)\n# B2 Year of birth of child\n# B5 Whether child was alive or dead at the time of interview. \n# Child mortality: a child has died in the household within the five years prior to the survey\nfive_year_threshold = 2009 # Since the survey year was 2014 \n\ndef child_died_within_5_years(row):\n    if (row.b5 == 0) & (row.b2+(row.b7/12) >= five_year_threshold):\n        return 1\n    else:\n        return 0\n    \ndef process_births_data(df):\n    df['child_died_within_5_years'] = df.apply(child_died_within_5_years, axis=1)\n    \n    # Get summary stats per household\n    aggregations = {\n        'child_died_within_5_years': 'sum'\n    }\n    return df.groupby(['v001', 'v002']).agg(aggregations).reset_index()","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"71f75e7f61287c016387e7b858e84e036b576bb2"},"cell_type":"markdown","source":"### Combined Dataset\n\nThe data sets can now be combined into a single dataset at the household level."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"9c98c03565312954a9101b461a4fd4767fd0897d"},"cell_type":"code","source":"def combine_datasets(household_df, household_member_df, births_df):\n    print(\"Original DHS household dataset: \", household_df.shape)\n    combined_df = household_df.merge(household_member_df)\n    combined_df = combined_df.merge(births_df, how='left', left_on=['hv001', 'hv002'], right_on=['v001', 'v002'])\n    print(\"Merged dataset: \", combined_df.shape)\n    \n    # drop irrelevant columns\n    combined_df = combined_df[combined_df.columns.drop(list(combined_df.filter(regex='^hv2')))]\n    combined_df = combined_df[combined_df.columns.drop(list(combined_df.filter(regex='^v0')))]\n    return combined_df","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"c4639111fbe388c2e2f29e56de4715cd5a73dc65"},"cell_type":"markdown","source":"## 4. Treatment of households with missing observations in at least one indicator <a class=\"anchor\" id=\"missing_observations\"/>\n***\nA household is excluded from the MPI calculation if there is missing information for one or more indicators. MPI estimates can be based only on the sample of households with available information in all 10 indicators.\n\n## 5. Treatment of households with non-eligible population <a class=\"anchor\" id=\"non_eligible_popluation\"/>\n***\nA household is considered non-eligible for the MPI estimation if estimation of its deprivation in the\nhealth dimension is not possible. This happens when the household does not have women of age\nbetween 15 and 49 and it does not have children of age under 60 months (under-5), and the BMI\nmeasurements were not taken for men. In this situation, it is not possible to observe any deprivation in\nthe health dimension.\n\n"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"2ac8caf110e6cd462d93dad6a4bcb6c8dee45899"},"cell_type":"code","source":"edu_ind_weight = 1/6\nhealth_ind_weight = 1/6\nliv_ind_weight = 1/18\n\ndef calculate_total_of_weighted_depriv(row):\n    return (row.school_attainment_depriv*edu_ind_weight) + (row.school_attendance_depriv*edu_ind_weight) + (row.malnourished*health_ind_weight) + (row.child_died_within_5_years*health_ind_weight) + (row.electricity_depriv*liv_ind_weight) + (row.water_depriv*liv_ind_weight) + (row.sanitation_depriv*liv_ind_weight) + (row.cooking_fuel_depriv*liv_ind_weight) + (row.floor_depriv*liv_ind_weight) + (row.asset_depriv*liv_ind_weight)\n\n#eligible_df['total_of_weighted_deprivations']  = (eligible_df.school_attainment_depriv*edu_ind_weight) + (eligible_df.school_attendance_depriv*edu_ind_weight) + (eligible_df.malnourished*health_ind_weight) + (eligible_df.child_died_within_5_years*health_ind_weight) + (eligible_df.electricity_depriv*liv_ind_weight) + (eligible_df.water_depriv*liv_ind_weight) + (eligible_df.sanitation_depriv*liv_ind_weight) + (eligible_df.cooking_fuel_depriv*liv_ind_weight) + (eligible_df.floor_depriv*liv_ind_weight) + (eligible_df.asset_depriv*liv_ind_weight)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"d6643a0f8e0bf9673f4864ea8af836457680ca91"},"cell_type":"markdown","source":"## 6. Calculating MPI with DHS Data <a class=\"anchor\" id=\"calculating_mpi\"/>\n***\nThe data can now be matched to MPI data spatially (at a sub-national level) to look at how closely the MPI calculated here reflects the given MPI scores."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e99c925f93afca7abb4443edb0862886609fc744"},"cell_type":"code","source":"def calculate_mpi(df, dhs_cluster_df):\n    # Headcount ratio\n    # The headcount ratio, H, is the proportion of the multidimensionally poor in the population:\n    # H = q / n\n    # where q is the number of people who are multidimensionally poor and n is the total population.\n    df['headcount_poor'] =  np.where(df['total_of_weighted_deprivations'] >= 0.333, df['total_household_members'], 0)\n\n    # The intensity of poverty, A, reflects the proportion of the weighted component indicators in which, on average,\n    # poor people are deprived. For poor households only (deprivation score c of 33.3 percent or higher), the deprivation \n    # scores are summed and divided by the total number of poor people.\n    df['total_poverty_intensity'] = df['headcount_poor']*df['total_of_weighted_deprivations']\n    \n    # Join eligible_df to cluster data \n\n    # Format the DHSID to get just the number part for matching with hv001\n    dhs_cluster_df['DHSID_num'] = dhs_cluster_df['DHSID'].str[6:].str.lstrip('0').astype(int)\n    \n    # Merge dhs_cluster with dhs_geo\n    print(\"Original dhs_cluster_df dataset: \", dhs_cluster_df.shape)\n    dhs_cluster_df = dhs_cluster_df.merge(dhs_geo_gdf[['DHSID', 'ADM1NAME', 'LATNUM', 'LONGNUM']], left_on=['DHSID'], right_on=['DHSID'], suffixes=('', '_y'))\n    dhs_cluster_df = dhs_cluster_df[dhs_cluster_df.columns.drop(list(dhs_cluster_df.filter(regex='_y')))]\n    print(\"Merged dhs_cluster_df dataset: \", dhs_cluster_df.shape)\n\n    # Merge combined_df with dhs_cluster data to get county information (name)\n    df = df.merge(dhs_cluster_df[['DHSID_num', 'ADM1NAME', 'LATNUM', 'LONGNUM']], left_on=['hv001'], right_on=['DHSID_num'])\n    print(\"Merged df dataset: \", df.shape)\n    \n    return df\n\n# Aggregate to specifed level, COUNTY level by default\ndef aggregate_admin_level(df, level='ADM1NAME', col='mpi_county'):\n    aggregations = {\n        'headcount_poor': 'sum',\n        'total_household_members': 'sum',\n        'total_poverty_intensity': 'sum'\n    }\n    df = df.groupby([level]).agg(aggregations).reset_index()\n\n    # Calculate MPI at COUNTY level\n    df['headcount_ratio'] = df['headcount_poor']/df['total_household_members']\n    df['poverty_intensity'] = df['total_poverty_intensity']/df['headcount_poor']\n    df[col] = df['headcount_ratio'] * df['poverty_intensity']\n    \n    return df","execution_count":10,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"15dbaee3ec65a0dbccaea198495f6d9fd646a875"},"cell_type":"code","source":"# Function to combine MPI subnational scores with geometry\ndef get_mpi_subnational_gdf(mpi_subnational_df, states_provinces_gdf, country):\n    # Join the mpi_subnational data to states and provinces data in order to plot\n\n    # Keep just country data\n    states_provinces_gdf = states_provinces_gdf[states_provinces_gdf['admin'] == country]\n    mpi_subnational_df = mpi_subnational_df[mpi_subnational_df['Country'] == country]\n\n    # This step is just to ensure we have matches where possible between the two datasets\n    #from string import punctuation\n    #states_provinces_gdf['name'] = states_provinces_gdf['name'].str.replace('-',' ')\n    #mpi_subnational_df['Sub-national region'] = mpi_subnational_df['Sub-national region'].str.replace('-',' ')\n\n    print(\"Country states_provinces_gdf dataset: \", states_provinces_gdf.shape)\n    print(\"Country mpi_subnational_df dataset: \", mpi_subnational_df.shape)\n\n    states_provinces_gdf.drop_duplicates(subset='woe_label', keep=\"last\", inplace=True)\n    print(\"Cleaned states_provinces_gdf dataset: \", states_provinces_gdf.shape)\n\n    mpi_subnational_df = mpi_subnational_df[mpi_subnational_df['Country'] == country]\n    mpi_subnational_df = mpi_subnational_df.merge(states_provinces_gdf, left_on='Sub-national region', right_on='name')\n    print(\"Merged mpi_subnational_gdf dataset (with states_provinces_gdf): \", mpi_subnational_df.shape)\n    \n    return mpi_subnational_df","execution_count":11,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"41916591dec691c34a4a3e8a3fbde854e815c5ef"},"cell_type":"code","source":"# Define some geo conversion functions\n# Spatially join to counties\ndef convert_to_geodataframe_with_lat_long(df, lon, lat):\n    df['geometry'] = df.apply(lambda row: Point(row[lon], row[lat]), axis=1)\n    gdf = gpd.GeoDataFrame( df, geometry='geometry')\n    gdf.crs = {\"init\":'epsg:4326'}\n    return gdf\n\ndef convert_to_geodataframe_with_geometry(df, geometry):\n    gdf = gpd.GeoDataFrame( df, geometry='geometry')\n    gdf.crs = {\"init\":'epsg:4326'}\n    return gdf","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"c746c6127190c16cc27c3735576a21bc4550086b"},"cell_type":"markdown","source":"Note: In the next step the datasetes are spatially joined using geopandas sjoin. This does not seem to work on Kaggle servers (due to a problem with the rtree dependency. Ref: https://www.kaggle.com/product-feedback/53008) but works on any system where the dependencies are set up correctly. To overcome this, the author has run sjoin locally, saved the result and read it back in when running this kernel on Kaggle servers. To run sjoin, simply uncomment below."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7f0123d7c0ec8ce31f0043c6cd6e5f579dba485c"},"cell_type":"code","source":"# Function to run the whole process\n# This calls all the subfunctions in order to calculate MPI at province level and calcualtes a correlation between \n# the country's calculated MPI and the UNDP MPI.\n# Note: The lines where sjoin is used are commented out in order to run on Kaggle servers. The data has been preprocessed locally,\n# and read in when running on Kaggle. To run full sjoin steps, simple uncomment the lines.\n\ndef process(country, admin1_col, admin1_mpi_col, admin2_geo=gpd.GeoDataFrame(), admin2_col='', admin2_mpi_col='', admin3_geo=gpd.GeoDataFrame(), admin3_col='', admin3_mpi_col=''):\n    global household_dhs_df\n    global household_member_dhs_df\n    global births_dhs_df\n    global dhs_mpi_df\n    global admin1_dhs_mpi_df\n    global admin1_dhs_mpi_merged_df\n    global admin2_dhs_mpi_df\n    global admin3_dhs_mpi_df\n    global country_mpi_subnational_gdf\n    \n    # delete after debugging\n    global dhs_mpi_joined_gdf\n    \n    # Process DHS data to get individual indicators\n    household_dhs_df = process_household_data(household_dhs_df)\n    household_member_dhs_summary_df = process_household_member_data(household_member_dhs_df)\n    births_dhs_summary_df = process_births_data(births_dhs_df)\n    combined_df = combine_datasets(household_dhs_df, household_member_dhs_summary_df, births_dhs_summary_df)\n\n    # remove households with missing indicators\n    print(\"Combined DHS Dataset: \", combined_df.shape)\n    combined_df.dropna(inplace=True)\n    print(\"Dataset after removing households with missing indicators: \", combined_df.shape)\n\n    # remove ineligible households\n    eligible_df = combined_df[(combined_df['woman_15_to_49'] != 0) | (combined_df['child_under_5'] != 0)]\n    print(\"Dataset after removing ineligible households: \", eligible_df.shape)\n\n    # calclate total weighted deprivations\n    eligible_df['total_of_weighted_deprivations'] = eligible_df.apply(calculate_total_of_weighted_depriv, axis=1)\n\n    # calculate MPI\n    dhs_mpi_df = calculate_mpi(eligible_df, dhs_cluster_df)\n\n    # Spatially join to admin1 boundaries\n    #dhs_mpi_gdf = convert_to_geodataframe_with_lat_long(dhs_mpi_df, 'LONGNUM', 'LATNUM')\n    #dhs_mpi_joined_gdf = gpd.sjoin(dhs_mpi_gdf, admin1_geo_gdf, op='within')\n    #print(\"Dataset spatially joined with admin level 1 geodata: \", dhs_mpi_joined_gdf.shape)   \n    #dhs_mpi_joined_gdf.to_csv(country+'_dhs_mpi_admin1_sjoin.csv', index = False)\n    dhs_mpi_joined_gdf = pd.read_csv('../input/preprocessed/'+country+'_dhs_mpi_admin1_sjoin.csv')\n    \n    # Aggregate to admin1 (Province) level\n    admin1_dhs_mpi_df = aggregate_admin_level(dhs_mpi_joined_gdf, level=admin1_col, col=admin1_mpi_col)\n    print(\"Dataset aggregated to admin level 1: \", admin1_dhs_mpi_df.shape)\n    \n    # Ensure we are using title case for names (this is inconsistent in some country's datasets)\n    admin1_dhs_mpi_df[admin1_col] = admin1_dhs_mpi_df[admin1_col].str.title()\n    # \n    country_mpi_subnational_gdf = get_mpi_subnational_gdf(mpi_subnational_df, states_provinces_gdf, country)\n    admin1_dhs_mpi_merged_df = admin1_dhs_mpi_df.merge(country_mpi_subnational_gdf[['Sub-national region', 'MPI Regional']],\n                                                    left_on=[admin1_col], right_on=['Sub-national region'])\n    print(\"Dataset after merge with UNDP MPI data: \", admin1_dhs_mpi_merged_df.shape)\n    \n    if not admin2_geo.empty:\n        # Spatially join to admin2 boundaries\n        #dhs_mpi_joined_gdf = gpd.sjoin(dhs_mpi_gdf, admin2_geo, op='within')\n        #print(\"Dataset spatially joined with admin level 2 geodata: \", dhs_mpi_joined_gdf.shape)\n        #dhs_mpi_joined_gdf.to_csv(country+'_dhs_mpi_admin2_sjoin.csv', index = False)\n        dhs_mpi_joined_gdf = pd.read_csv('../input/preprocessed/'+country+'_dhs_mpi_admin2_sjoin.csv')\n    if admin2_col:\n        # Aggregate to admin2 (County) level\n        admin2_dhs_mpi_df = aggregate_admin_level(dhs_mpi_joined_gdf, level=admin2_col, col=admin2_mpi_col)\n        print(\"Dataset aggregated to admin level 2: \", admin2_dhs_mpi_df.shape)\n    \n    if not admin3_geo.empty:\n        # Spatially join to admin3 boundaries\n        #dhs_mpi_joined_gdf = gpd.sjoin(dhs_mpi_gdf, admin3_geo, op='within')\n        #print(\"Dataset spatially joined with admin level 3 geodata: \", dhs_mpi_joined_gdf.shape)\n        #dhs_mpi_joined_gdf.to_csv(country+'_dhs_mpi_admin3_sjoin.csv', index = False)\n        dhs_mpi_joined_gdf = pd.read_csv('../input/preprocessed/'+country+'_dhs_mpi_admin3_sjoin.csv')\n    if admin3_col:\n        # Aggregate to admin3 level\n        admin3_dhs_mpi_df = aggregate_admin_level(dhs_mpi_joined_gdf, level=admin3_col, col=admin3_mpi_col)\n        print(\"Dataset aggregated to admin level 3: \", admin3_dhs_mpi_df.shape)\n\n    # Calculate Correlation at admin1 level\n    print(\"Correlation:\", admin1_dhs_mpi_merged_df[admin1_mpi_col].corr(admin1_dhs_mpi_merged_df['MPI Regional']))\n    sns.regplot(x=\"MPI Regional\", y=admin1_mpi_col, data=admin1_dhs_mpi_merged_df)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"671997081d1c91d4cadc5b2082c1a0222a5dbca9"},"cell_type":"markdown","source":"## Kenya\n\nKenya is the country on which this model was initially developed, so lets have a look at the results for Kenya."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"99450e6c443a0edf22c552417ee5e35701350fde"},"cell_type":"code","source":"read_data('kenya', \n          '../input/kenya-dhs-preprocessed/kenya_household_dhs.csv',\n          '../input/kenya-dhs-preprocessed/kenya_household_member_dhs.csv',\n          '../input/kenya-dhs-preprocessed/kenya_births_dhs.csv',\n          '../input/kenya-dhs-preprocessed/kenya_dhs_cluster.csv',\n          '../input/kenya-dhs-preprocessed/KEGE71FL.shp', \n          '../input/kenya-humdata-admin-geo/Kenya_admin_2014_WGS84.shp', \n          '../input/kenya-humdata-admin-geo/KEN_Adm2.shp')","execution_count":14,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"edde6abe0a02fefb834885e404dfa0f0a8f566a4"},"cell_type":"code","source":"# Replace polygons with simple ones\n# This step was done because folium maps were not plotting the original polygons for some reason. Maybe they were just too complex.\n\n# This step is only necessary for certain shapefiles, when the geometry has too many points.\ndef replace_geometry(gdf, gdf_simple_path):\n    gdf_simple = gpd.read_file(gdf_simple_path)\n    gdf['geometry'] = gdf_simple['geometry']\n\n# Note: Be careful when simplifying shapefiles, that there are still matches for all admin level entries and \n# no Polygon is simpified down to an empty polygon.\nreplace_geometry(admin1_geo_gdf, '../input/kenya-humdata-admin-geo/Kenya_admin_2014_WGS84_simple.shp')\nreplace_geometry(admin2_geo_gdf, '../input/kenya-humdata-admin-geo/KEN_Adm2_simple.shp')","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9bc11c5c83c7abab4f7a3ddca1f48f7c0596111"},"cell_type":"code","source":"process('Kenya', 'Province', 'mpi_admin1', \n        admin2_geo=admin2_geo_gdf, admin2_col='ADM1NAME', admin2_mpi_col='mpi_admin2', \n        admin3_col='Adm2Name', admin3_mpi_col='mpi_admin3')","execution_count":16,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7240e29e7a131daebaf30dcb400c4ef0c7a9b6f2"},"cell_type":"code","source":"# Define some helper functions\ndef get_geo_gdf(country):\n    return states_provinces_gdf[states_provinces_gdf['geonunit'] == country]\n\ndef create_map(geo_gdf, data, key_on, key_col, feature, fill_color, lat, long, zoom, threshold_scale):\n    geojson = geo_gdf.to_json()\n    country_map = folium.Map([lat, long], zoom_start = zoom)\n    country_map.choropleth(\n        geo_data=geojson,\n        name=feature+' choropleth',\n        key_on=key_on,\n        fill_color=fill_color,\n        data=data,\n        columns=[key_col, feature],\n        threshold_scale=threshold_scale,\n        legend_name= feature+' per Province'\n    )\n    return country_map","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"84846d87e6edd4861652abb382534abcbaf162cc"},"cell_type":"markdown","source":"#### Figure: UNDP Province (Sub-national) MPI - Kenya <a class=\"anchor\" id=\"fig_undp_admin1_mpi_kenya\"/>"},{"metadata":{"trusted":true,"_uuid":"f3747920f2b98858f82b214b2bdfb629ef1d6ec8"},"cell_type":"code","source":"kenya_mpi_threshold_scale = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6] # Define MPI scale for Kenya\nkenya_geo_gdf = get_geo_gdf('Kenya')\ncreate_map(kenya_geo_gdf, country_mpi_subnational_gdf, 'feature.properties.name', 'Sub-national region', 'MPI Regional', 'YlOrRd', 0.0236, 37.9062, 6, kenya_mpi_threshold_scale)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"0ba22c62acc2cdea7af87e1067c8d8de2316e5ba"},"cell_type":"markdown","source":"#### Figure: Calculated Province (Sub-national) MPI - Kenya <a class=\"anchor\" id=\"fig_calc_admin1_mpi_kenya\"/>"},{"metadata":{"trusted":true,"_uuid":"391d64a72fa3c7bf7a839709bb228bad5bec8131"},"cell_type":"code","source":"create_map(kenya_geo_gdf, admin1_dhs_mpi_df, 'feature.properties.name', 'Province', 'mpi_admin1', 'YlOrRd', 0.0236, 37.9062, 6, kenya_mpi_threshold_scale)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"72ed7dd7e69cb98f1d24cef98827b41f7952e502"},"cell_type":"markdown","source":"#### Figure: Calculated Administraton Level 1 MPI - Kenya <a class=\"anchor\" id=\"fig_calc_admin2_mpi_kenya\"/>"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"85cc38042fefdb5a5cbba409edc2e57ece37e9ab"},"cell_type":"code","source":"create_map(admin1_geo_gdf, admin2_dhs_mpi_df, 'feature.properties.COUNTY', 'ADM1NAME', 'mpi_admin2', 'YlOrRd', 0.0236, 37.9062, 6, kenya_mpi_threshold_scale)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"b5a7dc3418cf1a3f61daa5ec334f9c51e18634cc"},"cell_type":"markdown","source":"#### Figure: Calculated Administration Level 2 MPI - Kenya <a class=\"anchor\" id=\"fig_calc_admin3_mpi_kenya\"/>"},{"metadata":{"trusted":true,"_uuid":"7c270d0565baff093066834141f0b8d61176ede6"},"cell_type":"code","source":"create_map(admin2_geo_gdf, admin3_dhs_mpi_df, 'feature.properties.Adm2Name', 'Adm2Name', 'mpi_admin3', 'YlOrRd', 0.0236, 37.9062, 6, kenya_mpi_threshold_scale)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc6f1f00a68159d3bccec2b8001e20d2907ddcf2"},"cell_type":"code","source":"#TOOD : mpi_subnational_df['Sub-national region'] = mpi_subnational_df['Sub-national region'].str.replace('-',' ')\nadmin2_dhs_mpi_df.ADM1NAME.unique()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbbb7cbbc5506d2f71194ef606f0305a50f7d937"},"cell_type":"code","source":"admin2_geo_gdf.Adm1Name.unique()","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"52eb71b7294e2a70b3182d589b2e50a08cfa387b"},"cell_type":"markdown","source":"## Joining Kiva Loan Data\n\nSince the whole purpose of this work is to enable Kiva to estimate the level of poverty of their borrows more accurately, what is needed is a join between the Kiva loan data and the MPI at a county level. (This notebook will work at a county level when joning Kiva data even though, as shown in the previous section, it is possible to get more granular. Reason being that the next level down - county - will be an improvenment for Kiva and 1. is more likely to be applicable across countries as data should be more readily available and 2. the complexity of this notebook is reduced.)\n\nSince a direct mapping of Kiva loan data to counties is not available, the join will be done spatially by checking in which county polygon the latitude and longitude of the Kiva borrower lies."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"45fa4a7f958d8217396bcc16543c6a3352b6fda7"},"cell_type":"code","source":"# Original Kiva datasets\nkiva_loans_df = pd.read_csv(\"../input/data-science-for-good-kiva-crowdfunding/kiva_loans.csv\")\n#kiva_mpi_locations_df = pd.read_csv(\"../input/data-science-for-good-kiva-crowdfunding/kiva_mpi_region_locations.csv\")\nloan_theme_ids_df = pd.read_csv(\"../input/data-science-for-good-kiva-crowdfunding/loan_theme_ids.csv\")\nloan_themes_by_region_df = pd.read_csv(\"../input/data-science-for-good-kiva-crowdfunding/loan_themes_by_region.csv\")","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e3293ee366016347c73afbb75f178b4209e84d2"},"cell_type":"code","source":"# Merge Kiva loans to locations data via loan_themes\nprint(\"Original Kiva Loans dataset: \", kiva_loans_df.shape)\nkiva_loans_region_df = pd.merge(kiva_loans_df, loan_theme_ids_df, how='left', on='id', suffixes=('', '_y'))\nkiva_loans_region_df = kiva_loans_region_df[kiva_loans_region_df.columns.drop(list(kiva_loans_region_df.filter(regex='_y')))]\n\nkiva_loans_region_df = kiva_loans_region_df.merge(loan_themes_by_region_df, how='left', on=['Partner ID', 'Loan Theme ID', 'country', 'region'], suffixes=('', '_y'))\nkiva_loans_region_df = kiva_loans_region_df[kiva_loans_region_df.columns.drop(list(kiva_loans_region_df.filter(regex='_y')))]\n\n#kiva_loans_region_df = kiva_loans_region_df.merge(kiva_loans_region_df, how='left', left_on=['country', 'mpi_region'], right_on=['country', 'LocationName'], suffixes=('', '_y'))\n#kiva_loans_region_df = kiva_loans_region_df[kiva_loans_region_df.columns.drop(list(kiva_loans_region_df.filter(regex='_y')))]\nprint(\"Merged Kiva Loans dataset: \", kiva_loans_region_df.shape)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77be2c8c92c24c6a7f45f56ecb01a1384d893aaa"},"cell_type":"code","source":"# Keep only Kenya loans\nkiva_loans_kenya_df = kiva_loans_region_df[kiva_loans_region_df['country']=='Kenya']\nprint(\"Kenya Kiva Loans dataset: \", kiva_loans_kenya_df.shape)\n\n# Drop those with null lat/long. If lat/long is not known, the borrower cannot be more accurately classified using this method.\nkiva_loans_kenya_df = kiva_loans_kenya_df[np.isfinite(kiva_loans_kenya_df['lat'])]\nprint(\"Kenya cleaned Kiva Loans dataset: \", kiva_loans_kenya_df.shape)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46f4378be88682085e2eaff793092d24b5017063"},"cell_type":"code","source":"# Get county geomentry\n\n# Doing some manual recoding to get matches \nadmin1_geo_gdf.COUNTY.replace('Keiyo-Marakwet', 'Elgeyo Marakwet', inplace=True)\nadmin1_geo_gdf.COUNTY.replace('Tharaka', 'Tharaka-Nithi', inplace=True)\nadmin1_geo_gdf.COUNTY.replace('Trans Nzoia', 'Trans-Nzoia', inplace=True)\n\nprint(\"Original dhs_mpi_county_df dataset: \", admin2_dhs_mpi_df.shape)\nadmin2_dhs_mpi_df = admin2_dhs_mpi_df.merge(admin1_geo_gdf[['COUNTY', 'Province', 'geometry']], left_on='ADM1NAME', right_on=['COUNTY'])\nprint(\"Merged dhs_mpi_county_df dataset: \", admin2_dhs_mpi_df.shape)","execution_count":27,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"094e24dd1ed64cec49e98ad0c3237ce4ecb6c40c"},"cell_type":"code","source":"# function to add markers to folium map\ndef add_markers(df, m, radius='count', color='blue', popup=None):\n    for i in range(0, df.shape[0]):\n        folium.CircleMarker(\n            [df.iloc[i]['lat'], df.iloc[i]['lon']], \n            radius=df.iloc[i][radius]**(4**-1), # x**(n**-1) is used because there are clusters of loans with the same lot/long\n                                                 # and also single loans with unique lat/long\n            color=color, \n            fill=True, \n            fill_color=color\n        ).add_to(m)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"51c67073aaca1f9aa74fb03cc2a2bbabdaede432"},"cell_type":"markdown","source":"#### Figure: Kiva Loans + Calculated County MPI - Kenya <a class=\"anchor\" id=\"fig_loans_vs_calc_admin2_mpi_kenya\"/>"},{"metadata":{"trusted":true,"_uuid":"1d12e4ec862eaddbf7636299dd0fdc8652bcf0d7"},"cell_type":"code","source":"# Convert to geo dataframe\nkiva_loans_kenya_gdf = convert_to_geodataframe_with_lat_long(kiva_loans_kenya_df, 'lon', 'lat')\n\n# Group by lat/long, count because there are many loans recorded with the same lat/long and it takes too long to plot otherwise.\nprint(\"Original kiva_loans_kenya_gdf dataset: \", kiva_loans_kenya_gdf.shape)\nkiva_loans_kenya_grouped_gdf = kiva_loans_kenya_gdf.groupby(['lat','lon']).size().reset_index(name='count')\nprint(\"Grouped kiva_loans_kenya_gdf dataset: \", kiva_loans_kenya_grouped_gdf.shape)\n\n# plot at county level\nkenya_map = create_map(admin1_geo_gdf, admin2_dhs_mpi_df, 'feature.properties.COUNTY', 'ADM1NAME', 'mpi_admin2', 'YlOrRd', 0.0236, 37.9062, 6, kenya_mpi_threshold_scale)\nadd_markers(kiva_loans_kenya_grouped_gdf, kenya_map)\nkenya_map","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"861cf0868b5a1e9b1ddb15d6018f954b78a424f8"},"cell_type":"markdown","source":"It is interesting to note that there are no/not many loans in the poorest regions.\n"},{"metadata":{"_uuid":"2d61c88864dd243de6e6cef83e88a562115b1844"},"cell_type":"markdown","source":"## Scalability Testing Zimbabwe <a class=\"anchor\" id=\"scalability_testing\"/>\n***\nNow that we have a, hopefully, generic model developed on Kenya data, lets see how well it copes with data from other countries.\n\n### Zimbabwe <a class=\"anchor\" id=\"zimbabwe\"/>"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"30618f5729efdbfe0fdc19afba66292e91c93472"},"cell_type":"code","source":"# Uncomment the line below to run pre-processing of original DHS files\n#preprocess_dhs_data('zimbabwe', 'ZWHR71FL.DTA', 'ZWPR71FL.DTA', 'ZWBR71FL.DTA', 'ZWGC71FL.csv')","execution_count":30,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"358c05a6c5979818b774aa6a738ac0014b144054"},"cell_type":"code","source":"# Read in DHS and Geo Data\nread_data('zimbabwe', \n          '../input/zimbabwe-dhs-preprocessed/zimbabwe_household_dhs.csv',\n          '../input/zimbabwe-dhs-preprocessed/zimbabwe_household_member_dhs.csv',\n          '../input/zimbabwe-dhs-preprocessed/zimbabwe_births_dhs.csv',\n          '../input/zimbabwe-dhs-preprocessed/zimbabwe_dhs_cluster.csv',\n          '../input/zimbabwe-dhs-preprocessed/ZWGE72FL.shp', \n          '../input/zimbabwe-humdata-admin-geo/zwe_polbnda_adm1_250k_cso.shp', \n          '../input/zimbabwe-humdata-admin-geo/zwe_polbnda_adm2_250k_cso.shp'\n         )","execution_count":31,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"acc16584f8ed9982ec96bd8c609a0b0e7832f136"},"cell_type":"code","source":"# Simplify geometry. Seems to be necessary only for admin level 2 for Zimbabwe.\nreplace_geometry(admin2_geo_gdf, '../input/zimbabwe-humdata-admin-geo/zwe_polbnda_adm2_250k_cso_simple.shp')","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efad87a49240c188daf3db26373e0d79ffd5a4d7"},"cell_type":"code","source":"process('Zimbabwe', 'ADM1NAME', 'mpi_admin1', admin2_geo=admin2_geo_gdf, admin2_col='DIST_NM_LA', admin2_mpi_col='mpi_admin2', )","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"4121d6191239ffb834cd649dbf58ffe2c34f8cc9"},"cell_type":"markdown","source":"#### Figure: UNDP Province (Sub-national) MPI - Zimbabwe <a class=\"anchor\" id=\"fig_undp_admin1_mpi_zimbabwe\"/>"},{"metadata":{"trusted":true,"_uuid":"7415ba6e237cf862a33f4b58b875b25c4dbfe4d3"},"cell_type":"code","source":"zmbabwe_mpi_threshold_scale = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3] # Define MPI scale for Zimbabwe\nzimbabwe_geo_gdf = get_geo_gdf('Zimbabwe')\ncreate_map(zimbabwe_geo_gdf, country_mpi_subnational_gdf, 'feature.properties.name', 'Sub-national region', \n           'MPI Regional', 'YlOrRd', -19.0154, 29.1549, 6, zmbabwe_mpi_threshold_scale)","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"bacc782fdf1059ce5603a50651ed152aaeab281e"},"cell_type":"markdown","source":"#### Figure: Calculated Province (Sub-national) MPI - Zimbabwe <a class=\"anchor\" id=\"fig_calc_admin1_mpi_zimbabwe\"/>"},{"metadata":{"trusted":true,"_uuid":"e23e4a7c3688ee56d2339d8f1cbc8258c0f00c28"},"cell_type":"code","source":"create_map(zimbabwe_geo_gdf, admin1_dhs_mpi_df, 'feature.properties.name', 'ADM1NAME', 'mpi_admin1', 'YlOrRd', -19.0154, 29.1549, 6, zmbabwe_mpi_threshold_scale)","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"fb2416f1b3717a1db20d7fa52f172bb8a9e2ac3e"},"cell_type":"markdown","source":"#### Figure: Calculated Administration Level 2 MPI - Zimbabwe <a class=\"anchor\" id=\"fig_calc_admin2_mpi_zimbabwe\"/>"},{"metadata":{"trusted":true,"_uuid":"923d671ee7ef06be3956b12e1ea036afa0bf74db"},"cell_type":"code","source":"create_map(admin2_geo_gdf, admin2_dhs_mpi_df, 'feature.properties.DIST_NM_LA', 'DIST_NM_LA', 'mpi_admin2', 'YlOrRd', -19.0154, 29.1549, 6, zmbabwe_mpi_threshold_scale)","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"c2ed91b2a8947cb370ddd3ec0b88f0798223ca3b"},"cell_type":"markdown","source":"### Cambodia"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ea8afc5ab0ff1f3565e7b3d825b69e802ec40b6d"},"cell_type":"code","source":"# Uncomment the line below to run pre-processing of original DHS files\n#preprocess_dhs_data('cambodia', 'KHHR73FL.DTA', 'KHPR73FL.DTA', 'KHBR73FL.DTA', 'KHGC71FL.csv')","execution_count":37,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7f42a0f59d35636da9fcb46e1da9c5f95cad6df5"},"cell_type":"code","source":"# Read in DHS and Geo Data\nread_data('cambodia', \n          '../input/cambodia-dhs-preprocessed/cambodia_household_dhs.csv',\n          '../input/cambodia-dhs-preprocessed/cambodia_household_member_dhs.csv',\n          '../input/cambodia-dhs-preprocessed/cambodia_births_dhs.csv',\n          '../input/cambodia-dhs-preprocessed/cambodia_dhs_cluster.csv',\n          '../input/cambodia-dhs-preprocessed/KHGE71FL.shp', \n          '../input/cambodia-humdata-admin-geo/khm_admbnda_adm1_gov.shp', \n          '../input/cambodia-humdata-admin-geo/khm_admbnda_adm2_gov.shp'\n         )","execution_count":38,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"f59907812844bd732f88166077cd2fbeb9c9d1cf"},"cell_type":"code","source":"# Simplify geometry. Seems to be necessary only for admin level 2 for Zimbabwe.\nreplace_geometry(admin1_geo_gdf, '../input/cambodia-humdata-admin-geo/khm_admbnda_adm1_gov_simple.shp')\nreplace_geometry(admin2_geo_gdf, '../input/cambodia-humdata-admin-geo/khm_admbnda_adm2_gov_simple.shp')","execution_count":39,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"2d0e92f31a8e25283efbdee3711f1f37d913a662"},"cell_type":"code","source":"# Doing some manual recoding to get matches - no match for Banteay Mean Chey, Kampong Speu,  Kampong Thom, Kandal, Kratie, Pursat\nstates_provinces_gdf.name.replace('Bântéay Méanchey', 'Banteay Mean Chey', inplace=True)\n#states_provinces_gdf.name.replace('Battambang & Pailin', 'Pailin', inplace=True)\nstates_provinces_gdf.name.replace('Batdâmbâng', 'Battambang & Pailin', inplace=True)\nstates_provinces_gdf.name.replace('Kâmpóng Cham', 'Kampong Cham', inplace=True)\nstates_provinces_gdf.name.replace('Kâmpóng Chhnang', 'Kampong Chhnang', inplace=True)\nstates_provinces_gdf.name.replace('Kâmpóng Spœ', 'Kampong Speu', inplace=True)\nstates_provinces_gdf.name.replace('Kâmpóng Thum', 'Kampong Thom', inplace=True)\nstates_provinces_gdf.name.replace('Kep', 'Kampot & Kep', inplace=True)\nstates_provinces_gdf.name.replace('Kândal', 'Kandal', inplace=True)\nstates_provinces_gdf.name.replace('Krâchéh', 'Kratie', inplace=True)\nstates_provinces_gdf.name.replace('Môndól Kiri', 'Mondol Kiri & Rattanak Kiri', inplace=True)\nstates_provinces_gdf.name.replace('Krong Preah Sihanouk', 'Preah Sihanouk & Kaoh Kong', inplace=True)\nstates_provinces_gdf.name.replace('Preah Vihéar', 'Preah Vihear & Steung Treng', inplace=True)\nstates_provinces_gdf.name.replace('Stœng Trêng', 'Preah Vihear & Steung Treng', inplace=True)\nstates_provinces_gdf.name.replace('Prey Vêng', 'Prey Veng', inplace=True)\nstates_provinces_gdf.name.replace('Pouthisat', 'Pursat', inplace=True)\nstates_provinces_gdf.name.replace('Siemréab', 'Siem Reap', inplace=True)\nstates_provinces_gdf.name.replace('Takêv', 'Takeo', inplace=True)\n\n#cambodia_geo_gdf.name.replace('Bântéay Méanchey', 'Banteay Mean Chey', inplace=True)\n#cambodia_geo_gdf.name.replace('Krong Pailin', 'Pailin', inplace=True)\n#cambodia_geo_gdf.name.replace('Kaôh Kong', 'Preah Sihanouk & Kaoh Kon', inplace=True)\n#cambodia_geo_gdf.name.replace('Stœng Trêng', 'Preah Vihear & Steung Treng', inplace=True)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90f1aafe7170b74ca54478f9f9aaa9db027ffba2"},"cell_type":"code","source":"process('Cambodia', 'ADM1NAME', 'mpi_admin1', admin2_geo=admin2_geo_gdf, admin2_col='DIS_NAME', admin2_mpi_col='mpi_admin2')","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"7d65e655d2f701f32f4e8d5838b3c4ece1df4ecc"},"cell_type":"markdown","source":"#### Figure: UNDP Province (Sub-national) MPI - Cambodia <a class=\"anchor\" id=\"fig_undp_admin1_mpi_cambodia\"/>"},{"metadata":{"trusted":true,"_uuid":"7a4a08cee73aeab78ca85fb07ac55cf4611157d9"},"cell_type":"code","source":"cambodia_mpi_threshold_scale = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3] # Define MPI scale for Zimbabwe\ncambodia_geo_gdf = get_geo_gdf('Cambodia')\ncreate_map(cambodia_geo_gdf, country_mpi_subnational_gdf, 'feature.properties.name', 'Sub-national region', \n           'MPI Regional', 'YlOrRd', 12.5657, 104.9910, 7, cambodia_mpi_threshold_scale)","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"9a0cec17e607eeaea698b0951e1bb79800622226"},"cell_type":"markdown","source":"Note: It was quite fiddly to match the province names of Cambodia due to special characters in the language, different translations and also changes in provinces over time. Most were matched in the end but not all (some had a single mpi entry between what are now two different provinces) so keep in mind when looking at the map, some of the light regions may actually be missing MPI values.\nTODO: Clean this up / plot missing values as black instead of 0."},{"metadata":{"_uuid":"5b826e94ce1dee950e92dbca418060114d744912"},"cell_type":"markdown","source":"#### Figure: Calculated Province (Sub-national) MPI - Cambodia <a class=\"anchor\" id=\"fig_calc_admin1_mpi_cambodia\"/>"},{"metadata":{"trusted":true,"_uuid":"222802ff0790218cd3c6a888a9e7077040d897b7"},"cell_type":"code","source":"create_map(cambodia_geo_gdf, admin1_dhs_mpi_df, 'feature.properties.name', 'ADM1NAME', 'mpi_admin1', 'YlOrRd',  12.5657, 104.9910, 7, cambodia_mpi_threshold_scale)","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"a4cefeb10f2875ed654bd2a8738cc6661fd294b0"},"cell_type":"markdown","source":"The same goes for the calculated MPI plot - it was not possible to match all provinces up between both datasets (DHS and cambodia geo data). A suggestion would be to search for a more up-to-date source of geo data for Cambodia, however this will be left for now. The MPIs have been calculated for every province, just not all have been plotted above."},{"metadata":{"_uuid":"03eac4d7c7202e0eddb3c9b9d61e0fedeb30782d"},"cell_type":"markdown","source":"#### Figure: Calculated Administration Level 2 MPI - Cambodia <a class=\"anchor\" id=\"fig_calc_admin2_mpi_cambodia\"/>"},{"metadata":{"trusted":true,"_uuid":"302d8b99a295090536e9323d35ee8872fddeea5c"},"cell_type":"code","source":"create_map(admin2_geo_gdf, admin2_dhs_mpi_df, 'feature.properties.DIS_NAME', 'DIS_NAME', 'mpi_admin2', 'YlOrRd',  12.5657, 104.9910, 7, cambodia_mpi_threshold_scale)","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"a7324337c0a5b5a9b8913672f1c9bb1c622b7160"},"cell_type":"markdown","source":"Notice there is a much better level of matching between names at the administrative level two, as shown by the above plot."},{"metadata":{"_uuid":"d701ba437c0ee6d44f782180155dcd153096c3c1"},"cell_type":"markdown","source":"### Summary\n"},{"metadata":{"_uuid":"cdef1ce35111b037cd5d71c591bec160fe7def38"},"cell_type":"markdown","source":"To Be Continued. "},{"metadata":{"_uuid":"482b3c14d796de6ba662f27710e824a1334a192d"},"cell_type":"markdown","source":"Please leave a comment if you have any feedback for me and vote if you like my work. Thank you."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}