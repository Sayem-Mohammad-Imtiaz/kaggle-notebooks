{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainRaw = pd.read_csv(\"../input/house-price-prediction-challenge/train.csv\")\ntestRaw = pd.read_csv(\"../input/house-price-prediction-challenge/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainRaw.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainRaw.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainRaw.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initial thoughts on columns:\n* posted_by -- categorial, Owner/Dealer/?. May be useful, to be encoded\n* under_construction -- binary, no feature eng needed\n* rera -- binary, \"rera approval\", no feature eng needed\n* bhk_no -- room count, no feature eng needed\n* square_ft -- area, nfen\n* ready_to_move -- binary, nfen\n* resale -- binary, nfen\n* address -- text, probably of no use\n* lon/lat -- could be useful but would probably require some feature engineering first? Visualisation desired\n* target -- obv"},{"metadata":{"trusted":true},"cell_type":"code","source":"oheCol = lambda colN, pref : lambda origDf : pd.concat([origDf.drop(colN, axis = 'columns'), pd.get_dummies(origDf[colN], prefix = pref)], axis = 'columns')\ndrpCol = lambda colN : lambda origDf : origDf.drop(colN, axis = 'columns')\nrenCol = lambda renD : lambda origDf : origDf.rename(columns = renD)\nfrom functools import reduce\napplyPipes = lambda sourceDf, pipes: reduce(lambda df, func: df.pipe(func), pipes, sourceDf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepPipes = [oheCol('POSTED_BY', None), oheCol('BHK_OR_RK', None), drpCol('ADDRESS'), renCol({'TARGET(PRICE_IN_LACS)': 'target'})]\ntrainPrep = applyPipes(trainRaw, prepPipes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrM = trainPrep.corr()\nprint(corrM['target'].sort_values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(corrM)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The heatmap mostly shows internal consistenty -- ready to move or resale negatively correlates with under construction, etc\n\nTaken in isolation, best features would be square feet, not-resale, room count, sold-by-builder, not-sold-by-owner"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=trainPrep['LATITUDE'], y=trainPrep['LONGITUDE'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The india in there is quite obvious. We may want to train some clustering to give us features"},{"metadata":{"trusted":true},"cell_type":"code","source":"geoClusters = 20\nfrom sklearn.cluster import KMeans\nclusteringMod = KMeans(n_clusters=geoClusters, init='k-means++')\ngeoX = trainPrep.loc[:, ['LATITUDE', 'LONGITUDE']]\ntrainPrepGc = trainPrep.assign(geoCluster=clusteringMod.fit_predict(geoX))\nsns.scatterplot(x=trainPrep['LATITUDE'], y=trainPrep['LONGITUDE'], hue=trainPrepGc['geoCluster'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"applyModel = lambda model, targetCol, inputCols: lambda df: df.assign(**{targetCol:model.predict(df.loc[:, inputCols])})\nprepPipes2 = [applyModel(clusteringMod, 'geoCluster', ['LATITUDE', 'LONGITUDE']),\n              oheCol('geoCluster', 'geoCluster_'),\n              drpCol('LATITUDE'), drpCol('LONGITUDE')]\ntrainPrep2 = applyPipes(trainPrep, prepPipes2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geoColsCorr = list(filter(lambda s: s.startswith('geo'), trainPrep2.columns)) + ['target']\ntrainPrep2.loc[:, geoColsCorr].corr()['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = trainPrep2.drop('target', axis = 'columns')\ny = trainPrep2.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.model_selection import cross_val_score\n\nscoringStrategy = 'neg_mean_absolute_error'\n\ndef evalModel(model):\n    pipeline = Pipeline(steps=[('model', model)\n                             ])\n    return evalModelPipeline(pipeline)\n\ndef evalModelPreproc(preproc, model):\n    pipeline = Pipeline(steps = [('preproc', preproc), ('model', model)])\n    return evalModelPipeline(pipeline)\n\ndef evalModelPipeline(pipeline):\n    scores = -1 * cross_val_score(pipeline, X, y,\n                              cv=5,\n                              scoring=scoringStrategy)\n                              # scoring='neg_mean_squared_log_error') # TODO the function from the competition\n    print(scores)\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nstdScaler = StandardScaler()\nscalerPreproc = ColumnTransformer(\n    transformers=[\n        ('scaler', stdScaler, ['BHK_NO.', 'SQUARE_FT'])\n    ], remainder = 'passthrough')\n\n\nmmScaler = MinMaxScaler()\nscalerMMPreproc = ColumnTransformer(\n    transformers=[\n        ('scaler', mmScaler, ['BHK_NO.', 'SQUARE_FT'])\n    ], remainder = 'passthrough')\n\nallScaler = StandardScaler()\nscalerAllPreproc = ColumnTransformer(\n    transformers = [],\n    remainder = allScaler\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyRegressor\nevalModel(DummyRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nevalModel(LinearRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPreproc(scalerPreproc, LinearRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPreproc(scalerMMPreproc, LinearRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import TransformedTargetRegressor\nevalModelPreproc(scalerMMPreproc, TransformedTargetRegressor(regressor=LinearRegression(), transformer=MinMaxScaler()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPreproc(allScaler, TransformedTargetRegressor(regressor=HuberRegressor(), transformer = MinMaxScaler()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nevalModel(RandomForestRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPreproc(scalerPreproc, RandomForestRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nrandomForestParams = {'n_estimators': [40, 160, 320]}\ngsRandomForest = GridSearchCV(RandomForestRegressor(),\n                              randomForestParams, scoring = scoringStrategy)\n\ngsRandomForest.fit(X, y)\nprint(gsRandomForest.cv_results_['mean_test_score'])\nprint(gsRandomForest.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nevalModel(GradientBoostingRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPreproc(scalerPreproc, GradientBoostingRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalModelPreproc(scalerMMPreproc, GradientBoostingRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradientBoostingParams = {\"n_estimators\": [10, 100, 200], \"learning_rate\": [0.01, 0.1, 1.0], \"max_depth\": [1, 3, 10]}\ngsGradientBoosting = GridSearchCV(GradientBoostingRegressor(), gradientBoostingParams, scoring = scoringStrategy)\n\ngsGradientBoosting.fit(X, y)\nprint(gsGradientBoosting.cv_results_['mean_test_score'])\nprint(gsGradientBoosting.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perhapsGoodModel = RandomForestRegressor(n_estimators = 320)\nperhapsGoodModel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testPrep2 = applyPipes(testRaw, prepPipes+prepPipes2)\nperhapsOutput = perhapsGoodModel.predict(testPrep2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(perhapsOutput).to_csv(\"sub01-naive_randomForest.csv\", header = [\"TARGET(PRICE_IN_LACS)\"], index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor, plot_tree, export_graphviz\nfrom sklearn.metrics import mean_absolute_error\nimport graphviz\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.model_selection import train_test_split\nfrom IPython.core.display import display\n\ndef plotTree():\n    treeModel = DecisionTreeRegressor(min_samples_leaf = 4, max_depth = 5)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.9)\n    treeModel.fit(X_train, y_train)\n    print(mean_absolute_error(y_test, treeModel.predict(X_test)))\n    perm = PermutationImportance(treeModel).fit(X_test, y_test)\n    display(eli5.show_weights(perm, feature_names = X.columns.tolist()))\n    # plot_tree(treeModel)\n    treeGraph = export_graphviz(treeModel, out_file=None, feature_names=X.columns)\n    graph = graphviz.Source(treeGraph)\n    return graph\nplotTree()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getSplitSizeStats(test_size, model):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n    model.fit(X_train, y_train)\n    return[test_size, mean_absolute_error(y_train, model.predict(X_train)), mean_absolute_error(y_test, model.predict(X_test))]\n[getSplitSizeStats(j, DecisionTreeRegressor(min_samples_leaf = 4, max_depth = 5)) for j in np.linspace(0.01, 0.9, 20)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[getSplitSizeStats(j, LinearRegression()) for j in np.linspace(0.01, 0.9, 20)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame([getSplitSizeStats(j, LinearRegression()) for j in [0.2]*40]).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = Pipeline(steps = [('preproc', scalerPreproc), ('model', LinearRegression())])\n[getSplitSizeStats(j, p) for j in np.linspace(0.01, 0.9, 20)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data = trainPrep2.query('SQUARE_FT < 1500 & target < 400'), x='SQUARE_FT', y = 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data = trainPrep2.query('SQUARE_FT < 3000'), x='SQUARE_FT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data = trainPrep2.query('SQUARE_FT < 3000 & target < 2000').sample(frac=0.1), x='SQUARE_FT', y = 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data = trainPrep2.query('SQUARE_FT > 3000 & SQUARE_FT < 6000').sample(frac=0.1), x='SQUARE_FT', y = 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(data = trainPrep2.query('SQUARE_FT < 3000 & target > 2000'), x='SQUARE_FT', y = 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data = trainPrep2.query('target < 600'), x='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(data = np.log10(trainPrep2.target))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPrep2.query('target < 1000').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPrep2.query('target >= 1000').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treeModel = RandomForestRegressor(n_estimators = 320)\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8)\ntrain = trainPrep2.sample(frac=0.4)\ntest = trainPrep2.sample(frac=0.1)\nX_train, X_test, y_train, y_test = train.drop('target', axis = 'columns'), test.drop('target', axis = 'columns'), train.target, test.target\ntreeModel.fit(X_train, y_train)\nprint(mean_absolute_error(y_test, treeModel.predict(X_test)))\nperm = PermutationImportance(treeModel).fit(X_test, y_test)\ndisplay(eli5.show_weights(perm, feature_names = X.columns.tolist()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linModel = LinearRegression()\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8)\ntrain = pd.concat([trainPrep2.sample(frac=0.4), trainPrep2.query('target > 1000').sample(frac=0.5)])\ntest = pd.concat([trainPrep2.sample(frac=0.1), trainPrep2.query('target > 1000').sample(frac=0.5)])\nX_train, X_test, y_train, y_test = train.drop('target', axis = 'columns'), test.drop('target', axis = 'columns'), train.target, test.target\nlinModel.fit(X_train, y_train)\nprint(mean_absolute_error(y_test, linModel.predict(X_test)))\nprint(mean_absolute_error(y_train, linModel.predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainPrep3 = trainPrep2.assign(isExp=(trainPrep2.target > 1000).astype(int))\ntrainPrep3.loc[:, 'isExp'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\nfrom sklearn.metrics import f1_score\ndef plotTree2(data):\n    # treeModel = DecisionTreeRegressor(min_samples_leaf = 4, max_depth = 5)\n    treeModel = DecisionTreeClassifier(min_samples_leaf = 4, max_depth = 5)\n    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.9)\n    train = pd.concat([data.sample(frac=0.4), data.query('target > 1000').sample(frac=0.5)])\n    test = pd.concat([data.sample(frac=0.1), data.query('target > 1000').sample(frac=0.5)])\n    X_train, X_test, y_train, y_test = train.drop(['target', 'isExp'], axis = 'columns'), test.drop(['target', 'isExp'], axis = 'columns'), train.isExp, test.isExp\n    treeModel.fit(X_train, y_train)\n    print(f1_score(y_test, treeModel.predict(X_test)))\n    print(f1_score(y_train, treeModel.predict(X_train)))\n    perm = PermutationImportance(treeModel).fit(X_test, y_test)\n    display(eli5.show_weights(perm, feature_names = X.columns.tolist()))\n    # plot_tree(treeModel)\n    treeGraph = export_graphviz(treeModel, out_file=None, feature_names=X.columns)\n    graph = graphviz.Source(treeGraph)\n    return graph\nplotTree2(trainPrep3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"expensive = trainPrep3.query('isExp == 1')\n# expensive divide 0.5-0.5\nexpensiveSelector = np.random.randint(2, size=len(expensive)).astype('bool')\n# cheap divide 0.25 - 0.75\ncheap = trainPrep3.query('isExp == 0')\ncheapSelector = np.random.choice(2, size=len(cheap), p=[0.25, 0.75]).astype('bool')\n\ntrainExpensive = expensive.loc[expensiveSelector, :]\ntestExpensive = expensive.loc[~expensiveSelector, :]\ntrainCheap = cheap.loc[cheapSelector, :]\ntestCheap = cheap.loc[~cheapSelector, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# splitter = DecisionTreeClassifier(min_samples_leaf = 4, max_depth = 5)\nsplitter = RandomForestClassifier(n_estimators = 160)\ntrainAll = pd.concat([trainExpensive, trainCheap])\ntestAll = pd.concat([testExpensive, testCheap])\nsplitter.fit(trainAll.drop(['isExp', 'target'], axis = 'columns'), trainAll.isExp)\nprint(f1_score(testAll.isExp, splitter.predict(testAll.drop(['isExp', 'target'], axis = 'columns'))))\nlinRegExp = LinearRegression()\nlinRegChe = LinearRegression()\nlinRegExp.fit(trainExpensive.drop(['isExp', 'target'], axis = 'columns'), trainExpensive.target)\nprint(mean_absolute_error(testExpensive.target, linRegExp.predict(testExpensive.drop(['isExp', 'target'], axis = 'columns'))))\nlinRegChe.fit(trainCheap.drop(['isExp', 'target'], axis = 'columns'), trainCheap.target)\nprint(mean_absolute_error(testCheap.target, linRegExp.predict(testCheap.drop(['isExp', 'target'], axis = 'columns'))))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time to give up.\n\nI'm struggling with the fact that there are some houses in the dataset which have very high target value yet seem hard to separate.\nLinear models in particular suffer from it, as sometimes the predicted values go really crazy.\n\nThe last attempt was to train a decision tree first to do that, and that have linear regression classifiers on each of the subset.\nBut that produced pretty ashaming scores.\n\nOverall, nothing seems to realistically beat just a Decision Tree."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}