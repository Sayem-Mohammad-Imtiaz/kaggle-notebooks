{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imports and Installs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imports\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport re\nfrom wordcloud import WordCloud, STOPWORDS\nimport ast\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\nfrom IPython.display import Image\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_df = pd.read_csv('/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Datetime Conversion\ntweet_df[\"date\"] =pd.to_datetime(tweet_df[\"date\"]).dt.date\n\ntweet_df[\"ctext\"] =tweet_df.text.str.lower()\n\n#Remove twitter handlers\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub('@[^\\s]+','',x))\n\n#remove hashtags\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r'\\B#\\S+','',x))\n\n\n# Remove URLS\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n\n# Remove all the special characters\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n\n#remove all single characters\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n\n# Substituting multiple spaces with single space\ntweet_df.ctext = tweet_df.ctext.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n\ntweet_df.sort_values(\"date\", inplace=True)\ntweet_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"date_wise_count = tweet_df.groupby(\"date\").agg({\n    \"text\":\"count\"\n}).sort_values(\"date\").reset_index()\nplt.rcParams[\"figure.figsize\"] = (15,5)\nplt.plot(date_wise_count[\"date\"],date_wise_count[\"text\"],'--X', color='green')\nplt.legend([\"Number of Tweets\"])\nplt.title(\"Frequency of Tweets\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locationWise = tweet_df.user_location.value_counts().plot(title='Location with most Tweets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Popular Hashtags"},{"metadata":{"trusted":true},"cell_type":"code","source":"hashtags = []\nfor tags in tweet_df.hashtags.unique():\n    if not(tags is np.nan):\n        for _ in ast.literal_eval(tags):\n            hashtags.append(_)\ntext =''\nfor _ in hashtags:\n    text+=\" \"+_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a function to plot word cloud\ndef plot_cloud(wordcloud):\n    plt.figure(figsize=(40, 30))\n    plt.title(\"Popular HashTags\")\n    plt.imshow(wordcloud) \n    plt.axis(\"off\");\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate word cloud and Plot\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(text)\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Popular @'s"},{"metadata":{"trusted":true},"cell_type":"code","source":"# All \"@'s\"\nat = []\nfor text in tweet_df.text.unique():\n    text = re.findall('@[^\\s]+',text )\n    for _ in text:\n        at.append(_)\n\nats = \"\"\nfor _ in at:\n    ats+=_+\" \"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate word cloud and Plot\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(ats)\nplot_cloud(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Sentiment Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sid = SentimentIntensityAnalyzer()\ndef sentiments(sentence):\n    ss = sid.polarity_scores(sentence)\n    return (ss[\"pos\"], ss[\"neg\"])\ntweet_df[\"sentiments\"] =tweet_df[\"ctext\"].apply(lambda x: sentiments(x))\ntweet_df[\"text_blob_sentiment\"] =tweet_df[\"ctext\"].apply(lambda x: TextBlob(x).sentiment.polarity) \ntweet_df[\"pos_sentiments\"] =tweet_df[\"sentiments\"].apply(lambda x: float(x[0]))\ntweet_df[\"neg_sentiments\"] =tweet_df[\"sentiments\"].apply(lambda x: float(x[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gtf=tweet_df.groupby(\"date\").agg({\n    \"pos_sentiments\": [\"max\",\"mean\"],\n    \"neg_sentiments\": [\"min\",\"mean\"],\n    \"text_blob_sentiment\":\"mean\"\n}).reset_index()\ngtf.columns= [\"date\",\"ps_max\",\"ps_mean\", \"ns_min\",\"ns_mean\",\"tb_senti_mean\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(gtf[\"date\"],gtf[\"ps_mean\"], 'green' )\nplt.plot(gtf[\"date\"],gtf[\"ns_mean\"], 'red' )\nplt.legend([\"Positive Sentiment\",\"Negative Sentiment\"])\nplt.title(\"Positive and Negative Sentiments of Tweets\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(gtf[\"date\"],gtf[\"ps_mean\"]-gtf[\"ns_mean\"], \"blue\")\nplt.plot(gtf[\"date\"],gtf[\"tb_senti_mean\"], 'green')\nplt.legend([\"Vader Avg Sentiment\", \"Text Blob Avg Sentiment\"])\nplt.title(\"Average Sentiments of Tweets By TextBlob and Vader\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two series **Sentiment By Vader** and **Sentiment By TextBlob** are almost parallel. We may improve accuracy of Sentiments by **Training BERT Sentiment classifier** or any any other Neural Network Model. Leaving it for future improvements. "},{"metadata":{},"cell_type":"markdown","source":"## **What happend after 15 jan ?**\nBelow news might be the reason for Negative Sentiments on Pfizer Vaccine\n!Image(\"../input/newscreenshot/NewsScreenshot.png\")\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/newscreenshot/NewsScreenshot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Fetch some information from Tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers==3.0 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting a model\nfrom transformers import BertTokenizer\nPRE_TRAINED_MODEL_NAME = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query=\"Is Covid Vaccine Work \"\nquery_embedding = tokenizer.encode(query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = tokenizer.encode(tweet_df['ctext'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_k=5\ncos_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\ncos_scores = cos_scores.cpu()\n\n#We use torch.topk to find the highest 5 scores\ntop_results = torch.topk(cos_scores, k=top_k)\n\nprint(\"\\n\\n======================\\n\\n\")\nprint(\"Query:\", query)\nprint(\"\\nTop 5 most similar sentences in corpus:\")\n\nfor score, idx in zip(top_results[0], top_results[1]):\n    print(data['text'].values[idx], \"(Score: %.4f)\" % (score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(tweet_df['ctext'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}