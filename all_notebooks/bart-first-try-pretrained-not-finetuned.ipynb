{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U rouge transformers > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas()\nfrom IPython.display import display, Markdown\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd \n\nimport torch\nimport transformers\nfrom transformers import BartTokenizer, BartForConditionalGeneration\n\nfrom nltk.tokenize import sent_tokenize","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read data"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_CRYPTO_NEWS = Path('../input/news-about-major-cryptocurrencies-20132018-40k/')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_CRYPTO_NEWS / 'crypto_news_parsed_2013-2017_train.csv')\nvalid_df = pd.read_csv(PATH_TO_CRYPTO_NEWS / 'crypto_news_parsed_2018_validation.csv')\n\n# readling empty strings is a bit different locally and here, but not a big deal \ntrain_df['text'].fillna(' ', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, valid_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def minimal_processing(s):\n    return s.strip().replace('\\r', '').replace('\\n', ' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_and_process_first_k_sent(text, k=3):\n    \n    sent_tok = sent_tokenize(text)\n    \n    if not sent_tok:\n        return ' '\n    \n    result = \" \".join([minimal_processing(sent.strip(' .').lower()) \n                                 for sent in sent_tok[:k]])\n    \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_texts = train_df['text'].progress_apply(lambda text: \n#                                               extract_and_process_first_k_sent(text))\n\nvalid_texts = valid_df['text'].progress_apply(lambda text: \n                                              extract_and_process_first_k_sent(text, k=10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BART\nFollowing [this blog post](https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BartTokenizer.from_pretrained('bart-large-cnn')\nmodel = BartForConditionalGeneration.from_pretrained('bart-large-cnn').to(torch_device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generating a title for the first article**"},{"metadata":{"trusted":true},"cell_type":"code","source":"example_text = train_df.loc[0, 'text']\nexample_title = train_df.loc[0, 'title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(Markdown('> **Title:** ' + example_title))\ndisplay(Markdown('> **Text:** ' + example_text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"article_input_ids = tokenizer.batch_encode_plus([example_text], \n                                                return_tensors='pt', \n                                                max_length=128)['input_ids'].to(torch_device)\nsummary_ids = model.generate(article_input_ids,\n                             num_beams=4,\n                             length_penalty=2.0,\n                             max_length=20,\n                             min_length=5,\n                             no_repeat_ngram_size=3)\n\nsummary_txt = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\ndisplay(Markdown('> **Summary:** ' + summary_txt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **Now same for the whole validation set**"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bs = 32\n\nval_summaries = []\n\nfor i in tqdm(range(0, len(valid_texts), bs)):\n\n    article_input_ids = tokenizer.batch_encode_plus(valid_texts.iloc[i:i+bs].tolist(), \n                                                    return_tensors='pt', pad_to_max_length=True,\n                                                    max_length=512)['input_ids'].to(torch_device)\n    \n    summary_ids = model.generate(article_input_ids,\n                             num_beams=4,\n                             length_penalty=2.0,\n                             max_length=40,\n                             min_length=5,\n                             no_repeat_ngram_size=3)\n    \n    val_summaries.extend([tokenizer.decode(summary_ids[i].squeeze(), skip_special_tokens=True).lower()\n            for i in range(len(summary_ids))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_summaries[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_titles = valid_df['title'].str.lower().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from rouge import Rouge \n\nrouge = Rouge()\nscores = rouge.get_scores(hyps=[el.split('.')[0] for el in val_summaries], refs=valid_titles, \n                          avg=True, ignore_empty=True)\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_metric = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3\nfinal_metric","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Eyeballing the resuls: good and bad cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_res_df = pd.DataFrame({'title': valid_titles, \n                           'generated': val_summaries,\n                          'text': valid_texts.values}).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_rouge_scores = rouge.get_scores(hyps=val_summaries, refs=valid_titles, avg=False, ignore_empty=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_res_df['rouge-1'] = [el['rouge-1']['f'] for el in val_rouge_scores]\nval_res_df['rouge-2'] = [el['rouge-2']['f'] for el in val_rouge_scores]\nval_res_df['rouge-L'] = [el['rouge-l']['f'] for el in val_rouge_scores]\nval_res_df['avg_rouge'] = (val_res_df['rouge-1'] + val_res_df['rouge-2'] + val_res_df['rouge-L']) / 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_res_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_result(row):\n    print('_' * 68)\n    display(Markdown('> **Rouge:** ' + str(round(row['avg_rouge'], 3))))\n    display(Markdown('> **Title:** ' + row['title']))\n    display(Markdown('> **Text:** ' + row['text']))\n    display(Markdown('> **Generated:** ' + row['generated']))\n    print('_' * 68)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _, row in val_res_df.sort_values(by='avg_rouge', ascending=False).head(30).iterrows():\n    print_result(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _, row in val_res_df.sort_values(by='avg_rouge', ascending=True).head(30).iterrows():\n    print_result(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_res_df.to_csv('val_set_with_bart_generated_titles.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:py36_pytorch]","language":"python","name":"conda-env-py36_pytorch-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":4}