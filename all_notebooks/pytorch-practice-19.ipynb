{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=Akronim&effect=3d';      \n    </style><h1 class='font-effect-3d' \n    style='font-family:Akronim; color:#33ffcc;'>\n    %s</h1>\"\"\"%str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/rnn/rnn_lstm_packed_imdb.ipynb)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('Code Modules, Functions, & Classes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np,pylab as pl\nimport torch,random,spacy,pandas as pd\nimport torch.nn as tnn\nimport torch.nn.functional as tnnf\nfrom torchtext import data as ttdata\nfrom torchtext import datasets as ttds\ntorch.backends.cudnn.deterministic=True\ndev=torch.device('cuda' \\\nif torch.cuda.is_available() else 'cpu')\nnlp=spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D,\\\nMaxPooling1D,Dense,LSTM,Embedding\nfrom tensorflow.keras.preprocessing import \\\nsequence as ksequence\nfrom tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.callbacks import \\\nModelCheckpoint,ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def bin_accuracy(model,data_loader):\n    model.eval()\n    correct_pred,num_examples=0,0\n    with torch.no_grad():\n        for batch_ids,batch_data in enumerate(data_loader):\n            text,text_lengths=batch_data.text\n            logits=model(text,text_lengths)\n            predicted_labels=(torch.sigmoid(logits)>.5).long()\n            num_examples+=batch_data.label.size(0)\n            correct_pred+=(predicted_labels==\\\n                           batch_data.label.long()).sum()\n        return correct_pred.float()/num_examples*100\ndef predict_sentiment(model,sentence):\n    model.eval()\n    tokenized=[tok.text for tok in nlp.tokenizer(sentence)]\n    indexed=[ttext.vocab.stoi[t] for t in tokenized]\n    length_tensor=torch.LongTensor([len(indexed)])\n    tensor=torch.LongTensor(indexed).to(dev)\n    tensor=tensor.unsqueeze(1)\n    prediction=torch.sigmoid(model(tensor,length_tensor))\n    return prediction.item() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('Data')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_state=random.seed(12)\nids='train valid test'.split()\nttext=ttdata.Field(tokenize='spacy',\n                   include_lengths=True)\ntlabel=ttdata.LabelField(dtype=torch.float)\ntrain,test=ttds.IMDB.splits(ttext,tlabel)\ntrain,valid=train\\\n.split(random_state=random_state,split_ratio=.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame([len(el) for el in [train,valid,test]],\n    index=ids,columns=['length']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=23\ntorch.manual_seed(random_seed)\nvocab_size=20000; batch_size=128\nttext.build_vocab(train,max_size=vocab_size)\ntlabel.build_vocab(train)\nnum_clases=tlabel.vocab\ninput_dim=len(ttext.vocab); output_dim=1\ntrain_loader,valid_loader,test_loader=\\\nttdata.BucketIterator.splits((train,valid,test),\\\nbatch_size=batch_size,sort_within_batch=True,device=dev)\ndel train,test,valid\ndataloaders={ids[0]:train_loader,\n             ids[1]:valid_loader,\n             ids[2]:test_loader}\nfor i in range(3):\n    print(ids[i])\n    for batch in dataloaders[ids[i]]:\n        print(f'text matrix: {batch.text[0].size()}')\n        print(f'label vector: {batch.label.size()}')\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# 25,000 movies reviews from IMDB, \n# labeled by sentiment (positive/negative)\nnum_words,max_length,embedding_vector_len=\\\n10000,1000,32\n(x_train,y_train),(x_test,y_test)=\\\nimdb.load_data(path=\"imdb_full.pkl\",num_words=num_words,\n               skip_top=0,maxlen=max_length,seed=113,\n               start_char=1,oov_char=2,index_from=3)\nx_test,x_valid,y_test,y_valid=\\\ntrain_test_split(x_test,y_test,\n                 test_size=.5,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"print(x_train.shape,x_valid.shape,x_test.shape)\nprint('Label: ',y_train[1]) \nprint('Sequence of word indices: \\n',x_train[1])\npx_train=ksequence\\\n.pad_sequences(x_train,maxlen=max_length)\npx_valid=ksequence\\\n.pad_sequences(x_valid,maxlen=max_length)\npx_test=ksequence\\\n.pad_sequences(x_test,maxlen=max_length)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Basic RNNs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNN(tnn.Module):\n    def __init__(self,input_dim,embedding_dim,\n                 hidden_dim,output_dim):      \n        super().__init__()    \n        self.embedding=tnn.Embedding(input_dim,embedding_dim)\n        self.rnn=tnn.LSTM(embedding_dim,hidden_dim)\n        self.fc=tnn.Linear(hidden_dim,output_dim)    \n    def forward(self,text,text_length):\n        embedded=self.embedding(text)\n        packed=tnn.utils.rnn\\\n        .pack_padded_sequence(embedded,text_length)\n        packed_output,(hidden,cell)=self.rnn(packed)\n        return self.fc(hidden.squeeze(0)).view(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kmodel():\n    model=Sequential()\n    model.add(Embedding(num_words,embedding_vector_len,\n                        input_length=max_length))\n    model.add(Conv1D(filters=32,kernel_size=3,\n                     padding='same',activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))   \n    model.add(LSTM(32))    \n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(loss='binary_crossentropy',\n                  optimizer='nadam',metrics=['accuracy'])    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=34; learning_rate=1e-4\ntorch.manual_seed(random_seed)\nembedding_dim=128; hidden_dim=256\nmodel=RNN(input_dim,embedding_dim,\n          hidden_dim,output_dim)\nmodel=model.to(dev)\noptimizer=torch.optim\\\n.Adam(model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=10\nfor epoch in range(epochs):\n    model.train()\n    for batch_ids,batch_data in enumerate(train_loader):\n        text,text_lengths=batch_data.text\n        logits=model(text,text_lengths)\n        cost=tnnf.binary_cross_entropy_with_logits(logits,\n                                                   batch_data.label)\n        optimizer.zero_grad()\n        cost.backward(); optimizer.step()\n        if not batch_ids%100:\n            print (f'Epoch: {epoch+1:03d}/{epochs:03d} | '\n                   f'Batch: {batch_ids:03d}/{len(train_loader):03d} | '\n                   f'Cost: {cost:.6f}')\n    with torch.set_grad_enabled(False):\n        print(f'training acc: '\n              f'{bin_accuracy(model,train_loader):.2f}%'\n              f'\\nvalid acc: '\n              f'{bin_accuracy(model,valid_loader):.2f}%')\nprint(f'test acc: {bin_accuracy(model,test_loader):.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"kmodel=kmodel()\nfw='weights.best.hdf5'\ncheckpointer=\\\nModelCheckpoint(filepath=fw,verbose=2,\n                save_best_only=True)\nlr_reduction=\\\nReduceLROnPlateau(monitor='val_loss',patience=10,\n                  verbose=2,factor=.5)\nhistory=kmodel.fit(px_train,y_train,epochs=5,batch_size=128,\n                   validation_data=(px_valid,y_valid),\n                   callbacks=[checkpointer,lr_reduction])\nkmodel.load_weights(fw)\nkmodel.evaluate(px_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Predictions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('probability of being positive:')\nsent='I really love this movie. The actor team here is so great!'\npredict_sentiment(model,sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2index=imdb.get_word_index()\nsent=sent.lower().replace('.','').replace('!','')\nsent_index=[]\nfor word in sent.split():\n     sent_index.append(word2index[word])\nsent_index=ksequence.pad_sequences([sent_index],\n                                   maxlen=max_length)\nkmodel.predict(sent_index)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}