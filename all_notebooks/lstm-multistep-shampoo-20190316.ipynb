{"cells":[{"metadata":{"trusted":true,"_uuid":"d692f14ceb9d5e5b9941b51d6b31bfee2ca8a4e0"},"cell_type":"code","source":"from pandas import DataFrame\nfrom pandas import Series\nfrom pandas import concat\nfrom pandas import read_csv\nfrom pandas import datetime\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom math import sqrt\nfrom matplotlib import pyplot\nfrom numpy import array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26dec967f2fd24911ac3c90a19a823f3caf0287c"},"cell_type":"code","source":"# date-time parsing function for loading the dataset\ndef parser(x):\n\treturn datetime.strptime('190'+x, '%Y-%m')\n\n# convert time series into supervised learning problem\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf = DataFrame(data)\n\tcols, names = list(), list()\n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df.shift(i))\n\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df.shift(-i))\n\t\tif i == 0:\n\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n\t\telse:\n\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n\t# put it all together\n\tagg = concat(cols, axis=1)\n\tagg.columns = names\n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg\n\n# create a differenced series\ndef difference(dataset, interval=1):\n\tdiff = list()\n\tfor i in range(interval, len(dataset)):\n\t\tvalue = dataset[i] - dataset[i - interval]\n\t\tdiff.append(value)\n\treturn Series(diff)\n\n# transform series into train and test sets for supervised learning\ndef prepare_data(series, n_test, n_lag, n_seq):\n\t# extract raw values\n\traw_values = series.values\n\t# transform data to be stationary\n\tdiff_series = difference(raw_values, 1)\n\tdiff_values = diff_series.values\n\tdiff_values = diff_values.reshape(len(diff_values), 1)\n\t# rescale values to -1, 1\n\tscaler = MinMaxScaler(feature_range=(-1, 1))\n\tscaled_values = scaler.fit_transform(diff_values)\n\tscaled_values = scaled_values.reshape(len(scaled_values), 1)\n\t# transform into supervised learning problem X, y\n\tsupervised = series_to_supervised(scaled_values, n_lag, n_seq)\n\tsupervised_values = supervised.values\n\t# split into train and test sets\n\ttrain, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n\treturn scaler, train, test\n\n# fit an LSTM network to training data\ndef fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n\t# reshape training into [samples, timesteps, features]\n\tX, y = train[:, 0:n_lag], train[:, n_lag:]\n\tX = X.reshape(X.shape[0], 1, X.shape[1])\n\t# design network\n\tmodel = Sequential()\n\tmodel.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n\tmodel.add(Dense(y.shape[1]))\n\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n\t# fit network\n\tfor i in range(nb_epoch):\n\t\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=1, shuffle=False)\n\t\tmodel.reset_states()\n\treturn model\n\n# make one forecast with an LSTM,\ndef forecast_lstm(model, X, n_batch):\n\t# reshape input pattern to [samples, timesteps, features]\n\tX = X.reshape(1, 1, len(X))\n\t# make forecast\n\tforecast = model.predict(X, batch_size=n_batch)\n\t# convert to array\n\treturn [x for x in forecast[0, :]]\n\n# evaluate the persistence model\ndef make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n\tforecasts = list()\n\tfor i in range(len(test)):\n\t\tX, y = test[i, 0:n_lag], test[i, n_lag:]\n\t\t# make forecast\n\t\tforecast = forecast_lstm(model, X, n_batch)\n\t\t# store the forecast\n\t\tforecasts.append(forecast)\n\treturn forecasts\n\n# invert differenced forecast\ndef inverse_difference(last_ob, forecast):\n\t# invert first forecast\n\tinverted = list()\n\tinverted.append(forecast[0] + last_ob)\n\t# propagate difference forecast using inverted first value\n\tfor i in range(1, len(forecast)):\n\t\tinverted.append(forecast[i] + inverted[i-1])\n\treturn inverted\n\n# inverse data transform on forecasts\ndef inverse_transform(series, forecasts, scaler, n_test):\n\tinverted = list()\n\tfor i in range(len(forecasts)):\n\t\t# create array from forecast\n\t\tforecast = array(forecasts[i])\n\t\tforecast = forecast.reshape(1, len(forecast))\n\t\t# invert scaling\n\t\tinv_scale = scaler.inverse_transform(forecast)\n\t\tinv_scale = inv_scale[0, :]\n\t\t# invert differencing\n\t\tindex = len(series) - n_test + i - 1\n\t\tlast_ob = series.values[index]\n\t\tinv_diff = inverse_difference(last_ob, inv_scale)\n\t\t# store\n\t\tinverted.append(inv_diff)\n\treturn inverted\n\n# evaluate the RMSE for each forecast time step\ndef evaluate_forecasts(test, forecasts, n_lag, n_seq):\n\tfor i in range(n_seq):\n\t\tactual = [row[i] for row in test]\n\t\tpredicted = [forecast[i] for forecast in forecasts]\n\t\trmse = sqrt(mean_squared_error(actual, predicted))\n\t\tprint('t+%d RMSE: %f' % ((i+1), rmse))\n\n# plot the forecasts in the context of the original dataset\ndef plot_forecasts(series, forecasts, n_test):\n\t# plot the entire dataset in blue\n\tpyplot.plot(series.values)\n\t# plot the forecasts in red\n\tfor i in range(len(forecasts)):\n\t\toff_s = len(series) - n_test + i - 1\n\t\toff_e = off_s + len(forecasts[i]) + 1\n\t\txaxis = [x for x in range(off_s, off_e)]\n\t\tyaxis = [series.values[off_s]] + forecasts[i]\n\t\tpyplot.plot(xaxis, yaxis, color='red')\n\t# show the plot\n\tpyplot.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26c0bf31a8a368c3c28c48f398254b943469b55b"},"cell_type":"code","source":"# load dataset\nseries = read_csv('../input/shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n# summarize first few rows\nprint(series.head())\n# line plot\nseries.plot()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"1f72b1a22bd49d0743c0bdf0c07f1108bfa5dc03"},"cell_type":"code","source":"# configure\nn_lag = 1\nn_seq = 5\nn_test = 10\n# prepare data\nscaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n\nprint(test)\nprint('Scaler: %s, Train: %s, Test: %s' % (scaler, train.shape, test.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58edaf9575fc6e13526bf750abcb0bbf9e03e70e"},"cell_type":"code","source":"# configure\nn_epochs = 1500\nn_batch = 1\nn_neurons = 1\n# fit model\nmodel = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b35f11b8f1d97e14b208c547543fcb334279f80"},"cell_type":"code","source":"# make forecasts\nforecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n# inverse transform forecasts and test\nforecasts = inverse_transform(series, forecasts, scaler, n_test+2)\nactual = [row[n_lag:] for row in test]\nactual = inverse_transform(series, actual, scaler, n_test+2)\n# evaluate forecasts\nevaluate_forecasts(actual, forecasts, n_lag, n_seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5c018d4c8f78b779c1271750ec4928735cc7f75"},"cell_type":"code","source":"# plot forecasts\nplot_forecasts(series, forecasts, n_test+2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2853d2f0a6a18c14c7edf3377dff8d4d73c61e91"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}