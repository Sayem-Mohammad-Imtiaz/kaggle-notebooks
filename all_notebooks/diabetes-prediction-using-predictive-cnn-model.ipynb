{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I have implemented Diabetes Prediction using 6 approaches such as **KNN, Decision Tree,Random Forest, Voting Classifier and CNN model**. Random Forest is one of the most popular machine learning algorithm these days. It works well for both types of tasks - regression and classification.\n\nIf this helps you, do give UPVOTES as your UPVOTES would be very much appreciated â€“ as they are the source of motivation!\n\nHappy learning","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n%matplotlib inline\n\nsns.set_style('darkgrid')\ndf = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()\n\nprint(\"Shape of Data is ==> \",df.shape)\ndf.info()\n\ndf.describe().T\n\nfor i in df.columns:\n    print(i)\n    \ndf.rename({'DiabetesPedigreeFunction':'DPF'},inplace = True,axis =1)\ndf.head()\n\ndf.dtypes\n\ndef std_based(col_name,df):\n    mean = df[col_name].mean()\n    std = df[col_name].std()\n    cut_off = std * 3\n    lower, upper = mean - cut_off, mean + cut_off\n    new_df = df[(df[col_name] < upper) & (df[col_name] > lower)]\n    return new_df\n\ndf.isnull().sum()\n\ndf['Pregnancies'].describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Pregnancies'],ax=axes[0],color='m')\naxes[0].set_title('Distribution of Pregnancy',fontdict={'fontsize':8})\naxes[0].set_xlabel('Pregnancy Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Pregnancies',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\n#Treating Outlier and then verifying it\n\ndf = std_based('Pregnancies',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Pregnancies'],ax=axes[0],color='red')\naxes[0].set_title('Distribution of Pregnancy',fontdict={'fontsize':8})\naxes[0].set_xlabel('Pregnancy Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Pregnancies',data=df,ax=axes[1],orient = 'v',color='yellow')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf['Glucose'].describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Glucose'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of Glucose',fontdict={'fontsize':8})\naxes[0].set_xlabel('Glucose Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Glucose',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.Glucose = df.Glucose.replace(0,df.Glucose.mean())\ndf.head()\n\ndf.BloodPressure.describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BloodPressure'],ax=axes[0],color='m')\naxes[0].set_title('Distribution of BloodPressure',fontdict={'fontsize':8})\naxes[0].set_xlabel('BloodPressure Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BloodPressure',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.BloodPressure = df.BloodPressure.replace(0,df.BloodPressure.median())\ndf.head()\n\ndf  = std_based('BloodPressure',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BloodPressure'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of BloodPressure',fontdict={'fontsize':8})\naxes[0].set_xlabel('BloodPressure Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BloodPressure',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.SkinThickness.describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['SkinThickness'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of SkinThickness',fontdict={'fontsize':8})\naxes[0].set_xlabel('SkinThickness Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('SkinThickness',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.SkinThickness = df.SkinThickness.replace(0,df.SkinThickness.mean())\ndf.head()\n\ndf = std_based(\"SkinThickness\",df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['SkinThickness'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of SkinThickness',fontdict={'fontsize':8})\naxes[0].set_xlabel('SkinThickness Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('SkinThickness',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.Insulin.describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Insulin'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of Insulin',fontdict={'fontsize':8})\naxes[0].set_xlabel('Insulin Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Insulin',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.Insulin = df.Insulin.replace(0,df.Insulin.median())\ndf.head()\n\ndf = std_based('Insulin',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Insulin'],ax=axes[0],color='r')\naxes[0].set_title('Distribution of Insulin',fontdict={'fontsize':8})\naxes[0].set_xlabel('Insulin Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Insulin',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.BMI.describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BMI'],ax=axes[0],color='b')\naxes[0].set_title('Distribution of BMI',fontdict={'fontsize':8})\naxes[0].set_xlabel('BMI Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BMI',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.BMI = df.BMI.replace(0,df.BMI.mean())\ndf.head()\n\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['BMI'],ax=axes[0],color='m')\naxes[0].set_title('Distribution of BMI',fontdict={'fontsize':8})\naxes[0].set_xlabel('BMI Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('BMI',data=df,ax=axes[1],orient = 'v',color='c')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.DPF.describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['DPF'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of DPF',fontdict={'fontsize':8})\naxes[0].set_xlabel('DPF Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('DPF',data=df,ax=axes[1],orient = 'v',color='m')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf = std_based('DPF',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['DPF'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of DPF',fontdict={'fontsize':8})\naxes[0].set_xlabel('DPF Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('DPF',data=df,ax=axes[1],orient = 'v')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.Age.describe()\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Age'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of Age',fontdict={'fontsize':8})\naxes[0].set_xlabel('Age Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Age',data=df,ax=axes[1],orient = 'v')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf = std_based('Age',df)\n\nfig,axes = plt.subplots(nrows=1,ncols=2,dpi=120,figsize = (8,4))\n\nplot00=sns.distplot(df['Age'],ax=axes[0],color='green')\naxes[0].set_title('Distribution of Age',fontdict={'fontsize':8})\naxes[0].set_xlabel('Age Class',fontdict={'fontsize':7})\naxes[0].set_ylabel('Frequency/Distrubtion',fontdict={'fontsize':7})\nplt.tight_layout()\n\n\nplot01=sns.boxplot('Age',data=df,ax=axes[1],orient = 'v')\naxes[1].set_title('Five Point Summary',fontdict={'fontsize':8})\nplt.tight_layout()\n\ndf.head()\n\ndf.shape\n\n\ndf.info()\n\ndf.var()\n\ndf.drop('DPF',axis = 1,inplace=True)\n\ndf.Outcome.value_counts()\n\nsns.countplot(df['Outcome']).set_title('Distribution of Outcome')\nplt.show()\n\nx=df.iloc[:,:-1].values\ny=df.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\nx_train_std = ss.fit_transform(x_train)\nx_test_std = ss.transform(x_test)\n\n#KNN Classifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nknn = KNeighborsClassifier()\n\nparam_grid = {'n_neighbors':[5,10,15,25,30,50]}\n\ngrid_knn = GridSearchCV(knn,param_grid,scoring='accuracy',cv = 10,refit = True)\ngrid_knn.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_knn.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_knn.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_knn.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_knn.score(x_test_std,y_test))\n\n#Decision Tree Classifier\n\nfrom sklearn.tree import DecisionTreeClassifier\ndtc = DecisionTreeClassifier()\n\nparam_grid = {'criterion':['gini','entropy'],'max_depth':np.arange(2,10),'min_samples_leaf':[0.2,0.4,0.6,0.8,0.9,1]}\n\ngrid_dtc = GridSearchCV(dtc,param_grid,scoring='accuracy',cv = 10,refit = True)\ngrid_dtc.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_dtc.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_dtc.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_dtc.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_dtc.score(x_test_std,y_test))\n\n#SVM Classifier\n\nfrom sklearn.svm import SVC\n\nsvc = SVC(probability=True)\n\nparam_grid = {'kernel':['rbf','linear'],'C':[0.01,0.1,1,0.001],'gamma':[0.1,0.01,0.2,0.4]}\n\ngrid_svc = GridSearchCV(svc,param_grid,scoring='accuracy',cv = 10,refit = True)\ngrid_svc.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_svc.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_svc.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_svc.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_svc.score(x_test_std,y_test))\n\n# Voting Classifier Approach\n\nfrom sklearn.ensemble import VotingClassifier\n\nclassifiers = [('knn',grid_knn),('tree',grid_dtc),('svc',grid_svc)]\n\nvtc = VotingClassifier(classifiers)\nvtc.fit(x_train_std,y_train)\nprint(\"Accuracy on Test set ==> \", vtc.score(x_test_std,y_test))\n\n# Feature Selection\n\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\n\nfor i in range(2,7):\n    rfe = RFE(estimator=RandomForestClassifier(),n_features_to_select=i, verbose=0)\n    rfe.fit(x_train_std,y_train)\n    print(f\"Accuracy with Feature {i} ==>\",metrics.accuracy_score(y_test, rfe.predict(x_test_std)))\n    \nrfe = RFE(estimator=RandomForestClassifier(),n_features_to_select=5, verbose=0)\nrfe.fit(x_train_std,y_train)\nprint(\"Important Features are ==> \",list(df.columns[:7][rfe.support_]))\n\nx=df.loc[:,list(df.columns[:7][rfe.support_])].values\ny=df.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\n\nx_train_std = ss.fit_transform(x_train)\nx_test_std = ss.transform(x_test)\n\n# Random Forest Classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\nparam_grid = {'n_estimators':[200,500,1000],\n              'max_depth':[2,3,4,5],\n              'min_samples_leaf':[0.2,0.4,0.6,0.8,1],\n              'max_features':['auto','sqrt'],\n              'criterion':['gini','entropy']}\n\ngrid_rfc = RandomizedSearchCV(rfc,param_grid,n_iter=20,scoring='accuracy',cv = 10,refit = True)\ngrid_rfc.fit(x_train_std,y_train)\nprint(\"Best Score ==> \", grid_rfc.best_score_)\nprint(\"Tuned Paramerers ==> \",grid_rfc.best_params_)\nprint(\"Accuracy on Train set ==> \", grid_rfc.score(x_train_std,y_train))\nprint(\"Accuracy on Test set ==> \", grid_rfc.score(x_test_std,y_test))\n\n\n#CNN Model based Prediction Model\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nclassifier = Sequential()\n\nclassifier.add(Dense(units= 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))\nclassifier.add(Dense(units= 6, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nclassifier.fit(x_train_std, y_train, batch_size = 10, epochs = 100)\ny_pred_test = classifier.predict(x_test_std)\ny_pred_test=y_pred_test>0.5\n\ny_pred_train = classifier.predict(x_train_std)\ny_pred_train=y_pred_train>0.5\n\nprint(\"Accuracy on Train Set ==> \",metrics.accuracy_score(y_train,y_pred_train))\nprint(\"Accuracy on Test Set ==> \",metrics.accuracy_score(y_test,y_pred_test))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T11:24:51.639595Z","iopub.execute_input":"2021-06-11T11:24:51.640267Z","iopub.status.idle":"2021-06-11T11:29:03.324909Z","shell.execute_reply.started":"2021-06-11T11:24:51.640173Z","shell.execute_reply":"2021-06-11T11:29:03.323488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Among all SVC, Random Forest and XGBoost Classifiers are doing well.\n\nI have made 4 notebook on this dataset to show Statistics and Machine Learning. You can read all of them here ==>\n\nUnivariate Statistical Analysis\nMultivariate Staistical Analysis\nInferencial Statistics\nPredective Modelling on Diabtes\n\nPlease upvote my Notebook, if it is useful for you and keep supporting. \n\nThank you for reading.","metadata":{}}]}