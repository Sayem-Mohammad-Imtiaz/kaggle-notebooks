{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Unsupervised learning - prediction and visualization using Kmeans clustering"},{"metadata":{},"cell_type":"markdown","source":"Unsupervised learning involves building a machine learning algorithm that can draw inferences from datasets without labelling the responses. In other words, classifying the datasets into clusters using the training set and later using the trained model to identify which cluster the test data will automatically go into.\n\nK-means clustering is a very good technique to carry out unsupervised learning. This involves splitting the dataset into K number of clusters. Then random but unique centroids are chosen for each cluster and that is used to train the KNN classifier. This classifier is used to build the initial random set of clusters. Thereafter the centroid keeps adjusting itself to the mean of the clusters and this is a process that goes on for several iterations till the centroid stabilizes."},{"metadata":{},"cell_type":"markdown","source":"__________________________________________________________________________________________________________________________________"},{"metadata":{},"cell_type":"markdown","source":"### Importing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the file"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/titanic-machine-learning-from-disaster/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some Initial Analysis of dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Median fare of survived', df[df['Survived']==1]['Fare'].median())\nprint('Median fare of not survived', df[df['Survived']==0]['Fare'].median())\nprint('Number of Unique passenger ids=',len(df['PassengerId'].unique()))\nprint('Number of Unique Tickets=',len(df['Ticket'].unique()))\nprint('Number of Unique cabins=',len(df['Cabin'].unique())) ##Not a reliable number due to presence of missing information","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few observations:\n1. The name format is like that of in earlier days that is Surname, Title, Name, Middle name.\n2. Passenger id is unique for all and Ticket number, Cabin may be family wise.\n3. Assuming people with the same last name are a family and are together.\n4. The median fare of those survived is much higher than median fare of not survived.\n5. Sex and Embarked are categorical featured and must be converted for the purpose of model.\n6. The title of the person can be obtained and such title may tell us about the age and gender group of the individual."},{"metadata":{},"cell_type":"markdown","source":"## 1. Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Extracting Surnames for the purpose of identifying families"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_name(x):\n    l=[]\n    if isinstance(x,str):\n        l=x.split(\", \")\n        x=l[0]\n    return(x)\n\ndf['Surname'] = df['Name'].apply(clean_name).astype('str')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting titles for the purpose of gender vs age bracket"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_title(x):\n    l=[]\n    t=[]\n    if isinstance(x,str):\n        l=x.split(\", \")\n        s=l[1]\n        t=s.split(\". \")\n        x= t[0]\n    return(x)\n\ndf['Title'] = df['Name'].apply(clean_title).astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are undoubtedly too many titles to work with and by exploring this part of the data we can group the irrelevant titles into 4 basic title categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_title(x,Sex,Age):\n    a=''\n    if isinstance(x,str):\n        if x in ['Mr', 'Mrs', 'Miss', 'Master']:\n            a=x\n        else:\n            if Sex=='female' and Age<30:\n                a='Miss'\n            elif Sex=='female' and Age>=30:\n                a='Mrs'\n            elif Sex=='male' and Age>=18:\n                a='Mr'\n            else:\n                a='Master'\n    return(a)            \n\ndf['Title'] = df.apply(lambda x: new_title(x['Title'], x['Sex'],x['Age']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find out how many families are present aboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"sur= df.groupby('Surname').count()['Title']\ndf['Fam_count']=df['Surname'].map(sur)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mark passenger travelling with families as 1 and individual passengers as 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"def isfam(x):\n    if x>1:\n        a=1\n    else:\n        a=0\n    return(a)\n\ndf['IsFamily']=df['Fam_count'].apply(isfam)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding Title and Sex becasue it is categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['new_title']=df['Title'].replace({'Mr':0,'Mrs':1,'Master':2,'Miss':3})\ndf['Sex']=df['Sex'].replace({'male':0,'female':1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop irrelevant columns"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df1= df.drop(['PassengerId','Name','Ticket','Cabin','Title','Surname','Fam_count'],axis=1)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for presence of NaN values because models cannot build with an unclean dataset"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Null value imputation for features that show presence of NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Age'].fillna(df1['Age'].median(),inplace=True)\ndf1['Embarked'].fillna(df1['Embarked'].mode()[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df1.isnull().sum() #Recheck the data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transform the last categorical feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Embarked']=df1['Embarked'].replace({'C':0,'S':1,'Q':2})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final checking of dataset. This is only to check the cleanliness of data from null values, encoding of categorival features and checking the datatypes."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final step in pre-processing the data is to transform all values in the dataset so that they come to a common scale. This prevents the model weighing automatically to bigger numbers and keeps the model unbiased."},{"metadata":{"trusted":true},"cell_type":"code","source":"x1=df1.iloc[:,[1,2,3,4,5,6,7,8,9]].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nX = preprocessing.scale(x1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Building the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\ny = np.array(df['Survived'])\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Normally unless the prediction is binary like this dataset, unsupervised learning for clustering normally involves first finding the number of clusters because we wouldn't know it. The elbow method is used to visually represent the model and find out the number of clusters."},{"metadata":{},"cell_type":"markdown","source":"## 3. Checking the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\nfor i in range(len(x1)):\n    predict_me = np.array(x1[i].astype(float))\n    predict_me = predict_me.reshape(-1, len(predict_me))\n    prediction = kmeans.predict(predict_me)\n    if prediction[0] == y[i]:\n        correct += 1\n\nprint(correct/len(X))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normally an acceptable accuracy for the model at the time of initialization is 70% and above"},{"metadata":{},"cell_type":"markdown","source":"## 4. Prediction of Survival based on the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=kmeans.predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Plotting the clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X[pred == 0, 0], X[pred == 0, 1], \n            s = 30, c = 'red', label = 'dead')\nplt.scatter(X[pred == 1, 0], X[pred == 1, 1], \n            s = 30, c = 'blue', label = 'survived')\n\n\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], \n            s = 30, c = 'yellow', label = 'Centroids')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cross check the prediction numbers with actual"},{"metadata":{"trusted":true},"cell_type":"code","source":"a=df['Survived'].value_counts().values\nb=[len(pred[pred==0]),len(pred[pred==1])]\ncheck=pd.DataFrame({'Actual':a,'Predicted':b},columns=['Actual','Predicted'])\ncheck","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Model accuracy is: %.2f'%((correct/len(X))*100),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However it is to be noted that clustering algorithms are not responsible for prediction or labelling. It will just throw the data into respective clusters not labelling which is what. So just becaue this was a binary dataset with given survived and not survived, the accuracy could be fairly estimated."},{"metadata":{},"cell_type":"markdown","source":"## THANK YOU"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}