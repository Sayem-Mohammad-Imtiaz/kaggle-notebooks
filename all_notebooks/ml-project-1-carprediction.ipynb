{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the data set\ndf=pd.read_csv('../input/vehicle-dataset-from-cardekho/car data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for null values\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the unique values of categorical feature\nprint(df['Fuel_Type'].unique())\nprint(df['Seller_Type'].unique())\nprint(df['Transmission'].unique())\nprint(df['Owner'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We will remove car name from our data set because it will not have any mathematical significance\nfinal_dataset=df[['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven',\n       'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']]\n# Adding a column to show the age of the car. Will take reference year as 2020\nfinal_dataset['Age']=2020-final_dataset['Year']\n# Dropping the year column since we have captured that information in the Age column\nfinal_dataset.drop(['Year'],axis=1,inplace=True)\nfinal_dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding the catgorical features\nfrom sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\n\nfor col in final_dataset.columns:\n    if final_dataset[col].dtypes=='O':\n        final_dataset[col]=lb.fit_transform(final_dataset[col])\nfinal_dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding correlation\nfinal_dataset.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visual representation of correlation\nimport seaborn as sns\nsns.pairplot(final_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation heatmap\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.heatmap(data=final_dataset.corr().round(2), annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seperating the dependent and independent features\nX=final_dataset.drop(['Selling_Price'],axis=1)\ny=final_dataset['Selling_Price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting into test and train data\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=355)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForest regressor\nfrom sklearn.ensemble import RandomForestRegressor\nmodel1=RandomForestRegressor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyper-parameters\n\n# No. of trees in Random Forest\nn_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)]\n# No. of forests to consider at every split\nmax_features=['auto','sqrt']\n# Maximum number of levels in tree\nmax_depth=[int(x) for x in np.linspace(start=5,stop=30,num=6)]\n# Minimum number of samples required to split a node\nmin_samples_split=[2,5,10,15,100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf=[1,2,5,10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyper Parameter tuning\nfrom sklearn.model_selection import RandomizedSearchCV\n# Create random grid\nrandom_grid={'n_estimators':n_estimators,'max_features':max_features,'max_depth':max_depth,\n            'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf}\nmodel1=RandomizedSearchCV(estimator=RandomForestRegressor(),\n                             param_distributions=random_grid,scoring='neg_mean_squared_error',\n                            n_iter=10,cv=5,random_state=42, n_jobs = 1)\nmodel1.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# listing out the best parameters & score\nprint(model1.best_params_)\nprint(model1.best_score_)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_model=RandomForestRegressor(n_estimators=1000,min_samples_split=2, min_samples_leaf=1,\n                              max_features='sqrt',max_depth=25)\nrf_model.fit(X_train,y_train)\ny_pred=rf_model.predict(X_test)\n# Plotting the predictions\nplt.scatter(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying the model metrics\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\nprint(\"Model Score:\",rf_model.score(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Linear Regresison\n\n# from sklearn.linear_model  import Ridge, Lasso, RidgeCV, LassoCV, ElasticNet, ElasticNetCV, \nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nregression = LinearRegression()\nregression.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training & Testing data scores\n\nprint(\"R2 Score for Training dataset: \",regression.score(X_train,y_train))\nprint(\"Adjusted R2 Score for Training dataset: \",sm.OLS(y_train, X_train).fit().rsquared_adj)\n\nprint(\"R2 score for Test dataset: \",regression.score(X_test,y_test))\nprint(\"Adjusted R2 Score for Testing dataset: \",sm.OLS(y_test, X_test).fit().rsquared_adj)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the adjusted R2 score is slightly less for our test data. Let's see if our model is overfitting our training data.","metadata":{}},{"cell_type":"code","source":"# Lasso Regularization\nfrom sklearn.linear_model  import Lasso, LassoCV\n\n# LassoCV will return best alpha and coefficients after performing 10 cross validations\nlasscv = LassoCV(alphas = None,cv =5, max_iter = 100000, normalize = True)\nlasscv.fit(X_train, y_train)\n\n# best alpha parameter\nalpha = lasscv.alpha_\nalpha\n\n#now that we have best parameter, let's use Lasso regression and see how well our data has fitted before\n\nlasso_reg = Lasso(alpha)\nlasso_reg.fit(X_train, y_train)\nlasso_reg.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our r2_score for test data (67.98%) comes almost same as before using regularization. So, it is fair to say our OLS model did not overfit the data.","metadata":{}},{"cell_type":"code","source":"# Using Ridge regression model\n# RidgeCV will return best alpha and coefficients after performing 10 cross validations. \n# We will pass an array of random numbers for ridgeCV to select best alpha from them\nfrom sklearn.linear_model  import Ridge,RidgeCV\nalphas = np.random.uniform(low=0, high=10, size=(50,))\nridgecv = RidgeCV(alphas = alphas,cv=5,normalize = True)\nridgecv.fit(X_train, y_train)\n\nridge_model = Ridge(alpha=ridgecv.alpha_)\nridge_model.fit(X_train, y_train)\nridge_model.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We got the almost same r2 square using Ridge regression as well. So, it's safe to say there is no overfitting.","metadata":{}},{"cell_type":"code","source":"# Elastic net\nfrom sklearn.linear_model  import ElasticNet,ElasticNetCV\nelasticCV = ElasticNetCV(alphas = None, cv =5)\n\nelasticCV.fit(X_train, y_train)\n\nelasticnet_reg = ElasticNet(alpha = elasticCV.alpha_,l1_ratio=0.5)\nelasticnet_reg.fit(X_train, y_train)\nelasticnet_reg.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Even after using different types of regularisation techniques we are getting the same r2 score approximately, Hence we can conclude that our model is not overfitted.","metadata":{}},{"cell_type":"code","source":"# plotting the y_test vs y_pred\n# ideally should have been a straight line\nplt.scatter(y_test, regression.predict(X_test))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying the model metrics\nprint('MAE:', metrics.mean_absolute_error(y_test,  regression.predict(X_test)))\nprint('MSE:', metrics.mean_squared_error(y_test,  regression.predict(X_test)))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, regression.predict(X_test))))\nprint(\"Model Score:\",metrics.r2_score(y_test, regression.predict(X_test)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying XGBoost\n# Importing XG Boost libraries\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\n# fit model to training data\nxg_model = XGBRegressor()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning Rate\nlearning_rate=[1,0.5,0.1,0.01,0.001]\n# No. of trees\nn_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)]\n# Maximum number of levels in tree\nmax_depth=[int(x) for x in np.linspace(start=5,stop=30,num=6)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyper Parameter tuning\n\n# Create random grid\nrandom_grid_xg={'n_estimators':n_estimators,'learning_rate':learning_rate,'max_depth':max_depth}\nxg_model=RandomizedSearchCV(XGBRegressor(objective='reg:squarederror'),\n                            param_distributions=random_grid_xg,n_iter=10,cv=5,random_state=42, \n                            n_jobs = 1)\nxg_model.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# listing out the best parameters & score\nprint(xg_model.best_params_)\nprint(xg_model.best_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xg_model=XGBRegressor(n_estimators=900,max_depth=5,learning_rate=0.01)\nxg_model.fit(X_train,y_train)\n#y_pred=rf_model.predict(X_test)\n# Plotting the predictions\nplt.scatter(y_test,xg_model.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying the model metrics\n\nprint('MAE:', metrics.mean_absolute_error(y_test, xg_model.predict(X_test)))\nprint('MSE:', metrics.mean_squared_error(y_test, xg_model.predict(X_test)))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test,xg_model.predict(X_test))))\nprint(\"Model Score:\",xg_model.score(X_test,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **We can clearly see that XGBoost Regression gives us the best model score.**","metadata":{}}]}