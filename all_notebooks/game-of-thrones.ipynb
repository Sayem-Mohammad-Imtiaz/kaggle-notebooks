{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Exploratory Data Analysis of GOT script.**\n## Attempt to use NLP techniques."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport plotly.express as px ## Visualization\nimport plotly.graph_objects as go ## Visualization\nimport matplotlib.pyplot as plt ## Visualization\nimport plotly as py ## Visualization\nfrom wordcloud import WordCloud, STOPWORDS ## To create word clouds from script\nimport os\n%config IPCompleter.greedy=True\nimport nltk\nfrom nltk.corpus import stopwords\nfrom  nltk.stem import SnowballStemmer\nimport re\nimport gensim\nfrom gensim.models import word2vec\nfrom sklearn.manifold import TSNE\n\n# WORD2VEC \nW2V_SIZE = 300\nW2V_WINDOW = 7\nW2V_EPOCH = 32\nW2V_MIN_COUNT = 10\n\nos.chdir(\"../input/game-of-thrones-script-all-seasons/\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#read dataset\ndf = pd.read_csv('Game_of_Thrones_Script.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Change date format\ndf.loc[:,'Release Date'] = pd.to_datetime(df['Release Date'])\n\ndf['Year'] = df['Release Date'].dt.year\ndf['Month'] = df['Release Date'].dt.month\nmonth_mapper = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n               7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\ndf.loc[:,'Month'] = df['Month'].map(month_mapper)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Some preprocessing\nstop_words = stopwords.words(\"english\") #A stop.word is a commonly used word (“the”, “a”, “an”, “in”)\nstemmer = SnowballStemmer(\"english\") #A stemming algorithm reduces the words “chocolates”, “choco” to the root word,“chocolate”\n\n# TEXT CLENAING\nTEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\ndef preprocess(text, stem=False):\n    # Remove link,user and special characters\n    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n    tokens = []\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens)\n#Apply function\ndf.Sentence = df.Sentence.apply(lambda x: preprocess(x))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Function to count words\ndef counter(strng):\n    counter = 0\n    wordlist = strng.split()\n    for word in wordlist:\n        counter +=1\n    return counter \n#We will create a new columns to check most talkative character\ndf['count_words'] = df.Sentence.apply(lambda x: counter(x))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#We will drop some occasional characters.\ncharacters_drop = ['man', 'women', 'boy','girl', 'old man',]\ndf =df[-df['Name'].isin(characters_drop)] ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Total dialogues by Seasons\ntemp = df['Season'].value_counts().reset_index()\ntemp.columns=['Season', 'Counts']\ntemp.sort_values(by='Season', inplace=True)\nfig = px.bar(temp, 'Season', 'Counts')\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=600,\n    title={\n        \n        'text': \"Total dialougue counts in season.\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (15,10)\ntemp = df.groupby(['Season','Episode'])['count_words'].sum().unstack().plot(kind='bar', fill = 'count_words',stacked=True)\nplt.title(\"Number of words by Episodes in all Seasons\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Most frequent 20 words\nfrom collections import Counter\nwords = Counter(\" \".join(df[\"Sentence\"]).split()).most_common(20)\n\nnames, values = zip(*words)\nfig = px.bar(x=names, y=values, labels={'x':'words', 'y':'count'})\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=600,\n    title={\n        \n        'text': \"Most frequently used 20 words through all Seasons\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Most common words in GOT using wordCloud\nwordcloud = WordCloud(width=1600, height=800, min_font_size=10, background_color ='#add8e6').generate(\n    ' '.join(i for i in df['Sentence']))\nplt.figure(figsize = (12, 12), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title(\"Most frequently used words through all Seasons\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Most common 20 words of tyrion_lannister\ntyrion_lannister = df[df['Name']=='tyrion lannister']\nwords = Counter(\" \".join(tyrion_lannister[\"Sentence\"]).split()).most_common(20)\n\nnames, values = zip(*words)\nfig = px.bar(x=names, y=values, labels={'x':'words', 'y':'count'})\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=600,\n    title={\n        \n        'text': \"Most frequently used 20 words of Tyrion Lannister\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Most common words of tyrion_lannister using wordCloud\n\nwordcloud = WordCloud(width=1600, height=800, min_font_size=10, background_color ='#add8e6').generate(\n    ' '.join(i for i in tyrion_lannister['Sentence']))\nplt.figure(figsize = (12, 12), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.title(\"Most frequently used words of Tyrion Lannister\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Most common 20 words of daenerys_targaryen\ndaenerys_targaryen = df[df['Name']=='daenerys targaryen']\nwords = Counter(\" \".join(daenerys_targaryen[\"Sentence\"]).split()).most_common(20)\n\nnames, values = zip(*words)\nfig = px.bar(x=names, y=values, labels={'x':'words', 'y':'count'})\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=600,\n    title={\n        \n        'text': \"Most frequently used 20 words of Daenerys Targaryen\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Most common words of daenerys_targaryen using wordCloud\ndaenerys_targaryen = df[df['Name']=='daenerys targaryen']\nwordcloud = WordCloud(width=1600, height=800, min_font_size=10, background_color ='#add8e6').generate(\n    ' '.join(i for i in daenerys_targaryen['Sentence']))\nplt.figure(figsize = (12, 12), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.title(\"Most frequently used words of Daenerys Targaryen\", fontsize=20)\nplt.tight_layout(pad = 0) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#\"20 characters with most dialogues\"\ntemp = df['Name'].value_counts().reset_index()\ntemp.columns=['Character', 'No of Dialouges']\nfig = px.bar(temp.head(20), 'Character', 'No of Dialouges')\nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=600,\n    title={\n        \n        'text': \"20 characters that took part in the most dialogues\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#20 character with most words in dialogues\nplt.xticks(rotation =\"horizontal\")\np = df.groupby(\"Name\")['count_words'].sum().sort_values(ascending=False)[:20].plot(kind='bar',figsize=(30,12), fontsize = 20)\nplt.title(\"Characters by number of words\", fontsize=20)\nplt.xticks(rotation=-90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#I want to find the most important words for each of the main charatcers.\n#daenerys_targaryen using tf-idf\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer()\nx = tfidf.fit_transform(daenerys_targaryen.Sentence)\n\nfeature_array = np.array(tfidf.get_feature_names())\ntfidf_sorting = np.argsort(x.toarray()).flatten()[::-1]\n\nn = 20\ntop_n = feature_array[tfidf_sorting][:n]\n\ntext = ' '.join(top_n)\n\n# Create a cloud image:\nwordcloud = WordCloud(width=1600, height=800,min_font_size=10, background_color ='#add8e6').generate(text)\n\n# Display the generated image:\nplt.figure(figsize = (12, 12), facecolor = None) \nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Most important 20 words of Daenerys Targaryen\", fontsize=20)\nplt.tight_layout(pad = 0) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Tyrion_lannister important words.\n#tyrion_lannister using tf-idf\n\ntfidf = TfidfVectorizer()\nx = tfidf.fit_transform(tyrion_lannister.Sentence)\n\nfeature_array = np.array(tfidf.get_feature_names())\ntfidf_sorting = np.argsort(x.toarray()).flatten()[::-1]\n\nn = 20\ntop_n = feature_array[tfidf_sorting][:n]\n\ntext = ' '.join(top_n)\n\n# Create a cloud image:\nwordcloud = WordCloud(width=1600, height=800,min_font_size=10, background_color ='#add8e6').generate(text)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title(\"Most important 20 words of Tyrion Lannister\", fontsize=20)\n\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Jon Snow important words.\njon_snow = df[df['Name']=='jon snow']\n\ntfidf = TfidfVectorizer()\nx = tfidf.fit_transform(jon_snow.Sentence)\n\nfeature_array = np.array(tfidf.get_feature_names())\ntfidf_sorting = np.argsort(x.toarray()).flatten()[::-1]\n\nn = 30\ntop_n = feature_array[tfidf_sorting][:n]\ntext = ' '.join(top_n)\n\n# Create a cloud image:\nwordcloud = WordCloud(width=1600, height=800,min_font_size=10, background_color ='#add8e6').generate(text)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title(\"Most important 20 words of Jon Snow\", fontsize=20)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Cersei Lannister important words.\ncersei_lannister = df[df['Name']=='cersei lannister']\n\ntfidf = TfidfVectorizer()\nx = tfidf.fit_transform(cersei_lannister.Sentence)\n\nfeature_array = np.array(tfidf.get_feature_names())\ntfidf_sorting = np.argsort(x.toarray()).flatten()[::-1]\n\nn = 30\ntop_n = feature_array[tfidf_sorting][:n]\ntext = ' '.join(top_n)\n\n# Create a cloud image:\nwordcloud = WordCloud(width=1600, height=800,min_font_size=10, background_color ='#add8e6').generate(text)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title(\"Most important 20 words of Cersei Lannister\", fontsize=20)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Build a corpus for the word2vec model\ndef build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for sentence in data:\n        word_list = sentence.split(\" \")\n        corpus.append(word_list)    \n           \n    return corpus\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#cersei_lannister Words TSNE\n\ncorpus = build_corpus(cersei_lannister.Sentence) \nmodel = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n                                            window=W2V_WINDOW, \n                                            min_count=W2V_MIN_COUNT, \n                                            workers=4)\nmodel.build_vocab(corpus)\n\n# define the function to compute the dimensionality reduction\n# and then produce the biplot\ndef tsne_plot(model):\n    \"Creates a TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(18, 18)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n        plt.title(\"Cersei Lannister Words TSNE\", fontsize=20)\n\n    plt.show()\n    \n# call the function on our dataset\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#jon_snow Words TSNE\n\ncorpus = build_corpus(jon_snow.Sentence) \nmodel = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n                                            window=W2V_WINDOW, \n                                            min_count=W2V_MIN_COUNT, \n                                            workers=4)\nmodel.build_vocab(corpus)\n\n# define the function to compute the dimensionality reduction\n# and then produce the biplot\ndef tsne_plot(model):\n    \"Creates a TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(18, 18)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n        plt.title(\"Jon Snow Words TSNE\", fontsize=20)\n\n    plt.show()\n    \n# call the function on our dataset\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#daenerys_targaryen Words TSNE\n\ncorpus = build_corpus(daenerys_targaryen.Sentence) \nmodel = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n                                            window=W2V_WINDOW, \n                                            min_count=W2V_MIN_COUNT, \n                                            workers=4)\nmodel.build_vocab(corpus)\n\n# define the function to compute the dimensionality reduction\n# and then produce the biplot\ndef tsne_plot(model):\n    \"Creates a TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(18, 18)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n        plt.title(\"Daenerys Targaryen Words TSNE\", fontsize=20)\n\n    plt.show()\n    \n# call the function on our dataset\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#tyrion_lannister Words TSNE\n\ncorpus = build_corpus(tyrion_lannister.Sentence)   \nmodel = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n                                            window=W2V_WINDOW, \n                                            min_count=W2V_MIN_COUNT, \n                                            workers=4)\nmodel.build_vocab(corpus)\n\n# define the function to compute the dimensionality reduction\n# and then produce the biplot\ndef tsne_plot(model):\n    \"Creates a TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(18, 18)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n        plt.title(\"Tyrion Lannister Words TSNE\", fontsize=20)\n\n    plt.show()\n    \n# call the function on our dataset\ntsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#We will create new dataframe to do bar chart race.\ndf_new = pd.DataFrame(index=np.arange(30),columns=[\"Name\"])\n\n#Get 30 main character names from our big dataset \ntemp = df['Name'].value_counts().reset_index()[:30]\ntemp.columns=['Character', 'No of Dialouges']\nnames = temp.Character\n#Asign column with sorted names\nfor i in range(len(names)):\n    df_new.loc[i,[\"Name\"]] = temp.Character[i]\n    \ndf_new.sort_values('Name', inplace=True)\ndf_new = df_new.reset_index(drop=True)\ndel temp\n\n#We will create 2 lists to iterate trough loop\nseasons = ['Season 1', 'Season 2', 'Season 3', 'Season 4', \n           'Season 5', 'Season 6', 'Season 7', 'Season 8']\nepisodes = ['Episode 1','Episode 2','Episode 3','Episode 4',\n            'Episode 5','Episode 6','Episode 7','Episode 8','Episode 9','Episode 10']\n\ntemp_df = df.groupby(['Season', 'Episode', 'Name'])['count_words'].sum().reset_index()\ntemp_df = temp_df[temp_df.Name.isin(names)]\n#We will get words sums for our characters from each episode and all Seasons and join to new_df\nfor season in seasons:\n    for episode in episodes:\n            tempor = temp_df[(temp_df['Season']==season) & (temp_df['Episode']== episode)]\n            tempor = tempor.drop(columns=['Season', 'Episode'])\n            tempor = tempor.rename(columns={\"count_words\": season + \" \" + episode})\n            df_new = df_new.merge(tempor, how='left', on='Name')\n\n#We should delete some columns since some Seasons has less Episodes.\ncol_delete = ['Season 7 Episode 8', 'Season 7 Episode 9', 'Season 7 Episode 10',\n              'Season 8 Episode 7','Season 8 Episode 8', 'Season 8 Episode 9', \n              'Season 8 Episode 10' ]\n\ndf_new = df_new.drop(columns=col_delete)\n#Fill NAN with 0\ndf_new = df_new.fillna(0)\n\n#Now we should change each number of word to cumulative value n = n-1 + n\nfor i in df_new.index:\n    zero = 0\n    for x in range(len(df_new.columns)-1):\n        df_new.iloc[i,x+1] = zero + df_new.iloc[i,x+1]\n        zero = df_new.iloc[i,x+1]\n\n#Now we will save our df to try on flourish studio\n#df_new.to_csv('GOT_with_count_words.csv')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import IPython\nurl = \"https://flo.uri.sh/visualisation/1937774/embed\"\niframe = '<iframe src=' + url + ' width=950 height=600></iframe>'\nIPython.display.HTML(iframe)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}