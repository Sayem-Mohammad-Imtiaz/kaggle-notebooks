{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n1. [Read Data and PreCheck](#1)\n1. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        1. [Age Variable](#4)\n        1. [Sex Variable](#5)\n        1. [BP Variable](#6)\n        1. [Cholesterol Variable](#7)\n        1. [Na_to_K Variable](#8)\n        1. [Drug Variable](#9)\n1. [Basic Data Analysis and Visualization](#10)\n    * [Age -- Drug](#11)\n    * [Sex -- Drug](#12)\n    * [BP -- Drug](#13)\n    * [Na_to_K -- Drug](#14)\n    * [Cholesterol -- Drug](#15)\n    * [Na_to_K -- BP -- Drug](#16)\n1. [Preparing Data and Feature Engineering](#17)\n    * [Create New Features](#18)\n        * [Na_to_K_Bigger_Than_15](#19)\n    * [Label Encoding](#20)\n    * [Train Test Split](#21)\n1. [Model Implementation](#22)\n    1. [KNN Classifier](#23)\n        * [Default Parameters](#24)\n        * [GridSearchCV](#25)\n    2. [Random Forest Classifier](#26)\n        * [Default Parameters](#27)\n        * [GridSearchCV](#28)\n    3. [SVM Classifier](#29)\n        * [Default Parameters](#30)\n        * [GridSearchCV](#31)\n1. [Conclusion](#32)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='1'></a>\n# Read Data and PreCheck"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/drug-classification/drug200.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* No missing value\n* 6 columns\n* 200 rows"},{"metadata":{},"cell_type":"markdown","source":"<a id='2'></a>\n# Variable Description\n\n* Age: Age of patient\n* Sex: Gender of patient\n* BP: Blood pressure of patient\n* Cholesterol: Cholesterol of patient\n* Na_to_K: Sodium to Potassium Ratio in Blood \n* Drug: Drug Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* float64(1): Na_to_K\n* int64(1): Age\n* object(4): Sex, BP, Cholesterol, Drug"},{"metadata":{},"cell_type":"markdown","source":"<a id='3'></a>\n## Univariate Variable Analysis"},{"metadata":{},"cell_type":"markdown","source":"<a id='4'></a>\n### Age Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Max Age:\", df.Age.max())\nprint(\"Min Age:\", df.Age.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age distribution\nplt.figure(figsize = (9,5))\nsns.distplot(df.Age)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Age range is between 15 and 74."},{"metadata":{},"cell_type":"markdown","source":"<a id='5'></a>\n### Sex Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Sex.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sex Distribution\nplt.figure(figsize=(9,5))\nsns.countplot(x = df.Sex)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The ratio of gender seems balanced in the data\n* This is a categorical variable. It would be better if we apply label encoder to avoid any error during model implementation."},{"metadata":{},"cell_type":"markdown","source":"<a id='6'></a>\n### BP Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.BP.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df.BP)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='7'></a>\n### Cholesterol Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Cholesterol.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df.Cholesterol)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cholesterol is a balanced data. \n* It is categorical and label encoder will apply on it."},{"metadata":{},"cell_type":"markdown","source":"<a id='8'></a>\n### Na_to_K Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Max Na_to_K:\",df.Na_to_K.max())\nprint(\"Min Na_to_K:\",df.Na_to_K.min())\nprint(\"Mean Na_to_K:\",df.Na_to_K.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.distplot(df.Na_to_K)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='9'></a>\n### Drug Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Drug.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.countplot(df.Drug)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Drug is target column and you can see that it is unbalanced dataset. Using K Fold cross-validation would be better for reliable results."},{"metadata":{},"cell_type":"markdown","source":"<a id='10'></a>\n# Basic Data Analysis\n\n* Age -- Drug\n* Sex -- Drug\n* BP -- Drug\n* Cholesterol -- Drug"},{"metadata":{},"cell_type":"markdown","source":"<a id='11'></a>\n## Age -- Drug"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.swarmplot(x = \"Drug\", y = \"Age\",data = df)\nplt.legend(df.Drug.value_counts().index)\nplt.title(\"Age -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Minimum Age of DrugB\",df.Age[df.Drug == \"drugB\"].min())\nprint(\"Maximum Age of DrugA\",df.Age[df.Drug == \"drugA\"].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* DrugB is taken only by older than 51 years old. \n* DrugA is taken only by younger than 50 years old. "},{"metadata":{},"cell_type":"markdown","source":"<a id='12'></a>\n## Sex -- Drug"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Sex_Drug = df.groupby([\"Drug\",\"Sex\"]).size().reset_index(name = \"Count\")\ndf_Sex_Drug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"Sex\",data = df_Sex_Drug)\nplt.title(\"Sex -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Male people get drugA, drugB and drugC more than male people.\n* Female people get DrugY more than female people.\n* drugX seems equal for male and female people.\n* According to this graph, Sex feature is not an important feature for classification."},{"metadata":{},"cell_type":"markdown","source":"<a id='13'></a>\n## BP -- Drug"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_BP_Drug = df.groupby([\"Drug\",\"BP\"]).size().reset_index(name = \"Count\")\ndf_BP_Drug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"BP\",data = df_BP_Drug)\nplt.title(\"BP -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* drugA and drugB are got only by people who have HIGH blood pressure.\n* drugC is got by people who have LOW blood pressure.\n* drugX is got by people who have HIGH blood pressure.\n* BP is an important feature for classification."},{"metadata":{},"cell_type":"markdown","source":"<a id='14'></a>\n## Na_to_K -- Drug"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.swarmplot(x = \"Drug\", y = \"Na_to_K\",data = df)\nplt.title(\"Na_to_K -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Minimum Na_to_K for DrugY:\",df.Na_to_K[df.Drug == \"DrugY\"].min())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* People who have Na_to_K ratio is bigger than 15, get DrugY.\n* We can create a new feature from here."},{"metadata":{},"cell_type":"markdown","source":"<a id='15'></a>\n## Cholesterol -- Drug"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_CH_Drug = df.groupby([\"Drug\",\"Cholesterol\"]).size().reset_index(name = \"Count\")\ndf_CH_Drug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"Cholesterol\",data = df_CH_Drug)\nplt.title(\"Cholesterol -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* drugC is got by people who have HIGH cholesterol.\n* Cholesterol is an important feature to classify drugC"},{"metadata":{},"cell_type":"markdown","source":"<a id='16'></a>\n## Na_to_K -- BP -- Drug"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.swarmplot(x = \"Drug\", y = \"Na_to_K\",hue=\"BP\",data = df)\nplt.legend()\nplt.title(\"Na_to_K -- BP -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* If people have HIGH blood pressure and Na_to_K ratio is lower than 15 , they get drugA and drugB only.\n* If people have LOW blood pressure and Na_to_K ratio is lower than 15 , they get drugC only."},{"metadata":{},"cell_type":"markdown","source":"<a id='17'></a>\n# Preparing Data and Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"<a id='18'></a>\n## Create New Features"},{"metadata":{},"cell_type":"markdown","source":"<a id='19'></a>\n### Na_to_K_Bigger_Than_15 \n\nIf Na_to_K is bigger than 15, it is always drugY."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Na_to_K_Bigger_Than_15'] = [1 if i >=15.015 else 0 for i in df.Na_to_K]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_NaK15 = df.groupby([\"Drug\",\"Na_to_K_Bigger_Than_15\"]).size().reset_index(name = \"Count\")\ndf_NaK15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (9,5))\nsns.barplot(x = \"Drug\",y=\"Count\", hue = \"Na_to_K_Bigger_Than_15\",data = df_NaK15)\nplt.title(\"Na_to_K_Bigger_Than_15 -- Drug\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Na_to_K_Bigger_Than_15 feature will be important feature to drugY classification."},{"metadata":{},"cell_type":"markdown","source":"<a id='20'></a>\n## Label Encoding\n\nWe will convert from object to int64\n\n* Sex\n* BP\n* Cholesterol\n* Na_to_K\n* Na_to_K_Bigger_Than_15"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndef label_encoder(y):\n    le = LabelEncoder()\n    df[y] = le.fit_transform(df[y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_list = [\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\",\"Na_to_K_Bigger_Than_15\",\"Drug\"]\n\nfor l in label_list:\n    label_encoder(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='21'></a>\n## Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = df.drop([\"Drug\"],axis=1)\ny = df.Drug\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42, shuffle = True)\n\ny_train = y_train.values.reshape(-1,1)\ny_test = y_test.values.reshape(-1,1)\n\nprint(\"x_train shape:\",x_train.shape)\nprint(\"x_test shape:\",x_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data was splitted as 80% train data and 20% test data."},{"metadata":{},"cell_type":"markdown","source":"<a id='22'></a>\n# Model Implementation\n\nI will try three models and compare their results. For all models, I apply GridSearchCV method to find best score. Also, to be sure our models performance are random, I will use 5 Fold Cross Validation method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# To store results of models\nresult_dict_train = {}\nresult_dict_test = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='23'></a>\n## KNN Classifier\n\nTo find best score of KNN model, I will try different value of n_neighbors, p, and weights parameters. If you are not sure about what these parameters are you can check my another kernel [Understanding Parameters of KNN](http://www.kaggle.com/gorkemgunay/understanding-parameters-of-knn)"},{"metadata":{},"cell_type":"markdown","source":"<a id='24'></a>\n### Default Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\naccuracies = cross_val_score(knn, x_train, y_train, cv=5)\nknn.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",knn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict_train[\"KNN Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"KNN Default Test Score\"] = knn.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='25'></a>\n### GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {'n_neighbors':np.arange(1,120),\n        'p':np.arange(1,3),\n        'weights':['uniform','distance']\n       }\n\nknn = KNeighborsClassifier(algorithm = \"auto\")\nknn_cv = GridSearchCV(knn,grid,cv=5)\nknn_cv.fit(x_train,y_train)\n\nprint(\"Hyperparameters:\",knn_cv.best_params_)\nprint(\"Train Score:\",knn_cv.best_score_)\nprint(\"Test Score:\",knn_cv.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict_train[\"KNN GridSearch Train Score\"] = knn_cv.best_score_\nresult_dict_test[\"KNN GridSearch Test Score\"] = knn_cv.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='26'></a>\n# Random Forest\n\n\nTo find best score of Random Forest model, I will try different value of n_estimators and criterion parameters."},{"metadata":{},"cell_type":"markdown","source":"<a id='27'></a>\n### Default Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state = 42)\naccuracies = cross_val_score(rfc, x_train, y_train, cv=5)\nrfc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",rfc.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict_train[\"Random Forest Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"Random Forest Default Test Score\"] = rfc.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='28'></a>\n### GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {'n_estimators':np.arange(100,1000,100),\n        'criterion':['gini','entropy']\n       }\n\nrf = RandomForestClassifier(random_state = 42)\nrf_cv = GridSearchCV(rf,grid,cv=5)\nrf_cv.fit(x_train,y_train)\n\nprint(\"Hyperparameters:\",rf_cv.best_params_)\nprint(\"Train Score:\",rf_cv.best_score_)\nprint(\"Test Score:\",rf_cv.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict_train[\"Random Forest GridSearch Train Score\"] = rf_cv.best_score_\nresult_dict_test[\"Random Forest GridSearch Test Score\"] = rf_cv.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='29'></a>\n# SVM Classifier\n\nTo find best score of SVM model, I will try different value of C, kernel, degree and gamma parameters. The easy way to do this is GridSearchCV method. If you are not sure about what these parameters are you can check my another kernel [Understanding Parameters of SVM](https://www.kaggle.com/gorkemgunay/understanding-parameters-of-svm)"},{"metadata":{},"cell_type":"markdown","source":"<a id='30'></a>\n### Default Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(random_state = 42)\naccuracies = cross_val_score(svc, x_train, y_train, cv=5)\nsvc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",svc.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict_train[\"SVM Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"SVM Default Test Score\"] = svc.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='31'></a>\n### GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = {\n    'C':[0.01,0.1,1,10],\n    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n    'degree' : [1,3,5,7],\n    'gamma' : [0.01,1]\n}\n\nsvm  = SVC ();\nsvm_cv = GridSearchCV(svm, grid, cv = 5)\nsvm_cv.fit(x_train,y_train)\nprint(\"Best Parameters:\",svm_cv.best_params_)\nprint(\"Train Score:\",svm_cv.best_score_)\nprint(\"Test Score:\",svm_cv.score(x_test,y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict_train[\"SVM GridSearch Train Score\"] = svm_cv.best_score_\nresult_dict_test[\"SVM GridSearch Test Score\"] = svm_cv.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='32'></a>\n# Conclusion"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result_train = pd.DataFrame.from_dict(result_dict_train,orient = \"index\",columns=[\"Score\"])\ndf_result_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result_test = pd.DataFrame.from_dict(result_dict_test,orient = \"index\",columns=[\"Score\"])\ndf_result_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(20,5))\nsns.barplot(x = df_result_train.index,y = df_result_train.Score,ax = ax[0])\nsns.barplot(x = df_result_test.index,y = df_result_test.Score,ax = ax[1])\nax[0].set_xticklabels(df_result_train.index,rotation = 75)\nax[1].set_xticklabels(df_result_test.index,rotation = 75)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Random Forest classifier  and SVM classifier (after hyperparameter tuning) have a good scores.\n* KNN classifier has worst score in three clasifiers."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}