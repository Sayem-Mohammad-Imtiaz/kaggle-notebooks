{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TEST2 DenseNet121","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # additional plotting functionality\n\nimport os\nprint(os.listdir(\"../input/data\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nimport os\nimport matplotlib.gridspec as gridspec\nimport matplotlib.ticker as ticker\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n#from generator import DataGenerator\nimport keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/data/Data_Entry_2017.csv')\ndata = data[data['Patient Age']<100] #removing datapoints which having age greater than 100\ndata_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input','data', 'images*', '*', '*.png'))}\nprint('Scans found:', len(data_image_paths), ', Total Headers', data.shape[0])\ndata['path'] = data['Image Index'].map(data_image_paths.get)\ndata['Patient Age'] = data['Patient Age'].map(lambda x: int(x))\ndata.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\ndata.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# keep at least 1000 cases\nMIN_CASES = 100\nall_labels = [c_label for c_label in all_labels if data[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(data[c_label].sum())) for c_label in all_labels])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.04 + number of findings\nsample_weights = data['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights /= sample_weights.sum()\ndata = data.sample(40000, weights=sample_weights)\n\nlabel_counts = data['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating vector of diseases\ndata['disease_vec'] = data.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(data, \n                                   test_size = 0.20, \n                                   random_state = 2018,\n                                   stratify = data['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'test', test_df.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_df, \n                                   test_size = 0.10, \n                                   random_state = 2018,\n                                   stratify = train_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'valid', valid_df.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.densenet import DenseNet121, preprocess_input\n#from keras.applications.nasnet  import NASNetMobile, preprocess_input\n#from keras.applications.densenet import DenseNet201, preprocess_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nIMG_SIZE = (224, 224) # slightly smaller than vgg16 normally expects\ncore_idg_dense = ImageDataGenerator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = flow_from_dataframe(core_idg_dense, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 16)\n\nvalid_gen = flow_from_dataframe(core_idg_dense, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 32) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg_dense, \n                               test_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 8000)) # one big batch\n# used a fixed dataset for final evaluation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0])\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dense net model\nimg_in = Input(t_x.shape[1:])              #input of model \nmodel = DenseNet121(include_top= False , # remove  the 3 fully-connected layers at the top of the network\n                weights=None,      # pre train weight \n                input_tensor= img_in, \n                input_shape= t_x.shape[1:],\n                pooling ='avg') \n\nx = model.output  \npredictions = Dense(len(all_labels), activation=\"sigmoid\", name=\"predictions\")(x)    # fuly connected layer for predict class \nmodel = Model(inputs=img_in, outputs=predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nimport tensorflow as tf\nloaded_model = tf.keras.models.load_model('../input/nih-cxr-weight0102414/weights.best.01-0.24.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = Adam(lr=0.001)\nmodel.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[keras.metrics.binary_accuracy])\nmodel.load_weights('../input/chestxray8-dataframe/pretrained_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up a checkpoint for model training\n# https://keras.io/callbacks/\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpointer = ModelCheckpoint(filepath='weights.best.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only = True)\ncallbacks_list = [checkpointer]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = loaded_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_steps=1,\n                                  validation_data = valid_gen, \n                                  epochs = 3 , callbacks = callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\ny_pred = loaded_model.predict(test_X) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\n# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(y_pred,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (c_label, t_count, p_count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), y_pred[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nplt.plot([0, 1], [0, 1], 'k--')\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(test_Y.astype(int), y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import confusion_matrix\ny_pred =np.argmax(y_pred,axis=1)\ncm=confusion_matrix(np.argmax(test_Y, axis=1), y_pred)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nimport seaborn as sn\nimport pandas as pd\n\nplt.figure(figsize=(16, 16))\nax= plt.subplot()\n\ndf_cm = pd.DataFrame(cm, range(14), range(14))\n# plt.figure(figsize=(10,7))\nsn.set(font_scale=1.2) # for label size\nsn.heatmap(df_cm, annot=True, annot_kws={\"size\": 15}, cmap='Blues',ax = ax ) # font size\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis','Hernia'\n                ,'Infiltration','Mass','Nodule','Pleural_Thickening','Pneumonia','Pneumothorax'],rotation=30, ha=\"right\",rotation_mode=\"anchor\"); \nax.yaxis.set_ticklabels(['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis','Hernia'\n                ,'Infiltration','Mass','Nodule','Pleural_Thickening','Pneumonia','Pneumothorax'],rotation=30, ha=\"right\", rotation_mode=\"anchor\");\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#########################################\nfrom sklearn.metrics import accuracy_score\naccuracy_score(np.argmax(test_Y, axis=1), y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ntarget_names = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis','Hernia'\n                ,'Infiltration','Mass','Nodule','Pleural_Thickening','Pneumonia','Pneumothorax']\nclassification_report(np.argmax(test_Y, axis=1), y_pred,target_names=target_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_steps=1,\n                                  validation_data = valid_gen, \n                                  epochs = 3 , callbacks = callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(y_pred,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: actual: %2.2f%%, predicted: %2.2f%%' % (c_label, t_count, p_count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), y_pred[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nplt.plot([0, 1], [0, 1], 'k--')\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(test_Y.astype(int), y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}