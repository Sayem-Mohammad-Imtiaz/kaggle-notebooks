{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n    \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Frame the Problem","metadata":{}},{"cell_type":"markdown","source":"* This notebook is about making an analysis on whether we can create a high accuracy classifier of handwritten english letters\n* This model will be part of a solution that reads handwritten letters out of digitized documents\n* The problem can be framed as an offline supervised classification problem\n* The performance will be measured using accuracy score with a target of ~= 95%","metadata":{}},{"cell_type":"markdown","source":"# Get the Data","metadata":{}},{"cell_type":"markdown","source":"*The data used for this notebook are provided from Kaggle by user 'Sachin Patel' and are free to use*\n","metadata":{}},{"cell_type":"markdown","source":"The dataset consists of:\n\n* handwritten (A-Z) images in size 2828 pixels\n* each alphabet in the image is centre fitted to 2020 pixel box.\n* each image is stored as Gray-level","metadata":{}},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image, ImageEnhance\n\ndef load_images(path):\n    images = []\n    for i in os.listdir(path):\n        img_path = os.path.join(path, i)\n        images.append(Image.open(img_path))\n    return images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore the Data","metadata":{}},{"cell_type":"code","source":"english_dataset = np.array(pd.read_csv('../input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv'))\n\nenglish_alphabet = pd.DataFrame(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n                                 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n                                'u', 'v', 'w', 'x', 'y', 'z'], [i for i in range(1, 27)])\nenglish_alphabet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = english_dataset[:, 1:], english_dataset[:, 0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing data**","metadata":{}},{"cell_type":"code","source":"def plot_letters(images, labels, width=14, height=14):\n    rows, cols = 4, 6\n\n    fig=plt.figure(figsize=(14, 14))\n    sub_plot_i = 1\n\n    for i in range(0, 20):\n        fig.add_subplot(rows, cols, sub_plot_i)\n        sub_plot_i += 1\n        image = images[i].reshape(width, height)\n        plt.imshow(image, cmap='gray')\n        label = labels[i].astype(int) + 1\n        plt.title(english_alphabet.loc[label][0])\n\n\n    fig.tight_layout()    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_letters(X_train, y_train, 28, 28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the Data","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass ImageTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, width=14, height=14,  is_img=False):\n        self.width = width\n        self.height = height\n        self.is_img = is_img\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        if self.is_img:\n            images = []\n            # load the image and convert to grayscale\n            for img in X:                \n                \n                image = img.convert('L').resize((self.width, self.height))\n                \n                enhancer = ImageEnhance.Contrast(image)\n                image = enhancer.enhance(1.0)\n                \n                images.append(np.asarray(image).reshape(-1))\n            return np.array(images)\n        else:\n            return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n\npreprocessing_pipeline = Pipeline([\n    ('image_trf', ImageTransformer()),\n    ('scaler', StandardScaler()),\n])\n\nwidth, height = 28, 28\npreprocessing_pipeline.set_params(image_trf__width=width, image_trf__height=height, image_trf__is_img=False)\nX_train_proc = preprocessing_pipeline.fit_transform(X_train)\nX_test = preprocessing_pipeline.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and Compare Models","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict \nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef display_conf_mat(model, X, y):\n    _, ax = plt.subplots(figsize=(20, 20))\n    plot_confusion_matrix(model, X, y, \n                          display_labels=np.array(english_alphabet[0]).astype(str),\n                          cmap=plt.cm.Blues, ax=ax)\n    plt.show()\n    \n\ndef custom_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(14, 12))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nscores = cross_val_score(LogisticRegression(max_iter=1000), X_train_proc[:2000], y_train[:2000], cv=5)\nscores.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_clf = LogisticRegression(max_iter=1000)\nlog_clf.fit(X_train_proc[:2000], y_train[:2000])\ndisplay_conf_mat(log_clf, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LinearSVC**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nscores = cross_val_score(LinearSVC(max_iter=2000), X_train_proc[:2000], y_train[:2000], cv=5)\nscores.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lin_svc_clf = LinearSVC(max_iter=2000)\nlin_svc_clf.fit(X_train_proc[:2000], y_train[:2000])\ndisplay_conf_mat(lin_svc_clf, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SVC with RBF**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nscores = cross_val_score(SVC(), X_train_proc[:2000], y_train[:2000], cv=5)\nscores.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_clf = SVC()\nsvc_clf.fit(X_train_proc[:2000], y_train[:2000])\ndisplay_conf_mat(svc_clf, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nscores = cross_val_score(RandomForestClassifier(max_depth=10), X_train_proc, y_train, cv=5)\nscores.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_clf = RandomForestClassifier(max_depth=10)\nforest_clf.fit(X_train_proc[:5000], y_train[:5000])\ndisplay_conf_mat(forest_clf, X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_forest = forest_clf.predict(X_test)\naccuracy_score(y_pred_forest, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Covolutional Neural Network**","metadata":{}},{"cell_type":"code","source":"# Reshape for CNN\nfrom sklearn.preprocessing import OneHotEncoder\n\nX_train_proc_cnn = X_train_proc.reshape((-1, 28, 28, 1))\ny_train_proc_cnn = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).toarray()\n\nX_test_cnn = X_test.reshape((-1, 28, 28, 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\nl2 = 0.001\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=((28, 28, 1))))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (1, 1), activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(l2)))\nmodel.add(layers.Dense(26, activation='softmax'))\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\nhistory = model.fit(X_train_proc_cnn, y_train_proc_cnn, batch_size=256, epochs=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\n\npredictions = model.predict(X_test_cnn)\ny_pred_cnn = tf.argmax(predictions, axis=1)\ny_pred_cnn = np.array(y_pred_cnn)\naccuracy_score(y_pred_cnn, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_mx = confusion_matrix(y_pred_cnn, y_test)\ncustom_confusion_matrix(cm=conf_mx, normalize=False,\n                        target_names=np.array(english_alphabet[0]).astype(str),\n                        title= \"CNN Confusion Matrix\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclutions","metadata":{}},{"cell_type":"markdown","source":"Provided a good data machine learning models can do a good job at predicting handwriten characters. The next step for this algorithm would be to pair it with an object-detection model that would detect and extract characters from pictures","metadata":{}},{"cell_type":"markdown","source":"# Lets have some fun","metadata":{}},{"cell_type":"markdown","source":"We will pick some letters manualy to form a word, and make our CNN model predict them","metadata":{}},{"cell_type":"code","source":"def predict_letters(images, width=14, height=14, alphabet=None, model=None):\n    rows, cols = 1, len(images)\n\n    fig=plt.figure(figsize=(width, height))\n    sub_plot_i = 1\n\n    for i in range(0, len(images)):\n        fig.add_subplot(rows, cols, sub_plot_i)\n        sub_plot_i += 1\n        image = images[i]\n        plt.imshow(image, cmap='gray')\n    fig.tight_layout()    \n    plt.show()\n    \n    predictions = tf.argmax(model.predict(images), axis=1).numpy() + 1\n    predictions = [alphabet.loc[p][0] for p in predictions]\n    \n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def look_for_characters(chars, alphabet=None):\n    char_idx = [alphabet[alphabet[0] == p].index[0] for p in chars]\n    return [list(y_test).index(c - 1) for c in char_idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_read = ['i', 'n', 't', 'r', 'u', 'd', 'e', 'r',  'a', 'l', 'e', 'r', 't']\nread_chars = look_for_characters(to_read, english_alphabet)\npred_read = predict_letters(X_test_cnn[read_chars], width=14, height=14, alphabet=english_alphabet, model=model)\nprint(pred_read)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets read our predictions out loud using a text to speech algorithm","metadata":{}},{"cell_type":"code","source":"!pip install gTTS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gtts import gTTS\nimport os\n  \n# The text that you want to convert to audio\n# mytext = 'Welcome to the new world'\nmytext = ''.join(pred_read)\n  \n# Language in which you want to convert\nlanguage = 'en'\n  \n# Passing the text and language to the engine, \n# here we have marked slow=False. Which tells \n# the module that the converted audio should \n# have a high speed\nmyobj = gTTS(text=mytext, lang=language, slow=False)\n  \n# Saving the converted audio in a mp3 file named\n# welcome \nmyobj.save(\"./welcome.mp3\")\n\n# Playing the converted file\nos.system(\"mpg321 ./welcome.mp3\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment\nimport IPython\n\npath = './welcome.mp3'\n\nIPython.display.Audio(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}