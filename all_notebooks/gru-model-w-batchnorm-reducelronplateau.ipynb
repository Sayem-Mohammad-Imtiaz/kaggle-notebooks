{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler(feature_range = (0, 1))\n\n# print(tf.VERSION)\nprint(tf.keras.__version__)\n\nrock_dataset = pd.read_csv(\"../input/emg-4/0.csv\", header=None) # class = 0\nscissors_dataset = pd.read_csv(\"../input/emg-4/1.csv\", header=None) # class = 1\npaper_dataset = pd.read_csv(\"../input/emg-4/2.csv\", header=None) # class = 2\nok_dataset = pd.read_csv(\"../input/emg-4/3.csv\", header=None) # class = 3\n\nframes = [rock_dataset, scissors_dataset, paper_dataset, ok_dataset]\ndataset = pd.concat(frames)\n\ndataset_train = dataset.iloc[np.random.permutation(len(dataset))]\ndataset_train.reset_index(drop=True)\n\nX_train = []\ny_train = []\n\nfor i in range(0, dataset_train.shape[0]):\n    row = np.array(dataset_train.iloc[i:1+i, 0:64].values)\n    X_train.append(np.reshape(row, (64, 1)))\n    y_train.append(np.array(dataset_train.iloc[i:1+i, -1:])[0][0])\n    \nX_train = np.array(X_train)\ny_train = np.array(y_train)\n\n# Reshape to one flatten vector\nX_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], 1)\nX_train = sc.fit_transform(X_train)\n\n# Reshape again after normalization to (-1, 8, 8)\nX_train = X_train.reshape((-1, 8, 8))\n\n# Convert to one hot\ny_train = np.eye(np.max(y_train) + 1)[y_train]\n\nprint(\"All Data size X and y\")\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Splitting Train/Test\nX_test = X_train[7700:]\ny_test = y_train[7700:]\nprint(\"Test Data size X and y\")\nprint(X_test.shape)\nprint(y_test.shape)\n\nX_train = X_train[0:7700]\ny_train = y_train[0:7700]\nprint(\"Train Data size X and y\")\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.layers import Dropout\n\nclassifier = Sequential()\n\nclassifier.add(GRU(units=32, return_sequences=True, input_shape=(X_train.shape[1], 8)))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(GRU(units = 64, return_sequences = True))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units = 100))\nclassifier.add(BatchNormalization())\n\nclassifier.add(GRU(units = 100, return_sequences = True))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(GRU(units = 64))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units = 64, activation=\"relu\"))\nclassifier.add(Dense(units = 128, activation=\"relu\"))\n\nclassifier.add(Dense(units = 4, activation=\"softmax\"))\n\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n\nclassifier.fit(X_train, y_train, epochs = 250, batch_size = 8, verbose=2, callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),keras.callbacks.ReduceLROnPlateau(patience=7) ])\n\n# Save\nclassifier.save(\"model_cross_splited_data.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###############################################\n\nfrom tensorflow import keras\n\n# # Load Model\n# model = keras.models.load_model('model_cross_splited_data.h5')\n# model.summary()\n\ndef evaluateModel(prediction, y):\n    good = 0\n    for i in range(len(y)):\n        if (prediction[i] == np.argmax(y[i])):\n            good = good +1\n    return (good/len(y)) * 100.0\n\nresult_test = classifier.predict_classes(X_test)\nprint(\"Correct classification rate on test data\")\nprint(evaluateModel(result_test, y_test))\n\nresult_train = classifier.predict_classes(X_train)\nprint(\"Correct classification rate on train data\")\nprint(evaluateModel(result_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.layers import Dropout\n\nclassifier = Sequential()\n\nclassifier.add(LSTM(units=32, return_sequences=True, input_shape=(X_train.shape[1], 8)))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(LSTM(units = 64, return_sequences = True))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units = 100))\nclassifier.add(BatchNormalization())\n\nclassifier.add(LSTM(units = 100, return_sequences = True))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(LSTM(units = 64))\nclassifier.add(Dropout(0.2))\n\nclassifier.add(Dense(units = 64, activation=\"relu\"))\nclassifier.add(Dense(units = 128, activation=\"relu\"))\n\nclassifier.add(Dense(units = 4, activation=\"softmax\"))\n\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n\nclassifier.fit(X_train, y_train, epochs = 250, batch_size = 8, verbose=2, callbacks=[keras.callbacks.EarlyStopping(restore_best_weights=True, patience=10),keras.callbacks.ReduceLROnPlateau(patience=7) ])\n\n# Save\nclassifier.save(\"model_cross_splited_data.h5\")\nprint(\"Saved model to disk\")\n\n###############################################\n\nfrom tensorflow import keras\n\n# # Load Model\n# model = keras.models.load_model('model_cross_splited_data.h5')\n# model.summary()\n\ndef evaluateModel(prediction, y):\n    good = 0\n    for i in range(len(y)):\n        if (prediction[i] == np.argmax(y[i])):\n            good = good +1\n    return (good/len(y)) * 100.0\n\nresult_test = classifier.predict_classes(X_test)\nprint(\"Correct classification rate on test data\")\nprint(evaluateModel(result_test, y_test))\n\nresult_train = classifier.predict_classes(X_train)\nprint(\"Correct classification rate on train data\")\nprint(evaluateModel(result_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}