{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sfb_permits = pd.read_csv('../input/building-permit-applications-data/Building_Permits.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sfb_permits.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sfb_permits.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sfb_permits.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sfb_permits.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Let's have a look at missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values = sfb_permits.isna().sum()\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*A lot of missing values here, let's heck the percentage of missing values in the whole dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cells = np.product(sfb_permits.shape)\ntotal_missing = missing_values.sum()\npercent_total_missing = total_missing/total_cells*100\npercent_total_missing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**More than a quarter of data is missing here**\n\n\n\n\n\n\n\n\n\n\n*So what do we do now?*"},{"metadata":{},"cell_type":"markdown","source":"### **As they say, there are three general methods to handle the missing values**\n\n\n### *1. Either you just drop those rows/columns which is having missing values*\n\n### *2. Impute( Fill in) the missing values*\n\n### *3. Use a predictor to fill in the missing values by ccreating a model on the available data in your dataset.*"},{"metadata":{},"cell_type":"markdown","source":"## 1. **Dropping the rows which possesses missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sfb_permits.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Oops!!! it's just deleted all our data which was there in the dataset, which means that there is not a single row which is immune to missing data. So this probably didn't work well. Let's look at the column operation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping columns with any single NaN values.\ndroppped_column_with_nan = sfb_permits.dropna(axis =1)\ndroppped_column_with_nan.sample(9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's just check how much data we've lost here.\nprint(\"Columns in original dataset: %d \\n\" % sfb_permits.shape[1])\nprint(\"Columns with na's dropped: %d\" % droppped_column_with_nan.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We have lost quite a bit of data here but now we've no missing values in our dataset.*"},{"metadata":{},"cell_type":"markdown","source":"## **2. Imputing the missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's say we want to impute '0' wherever the data is missing(NaN)\nimputed_dataset = sfb_permits.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check whether we have any missing values now \nimputed_dataset.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Slightly better approach than just imputing '0' is using methods like 'bfill' or 'ffill'\n>>*Method 'bfill' is Backward fill*\n\n\n>>*Method 'ffill' is forward fill*\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace all NA's the value that comes directly before it in the same column, \n# then replace all the reamining na's with 0\nusing_bfill_sfb = sfb_permits.fillna(method = 'bfill', axis=0).fillna(0)\nusing_bfill_sfb.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace all NA's the value that comes directly after it in the same column, \n# then replace all the reamining na's with 0\nusing_ffill_sfb = sfb_permits.fillna(method = 'ffill', axis=0).fillna(0)\nusing_ffill_sfb.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Using sklearn imputer method**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's just exclude the object data type here coz imputer can't handle it\nsfb_permits_num = sfb_permits.select_dtypes(exclude ='object')\nlen(sfb_permits_num.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\ndata_with_imputed_values = my_imputer.fit_transform(sfb_permits_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Ok, so we managed to fill in the NaN value with zero, but that's good only when you're a Novice. I am sure you won't usually perform it in a serious project, reason being you're losing a lot of data along the way which isn't acceptable and even though the values that you're imputing in order to eliminate the NaNs aren't possibly accurate, * **Which brings us to predicting the missing values**"},{"metadata":{},"cell_type":"markdown","source":"## **3. Predicting the missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Select target\ny = sfb_permits['Permit Type']\n\n# To keep things simple, we'll use only numerical predictors\nsfb_permits_predictors = sfb_permits.drop(['Permit Type'], axis=1)\nX = sfb_permits_predictors.select_dtypes(exclude=['object'])\n\n# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=10, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score from Approach 1 (Drop Columns with Missing Values)\n\n# Get names of columns with missing values\ncols_with_missing = [col for col in X_train.columns\n                     if X_train[col].isnull().any()]\n\n# Drop columns in training and validation data\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n\nprint(\"MAE from Approach 1 (Drop columns with missing values):\")\nprint(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score from Approach 2 (Imputation)\nfrom sklearn.impute import SimpleImputer\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n\n# Imputation removed column names; put them back\nimputed_X_train.columns = X_train.columns\nimputed_X_valid.columns = X_valid.columns\n\nprint(\"MAE from Approach 2 (Imputation):\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score from Approach 3 \n# Make copy to avoid changing original data (when imputing)\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n# Make new columns indicating what will be imputed\nfor col in cols_with_missing:\n    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n\n# Imputation removed column names; put them back\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shape of training data (num_rows, num_columns)\nprint(X_train.shape)\n\n# Number of missing values in each column of training data\nmissing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### So, why did imputation performed better than dropping the columns?\n\nThe training data has 159120 rows and 14 columns, where twelve columns contain missing data. So a lot of data is missing here. Thus, dropping the columns removes a lot of useful information, and so it makes sense that imputation would perform better."},{"metadata":{},"cell_type":"markdown","source":"### **Although i'm mentioning it the last but one of the most important factor is looking at the dataset and deciding whether the missing data is meaningful(i.e the height of the son is missing when the parents have no son at all ) or it's not recorded.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}