{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# QUIZ 2 | INSUFICIENCIA CARDÍACA","metadata":{}},{"cell_type":"markdown","source":"### Alan Rhenals | Juan Caro | Jose Manuel Montes ","metadata":{}},{"cell_type":"markdown","source":"Importación de Librerías","metadata":{}},{"cell_type":"code","source":"import pandas as pd #manejo y análisis de estructuras de datos.\nimport numpy as np #crear vectores y matrices + funciones matemáticas de alto nivel\nimport seaborn as sns #Visualizacion de datos estadisticos\nimport matplotlib.pyplot as plt #generación de gráficos\nfrom sklearn import preprocessing #procesamiento previo de datos\n%matplotlib inline \nfrom sklearn.linear_model import LogisticRegression #implementa la regresión logística regularizada\nfrom sklearn.model_selection import train_test_split #Divide matrices/listas en subconjuntos de prueba y entrenamiento aleatorio\nfrom sklearn.metrics import confusion_matrix #Calcula la matriz de confusión para evaluar la precisión de una clasificación.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Guardamos los datos y visualizamos los 5 primeros\ndf = pd.read_csv(\"../input/insuficienciacardiaca/dataset.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Generamos estadísticas descriptivas\ndf.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Imprime un resumen conciso de un DataFrame.\ndf.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlación de columnas por pares, excluyendo NA / valores nulos.\ndf.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#guardamos las variables de las columnas en X, excepto 'DEATH_EVENT'\nX = np.asarray(df.drop(['DEATH_EVENT'],1))\nX[0:5] #Visualizamos 5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape #Devuelve una tupla que representa la dimensionalidad del DataFrame","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convertimos la entrada en un array y la guardamos en y\ny = np.asarray(df['DEATH_EVENT'])\ny [0:5] #Visualizamos 5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Estandarizamos las características eliminando la media y escalando a la varianza de la unidad\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5] #Visualizamos 5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dividimos los array en subconjuntos de prueba y entrenamiento aleatorio aleatorio\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape) #Devuelve una tupla que representa la dimensionalidad del DataFrame\nprint ('Test set:', X_test.shape,  y_test.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = LogisticRegression(penalty='l2',C=0.01, solver='liblinear').fit(X_train,y_train) \nLR","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"penalty = especifica la norma utilizada en la penalización. Los solucionadores 'newton-cg', 'sag' y 'lbfgs' solo admiten penalizaciones 12.\nC = Inversa de la fuerza de regularización; debe ser un float positivo.\nsolver = Algoritmo a utilizar en el problema de optimización.\nPara conjuntos de datos pequeños, 'liblinear' es una buena opción","metadata":{}},{"cell_type":"code","source":"#Predicciones\nMP = LR.predict(X_test)\nMP","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MP_prob = LR.predict_proba(X_test)\nMP_prob","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\n#Imprimimos y trazamos la matriz de confusión.\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Matriz de Confusion Normalizada\")\n    else:\n        print('Matriz de Confusion Sin Normalizar')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_test, MP, labels=[1,0]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calcula la matriz de confusión\ncnf_matrix = confusion_matrix(y_test, MP, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n#Grafica la matriz de confusión no normalizada\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Death Event=1','Death Event=0'],normalize= False,  title='Confusion matrix')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Resultados\nprint (classification_report(y_test, MP))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Interpretación de Resultados","metadata":{}},{"cell_type":"markdown","source":"1. Con la métrica de precisión podemos medir la calidad del modelo en tareas de clasificación:\n\n  * Precision en Prediccion de personas que no moririan = 89%\n  * Precision en Prediccion de personas que moririan = 81%\n  ----\n\n2. La métrica de recall nos va a informar sobre la cantidad que el modelo es capaz de identificar:\n\n* El modelo identificará a 93% de los pacientes que no moriran\n* El modelo identificará a 72% de los pacientes que moriran\n____\n\n3. La exactitud (accuracy) mide el porcentaje de casos que el modelo ha acertado:\n * Nuestro modelo ha acertado en un 83% de los casos\n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}