{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Smart Building System\n"},{"metadata":{},"cell_type":"markdown","source":"*Accuracy : 94.40137831403612*\n\n<!-- *F1 Score : 0.3956073003400257* -->\nF1 Score : 0.38970552797725183\n\n*------------------------------------------*\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom pathlib import Path\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"paths = list(Path('/kaggle/input/smart-building-system/KETI/').rglob('*.*'))\n\n## Features path\nco2_paths = [path for path in paths if path.name == 'co2.csv']\nhumidity_paths = [path for path in paths if path.name == 'humidity.csv']\ntemperature_paths = [path for path in paths if path.name == 'temperature.csv']\nlight_paths = [path for path in paths if path.name == 'light.csv']\n\n\n## Target path\npir_paths = [path for path in paths if path.name == 'pir.csv']\n\nframes = []\nfor light_path, temperature_path, co2_path, pir_path, humidity_path in zip(light_paths, temperature_paths, co2_paths, pir_paths, humidity_paths):\n    \n    ## Features\n    light_df = pd.read_csv(light_path, names=['unix_time', 'light'], index_col='unix_time')\n    temperature_df = pd.read_csv(temperature_path, names=['unix_time', 'temperature'], index_col='unix_time')\n    co2_df = pd.read_csv(co2_path, names=['unix_time', 'co2'], index_col='unix_time')\n    humidity_df = pd.read_csv(humidity_path, names=['unix_time', 'humidity'], index_col='unix_time')\n    \n    ##Target\n    pir_df = pd.read_csv(pir_path, names=['unix_time', 'pir'], index_col='unix_time')\n    \n    ##Adding into single label\n    df = pd.concat([light_df, temperature_df, co2_df, pir_df, humidity_df], axis=1)\n    df['room'] = light_path.parent.name\n    frames.append(df)\ndata = pd.concat(frames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"------------------Data ------------------\")\nprint(data.head())\nprint(\"---------------------------------------------\\n\")\nprint('No of rows:{}'.format(data.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define the function\ndef percent_missing(df):\n    data = pd.DataFrame(df)\n    df_cols = list(pd.DataFrame(data))\n    dict_x = {}\n    for i in range(0, len(df_cols)):\n        dict_x.update({df_cols[i]: round(data[df_cols[i]].isnull().mean()*100,2)})\n    \n    return dict_x\n\nmissing = percent_missing(data)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\nprint('Percent of missing data')\ndf_miss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna(subset=['pir'])\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing = percent_missing(data)\ndf_miss = sorted(missing.items(), key=lambda x: x[1], reverse=True)\nprint('Percent of missing data')\ndf_miss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Target\ny= data.pop(\"pir\")\ny = y.apply(lambda x:0 if x==0 else 1)\n\n#Features\nx= data\n\nprint(\"-------------------------------\")\nprint(x.head())\nprint(\"-------------------------------\")\nprint(y.head())\nprint('----------------------')\nprint('No of rows:{}'.format(x.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n    \nx.room=le.fit_transform(x.room)\n\nprint(\"-------------------------------\")\nprint('Room column dtype: {}'.format(x.room.dtype))\nprint(\"-------------------------------\")\nprint(x.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.impute import SimpleImputer\n\n# # Imputation\n# my_imputer = SimpleImputer()\n# X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n# X_test = pd.DataFrame(my_imputer.transform(X_test))\n\nfrom sklearn.experimental import enable_iterative_imputer  #\n\nfrom sklearn.impute import IterativeImputer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp = IterativeImputer(max_iter=10, \n                       random_state=0,\n                      n_nearest_features=2,\n                      initial_strategy='most_frequent',\n                    add_indicator=True,\n                      verbose=1)\n\n\nX_train = pd.DataFrame(imp.fit_transform(X_train))\nX_test = pd.DataFrame(imp.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Accuracy Function\nimport matplotlib.pyplot as plt  \nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\n\ndef acc(clf,y_test,y_pred,X_test):\n    print('------------------------------------------')\n    print('Accuracy :',accuracy_score(y_test,y_pred)*100)\n    print('------------------------------------------')\n    print('Precision :',precision_score(y_test, y_pred))\n    print('------------------------------------------')\n    print('Recall :',recall_score(y_test, y_pred))\n    print('------------------------------------------')\n    print('Roc Auc :',roc_auc_score(y_test, y_pred))\n    print('------------------------------------------')\n    print('\\n')\n    print('------------------------------------------')\n    print('F1 Score :',f1_score(y_test, y_pred))\n    print('------------------------------------------')\n    plot_confusion_matrix(clf, X_test, y_pred)\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nclf = Pipeline([\n('scaler', StandardScaler()),\n  ('classification',  XGBClassifier())\n])\nclf.fit(X_train,y_train)\ny_pred= clf.predict(X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc(clf,y_test, y_pred,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.linear_model import SGDClassifier\n\n# model= SGDClassifier()\n\n# model.fit(X_train,y_train)\n\n# y_pred= model.predict(X_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# acc(model,y_test, y_pred,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n# model_one =QuadraticDiscriminantAnalysis()\n\n\n# model_one.fit(X_train,y_train)\n\n# y_pred= model_one.predict(X_test)\n\n# acc(model_one,y_test, y_pred,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.svm import LinearSVC\n# from sklearn.feature_selection import SelectFromModel\n# from sklearn.pipeline import Pipeline\n# from sklearn.preprocessing import StandardScaler\n    \n# model_two = Pipeline([\n# #   ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n#     ('scaler', StandardScaler()),\n#   ('classification',  XGBClassifier())\n# ])\n\n\n\n# model_two.fit(X_train,y_train)\n# y_pred= model_two.predict(X_test)\n\n\n# acc(model_two,y_test, y_pred,X_test)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.svm import LinearSVC\n# from sklearn.feature_selection import SelectFromModel\n# from sklearn.pipeline import Pipeline\n# from sklearn.preprocessing import StandardScaler\n    \n# # model_two = Pipeline([\n# #   ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n# # #     ('scaler', StandardScaler()),\n# #   ('classification',  XGBClassifier())\n# # ])\n\n# linear = LinearSVC()\n# sfm = SelectFromModel(linear)\n# sfm.fit(X_train, y_train)\n\n# X_test_transform = sfm.transform(X_test)\n\n# X_train_transform = sfm.transform(X_train)\n\n\n# # sfm.fit(X_train,y_train)\n# # y_pred= sfm.predict(X_test)\n\n\n# # acc(model_two,y_test, y_pred,X_test)\n\n# X_test_transform.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_final = XGBClassifier()\n# model_final.fit(X_train_transform,y_train)\n\n# y_pred= model_final.predict(X_test_transform)\n\n# acc(model_final,y_test, y_pred,X_test_transform)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}