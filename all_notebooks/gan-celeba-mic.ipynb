{"cells":[{"metadata":{"_uuid":"33f9b0bd-ce2c-4497-9f43-a450f6e290a3","_cell_guid":"724542ba-a822-4737-a916-2a1689b6dc0e","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function\n%matplotlib inline\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\n\n\n\nmanualSeed = 999\n\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagefolder = '/kaggle/input/celeba-dataset/img_align_celeba'\nprint(os.listdir(imagefolder))\n\nout_folder = \"/kaggle/working/models/celeba/\"\n\nbatch_size = 128\nimage_size = 64\nnc = 3\nnoise_dim = 100\nnum_epochs = 0\nlr = 0.0002\nbeta1 = 0.5\niter_check = 2000\nprint_check = 100\ndemo_batch_size = 5\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\nprint(device)\n\nNUM_TRAIN = 200000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/kaggle/working/models\")\nos.mkdir(\"/kaggle/working/models/celeba\")\nos.mkdir(\"/kaggle/working/models/dataloader\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dset.ImageFolder(root=imagefolder,transform=transforms.Compose([\n                               transforms.Resize(image_size),\n                               transforms.CenterCrop(image_size),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\n\nprint(len(dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = [i for i in range(NUM_TRAIN)]\nprint(mask[0])\ntraining_set = torch.utils.data.Subset(dataset,mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_mask  = [i for i in range(NUM_TRAIN,len(dataset))]\nprint(val_mask[-1])\nval_set = torch.utils.data.Subset(dataset,val_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/working/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loader = torch.utils.data.DataLoader(val_set, batch_size=32,\n                                         shuffle=True,drop_last=True ,num_workers=4,pin_memory=True)\nprint(len(val_loader))\n\ntorch.save(val_loader,\"/kaggle/working/models/dataloader/test.pt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"/kaggle/working/models/dataloader\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(training_set))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create the dataloader\ndataloader = torch.utils.data.DataLoader(training_set, batch_size=batch_size,\n                                         shuffle=True,drop_last=True ,num_workers=4,pin_memory=True)\nprint(len(dataloader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_batch = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from models import Generator,Discriminator\nfrom helpers import initialize_weights,get_optimizer\nGen = Generator().to(device)\nDis = Discriminator().to(device) \n\nGen.apply(initialize_weights)\nDis.apply(initialize_weights)\n\ncriterion = nn.BCEWithLogitsLoss()\n\nGen_opt = get_optimizer(Gen)\nDis_opt = get_optimizer(Dis)\n\nrandom_images = []\nfixed_noise = torch.randn(64, noise_dim, 1, 1, device=device)\n\niters = 0\nG_losses = []\nD_losses = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs=25\nprint(iter_check)\niter_check=1000\nprint(num_epochs)\nprint(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs_done = 25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"new_epochs = 2\nnum_epochs = epochs_done + new_epochs\nfor epoch in range(epochs_done,num_epochs):\n    for i,data in enumerate(dataloader,0):\n        Dis_opt.zero_grad()\n        data = data[0]\n        real_images = data.to(device)\n        b_size=real_images.size(0)\n\n        d_label_real=0.9*torch.ones(b_size,device=device) + 0.1*torch.rand(b_size,device=device)\n        d_real = Dis(real_images).view(-1)\n        d_loss_real = criterion(d_real,d_label_real)\n\n        d_noise=torch.randn(b_size,noise_dim, 1, 1,device=device)\n        d_fake_images = Gen(d_noise).detach()\n        d_fake = Dis(d_fake_images).view(-1)\n        d_fake_label = torch.zeros(b_size,device=device)\n        d_loss_fake = criterion(d_fake,d_fake_label)\n\n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n\n        D_x = d_real.mean().item()\n        D_G_z1 = d_fake.mean().item()\n\n        Dis_opt.step()\n\n        Gen_opt.zero_grad()\n        g_noise=torch.randn(b_size,noise_dim, 1, 1,device=device)\n        g_fake_images=Gen(g_noise)\n\n        g_label = torch.ones(b_size,device=device)\n\n        g_fake_images = Dis(g_fake_images).view(-1)\n        g_loss = criterion(g_fake_images,g_label)\n        g_loss.backward()\n        D_G_z2 = g_fake_images.mean().item()\n\n        Gen_opt.step()\n\n        if i % print_check == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     d_loss.item(), g_loss.item(), D_x, D_G_z1, D_G_z2))\n        \n        # Save Losses for plotting later\n        G_losses.append(g_loss.item())\n        D_losses.append(d_loss.item())\n        \n        # Check how the generator is doing by saving G's output on fixed_noise\n        if (iters % iter_check == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = Gen(fixed_noise).detach().cpu()\n            random_images.append(vutils.make_grid(fake, padding=2, normalize=True))\n            \n        iters += 1\n    curr_outpath=os.path.join(out_folder,\"celeba_epoch{}.pt\".format(epoch+1))\n    torch.save({\"epoch\":epoch+1,\"state_dict_G\":Gen.state_dict(),\n                \"state_dict_D\":Dis.state_dict(),\n                \"opt_G\":Gen_opt.state_dict(),\n                \"opt_D\":Dis_opt.state_dict()\n    },curr_outpath)\n    epochs_done += 1\n    print(epoch+1)\n    plt.subplot(1,1,1)\n    plt.axis(\"off\")\n    plt.title(\"Images\")\n    plt.imshow(np.transpose(random_images[-1],(1,2,0)))\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fixed_noise = torch.randn(16, noise_dim, 1, 1, device=device)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_epochs = 1\nnum_epochs = epochs_done + new_epochs\nfor epoch in range(epochs_done,num_epochs):\n    for i,data in enumerate(dataloader,0):\n        Dis_opt.zero_grad()\n        data = data[0]\n        real_images = data.to(device)\n        b_size=real_images.size(0)\n\n        d_label_real=0.9*torch.ones(b_size,device=device) + 0.1*torch.rand(b_size,device=device)\n        d_real = Dis(real_images).view(-1)\n        d_loss_real = criterion(d_real,d_label_real)\n\n        d_noise=torch.randn(b_size,noise_dim, 1, 1,device=device)\n        d_fake_images = Gen(d_noise).detach()\n        d_fake = Dis(d_fake_images).view(-1)\n        d_fake_label = torch.zeros(b_size,device=device)\n        d_loss_fake = criterion(d_fake,d_fake_label)\n\n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n\n        D_x = d_real.mean().item()\n        D_G_z1 = d_fake.mean().item()\n\n        Dis_opt.step()\n\n        Gen_opt.zero_grad()\n        g_noise=torch.randn(b_size,noise_dim, 1, 1,device=device)\n        g_fake_images=Gen(g_noise)\n\n        g_label = torch.ones(b_size,device=device)\n\n        g_fake_images = Dis(g_fake_images).view(-1)\n        g_loss = criterion(g_fake_images,g_label)\n        g_loss.backward()\n        D_G_z2 = g_fake_images.mean().item()\n\n        Gen_opt.step()\n\n        if i % print_check == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     d_loss.item(), g_loss.item(), D_x, D_G_z1, D_G_z2))\n        \n        # Save Losses for plotting later\n        G_losses.append(g_loss.item())\n        D_losses.append(d_loss.item())\n        \n        # Check how the generator is doing by saving G's output on fixed_noise\n        if (iters % iter_check == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = Gen(fixed_noise).detach().cpu()\n            random_images.append(vutils.make_grid(fake, padding=2, normalize=True))\n            \n        iters += 1\n    curr_outpath=os.path.join(out_folder,\"celeba_epoch{}.pt\".format(epoch+1))\n    torch.save({\"epoch\":epoch+1,\"state_dict_G\":Gen.state_dict(),\n                \"state_dict_D\":Dis.state_dict(),\n                \"opt_G\":Gen_opt.state_dict(),\n                \"opt_D\":Dis_opt.state_dict()\n    },curr_outpath)\n    epochs_done += 1\n    print(epoch+1)\n    plt.axis(\"off\")\n    plt.title(\"Images\")\n    plt.imshow(np.transpose(random_images[-1],(1,2,0)))\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.axis(\"off\")\nplt.title(\"Images\")\nplt.imshow(np.transpose(random_images[-1],(1,2,0)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n     fake = Gen(fixed_noise).detach().cpu()\nrandom_images.append(vutils.make_grid(fake, padding=2, normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloader = torch.utils.data.DataLoader(training_set, batch_size=32,\n                                         shuffle=True,drop_last=True ,num_workers=4,pin_memory=True)\nprint(len(dataloader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_epochs = 1\nnum_epochs = epochs_done + new_epochs\nfor epoch in range(epochs_done,num_epochs):\n    for i,data in enumerate(dataloader,0):\n        Dis_opt.zero_grad()\n        data = data[0]\n        real_images = data.to(device)\n        \n        b_size=real_images.size(0)\n\n        d_label_real=0.9*torch.ones(b_size,device=device) + 0.1*torch.rand(b_size,device=device)\n        d_real = Dis(real_images).view(-1)\n        d_loss_real = criterion(d_real,d_label_real)\n\n        d_noise=torch.randn(b_size,noise_dim, 1, 1,device=device)\n        d_fake_images = Gen(d_noise).detach()\n        d_fake = Dis(d_fake_images).view(-1)\n        d_fake_label = torch.zeros(b_size,device=device)\n        d_loss_fake = criterion(d_fake,d_fake_label)\n\n        d_loss = d_loss_real + d_loss_fake\n        d_loss.backward()\n\n        D_x = d_real.mean().item()\n        D_G_z1 = d_fake.mean().item()\n\n        Dis_opt.step()\n\n        Gen_opt.zero_grad()\n        g_noise=torch.randn(b_size,noise_dim, 1, 1,device=device)\n        g_fake_images=Gen(g_noise)\n\n        g_label = torch.ones(b_size,device=device)\n\n        g_fake_images = Dis(g_fake_images).view(-1)\n        g_loss = criterion(g_fake_images,g_label)\n        g_loss.backward()\n        D_G_z2 = g_fake_images.mean().item()\n\n        Gen_opt.step()\n\n        if i % print_check == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     d_loss.item(), g_loss.item(), D_x, D_G_z1, D_G_z2))\n            print(real_images.size())\n        \n        # Save Losses for plotting later\n        G_losses.append(g_loss.item())\n        D_losses.append(d_loss.item())\n        \n        # Check how the generator is doing by saving G's output on fixed_noise\n        if (iters % iter_check == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = Gen(fixed_noise).detach().cpu()\n            random_images.append(vutils.make_grid(fake, padding=2, normalize=True))\n            \n        iters += 1\n    curr_outpath=os.path.join(out_folder,\"celeba_epoch{}.pt\".format(epoch+1))\n    torch.save({\"epoch\":epoch+1,\"state_dict_G\":Gen.state_dict(),\n                \"state_dict_D\":Dis.state_dict(),\n                \"opt_G\":Gen_opt.state_dict(),\n                \"opt_D\":Dis_opt.state_dict()\n    },curr_outpath)\n    epochs_done += 1\n    print(epoch+1)\n    plt.axis(\"off\")\n    plt.title(\"Images\")\n    plt.imshow(np.transpose(random_images[-1],(1,2,0)))\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.lines import Line2D\ndef plot_grad_flow(named_parameters):\n    '''Plots the gradients flowing through different layers in the net during training.\n    Can be used for checking for possible gradient vanishing / exploding problems.\n    \n    Usage: Plug this function in Trainer class after loss.backwards() as \n    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n    ave_grads = []\n    max_grads= []\n    layers = []\n    for n, p in named_parameters:\n        if(p.requires_grad) and (\"bias\" not in n):\n            layers.append(n)\n            ave_grads.append(p.grad.abs().mean())\n            max_grads.append(p.grad.abs().max())\n    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n    plt.xlim(left=0, right=len(ave_grads))\n    plt.ylim(bottom = -0.001, top=0.05) # zoom in on the lower gradient regions\n    plt.xlabel(\"Layers\")\n    plt.ylabel(\"average gradient\")\n    plt.title(\"Gradient flow\")\n    plt.grid(True)\n    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n                Line2D([0], [0], color=\"b\", lw=4),\n                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_grad_flow(Dis.named_parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageMask(torch.utils.data.Dataset):\n  def __init__(self, dataset, image_size=(3,64,64),param=0.4):\n    self.dataset = dataset\n    self.image_size = image_size\n    self.image_shape = (image_size[1],image_size[2])\n    self.map = ['random','center','left','right','grid','up','down']\n    self.param = param\n  \n  def __getitem__(self, index):\n    target_image = self.dataset[index][0]\n    assert(torch.is_tensor(target_image))\n    \n    maskType = self.map[index%2]\n    mask = np.ones(self.image_shape)\n\n    param = 0.4\n    if maskType == 'random':\n        mask[np.random.random(self.image_shape) < param] = 0.0\n    elif maskType == 'center':\n        centerScale = 0.35\n        sz = tuple([(int)(z * centerScale) for z in self.image_shape])\n        mask[ sz[1]:-sz[1], sz[0]:-sz[0]] = 0.0\n    elif maskType == 'left':\n        c = self.image_shape[1] // 2\n        mask[:c,:] = 0.0\n    elif maskType == 'right':\n        c = self.image_shape[1] // 2\n        mask[c:,:] = 0.0\n    elif maskType == 'grid':\n        mask[::4,::4] = 0.0\n    elif maskType == 'up':\n        c = self.image_shape[0] // 2\n        mask[:,:c] = 0.0\n    elif maskType == 'down':\n        c = self.image_shape[0] // 2\n        mask[:,c:] = 0.0\n    else:\n        assert(False)\n\n    return (target_image, torch.FloatTensor(mask))\n  \n  def __len__(self):\n    return len(self.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masked_dataset = ImageMask(val_set)\nmasked_loader = torch.utils.data.DataLoader(masked_dataset, batch_size=64,\n                                         shuffle=False,drop_last=True ,num_workers=0,pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from models import Generator,Discriminator\n\nGen_eval = Generator().to(device)\nDis_eval = Discriminator().to(device) \n\nGen_eval.load_state_dict(Gen.state_dict())\nDis_eval.load_state_dict(Dis.state_dict())\n\nGen_eval.eval()\nDis_eval.eval()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from models import Generator,Discriminator\n\npretrained = torch.load(\"../input/pretrained/celeba_epoch31.pt\")\nGen_eval = Generator().to(device)\nDis_eval = Discriminator().to(device) \n\nGen_eval.load_state_dict(pretrained[\"state_dict_G\"])\nDis_eval.load_state_dict(pretrained[\"state_dict_D\"])\n\nGen_eval.eval()\nDis_eval.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for p in Gen_eval.parameters():\n    p.requires_grad=False\n    \nfor p in Dis_eval.parameters():\n    p.requires_grad=False\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WINDOW_SIZE = 7\nprior_loss_parameter = 0.003\nspecial_conv = torch.ones(1,1,WINDOW_SIZE,WINDOW_SIZE,device=device)\ninpaint_iters = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_gradient(image,device):\n    grad_mat = torch.Tensor([[[[1, 0, -1], [2, 0, -2], [1, 0, -1]]]]).to(device)\n    image_size = image.size()\n    image = image.view(-1, 1, image_size[2], image_size[3])\n    grad_x = torch.nn.functional.conv2d(image, grad_mat, padding=1)\n    grad_y = torch.nn.functional.conv2d(image, torch.transpose(grad_mat, 2, 3), padding=1)\n    return grad_x.view(image_size), grad_y.view(image_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def posisson_blending(masks, masks_inv, generated_images, corrupted_images,device ,blending_steps=3000):\n  #reference: https://zhuanlan.zhihu.com/p/51279118\n    initial_guess = masks*corrupted_images + (masks_inv)*generated_images\n    optimum = initial_guess.requires_grad_()\n    optimizer = torch.optim.Adam([optimum])\n    generated_grad_x, generated_grad_y = image_gradient(generated_images,device)\n\n    for epoch in range(blending_steps):\n        optimizer.zero_grad()\n        image_optimum_grad_x, image_optimum_grad_y = image_gradient(optimum,device)\n        loss = torch.sum(((generated_grad_x-image_optimum_grad_x)**2 + (generated_grad_y-image_optimum_grad_y)**2)*(masks_inv))\n        loss.backward()\n        optimum.grad = optimum.grad*(masks_inv) #maintaining fixed pixel values\n        optimizer.step()\n\n    return optimum.detach()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ninpaint_iters=1500\nfor i,data in enumerate(masked_loader,0):\n    \n    b_size = data[0].size(0)\n    image_batch = data[0].to(device)\n    masks = data[1].to(device).unsqueeze(1)\n    masks_inv = torch.ones_like(masks) - masks\n    \n    weighted_masks = (torch.nn.functional.conv2d(masks_inv,special_conv,padding=WINDOW_SIZE//2)*masks + masks)/(WINDOW_SIZE*WINDOW_SIZE)\n\n    z_closest = torch.randn(b_size,noise_dim,1,1,device=device,requires_grad=True)\n    z_optimizer = torch.optim.Adam([z_closest])\n    \n    prior_criterior = nn.BCEWithLogitsLoss()\n    \n    for i in range(inpaint_iters):\n        z_optimizer.zero_grad()\n        fake_images = Gen_eval(z_closest)\n        d_output = Dis_eval(fake_images).view(-1)\n\n        prior_loss=prior_loss_parameter*prior_criterior(d_output,torch.ones(b_size,device=device))\n\n        context_loss = torch.norm(weighted_masks*(fake_images - image_batch),p=1)\n        loss = context_loss + prior_loss\n        loss.backward()\n        z_optimizer.step()\n    inpainted_images_gan = Gen_eval(z_closest.detach()).detach()    \n    inpainted_images = posisson_blending(masks,masks_inv,inpainted_images_gan,image_batch,device,blending_steps=1000)\n    \n    for img,gen_img,genp_img,mask in zip(image_batch,inpainted_images_gan,inpainted_images,masks):\n        og = transforms.ToPILImage(mode=\"RGB\")(img.cpu()/2 + 0.5)\n        inp = transforms.ToPILImage(mode=\"RGB\")(gen_img.cpu()/2 + 0.5)\n        inpp = transforms.ToPILImage(mode=\"RGB\")((genp_img/2 + 0.5).cpu())\n        ogm = transforms.ToPILImage(mode=\"RGB\")(((img/2 + 0.5)*mask).cpu())\n        inpm = transforms.ToPILImage(mode=\"RGB\")(((gen_img/2 + 0.5)*mask).cpu())\n        inppm = transforms.ToPILImage(mode=\"RGB\")(((genp_img/2 + 0.5)*mask).cpu())\n        pinp = transforms.ToPILImage(mode=\"RGB\")(((img/2 + 0.5)*mask + (gen_img/2 + 0.5)*(1-mask)).cpu())\n        pinpm = transforms.ToPILImage(mode=\"RGB\")(((img/2 + 0.5)*mask).cpu())\n        f = plt.figure()\n        f.add_subplot(2,4, 1)\n        plt.imshow(og)\n        f.add_subplot(2,4, 2)\n        plt.imshow(ogm)\n        f.add_subplot(2,4, 3)\n        plt.imshow(inp)\n        f.add_subplot(2,4, 4)\n        plt.imshow(inpm)\n        f.add_subplot(2,4, 5)\n        plt.imshow(inpp)\n        f.add_subplot(2,4, 6)\n        plt.imshow(inppm)\n        f.add_subplot(2,4, 7)\n        plt.imshow(pinp)\n        f.add_subplot(2,4, 8)\n        plt.imshow(pinpm)\n        plt.show(block=True)\n        \n    break\n        \n    \n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}