{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport missingno as msno\nfrom sklearn.impute import KNNImputer\n# Autoreg, autocorrolationand time series tools...\n\nfrom pandas.plotting import lag_plot, autocorrelation_plot\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\n\n\nplt.style.use('seaborn-whitegrid')\n\nfrom termcolor import colored","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a quick overview and analysis on the AQI(air quality index) of many cities in India. It's really interesting to examine different factors and see what has changed and how. We'll try to get an overall understanding of the coronavirus situation.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"city_day = pd.read_csv('/kaggle/input/air-quality-data-in-india/city_day.csv').sort_values(by = ['Date', 'City'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(city_day.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_day.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_day.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_day.Date = city_day.Date.apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d'))\ncity_day = city_day.sort_values(by = 'Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Date starts from {}, and ends in {}'.format(city_day.Date.min().strftime('%Y-%m-%d'), city_day.Date.max().strftime('%Y-%m-%d')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see which columns/type of pollution are generally making the AQI go higher.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"city_day.corr().AQI.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's generate some features:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding all the features with corr less than 0.4\n\ncity_day['B_X_O3_NH3'] = city_day['Benzene'] +\\\ncity_day['Xylene'] + city_day['O3'] + city_day['NH3']\n\ncity_day['ParticulateMatters'] = city_day['PM2.5'] + city_day['PM10']\n\ncorr_with_AQI = city_day.corr().AQI.sort_values(ascending = False)\n\n\ncorr_with_AQI\n# from here we can see: we can impute values with linear\n# interpolation for the ones that have high value of corr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how much is the average amount of pollution in each city stations\nmost_polluted = city_day[['City', 'AQI', 'PM10', 'CO']].groupby(['City']).mean().sort_values(by = 'AQI', ascending = False)\nmost_polluted","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nf, ax_ = plt.subplots(1, 3, figsize = (15,15))\n\nbar1 = sns.barplot(x = most_polluted.AQI,\n                   y = most_polluted.index,\n                   palette = 'Reds_r',\n                   ax = ax_[0]);\n\nbar1 = sns.barplot(x = most_polluted.PM10,\n                   y = most_polluted.index,\n                   palette = 'RdBu',\n                   ax = ax_[1]);\n\nbar1 = sns.barplot(x = most_polluted.CO,\n                   y = most_polluted.index,\n                   palette = 'RdBu',\n                   ax = ax_[2]);\n\ntitles = ['AirQualityIndex', 'ParticulateMatter10', 'CO']\nfor i in range(3) :\n    ax_[i].set_ylabel('')   \n    ax_[i].set_yticklabels(labels = ax_[i].get_yticklabels(),fontsize = 14);\n    ax_[i].set_title(titles[i])\n    f.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wait a minute... how is Ahmadabad more polluted than Dehli, but doesn't have a high amount of particulate matter?(PM10)\nwell it may be because of the stations, maybe they could not measure this feature from the early days that this survay started.\nLet's findout when were the first times that each measurement has been being conducted for each city so we won't be misunderstanding anything.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"most_polluted = city_day[['City', 'AQI', 'PM10', 'CO']].groupby(['City']).mean().sort_values(by = 'AQI', ascending = False)\n\ncities = most_polluted.index\nparams = most_polluted.columns\n\ndef first_date(city, parameter):\n    df = city_day[(city_day.City == city)]\n    df = df[df[parameter].notnull()]\n    if len(df) != 0:\n        return df.iloc[0].Date.strftime('%Y-%m-%d')\n    else: return('no_measurement')\n        \n        \nfor city in cities:\n    #print(colored('city: ', 'green'), city)\n    for param in params:\n      #  print('param: ', param)\n        most_polluted.loc[city, str(param) + '_date'] = first_date(city, param)\n        \nmost_polluted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Oh yes. That's right, they didn't even measure PM10 till June 2015. \nBut now let's look at the sum of all the pollution measurements and compare them to each other.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sum of pollution\nimport plotly.express as px\n\ndf = city_day.drop(columns = ['Date', 'AQI_Bucket', 'AQI']).groupby('City').sum().reset_index()\nfig = px.treemap(pd.melt(df, id_vars = 'City'), path=['City','variable'],\n                 values=pd.melt(df, id_vars = 'City')['value'],\n                 title = 'Cities and the proportion of pollution in each')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if there is any seasonality(visually and not with any stat tool, but we'll see more on this later on this kernel)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"city_day['Year_Month'] = city_day.Date.apply(lambda x : x.strftime('%Y-%m'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = city_day.groupby(['Year_Month']).sum().reset_index()\n\n# let's only see those that are important to the AQI\n# otherwise we will have a messy plot\n\nmetrices = corr_with_AQI[corr_with_AQI>0.5].index","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid');\nfig, ax_ = plt.subplots(figsize=(20,10));\n\ndf = city_day.groupby(['Year_Month']).sum().reset_index()\n\nfor col in metrices:\n    x = df['Year_Month']\n    y = df[col]\n    \n    ax_.plot_date(x ,y ,label=col, linestyle=\"-\");\n    \nax_.set_xticklabels(df['Year_Month'], rotation=85);\nax_.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For most metrices we can see that there is an obvious seasonality with an increasing trend. We will go deeper into this seasonality by plotting the sum of pollution in all years with respect to the months.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"city_day['Month'] = city_day.Date.dt.month\ncity_day['Year'] = city_day.Date.dt.year\n\nindex = 'Month'\ndf = city_day.groupby([index]).sum().reset_index()\n\nplt.style.use('seaborn-whitegrid');\nfig, ax_ = plt.subplots(figsize=(21,8));\n\n\nfor i, col in enumerate(metrices):\n    x = df[index]\n    y = df[col]\n    plot = sns.lineplot(x ,y );\n    \n\nplot.set_xticklabels(df[index], );\nax_.set(xlabel='Metrics', ylabel='Months');\nleg = plot.legend(title='legends', loc='upper left', labels=metrices, fontsize = 11);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The pollution level drops as we get closer to summer and again escelates in colder seasons. This is deemed to be related to the monsoon(the wind that carries heavy rains to southern Asia.)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = city_day.groupby(['Year_Month']).sum().reset_index()\n\nplt.style.use('seaborn-whitegrid')\nfig, ax_ = plt.subplots(len(metrices), 1, figsize=(20,50))\n\nfig.tight_layout(pad=4)\nfor i, col in enumerate(metrices):\n    \n    x = df['Year_Month']\n    y = df[col]\n    ax_[i].plot_date(x ,y ,label=col, linestyle=\"-\")\n    ax_[i].set_xticklabels(df['Year_Month'], rotation=85);\n    ax_[i].legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Null values?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def tell_me_null(df):\n    num_null = df.isnull().sum().sort_values(ascending = False)\n    percentage_null = round(df.isnull().sum().sort_values(ascending = False)/len(df) * 100, 1)\n    return pd.DataFrame(np.c_[num_null, percentage_null], index = num_null.index,  columns = ['# of Null', 'Percentage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tell_me_null(city_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nmsno.matrix(city_day, );","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we'll work on one city and fill it's values and go deeper on that one for simplicity\n\ndelhi = city_day[(city_day.AQI.notnull()) & (city_day.City == 'Delhi')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delhi.corr().AQI.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tell_me_null(delhi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = delhi.corr().AQI.sort_values(ascending = False)\nrelated = list(corr[corr>0.6].index)\nprint(related)\ninter = delhi.loc[:, related].interpolate(method = 'linear');\ndelhi.loc[:, related] = inter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delhi.columns","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"knn_imputer = KNNImputer(n_neighbors = 3)\n\nimputing_cols = [ 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2',\n       'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI', 'B_X_O3_NH3',\n       'ParticulateMatters', 'Month', 'Year']\n# we eliminated city, date, Year_Month and AQI_Bucket because \n# they either were unique or had numerical substitude in other fields(AQI_bucket)\n\nknn_imputer.fit(delhi[imputing_cols])\n\nimputed = knn_imputer.transform(delhi[imputing_cols])\n\ndelhi.loc[:, imputing_cols] = imputed\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tell_me_null(delhi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we want to see what would have happened if there was no quarentine\n# so we start our analysis using the data before 2020\n# but first let's see how many records are in 2020\n\nx_pred_after = delhi[delhi.Date > '2020-01-01']\ndelhi_b = delhi[delhi.Date < '2020-01-01']\n\nprint(\"the proportion of data recorded in 2020: {:.2f}\".format (len(x_pred_after)/len(delhi)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delhi_monthly = delhi_b.groupby('Year_Month').mean().reset_index().sort_values(by ='Year_Month')\ndelhi_daily = delhi_b.groupby('Date').mean().reset_index().sort_values(by ='Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,5))\nplot = sns.distplot(delhi_daily.AQI,bins = 100, hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n                            \"alpha\": 0.5, \"color\": \"blue\"});\nplot.set_title('Histogram of AQI distribution', fontsize = 14); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shape that we got isn't a neat and clean bell shape so we can suspect that there is a seasonality that stops the air quality indices to be in a specified range.\nLet's see if it is stationary or non-stationary.\n(Stationary: has a specific mean and variance that don't change over time,\nnon-stationary: has a changing mean and variance.)\nWe do this test to better understand the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# a quick look on how the aqi has changed overtime\nplt.style.use('seaborn-whitegrid')\ndelhi_daily.AQI.plot( figsize = (21,10));\nplt.title('Dehli AQI over time', fontsize = 14);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# the null hypothesis is that it is non_stationary\n# function for adfuller:\n\ndef test_adfuller(df, field):\n    results = adfuller(df[field],)\n    print('This is the adfuller statistic:%.3f'%(results[0]))\n    print('This is the p_value: %.5f' % (results[1])) \n    print('The Critical Values for each probability:\\n')\n    for key, value in results[4].items():\n        print('%s: %.3f'%(key, value))\n    if (results[0]) < list(results[4].values())[0] :\n        print('This data is a cool', colored( 'Stationary dataset!', 'green'))\n    else:\n        print('This is a non_cool',colored( 'non_stationary dataset!', 'yellow'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_adfuller(delhi_daily, 'AQI')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because the data is non-stationary, we can't use the actuall data to predict with methods like autoregressive model. But we can use very simple methods like averaging to do one-step prediction and predict each day based on the several previous days. In this case the data has to have auto correlation(it has to corrolate with itself. So we can predict the next day based on previous days.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax_ = plt.subplots(1, 3, figsize = (20, 5))\naqi_serie = delhi_daily.AQI\nfor i in range(3):\n    \n    lag_plot((aqi_serie), lag = i+1, ax = ax_[i]);\n    ax_[i].plot([min(aqi_serie), max(aqi_serie)], [min(aqi_serie), max(aqi_serie)],'--', color = 'red' )\n\nfig.suptitle('Auto-corrolation with first, second and third previous index', fontsize = 16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"There is a relatively good auto-correlation when we compare each day's index with the previous day's index. so There is a good chance to predict the quality of air well, if we have the previous day's data.\n# One step prediction\n## Here I'll generate a base method to predict index of each day just as the previous day\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shifted = pd.concat([delhi_daily.Date, delhi_daily.AQI, delhi_daily.AQI.shift(1)], axis = 1)\nshifted.columns = ['Date', 'actual', 'pred']\nshifted.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shifted.corr()\n# There is about 90 precent correlation between each day's index and the previous day's index.\n# So it can be a good method to predict each day based on previous.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here is the auto-correlation plot.\n# It shows us how much we can depend on each of the previous indices(separately.)\n# each line is representing the correlation of Y(t-n) to Y(t)\n# and the more it is in the blue area, the more certain we are that it actually has this correlation most of the time\n\nN = 20\nfig, ax_ = plt.subplots( figsize = (10,4))\nplot_acf(delhi_daily.AQI, lags = N, alpha = 0.05, use_vlines = True, ax = ax_ )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (21,10))\n\nsns.lineplot(shifted.Date, shifted.actual, sort = False)\nplot = sns.lineplot(shifted.Date, shifted.pred, color = 'red')\n\nplot.legend(title='legends', loc='upper left',\n           labels=['Actual', 'Prediction'], fontsize = 14)\n\n\nplot.set_ylabel('AQI index', fontsize = 14);\nplot.set_xlabel('Date', fontsize = 14);\nplot.set_title('Base model 1 prediction', fontsize = 14);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_error_1 = mean_squared_error(shifted[1:].actual, shifted[1:].pred)\nprint('The error of our simple and basic model is: {:.2f}'.format(base_error_1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Here we'll generate another simple one-step model that predicts each future value based on average of N previous values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 3\ndef average_of_N_previous_records(N, df):\n    df[ 'average_of_N_previous_records'] = 0\n    for i in range(N, len(df)):\n        #print(i)\n        for n in range(1, N+1):\n\n            df.loc[i, 'average_of_N_previous_records'] += df.loc[i-n, 'AQI']\n    df.loc[:, 'average_of_N_previous_records'] /=3\n    df.loc[:N-1, 'average_of_N_previous_records'] = np.nan\n    \naverage_of_N_previous_records(N, delhi_daily)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the result\nmean = delhi_daily.AQI.mean()\nfirst_date = min(delhi_b.Date)\nlast_date = max(delhi_b.Date)\n\n\nN = 3\nplt.figure(figsize = (21,10))\nsns.lineplot(delhi_daily.Date, delhi_daily.AQI, sort = False)\nsns.lineplot([first_date, last_date], [mean,mean])\n\nplot = sns.lineplot(delhi_daily.Date,\n             delhi_daily.average_of_N_previous_records, \n              color = 'red')\n\nplot.legend(title='legends', loc='upper left',\n           labels=['AQI Monthly Average', 'Total Average', 'Average of past N months'], fontsize = 14)\n\n\nplot.set_ylabel('AQI index', fontsize = 14);\nplot.set_xlabel('Date', fontsize = 14);\nplot.set_title('Base model 2 prediction', fontsize = 14);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_error_2 = mean_squared_error(delhi_daily.AQI[N:], delhi_daily.average_of_N_previous_records[N:])\nprint('The error of averaging {} previous records model is: {:.2f}'.format(N, base_error_2))\n# Though the difference is not that much,\n# because the error gets bigger we should say averaging doesn't seem to be a great method for one-step predicton\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Here we'll use auto regression model for predicting\nAn autoreg model combines different previous records. It will not work properly or be able to predict well when there is a volatile mean and variance and set the best coefficients for each Y(t).\n\nSo because our data is non-stationary, we either have to use methods like subtracting (Y(t) - Y(t-1)) or some features of Autoreg package to delete the trend and seasonality of our dataset.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's first predict the last 7 records by using the last 20 previous records of each\n\ntrain, test = delhi_daily.AQI[:-7], delhi_daily.AQI[-7:]\nmodel = AutoReg(train, lags = N)\nfitted_model = model.fit()\n\ny_pred_autoreg = fitted_model.predict(start = list(test.index)[0],\n                                      end = list(test.index)[-1],\n                                      dynamic = False)\npd.DataFrame(np.c_[test, y_pred_autoreg], columns= ['actual', 'pred'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to make sure what is the best N for our autoregression equation,\n# let's try out different numbers and take the one with lowest error\n\nN = 100\ntrain, test = delhi_daily.AQI[:-20], delhi_daily.AQI[-20:]\n\nmodel = AutoReg(train, lags = 1, seasonal=True, trend = 'c', period = 365)\nfitted_model = model.fit()\ny_pred_autoreg = fitted_model.predict(start = list(test.index)[0],\n                                    end = list(test.index)[-1],\n                                    dynamic = False)\nerror = mean_squared_error(test, y_pred_autoreg)\nbest_n = 0\ntrend_ = 'c'\nseasonal_ = True\n# we know if there is any seasonality it will be 365 days period so we won't use a for loop for that.\nfor n in range(1, N):\n    \n    for trend in ['n', 'c', 't', 'ct']:\n        \n        for seasonal in [True, False]:\n            model = AutoReg(train, lags = n, seasonal=seasonal, trend = trend, period = 365)\n            fitted_model = model.fit()\n            y_pred_autoreg = fitted_model.predict(start = list(test.index)[0],\n                                                  end = list(test.index)[-1],\n                                                  dynamic = False)\n\n            mse = mean_squared_error(test, y_pred_autoreg)\n\n            if error > mse:\n                error = mse\n                best_n = n\n                trend_ = trend\n                seasonal_ = seasonal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The best number of previous records to use for prediction is: ', colored(best_n, 'yellow'))\nprint('The Trend parameter is: ', colored(trend_, 'yellow'))\nprint('The seasonal parameter is: ', colored(seasonal_, 'green'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = delhi_daily.AQI\n\nmodel = AutoReg(train, lags = best_n, seasonal = seasonal_, period = 365, trend = trend_)\nfitted_model = model.fit()\ny_pred_autoreg = fitted_model.predict(start = list(train.index)[0],\n                                      end = list(train.index)[-1],\n                                      dynamic = False)\ndelhi_daily['Autocorr'] = y_pred_autoreg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (21,10))\n\nsns.lineplot(delhi_daily.Date, delhi_daily.AQI, sort = False)\n\nplot = sns.lineplot(delhi_daily.Date,\n             delhi_daily.Autocorr, \n              color = 'red')\n\nplot.legend(title='legends', loc='upper left',\n           labels=['Actual AQI', 'Prediction based on '+str(best_n)+' previous results'], fontsize = 14)\n\n\nplot.set_ylabel('AQI index', fontsize = 14);\nplot.set_xlabel('Date', fontsize = 14);\nplot.set_title('Prediction using Autoreg \\n Seasonality = '+str(seasonal_)+'\\n trend = '+str(trend_));\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we'll again measure the mean squared error, but bare in mind that this is not an ideal way to assert the quality of base models because each of the models predict a specific number of records. For a better assersion we shall measure the mean squared error of all the records starting from a specific Nth record.\nI this case N would be 30.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"autoreg_error_1 = mean_squared_error(delhi_daily.Autocorr[best_n:], delhi_daily.AQI[best_n:])\nprint('The error of the autoregression model is: {:.2f}'.format(autoreg_error_1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you for baring with me and going through this dataset. I hope I could help you. \nI have to thank [this](https://www.kaggle.com/parulpandey/a-guide-to-handling-missing-values-in-python) kernel's writer too, for having amazing insight for me in writing this kernel! \nPlease feel free to ask me your questions. Constuctive critisism is also welcome!\nGood luck!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}