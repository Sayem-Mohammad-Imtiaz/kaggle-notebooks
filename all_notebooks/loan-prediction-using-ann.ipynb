{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loan Prediction using Artificial Neural Network"},{"metadata":{},"cell_type":"markdown","source":"## Importing the libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset contains 614 rows and 13 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check the head of the dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loan_Status is the target column"},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### checking for missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 7 columns which contain missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputing missing values\n# imputing missing values\ndata['LoanAmount']=data['LoanAmount'].fillna(data['LoanAmount'].mean())\ndata['Credit_History']=data['Credit_History'].fillna(data['Credit_History'].median())\ndata.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dependent and independent variables\nX = data.iloc[: , 1:-1].values\nY = data.iloc[: ,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X)\nprint(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = np.where(Y=='Y',1,Y)\nY = np.where(Y=='N',0,Y)\nprint(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = Y.astype('int')\nY.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[: ,2] = np.where(X[:, 2]=='3+',3,X[: ,2])\nX[:, 2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX[:, 0] = le.fit_transform(X[:, 0])\nX[:, 1] = le.fit_transform(X[:, 1])\nX[:, 3] = le.fit_transform(X[:, 3])\nX[:, 4] = le.fit_transform(X[:, 4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [10])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.astype('int')\nX.dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting the dataset into training and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing ANN\nann = tf.keras.models.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding input and first hidden layer\nann.add(tf.keras.layers.Dense(units=8, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding second hidden layer\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding third hidden layer\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding output layer\nann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compiling ANN\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training ANN on training set\nann.fit(X_train, y_train, batch_size = 32, epochs = 150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = ann.predict(X_test)\ny_pred = (y_pred > 0.5)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}