{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **1. Reading And Understanding The Data**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom datetime import timedelta\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_survey_data = pd.read_csv('../input/hr-analytics-case-study/employee_survey_data.csv')\ngeneral_data = pd.read_csv('../input/hr-analytics-case-study/general_data.csv')\nstart_time = pd.read_csv('../input/hr-analytics-case-study/in_time.csv')\nmanager_survey_data = pd.read_csv('../input/hr-analytics-case-study/manager_survey_data.csv')\nfinish_time = pd.read_csv('../input/hr-analytics-case-study/out_time.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(general_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(employee_survey_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(manager_survey_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(start_time.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(finish_time.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('General data shape:', general_data.shape)\nprint('Employee survey data shape:', employee_survey_data.shape)\nprint('Manager survey data shape:', manager_survey_data.shape)\nprint('Start working time data shape', start_time.shape)\nprint('End working time data shape:', finish_time.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 4410 employee records in all of the datasets. We will combine them to get more accurate results.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are columns named  Unnamed: 0  in start_time and finish_time files. We will convert to EmployeeID for clearity, because we will combine the files later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly, change column name Unnamed: 0 to EmployeeID in start and end time datasets.\nstart_time.rename(columns={'Unnamed: 0':'EmployeeID'}, inplace=True)\nfinish_time.rename(columns={'Unnamed: 0':'EmployeeID'}, inplace=True)\nprint('Number of unique values of EmployeeID in start time dataset:', start_time.EmployeeID.nunique())\nprint('Number of unique values of EmployeeID in finish time dataset:', finish_time.EmployeeID.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's set the column named EmployeeID in all files. We are getting ready for merging.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"general_data.set_index('EmployeeID', inplace=True)\nemployee_survey_data.set_index('EmployeeID', inplace=True)\nmanager_survey_data.set_index('EmployeeID', inplace=True)\nstart_time.set_index('EmployeeID', inplace=True)\nfinish_time.set_index('EmployeeID', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, we will combine the files of general_data, employee_survey_data, manager_survey_data. We need to change time files before merging.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data = pd.concat([general_data, employee_survey_data, manager_survey_data], axis = 1)\nprint(main_data.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to calculate total working hours as below from workin times. After that, we can calculate overtime as well. Finally, we can merge all files by adding WorkingHours and Overtime columns to our main_data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = start_time.apply(pd.to_datetime)\nfinish_time = finish_time.apply(pd.to_datetime)\nmain_data['WorkingHours'] = (finish_time - start_time).mean(axis=1)\nmain_data['WorkingHours'] = main_data['WorkingHours'] / np.timedelta64(1, 's')\nmain_data['Overtime'] = main_data['WorkingHours'] - main_data['StandardHours'] * 3600","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(main_data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems there are some null values in our dataset. The values under Non_null column are not all 4410.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Cleaning The Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\033[1mNULL VALUES\\033[0m\\n'+ str(main_data.isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to handle the null values in our dataset. Firstly, let's visulize them, so that we can decide to fill them either with median or mean etc..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\n\nplt.subplot(1,5,1)\nmain_data['NumCompaniesWorked'].plot(kind='density', color='teal')\nplt.title('Density Plot Of Number Of \\nCompanies Worked')\n\nplt.subplot(1,5,2)\nmain_data['TotalWorkingYears'].plot(kind='density', color='blue')\nplt.title('Density Plot Of \\nTotal Working Years')\n\nplt.subplot(1,5,3)\nmain_data['EnvironmentSatisfaction'].plot(kind='density', color='teal')\nplt.title('Density Plot Of \\nEnvironment Satisfaction')\n\nplt.subplot(1,5,4)\nmain_data['JobSatisfaction'].plot(kind='density', color='blue')\nplt.title('Density Plot Of \\nJob Satisfaction')\n\nplt.subplot(1,5,5)\nmain_data['WorkLifeBalance'].plot(kind='density', color='green')\nplt.title('Density Plot Of \\nWork Life Balance')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Other values in these columns are not normally distributed. It's better to use median value to fill the null values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"null = ['NumCompaniesWorked', 'TotalWorkingYears', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']\nfor i in null:\n    main_data[i] = main_data[i].fillna(main_data[i].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\033[1mNULL VALUES\\033[0m\\n'+ str(main_data.isnull().values.any()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't have any null values left in our dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's check the number of unique values in our dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in main_data:\n    print(\"data[\\'\" + i + \"\\']:\", main_data[i].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of unique values in the columns of EmployeeCount, Over18, StandardHours is just 1. All values are same. Let's remove these columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data.drop(['EmployeeCount', 'StandardHours', 'Over18'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Firstly, it is better to see attriton level in our dataset. The number of people who want to leave the company, and the number of people who are satisfied to work.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total = len(main_data['Attrition'])\nAttrition = pd.DataFrame(main_data['Attrition'].value_counts())\nprint(Attrition.T)\nplt.figure(figsize=(6,4))\nplt.style.use('ggplot')\nax = Attrition.plot(kind='bar', color='pink')\nplt.title('Attrition', fontweight='bold', fontsize=15)\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x() + p.get_width()/2., height + 10 , '{:.0%}'.format(height/total))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"16% of employess are not satisfied. It's not that small number for the company. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data['AgeGroups'] = pd.cut(main_data['Age'], range(10, 70, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,3,1)\nsns.distplot(main_data['Age'], color='green')\nplt.xlim(10,70)\nplt.title('Age Distribution')\n\nplt.subplot(1,3,2)\nmain_data['MaritalStatus'].value_counts().plot(kind='bar', color='lightblue')\nplt.xticks(rotation=0)\nplt.title('Marital Status Distribution')\n\nplt.subplot(1,3,3)\nmain_data['Gender'].value_counts().plot(kind='bar', color='lightpink')\nplt.xticks(rotation=0)\nplt.title('Gender Distribution')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Age : Age group of employees is usually 30 - 40.\n* Marital Status : The number of married people is highest, while the divorced is lowest.\n* Gender : Male population is higher than female.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,10))\n\nplt.subplot(2,3,4)\nmain_data['Department'].value_counts().plot(kind='bar', color='lightblue')\nplt.xticks(rotation=0)\nplt.title('Department Distribution')\n\nplt.subplot(2,3,5)\nmain_data['JobRole'].value_counts().plot(kind='bar', color='lightblue')\nplt.title('Job Role Distribution')\n\nplt.subplot(2,3,6)\nmain_data['EducationField'].value_counts().plot(kind='bar', color='lightblue')\nplt.title('Education Field Distribution')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Department : There are many people working in R&D department. The number of people works in HR is the lowest.\n* Job Role: There are so many sales executive in the company. Sales department mostly include Sales Executives.\n* Education Field: There are so many people in the company who studied Life Sciences.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphs = ['AgeGroups', 'MaritalStatus', 'Gender', 'Department', 'JobRole', 'EducationField']\nplt.figure(figsize=(20,15))\nfor index, item in enumerate(graphs):\n    plt.subplot(2,3,index+1)\n    ax = sns.countplot(x=item, hue='Attrition', data=main_data, palette='husl')\n    if index+1>3: plt.xticks(rotation=90)\n    index = int(len(ax.patches)/2)\n    for left,right in zip(ax.patches[:index], ax.patches[index:]):\n        left_height = left.get_height()\n        right_height = right.get_height()\n        total = left_height + right_height\n        ax.text(left.get_x() + left.get_width()/2., left_height + 20, '{:.0%}'.format(left_height/total), ha=\"center\")\n        ax.text(right.get_x() + right.get_width()/2., right_height + 20, '{:.0%}'.format(right_height/total), ha=\"center\")\nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These graphs show the Attrition level by Age, Marital Status, Gender, Department, Job Role, Education Field.\n\nAge Group : 23% of 20-30 age group wants to leave the company.\n\nMarital Status : 26% od single people wants to leave the company.\n\nGender : 17% of male employess wants to leave the company.\n\nDepartment : 16% of R&D department wants to leave the company.\n\nJob Role: 24% of Research Directors wants to leave the company.\n\nEducation Field : 41% of Human Resources wants to leave the company. This is very high.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data = main_data.drop('AgeGroups', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot(main_data[main_data['Attrition']=='Yes']['MonthlyIncome'], color='darkblue')\nplt.title('Distribution of Monthly Income for Attrition (YES)', fontsize=12, fontweight='bold')\n\nplt.subplot(1,2,2)\nsns.distplot(main_data[main_data['Attrition']=='No']['MonthlyIncome'], color='darkred')\nplt.title('Distribution of Monthly Income for Attrition (NO)', fontsize=12, fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The income of employees who want to leave the company is lower.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot(main_data[main_data['Attrition']=='Yes']['PercentSalaryHike'], color='darkgreen')\nplt.title('Distribution of Percent Salary Hike for Attrition (YES)', fontsize=12, fontweight='bold')\n\nplt.subplot(1,2,2)\nsns.distplot(main_data[main_data['Attrition']=='No']['PercentSalaryHike'], color='darkorange')\nplt.title('Distribution of Percent Salary Hike for Attrition (NO)', fontsize=12, fontweight='bold')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percent Salary Hike of employees who want to leave the company is lower.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\n\nsns.kdeplot(main_data['YearsSinceLastPromotion'][main_data.Attrition=='Yes'], color='blue', shade=True)\nsns.kdeplot(main_data['YearsSinceLastPromotion'][main_data.Attrition=='No'], color='red', shade=True)\nplt.title('Distribution of Years Since Last Promotion', fontsize=15)\nplt.legend(['Attrition (YES)', 'Attrition (NO)'])\nplt.xlabel('Years', fontsize=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.kdeplot(main_data['YearsAtCompany'][main_data.Attrition=='Yes'], shade=True, color='green')\nsns.kdeplot(main_data['YearsAtCompany'][main_data.Attrition=='No'], shade=True, color='red')\nplt.title('Distribution Of Years At Company', fontsize=13)\nplt.ylabel('Distribution')\nplt.legend(['Attrition (YES)','Attrition (NO)'])\n\nplt.subplot(1,2,2)\nsns.kdeplot(main_data['YearsWithCurrManager'][main_data.Attrition=='Yes'], shade=True, color='green')\nsns.kdeplot(main_data['YearsWithCurrManager'][main_data.Attrition=='No'], shade=True, color='red')\nplt.title('Distribution of Years With Current Manager', fontsize=13)\nplt.legend(['Attrition (YES)','Attrition (NO)'])\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If employees spend more time in the company, attrition rate is lower. People don't want to leave the company after spending long time in the same company.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\n\nplt.subplot(1,3,1)\nsns.violinplot(data=main_data, x='Attrition', y='JobSatisfaction', palette='Blues')\nplt.title('Job Satisfaction')\n\nplt.subplot(1,3,2)\nsns.violinplot(data=main_data, x='Attrition', y='EnvironmentSatisfaction', palette='Blues')\nplt.title('Environment Satisfaction')\n\nplt.subplot(1,3,3)\nsns.violinplot(data=main_data, x='Attrition', y='WorkLifeBalance', palette='Blues')\nplt.title('Work Life Balance')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Employees who want to quit their jobs are not quite satisfied with their jobs. Work life balance is lower.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Outliers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Logistic regression is sensitive to outliers. I will check for outliers in the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = main_data.select_dtypes(exclude='object').columns\nnumerical_data = main_data[numerical_columns]\ncategorical_columns = main_data.select_dtypes(include='object').columns\ncategorical_data = main_data[categorical_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nfor index, item in enumerate(numerical_columns, 1):\n    plt.subplot(5, 4, index)\n    sns.boxplot(main_data[item])\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are outliers in the dataset. I will apply log transformation to these variables. Log transformation de-emphasizes outliers and allows us to potentially obtain a bell-shaped distribution.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['MonthlyIncome', 'NumCompaniesWorked', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', \n           'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'PerformanceRating', 'WorkingHours']\nmain_data[columns] = (main_data[columns] + 1).transform(np.log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting to numerical variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I will convert categorical variables to numerical variables. Categorical variables are not ordinal. For this reason, I will apply OneHotEncoder.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies = pd.get_dummies(main_data[categorical_columns], drop_first = True)\nmain_data = pd.concat([main_data, dummies], axis = 1)\nmain_data.drop(categorical_columns, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = main_data.drop('Attrition_Yes', axis=1)\ny = main_data['Attrition_Yes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ncolumns = X.columns\nmain_data[columns] = scaler.fit_transform(main_data[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking Multicollinearity","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Multicollinearity occurs when the model includes multiple factors that are correlated to each other. Logistic regression requires there to be little or no multicollinearity among the independent variables. This means that the independent variables should not be too highly correlated with each other.\n\nI will check the correlation between the variables visually and with the VIF value. I will drop the variables with VIF above 5.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [35,30]\nsns.heatmap(main_data.corr(), cmap='PuBu', annot=True, linewidths=.5, annot_kws={'size':8})\nplt.title('Correlation Matrix', fontweight='bold', fontsize='15')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"variables\"] = X.columns\nvif['vif'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nfor index,column in enumerate(X.columns):\n    print(index, column, vif['vif'][index])\n    if vif['vif'][index]>5:\n        vif = vif.drop([index], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(vif)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Building The Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = list(vif['variables'])\ndata = main_data[columns]\ndata = pd.concat([data, main_data['Attrition_Yes']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data.drop('Attrition_Yes', axis=1)\ny = data ['Attrition_Yes']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(solver='liblinear', random_state=42)\nlr.fit(X_train, y_train)\nlrpred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluating The Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy score of Logistic Regression:' + str(accuracy_score(y_test,lrpred)))\nprint('Confusion Matrix\\n' + str(confusion_matrix(y_test, lrpred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression predicted 146 False Negative values. 146 people are actually want to quit their jobs, but the model says they want to stay. This is quite important, because we don't want to lose them in the company. Other models can be used on this dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\n\nlrprob = lr.predict_proba(X_test)\nlr_pred = lrprob[:,1]\nfpr, tpr, threshold = metrics.roc_curve(y_test, lr_pred)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.title('Logistic Regression ROC', fontsize=15)\nplt.ylabel('True Positive Rate', fontsize=15)\nplt.xlabel('False Positive Rate', fontsize=15)\nplt.legend(loc = 'lower right', prop={'size': 14})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint('Logistic Regression\\n',classification_report(y_test, lrpred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}