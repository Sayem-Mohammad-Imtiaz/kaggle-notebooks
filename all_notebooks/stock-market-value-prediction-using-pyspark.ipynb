{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"31f8a6c7-572c-d4a1-c105-ff3312d5ebed"},"source":"This program performs the stock market prediction using Random Forest model in pyspark. Although the size of the data does not require to perform the task on Spark, I wrote this code for those who want to see how to do prediction on Spark."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"60e2c6cc-d5d8-de55-f77f-565a0ce75936"},"outputs":[],"source":"import findspark\nfindspark.init()\nimport numpy\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pylab import *\nfrom pyspark.sql.functions import udf, concat, col, lit\nfrom pyspark.sql.types import IntegerType, ArrayType, StringType, DoubleType\nimport string\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer, CountVectorizer, Tokenizer, StopWordsRemover, NGram\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder\nfrom pyspark.ml.tuning import CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nconf = SparkConf()\nsc = SparkContext(conf)\nsqlContext = SQLContext(sc)\n\n#the data file is read from HDFS\n#the file stockMarketAndNewsData.csv a modified version of the file combined_News_DJIA.csv, whereby the newlines that are wrongly introduced in the data are removed\n\ndata = sqlContext.read.load('/directory-of-your-file/stockMarketAndNewsData.csv', \n                          delimiter=',',\n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n\n\n#replace null values with empty string\ndata = data.na.fill(' ')\n\n# Only the columns that represent the news\nnewsColumns = [x for x in data.columns if x not in ['Date', 'Label']]\n\n#merge news from different news sources per day\n\ndata = data.withColumn(\"allNews\", data.Top1)\nfor i in range(2, len(newsColumns)+1):\n    colName = 'Top' + str(i)\n    data = data.withColumn('allNews', concat(col(\"allNews\"), lit(\" \"), col(colName)))\n\n#remove puntuation marks from the news\n\nremovePunctuation = udf(lambda x: ''.join([' ' if ch in string.punctuation else ch for ch in x]))\ndata = data.withColumn('allNews', removePunctuation(data.allNews))\n\n#split the news into words\n\nsplitNews = udf(lambda s: [x for x in s.split(' ') if (x != u'' and len(x) >= 2)], ArrayType(StringType(), True))\ndata = data.withColumn('words', splitNews(data.allNews)).select('Date', 'label', 'words')\n\n#remove the stop words\n\nmyStopwordRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"stopRemoved\")\ndata = myStopwordRemover.transform(data)\n\n# Create ngrams of size 2\n\nmyngram = NGram(inputCol=\"stopRemoved\", outputCol=\"ngrams\", n=2)\ndata = myngram.transform(data)\ndata = data.withColumn('ngrams', data.ngrams.cast(ArrayType(StringType(), True)))\n\n# Apply count vectorizer to convert to vector of counts of the ngrams\n\nmyCountVectorizer = CountVectorizer(inputCol=\"ngrams\", outputCol=\"countVect\", minDF=1.0)\ndata = myCountVectorizer.fit(data).transform(data)\n\n# Transform the label using StringINdexer\n\nsi_label = StringIndexer(inputCol=\"label\", outputCol=\"label2\", handleInvalid=\"skip\")\ndata = si_label.fit(data).transform(data)\ndata.drop('label')\ndata = data.withColumn('label', data.label2)\n\n# Divide into training and test data\n\ntrainData = data[data['Date'] < '20150101']\ntestData = data[data['Date'] >= '20141231']\n\n# define the random forest classifier model\n\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"countVect\", numTrees=3, maxDepth=4, maxBins=200)\n\n# perform a grid search on a set of parameter values\n\ngrid = ParamGridBuilder().addGrid(rf.numTrees, [2, 5])\\\n                         .addGrid(rf.maxDepth, [2, 5])\\\n                         .build()\nevaluator = BinaryClassificationEvaluator()\ncv = CrossValidator(estimator=rf, estimatorParamMaps=grid, evaluator=evaluator)\ncvModel = cv.fit(trainData)\nevaluator.evaluate(cvModel.transform(testData))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}