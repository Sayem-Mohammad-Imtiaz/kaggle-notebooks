{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Splitting Data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\n\n# Modeling\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, recall_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import plot_tree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cancer = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ncancer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cancer.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's check if the cancer is Malignant or Benign**","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"*Drop Columns*","metadata":{}},{"cell_type":"code","source":"cancer.drop(columns=['id', 'Unnamed: 32'], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Missing Value*","metadata":{}},{"cell_type":"code","source":"cancer.isna().sum()/len(cancer.index)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Dataset","metadata":{}},{"cell_type":"code","source":"cancer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PreProcessing","metadata":{}},{"cell_type":"markdown","source":"### *Define Target Data*\n* If the cancer is Benign, it will be 0\n* If the cancer is Malignant, it will be 1","metadata":{}},{"cell_type":"code","source":"cancer['diagnosis'] = np.where(cancer['diagnosis'] == 'M', 1, 0)\ncancer['diagnosis'].value_counts()/cancer.shape[0]*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Data is imbalanced.","metadata":{}},{"cell_type":"code","source":"X = cancer.drop('diagnosis', axis = 1)\ny = cancer['diagnosis']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"robust = RobustScaler()\nX_scaled = robust.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* In the case of breast cancer, I want to reduce predictions to people who are misdiagnosed, diagnosed as benign, but it turns out to be malignant, that is, the person we predict is not the default (FN). Evaluation metrics used: **Recall**","metadata":{}},{"cell_type":"markdown","source":"### *Data Splitting*","metadata":{}},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n                                                   stratify = y,\n                                                    test_size = 0.3,\n                                                   random_state = 3030)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* I use 0.3 as default score for test_size and X.shape for random_state so the data will be devided equally.","metadata":{}},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"**KNeighbors Classifier**","metadata":{}},{"cell_type":"code","source":"k = range(1,100,2)\ntesting_accuracy = []\ntraining_accuracy = []\nscore = 0\n\nfor i in k:\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    \n    y_predict_train = knn.predict(X_train)\n    training_accuracy.append(accuracy_score(y_train, y_predict_train))\n    \n    y_predict_test = knn.predict(X_test)\n    acc_score = accuracy_score(y_test,y_predict_test)\n    testing_accuracy.append(acc_score)\n    \n    if score < acc_score:\n        score = acc_score\n        best_k = i\n\nsns.lineplot(k, training_accuracy)\nsns.scatterplot(k, training_accuracy)\nsns.lineplot(k, testing_accuracy)\nsns.scatterplot(k, testing_accuracy)\nplt.legend(['training accuracy', 'testing accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('This is the best K for KNeighbors Classifier: ', best_k, '\\nAccuracy score is: ', score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This model indicates **underfitting** because training accuracy and testing accuracy are both decreases.","metadata":{}},{"cell_type":"markdown","source":"**Decision Tree Classifier**","metadata":{}},{"cell_type":"code","source":"depth = range(1,25)\ntesting_accuracy = []\ntraining_accuracy = []\nscore = 0\n\nfor i in depth:\n    tree = DecisionTreeClassifier(max_depth = i, criterion = 'entropy')\n    tree.fit(X_train, y_train)\n    \n    y_predict_train = tree.predict(X_train)\n    training_accuracy.append(accuracy_score(y_train, y_predict_train))\n    \n    y_predict_test = tree.predict(X_test)\n    acc_score = accuracy_score(y_test,y_predict_test)\n    testing_accuracy.append(acc_score)\n    \n    if score < acc_score:\n        score = acc_score\n        best_depth = i\n        \nsns.lineplot(depth, training_accuracy)\nsns.scatterplot(depth, training_accuracy)\nsns.lineplot(depth, testing_accuracy)\nsns.scatterplot(depth, testing_accuracy)\nplt.legend(['training accuracy', 'testing accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('This is the best depth for Decision Tree Classifier: ', best_depth, '\\nAccuracy score is: ', score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This model indicates **overfitting** because training accuracy is good and the testing accuracy is decreased.","metadata":{}},{"cell_type":"markdown","source":"### *Define Model*","metadata":{}},{"cell_type":"markdown","source":"* I use **KNeighbors Classifier** with best K score and **Decision Tree Classifier** with best depth score.","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\ntree = DecisionTreeClassifier(max_depth = 3, random_state = 3030)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_evaluation(model, metric):\n    model_cv = cross_val_score(model, X_train, y_train, cv = StratifiedKFold(n_splits = 5), scoring = metric)\n    return model_cv\n\nknn_cv = model_evaluation(knn, 'recall')\ntree_cv = model_evaluation(tree, 'recall')\n\nfor model in [knn, tree]:\n    model.fit(X_train, y_train)\n\nscore_cv = [knn_cv.round(5), tree_cv.round(5)]\nscore_mean = [knn_cv.mean(), tree_cv.mean()]\nscore_std = [knn_cv.std(), tree_cv.std()]\nscore_recall_score = [recall_score(y_test, knn.predict(X_test)), \n            recall_score(y_test, tree.predict(X_test))]\nmethod_name = [ 'KNN Classifier', 'Decision Tree Classifier']\ncv_summary = pd.DataFrame({\n    'method': method_name,\n    'cv score': score_cv,\n    'mean score': score_mean,\n    'std score': score_std,\n    'recall score': score_recall_score\n})\ncv_summary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* From the cross validation and model evaluation processes, I decide to continue with **Decision Tree Classifier** even the score is indicated overfitting. Let's tune the model.","metadata":{}},{"cell_type":"markdown","source":"# HyperParam Tuning","metadata":{}},{"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth = 3, random_state = 3030)\n\nhyperparam_space = {\n    'criterion': ['gini', 'entropy'],\n    'splitter': ['best', 'random'],\n    'max_depth': [3, 5, 7, 9, 11],\n    'min_samples_leaf': [3, 9, 13, 15, 17],\n    'class_weight': ['list', 'dict', 'balanced'],\n    'random_state': [3030]\n}\n\ngrid = GridSearchCV(\n                tree,\n                param_grid = hyperparam_space,\n                cv = StratifiedKFold(n_splits = 5),\n                scoring = 'recall',\n                n_jobs = -1)\n\ngrid.fit(X_train, y_train)\n\nprint('best score', grid.best_score_)\nprint('best param', grid.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparison Between Before & After Tuning","metadata":{}},{"cell_type":"code","source":"tree.fit(X_train, y_train)\ntree_recall = (recall_score(y_test, tree.predict(X_test)))\n\ngrid.best_estimator_.fit(X_train, y_train)\ngrid_recall = (recall_score(y_test, grid.predict(X_test)))\n\nscore_list = [tree_recall, grid_recall]\nmethod_name = ['Decision Tree Classifier Before Tuning', 'Decision Tree Classifier After Tuning']\nbest_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nbest_summary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This is the comparison between before tuning score and after tuning score using Decision Tree Classifier. **I choose to use Decision Tree Classifier after tuning** score in this section.","metadata":{}},{"cell_type":"markdown","source":"# Decision Tree Classifier Plot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplot_tree(grid.best_estimator_, feature_names = list(X), class_names = ['Benign','Malignant'], filled = True)\nplt.title('Tree Plot')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"importance_table = pd.DataFrame({\n    'imp': grid.best_estimator_.feature_importances_\n}, index = X.columns)\nimportance_table.sort_values('imp', ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"importance_table.sort_values('imp', ascending = True).plot(kind = 'barh', figsize = (15,8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The results suggest perhaps 4 of the 30 features as being important to prediction.","metadata":{}},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"markdown","source":"- In the first step, I did **scaling at X data using Robust Scaler** because I believe there are so many outliers.\n- I only use **KNeighbor Classifier (KNN) and the Decision Tree Classifier (Tree)** in this prediction. I try to find the best K score and best depth for each model and see how the training and testing data on both models either.\n- From the cross-validation process, the KNN model has the highest score with 0.9 but after model evaluation using recall metric, the **Tree model has the highest score with 0.92**. Even the Tree model **indicated overfitting**, I still choose to use this score to continue the process.\n- I decide to get the best parameter for the Tree model by Tuning with the best score of 0.95 which is increasing, then compare the Tree model score before and after tuning. The comparison results prove that the **Tree model after the Tuning process is higher than before with 0.9375**.\n- I check again to see the data using the Feature Importance process. Surprisingly, from 30 features (columns), **only 4 features that is important** to prediction.","metadata":{}}]}