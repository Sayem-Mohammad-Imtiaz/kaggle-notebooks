{"cells":[{"metadata":{},"cell_type":"markdown","source":"> **Importing Important Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"\n@author: Mohamed Wael Bishr\n\"\"\"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom textblob import TextBlob\nimport nltk\n\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nimport collections\nfrom collections import Counter \nfrom wordcloud import WordCloud, STOPWORDS \nimport warnings\n\n#Downloading wordbags from nltk\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Define Variables**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"S =[]\nl=[]\nnum=0\nAll=[]\nsent=0.0\nPos=0\nNeg=0\nNat=0\nWords=''\nword_counter=0\nPOS_LST=[]\nNEG_LST=[]\nNAT_LST=[]\nCloudPOS='';CloudNEG='';CloudNAT=''\nCLOUDS=[CloudPOS,CloudNEG,CloudNAT]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Read The Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/qurancsv/Quran.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Lets see it**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(plt.style.available) # look at available plot styles\nplt.style.use('ggplot')\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Droping Unnecessary Columns ['OrignalArabicText', 'ArabicText','ArabicWordCount','ArabicLetterCount']**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data= df.drop(columns=['OrignalArabicText', 'ArabicText','ArabicWordCount','ArabicLetterCount'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Looping Over Columns To Make A List Of Surahs And Its Number Of Ayahs**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data['SurahNo']:\n    if i not in l:\n        l.append(i)\n\nfor x in range(1,len(l)+1):\n    for m in data['SurahNo']:\n        if m == x:\n            num +=1\n    S.append([x,num])\n    num=0\n        \nfor j in range(len(S)):\n    surah = S[j][0]\n    aya =   S[j][1]\n    ayas = []\n    for a in range(len(data['SurahNo'])):\n        if data['SurahNo'][a] == surah:\n            ayas.append(data['EnglishTranslation'][a])\n    All.append([surah,ayas])\n    ayas=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Get The Average Sentiment Polarity For Each Surah Using TextBlob Library**"},{"metadata":{},"cell_type":"markdown","source":"> **As U Can See We Got Number Of Surahs For Each Polarity**\n\n**Positive** Means That Most Of Surah's Ayahs Is **Positive** Like ***Heaven , Good , Happiness , Belivers***\n\n**Negative** Means That Most Of Surah's Ayahs Is **Negative** Like ***Hell , Evil , Sadness , Unbelivers***\n\n**Natural** Means That Most Of Surah's Ayahs Is **Natural** Like ***Light , Walk , Go , In , Say***"},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in All:\n    for a in s[1]:\n        obj = TextBlob(a)\n        sent = sent + obj.sentiment.polarity\n        Words+=''+a\n    result = sent/(len(s[1]))*100\n    if result > 0:\n        Pos+=1\n    elif result < 0:\n        Neg+=1\n    else:\n        Nat+=1\n    sent=0    \nprint(f'''\n          ==========================\n          Happy Surahs   => {Pos}\n          Sad Surahs     => {Neg}\n          Natural Surhas => {Nat}\n          ==========================\n          ''')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Removing The stopword using nltk stopwords wordbag**"},{"metadata":{"trusted":true},"cell_type":"code","source":"stoplist = set(stopwords.words('english')) \n  \nword_tokens = word_tokenize(Words) \n  \nfiltered_sentence = [w for w in word_tokens if not w in stoplist] \n\nimport string\ncleanList = []\nstring.punctuation\nfor i in filtered_sentence:\n    cleanList.append(i.translate(str.maketrans('','',string.punctuation)))\n    \nfor i in cleanList:\n    if i=='':\n        cleanList.remove(i)\n        \n\n# Pass the split_it list to instance of Counter class. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Splitting The Words In Hole Quran After Cleaning It Into **3 Lists** For Each Polarity **POS , NEG , NAT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor word in cleanList:\n    obj = TextBlob(word)\n    sent = obj.sentiment.polarity\n    if sent >0: POS_LST.append(word)\n    elif sent < 0 : NEG_LST.append(word)\n    else: NAT_LST.append(word)\n  \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Plotting The Words With Higher Occurrence In Each Polarity List**"},{"metadata":{"trusted":true},"cell_type":"code","source":" \n\nC_POS = Counter(POS_LST)\nmost_occurPOS = C_POS.most_common(50)\ndfPOS = pd.DataFrame(most_occurPOS, columns = ['Word', 'Count'])\ndfPOS.plot.bar(x='Word',y='Count')\nC_NEG = Counter(NEG_LST)\nmost_occurNEG = C_NEG.most_common(50)\ndfNEG = pd.DataFrame(most_occurNEG, columns = ['Word', 'Count'])\ndfNEG.plot.bar(x='Word',y='Count')\nC_NAT = Counter(NAT_LST)\nmost_occurNAT = C_NAT.most_common(50)\ndfNAT = pd.DataFrame(most_occurNAT, columns = ['Word', 'Count'])\ndfNAT.plot.bar(x='Word',y='Count')\n# most_common() produces k frequently encountered \n# input values and their respective counts. ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Type Percentage Of Each Polarity To All Words**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'''Pos: {len(POS_LST)} [{len(POS_LST)/len(word_tokens)*100}%]\n          Neg: {len(NEG_LST)} [{len(NEG_LST)/len(word_tokens)*100}%] \n          Nat: {len(NAT_LST)} [{len(NAT_LST)/len(word_tokens)*100}%]''')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Convert Each Polarity List To String**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in POS_LST:\n    CloudPOS +=word+' '\n    \nfor word in NEG_LST:\n    CloudNEG +=word+' '\n    \nfor word in NAT_LST:\n    CloudNAT +=word+' '\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Plotting WordCloud Of Positive Words Using WordCloud Module**"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = stopwords.words(), min_font_size = 10).generate(CloudPOS) \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Plotting WordCloud Of Negative Words Using WordCloud Module**"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = stopwords.words(), min_font_size = 10).generate(CloudNEG) \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Plotting WordCloud Of Natural Words Using WordCloud Module**"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = stopwords.words(), min_font_size = 10).generate(CloudNAT) \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}