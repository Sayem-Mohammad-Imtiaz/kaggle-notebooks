{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport torch\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\n\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport pandas as pd\nlabels = pd.read_csv('../input/head-ct-hemorrhage/labels.csv')\nlabels.head()\n\nlabels['id'] = str('%03d' % (labels['id'][0]))+\".png\"\nlabel_df = labels[['id',' hemorrhage']]\nclasses=list(label_df[' hemorrhage'].unique())\nfrom sklearn.model_selection import train_test_split\ntrain_label_df, test_label_df = train_test_split(label_df, test_size=0.10,shuffle=True)\ntrain_label_df.to_csv ('./train_csv.csv', index = False, header=True)\ntest_label_df.to_csv ('./test_csv.csv', index = False, header=True)\nfrom torch.utils.data import Dataset\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport torch\n\nclass CTDataset(Dataset):\n    def __init__(self, root_dir, annotation_file, transform=None):\n        self.root_dir = root_dir\n        self.annotations = pd.read_csv(annotation_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_id = self.annotations.iloc[index, 0]\n        img = Image.open(self.root_dir+ img_id).convert(\"L\")\n        y_label = torch.tensor(float(self.annotations.iloc[index, 1]))\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return (img, y_label)\ntransform = transforms.Compose(\n    [transforms.Resize((1000,1000)),transforms.ToTensor(),\n     transforms.Normalize((0.5), (0.5))])\n\nbatch_size = 1\n\ntrainset = CTDataset(root_dir='../input/head-ct-hemorrhage/head_ct/head_ct/', annotation_file='./train_csv.csv', transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = CTDataset(root_dir='../input/head-ct-hemorrhage/head_ct/head_ct/', annotation_file='./test_csv.csv', transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nclass MyConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n        super(MyConv2d, self).__init__()\n\n        self.kernel_size = (kernel_size, kernel_size)\n        self.kernel_size_number = kernel_size * kernel_size\n        self.out_channels = out_channels\n        self.dilation = (dilation, dilation)\n        self.padding = (padding, padding)\n        self.stride = (stride, stride)\n        self.in_channels = in_channels\n        self.weights = nn.Parameter(torch.randn(self.out_channels, self.in_channels, self.kernel_size_number))\n\n    def forward(self, x):\n        width = ((x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)// self.stride[0]\n        ) + 1\n        height = ((x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)// self.stride[1]\n        ) + 1\n        windows = F.unfold(\n            x, kernel_size=self.kernel_size, padding=self.padding, dilation=self.dilation, stride=self.stride\n        )\n\n        windows = windows.transpose(1, 2).contiguous().view(-1, x.shape[1], self.kernel_size_number)\n        windows = windows.transpose(0, 1)\n        \n        \n        result = torch.zeros(\n            [x.shape[0] * self.out_channels, width, height], dtype=torch.float32, device=\"cpu\"\n        )\n\n        for channel in range(x.shape[1]):\n            for i_convNumber in range(self.out_channels):\n                xx = torch.matmul(windows[channel], self.weights[i_convNumber][channel]) \n                xx = xx.view(-1, width, height)\n                result[i_convNumber * xx.shape[0] : (i_convNumber + 1) * xx.shape[0]] += xx\n                \n        result = result.view(x.shape[0], self.out_channels, width, height)\n        return result  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 =MyConv2d(in_channels=3, out_channels=1, kernel_size=6,dilation=2,stride=5,padding=1)\n        #self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(39601, 2)\n        \n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = self.fc1(x)\n        return x\n\n\nnet = Net()\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses=[]\nfor epoch in range(6):  \n    running_loss = 0.0\n    i=0\n    for inputs, labels in trainloader:\n        optimizer.zero_grad()\n        outputs = net(inputs.float())\n        loss = criterion(outputs,labels.long())\n        loss.backward()\n        optimizer.step()        \n        running_loss += loss.item()\n        i+=1\n        if i % 200 == 0:    \n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 200))\n            running_loss = 0.0\n    with torch.no_grad():\n        val_loss=0\n        for val_inputs,val_labels in testloader:\n            val_outputs = net(val_inputs.float())\n            loss = criterion(val_outputs,val_labels.long())     \n            val_loss += loss.item()\n        losses.append(val_loss)\n        print(\"Validation loss:\",val_loss)\n\nprint('Finished Training')","metadata":{},"execution_count":null,"outputs":[]}]}