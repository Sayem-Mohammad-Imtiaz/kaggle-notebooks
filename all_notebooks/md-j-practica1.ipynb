{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PRÁCTICA 1 MINERIA DE DATOS"},{"metadata":{},"cell_type":"markdown","source":"*Autores: Marina Ceballos Verdejo y Jesús Martínez Garrido*"},{"metadata":{},"cell_type":"markdown","source":"# 1. Diabetes database"},{"metadata":{},"cell_type":"markdown","source":"Primero importamos todo lo necesario:"},{"metadata":{"_uuid":"e46dd0285013848672368ecbbe380e83103949c1","trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer, LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.impute import SimpleImputer\n\n# Local application\nimport utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fijamos la semilla para que los datos sean reproducibles"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Cargamos la base de datos:"},{"metadata":{"_uuid":"6476f218bc9071bd38b06ee77eae9f0e651228a7","trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\nindex = None\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos los 5 primeros ejemplos para visualizar los datos."},{"metadata":{"_uuid":"40e7c0685585665698306298e77530096dffc559","scrolled":true,"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De aquí podemos obtener la siguiente información:\n\n* Pregnancies es un número entero\n* Glucosa es un número entero que se mueve en el rango [80, 200] más o menos.\n* BloodPressure es otro entero y podría estar en el rango[40,80]\n* SkinThickness es también un número entero con números que podrían estar en el rango [0, 40]\n* Insulin es otro entero con números que podrían estar entre [0, 180]\n* BMI es un número real con datos que podrían estar comprendidos entre [20.0, 50.0]\n* DiabetesPedigreeFunction es una variable con datos reales del rango [0, 1] pero puede haber algún dato anómalo como pasa en el ejemplo 4\n* Age es un número entero con datos comprendidos entre [0, 100]\n* Outcome es la variable objetivo con únicos valores de 0 y 1\n\nObviamente no podemos diseñar unos rangos con los primeros 5 ejemplos ya que no es una muestra muy representativa de la población. Es un pequeño estudio que podemos sacar de los primeros 5 ejemplos para ir familiarizándonos con los datos. Este estudio se llevará en profundidad en el apartado \"Análisis exploratorio de datos\""},{"metadata":{},"cell_type":"markdown","source":"A continuación, vamos a obtener otros 5 ejemplos aleatorios para poder obtener más información"},{"metadata":{"_uuid":"9f1a39585fceb516af8ddcf5afd85945b50c418a","trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí podemos ver datos que pueden variar con respecto a los cinco primeros.\n* En la variable BloodPressure podemos ver que pueden existir datos más altos (84 y 110)\n* Insulin también tiene un dato que se aleja del intervalo definido anteriormente (240)"},{"metadata":{},"cell_type":"markdown","source":"Ahora procedemos a dividir los datos:"},{"metadata":{"_uuid":"77c75aa49e6cd91426d1de882b7feaa0a883fcdb","trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volvemos a obtener los ejemplos aleatorios para comprobar que se ha realizado correctamente la división"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos los datos en train/test para tener una parte de los datos para entrenar y otra para llevar a cabo la evaluación de nuestro modelo. En nuestro caso hemos puesto que el 75% de los datos serán train y el 25% test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.75\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos un subconjunto de cada:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unimos las variables predictoras con la variable clase en ambos conjuntos de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfa6448396ab99305eddfd23cfd958266ad967a8"},"cell_type":"markdown","source":"## 1.2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el preprocesamiento vamos a observar las características del conjunto de datos (de esta forma, haremos el preprocesamiento de una manera más efectiva)."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{"_uuid":"2353b44c7a384810e27f487853d000a2edbe543a","trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tal y como se puede observar, el conjunto de datos de entrenamiento está formado por 576 casos y 9 variables (8 variables predictoras y 1 variable clase)."},{"metadata":{"_uuid":"015c899c3ec4a2177b1986797554b66dfcaac1ee","trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestras variables predictoras son continuas (todas ellas enteros menos BMI y DiabetesPedigreeFunction que son decimales). No hay ningún dato perdido porque todos tienen 576 non-null (número de ejemplos)."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esto es, nuestra variable clase es multivariada con dos estados."},{"metadata":{"_uuid":"f17f376d1ed7405027aebcd226bb6f54d61834ed"},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{"_uuid":"9ab7ff50c8e596f47f8b1e2bece56de40ad52da9","trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4083a4c4c0cf6cfceafe1febbb68be23664931a2"},"cell_type":"markdown","source":"Los histogramas de algunas variables predictoras representan una distribución normal (BMI, BloodPressure, Glucose), aunque las tres presentan algún dato ruidoso ya que son valores erróneos, por ejemplo:\n* BMI, en 0. En 80 se puede dar el caso pero es muy poco probable.\n* BloodPressure, en 0.\n* Glucose, en 0.\n\nLos datos suelen estar entre los siguientes rangos:\n* BMI se encuentra en el rango [17,69]\n* BloodPressure se encuentra en el rango [20, 124]\n* Glucose se encuentra en el rango [55,200]\n\nTambién podemos encontrar algunas distribuciones más complejas, por ejemplo en la variable Skin Thickness encontramos lo que podrían ser dos distribuciones normales juntas en el rango [5,64] (mixtura de distribuciones normales). \nAdemás, encontramos un dato anómalo en el rango [95,99], ya que se aleja de la distribución de la variable. Tiene valores ruidosos ya que es imposible tener 0 de Skin Thickness.\n\n\nPor otro lado, las distribuciones de las variables Pregnancies, DiabetesPedigreeFunction y Age son también algo más complejas que una normal ya que podría ser una distribución normal pero en este caso es asimétrica por la parte derecha.\n* La distribución de la variable Pregancies se encuentra en el rango [0,17].\n* La distribución de la variable DiabatesPedrigreeFunction se encuentra en el rango [0,2.5].\n* La distribución de la variable Age se encuentra en el rango [20,71], y encontramos un dato anómalo en el valor 80 porque se aleja de la distribución de la variable.\n\nFinalmente, en la variable Insuline encontramos una distribución normal en el rango [20,700], aunque podemos apreciar una mixtura de esta distribución con otra uniforme que se encuentra al principio con valores entre [0,19]. \nA partir del valor 700 encontramos unos valores anómalos hasta el valor 800, ya que esán alejados de la distribución de la variable.\n"},{"metadata":{},"cell_type":"markdown","source":"Continuamos visualizando las variables categóricas del problema:"},{"metadata":{"_uuid":"268a87c979078129be8902cc50e24118d7f6254b","trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9852797c305df3f69fd5b8a4436509758a57a0d0"},"cell_type":"markdown","source":"Lo que podemos observar es que las dos clases de la variable objetivo del problema no tienen el mismo número de casos, por lo tanto no es una muestra balanceada, ya que hay más personas que no tengan diabetes. Es algo que suele pasar en los estudios médicos, el porcentaje de la población afectada suele ser menor.\n"},{"metadata":{},"cell_type":"markdown","source":"A continuación, vamos a proceder a realizar un análisis multivariado:"},{"metadata":{"_uuid":"868d232e2b351a751d24b70ba8cb3e93236ec6bf","trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c56414dd13eab3f01ad4f1acb8d770e20c67981d"},"cell_type":"markdown","source":"Viendo este análisis multivariado, primero analizamos las variables predictoras por separado:\n* En Pregnancies, vemos como los valores están bastante dispersos, pero hay una diferencia notable entre los puntos rojos y los azules, ya que los azules tienen valores de Pregnancies más altos que los rojos, por lo que los encontramos más a la derecha. También, como sabemos por el histograma los ejemplos de pregnancies altos son pocos y los valores de clase '1' se mantienen en las gráficas de Pregnancies, podemos decir que Pregnancies y Outcome están relacionadas.\n* En Glucose, ocurre lo mismo que en el caso anterior.\n* En BloodPressure, los datos están más mezclados que en las variables anteriores viendo como los puntos azules están más levemente desplazados hacia la derecha (valores más altos) que los rojos.\n* SkinThickness, insulin, BMI y DiabetesPedigreeFunction, ocurre lo mismo que en el caso anterior pero podemos notar como en el valor 0 predominan los puntos rojos.\n* En la variable predictora Age la diferencia es menos notable porque los puntos están más superpuestos los unos de los otros. Pero al ver en el histograma de 'edad' que existen pocos ejemplos de personas mayores y los puntos azules se mantienen podemos decir que la edad está relacionada con la variable clase.\n\n\nAhora procedemos a analizar variables predictoras de forma conjunta:\n* Vemos que en la gráfica de Insulin x Pregnancies los valores de clase 0 predominan con valores de insulin y pregnancies bajos y los valores de clase 1 predominan con insulin y pregnancies algo más altos\n* En las gráfica DiabetesPedigreeFunction x Pregnancies pasa lo mismo que en el caso anterior\n* En la gráfica Glucose x Insulin podemos ver como cuando la glucosa sube la insulina también lo hace (es decir, existe una relación directa entre ambas variables).\n* En la gráfica de Insulin x Age se puede ver una relación inversa entre ambas variables predictoras ya que cuando aumenta la edad, la variable insulina es más baja.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_heatmap(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta gráfica podemos encontrar varias relaciones claras:\n\n* Age y Pregnancies: relación directa\n* Insulin y Glucose: hay una relación directa entre ambas variables\n* Insulin y SkinThickness: tienen otra relación directa\n* BMI y SkinThickness: relación directa\n\nTambién debemos de destacar que no hay relaciones inversas (o son poco significantes)."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_box(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con estos diagramas de cajas podemos sacar rangos más precisos sobre cada variable (sin tener en cuenta los valores anómalos representados por puntos en el diagrama). Obtendremos intervalos mas exáctos que en el histograma (ya que en este tipo de gráficos aparecen valores máximos, mínimos y anómalos):\n* Pregnancies [0, 13] tiene dos valores anómalos en 14 y 17\n* Glucose [56, 199] tiene un valor anómalo en 0 (en este caso es un valor ruidoso porque no es posible tener la glucosa en 0)\n* BloodPressure [38, 106] con 6 valores anómalos en 24, 30, 108, 110, 114, 122 y un valor ruidoso en 0 ya que no se puede tener la presión de sangre como 0.\n* SkinThickness [0,63] con un valor anómalo en 99. Además, los valores que se encuentran 0 (o cerca del 0), aunque sean muchos casos, son ruidosos ya que no tiene sentido tener ese grosor de piel.\n* Insulin [0, 325] en este caso tener 0 de insulina es algo usual en los diabéticos, por lo que no es un valor ruidoso. Hay bastantes valores anómalos, siendo los más significantes 846, 744, 680 (estos son valores demasiado altos de insulina por lo que podrían ser considerados ruidosos).\n* BMI [18.2, 50] con valores anómalos en 52.3, 52.9, 53.2, 57.3, 59.4, 67.1 y un valor ruidoso en 0 (es imposible tener 0 en BMI).\n* DiabetesPedigreeFunction [0.078, 1.182] además aparecen varios valores anómalos que no vamos a considerar como ruido porque en estudios médicos hay un pequeño porcentaje que se diferencia de los demás.\n* Age [21, 64] con varios valores anómalos (el mayor de estos 81).\n\nAdemás, estos diagramas nos brindan más información que puede resultar interesante para este problema:\n* Pregnancies, SkinThickness, Insulin, DiabetesPedigreeFunction y Age suelen concentrar sus valores bajos cerca de la mediana y sus valores altos se expanden aún más ya que la mediana se encuentra más cerca de el valor minimo que del valor máximo del diagrama de cajas.\n* Glucose, BloodPressure, BMI tienen diagramas de cajas más simétricos que los anteriores ya que como hemos visto en el histograma siguen una distribución normal\n"},{"metadata":{},"cell_type":"markdown","source":"A continuación, vamos a ver qué cantidad de datos ruidosos tiene cada variable para estudiar qué variables presentan una cantidad de errores significante:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ruidosos=utils.df_ruidosos(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ruidosos.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Después de ver la cantidad de datos ruidosos y no ruidosos, nos damos cuenta de que Skin Thickness tiene más de un 20% de valores ruidosos, es una variable con demasiado ruido para tenerla en cuenta a la hora de realizar el estudio."},{"metadata":{"_uuid":"fc2aa9d5aa56e348dfdc227ee8e0aa06b0396c8b","scrolled":true,"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resumen"},{"metadata":{},"cell_type":"markdown","source":"Después de analizar los datos sacamos las siguientes conclusiones:\n* SkinThickness tiene demasiados valores ruidosos por lo que es una candidata a ser imputada en el siguiente paso.\n* Insulin tiene varios valores anómalos que pueden ser importantes en este estudio médico.\n* Encontramos distintas relaciones entre variables por lo que estas variable son importantes a la hora de predecir. Sabemos que esto es importante en los árboles de decisión.\n* Los rangos que aparecen en el diagrama de cajas coinciden en su mayoría con los creados en los histogramas. Esto se tendrá en cuenta para suavizar ruido, imputar valores perdidos,...\n* Viendo el diagrama de puntos y el histograma, este problema sería mejor discretizarlo usando kmeans porque en algunos casos existe una división entre valores notable, por lo que se podría discretizar usando clustering (en algunos casos se ve una separación entre dos grupos).\n* En algunas todas las variables no merece la pena quitar los valores anómalos (esto lo vemos en el pairplot) ya que estos valores pueden ser muy importantes (puede ser que estos anómalos sean los que provoquen la diabetes, debemos de recordar que los casos con diabetes son menos).\n"},{"metadata":{},"cell_type":"markdown","source":"## 1.3. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Crearemos varios transformadores que se ejecutaran sobre los datos crudos y que serán añadidos en las pipelines correspondientes."},{"metadata":{},"cell_type":"markdown","source":"### Limpieza de datos"},{"metadata":{},"cell_type":"markdown","source":"Los transformadores que aparecen a continuación se encargan de suavizar el ruido de nuestros datos. "},{"metadata":{},"cell_type":"markdown","source":"Vamos a crear un transformador que se encarga de poner los valores que no pertenecen a un rango a nulos. No eliminaremos valores anómalos ya que, como hemos dicho en el resumen del analisis exploratorio, en este caso los valores anómalos nos brindan bastante información."},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_put=utils.ManualNanPut({'Glucose':[50,250], 'BloodPressure':[10,150], 'Pregnancies':[0,50], 'SkinThickness':[1,80], 'Insulin':[0,650], 'BMI':[10,65], 'DiabetesPedigreeFunction':[0.0,3.0], 'Age':[0,100], })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Después de borrar todos los valores ruidosos, realizaremos una imputación de valores perdidos (preservando la media):"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp = SimpleImputer(missing_values=float('nan'), strategy='mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reducción de datos"},{"metadata":{},"cell_type":"markdown","source":"#### Imputación de variables"},{"metadata":{},"cell_type":"markdown","source":"Después, como hemos visto en el analisis exploratorio de datos vamos a imputar la variable 'SkinThickness' ya que es una variable con demasiado ruido."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_selector=utils.ManualFeatureSelector([0,1,2,4,5,6,7])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Discretización"},{"metadata":{},"cell_type":"markdown","source":"Tal y como hemos visto en el análisis exploratorio de datos, lo mejor sería discretizar usando la estrategia de k-medias en 2 intervalos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4. Creación de nuestros modelos y pipelines"},{"metadata":{},"cell_type":"markdown","source":"Creamos el clasificador 0R:"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos el árbol de decisión:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model_classifier = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pipeline"},{"metadata":{},"cell_type":"markdown","source":"Creamos el pipeline del árbol de decisión con discretización:"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(nan_put, imp, feature_selector, discretizer, tree_model_classifier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos el pipeline del árbol de decisión sin discretización"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = make_pipeline(nan_put, imp, feature_selector, tree_model_classifier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTA: No es necesario crear el pipeline para 0R ya que en este modelo siempre se va a elegir la clase mayoritaria (no necesitamos un preprocesamiento de datos)."},{"metadata":{"_uuid":"9efefc8412fcc24769a7d98bf42ddbdd15d974df"},"cell_type":"markdown","source":"## 1.5. Evaluación de modelos"},{"metadata":{"_uuid":"96ade70b1295a55b55307c9bd09cfd37a783c1e4"},"cell_type":"markdown","source":"Ahora es el momento de entrenar y validar nuestros clasificadores. Para ello, vamos a usar una matriz de confusión, precisión y recall ya que en problemas médicos es lo más usual (ya que en este tipo de problemas la variable clase no se encuentra balanceada).\n\nPrecisión= TP/(TP+FP)\nRecall= TP/(TP+FN)\n\nTambién dibujaremos la curva ROC para analizar con mayor certeza los resultados."},{"metadata":{},"cell_type":"markdown","source":"### Clasificador 0R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model, X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56eac04a7c1e86758c1a208ba0d568d216132393"},"cell_type":"markdown","source":"Precisión=0/(0+0)=0\nRecall=0/(0+67)=0\n\nObviamente con 0R hemos obtenido malos resultados ya que 0R clasifica siempre como la clase mayoritaria. No tener diabetes siempre será la clase mayoritaria por lo que siempre se predice como no diabetes. Un modelo que siempre predice como no diabetes no es útil para este caso, se busca un modelo que sea capaz de encontrar los diabéticos.\n\nTambién tenemos que el area de la curva ROC es 0.5, este valor nos aclara que 0R es un mal modelo ya que no tiene capacidad discriminatoria. Al ver que la curva ROC es la diagonal, concluimos que OR es un mal modelo en este caso."},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión sin discretizar"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concluimos que el 53% de los casos clasificados como diabéticos, lo son realmente, sabiendo además que el 66% de los diabéticos ha sido diagnosticado como diabéticos. Estos números no son muy altos, por lo que tenemos un modelo regular.\n\nAdemás, vemos que el area debajo de la curva ROC es 0.67236, por lo que, como hemos dicho antes, es un modelo regular para análisis médico.\n"},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión discretizado"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concluimos que el 65% de los casos clasificados como diabéticos, lo son realmente, sabiendo además que el 51% de los diabéticos ha sido diagnosticado como diabéticos. En este caso hemos obtenido una mayor precision pero recall es algo peor que el anterior modelo. \n\nLa curva ROC tiene un area de 0.68173, algo mejor que el anterior modelo, aún así, no es un buen modelo."},{"metadata":{},"cell_type":"markdown","source":"### Resumen de resultados"},{"metadata":{},"cell_type":"markdown","source":"Habiendo estudiado los tres modelos anteriores, ninguno de ellos son buenos modelos, pero el mejor de ellos es el árbol de decisión discretizado."},{"metadata":{},"cell_type":"markdown","source":"# 2. Wisconsin database"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Cargamos la base de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos los 5 primeros ejemplos para visualizar los datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De aquí podemos obtener la siguiente información:\n\n* La mayoría de variables son valores continuos (todos los que aparecen son decimales).\n* Tenemos 31 variables predictoras y 1 variable clase (diagnosis)\n* La variable clase es discreta (valores M o B).\n* Aparece una variable sin nombre con todos los valores NaN.\n\nNo aparecen todas las variables en la tabla por eso hemos hecho este pequeño estudio para ir familiarizándonos con los datos. Este estudio se llevará en profundidad en el apartado \"Análisis exploratorio de datos\""},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora procedemos a dividir los datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volvemos a obtener los ejemplos aleatorios para comprobar que se ha realizado correctamente la división"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos los datos en train/test para tener una parte de los datos para entrenar y otra para llevar a cabo la evaluación de nuestro modelo. En nuestro caso hemos puesto que el 75% de los datos serán train y el 25% test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.75\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos un subconjunto de cada:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unimos las variables predictoras con la variable clase en ambos conjuntos de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el preprocesamiento vamos a observar las características del conjunto de datos (de esta forma, haremos el preprocesamiento de una manera más efectiva)."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tal y como se puede observar, el conjunto de datos de entrenamiento está formado por 426 casos y 32 variables (31 variables predictoras y 1 variable clase)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viendo esto, concluimos que la variable Unamed: 32 tiene todos los valores NaN (no aporta ningún valor al problema). No encontramos ningún valor perdido en ninguna de las otras variables (todas tienen 426 no nulos). Todas las variables predictoras son float. La variable clase es de tipo category.\n\nAl analizar todas las variables, encontramos tres tipos de estas:\n* El valor medio (el que vamos a usar para predecir).\n* El error estandar (utilizaremos para encontrar valores ruidosos de las variables).\n* Peores valores de cada variable (también se puede usar para predecir).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esto es, nuestra variable clase es multivariada con dos estados (B y M)."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Las variables predictoras de tipo mean y worst que presentan una distribución normal:\n* radius_mean aunque es un poco asimétrica. No tiene ruido aunque tiene valores anómalos en 27 y 28.\n* texture_mean con un valor anómalo en 39.\n* perimeter_mean parece que sigue una distribución normal aunque se encuentra algo asimétrica (aparentemente no tiene ningún valor anómalo).\n* smoothness_mean presenta un valor anómalo en 0.16.\n* symmetry_mean aparentemente no presenta ningún valor anómalo ni ruidoso.\n* fractal_dimension_mean presenta valores anómalos a partir de 0.09. No tiene valores ruidosos.\n* radius_worst con un valor anómalo en 36\n* texture_worst sin ningún valor anómalo ni ruidoso aparentemente.\n* perimeter_worst igual que perimeter_mean presenta una distribución normal aunque se encuentra algo asimétrica. Tiene un valor anómalo en 250.\n* smoothness_worst tiene dos valores anómalos en 0.215 y 0.22.\n* symmetry_worst con bastantes valores anómalos a partir de 0.5.\n* fractal_dimension_worst con valores anómalos a partir de 0.14.\n\nA continuación hablaremos sobre las variables que no representan distribuciones normales:\n* concave point_worst y concave point_mean: parecen una mixtura de distribuciones normales. Aparentemente no tienen valores anómalos ni ruidosos.\n* area_mean: es parecida a una distribución normal pero no llega a serlo porque sus datos se encuentran balanceados hacia la izquierda. Tiene valores anómalos a partir de 2000.\n* area_worst: tiene una distribución parecida a area_mean. Tiene un valor anómalo en 4200.\n* compactness_mean y compactness_worst: también tiene una distribución balanceada hacia la izquierda. compactness_mean tiene valores anómalos a partir de 0.27 y compactness_worst a partir de 0.85.\n* concavity_mean y concavity_worst: tienen una distribución como las anterior. concavity_mean tiene valores anómalos a partir de 0.4 y concavity_worst a partir de 1.\n \nEn las gráficas anteriores no se han encontrado valores ruidosos (no había valores que parecieran erróneos según el significado de la variable) por lo tanto, vamos a analizar las variables de tipo \"se\" (error estandar) para así poder encontrar los valores ruidosos de las variables:\n* radius_se: hay nueve valores que se alejan de la distribución de errores (a partir de 1.2). Estos valores los consideraremos como ruidosos.\n* texture_se: hay 14 valores ruidosos a partir de 2.5.\n* perimeter_se: tiene dos valores ruidosos a partir de 18.5.\n* area_se: tiene cuatro valores ruidosos a partir de 229.99.\n* smoothness_se: hay nueve valores ruidosos a partir de 0.015.\n* compactness_se: tiene 131 varios valores ruidosos a partir de 0.03\n* concavity_se : tiene 216 valores ruidosos a partir de 0.025.\n* concave points_se : tiene 105 valores ruidosos a partir de 0.015.\n* simmetry_se : tiene 19 valores ruidosos a partir de 0.036.\n* fractal_dimension_se : tiene 18 valores ruidosos a partir de 0.0085.\n\nPara analizar la cantidad de valores ruidosos y el umbral por el que consideramos que un valor es ruidoso hemos comparado gráficas de \"mean\" y \"se\" para ver los valores promedios. Por ejemplo como concavity tiene valores muy pequeños, el mínimo error estandar ya ocasiona que sea un valor ruidoso\n"},{"metadata":{},"cell_type":"markdown","source":"Continuamos visualizando las variables categóricas del problema:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A partir de esta gráfica concluimos que las dos clases de la variable objetivo del problema no tienen el mismo número de casos, entonces no es una muestra balanceada, ya que hay más ejemplos con un tumor benigno. Es algo que suele pasar en los estudios médicos, el porcentaje de la población afectada suele ser menor."},{"metadata":{},"cell_type":"markdown","source":"A continuación, vamos a proceder a realizar un análisis multivariado:"},{"metadata":{},"cell_type":"markdown","source":"Para hacer nuestro análisis multivariado vamos analizar por un lado las variables tipos \"mean\" y por el otro \"worst\" para que se pueda analizar con más claridad."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_aux1=data_train[['radius_mean','texture_mean','perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'diagnosis']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train_aux1, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Viendo este análisis multivariado, primero analizamos las variables predictoras por separado:\n* En radius vemos que los puntos donde el tumor es Benigno se encuentran a la izquierda de nuestras gráficas. Es decir, los tumores malignos tienden a tener un radio mayor que los tumores benignos.\n* En texture podemos ver que se cumple lo mismo que la variable predictora anterior, aunque aquí los puntos están mas dispersos y la diferencia no es tan notable ya que encontramos puntos azules a la derecha (hay tumores benignos con textura alta).\n* En perimeter hemos visto que ocurre lo mismo que en las anteriores gráficas. De hecho, observamos que las gráficas de radius y perimeter son muy parecidas (tiene sentido porque si los tumores tienden a ser circulares el perimetro y el radio estarán relacionados directamente).\n* En la variable predictora area ocurre lo mismo que en perimeter aunque, está algo más dispersa.\n* En Smooothness las gráficas no está tan clara como las anteriores, pero, aún así, se puede ver como los tumores benignos tienden a tener valores de smoothness más bajos.\n* En la variable predictora Compactness pasa lo mismo que en la anterior variable.\n* En concavity vemos como los tumores benignos tienden a tener valores bastantes bajos (con algún valor que se aleja de la media).\n* Concave points muestra unas gráficas algo más claras que las anteriores donde los puntos benignos están más a la izquierda que los malignos.\n* Symmetry tiene valores bastantes dispersos (más que las anteriores variables) y no podemos sacar una conclusión clara donde podamos diferenciar los tumores benignos y malignos.\n* En fractal_dimmension encontramos los tumores benignos con valores más altos que los malignos.\n\nAhora procedemos a analizar variables predictoras de forma conjunta:\n\n* Las variables radius, perimeter y area estan muy relacionadas (directamente) entre ellas ya que sus gráficas conjuntas se muestran como una línea creciente y tienen gráficas muy parecidas entre ellas.\n* Existe una relación entre concave points y perimeter ya que se puede ver una gráfica con puntos crecientes. Además, se diferencian los puntos de los valores malignos (concave points y perimeter más altos) a los valores benignos (concave points y perimeter más bajos). Obviamente, también existe una relación de concave points con radius y area ya que estas dos últimas variables predictoras son muy parecidas a perimeter.\n"},{"metadata":{},"cell_type":"markdown","source":"Ahora procedemos a realizar el mismo análisis pero con la variable worst."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_aux2=data_train[['radius_worst','texture_worst','perimeter_worst','area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst', 'diagnosis']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train_aux2, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí encontramos varias diferencias con el anterior estudio:\n* En este caso Area se diferencia algo más de perimeter y radius.\n* Texture tiene los valores de ámbas clases más dispersos por lo que la diferencia entre clases se disipa.\n* En este caso los valores clase de las gráficas de concave points se diferencian más entre sí (los tumores benignos tienden a tener menor valor de concave points que los malignos).\n* Fractal_dimension ha cambiado sus gráficas. En este caso la variable predictora es algo peor ya que la diferencia entre clases no se llega a ver como en el anterior."},{"metadata":{},"cell_type":"markdown","source":"A continuación, vamos a volver a hacer un análisis multivariado usando \"mean\" y luego \"worst\" con un heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_heatmap(data_train_aux1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En esta gráfica podemos encontrar varias relaciones claras:\n\n* Radius, perimeter y area tienen una relación directa como hemos podido comprobar antes.\n* Concave poinst con radius perimeter y area tiene una relación directa (esto también lo hemos podido comprobar en la anterior gráfica).\n* Compactness concavity y concave points también están relacionadas diréctamente."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_box(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con estos diagramas de cajas podemos sacar rangos más precisos sobre cada variable (sin tener en cuenta los valores anómalos representados por puntos en el diagrama). Obtendremos intervalos mas exáctos que en el histograma (ya que en este tipo de gráficos aparecen valores máximos, mínimos y anómalos). Empezaremos con las variables predictoras de tipo mean:\n\n* Radius: [6.981, 22.27] con ocho valores anómalos desde 23.09 hasta 28.11.\n* Texture: [10.38, 29.43] con siete valores anómalos desde 29.81 hasta 39.28.\n* Perimeter: [43.79, 153.5] con seis valores anómalos desde 155.1 hasta 188.5.\n* Area: [143.5, 1386] con trece valores anómalos desde 1404 hasta 2501.\n* Smoothness: [0.06251, 0.1326] con cinco valores anómalos desde 0.1371 hasta 0.1634.\n* Compactness: [0.01938, 0.2276] con diez valores anómalos desde 0.2293 hasta 0.3454.\n* Concavity: [0, 0.2871] con diez valores anómalos desde 0.3001 hasta 0.4268.\n* Concave points: [0, 0.152] con siete valores anómalos desde 0.1562 hasta 0.2212.\n* Symmetry: [0.1203, 0.2459] con un valor anómlao en 0.106 y once anómalos desde 0.2495 hasta 0.304.\n* Fractal_dimension: [0.04996, 0.07871] con doce valores anómalos desde 0.0795 hasta 0.09744.\n\nContinuamos con las variables de tipo worst:\n* Radius: [7.93, 28.4] con seis valores anómalos desde 29.17 hasta 36.04.\n* Texture: [12.49, 40.68] con cinco valores anómalos desde 41.61 hasta 47.16.\n* Perimeter: [50.41, 188.5] con once valores anómalos desde 195 hasta 251.2.\n* Area: [185.2, 2089] con veinte valores anómalos desde 2145 hasta 4254.\n* Smoothness: [0.08125, 0.1862] con un valor anómalo en 0.07117 y siete valores anómalos desde 0.1878 hasta 0.2226.\n* Compactness: [0.02729, 0.6247] con trece valores anómalos desde 0.659 hasta 1.058.\n* Concavity: [0, 0.7681] con nueve valores anómalos desde 0.8216 hasta 1.252.\n* Concave points: [0, 0.291] sin valores anómalos.\n* Symmetry: [0.1566, 0.4154] con 17 valores anómalos desde 0.4228 hasta 0.6638.\n* Fractal_dimension: [0.05521, 0.1224] con 14 valores anómalos desde 0.1233 hasta 0.2075.\n\n\nAdemás, estos diagramas nos brindan más información que puede resultar interesante para este problema:\n\n* Los diagramas de caja de las variables que siguen distribuciones normales son simétricas.\n* Además, los valores anómalos casi siempre se encuentran con valores mayores del rango."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"A continuación vamos a analizar la anchura de los intervalos de confianza del 95% (fórmula intervalo confianza media+-z\\*se). Compararemos las variables de tipo 'mean' con la anchura del intervalo de confianza."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvariables=['radius','texture','perimeter','area', 'smoothness', 'compactness', 'concavity', 'concave points', 'symmetry', 'fractal_dimension']\ndata_train_anchura=utils.anchura_intervalo_confianza(variables, data_train)\nfor v in variables:\n    data_train_anchura[v+\"_mean\"]=data_train_aux1[v+\"_mean\"]\nutils.plot_histogram(data_train_anchura)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combinando diagramas de variables de tipo mean y anchura vemos intervalos demasiado anchos en compactness, concavity y concave points.\n\nTambién encontramos variables con intervalos anchos (no tanto como los otros), por ejemplo fractal_dimension, symmetry y smoothness.\n\nLas variables que mejores intervalos de confianza (del 95%) nos brindan son: radius, texture, perimeter y area.\n\nPor lo que debemos de tener en cuenta que las variables más \"fiables\" son radius,texture, perimeter y area. Luego encotramos variables que no son tan buenas como fractal_dimension, symetry y smoothness. Por último, las variables compactness, concavity y concave son variables poco fiables ya que tienen un intervalo de confianza (medio) demasiado ancho."},{"metadata":{},"cell_type":"markdown","source":"### Resumen"},{"metadata":{},"cell_type":"markdown","source":"Después de analizar los datos sacamos las siguientes conclusiones:\n* Tenemos variables muy parecidas en 'mean': radius, perimeter y area\n* En 'worst' la variable area es algo más distinta de radius y perimeter.\n* Los tumores benignos suelen casi todos los valores de las variables predictoras más bajos (menos en fractal_dimension).\n* Las varibles que más confianza brindan (en cuanto a error estandar) son radius, texture, perimeter y area.\n* Las variables que menos confianza brindan son compactness, concavity y concave por su gran error estandar (deben de ser imputadas).\n* Usaremos los rangos de los diagramas de cajas para suavizar los valores anómalos.\n* En el pairplot podemos ver que si dividimos los rangos en 5 hay partes donde encontraremos solo puntos azules en la izquierda y puntos rojos en la derecha de algunos diagramas. Por ello, pensamos que una discretización uniforme en 5 beans puede ir bien para este problema.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## 2.3. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Crearemos varios transformadores que se ejecutaran sobre los datos crudos y que serán añadidos en las pipelines correspondientes."},{"metadata":{},"cell_type":"markdown","source":"### Limpieza de datos"},{"metadata":{},"cell_type":"markdown","source":"Los transformadores que aparecen a continuación se encargan de suavizar el ruido de nuestros datos. "},{"metadata":{},"cell_type":"markdown","source":"Primero creamos un transformador que se encarga de poner como valores nulos los valores anómalos de cada variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_put_anomalos=utils.ManualNanPut({'radius_mean':[6.981,22.27], 'texture_mean':[10.38,29.43], 'perimeter_mean':[43.79,153.5], 'area_mean':[143.5,1386], 'smoothness_mean':[0.06251, 0.1326], 'compactness_mean':[0.01938, 0.2276], 'concavity_mean':[0,0.2871], 'concave points_mean':[0,0.152],'symmetry_mean':[0.1203, 0.2459], 'fractal_dimension_mean':[0.04996, 0.0787], 'radius_worst':[7.93,28.4], 'texture_worst':[12.49,40.68], 'perimeter_worst':[50.41,188.5], 'area_worst':[185.2,2089], 'smoothness_worst':[0.08125, 0.1862], 'compactness_worst':[0.02729, 0.6247], 'concavity_worst':[0,0.7681], 'concave points_worst':[0,0.291],'symmetry_worst':[0.1506, 0.4154], 'fractal_dimension_worst':[0.05521, 0.1224] })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Primero creamos un transformador que se encarga de poner como valores nulos los valores ruidosos de cada variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_put_ruidosos=utils.ManualNanPutSE({'radius':1.2, 'texture':2.5, 'perimeter':18.5, 'area':229.99, 'smoothness':0.015, 'compactness':0.03, 'concavity':0.025, 'concave points':0.015,'symmetry':0.036, 'fractal_dimension':0.0085 })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Después de borrar todos los valores ruidosos y anómalos, realizaremos una imputación de valores perdidos (preservando la media):"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp = SimpleImputer(missing_values=float('nan'), strategy='mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reducción de datos"},{"metadata":{},"cell_type":"markdown","source":"#### Imputación de variables"},{"metadata":{},"cell_type":"markdown","source":"Después, como hemos visto en el analisis exploratorio de datos vamos a imputar las variables 'concavity', 'compactness' y 'concavity points' ya que son variables con demasiado ruido. También, en la parte de 'mean' quitaremos perimeter y area porque son muy parecidas a radius (es decir, estan muy relacionadas). En la parte de worst solo quitaremos perimeter ya que area se diferencia un poco más de las otras dos. Además, quitaremos las variables de tipo 'se' ya que no se deben de usar para predecir."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_selector=utils.ManualFeatureSelector([0, 1, 4, 8, 9, 20, 21, 23, 24, 28, 29])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Discretización"},{"metadata":{},"cell_type":"markdown","source":"Tal y como hemos visto en el análisis exploratorio de datos, lo mejor sería discretizar usando la estrategia de k-medias en 2 intervalos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=5, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4. Creación de nuestros modelos y pipelines"},{"metadata":{},"cell_type":"markdown","source":"Creamos el clasificador 0R:"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos el árbol de decisión:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model_classifier = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pipeline"},{"metadata":{},"cell_type":"markdown","source":"Creamos el pipeline del árbol de decisión con discretización:"},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(nan_put_anomalos, nan_put_ruidosos, imp, feature_selector, discretizer, tree_model_classifier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creamos el pipeline del árbol de decisión sin discretización"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = make_pipeline(nan_put_anomalos, nan_put_ruidosos, imp, feature_selector, tree_model_classifier)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTA: No es necesario crear el pipeline para 0R ya que en este modelo siempre se va a elegir la clase mayoritaria (no necesitamos un preprocesamiento de datos)."},{"metadata":{},"cell_type":"markdown","source":"## 2.5. Evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"Ahora es el momento de entrenar y validar nuestros clasificadores. Para ello, vamos a usar una matriz de confusión, precisión y recall ya que en problemas médicos es lo más usual (ya que en este tipo de problemas la variable clase no se encuentra balanceada).\n\nPrecisión= TP/(TP+FP) Recall= TP/(TP+FN)\n\nTambién dibujaremos la curva ROC para analizar con mayor certeza los resultados."},{"metadata":{},"cell_type":"markdown","source":"### Clasificador 0R"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate2(zero_r_model, X_train, X_test, y_train, y_test, 'M')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Precisión=0/(0+0)=0 Recall=0/(0+53)=0\n\nObviamente con 0R hemos obtenido malos resultados ya que 0R clasifica siempre como la clase mayoritaria. El tumor benigno siempre será la clase mayoritaria por lo que siempre se predice como benigno. Un modelo que siempre predice como benigno no es útil para este caso ya que nunca nos ayudará a encontrar los tumores malignos (y diagnosticarlos correctamente)."},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión sin discretizar"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate2(tree_model,\n               X_train, X_test,\n               y_train, y_test, 'M')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concluimos que el 87% de los casos clasificados como malignos, lo son realmente, sabiendo además que el 88% de los tumores malignos ha sido diagnosticado como tal. Tenemos un buen comportamiento en este caso ya que la precision y recall son altos."},{"metadata":{},"cell_type":"markdown","source":"### Árbol de decisión discretizado"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate2(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test, 'M')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concluimos que el 90% de los casos clasificados como malignos, lo son realmente, sabiendo además que el 90% de los tumores malignos ha sido diagnosticado como tal. Tenemos un muy buen comportamiento en la precisión y en el recall."},{"metadata":{},"cell_type":"markdown","source":"### Resumen de resultados"},{"metadata":{},"cell_type":"markdown","source":"Habiendo estudiado los tres modelos anteriores 0R es un mal modelo (no es conveniente llevarlo a la práctica). Los dos modelos siguientes se comportan mucho mejor siendo el discretizado el que mejor se comporta de los tres."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}