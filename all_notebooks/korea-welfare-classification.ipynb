{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Introduction**\nWe were provided data from the Korean Government for years of 2005 to 2018. This included lots of information on the household statistics and their income. The content included in the dataset can be broken down into the following:\n\nid\n\nyear : study conducted\n\nwave : from wave 1st in 2005 to wave 14th in 2018\n\nregion: 1) Seoul 2) Kyeong-gi 3) Kyoung-nam 4) Kyoung-buk 5) Chung-nam 6) Gang-won &. Chung-buk 7) Jeolla & Jeju\n\nincome: yearly income in M KRW(Million Korean Won. 1100 KRW = 1 USD)\n\nfamily_member: no. of family members\n\ngender: 1) male 2) female\n\nyear_born\n\neducation_level: 1) no education(under 7 yrs-old) 2) no education(7 & over 7 yrs-old) 3) elementary 4) middle school 5) high school 6) college 7) university degree 8) MA 9) doctoral degree\n\nmarriage: marital status. 1) not applicable (under 18) 2) married 3) separated by death 4) separated 5) not married yet 6) others\n\nreligion: 1) have religion 2) do not have\n\noccupation: this will be provided in separated code book\n\ncompany_size\n\nreasonnoneworker: 1) no capable 2) in military service 3) studying in school 4) prepare for school 5) preprare to apply job 6) house worker 7) caring kids at home 8) nursing 9) giving-up economic activities 10) no intention to work 11) others\n\nThroughout my analysis, I will look at how the data can be presented visually and determine if there are any interesting facts that can be pulled from this data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load information from the overall dataset and the definitions for the occupations into dataframes. Although the job titles will not be used for analysis, it will be added into our dataset to make it easier to visualize the data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"wf = pd.read_csv('/kaggle/input/korea-income-and-welfare/Korea Income and Welfare.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The analysis only requires the job code and title. In the interest of keeping the data clean, the first two columns can be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"job_check = pd.read_excel('/kaggle/input/korea-income-and-welfare/job_code_translated.xlsx')\njob_check = job_check[['job_code', 'job_title']]\njob_check = job_check.rename(columns={\"job_code\": \"occupation\", \"job_title\": \"job_title\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**\n\nI wanted to see if there were any missing values in the dataset. Based on the below, there are no null values in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, using describe we can look at the data in a much more aggregated view. There were a couple of pieces that jump out right away in this view.\n\n1. Income - Dispersed between 468,209 Won and -232,174 Won, with the majority of income being below 5,000.\n\n2. Marriage - There are values that are noted as 0 and 9 which do not have a description associated with it.\n\n3. Religion - There should be binary (1 or 2). Currently there is a 9 in the column. \n\n4. Occupation, Company_size, Reason_none_worker - Did not show up in the aggregated view. Based on this, it seems like there are some none numeric values in the column."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.marriage.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"The only numbers that have associated descriptions are numbers between 1 and 8. The below will remove all rows from that have a 0 or 9 in the marriage column."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf = wf[wf['marriage'].between(1, 8)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.marriage.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, the reason_none_worker column needs to be cleaned up. The numbers that have descriptions are numbers between 1 and 11. In addition, cells that have ' ' are individuals that currently have jobs."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.reason_none_worker.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There were a large amount of rows that have ' ' in the reason_none_worker. To ensure all of these instances were actually individuals who had no jobs, the dataset was filtered by rows under occupation with ' ' which would signify no jobs. Using the value counts, we can see there are situations where column reason_none_worker has ' ' (1493 instances of this). In order to clean the data we will need to remove these."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf[(wf['occupation'] == ' ')].value_counts('reason_none_worker')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove all rows that have 0 and 99 noted in the column reason_none_worker."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf = wf[wf['reason_none_worker'] != '99']\nwf = wf[wf['reason_none_worker'] != '0']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to remove the rows that had a ' ' in columns occupation and reason_none_worker, two column checks were added to the dataset. Once the indexes of the True statements were found, the rows associated with these indexed numbers. In addition, the newly made columns were dropped because they were no longer useful."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf['check'] = wf.occupation.apply([lambda x: True if x == ' ' else False])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf['check2'] = wf.reason_none_worker.apply([lambda x: True if x == ' ' else False])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexNames = wf[(wf['check'] == True) & (wf['check2'] == True)].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(indexNames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to "},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.drop(indexNames , inplace=True)\nwf = wf.drop(['check'], axis=1)\nwf = wf.drop(['check2'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To continue with the analysis, the descriptions were added to the dataset. The columns will eventually need to be broken into dummies that will allow the machine learning models to run."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['marriage'] == 1, 'marriage'] = 'NA(Under_18)'\nwf.loc[wf['marriage'] == 2, 'marriage'] = 'married'\nwf.loc[wf['marriage'] == 3, 'marriage'] = 'separated_by_death'\nwf.loc[wf['marriage'] == 4, 'marriage'] = 'separated'\nwf.loc[wf['marriage'] == 5, 'marriage'] = 'not_married_yet'\nwf.loc[wf['marriage'] == 6, 'marriage'] = 'others'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['education_level'] == 1, 'education_level'] = 'no_education(under_7)'\nwf.loc[wf['education_level'] == 2, 'education_level'] = 'no_education'\nwf.loc[wf['education_level'] == 3, 'education_level'] = 'elementary'\nwf.loc[wf['education_level'] == 4, 'education_level'] = 'middle_school'\nwf.loc[wf['education_level'] == 5, 'education_level'] = 'high_school'\nwf.loc[wf['education_level'] == 6, 'education_level'] = 'college'\nwf.loc[wf['education_level'] == 7, 'education_level'] = 'university_degree'\nwf.loc[wf['education_level'] == 8, 'education_level'] = 'MA'\nwf.loc[wf['education_level'] == 9, 'education_level'] = 'doctoral_degree'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['region'] == 1, 'region'] = 'Seoul'\nwf.loc[wf['region'] == 2, 'region'] = 'Kyeong-gi'\nwf.loc[wf['region'] == 3, 'region'] = 'Kyoung-nam'\nwf.loc[wf['region'] == 4, 'region'] = 'Kyong-buk'\nwf.loc[wf['region'] == 5, 'region'] = 'Chong-nam'\nwf.loc[wf['region'] == 6, 'region'] = 'Gang-won & Chung-buk'\nwf.loc[wf['region'] == 7, 'region'] = 'Jeju'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['reason_none_worker'] == '1', 'reason_none_worker'] = 'not_capable'\nwf.loc[wf['reason_none_worker'] == '2', 'reason_none_worker'] = 'in_military_service'\nwf.loc[wf['reason_none_worker'] == '3', 'reason_none_worker'] = 'studying_in_school'\nwf.loc[wf['reason_none_worker'] == '4', 'reason_none_worker'] = 'prepare_for_school'\nwf.loc[wf['reason_none_worker'] == '5', 'reason_none_worker'] = 'prepare_to_apply_job'\nwf.loc[wf['reason_none_worker'] == '6', 'reason_none_worker'] = 'house_worker'\nwf.loc[wf['reason_none_worker'] == '7', 'reason_none_worker'] = 'caring_for_kids_at_home'\nwf.loc[wf['reason_none_worker'] == '8', 'reason_none_worker'] = 'nursing'\nwf.loc[wf['reason_none_worker'] == '9', 'reason_none_worker'] = 'giving_up_economic_activities'\nwf.loc[wf['reason_none_worker'] == '10', 'reason_none_worker'] = 'no_intention_to_work'\nwf.loc[wf['reason_none_worker'] == '11', 'reason_none_worker'] = 'other'\nwf.loc[wf['reason_none_worker'] == ' ', 'reason_none_worker'] = 'employed'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['gender'] == 1, 'gender'] = 'male'\nwf.loc[wf['gender'] == 2, 'gender'] = 'female'\nwf.loc[wf['religion'] == 1, 'religion'] = 'religious'\nwf.loc[wf['religion'] == 2, 'religion'] = 'non-religious'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['occupation'] == ' ', 'occupation'] = 20000\n\nwf = wf.astype({'occupation': 'int64'})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf = wf.merge(job_check, on='occupation', how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Visualization**"},{"metadata":{},"cell_type":"markdown","source":"The first variable that we will look at is the income by education level. We can see that the majority of data is congregated around 0, with the largest depersement on income in people with an education level of high school, college and university. After the boxplot (shown below), we determined that 99.6 percent of the income is within the range of -47 and 24,484. Without additional information, I assumed that there cannot be negative income and removed all rows that had income under 0 and over 25,000."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.boxplot(data=wf, x='education_level', y='income')\nplt.title('Education to Income Comparison')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.income.quantile([.002, .998])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf = wf[(wf['income'] <= 25000) & (wf['income'] >= 0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data has a much larger proportion of males in the data. In addtion, there seemed to be a large increase in the number of the individuals included in the dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize = (15,8))\nsns.countplot(data = wf, x='year', hue='gender')\nplt.title('Total Individuals Per Year by Gender')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we wanted to see if there was a breakdown by marriage to determine if there was a specific group that would caused the increase in the welfare survey in 2011. In the visualization, we can see the majority of the increase was mainly caused by individuals under 18. There is a possibility that there was a major increase in birth rates; however, there has been a decrease in birth rates in Korea so I find this reasoning unlikely. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,8))\nsns.countplot(data = wf, x='year', hue='marriage')\nplt.title('Marriage by Year')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the following visualization, we look at the number of individuals included in each Job Category (Top 10). Based on the survey, cleaners and car drivers are the categories that most people work in. In the visualization showing the average income for these categories, we see that cleaners are by far the least paid of all of the other top job categories. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,6))\nsns.countplot(data = wf, y='job_title', order=wf.job_title.value_counts().iloc[1:11].index)\nplt.xticks(rotation=90)\nplt.title('Workers by Job Category (Top 10)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.barplot(data=wf, x='job_title', y='income', order=wf.job_title.value_counts().iloc[1:11].index)\nplt.title('Job Category to Income Comparison (Top 10)')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instead of using year born, I thought it would be easier to look at the age of an individual. Below is the code to add the column and remove the year_born."},{"metadata":{"trusted":true},"cell_type":"code","source":"wf['age'] = [y-z for y, z in zip(wf['year'], wf['year_born'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf=wf.drop('year_born', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is a visualization breaking down the age and gender of the dataset. Men is much more distributed over the total age range vs. women which were much more likely to be between 60 and 80 in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"target_0 = wf.loc[wf['gender'] == 'male']\ntarget_1 = wf.loc[wf['gender'] == 'female']\n\nsns.distplot(target_0[\"age\"], kde=False, bins = 20)\nsns.distplot(target_1[\"age\"], kde=False, bins = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similar to the job category visualizations, I wanted to look at total count and average income by region in Korea. Kyeong-gi had the largest number of individuals in the dataset, but Seoul had the highest average income in the dataset. I chose to see if the data will be able to help us predict the region of an individual. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,8))\nsns.countplot(data = wf, y='region', hue='gender')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.barplot(data=wf, x='region', y='income')\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Prior to going through the classification models, we need to normalize data in columns that have a wider range than 0 and 1. This will ensure that our models do not give it more siginficance purly based on the size of the data compared to a binary variable. The columns that we will need to normalize are: age, income, company_size and family members. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nx = np.array(wf['age']) #returns a numpy array\nx = np.reshape(x,(-1,1))\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nwf['age'] = x_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(wf['income']) #returns a numpy array\nx = np.reshape(x,(-1,1))\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nwf['income'] = x_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wf.loc[wf['company_size'] == ' ', 'company_size'] = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(wf['company_size']) \nx = np.reshape(x,(-1,1))\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nwf['company_size'] = x_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(wf['family_member']) \nx = np.reshape(x,(-1,1))\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nwf['family_member'] = x_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(wf['year']) \nx = np.reshape(x,(-1,1))\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nwf['year'] = x_scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For our model, I chose to drop id and wave because they were no longer useful because id was only an identifier and wave provides same information as year. In addition, I chose to drop company_size and occupation because occupation because it will add too many columns to the dataset when broken down into the dummy variables and company size is tied to the occupation variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=wf[['region', 'income', 'age', 'year','family_member', 'gender', 'education_level', 'marriage', 'religion', 'reason_none_worker']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In order to include variables that are in a string form, we need to break out the variable by using dummy variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns[5:]:\n    df = pd.get_dummies(df, columns=[col], prefix = [col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, I broke down our dataset into a train and test variable. For ease, I used an 80/20 split. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntarget = df.iloc[:, 0:1].values.ravel()\ndata = df.iloc[:,1:len(df.columns)]\n\nx_train, x_test, y_train, y_test = train_test_split(data, target, test_size=.2, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The classification models that I'm using are: Logistic Regression, Decision Tree Classifier, and K Neighbors Classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(multi_class=\"multinomial\", max_iter=500)\nmodel.fit(x_train, y_train)\npre = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier()\nmodel_dec = model.fit(x_train, y_train)\npre_dec = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh = KNeighborsClassifier(n_neighbors = 7).fit(x_train,y_train)\npre_kn = neigh.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we ran a classification report to determine which model ran the best. Below we can see that KNeighbors has the highest accuracy F1 score (only slightly higher than the other models.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint('Logistic Regression')\nprint(classification_report(y_test, pre))\nprint('Decision Tree')\nprint(classification_report(y_test, pre_dec))\nprint('KN Neighbors')\nprint(classification_report(y_test, pre_kn))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the original model, the neighbors were chosen at 7. Next we will see if we can increase our accuracy score by increasing the number of neighbors in the model. We see that having 19 neighbors, we would be able to increase accuracy but it would only be by about 1.5%."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nacc = {}\nfor i in range(1,20):\n    neigh = KNeighborsClassifier(n_neighbors = i).fit(x_train,y_train)\n    pre_kn = neigh.predict(x_test)\n    acc[i] = metrics.accuracy_score(y_test, pre_kn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import operator\n\nmax(acc, key=lambda key: acc[key])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that a comparison of the predicted values to the actual values in the confusion matrix which resulted in poorly predicted values."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \n\nfinal_cm = confusion_matrix(y_test, pre_kn)\nknn_labels = neigh.classes_\n\nplt.figure(figsize=(10,7))\n\nax= plt.subplot()\nsns.heatmap(final_cm, annot=True, ax = ax, fmt=\"d\");\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels');\nax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix');\nax.yaxis.set_tick_params(rotation=360)\nax.xaxis.set_tick_params(rotation=90)\n\nax.xaxis.set_ticklabels(knn_labels); \nax.yaxis.set_ticklabels(knn_labels);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nBased on the above models, the information that I chose did not provide a strong predictor of where a person would be from. The models may have been improved if i had not have dropped the occupation and company size, but I believe that this may not have helped much due to the relative evenly distributed data associated with regions. In addition, I there many other areas variables that we may have been able to look at in the future for classification purposes. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}