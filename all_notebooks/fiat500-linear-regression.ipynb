{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Fiat500 used car prices","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://cdn.pixabay.com/photo/2017/09/05/08/55/isolated-2716838_960_720.png\" alt=\"Fiat500\" width=\"200\"/>","metadata":{"persistent_id":"fa37df12-0390-4179-96df-51ca3bea6289"}},{"cell_type":"markdown","source":"# The problem\nIn this notebook we look at the data we got via this [Kaggle competition](https://www.kaggle.com/paolocons/small-dataset-about-used-fiat-500-sold-in-italy). \n\nWe will see if we can predict the sales price of a used Fiat 500 car. \n\nWe will explore the dataset given, check the various features we have and we will make an algorithm that can predict the sales price of the car.","metadata":{"persistent_id":"f7df9533-c6e2-4ece-98f0-ed92be877650"}},{"cell_type":"markdown","source":"# 1. Import the important libraries / packages\nThese packages are needed to load and use the dataset","metadata":{"execution_event_id":"13d304eb-fdbe-4906-88e5-e374ea44fd29","last_executed_text":"# 1. Import the important libraries / packages\nThese packages are needed to load and use the dataset","persistent_id":"4df8bd6f-e931-42f2-b03c-a0e24841b32c"}},{"cell_type":"code","source":"import pandas as pd #we use this to load, read and transform the dataset\nimport numpy as np #we use this for statistical analysis\nimport matplotlib.pyplot as plt #we use this to visualize the dataset\nimport seaborn as sns #we use this to make countplots\nimport sklearn.metrics as sklm #This is to test the models","metadata":{"execution_event_id":"8b38ea31-f105-4347-8725-b3509566ff86","last_executed_text":"import pandas as pd #we use this to load, read and transform the dataset\nimport numpy as np #we use this for statistical analysis\nimport matplotlib.pyplot as plt #we use this to visualize the dataset\nimport seaborn as sns #we use this to make countplots\nimport sklearn.metrics as sklm #This is to test the models","persistent_id":"57c63c86-b234-4e77-aa3a-0a07094e620f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here we load the train data\ndata = pd.read_csv(r'/kaggle/input/small-dataset-about-used-fiat-500-sold-in-italy/Used_fiat_500_in_Italy_dataset.csv')\n\n#and immediately I would like to see how this dataset looks like\ndata.head()","metadata":{"execution_event_id":"ad33e27f-1761-44bb-ab25-a29b1b07ad7f","last_executed_text":"#here we load the train data\ndata = pd.read_csv(r'C:\\Users\\Renate\\Documents\\GitHub\\Python-in-Power-BI\\Used Fiat 500 in Italy/Used_fiat_500_in_Italy_dataset.csv')\n\n#and immediately I would like to see how this dataset looks like\ndata.head()","persistent_id":"c2f3b90a-7328-4fda-a93c-1525ac6c3b36","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now let's look closer at the dataset we got\ndata.info()","metadata":{"execution_event_id":"5ed0229b-711c-40be-9680-a2c69eff305f","last_executed_text":"#now let's look closer at the dataset we got\ndata.info()","persistent_id":"537c48da-2809-4a2a-ab62-78546f089558","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution_event_id":"8931a147-e8c3-4098-bb6f-edf177025f87","last_executed_text":"data.shape","persistent_id":"388ad441-6c0a-456d-bac0-bf3a9d282e08","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution_event_id":"17ac9cee-3e77-4dd1-8d73-aca19a834619","last_executed_text":"data.describe()","persistent_id":"4e2bf2b5-4414-4d66-a42a-cb129a5c9c07","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's see what the options are in the model column (the objects)\nprint(data['model'].unique())","metadata":{"execution_event_id":"5a90d984-9ea8-4379-890a-c6ff668b61d0","last_executed_text":"#Let's see what the options are in the text columns (the objects)\nprint(data['model'].unique())","persistent_id":"434028e0-0409-4ded-9b7b-832b6a673e13","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's see what the options are in the transmission column (the objects)\nprint(data['transmission'].unique())","metadata":{"execution_event_id":"cda4e715-94cd-4006-be09-f4d0583f2b99","last_executed_text":"#Let's see what the options are in the transmission column (the objects)\nprint(data['transmission'].unique())","persistent_id":"8d490fb6-118d-4781-b7ef-48ea4631bf24","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Explore the dataset","metadata":{}},{"cell_type":"markdown","source":"## Price in the dataset\nAs this is the column we would like to predict, let's look closer to this column.","metadata":{"persistent_id":"c81b18c0-1589-4422-93b7-50b79ee5f697"}},{"cell_type":"code","source":"#Now let's try a histogram\nplt.hist(data['price'])","metadata":{"execution_event_id":"252cfd4d-b403-4e3d-a4d9-09fe9e9cbe7f","last_executed_text":"#Now let's try a histogram\nplt.hist(data['price'])","persistent_id":"cae87ef7-e1c1-4793-914a-5f4c454963e2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we will try a Box & Wiskers plot\nplt.boxplot(data['price'])","metadata":{"execution_event_id":"64978003-4da5-4971-9db0-fff64a795d48","last_executed_text":"#Now we will try a Box & Wiskers plot\nplt.boxplot(data['price'])","persistent_id":"c18c8ea6-aabc-4855-9a78-448e5453d9ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see an outlier around 16.000 euro. Let's look closer at this outlier","metadata":{}},{"cell_type":"code","source":"outliers = data[data['price'] > 14000]\noutliers.head()","metadata":{"execution_event_id":"9c65eda5-dbf7-498b-aac9-1603b94f17a2","last_executed_text":"outliers = data[data['price'] > 14000]\noutliers.head()","persistent_id":"d183e169-ce6e-4daf-b07c-49e085cffacc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This price is for a pop model, let's look more closely to the price range per model type","metadata":{}},{"cell_type":"code","source":"#first let's set the model column as categorical\ndata['model'] = data['model'].astype('category')\ndata.info()","metadata":{"execution_event_id":"5463f2e0-41cf-43f5-a298-4b64821bc7cf","last_executed_text":"#first let's set the model column as categorical\ndata['model'] = data['model'].astype('category')\ndata.info()","persistent_id":"8db6d620-620a-4bd9-b7b4-489c26c3df72","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#next let's plot per category how the data distribution looks like\nmodels = list(data['model'])\nvalues = list(data['price'])\n\nfig, axs = plt.subplots(1, 2, figsize=(9,4), sharey=True)\naxs[0].bar(models, values)\naxs[1].scatter(models, values)\nfig.suptitle('Categorical Plotting')","metadata":{"execution_event_id":"5b636469-f792-47e3-bdb0-0cb18383be12","last_executed_text":"#next let's plot per category how the data distribution looks like\nmodels = list(data['model'])\nvalues = list(data['price'])\n\nfig, axs = plt.subplots(1, 2, figsize=(9,4), sharey=True)\naxs[0].bar(models, values)\naxs[1].scatter(models, values)\nfig.suptitle('Categorical Plotting')","persistent_id":"2e64e00b-d77d-4b8e-92aa-db5c97609eda","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Make a countplot to see how many models are sold\ncountplt, ax = plt.subplots(figsize = (10,7))\nax =sns.countplot(x = 'model', data=data)","metadata":{"execution_event_id":"cd75f3bb-036b-4460-a7d7-883578f3142f","last_executed_text":"# define the figure and plot; modify the countplot figure size\ncountplt, ax = plt.subplots(figsize = (10,7))\nax =sns.countplot(x = 'model', data=data)","persistent_id":"c4aa72a7-44df-4620-b69b-7d6e741fc7ba","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like lounge is the most sold type of model and there is only one star model in this dataset.\nLet's look into this star model more closely.","metadata":{"execution_event_id":"531b59b5-3ce4-47fc-987c-7541d61e3c8e","last_executed_text":"fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4)\nplt.rcParams[\"figure.figsize\"] = (5, 20)\npop = data[data['model'] == 'pop']\nlounge = data[data['model'] == 'lounge']\nsport = data[data['model'] =='sport']\nstar = data[data['model'] =='star']\nax1.boxplot(pop['price'])\nax2.boxplot(lounge['price'])\nax3.boxplot(sport['price'])\nax4.boxplot(star['price'])\nplt.show()","persistent_id":"44769c9a-8b4c-4d5d-a207-d7423ff7bf72"}},{"cell_type":"code","source":"star = data[data['model'] == 'star']\nstar.head()","metadata":{"execution_event_id":"72bb0289-d7e2-441b-a24d-bf560473a030","last_executed_text":"star = data[data['model'] == 'star']\nstar.head()","persistent_id":"926fbe8b-6f7e-44bd-a561-4355ec5ddcbd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is indeed only one star model in this dataset. ","metadata":{}},{"cell_type":"markdown","source":"# 3. Make all columns numeric\nWe need to make all column input numeric to use them further on. \nThis is what we will do now. ","metadata":{"persistent_id":"adda1573-c8ae-48a1-a4a1-7ec970b92014"}},{"cell_type":"code","source":"#the only two columns that are not numeric are 'model' and ' transmission'.\n#to show how we have changed the values, let's encode this manually\nmodel_dict = {'pop':4, 'lounge':3, 'sport':2, 'star':1}\ndata['model'].replace(model_dict, inplace=True)\ndata.info()","metadata":{"execution_event_id":"5b4ccfd9-aaa8-4dd1-8f43-e3e46aa3a2bd","last_executed_text":"#the only column that is not numeric is the column with the models.\n#to show how we have changed the values, let's encode this manually\nmodel_dict = {'pop':4, 'lounge':3, 'sport':2, 'star':1}\ndata['model'].replace(model_dict, inplace=True)\ndata.info()","persistent_id":"3036e739-36a9-4dda-97ae-1a63f4d9ccc9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the only two columns that are not numeric are 'model' and ' transmission'.\n#to show how we have changed the values, let's encode this manually\ntrans_dict = {'manual':1, 'automatic':2}\ndata['transmission'].replace(trans_dict, inplace=True)\ndata.info()","metadata":{"execution_event_id":"d173eba0-81e3-41bc-b50d-5843e12d7eda","last_executed_text":"#the only two columns that are not numeric are 'model' and ' transmission'.\n#to show how we have changed the values, let's encode this manually\ntrans_dict = {'manual':1, 'automatic':2}\ndata['transmission'].replace(trans_dict, inplace=True)\ndata.info()","persistent_id":"60b4eab6-3613-4546-a793-b6d3aedc2864","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Most important features\nLet's continue by looking at the most important features according to three different tests. \nThan we will use the top ones to train and test our first model. ","metadata":{}},{"cell_type":"code","source":"#First we need to split the dataset in the y-column (the target) and the components (X), the independent columns. \n#This is needed as we need to use the X columns to predict the y in the model. \n\ny = data['price'] #the column we want to predict \nX = data.drop(labels = ['price'], axis = 1)  #independent columns ","metadata":{"execution_event_id":"65e1ba19-f342-4530-9787-3206b546ea19","last_executed_text":"#First we need to split the dataset in the y-column (the target) and the components (X), the independent columns. \n#This is needed as we need to use the X columns to predict the y in the model. \n\ny = data['price'] #the column we want to predict \nX = data.drop(labels = ['price'], axis = 1)  #independent columns ","persistent_id":"fda58c53-79e1-465f-86e6-f0d9105c9c39","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#as Longitude and latitude are features which need to be combined to have an influence, we will drop them for now. \nX = X.drop(labels = ['lon', 'lat'], axis =1)","metadata":{"execution_event_id":"fb4df24b-3456-4634-bb65-bd946cb1692b","last_executed_text":"#as Longitude and latitude are features which need to be combined to have an influence, we will drop them for now. \nX = X.drop(labels = ['lon', 'lat'], axis =1)","persistent_id":"b2dfda85-f2ab-4f25-b66a-b756b4784a13","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST 1 - ExtraTreesClassifier - GOOD IF YOU USE DECISION TREE MODELS\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values()\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","metadata":{"execution_event_id":"e6865045-438b-433b-8572-dea25f52aa58","last_executed_text":"#TEST 1 - ExtraTreesClassifier - GOOD IF YOU USE DECISION TREE MODELS\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values()\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","persistent_id":"4b66d805-6145-4397-8565-875826bf3741","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST 2 - SelectKBest - GOOD IF YOU USE A K-NEAREST NEIGHBOR MODEL\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\n#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k='all')\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Name of the column','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10,'Score'))  #print 10 best features","metadata":{"execution_event_id":"fa70956a-ff66-4c3b-a123-d8de8f7a81c0","last_executed_text":"#TEST 2 - SelectKBest - GOOD IF YOU USE A K-NEAREST NEIGHBOR MODEL\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\n#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k='all')\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Name of the column','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10,'Score'))  #print 10 best features","persistent_id":"d6cfd620-8d74-4859-a46c-7491b8db16f9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST 3 - Correlations - Linear and logistic regression like correlated data to have a good prediction\n#get correlations of each features in dataset\ncorrmat = data.drop(labels =['lon', 'lat'], axis = 1) #this is because it is the original target column and therefore has a high correlation with our percentage column\ncorrmat = corrmat.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\n\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","metadata":{"execution_event_id":"3a5addcd-5980-4dae-8109-eb022ec6858c","last_executed_text":"#TEST 3 - Correlations - Linear and logistic regression like correlated data to have a good prediction\n#get correlations of each features in dataset\ncorrmat = data.drop(labels =['lon', 'lat'], axis = 1) #this is because it is the original target column and therefore has a high correlation with our percentage column\ncorrmat = corrmat.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\n\n#plot heat map\ng=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","persistent_id":"1e70e898-5146-486b-b6c8-9f0c00ee5fd7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems that Age in days and km have a strong negative relationship to the price of the car, which is very logical, as the older the car, the less it's worth. \n\nAlso age and km have a strong positive relationship, which is also logical, as the older the car the more likely it has ran more km. ","metadata":{}},{"cell_type":"code","source":"#let's keep all features for now. ","metadata":{"execution_event_id":"42a6f04b-4b01-4864-bb35-311e8c6041ec","last_executed_text":"#let's keep all features for now. ","persistent_id":"9d92750d-8e6e-40a3-967c-08fdf8a0ad07","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Machine learning Model\nAs we would like to predict a continuous number, the price, we would use a Linear Regression model here. ","metadata":{}},{"cell_type":"code","source":"#Load the chosen model here\nfrom sklearn.linear_model import LinearRegression","metadata":{"execution_event_id":"dd621a7b-5607-4078-a658-18c67075b8e6","last_executed_text":"#Load the chosen model here\nfrom sklearn.linear_model import LinearRegression","persistent_id":"4fb3c6f9-1604-49ef-a5a2-d00cdffc27cd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5a. Split the dataset in train and test","metadata":{}},{"cell_type":"markdown","source":"Before we are going to use the models choosen, we will first split the dataset in a train and test set.\nThis because we want to test the performance of the model on the training set and to be able to check it's accuracy. ","metadata":{"persistent_id":"cc2ae5b1-c5e7-47ec-9935-35b01d43c147"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#First try with all features\n\n#I want to withhold 35 % of the trainset to perform the tests\nX_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.35 , random_state = 25)","metadata":{"execution_event_id":"4daaa9ef-a572-4ea3-803d-6396b9da39f8","last_executed_text":"from sklearn.model_selection import train_test_split\n\n#First try with all features\n\n#I want to withhold 35 % of the trainset to perform the tests\nX_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.35 , random_state = 25)","persistent_id":"e2bd241f-ba81-48a3-945a-9b51836d9f7c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of X_train is: ', X_train.shape)\nprint('Shape of X_test is: ', X_test.shape)\nprint('Shape of Y_train is: ', y_train.shape)\nprint('Shape of y_test is: ', y_test.shape)","metadata":{"execution_event_id":"f1f01911-852e-458c-abc9-31d3e59088ab","last_executed_text":"print('Shape of X_train is: ', X_train.shape)\nprint('Shape of X_test is: ', X_test.shape)\nprint('Shape of Y_train is: ', y_train.shape)\nprint('Shape of y_test is: ', y_test.shape)","persistent_id":"a9076afe-ae3b-4409-914a-d1adab09426d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5b. Make a check for the model","metadata":{"persistent_id":"5ee150cc-c7a6-4acc-9d62-1d5fcc618d61"}},{"cell_type":"code","source":"#To check the model, I want to build a check:\nimport math\ndef print_metrics(y_true, y_predicted, n_parameters):\n    ## First compute R^2 and the adjusted R^2\n    r2 = sklm.r2_score(y_true, y_predicted)\n    r2_adj = r2 - (n_parameters - 1)/(y_true.shape[0] - n_parameters) * (1 - r2)\n    \n    ## Print the usual metrics and the R^2 values\n    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n    print('R^2                    = ' + str(r2))\n    print('Adjusted R^2           = ' + str(r2_adj)) #This is the number we will be focussing on. \n    #A good model would have an adjusted R2 of >70%, a bad model below this. \n    ","metadata":{"execution_event_id":"19363f39-cbd2-45ee-a2b6-f6173dca2973","last_executed_text":"#To check the model, I want to build a check:\nimport math\ndef print_metrics(y_true, y_predicted, n_parameters):\n    ## First compute R^2 and the adjusted R^2\n    r2 = sklm.r2_score(y_true, y_predicted)\n    r2_adj = r2 - (n_parameters - 1)/(y_true.shape[0] - n_parameters) * (1 - r2)\n    \n    ## Print the usual metrics and the R^2 values\n    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n    print('R^2                    = ' + str(r2))\n    print('Adjusted R^2           = ' + str(r2_adj)) #This is the number we will be focussing on. \n    #A good model would have an adjusted R2 of >70%, a bad model below this. \n    ","persistent_id":"a9a83104-0ec8-4cd3-ad91-c3d9d6ff81c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5c. Fit and check the Linear regression model","metadata":{}},{"cell_type":"code","source":"# Linear regression model\nmodel = LinearRegression() \nmodel.fit(X_train, y_train)","metadata":{"execution_event_id":"076839f1-b254-4254-8e4f-ef5c4ce5ff98","last_executed_text":"# Linear regression model\nmodel = LinearRegression() \nmodel.fit(X_train, y_train)","persistent_id":"c549429b-27c9-4490-8f9a-f63bbe3f708b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now let's see how this model performs\nPredictions = model.predict(X_test)\nprint_metrics(y_test, Predictions, 6)","metadata":{"execution_event_id":"dce8cdac-3266-4051-aca6-cda7bd1d857d","last_executed_text":"#Now let's see how this model performs\nPredictions = model.predict(X_test)\nprint_metrics(y_test, Predictions, 6)","persistent_id":"1fe8fab7-e6d6-4e1a-9a21-bde9345011c3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nAs you can see here, we have an adjusted R2 of 79%, so this model is not bad to predict the prices. ","metadata":{"persistent_id":"791d326c-2104-41b7-8567-9e50e670ab6f"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}