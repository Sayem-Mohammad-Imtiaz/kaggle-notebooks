{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HITTERS:\n\n# Baseball Data\nDescription\nMajor League Baseball Data from the 1986 and 1987 seasons.\n\n# Usage\nHitters\n\n# Format\n\nA data frame with 322 observations of major league players on the following 20 variables.\n\n* AtBat: Number of times at bat in 1986\n\n* Hits: Number of hits in 1986\n\n* HmRun: Number of home runs in 1986\n\n* Runs: Number of runs in 1986\n\n* RBI: Number of runs batted in in 1986\n\n* Walks: Number of walks in 1986\n\n* Years: Number of years in the major leagues\n\n* CAtBat: Number of times at bat during his career\n\n* CHits: Number of hits during his career\n\n* CHmRun: Number of home runs during his career\n\n* CRuns: Number of runs during his career\n\n* CRBI: Number of runs batted in during his career\n\n* CWalks: Number of walks during his career\n\n* League: A factor with levels A and N indicating player's league at the end of 1986\n\n* Division: A factor with levels E and W indicating player's division at the end of 1986\n\n* PutOuts: Number of put outs in 1986\n\n* Assists: Number of assists in 1986\n\n* Errors: Number of errors in 1986\n\n* Salary: 1987 annual salary on opening day in thousands of dollars\n\n* NewLeague: A factor with levels A and N indicating player's league at the beginning of 1987\n\n# Source\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:13:15.653233Z","iopub.execute_input":"2021-07-14T14:13:15.653691Z","iopub.status.idle":"2021-07-14T14:13:15.669471Z","shell.execute_reply.started":"2021-07-14T14:13:15.653657Z","shell.execute_reply":"2021-07-14T14:13:15.66783Z"}}},{"cell_type":"code","source":"#####################\n# Importing Library:\n#####################\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.impute import KNNImputer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor,ExtraTreesRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate,validation_curve\nfrom sklearn.model_selection import GridSearchCV, cross_validate, RandomizedSearchCV, validation_curve\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:17.265773Z","iopub.execute_input":"2021-07-14T14:16:17.266217Z","iopub.status.idle":"2021-07-14T14:16:17.277467Z","shell.execute_reply.started":"2021-07-14T14:16:17.266181Z","shell.execute_reply":"2021-07-14T14:16:17.276167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########\n# Setting:\n###########\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 50)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.5f' % x)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:19.960772Z","iopub.execute_input":"2021-07-14T14:16:19.961315Z","iopub.status.idle":"2021-07-14T14:16:19.968755Z","shell.execute_reply.started":"2021-07-14T14:16:19.961257Z","shell.execute_reply":"2021-07-14T14:16:19.967861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############################################\n# Some sets of functions for EDA processing:\n############################################\n\n#1\n\ndef check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n    \n#2\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n#3\n\ndef outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n#4\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n    \n#5\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_columns\n    \n#6\n\ndef high_correlated_cols(dataframe, plot=False, corr_th=0.90):\n    corr = dataframe.corr()\n    cor_matrix = corr.abs()\n    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n    if plot:\n        import seaborn as sns\n        import matplotlib.pyplot as plt\n        sns.set(rc={'figure.figsize': (15, 15)})\n        sns.heatmap(corr, cmap=\"RdBu\")\n        plt.show()\n    return drop_list\n\n# 7\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\n# 8\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n\n    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n\n    Parameters\n    ------\n        dataframe: dataframe\n                Değişken isimleri alınmak istenilen dataframe\n        cat_th: int, optional\n                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n        car_th: int, optinal\n                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n\n    Returns\n    ------\n        cat_cols: list\n                Kategorik değişken listesi\n        num_cols: list\n                Numerik değişken listesi\n        cat_but_car: list\n                Kategorik görünümlü kardinal değişken listesi\n\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n\n\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n        num_but_cat cat_cols'un içerisinde.\n        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n\n    \"\"\"\n\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-14T14:16:22.227602Z","iopub.execute_input":"2021-07-14T14:16:22.228227Z","iopub.status.idle":"2021-07-14T14:16:22.261165Z","shell.execute_reply.started":"2021-07-14T14:16:22.228184Z","shell.execute_reply":"2021-07-14T14:16:22.259577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing File:\ndf = pd.read_csv('/kaggle/input/hitters/hitters.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:27.580552Z","iopub.execute_input":"2021-07-14T14:16:27.580983Z","iopub.status.idle":"2021-07-14T14:16:27.610586Z","shell.execute_reply.started":"2021-07-14T14:16:27.580949Z","shell.execute_reply":"2021-07-14T14:16:27.609839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################\n# EDA\n################\n# (322, 20)\n# NewLeague;Division;League data type is \"object\":\n# Pre-processing control-check step : There are 59 NA of salary values:\n\ncheck_df(df)\n\n# The next step is determining of categoric, numeric columns: \ncat_cols, num_cols, cat_but_car =grab_col_names(df)\n\n# Missing value of Salary is filled via KNN imputatin method:\n\ndf_knn = df.select_dtypes(include=[\"float64\",\"int64\"])\nimputer = KNNImputer(n_neighbors=15)\ndf_knn = imputer.fit_transform(df_knn)\ndf_knn = pd.DataFrame(df_knn,columns=num_cols)\ndf[\"Salary\"] = df_knn[\"Salary\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:30.125813Z","iopub.execute_input":"2021-07-14T14:16:30.126364Z","iopub.status.idle":"2021-07-14T14:16:30.183486Z","shell.execute_reply.started":"2021-07-14T14:16:30.126325Z","shell.execute_reply":"2021-07-14T14:16:30.182052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Num_col histogram:\nfor col in num_cols:\n    plt.hist(df[col], align='mid',color = \"skyblue\")\n    plt.title(col)\n    plt.show()\n\n# Some of graphs are right - skewness based on Empirical Analysis so the values can be marked as Outliers\n# Salary < 1500\n# CRBI < 1500\n# CRuns <1500\n# CHits < 3000\n\ndf = df[(df['Salary'] < 1500) & (df['CHits']<3000) & (df[\"CRBI\"]< 1500) & (df[\"CRuns\"]<1500)]","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:36.189561Z","iopub.execute_input":"2021-07-14T14:16:36.190033Z","iopub.status.idle":"2021-07-14T14:16:39.395963Z","shell.execute_reply.started":"2021-07-14T14:16:36.189994Z","shell.execute_reply":"2021-07-14T14:16:39.393712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"########################################\n#New Feature Engineering:\n########################################\n\ndf['AtBat*RBI'] = df['AtBat'] * df['RBI']\ndf['Walks*Years'] = df['Walks'] * df['Years']\ndf['AtBat*RBI'] = df['AtBat'] * df['RBI']\ndf['Walks*Years'] = df['Walks'] * df['Years']\ndf['AtBat/Hits'] = df['AtBat'] / df['Hits']\ndf['AtBat/Runs'] = df['AtBat'] / df['Runs']\ndf['Hits/Runs'] = df['Hits'] / df['Runs']\ndf['HmRun/RBI'] = df['HmRun'] / df['RBI']\ndf['Runs/RBI'] = df['Runs'] / df['RBI']\ndf['Years/CAtBat'] = df['Years'] / df['CAtBat']\ndf['Years/CHits'] = df['Years'] / df['CHits']\ndf['Years/CHmRun'] = df['Years'] / df['CHmRun']\ndf['Years/CRuns'] = df['Years'] / df['CRuns']\ndf['Years/CRBI'] = df['Years'] / df['CRBI']\ndf['CAtBat/CHits'] = df['CAtBat'] / df['CHits']\ndf['CAtBat/CRuns'] = df['CAtBat'] / df['CRuns']\ndf['CAtBat/CRBI'] = df['CAtBat'] / df['CRBI']\ndf['CAtBat/CWalks'] = df['CAtBat'] / df['CWalks']\ndf['CHits/CRuns'] = df['CHits'] / df['CRuns']\ndf['CHits/CRBI'] = df['CHits'] / df['CRBI']\ndf['CHits/CWalks'] = df['CHits'] / df['CWalks']\ndf['CHmRun/CRuns'] = df['CHmRun'] / df['CRuns']\ndf['CHmRun/CRBI'] = df['CHmRun'] / df['CRBI']\ndf['CHmRun/CWalks'] = df['CHmRun'] / df['CWalks']\ndf['CRuns/CRBI'] = df['CRuns'] / df['CRBI']\ndf['CRuns/CWalks'] = df['CRuns'] / df['CWalks']\ndf['CHmRun/CRBI'] = df['CHmRun'] / df['CRBI']\ndf.replace([np.inf, -np.inf], 0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:48.772974Z","iopub.execute_input":"2021-07-14T14:16:48.773399Z","iopub.status.idle":"2021-07-14T14:16:48.819632Z","shell.execute_reply.started":"2021-07-14T14:16:48.773359Z","shell.execute_reply":"2021-07-14T14:16:48.818505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determining numeric and categorical columns:\ncat_cols, num_cols, cat_but_car =grab_col_names(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:53.247671Z","iopub.execute_input":"2021-07-14T14:16:53.248076Z","iopub.status.idle":"2021-07-14T14:16:53.281765Z","shell.execute_reply.started":"2021-07-14T14:16:53.24804Z","shell.execute_reply":"2021-07-14T14:16:53.280684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Determing Outliers \n\noutlier_list= []\nfor col in num_cols:\n    if check_outlier(df, col) == True:\n        outlier_list.append(col)\n        print(col, check_outlier(df, col))\n\n# Check step:\n\noutlier_list\n\n# Replace thresholds for outlier values:\nfor col in num_cols:\n    replace_with_thresholds(df,col)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:16:55.673749Z","iopub.execute_input":"2021-07-14T14:16:55.67414Z","iopub.status.idle":"2021-07-14T14:16:56.118554Z","shell.execute_reply.started":"2021-07-14T14:16:55.674108Z","shell.execute_reply":"2021-07-14T14:16:56.116828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for Missing Values via the function:\n\nmissing_values_table(df)\n\n#               n_miss   ratio\n#HmRun/RBI           2 0.65000\n#CHmRun/CRBI         1 0.33000\n#CHmRun/CWalks       1 0.33000\n\n# A few rows are dropped.\n\ndf.dropna(subset=[\"HmRun/RBI\",\"CHmRun/CWalks\",\"CHmRun/CRBI\"], axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:01.689377Z","iopub.execute_input":"2021-07-14T14:17:01.689812Z","iopub.status.idle":"2021-07-14T14:17:01.714702Z","shell.execute_reply.started":"2021-07-14T14:17:01.689775Z","shell.execute_reply":"2021-07-14T14:17:01.71342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Controlling whether or not there is multi correlated with features:\ndrop_list = high_correlated_cols(df,corr_th=0.80)\n\n# Let's control:\ndrop_list\n\n# Deleted:\ndf.drop(drop_list, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:05.836178Z","iopub.execute_input":"2021-07-14T14:17:05.836603Z","iopub.status.idle":"2021-07-14T14:17:05.855851Z","shell.execute_reply.started":"2021-07-14T14:17:05.836567Z","shell.execute_reply":"2021-07-14T14:17:05.854524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Label encoding ###\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float] and df[col].nunique() == 2]\n# ['League', 'Division', 'NewLeague']\nfor col in binary_cols:\n    df = label_encoder(df, col)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:09.107153Z","iopub.execute_input":"2021-07-14T14:17:09.107599Z","iopub.status.idle":"2021-07-14T14:17:09.120055Z","shell.execute_reply.started":"2021-07-14T14:17:09.107558Z","shell.execute_reply":"2021-07-14T14:17:09.118753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Robust Scale:\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\nnum_cols.remove(\"Salary\") #Targeted feature exlude from num_cols\n\nfor col in num_cols:\n    transformer = RobustScaler().fit(df[[col]])\n    df[col] = transformer.transform(df[[col]])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:11.426676Z","iopub.execute_input":"2021-07-14T14:17:11.427166Z","iopub.status.idle":"2021-07-14T14:17:11.547313Z","shell.execute_reply.started":"2021-07-14T14:17:11.427121Z","shell.execute_reply":"2021-07-14T14:17:11.545856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's checking the DataFrame\ndf.shape\ndf.info()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:14.334099Z","iopub.execute_input":"2021-07-14T14:17:14.33452Z","iopub.status.idle":"2021-07-14T14:17:14.371402Z","shell.execute_reply.started":"2021-07-14T14:17:14.334486Z","shell.execute_reply":"2021-07-14T14:17:14.37007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The result of EDA:\ny = df[\"Salary\"]\nX = df.drop([\"Salary\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:18.661873Z","iopub.execute_input":"2021-07-14T14:17:18.662321Z","iopub.status.idle":"2021-07-14T14:17:18.66967Z","shell.execute_reply.started":"2021-07-14T14:17:18.662283Z","shell.execute_reply":"2021-07-14T14:17:18.668235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"######################################################\n# Automated Hyperparameter Optimization\n######################################################\n\n# Defining parameters:\n\ncart_params = {'max_depth': range(1, 20),\n                \"min_samples_split\": range(2, 30)}\n\nrf_params = {\"max_depth\": [5, 8, 15, None],\n                \"max_features\": [5, 7, \"auto\"],\n                \"min_samples_split\": [8, 15, 20],\n                 \"n_estimators\": [200, 500]}\n\n\nlightgbm_params = {\"learning_rate\": [0.001, 0.01, 0.1],\n                    \"n_estimators\": [500, 1000],\n                    \"colsample_bytree\": [0.1, 0.3, 0.7, 1]}\n\n\ncatboost_params = {\"iterations\": [500,1000],\n                     \"learning_rate\": [0.01, 0.1],\n                     \"depth\": [3, 6]}\n\nextraTrees_params = {\n        'n_estimators': [500, 1000],\n        'max_depth': [2, 16, 50],\n        'min_samples_split': [2, 10],\n        'min_samples_leaf': [1, 2],\n        'max_features': ['auto', 'sqrt', 'log2'],\n        'bootstrap': [True, False],\n        'warm_start': [True, False],\n     }\n\n\n\nregressors = [(\"CART\", DecisionTreeRegressor(), cart_params),\n                (\"RF\", RandomForestRegressor(), rf_params),\n                ('LightGBM', LGBMRegressor(), lightgbm_params),\n                ('Catboost',CatBoostRegressor(verbose=False),catboost_params),\n                ('ExtraTrees', ExtraTreesRegressor(), extraTrees_params),\n                ]\n#################################################################################################\n\nbest_models = {}\n\nfor name, regressor, params in regressors:\n    print(f\"########## {name} ##########\")\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n\n    gs_best = GridSearchCV(regressor, params, cv=3, n_jobs=-1, verbose=False).fit(X, y)\n\n    # After hyper parameters tunned\n    final_model = regressor.set_params(**gs_best.best_params_)\n    rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE (After): {round(rmse, 4)} ({name}) \")\n\n    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n\n    best_models[name] = final_model\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T14:17:21.251301Z","iopub.execute_input":"2021-07-14T14:17:21.251765Z","iopub.status.idle":"2021-07-14T14:27:48.540352Z","shell.execute_reply.started":"2021-07-14T14:17:21.251725Z","shell.execute_reply":"2021-07-14T14:27:48.539122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Results:\n\n*** ########## CART ##########**\n* RMSE: 287.532 (CART) \n* RMSE (After): 248.1274 (CART) \n* CART best params: {'max_depth': 5, 'min_samples_split': 17}\n\n* ########## RF ##########\n* RMSE: 193.4727 (RF) \n* RMSE (After): 190.6059 (RF) \n* RF best params: {'max_depth': 8, 'max_features': 7, 'min_samples_split': 8, 'n_estimators': 200}\n\n*** ########## LightGBM ##########**\n* RMSE: 196.0429 (LightGBM) \n* RMSE (After): 188.5556 (LightGBM) \n* LightGBM best params: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'n_estimators': 500}\n\n*** ########## Catboost ##########**\n* RMSE: 185.9416 (Catboost) \n* RMSE (After): 186.1933 (Catboost) \n* Catboost best params: {'depth': 6, 'iterations': 1000, 'learning_rate': 0.01}\n\n*** ########## ExtraTrees ##########**\n* RMSE: 182.8924 (ExtraTrees) \n* RMSE (After): 178.7743 (ExtraTrees) \n* ExtraTrees best params: {'bootstrap': False, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 1000, 'warm_start': True}","metadata":{}}]}