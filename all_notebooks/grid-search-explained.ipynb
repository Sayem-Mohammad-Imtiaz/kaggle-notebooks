{"cells":[{"metadata":{},"cell_type":"markdown","source":"A model `hyperparameter` is a characteristic of a model that is external to the model and whose value cannot be estimated from data. The value of the `hyperparameter` has to be set before the learning process begins. For example, `c` in `SVM`, `k` in `KNN`, the number of hidden layers in Neural Networks.\n\nIn contrast, a parameter is an internal characteristic of the model and its value can be estimated from data. Example, `beta coefficients of linear/logistic regression` or `support vector`s in `SVM`."},{"metadata":{},"cell_type":"markdown","source":">Grid-search is used to find the optimal hyperparameters of a model which results in the most ‘accurate’ predictions."},{"metadata":{},"cell_type":"markdown","source":"### Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.model_selection import GridSearchCV\nnp.set_printoptions(precision=2)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import data\ndata = pd.read_csv('/kaggle/input/breast-cancer-csv/breastCancer.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each row in the dataset have one of two possible classes: benign (represented by 2) and malignant (represented by 4). Also, there are 10 attributes in this dataset (shown above) which will be used for prediction."},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning\nClean the data and rename the class values as 0/1 for model building (where 1 represents a malignant case). Also, let’s observe the distribution of the class."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['id'],axis=1) #Drop 1st column\ndata = data[data['bare_nucleoli'] != '?'] #Remove rows with missing data\ndata['class'] = np.where(data['class'] ==2,0,1) #Change the Class representation\ndata['class'].value_counts() #Class distribution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 444 benign and 239 malignant cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data into attributes and class\nX = data.drop(['class'],axis=1)\ny = data['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#perform training and test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dummy Classifier\n`DummyClassifier` is a classifier that makes predictions using simple rules.This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dummy Classifier\n# clf=DummyClassifier(strategy=\"most_frequent\")\n# clf.fit(X_train,y_train)\nclf = DummyClassifier(strategy= 'most_frequent',random_state=42).fit(X_train,y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Distribution of y test\nprint('y actual : \\n' +  str(y_test.value_counts()))\n#Distribution of y predicted\nprint('y predicted : \\n' + str(pd.Series(y_pred).value_counts()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate the evaluation metrics of model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Evaluation metrics \nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred,labels=np.unique(y_pred))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Dummy Classifier Confusion matrix\nprint('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function for confusion matrix plot"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Function to plot intuitive confusion matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - DummyClassifier')\na = plt.gcf()\na.set_size_inches(8,4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression model with default parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic regression\nclf = LogisticRegression(solver=\"lbfgs\",random_state=42).fit(X_train,y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Evaluation metrics \nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression Classifier Confusion matrix\nprint('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - LogisticRegression')\na = plt.gcf()\na.set_size_inches(8,4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression + Grid Search\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grid Search\nclf = LogisticRegression(solver='liblinear',random_state=42)\ngrid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\ngrid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall',cv=5,iid=True)\ngrid_clf_acc.fit(X_train, y_train)\n\n#Predict values based on new parameters\ny_pred_acc = grid_clf_acc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Model Evaluation metrics \nprint('Accuracy Score : ' + str(accuracy_score(y_test,y_pred_acc)))\nprint('Precision Score : ' + str(precision_score(y_test,y_pred_acc)))\nprint('Recall Score : ' + str(recall_score(y_test,y_pred_acc)))\nprint('F1 Score : ' + str(f1_score(y_test,y_pred_acc)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression (Grid Search) Confusion matrix\nconfusion_matrix(y_test,y_pred_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - Logistic Regression (Grid Search)')\na = plt.gcf()\na.set_size_inches(8,4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The hyperparameters we tuned are:\n- Penalty: l1 or l2 which species the norm used in the penalization.\n- C: Inverse of regularization strength- smaller values of C specify stronger regularization."},{"metadata":{},"cell_type":"markdown","source":"## HistGradientBoostingClassifier\n`HistGradientBoostingClassifier` is Histogram-based Gradient Boosting ClassificationTree."},{"metadata":{"trusted":true},"cell_type":"code","source":"# explicitly require this experimental feature\nfrom sklearn.experimental import enable_hist_gradient_boosting  # noqa\n# now you can import normally from ensemble\nfrom sklearn.ensemble import HistGradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = HistGradientBoostingClassifier(learning_rate=0.005,random_state=42).fit(X_train, y_train)\ny_pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression Classifier Confusion matrix\nprint('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnf_matrix_hgbc = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix_hgbc, classes=class_names,\n                      title='Confusion matrix - HistGradientBoostingClassifier')\na = plt.gcf()\na.set_size_inches(8,4)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}