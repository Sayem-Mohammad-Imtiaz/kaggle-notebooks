{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Implement polynomial regression using the Ridge Regression method available in scikit-learn, see sklearn.linear model.Ridge() and look at the behavior of the solution when changing the parameter alpha (ùõº).\n\nThis notebook focuses on analyzing multiple ridge regression models over the \"Coal Electric Power Sector CO2 Emissions\" section of the \"Carbon dioxide emissions from electricity generation\" table available at https://www.eia.gov/electricity/data.php#elecenv. It will focus mostly on the technical aspects of creating a ridge regression model, exploring the effects of different polynomials and alphas and plotting the results, while evaluating their accuracy in predicting monthly trends on a smaller test sample."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import necessary libraries\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we will load the dataset and separate the data we wish to manipulate: monthly emission estimates from coal energy production."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = pd.read_csv('/kaggle/input/co2emissions/MER_T12_06.csv')\n\n# Coal Electric Power Sector CO2 Emissions\nds_1 = ds[ds['Column_Order']==1]\n# Remove yearly values\nds_1 = ds_1[~ds_1.index.isin(ds_1[12::13].index)].sort_values(['YYYYMM'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the starting data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.to_datetime(ds_1['YYYYMM'], format='%Y%m')\ny = ds_1['Value'].astype('float64')\n\nplt.figure(figsize=(25, 10))\nplt.xlabel('Date')\nplt.ylabel('Million Metric Tons of Carbon Dioxide')\n\nplt.scatter(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will normalize the dates and emissions while retaining the ability to invert the transform for plotting.\nWe will also separate the data into a training and a test section, to evaluate the regressions' accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_scaler = StandardScaler()\ny_scaler = StandardScaler()\n\nx_scaler.fit(x.values.reshape(-1, 1))\ny_scaler.fit(y.values.reshape(-1, 1))\n\nX = x_scaler.transform(x.values.reshape(-1, 1))\nY = y_scaler.transform(y.values.reshape(-1, 1))\n\n\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\nX_train = x_scaler.transform(np.array(x_train).reshape(-1, 1))\nY_train = y_scaler.transform(np.array(y_train).reshape(-1, 1))\nX_test = x_scaler.transform(np.array(x_test).reshape(-1, 1))\nY_test = y_scaler.transform(np.array(y_test).reshape(-1, 1))\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(X_test.shape)\nprint(Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will plot the effects on a varying number of features into our polynomial regression. Note that alpha is set to 0 and we are only evaluating the basic regression. \n\nThe resulting difference may be more or less obvious depending on the training sample selected, but we can see a stagnation or even a decrease in the model score after the polynomial degree rises over a certain amount, due to overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(25, 10))\nplt.xlabel('Date')\nplt.ylabel('Million Metric Tons of Carbon Dioxide')\n\n\nplt.scatter(x, y, alpha=0.3)\n\nfor deg in range(1,18):\n    model = make_pipeline(PolynomialFeatures(deg), Ridge(alpha = 0))\n    model.fit(X_train,Y_train)\n    \n    r_test = mean_squared_error(Y_test, model.predict(X_test))\n    print('{:13f}: {}, {}'.format(deg, r_test, model.score(X_test, Y_test)))\n    \n    plt.plot(x,y_scaler.inverse_transform(model.predict(X)),label = 'deg={}'.format(deg))\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now evaluate the effects of different alpha values on a ridge regression from a 6th degree polynomial.\n\nDepending on the original accuracy, the polynomial degree and the logarithmic scale chosen, we should see that while lower values of alpha don't affect the model score very much, and some intermediate values may improve it, a value of alpha that is too large will start deviating the regression from the original data until, for values of alpha close to +Inf, the coefficient will near 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplt.figure(figsize=(25, 10))\nplt.xlabel('Date')\nplt.ylabel('Million Metric Tons of Carbon Dioxide')\n\n# alpha=transparency\nplt.scatter(x, y, alpha=0.3)\n\n# This is the alpha we're actually interested in.\nfor alpha in np.logspace(-5, 5, 11):\n    model = make_pipeline(PolynomialFeatures(6), Ridge(alpha = alpha))\n    model.fit(X_train,Y_train)\n    \n    r_test = mean_squared_error(Y_test, model.predict(X_test))\n    print('{:13f}: {}, {}'.format(alpha, r_test, model.score(X_test, Y_test)))\n    \n    plt.plot(x,y_scaler.inverse_transform(model.predict(X)),label = 'alpha={}'.format(alpha))\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the other sources of CO2 emissions for energy production, we can see that while some are following an upward trend, the vast majority of total CO2 emissions, still dominated by coal plants, has been on a significant decline over the last 10 years.\n\nIt is worth noting that the ridge regression model following some of the better performing parameters of the previous sections is able to correctly extrapolate the overall trend on data points, such as natural gas emissions, highly dependent on seasonal demand."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 10))\nplt.xlabel('Date')\nplt.ylabel('Million Metric Tons of Carbon Dioxide')\n\nfor i in range(1,10):\n    ds_2 = ds[ds['Column_Order']==i]\n    # Remove yearly values\n    ds_2 = ds_2[~ds_2.index.isin(ds_2[12::13].index)].sort_values(['YYYYMM'])\n    ds_2 = ds_2[ds_2['Value'] != 'Not Available']\n    x2 = pd.to_datetime(ds_2['YYYYMM'], format='%Y%m')\n    y2 = ds_2['Value'].astype('float64')\n    plt.scatter(x2,y2, s=20, label=ds_2['Description'].iloc[0], alpha=0.30)\n    \n    x2scaler = StandardScaler()\n    y2scaler = StandardScaler()\n    \n    X2 = x2scaler.fit_transform(x2.values.reshape(-1, 1))\n    Y2 = y2scaler.fit_transform(y2.values.reshape(-1, 1))\n    \n    model = make_pipeline(PolynomialFeatures(6), Ridge(alpha = 0.001))\n    model.fit(X2,Y2)\n    \n    plt.plot(x2,y2scaler.inverse_transform(model.predict(X2)))\n\nplt.legend()\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}