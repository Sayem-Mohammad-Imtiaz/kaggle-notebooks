{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Basics 3 - \"Unsupervised Beginner Mode\"\nWe want to group articles without using the given category.. we will use the category only to ensure that our model is coherent. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/bbc-fulltext-and-category/bbc-text.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dataset.text[0] #The data was already prepared and stop words were removed :(","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorize\nhere we build a Sparce Matrix of the vectors in the database "},{"metadata":{"trusted":true},"cell_type":"code","source":"import re, string\nvectorizer = TfidfVectorizer(ngram_range=(1,2),\n               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1, stop_words='english')\nX = vectorizer.fit_transform(dataset.text)\nword_vects = X.toarray()\nword_vects.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dimentionality Reduction and Clustering\nWe will use UMAP to reduce the dimentionality after that we will use K-Means to separate out the clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"import umap\n\nreducer = umap.UMAP(random_state=70,metric='cosine')\nembedding = reducer.fit_transform(word_vects)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defined Clusters\nAs you can see we have well defined clusters when using UMAP (cosine metric)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(embedding[:,0], embedding[:,1])\nplt.title(\"UMAP dimentionality Reduction\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's give K-Means a go... "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nclustering = KMeans(n_clusters=6, init='k-means++').fit(embedding)\n\ndataset['cluster'] = clustering.labels_\ndataset['vectX'] = embedding[:,0]\ndataset['vectY'] = embedding[:,1]\ndataset.cluster.unique()\nplt.figure(num=None, figsize=(12, 6), dpi=80, facecolor='w', edgecolor='k')\nfor x in dataset.cluster.unique():\n    vctsX = dataset.loc[dataset.cluster == x].vectX\n    vctsY = dataset.loc[dataset.cluster == x].vectY\n    c = dataset.loc[dataset.cluster == x].cluster\n    plt.title(\"K-means Clustering\")\n    plt.scatter(vctsX, vctsY, c=np.random.rand(3,), label=x)\n    plt.legend(loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results and Conclusion\nWe can compare the clustering with the labels.\nIn a real life scenario we might use human assistance to read some examples and label the clusters accordingly."},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster2cat = {}\n\nfor x in dataset.cluster.unique():\n    cat = {}\n    ds = dataset.loc[dataset.cluster == x]\n    for y in ds.category.unique():\n        cat[y] = ds.loc[ds.category == y].count()['category']\n    print(x, 'Shows labeled data of:', cat)\n    i = 0\n    # Get the most frequent label\n    selected = list(cat.values()).index(max(cat.values()))\n    cluster2cat[x] = list(cat.keys())[selected]\nprint(\"Mapping is:\",cluster2cat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\nWe can see that it clusters quite well!! :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['cluster_class'] = dataset['cluster'].map(cluster2cat)\nconfusion_matrix = pd.crosstab(dataset.category, dataset.cluster_class, rownames=['Actual'], colnames=['Predicted'])\naccuracy = confusion_matrix.values.diagonal().sum()/(confusion_matrix.values.sum())\nprint(\"Accuracy: %.2f\"%(100*accuracy)+\"%\")\nconfusion_matrix.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}