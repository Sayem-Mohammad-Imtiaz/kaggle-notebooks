{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Stroke Pre-Processing: MICE & Encoding**","metadata":{}},{"cell_type":"markdown","source":"**Hello and welcome**.  \n\n**This is part 1 to a 3-kernel project on Stroke Prediction.**\n\n  \n**Part 1 (which is this one) is Preprocessing: Data Cleaning, Encoding and MICE for missing values**  \n  \n**Part 2 is EDA (including UMAP and PCA) and Random Oversampling**  \nLink: **https://www.kaggle.com/mahmoudlimam/stroke-eda-umap-resampling**\n\n  \n**Part 3 is Detailed Feature extraction and Selection, and model evaluation**  \nLink: **https://www.kaggle.com/mahmoudlimam/stroke-pca-ica-lda-kmeans-dbscan-prediction** \n\nI didn't include a hyperparameter tuning section as Feature Engineering in an F1_Score of 1 with a somewhat deep Random Forest.","metadata":{}},{"cell_type":"markdown","source":"بسم الله","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A bit of Exploration","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(\"id\",axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Unique Values per Variable\")\nfor col in data.columns:\n    un=data[col].unique()\n    print(\"\\n\\nUnique Values in {}:\\n{}\".format(col,un))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"markdown","source":"If very few people have a gender value of \"Other\" then it might be better to drop them or turn them into NaN and impute them.  \nSame for people with an \"Unknown\" smoking status, as unknown is the very definition of a missing value.","metadata":{}},{"cell_type":"code","source":"(data[\"gender\"]==\"Other\").sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll just drop that one.","metadata":{}},{"cell_type":"code","source":"data[data[\"gender\"]==\"Other\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data.drop(3116,axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have a missing row at 3116:","metadata":{}},{"cell_type":"code","source":"data.iloc[3114:3118,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index=[i for i in range(data.shape[0])]\ndata.index=index\ndata.iloc[3114:3118,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding","metadata":{}},{"cell_type":"code","source":"from category_encoders.target_encoder import TargetEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc=TargetEncoder()\nto_encode=\"work_type\"\nenc.fit(X=data[to_encode],y=data[\"stroke\"])\nencoded = enc.transform(data[to_encode])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"work_type\"] = encoded[\"work_type\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[[\"ever_married\",\"Residence_type\",\"gender\"]]=pd.get_dummies(data[[\"ever_married\",\"Residence_type\",\"gender\"]],drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dealing with Missing Values","metadata":{}},{"cell_type":"code","source":"print(\"Proportions of 'smoking' categories:\")\ndata[\"smoking_status\"].value_counts()/data.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's about 30%.  \nQuite a lot.  \n\"Unknown\" is the very definition of \"missing value\"/NaN.  \nThus, I'll turn it into NaNs and impute it.  ","metadata":{}},{"cell_type":"markdown","source":"Since people who've never smoked are probably less likely (on average) to have a stroke than those who did smoke in the past, which in turn are less likely to have a stroke than those who currently smoke, we can say there is some inherent order to these three categories.  \nThus, it would be meaningful to encode them with 0, 1 & 2.  ","metadata":{}},{"cell_type":"code","source":"smoking_mapper={\"never smoked\":0,\"formerly smoked\":1,\"smokes\":2,\"Unknown\":np.nan}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(data.shape[0]):\n    status=data[\"smoking_status\"][i]\n    data[\"smoking_status\"][i]=smoking_mapper[status]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"smoking_status\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Multiple Imputation by Chained Equations (or simply MICE)","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator=RandomForestRegressor(max_depth=8)\nmice = IterativeImputer(estimator=estimator,random_state=11,skip_complete=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impdata=mice.fit_transform(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impdata=pd.DataFrame(impdata,columns=data.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impdata.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impdata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(impdata.shape[0]):\n    if impdata.loc[i,\"smoking_status\"]<0.5:\n        impdata.loc[i,\"smoking_status\"]=0\n    elif impdata.loc[i,\"smoking_status\"] <1.5:\n        impdata.loc[i,\"smoking_status\"]=1\n    else:\n        impdata.loc[i,\"smoking_status\"]=2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.style as style\nstyle.use('seaborn-darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(16,10))\nfig.suptitle(\"Effect of MICE on Distributions\\n\",fontsize=25)\nsns.histplot(x=data[\"bmi\"],ax=axes[0,0],color=\"mediumspringgreen\")\naxes[0,0].set_title(\"BMI before MICE\")\naxes[0,0].set_xlabel(None)\nsns.histplot(x=impdata[\"bmi\"],ax=axes[0,1],color=\"mediumspringgreen\")\naxes[0,1].set_title(\"BMI after MICE\")\naxes[0,1].set_xlabel(None)\nsns.countplot(x=data[\"smoking_status\"],ax=axes[1,0],palette=\"cool\")\naxes[1,0].set_title(\"Smoking Status before MICE\")\naxes[1,0].set_xlabel(None)\nsns.countplot(x=impdata[\"smoking_status\"],ax=axes[1,1],palette=\"cool\")\naxes[1,1].set_title(\"Smoking Status after MICE\")\naxes[1,1].set_xlabel(None)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nrf=RandomForestClassifier(n_jobs=-1,max_depth=7)\nx=impdata.drop('stroke',axis=1)\ny=impdata[\"stroke\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2, random_state=2)\nrf.fit(xtrain,ytrain)\ny_pred_tr=rf.predict(xtrain)\ny_pred_ts=rf.predict(xtest)\ntrain_mat=classification_report(ytrain,y_pred_tr)\ntest_mat=classification_report(ytest,y_pred_ts)\nprint(\"Baseline Random Forest Results:\")\nprint(\"Training Classification_Report:\\n{}\".format(train_mat))\nprint(\"Testing Classification_Report:\\n{}\".format(test_mat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nThe model scored a very low recall and 1 in precision for the stroke class on the training data.  \nThis shows that the dataset is seriously imbalanced.  \nThe results on the testing data are even worse: the model is classifying everything as without stroke.  ","metadata":{}},{"cell_type":"markdown","source":"**What now?**  \n**Resampling**  .\nBut some EDA first.  \nThen resampling. Random sampling to be exact.  \nMake sure you check it out in part 2 here: https://www.kaggle.com/mahmoudlimam/stroke-eda-random-sampling  ","metadata":{}},{"cell_type":"markdown","source":"الحمد لله الذي بنعمته تتم الصالحات","metadata":{}}]}