{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/mobile-price-classification/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',50)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Since the count of target variables are equal, we don't do Stratified splits"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.price_range.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## taking equal columns in 2 dataset to plot swarmplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plot_1 = df_train[df_train.columns[0:10]].copy()\ndf_plot_2 = df_train[df_train.columns[10:21]].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_plot_2.iloc[:,-1:]\ndf_plot_2.drop('price_range',axis=1,inplace=True)\ndf_plot_1.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plot_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plot_2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plot_1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standarzation for features in the dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_std_1 = (df_plot_1 - df_plot_1.mean()) / (df_plot_1.std())              # standardization\ndata_std_2 = (df_plot_2 - df_plot_2.mean()) / (df_plot_2.std())              # standardization\n\ndata_std_1['price_range'] = y\ndata_std_2['price_range'] = y\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_std_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_std_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pairplot for all the features in the dataset for better understanding of how all features line up for for different price_ranges"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.pairplot(df_train, hue= 'price_range', height=2)\ng.map_lower(sns.kdeplot, levels=4, color=\".2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## After Analysing the Pairplot, plotting only columns with clear sepration of different target classes(price_range)"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.pairplot(data=df_train, hue= 'price_range', height=2.5,aspect=.5, y_vars = ['ram'],x_vars=['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n       'touch_screen', 'wifi'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"dark\", palette=\"bright\")\ndata_1 = pd.melt(data_std_2,id_vars=\"price_range\",\n                    var_name=\"features\",\n                    value_name='value')\ndata_1\nplt.figure(figsize=(12,12))\nsns.swarmplot(x=\"features\", y=\"value\", hue=\"price_range\", data=data_1)\n\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"dark\", palette=\"bright\")\ndata_2 = pd.melt(data_std_1,id_vars=\"price_range\",\n                    var_name=\"features\",\n                    value_name='value')\nplt.figure(figsize=(12,12))\nsns.swarmplot(x=\"features\", y=\"value\", hue=\"price_range\", data=data_2)\n\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As visible from Swarmplot, RAM is indeed very important feature for pricing "},{"metadata":{},"cell_type":"markdown","source":"## Plotting heatmap of Correlation between features"},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(df_train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some more visualization of Battery power, RAM, px_height and width"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.subplots(figsize=(18,12))\nsns.set(rc={'figure.figsize':(18,12)})\n\nsns.displot(df_train, x=\"battery_power\",hue=\"price_range\", kind=\"kde\",col='price_range')\nsns.displot(df_train, x=\"ram\",hue=\"price_range\", kind=\"kde\",col='price_range')\nsns.displot(df_train, x=\"px_width\",hue=\"price_range\", kind=\"kde\",col='price_range')\nsns.displot(df_train, x=\"px_height\",hue=\"price_range\", kind=\"kde\",col='price_range')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking out cross validation score with LogisticRegression,DecisionTree,Randomforest and Support Vector Classifier for Multiclass classification using pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report,confusion_matrix,f1_score\nfrom sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_pipeline = Pipeline(steps = [('scale',StandardScaler()),('DT',DecisionTreeClassifier(random_state=42))])\nRF_pipeline = Pipeline(steps = [('scale',StandardScaler()),('DT',RandomForestClassifier(random_state=42))])\nSVM_pipeline = Pipeline(steps = [('scale',StandardScaler()),('DT',SVC(random_state=42))])\nLR_pipeline = Pipeline(steps = [('scale',StandardScaler()),('DT',LogisticRegression(random_state=42))])\n\nX = df_train.iloc[:,:-1]\nY = df_train.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_CROSS_VAL = cross_val_score(DT_pipeline,X,Y,cv=10)\nRF_CROSS_VAL = cross_val_score(RF_pipeline,X,Y,cv=10)\nSVM_CROSS_VAL = cross_val_score(SVM_pipeline,X,Y,cv=10)\nLR_CROSS_VAL = cross_val_score(LR_pipeline,X,Y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_CROSS_VAL, SVM_CROSS_VAL, LR_CROSS_VAL, DT_CROSS_VAL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\nfig = make_subplots(rows=4, cols=1,shared_xaxes=True,subplot_titles=('Decision Tree Cross Val Scores',\n                                                                     'RandomForest Cross Val Scores',\n                                                                    'SVM Cross Val Scores','Logistic Regression Cross Val Scores'))\n\nfig.add_trace(\n    go.Scatter(x=list(range(0,len(DT_CROSS_VAL))),y=DT_CROSS_VAL,name='Decision Tree'),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Scatter(x=list(range(0,len(DT_CROSS_VAL))),y=RF_CROSS_VAL,name='RandomForest'),\n    row=2, col=1\n)\nfig.add_trace(\n    go.Scatter(x=list(range(0,len(DT_CROSS_VAL))),y=SVM_CROSS_VAL,name='SVM'),\n    row=3, col=1\n)\nfig.add_trace(\n    go.Scatter(x=list(range(0,len(DT_CROSS_VAL))),y=LR_CROSS_VAL,name='Logistic Regression'),\n    row=4, col=1\n)\n\nfig.update_layout(height=700, width=900, title_text=\"Different Model 5 Fold Cross Validation\")\nfig.update_yaxes(title_text=\"F1 Score\")\nfig.update_xaxes(title_text=\"Fold #\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## confusion matrix for Logistic regression (Multiclass)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\nf,ax = plt.subplots(figsize=(18, 18))\ny_train_pred = cross_val_predict(LR_pipeline, X, Y, cv=3)\nconf_mx = confusion_matrix(Y, y_train_pred)\nsns.heatmap(conf_mx, annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## confusion matrix for RandomForest (Multiclass)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\nf,ax = plt.subplots(figsize=(18, 18))\ny_train_pred = cross_val_predict(RF_pipeline, X, Y, cv=3)\nconf_mx = confusion_matrix(Y, y_train_pred)\nsns.heatmap(conf_mx, annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_pipeline.fit(X_train,y_train)\nRF_pipeline.fit(X_train,y_train)\nSVM_pipeline.fit(X_train,y_train)\nLR_pipeline.fit(X_train,y_train)\n\n\nDT_PRED   = DT_pipeline.predict(X_test)\nRF_PRED   =RF_pipeline.predict(X_test)\nSVM_PRED  = SVM_pipeline.predict(X_test)\nLR_PRED   = LR_pipeline.predict(X_test)\n\nDT_CM  = confusion_matrix(y_test,DT_PRED )\nRF_CM  = confusion_matrix(y_test,RF_PRED )\nSVM_CM = confusion_matrix(y_test,SVM_PRED)\nLR_CM  = confusion_matrix(y_test,LR_PRED )\n\nDT_F1  = f1_score(y_test,DT_PRED,average='weighted' )\nRF_F1  = f1_score(y_test,RF_PRED,average='weighted' )\nSVM_F1 = f1_score(y_test,SVM_PRED,average='weighted')\nLR_F1  = f1_score(y_test,LR_PRED,average='weighted' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## weighted f1 score on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Bar(x=['Decision Tree','Random Forest','SVM','Logistic Regression'],y=[DT_F1,RF_F1,SVM_F1,LR_F1]))\nfig.update_layout(title='F1 Score Of Our Model On Original Data',xaxis_title='Model',yaxis_title='F1 Score')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Important features using RandomForest"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Bar(x=X_train.columns,y=RF_pipeline['DT'].feature_importances_))\nfig.update_layout(title='The Importance Of The Original Attributes On Our Prediction',xaxis_title='Model',yaxis_title='F1 Score')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nclf_rf = RandomForestClassifier() \nrfecv = RFECV(estimator=clf_rf, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\nrfecv = rfecv.fit(X_train, y_train)\n\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', X_train.columns[rfecv.support_])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using GridSearchCV for logistic regression since f1 scoring was maximum "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find best hyperparameters (roc_auc)\nfrom sklearn.model_selection import GridSearchCV\nlog_clf = LogisticRegression(random_state = 42)\nparam_grid = {'class_weight' : ['balanced', None], \n                'penalty' : ['l2','l1'],  \n                'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\ngrid = GridSearchCV(estimator = log_clf, param_grid = param_grid , scoring = 'roc_auc', verbose = 1, n_jobs = -1)\n\ngrid.fit(X,Y)\n\nprint(\"Best Score:\" + str(grid.best_score_))\nprint(\"Best Parameters: \" + str(grid.best_params_))\n\nbest_parameters = grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_scaled =scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_clf = LogisticRegression(**best_parameters)\nlog_clf.fit(X_scaled,Y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred   = log_clf.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_data = pd.read_csv('/kaggle/input/mobile-price-classification/test.csv')\nx_test_data.drop('id',axis=1,inplace=True)\nscaling_test = StandardScaler()\nx_test_scaled =scaling_test.fit_transform(x_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction= log_clf.predict(x_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(y_prediction, return_counts=True)\ndict(zip(unique, counts))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}