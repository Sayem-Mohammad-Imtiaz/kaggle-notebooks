{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport os\nimport gc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_fer = pd.read_csv('../input/fer2013/fer2013.csv')\ndata_fer.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\nidx_to_emotion_fer = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_fer_train, y_fer_train = np.rollaxis(data_fer[data_fer.Usage == \"Training\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_train = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_train]).reshape((-1, 48, 48))\ny_fer_train = y_fer_train.astype('int8')\n\nX_fer_test_public, y_fer_test_public = np.rollaxis(data_fer[data_fer.Usage == \"PublicTest\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_test_public = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_test_public]).reshape((-1, 48, 48))\ny_fer_test_public = y_fer_test_public.astype('int8')\n\nX_fer_test_private, y_fer_test_private = np.rollaxis(data_fer[data_fer.Usage == \"PrivateTest\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_test_private = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_test_private]).reshape((-1, 48, 48))\ny_fer_test_private = y_fer_test_private.astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"X_fer_train shape: {X_fer_train.shape}; y_fer_train shape: {y_fer_train.shape}\")\nprint(f\"X_fer_test_public shape: {X_fer_test_public.shape}; y_fer_test_public shape: {y_fer_test_public.shape}\")\nprint(f\"X_fer_test_private shape: {X_fer_test_private.shape}; y_fer_test_private shape: {y_fer_test_private.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_fer_train[10], interpolation='none', cmap='gray')\nplt.title(idx_to_emotion_fer[y_fer_train[10]])\nplt.show()\nplt.imshow(X_fer_test_public[10], interpolation='none', cmap='gray')\nplt.title(idx_to_emotion_fer[y_fer_test_public[10]])\nplt.show()\nplt.imshow(X_fer_test_private[10], interpolation='none', cmap='gray')\nplt.title(idx_to_emotion_fer[y_fer_test_private[10]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nfrom keras.models import Model, Sequential\nfrom keras.layers import Flatten, Dense, Input, Concatenate\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(y):\n    return to_categorical(y, 7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Baseline VGG16 with no pretraining"},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = VGG16(weights=None, include_top=False, \n                    input_shape=(48, 48, 3))\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = conv_base(img_conc)\n\nconv_output_flattened = Flatten()(conv_output)\ndense_out = Dense(128, activation='relu')(conv_output_flattened)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy']) \n\n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### CNN from another kernel \nhttps://www.kaggle.com/deadskull7/facreco-90-14-10-epochs\nIn that notebook the model used binary_crossentropy, but since then also binary_accuracy was automatically used, the results are not correct."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense , Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD , Adam\nfrom keras.layers import Conv2D , BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\ndef swish_activation(x):\n    return (K.sigmoid(x) * x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(48,48, 1)))\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\nmodel.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\nmodel.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation=swish_activation))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(7 , activation='sigmoid'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam' ,\n              metrics=['categorical_accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results are not as good as in the referenced notebook, but still better than the baseline. One dense layer on top of a network trained on imagenet is not enough to predict the emotions."},{"metadata":{},"cell_type":"markdown","source":"### Trying VGGFace"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/rcmalli/keras-vggface.git\nfrom keras_vggface.vggface import VGGFace\nfrom keras_vggface import utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VGGFace(include_top = False, input_shape = (48,48,3),pooling = 'avg').summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vggfeatures = VGGFace(include_top = False, input_shape = (48,48,3),pooling = 'avg')\nfor x in vggfeatures.layers[:]:\n    x.trainable = False\nbase_model = vggfeatures\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = base_model(img_conc)\n\ndense_out = Dense(128, activation='relu')(conv_output)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy'])\n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Unfreezing layers topmost convolutions"},{"metadata":{"trusted":true},"cell_type":"code","source":"vggfeatures = VGGFace(include_top = False, input_shape = (48,48,3),pooling = 'avg')\nfor x in vggfeatures.layers[:-5]:\n    x.trainable = False\nbase_model = vggfeatures\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = base_model(img_conc)\n\ndense_out = Dense(128, activation='relu')(conv_output)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy'])\n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Unfreezing all"},{"metadata":{"trusted":true},"cell_type":"code","source":"vggfeatures = VGGFace(include_top = False, input_shape = (48,48,3),pooling = 'avg')\n\nbase_model = vggfeatures\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = base_model(img_conc)\n\ndense_out = Dense(128, activation='relu')(conv_output)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy'])\n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VGG pretrained on imagenet with freezed layers and removed top"},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = VGG16(weights='imagenet', include_top=False, \n                    input_shape=(48, 48, 3))\nconv_base.trainable = False\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = conv_base(img_conc)\n\nconv_output_flattened = Flatten()(conv_output)\ndense_out = Dense(128, activation='relu')(conv_output_flattened)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy']) \n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Unfreezing topmost convolutions"},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = VGG16(weights='imagenet', include_top=False, \n                    input_shape=(48, 48, 3))\n\n\nfor x in conv_base.layers[:-4]:\n    x.trainable = False\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = conv_base(img_conc)\n\nconv_output_flattened = Flatten()(conv_output)\ndense_out = Dense(128, activation='relu')(conv_output_flattened)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy']) \n\n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Unfreezing all"},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = VGG16(weights='imagenet', include_top=False, \n                    input_shape=(48, 48, 3))\n\nimg_input = Input(shape=(48,48,1))\nimg_conc = Concatenate()([img_input, img_input, img_input])   \nconv_output = conv_base(img_conc)\n\nconv_output_flattened = Flatten()(conv_output)\ndense_out = Dense(128, activation='relu')(conv_output_flattened)\nout = Dense(7, activation='softmax')(dense_out)\n\nmodel = Model(inputs=img_input, outputs=out)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['categorical_accuracy']) \n\n\nmodel.fit(\n    X_fer_train.reshape((-1, 48, 48, 1)), \n    one_hot(y_fer_train), \n    batch_size=128, \n    epochs=15, \n    validation_data=(X_fer_test_public.reshape((-1, 48, 48, 1)), one_hot(y_fer_test_public)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}