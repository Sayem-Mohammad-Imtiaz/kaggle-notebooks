{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport librosa\nimport math\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Dense, Flatten, Dropout, SeparableConv1D\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nimport matplotlib.pyplot as plt\n\nfrom scipy.signal import savgol_filter\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy.signal import find_peaks\nfrom scipy.signal import hilbert, chirp\nfrom scipy.signal import butter, lfilter\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.metrics import plot_confusion_matrix\n\nimport librosa.display as lrd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mel_width = 128\nn_mels = 128\ndef_sr = 44100\n\nlearning_rate = 1e-4\nepochs = 50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def butter_bandpass(lowcut, highcut, fs, order=5): # filter out noise outside [lowcout, highcut]\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = lfilter(b, a, data)\n    return y\n\ndef rm_lowPSD_noise(signal_data, sr = 4000, PSD_cut = 0.1): # remove noise with energy density < 10%\n    \n    y = signal_data\n    n = len(signal_data)\n    t = np.arange(n)/sr\n    \n    yhat = np.fft.fft(y,n)\n    PSD = yhat*np.conj(yhat) / n\n    dt = 1/sr\n    \n    freq = (1/(dt*n))*np.arange(n)\n    \n    L = np.arange(1, np.floor(n/2), dtype = 'int')\n    \n    indices = PSD > np.min([np.abs(np.percentile(PSD, 99))*0.1, PSD_cut])\n    PSDclean = PSD*indices\n    yhat = indices * yhat\n    signal_denoised = np.fft.ifft(yhat)\n    \n    return np.abs(signal_denoised)\n\ndef preprocessing_signal(raw_audio_wave, sr, order = 5, lowcut = 500, highcut = 1500, sigma = 3):\n    '''\n    - filter out the low-frequence noise \n    - remove the outliers according to n-sigma rule\n    - normalization, scaled signal to [-1, 1]  \n    **(raw)audio_waves --> high_pass_audio --> no_outlier_audio --> normalized_audio**\n    '''\n    # filter out low- and high-frequency noises\n    band_pass_signal = butter_bandpass_filter(raw_audio_wave, lowcut, highcut, sr, order=order)\n    \n    # remove outliers\n    y = band_pass_signal\n    y_filtered_outlier_removed = y.copy()\n    y_filtered_outlier_removed[np.abs(y) > sigma*np.std(y)] = 0\n    \n    # normalization\n    y_max = np.max([np.abs(y_filtered_outlier_removed.min()), y_filtered_outlier_removed.max()])\n    norm_y_filtered_outlier_removed = y_filtered_outlier_removed/y_max\n    \n    # filter out low spectral density noise\n    y_prep = rm_lowPSD_noise(norm_y_filtered_outlier_removed, sr = sr, PSD_cut = 0.05)\n    \n    return y_prep","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def audio_to_melspec(audio, sr, width=mel_width):\n    mel = librosa.feature.melspectrogram(audio, sr=sr)\n    return mel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def slice_resp_cycle(audio_file_path, annotation_df: pd.DataFrame):\n    y, sr = librosa.load(audio_file_path)\n    resp_original_mel = []\n    resp_fix_len_mel = []\n    crackle_label = []\n    for _, row in annotation_df.iterrows():\n        start = math.floor(row['begin'] * sr)\n        end = min(math.ceil(row['end']*sr) + 1, len(y))\n        cycle_audio = y[start:end]\n        preprocessed_audio = preprocessing_signal(cycle_audio, sr=sr)\n        if 4*def_sr >= len(preprocessed_audio):\n            clip = librosa.util.pad_center(preprocessed_audio, int(4*def_sr))\n            fix_len_mel = audio_to_melspec(clip, sr)\n            orig_mel = audio_to_melspec(preprocessed_audio, sr)\n\n            fix_len_img = librosa.amplitude_to_db(fix_len_mel, ref=np.max)\n            orig_img = librosa.amplitude_to_db(orig_mel, ref=np.max)\n            resp_fix_len_mel.append(fix_len_img)\n            resp_original_mel.append(orig_img)\n            crackle_label.append(row['is_crackle'])\n    return resp_original_mel, resp_fix_len_mel, crackle_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_annotation_df(fname):\n    with open(fname) as f_annot:\n        lines = [[float(x) if '.' in x else int(x) for x in line.strip().split()] for line in f_annot.readlines() ]\n    df = pd.DataFrame(lines, columns=['begin', 'end', 'is_crackle', 'is_wheeze'])\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_path = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\nfiles = [f for f in os.listdir(audio_path) if os.path.isfile(os.path.join(audio_path, f))] \naudio_ids = [f.split('.')[0] for f in files if f.endswith('.wav')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_id = audio_ids[210]\n\nwav_file = os.path.join(audio_path, audio_id + '.wav')\nanno_file = os.path.join(audio_path, audio_id + '.txt')\nanno_df = read_annotation_df(anno_file)\noriginal_mels, mels, labels = slice_resp_cycle(wav_file, anno_df)\n\nplt.figure(figsize = (10,10))\nplt.subplot(2, 1, 1)\nlrd.specshow(mels[0])\nplt.subplot(2, 1, 2)\nlrd.specshow(original_mels[0])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orig_mel_list = []\nmel_list = []\nlabel_list = []\n\nfor audio_id in audio_ids:\n    wav_file = os.path.join(audio_path, audio_id + '.wav')\n    anno_file = os.path.join(audio_path, audio_id + '.txt')\n    anno_df = read_annotation_df(anno_file)\n    orig_mels, mels, labels = slice_resp_cycle(wav_file, anno_df)\n    mel_list += mels\n    orig_mel_list += orig_mels\n    label_list += labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(np.array(mel_list), np.array(label_list), test_size=0.2, random_state=10)\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n\ndef f1_loss(y_true, y_pred): \n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0) \n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0) \n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0) \n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0) \n    p = tp / (tp + fp + K.epsilon()) \n    r = tp / (tp + fn + K.epsilon()) \n    f1 = 2*p*r / (p+r+K.epsilon()) \n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1) \n    return 1 - K.mean(f1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mSpec_input=keras.layers.Input(shape=(128,345,1),name=\"mSpecInput\")\nx=keras.layers.Conv2D(32,5,strides=(2,3),padding='same')(mSpec_input)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(64,3,strides=(2,2),padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(96,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.Dropout(0.4)(x)\nx=keras.layers.MaxPooling2D(pool_size=2,padding='valid')(x)\n\nx=keras.layers.Conv2D(128,2,padding='same')(x)\nx=keras.layers.BatchNormalization()(x)\nx=keras.layers.Activation(keras.activations.relu)(x)\nx=keras.layers.Dropout(0.4)(x)\nx=keras.layers.GlobalMaxPooling2D()(x)\nmSpec_output=keras.layers.Dense(1, activation='sigmoid')(x)\n\nmSpec_model=keras.Model(mSpec_input, mSpec_output, name=\"mSpecModel\")\n\nmSpec_model.summary()\n\nopt = keras.optimizers.Adam(learning_rate=learning_rate/5)\n\nmSpec_model.compile(optimizer=opt, \n#                     loss=f1_loss, \n                    loss='binary_crossentropy',\n                    metrics=[Recall(), Precision(), 'accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\nhistory = mSpec_model.fit(X_train, \n                          y_train, \n                          validation_data = (X_validation, y_validation),\n                          epochs = 100,\n                          callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuary vs Validation Accuary')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuary')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_mel = [np.mean(x, axis=1) for x in orig_mel_list]\nX_train, X_test, y_train, y_test = train_test_split(np.array(mean_mel), np.array(crackle_lables), test_size=0.2, random_state=10)\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.reshape(y_train, (y_train.shape[0], 1))\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\ny_validation = np.reshape(y_validation, (y_validation.shape[0], 1))\nX_validation = np.reshape(X_validation, (X_validation.shape[0], X_validation.shape[1], 1))\ny_test = np.reshape(y_test, (y_test.shape[0], 1))\nX_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1],  1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(128, 1)))\n\nmodel.add(Conv1D(128, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(3)) \n\nmodel.add(SeparableConv1D(256, kernel_size=5, activation='relu'))\nmodel.add(MaxPooling1D(5)) \n\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))   \nmodel.add(Dropout(0.))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[Recall(), Precision(), 'accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\nhistory = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=100, verbose=1, callbacks=[early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prediction = mSpec_model.predict(X_test)\nx = Recall()\ny = Precision()\nx.update_state(y_test, y_prediction)\ny.update_state(y_test, y_prediction)\nprint(x.result().numpy())\nprint(y.result().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as ipd\nipd.Audio('../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/101_1b1_Al_sc_Meditron.wav')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}