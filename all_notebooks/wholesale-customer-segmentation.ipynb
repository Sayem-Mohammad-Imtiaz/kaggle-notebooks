{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Customer Segmentation\n\nIn the following customers will be segmented according to their annual spending using KMeans.\n\n* Data Exploration\n* Requirements Check\n* Data Preparation\n* Model development"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"wholesale_all = pd.read_csv('../input/wholesale-customers-data-set/Wholesale customers data.csv')\n\nwholesale_all.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"wholesale_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wholesale = wholesale_all.drop(['Channel','Region'], axis=1)\nwholesale_all.groupby(['Channel', 'Region']).agg(['mean', 'std']).round(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(15,10))\nsns.boxplot(x='variable', y='value', data=wholesale.melt())\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(wholesale, diag_kind='kde')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Requirements Check"},{"metadata":{},"cell_type":"markdown","source":"As the distributions are skewed a transformation must be found to normalise the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import boxcox, probplot, norm, shapiro\n\nshapiro_test = {}\nplt.figure(figsize=(15, 10))\nfor i in range(0,6):\n    ax = plt.subplot(2,3,i+1)\n    probplot(x = wholesale[wholesale.columns[i]], dist=norm, plot=ax)\n    plt.title(wholesale.columns[i])\n    shapiro_test[wholesale.columns[i]] = shapiro(wholesale[wholesale.columns[i]])\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" All the variable are statistically significant non normally distributed.\n \n Let's try the Logarithmic Transformation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nwholesale_log = np.log(wholesale)\n\nshapiro_test = {}\n\nplt.figure(figsize=(15, 10))\nfor i in range(6):\n    ax = plt.subplot(2,3,i+1)\n    probplot(x = wholesale_log[wholesale_log.columns[i]], dist=norm, plot=ax)\n    plt.title(wholesale_log.columns[i])\n    shapiro_test[wholesale.columns[i]] = shapiro(wholesale[wholesale.columns[i]])\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Log-Transformation is also not satisfactorily. Let's try BoxCox transformation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import boxcox\n\nshapiro_test = {}\nlambdas = {}\n\nplt.figure(figsize=(15, 10))\nplt.title('BoxCox Transformation')\nfor i in range(6):\n    ax = plt.subplot(2,3,i+1)\n    x, lbd = boxcox(wholesale[wholesale.columns[i]])\n    probplot(x = x, dist=norm, plot=ax)\n    plt.title(wholesale.columns[i])\n    shapiro_test[wholesale.columns[i]] = shapiro(x)\n    lambdas[wholesale.columns[i]] = lbd\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict(lambdas, orient='index', columns=['lambda'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer, StandardScaler\n\nbc = PowerTransformer(method='box-cox')\nwholesale_boxcox = bc.fit_transform(wholesale)\n\nsc = StandardScaler()\nwholesale_processed = sc.fit_transform(wholesale_boxcox)\n\nwholesale_processed_df = pd.DataFrame(wholesale_processed, columns=wholesale.columns)\nwholesale_processed_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(wholesale_processed_df, diag_kind='kde')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model Development"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nsse = {}\n\nfor k in range(2,11):\n    kmeans = KMeans(n_clusters = k, random_state=123)\n    cluster_labels = kmeans.fit_predict(wholesale_processed_df)\n    sse[k] = kmeans.inertia_\n   \nplt.figure(figsize=(10,5))\nplt.title('Elbow Plot')\nsns.pointplot(x = list(sse.keys()), y = list(sse.values()))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The elbow is by 3 clusters so we try the kmeans with 3 and 4 clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=3, random_state=123)\nkmeans.fit(wholesale_processed_df)\n\nwholesale = wholesale.assign(segment = kmeans.labels_)\n\nkmeans_3_means = wholesale.groupby('segment').mean()\n\nkmeans = KMeans(n_clusters=4, random_state=123)\nkmeans.fit(wholesale_processed_df)\n\nwholesale = wholesale.assign(segment = kmeans.labels_)\n\nkmeans_4_means = wholesale.groupby('segment').mean()\n\nplt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.heatmap(kmeans_3_means.T, cmap='Blues')\n\nplt.subplot(1,2,2)\nsns.heatmap(kmeans_4_means.T, cmap='Blues')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}