{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"file_extension":".py","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":1,"cells":[{"metadata":{"_uuid":"22ddb49c9d139f3050f670707b4b45fd648a1854","_cell_guid":"0bb128d2-544c-4ddd-a630-d43d7cfe5dee"},"source":"Grid search and random search are both popular hyperoptimization methods.\nIn this notebook, we'll compare the two and see which one is more effective.\n","cell_type":"markdown"},{"execution_count":null,"metadata":{"_uuid":"169b584ab05bfd0a099baea6dc829fed8e8b3dd0","_cell_guid":"096196bd-0057-4c63-982e-8e8de4bc0537"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt # data visualization\n\nimport scipy as sp\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{"_uuid":"aec8ce76f5014a06dae5ba66ece8b20e2027e75b","_cell_guid":"41d1678a-bdcb-4980-92bd-be00739507d7"},"source":"data = pd.read_csv('../input/voice.csv')\ndata.sample(5)\n","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{"_uuid":"2176b5a6e6f8a62ddeecadd3574786f778416e6a","_cell_guid":"d2e37d89-384b-47cb-bf88-1bc557f92d07"},"source":"data.info()","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{"_uuid":"20d78936959d41e081030ac9da06b7770bb366f0","_cell_guid":"53357c3c-3b41-400b-9b55-536dd011b568"},"source":"X = data.drop('label', axis = 1)\ny = data.label\n\nX.shape, y.shape","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{"_uuid":"6342614fa845680dfca7a723f5d9462539ff7749","_cell_guid":"c21f2e04-07ee-4794-a8fd-b288b059d0b0"},"source":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","outputs":[],"cell_type":"code"},{"metadata":{"_uuid":"8a768fcb66c619da5bc0f57f1ddfb8638c1878b2","_cell_guid":"eedb7ec9-5112-4ab2-8e9f-5fdb3b2d29fb"},"source":"\n\n","cell_type":"markdown"},{"execution_count":null,"metadata":{"_uuid":"664c39dd47f65b2a167e97acbde18bc65e079ee9","_cell_guid":"108397ad-07db-4849-8922-2d55615f0024"},"source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\nfrom sklearn.svm import SVC\n\ndef tune(X , y, search_type, n_iter):\n    scores = []\n    params = []\n    for i in range(len(n_iter)):\n        scaler = StandardScaler()\n        clf = SVC()\n        pipe = Pipeline(steps=[('scaler', scaler), \n                               ('svc', clf)])\n        if search_type == 'grid':\n            param_grid = dict(svc__C = np.logspace(-2, 5, np.round(n_iter[i]**0.5)), svc__gamma = np.logspace(-5, 1, np.round(n_iter[i]**0.5)))\n            gridsearch = GridSearchCV(pipe, param_grid = param_grid, cv = 3)\n            gridsearch.fit(X, y)\n            scores.append(gridsearch.best_score_)\n            params.append(gridsearch.best_params_)\n        elif search_type == 'random':\n            param_distributions = {'svc__C': sp.stats.expon(scale=10), \n            'svc__gamma': sp.stats.expon(scale=0.1)}\n            randsearch = RandomizedSearchCV(pipe, param_distributions = param_distributions, n_iter= n_iter[i], cv = 3, random_state = 333)\n            randsearch.fit(X, y)\n            scores.append(randsearch.best_score_)\n            params.append(randsearch.best_params_)\n        \n        print(search_type, \"with\", str(n_iter[i]), \"iterations completed\")\n    \n    return scores, params\n","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{},"source":"n_iterations = [9, 25, 64, 100, 169]\n\nscores_grid, params_grid = tune(X, y, 'grid', n_iterations)\nscores_random, params_random = tune(X, y, 'random', n_iterations)","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{},"source":"\n\nplt.style.use('fivethirtyeight')\n\nplt.plot(n_iterations, scores_grid)\nplt.plot(n_iterations, scores_random)\n\nplt.legend(['Grid Search', 'Random Search'], loc='lower right')\nplt.xlabel('Number of iterations')\nplt.ylabel('Mean cross-validated accuracy of the best classifier')\nplt.show()","outputs":[],"cell_type":"code"},{"metadata":{},"source":"We can see that random search outperforms grid search for most number of iterations.\nLet's build dummy dataset and compare the two again.","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"from sklearn.datasets import make_classification\nX, y = make_classification(n_samples=3000,\n                                   n_features=20,\n                                   n_informative=10,\n                                   n_redundant=4)","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{"collapsed":true},"source":"def tune(X , y, search_type, n_iter):\n    scores = []\n    params = []\n    for i in range(len(n_iter)):\n        if search_type == 'grid':\n            param_grid = {'C' : np.logspace(-2, 5, np.round(n_iter[i]**0.5)), 'gamma' : np.logspace(-5, 1, np.round(n_iter[i]**0.5))}\n            gridsearch = GridSearchCV(SVC(), param_grid = param_grid, cv = 3)\n            gridsearch.fit(X, y)\n            scores.append(gridsearch.best_score_)\n            params.append(gridsearch.best_params_)\n        elif search_type == 'random':\n            param_distributions = {'C': sp.stats.expon(scale=10), \n            'gamma': sp.stats.expon(scale=0.1)}\n            randsearch = RandomizedSearchCV(SVC(), param_distributions = param_distributions, n_iter= n_iter[i], cv = 3, random_state = 333)\n            randsearch.fit(X, y)\n            scores.append(randsearch.best_score_)\n            params.append(randsearch.best_params_)\n        \n        print(search_type, \"with\", str(n_iter[i]), \"iterations completed\")\n    \n    return scores, params","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{},"source":"n_iterations = [9, 25, 64, 100, 169]\n\nscores_grid, params_grid = tune(X, y, 'grid', n_iterations)\nscores_random, params_random = tune(X, y, 'random', n_iterations)","outputs":[],"cell_type":"code"},{"execution_count":null,"metadata":{},"source":"\nplt.style.use('fivethirtyeight')\n\nplt.plot(n_iterations, scores_grid)\nplt.plot(n_iterations, scores_random)\n\nplt.legend(['Grid Search', 'Random Search'], loc='lower right')\nplt.xlabel('Number of iterations')\nplt.ylabel('Mean cross-validated accuracy of the best classifier')\nplt.show()","outputs":[],"cell_type":"code"},{"metadata":{},"source":"# Conclusion:\n\nRandom search outperformed grid search on both datasets across every number of iterations.\nAlso random search seemed to converge to an optimum more quickly than grid search, which means random search with fewer iterations is comparable to grid search with more iterations.\n\nIn highdimensional parameter space, grid search would perform worse with the same iterations because points become more sparse. \nAlso it is common that one of the hyperparameters is unimportant to finding the optimal hyperparameters, in which case grid search wastes a lot of iterations where as random search does not waste any iteration.\n\n\nFine grid search/manual search after either grid search or random search may result in a better validation score.","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true},"source":"","outputs":[],"cell_type":"code"}]}