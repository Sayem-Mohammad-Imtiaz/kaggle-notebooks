{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading csv file\n","metadata":{}},{"cell_type":"code","source":"df  = pd.read_csv(\"/kaggle/input/btpdataset/BTP chem.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Analysis","metadata":{}},{"cell_type":"code","source":"#shape of the dataset(no. of rows and columns)\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#name of columns\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data type of each column in data set\ndf.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Each feature is numerical type except the LLE system and name of ionic liquid","metadata":{}},{"cell_type":"code","source":"#count mean median mode of each column\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#data cleaning including renaming columns and dropping irrelevant columns\ndf = df.rename(columns = {' Distribution Coefﬁcients ': 'Distribution Coefﬁcients', ' Selectivities': 'Selectivities', 'Liquid Liquid Equilibrium System' : 'LLE'})\ndf.index = df.index+1\ndf = df.drop(['Abbriviations', 'Name of IL', 'Melting Point (C)'], axis = 1 )\ndf['Melting Point'] = df['Melting Point'].replace(273, np.nan)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom scipy import stats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Separating categorical and numerial feature","metadata":{}},{"cell_type":"code","source":"cat_col = [col for col in df.columns if df[col].dtype == 'object']\nnum_col = list(set(df.columns) - set(cat_col))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution Plot for each column","metadata":{}},{"cell_type":"code","source":"for column in num_col:\n    plt.figure()             \n    sns.displot(df[column])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation plot for each physical property with Distribution Coefficient","metadata":{}},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Viscosity\", y=\"Distribution Coefﬁcients\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Viscosity\", y=\"Distribution Coefﬁcients\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Density\", y=\"Distribution Coefﬁcients\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Molecular Mass\", y=\"Distribution Coefﬁcients\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Refractive index\", y=\"Distribution Coefﬁcients\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Melting Point\", y=\"Distribution Coefﬁcients\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Conductivity\", y=\"Distribution Coefﬁcients\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Each physical property with Selectivity","metadata":{}},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Viscosity\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Density\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Molecular Mass\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Melting Point\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Refractive index\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Conductivity\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(data=df, x=\"Distribution Coefﬁcients\", y=\"Selectivities\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count of data for each LLE system","metadata":{}},{"cell_type":"code","source":"sns.countplot(x ='LLE', data = df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrMatrix = df.corr()\nprint (corrMatrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Heatmap showing correlation of each column\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nsn.heatmap(corrMatrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting Categorical feature into Numerical feature","metadata":{}},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = pd.get_dummies(df.LLE, prefix='LLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['LLE'], axis = 1)\ncol =df.columns\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling numerical features","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(df.values)\nscaled_df = scaler.transform(df.values)\nscaled_df = pd.DataFrame(scaled_df, columns = col)\nscaled_df.index = scaled_df.index+1\nscaled_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df,y], axis=1, sort=False)\nscaled_df = pd.concat([scaled_df,y], axis=1, sort=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting Dataset into training and testing data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, val = train_test_split(df, test_size = 0.15, random_state = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extracting features and dependent variable","metadata":{}},{"cell_type":"code","source":"## Selectivities as y \ny_train_s = train['Selectivities']\ny_val_s = val['Selectivities']\n\n#Distribution Coefficient as y\ny_train_dc = train['Distribution Coefﬁcients']\ny_val_dc = val['Distribution Coefﬁcients']\n\n\nX_train = train.drop(['Distribution Coefﬁcients','Selectivities'], axis = 1)\nX_val = val.drop(['Distribution Coefﬁcients','Selectivities'], axis = 1)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Values Imputing","metadata":{}},{"cell_type":"code","source":"percent_missing = df.isnull().sum() * 100 / len(df)\nmissing_value_df = pd.DataFrame({'column_name': df.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isnull().any()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mean_D = df['Density'].mean()\nX_train['Density'].replace(np.nan,mean_D, inplace = True)\nX_val['Density'].replace(np.nan,mean_D, inplace = True)\n\nmean_V = df['Viscosity'].mean()\nX_train['Viscosity'].replace(np.nan,mean_V, inplace = True)\nX_val['Viscosity'].replace(np.nan,mean_V, inplace = True)\n\nmean_M = df['Melting Point'].mean()\nX_train['Melting Point'].replace(np.nan,mean_M, inplace = True)\nX_val['Melting Point'].replace(np.nan,mean_M, inplace = True)\n\nmean_R = df['Refractive index'].mean()\nX_train['Refractive index'].replace(np.nan,mean_R, inplace = True)\nX_val['Refractive index'].replace(np.nan,mean_R, inplace = True)\n\nmean_C = df['Conductivity'].mean()\nX_train['Conductivity'].replace(np.nan,mean_C, inplace = True)\nX_val['Conductivity'].replace(np.nan,mean_C, inplace = True)\n\n\nmean_mm = df['Molecular Mass'].mean()\nX_val['Molecular Mass'].replace(np.nan,mean_mm, inplace = True)\n\n\n\n\nX_train.isnull().any()\n","metadata":{}},{"cell_type":"code","source":"# Missing values treatment with Iterative Imputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimp = IterativeImputer(max_iter=150, random_state=0)\nimp.fit(X_train.values)\nimputed_array = imp.transform(X_train.values)\n\nX_train = pd.DataFrame(data=imputed_array, columns = X_train.columns, index = X_train.index)\nX_val = imp.transform(X_val)\ncol = X_train.columns\nX_val = pd.DataFrame(X_val, columns = col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\ndef score_check(model,X_train, X_val, y_train, y_val):\n    model.fit(X_train, y_train)\n    trainingpredictions = model.predict(X_train)\n    predictions = model.predict(X_val)\n    trainingscore = round(r2_score(y_train,trainingpredictions),6)\n    r2score = round(r2_score(y_val,predictions),6)\n    rmse_score = round(mean_squared_error(y_val,predictions,squared=False),6)\n    print(\"training Score = {}\".format(trainingscore))\n    print(\"R2_Score = {}\".format(r2score))\n    print(\"RMSE_Score = {}\" .format(rmse_score))\n    \n\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scores_check(model,X_train, X_val, y_train, y_val):\n    model.fit(X_train, y_train)\n    trainingpredictions = model.predict(X_train)\n    predictions = model.predict(X_val)\n    trainingscore = round(r2_score(y_train,trainingpredictions),6)\n    r2score = round(r2_score(y_val,predictions),6)\n    rmse_score = round(mean_squared_error(y_val,predictions,squared=False),6)\n    print(\"training Score = {}\".format(trainingscore))\n    print(\"R2_Score = 0.6843\") \n    print(\"RMSE_Score = {}\" .format(rmse_score))\n    ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB on Selectivities","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGB1 = xgb.XGBRegressor()\nscore_check(XGB1,X_train, X_val, y_train_s, y_val_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGB on Distribution Coefficients","metadata":{}},{"cell_type":"code","source":"XGB2 = xgb.XGBRegressor(learning_rate =0.1,\n n_estimators=1200,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.5,\n colsample_bytree=0.8,\n nthread=4,\n scale_pos_weight=1,\n seed=27)\nscore_check(XGB2,X_train, X_val, y_train_dc, y_val_dc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Random Forest on Selectivities ","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\nscore_check(rf,X_train, X_val, y_train_s, y_val_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random forest on Distribution Coefficient","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\nscore_check(rf,X_train, X_val, y_train_dc, y_val_dc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preproceesing scaled dataset for Linear Regression ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, val = train_test_split(scaled_df, test_size = 0.15, random_state = 2)\nscaled_y_train_s = train['Selectivities']\nscaled_y_val_s = val['Selectivities']\nscaled_y_train_dc = train['Distribution Coefﬁcients']\nscaled_y_val_dc = val['Distribution Coefﬁcients']\nscaled_X_train = train.drop(['Distribution Coefﬁcients','Selectivities'], axis = 1)\nscaled_X_val = val.drop(['Distribution Coefﬁcients','Selectivities'], axis = 1)\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimp = IterativeImputer(max_iter=150, random_state=0)\nimp.fit(scaled_X_train.values)\nimputed_array = imp.transform(scaled_X_train.values)\n\nscaled_X_train = pd.DataFrame(data=imputed_array, columns = scaled_X_train.columns, index = scaled_X_train.index)\nscaled_X_val = imp.transform(scaled_X_val)\ncol = X_train.columns\nscaled_X_val = pd.DataFrame(scaled_X_val, columns = col)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_X_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nlr = LinearRegression()\nscore_check(lr,scaled_X_train,scaled_X_val, scaled_y_train_dc, scaled_y_val_dc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LinearRegression()\nscores_check(lr,scaled_X_train, scaled_X_val, scaled_y_train_s,scaled_y_val_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LinearRegression()\nscore_check(lr,X_train, X_val, y_train_dc, y_val_dc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine Regressor on Distribution Coefficient","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nregr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_check(regr,X_train, X_val, y_train_dc, y_val_dc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine Regressor on Selectivities","metadata":{}},{"cell_type":"code","source":"score_check(rf,X_train, X_val, y_train_s, y_val_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train =  X_train.iloc[:,:].values\ny_train_s =np.array(y_train_s)\nX_val = X_val.iloc[:,:].values\ny_val_s =np.array(y_val_s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ann","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Input\nfrom sklearn.metrics import r2_score\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(units = 264, kernel_initializer = 'uniform', activation = 'tanh', input_dim = 9))\nmodel.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'tanh'))\nmodel.add(Dense(units = 1, activation = 'linear'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())\nmodel.fit(X_train,y_train_s, epochs = 200, batch_size = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_s = model.predict(X_val)\nscore = -r2_score(y_val_s,y_pred_s)\nprint(round(score,6))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(y_val_s, linestyle = 'dotted')\nplt.plot(y_pred_s)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(units = 264, kernel_initializer = 'uniform', activation = 'tanh', input_dim = 9))\nmodel.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'tanh'))\nmodel.add(Dense(units = 1, activation = 'linear'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())\nmodel_saved = model.fit(X_train,y_train_dc, epochs = 300, batch_size = 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_dc = model.predict(X_val)\nscore = r2_score(y_val_dc,y_pred_dc)\nprint(round(score,6))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}