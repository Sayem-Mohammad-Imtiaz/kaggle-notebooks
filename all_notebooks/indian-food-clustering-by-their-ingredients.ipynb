{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Contents  \n#### * Load Data and Libraries  \n#### * Data Visualization  \n#### * Cleaning Data - arrange Ingredients  \n#### * Clustering  \n#### * appendix"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### * Load Data and Libraries\n  \nTo help unify the wording of Ingredients, I use FuzzyWuzzy  \n[FuzzyWuzzy -GitHub](https://github.com/seatgeek/fuzzywuzzy)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nimport collections\nfrom wordcloud import WordCloud\n\nfrom sklearn.cluster import KMeans\n\n!pip install --q fuzzywuzzy\nfrom fuzzywuzzy import fuzz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"food = pd.read_csv('../input/indian-food-101/indian_food.csv').set_index('name')\nfood.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"food.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### * Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 2, sharey=True,figsize=(12,8))\nplt.subplots_adjust(hspace=0.6)\nfor i, f in enumerate(['diet', 'flavor_profile','course', 'region']):\n    axy, axx = divmod(i,2)\n    sns.countplot(food[f], ax=ax[axy, axx])\n    ax[axy,axx].tick_params(axis='x', labelrotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,3))\nsns.countplot(food['state'], ax=ax)\nax.tick_params(axis='x', labelrotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### * Cleaning Data - arrange Ingredients"},{"metadata":{"trusted":true},"cell_type":"code","source":"ing_dic = collections.defaultdict(int)\n\nfor f in food.index:\n    ing_list = food.at[f, 'ingredients'].split(', ')\n    for i in ing_list:\n        i = i.lower().strip()\n        ing_dic[i] += 1\n\ning_df = pd.DataFrame.from_dict(ing_dic, orient='index')\\\n    .rename(columns={0:'count'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check components of Ingredients, start with 'red'"},{"metadata":{"trusted":true},"cell_type":"code","source":"ing_df.sort_index().loc['red': 'red0'].T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There exists red chili, red chilli and red chillies in components of Ingredients!"},{"metadata":{},"cell_type":"markdown","source":"Check for similarity in the expression of the ingredients by FuzzyWuzzy  "},{"metadata":{},"cell_type":"markdown","source":"> Combinations with FuzzyWuzzy.ratio>70"},{"metadata":{"trusted":true},"cell_type":"code","source":"ing_list = ing_df.sort_values('count').index.to_list()\n\nn = 0\n\nfor i in range(len(ing_list)-1):\n    for j in range(i+1, len(ing_list)):\n        ratio = fuzz.ratio(ing_list[i], ing_list[j])\n        if n == 30:\n            break\n        if ratio > 70:\n            print(ing_list[i], ', ', ing_list[j], '\\t', ratio)\n            n += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When the ratio is greater than 80, the two expressions appear to refer to the same content in many cases"},{"metadata":{},"cell_type":"markdown","source":"> all combination with ratio>80 shown in hidden cell"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for i in range(len(ing_list)-1):\n    for j in range(i+1, len(ing_list)):\n        ratio = fuzz.ratio(ing_list[i], ing_list[j])\n        if ratio > 80:\n            print('\"', ing_list[i], '\": \"',ing_list[j], '\"\\t', ratio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"similar_ing_dic = {\n    \"red chili\": \"red chilli\",\n    \"greens\":\"green\",\n    \"drumstick\":\"drumsticks\",\n    \"thin rice flakes\":\"beaten rice flakes\",\n    \"chana daal\":\"chana da \",\n    \"whole urad dal\":\"white urad dal\",\n    \"bell pepper\":\"bell peppers\",\n    \"frozen green peas\":\"green peas\" ,\n    \"fresh green peas\":\"green peas\",\n    \"chilli\": \"chillies\",\n    \"fish fillets\": \"fish fillet\",\n    \"mustard seed\": \"mustard seeds\",\n    \"peanut\":\"peanuts\",\n    \"red chillies\":\"red chilli\",\n    \"dried fruits\":\"dry fruits\",\n    \"almond\":\"almonds\",\n    \"carrots\":\"carrot\",\n    \"yoghurt\":\"yogurt\",\n    \"chenna\":\"chhena\",\n    \"green chillies\":\"green chilies\",\n    \"green chilli\":\"green chilies\",\n    \"green chili\":\"green chilies\",\n    \"potatoes\":\"potato\",\n    \"tomatoes\":\"tomato\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_ing_dic = collections.defaultdict(int)\n\nfor f in food.index:\n    tmp_list = food.at[f, 'ingredients'].split(', ')\n    for i in tmp_list:\n        i = i.lower().strip()\n        if i in similar_ing_dic:\n            i = similar_ing_dic[i]\n        new_ing_dic[i] += 1\n            \nnew_ing_df = pd.DataFrame.from_dict(new_ing_dic, orient='index')\\\n    .rename(columns={0:'count'})\nnew_ing_df.sort_index().loc['red':'red0'].T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### * Clustering"},{"metadata":{},"cell_type":"markdown","source":"> Setting a 'Bag-of=Ingredient'"},{"metadata":{"trusted":true},"cell_type":"code","source":"BoI_df = pd.DataFrame(\n    np.zeros(len(food)*len(new_ing_dic)).reshape(len(food),len(new_ing_dic))\\\n    .astype(int),index=food.index, columns=new_ing_df.index)\n\nfor f in food.index:\n    tmp_list = food.at[f, 'ingredients'].split(', ')\n    for i in tmp_list:\n        i = i.lower()\n        if i[0] == ' ':\n            i = i[1:]\n        if i[-1] ==' ':\n            i = i[:-1]\n        if i in similar_ing_dic:\n            i = similar_ing_dic[i]\n        BoI_df.at[f, i]=1\n\nBoI_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Run KMeans"},{"metadata":{"trusted":true},"cell_type":"code","source":"km = KMeans(n_clusters=5,random_state=0)\nclust5 = pd.DataFrame(\n    km.fit(BoI_df).labels_, index=BoI_df.index).rename(columns={0:'grp'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Features by Cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=clust5['grp'], orient='h');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(4,figsize=(12,16))\nfor i, f in enumerate(['flavor_profile','course','region','diet']):\n    pd.crosstab(clust5['grp'],food[f],normalize='index')[::-1]\\\n    .plot.barh(stacked=True,ax=ax[i])\n    ax[i].set_title(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_ing = BoI_df.sum().sort_values(ascending=False)[:10].index.to_list()\nfreq_ing_df = pd.merge(clust5, BoI_df[freq_ing],\n                       how='inner', left_index=True, right_index=True)\\\n                    .groupby('grp').sum()\ntot_ing_df = pd.DataFrame(BoI_df.sum()).rename(columns={0:'total'})\n\nfor c in freq_ing_df.columns:\n    freq_ing_df[c] = freq_ing_df[c]/tot_ing_df.at[c, 'total']\n\nfreq_ing_df.T[::-1].plot.barh(stacked=True, figsize=(12,8),\n                              title='Share of frequently used ingredient');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> 0: main course, South region  \n1: main course, North region  \n2: rice flour and jaggery  \n3: Desert  \n4: Spicy, main course and snack, south region"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, sharey=True, figsize=(14,4))\nsns.boxplot(y=clust5['grp'], x=food['prep_time'], orient='h', ax=ax[0])\nax[0].set_xscale('log')\nsns.boxplot(y=clust5['grp'], x=food['cook_time'], orient='h', ax=ax[1])\nax[1].set_xscale('log');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think I've made a reasonably meaningful classification for myself. What do you think?"},{"metadata":{},"cell_type":"markdown","source":"Ingredient WordCloud by Cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"wc_df = pd.merge(clust5, BoI_df, how='inner', left_index=True, right_index=True)\n\ndef wc():\n    for i in range(5):\n        tmp_df = wc_df[wc_df['grp']==i]\n        tmp_list = []\n        for f in tmp_df.index:\n            for c in tmp_df.columns[1:]:\n                if tmp_df.at[f, c]==1:\n                    tmp_list.append(c.replace(' ', '_'))\n        words = ' '.join([word for word in tmp_list])\n        wordcloud =WordCloud(\n            width=700, height=300, collocations=False, background_color='white',\n            max_font_size=100).generate(words)\n        plt.figure(figsize=(14, 6))\n        plt.title('Group '+str(i), fontsize=32)\n        plt.imshow(wordcloud, interpolation=\"bilinear\")\n        plt.axis('off')\n\nwc()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### * appendix"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clust5[clust5['grp']==0].index.to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clust5[clust5['grp']==1].index.to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clust5[clust5['grp']==2].index.to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clust5[clust5['grp']==3].index.to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clust5[clust5['grp']==4].index.to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}