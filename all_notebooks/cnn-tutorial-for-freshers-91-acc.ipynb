{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets make a list of categories.ie infected or non infected leaf\ncategories=list(os.listdir('/kaggle/input/corn-leaf-infection-dataset/Corn Disease detection'))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now preprocess the data from the directory\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\ndire='/kaggle/input/corn-leaf-infection-dataset/Corn Disease detection'\nfeatures=[]\nIMG_SIZE=224\nfor i in categories:\n    path=os.path.join(dire,i)\n    num_classes=categories.index(i)\n    for img in os.listdir(path):\n        if img.endswith('.jpg'):\n            \n            img_array=cv2.imread(os.path.join(path,img))\n            img_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n            features.append([img_array,num_classes])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now separate the dependent and independent variables from the list\nX=[]\nY=[]\nfor i ,j in features:\n    X.append(i)\n    Y.append(j)\nnp.save('x.npy',X)\nnp.save('Y.npy',y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets visualize the data before normalising\nfor i in range(1,5):\n    plt.imshow(X[i])\n    plt.xlabel(Y[0])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets normalize the training data\nx=np.array(X)/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#after normalising\nfor i in range(1,5):\n    plt.imshow(x[i])\n    plt.xlabel(Y[0])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets reshape the x array to meet the keras requirement\nx=x.reshape(-1,200,200,3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we need to convert target lables into one hot encoding integers\nfrom tensorflow.keras.utils import to_categorical\ny=to_categorical(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we have to split our data into train and test sets\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=12,test_size=0.2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nimport keras \nfrom keras.layers import Conv2D\nfrom keras.models import Sequential\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport cv2\nimport re\nimport random\nrandom.seed(0)\nnp.random.seed(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model= keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=(3, 224, 224), pooling='avg', classes=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import MaxPool2D,Flatten,Dense,BatchNormalization,Dropout,Conv2D\n'''\nmodel=Sequential([\n    Conv2D(64,(3,3),padding='same',activation='relu',input_shape=(200,200,3)),\n    MaxPool2D((2,2)),\n    Conv2D(128,(3,3),activation='relu'),\n    MaxPool2D((3,3)),\n    Dropout(0.2),\n    BatchNormalization(),\n    Conv2D(256,(3,3),padding='same',activation='relu'),\n    MaxPool2D((3,3)),\n    Conv2D(512,(3,3),activation='relu',padding='same'),\n    MaxPool2D((2,2)),\n    Dropout(0.3),\n    BatchNormalization(),\n    Flatten(),\n    Dense(1024,activation='relu'),\n    Dense(2,activation='sigmoid')\n])\n'''\nmodel.summary()\nmodel.compile(optimizer='Adam',loss='mae',metrics=['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(x_train,y_train,epochs=150,batch_size=56,validation_split=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_dense_150.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the model results to evaluate better\nplt.figure(figsize=(12,5))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.xlabel('epochs')\nplt.ylabel('accuracy score')\nplt.title('accuracy score vs epochs')\nplt.legend(['train','test'])\nplt.show()\nplt.savefig('img1.png',dpi=400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#there are many sharp peaks during the training phase but at the end it achieves a quite good accuracy 91 on test set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot the loss score of both test and train sets\nplt.figure(figsize=(12,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('loss vs epochs')\nplt.legend(['train','test'])\nplt.show()\nplt.savefig('img1_Loss.png',dpi=400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}