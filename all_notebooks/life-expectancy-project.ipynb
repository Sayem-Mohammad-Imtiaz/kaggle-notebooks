{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Sütun başlıkları hakkında.\nCountry: Ülke\nYear: Yıl\nStatus: Gelişmiş ve gelişmekte olan\nLife expectancy: Yaşta yaşam beklentisi\nAdult Mortality: Her iki cinsiyette yetişkin ölüm oranları\ninfant deaths: Bebek ölümlerinin sayısı\nAlcohol: Kişi başına göre alkol tüketimi\npercentage expenditure: Kişi başı GSYİH\nHepatitis B: 1 yaşındakiler arasında hepatit B aşılama kapsamı\nMeasles: Kızamık - 1000 kişi başına bildirilen vaka sayısı\nBMI: Ortalama vücut kitle indeksi\nunder-five deaths: Beş yaş altı ölümlerin sayısı\nPolio: 1 yaşındakiler arasında çocuk felci aşılama kapsamı\nTotal expenditure: Sağlık için toplam devlet harcalamaları\nDiphtheria: 1 yaşındakiler arasında difteri, tetanoz, toksoidi ve boğmaca aşılama kapsamı\nHIV/AIDS: 0-4 yaş 1000 canlı doğumda ölüm\nGDP: Kişi başına Gayri Safi Yurtiçi Hasıla (ABD Doları cinsinden)\nPopulation: Ülkenin nüfusu\nthinness 1-19 years: 10-19 Yaş arası çocuklar ve ergenler arasında zayıflık prevalansı\nthinness 5-9 years: 5-9 Yaş arası çocuklarda zayıflık prevalansı (%)\nIncome composition of resources: Kaynakların gelir bileşimi açısından İnsani Gelişme Endeksi\nSchooling: Eğitim yılı sayısı (yıl)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import tree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dizi = pd.read_csv('../input/life-expectancy-data/Life_Expectancy_Data.csv', header = 0)\ndizi.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dizi.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dizi.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gözlem ve değişken sayılarını inceliyoruz.\ndizi.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Her bir değişkenin veri tiplerini inceliyoruz.\ndizi.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Şimdi her kolonda kaç tane eksik değer var onları inceliyoruz.\ndizi.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Eksik değerlerin yerini görselleştiriyoruz.\nfig, ax = plt.subplots(figsize = (9, 5))\nsns.heatmap(dizi.isnull(), cmap = \"cubehelix_r\", yticklabels='')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Her özellik için boş olan değerleri siliyoruz.\ndizi.dropna(inplace=True)\ndizi.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Meta verileri (ülke ve yıl) atıyoruz.\ndizi = dizi.drop('Country', axis=1)\ndizi = dizi.drop('Year', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sütun isimlerini standart bir hale getiriyoruz.\norjinal_sutunlar = list(dizi.columns) \nyeni_sutunlar = [] \nfor sutun in orjinal_sutunlar:     \n    yeni_sutunlar.append(sutun.strip().replace('  ', ' ').replace(' ', '_').lower()) \n\ndizi.columns = yeni_sutunlar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box Plot kullanarak her bir özelliğin verilerini görselleştiriyoruz.\nsutun_isimleri = {'life_expectancy':1,'adult_mortality':2,'infant_deaths':3,'alcohol':4,'percentage_expenditure':5,'hepatitis_b':6,'measles':7,'bmi':8,\n            'under-five_deaths':9,'polio':10,'total_expenditure':11,'diphtheria':12,'hiv/aids':13,'gdp':14,'population':15,'thinness_1-19_years':16,\n            'thinness_5-9_years':17,'income_composition_of_resources':18,'schooling':19}\n\nplt.figure(figsize=(18,30))\n\nfor variable,i in sutun_isimleri.items():\n                     plt.subplot(5,4,i)\n                     plt.boxplot(dizi[variable],whis=1.5)\n                     plt.title(variable)\n\nplt.show()\ndizi.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Çeyrekler arası aralığı (IQR) kullanarak aykırı değerleri kaldırıyoruz.\nQ1 = dizi.quantile(0.25)\nQ3 = dizi.quantile(0.75)\nIQR = Q3 - Q1\n\ndizi = dizi[~((dizi < (Q1 - 1.5 * IQR)) |(dizi > (Q3 + 1.5 * IQR))).any(axis=1)]\n\n#Durumu boolean değişkenleriyle değiştiriyoruz.\ndizi[\"status\"].replace({\"Developing\": 1, \"Developed\": 0}, inplace=True)\ndizi.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Korelasyonları görselleştirmek için ısı haritasını çiziyoruz.\nplt.figure(figsize = (14, 12))\nsns.heatmap(dizi.corr(), annot = True)\nplt.title('Özellikler arasındaki ilişki');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Özellikleri etiketlerden ayırıyoruz.\nX = dizi.iloc[:,1:].values\ny = dizi.iloc[:,0].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Verileri normalleştiriyoruz.\nX_std= StandardScaler().fit_transform(X)\nmean_vec = np.mean(X_std, axis=0)\n\n#Kovaryans matrisini hesaplıyoruz.\ncov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Özdeğerleri ve özvektörleri hesaplayın.\neig_vals, eig_vecs = np.linalg.eig(cov_mat)\ntot = sum(eig_vals)\nvar_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Kümülatif varyansın grafiğini çiziyoruz.\npca = PCA(n_components=19).fit(X_std)\nplt.figure(figsize=(12, 4))\nplt.plot(np.cumsum(pca.explained_variance_ratio_), label='Kümülatif varyans')\nplt.xlim(0,18,1)\nplt.xlabel('Bileşen sayısı')\nplt.ylabel('Kümülatif açıklanan varyans')\nplt.legend(loc='best')\nplt.grid(color='#E3E3E3')\nplt.xticks(np.arange(0, 19, 1.0));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hedef değişkenler ile ilgili özelliklerin değerlerini alıyoruz.\nozellikler = dizi['income_composition_of_resources'].values.reshape(-1,1)\netiketler = dizi['life_expectancy'].values.reshape(-1,1)\n\n#Veriyi normalleştiriyoruz.\nmin_max_scaler = MinMaxScaler()\nozellikler = min_max_scaler.fit_transform(ozellikler)\n\n#Veri setini eğitim ve test setine bölüyoruz.\nozellikler_egitim, ozellikler_test, etiketler_egitim, etiketler_test = train_test_split(ozellikler, etiketler, train_size = 0.7, test_size = 0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# Linear Regression","metadata":{}},{"cell_type":"code","source":"linear_model = LinearRegression()\n#Modeli eğitiyoruz.\nlinear_model.fit(ozellikler_egitim, etiketler_egitim);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Modeli test ediyoruz.\nlinear_model_score = linear_model.predict(ozellikler_test)\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ozellikler_test, etiketler_test,  color='black')\nplt.plot(ozellikler_test, linear_model_score, color='blue', linewidth=2)\nplt.xlabel('Kaynakların gelir bileşimi')\nplt.ylabel('Yaşam beklentisi')\nplt.show()\n\nprint('Katsayılar: \\n', linear_model.coef_)\nprint(\"Ortalama karesel hata: %.2f\" % mean_squared_error(etiketler_test,linear_model_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# Multiple Linear Regression","metadata":{}},{"cell_type":"code","source":"ozellikler = dizi.iloc[:, 1:].values\netiketler = dizi.iloc[:,0]\n\nmin_max_scaler = MinMaxScaler()\nozellikler = min_max_scaler.fit_transform(ozellikler)\n\nozellikler_egitim, ozellikler_test, etiketler_egitim, etiketler_test = train_test_split(ozellikler, etiketler, train_size = 0.7, test_size = 0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"linear_model.fit(ozellikler_egitim, etiketler_egitim);\n\nlinear_model_score = linear_model.predict(ozellikler_test)\n\nprint('Katsayılar: \\n', linear_model.coef_)\nprint(\"Ortalama karesel hata: %.2f\" % mean_squared_error(etiketler_test, linear_model_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"#Yaşam beklentisinin ortalamasını hesaplıyoruz.\ndizi_ort = dizi['life_expectancy'].mean()\ndizi_lr = dizi.copy()\n\n# Yaşam beklentisi ortalamadan büyük ise 1, değil ise 0\ndizi_lr['life_expectancy'] = (dizi_lr['life_expectancy'] > dizi_ort).astype(int)\n\n# Separate the features from the labels.\nozellikler_lr = dizi_lr.iloc[:, 1:].values\netiketler_lr = dizi_lr.iloc[:,0]\n\nmin_max_scaler = MinMaxScaler()\nozellikler_lr = min_max_scaler.fit_transform(ozellikler_lr)\n\n# Split the dataset in training and test set.\nozellikler_egitim_lr, ozellikler_test_lr, etiketler_egitim_lr, etiketler_test_lr = train_test_split(ozellikler_lr, etiketler_lr, train_size = 0.7, test_size = 0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_model = LogisticRegression(solver='liblinear')\n\n#Modeli eğitiyoruz.\nlogistic_model.fit(ozellikler_egitim_lr, etiketler_egitim_lr);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_score = logistic_model.predict(ozellikler_test_lr)\n\nconfusion_matrix = confusion_matrix(etiketler_test_lr, logistic_score)\n\n#Karışıklık matrisi ısı haritası\nclass_names=[0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix),cmap='YlGnBu',annot=True,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.xlabel('Tahmin edilen etiket')\nplt.ylabel('Gerçek etiket')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Eğitim verisi skor: %.2f\" % logistic_model.score(ozellikler_egitim_lr, etiketler_egitim_lr))\nprint(\"Test verisi skor: %.2f\" % logistic_model.score(ozellikler_test_lr, etiketler_test_lr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"# 3 farklı derinlikte gerçekleştiriyoruz.\ndecision_tree_model1 = DecisionTreeRegressor(max_depth=1)\ndecision_tree_model3 = DecisionTreeRegressor(max_depth=3)\ndecision_tree_model5 = DecisionTreeRegressor(max_depth=5)\n\n#Eğitim modeli\ndecision_tree_model1 = decision_tree_model1.fit(ozellikler_egitim, etiketler_egitim)\ndecision_tree_model3 = decision_tree_model3.fit(ozellikler_egitim, etiketler_egitim)\ndecision_tree_model5 = decision_tree_model5.fit(ozellikler_egitim, etiketler_egitim)\n\nprint(\"Derinliği 1 olan eğitim verisindeki puan: %.2f\" % decision_tree_model1.score(ozellikler_egitim, etiketler_egitim))\nprint(\"Derinliği 1 olan test verisindeki puan: %.2f\" % decision_tree_model1.score(ozellikler_test, etiketler_test))\nprint(\"Derinliği 3 olan eğitim verisindeki puan: %.2f\" % decision_tree_model3.score(ozellikler_egitim, etiketler_egitim))\nprint(\"Derinliği 3 olan test verisindeki puan: %.2f\" % decision_tree_model3.score(ozellikler_test, etiketler_test))\nprint(\"Derinliği 5 olan eğitim verisindeki puan: %.2f\" % decision_tree_model5.score(ozellikler_egitim, etiketler_egitim))\nprint(\"Derinliği 5 olan test verisindeki puan: %.2f\" % decision_tree_model5.score(ozellikler_test, etiketler_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"#Random Forest","metadata":{}},{"cell_type":"code","source":"random_forest_model = RandomForestRegressor(n_estimators=100,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1)\n\nrandom_forest_model.fit(ozellikler_egitim, etiketler_egitim);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(dizi.iloc[:, 1:].columns, columns = ['feature'])\ndf['fscore'] = random_forest_model.feature_importances_[:, ]\n\n#İlk 10 özelliği göreceli inceliyoruz.\ndf['fscore'] = df['fscore'] / df['fscore'].max()\ndf.sort_values('fscore', ascending = False, inplace = True)\ndf = df[0:19]\ndf.sort_values('fscore', ascending = True, inplace = True)\nax = df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(15, 10))\n\n# Plot the result.\nplt.title('Random Forest özelliği')\nplt.xlabel('')\nplt.ylabel('')\nplt.xticks([], [])\nplt.yticks()\n\n#Verileri toplamak için liste oluşturuyoruz.\ntoplamlar = []\n\nfor i in ax.patches:\n    toplamlar.append(i.get_width())\n\n# Set individual bar lables using above list.\ntoplam = sum(toplamlar)\n\nfor i in ax.patches:\n    # get_width pulls left or right; get_y pushes up or down.\n    ax.text(i.get_width(), i.get_y()+.13, \\\n            str(round((i.get_width()/toplam)*100, 2))+'%', fontsize=10,\ncolor='#505050')\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest_score = random_forest_model.predict(ozellikler_test)\n\nprint(\"Eğitim verisindeki puan: %.2f\" % random_forest_model.score(ozellikler_egitim, etiketler_egitim))\nprint(\"Test verisindeki puan: %.2f\" % random_forest_model.score(ozellikler_test, etiketler_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}