{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Allgemein\n\nErsteller dieses Notebooks:\n    Djabrail Abdullaev | 709070\n \n Datensatz: IBM HR Analytics Employee Attrition & Performance (WA_Fn-UseC_-HR-Employee-Attrition.csv\n     "},{"metadata":{},"cell_type":"markdown","source":"# 2. Aufgabenstellung\n\nWarum kündingen unsere wertvollsten Mitarbeiter? \n\nEine Vorhersage muss getroffen werden, welcher wichtiger Mitarbeiter als nächstes kündigt."},{"metadata":{},"cell_type":"markdown","source":"# *Dataset import und Warnings ausschalten*"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = pd.read_csv(\"../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Überblick Daten"},{"metadata":{},"cell_type":"markdown","source":"Um uns den ersten Überblick zu verschaffen, wird der Command ds.head() genutzt. Hervorragend um die ersten Zeilen und alle Spalten angezeigt zubekommen."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Als nächstes wird der Command ds.dtypes genutzt um zu sehen ob das Dataset die richtigen Typen beitzt. "},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wie man sehen kann sind object Typen vorhanden. Diese werden später modifiziert."},{"metadata":{},"cell_type":"markdown","source":"Auch möchten man wissen wieviele Zeilen und Spalten die Tabelle insgesammt besitzt. Hierfür wird ds.shape genutzt."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vorhanden sind 1470 Zeilen und 35 Spalten."},{"metadata":{},"cell_type":"markdown","source":"Um einen noch genaureren Überblick zu kriegen wird ds.info() genutzt. "},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Als nächstes wird der Command ds.describe() genutzt um die zentrale Tendenz, Streuung und Form der Verteilung des Datensatzes ohne NaN-Werte zusammenzufassen."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Als nächstes wird gezeigt ob fehlende Daten vorhanden sind."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.isnull().mean() * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Da alle Werte gleich 0 sind, wird klar dass keine Daten fehlen."},{"metadata":{},"cell_type":"markdown","source":"# 4. Visualisierung"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['Education']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['EnvironmentSatisfaction']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['RelationshipSatisfaction']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['WorkLifeBalance']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['YearsAtCompany']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['Gender']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['Gender','WorkLifeBalance']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds.groupby(['JobLevel','Gender']).size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Bereinigung des Datasets"},{"metadata":{},"cell_type":"markdown","source":"Sinnlose Spalten müssen gelöscht werden, damit kein Dataleakage verursacht wird. \nDa die wertvollsten Mitarbeiter gesucht sind, müssen zunächst einmal alle anderen aussortiert werden. \nDiese sind Mitarbeiter mit weniger als 5 Jahre 'TotalWorkingYears'.\nAuch werden Daten aussortiert, die nutzlos sind. "},{"metadata":{"trusted":true},"cell_type":"code","source":"clear_column = ['EmployeeCount', 'EmployeeNumber']\ncleared = ds.drop(columns= clear_column)\ncleared = cleared.drop(cleared[cleared['TotalWorkingYears'] < 5].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"working_years = cleared['TotalWorkingYears']\nworking_years.sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nun ist es wichtig Dummy Variablen zu erzeugen, da sjkearn nicht mit kathegorischen Variablen arbeiten kann. "},{"metadata":{"trusted":true},"cell_type":"code","source":"create_dummys = pd.get_dummies(cleared)\ncreate_dummys\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_dummys.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Im nächsten Schritt müssen Dopplungen entfernt werden, da diese dasselbe aussagen:\n*     Attrition_No\n*   Gender_Female\n* OverTime_Yes\n     "},{"metadata":{"trusted":true},"cell_type":"code","source":"clear_column = ['Attrition_No','Gender_Female','OverTime_Yes']\ndone_ds = create_dummys.drop(columns= clear_column)\ndone_ds.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clear_column = ['Attrition_Yes']\nX = done_ds.drop(columns= clear_column)\nX.head()\nX.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = done_ds['Attrition_Yes']\ny","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Im nächsten Schritt wird der Train-Test Split angewandt.\nDer Test size beträgt 30%."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 36)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Bildung von Darstellungen"},{"metadata":{},"cell_type":"markdown","source":"# Dummy Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\ndummy_model = DummyClassifier(strategy=\"most_frequent\")\ndummy_model.fit(X_train, y_train)\ndummy_model.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = dummy_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nauc_score = metrics.roc_auc_score(y_test, y_prediction)\nprint(f\"AUC score: {auc_score}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Entscheidungsbaum"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prms = {'max_depth':[1, 2, 3, 4, 5, 6, 7],\n        'splitter':['best', 'random'],\n        'max_features':['auto', 'sqrt', 'log2', None],\n        'criterion':['gini', 'entropy']\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\ngrid_model = GridSearchCV(estimator = model,\n                        param_grid = prms,\n                        scoring = 'precision', \n                        cv = 10, \n                        verbose = 1,\n                        n_jobs = -1\n                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify optimal hyperparameter values\nopt_criterion      = grid_model.best_params_['criterion']\nopt_max_features = grid_model.best_params_['max_features'] \nopt_splitter = grid_model.best_params_['splitter'] \nopt_max_depth = grid_model.best_params_['max_depth'] \n \nprint(f\"Optimal cross-validation score: {grid_model.best_score_:.3f}\")\nprint(f\"Optimal performing criterion: {opt_criterion}\")\nprint(f\"Optimal performing max_features: {opt_max_features}\")\nprint(f\"Optimal performing splitter: {opt_splitter}\")\nprint(f\"Optimal performing max_depth: {opt_max_depth}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(criterion=best_criterion, \n                                max_depth=best_max_depth,\n                                max_features = best_max_features,\n                                splitter=best_splitter,\n                                class_weight = {0:1,1:7}\n                                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)\ny_prediction = model.predict(X_test)\nauc_score = metrics.roc_auc_score(y_test, y_prediction)\nprint(f\"AUC score: {auc_score}\")\nprint(metrics.classification_report(y_test, y_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.classifier import ConfusionMatrix\ncmax = ConfusionMatrix(model, classes=['no', 'yes'],\n                        label_encoder={0: 'no', 1: 'yes'}\n                        )\ncmax.score(X_test, y_test)\ncmax.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nplt.figure(figsize = (20,20))\nplot_tree(model, feature_names=X_train.columns, class_names = ['nicht_kündigen', 'kündigen'], filled = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGB Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"prms = {'n_estimators':range(20,81,10),\n         'max_depth':range(5,9,3),\n         'min_samples_split':range(1000,2100,200),\n         'min_samples_leaf':range(10,70,20),\n         'max_features':[range(7,20,2),None],\n         'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n         'class_weight':[{0:1, 1:1},{0:1, 1:19}]\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV                         \nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV                         \nmodel = GridSearchCV(estimator = model,\n                    param_grid = prms,\n                    scoring = 'recall', \n                    cv = 10, \n                    verbose = 1,\n                    n_jobs = -1\n                    ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier()\nmodel.fit(X_train, y_train)\ny_prediction = model.predict(X_test)\nprint(metrics.classification_report(y_test, y_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.classifier import ConfusionMatrix\ncmax = ConfusionMatrix(\n            model, classes = ['no', 'yes'],\n            label_encoder = {0: 'no', 1: 'yes'}\n            )\ncmax.score(X_test, y_test)\ncmax.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_roc_curve\nrcurve = plot_roc_curve(model, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Fazit"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}