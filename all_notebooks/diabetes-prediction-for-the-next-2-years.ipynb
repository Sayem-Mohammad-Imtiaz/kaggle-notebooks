{"cells":[{"metadata":{"_uuid":"3375e4b6-b1dd-404c-9a83-3eaf360eefcf","_cell_guid":"ba219856-c1ec-4735-95e9-07e0b2967dab","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc87d2ac-ffd9-4c2e-a307-6387bd51a7f8","_cell_guid":"6b9fd6f0-d217-4979-8cae-0c3f9074d5b6","trusted":true},"cell_type":"markdown","source":"# 1. Load libraries and read the data"},{"metadata":{"_uuid":"051146d1-2e07-44f5-a35b-69c7346c838d","_cell_guid":"a4c8d2e6-ea35-44db-a8b5-16a2a55ca9c6","trusted":true},"cell_type":"markdown","source":"## 1.1. Load libraries"},{"metadata":{},"cell_type":"markdown","source":"Loading the libraries"},{"metadata":{"_uuid":"19fa7a98-a403-420b-a5ef-fc2d9e83993d","_cell_guid":"b3b26181-a620-4ba5-99ed-7e839029a598","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nfrom os.path import join\nimport copy\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\n\n#Plots\nimport sklearn\nimport missingno as msno\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport graphviz\nfrom sklearn import tree\nfrom sklearn.pipeline import make_pipeline\nimport plotly.graph_objs as go\nimport plotly.offline as py\n\n\n#Data processing, metrics and modeling\nfrom hyperopt import fmin, tpe, hp\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom xgboost import plot_tree\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, auc\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d376070-2d9a-4fe0-a3f0-ec4bea121b0d","_cell_guid":"b749c1bb-bf21-4634-bf0b-f5e82d9d4650","trusted":true},"cell_type":"markdown","source":"## 1.2. Read data"},{"metadata":{"_uuid":"98d3ff17-b291-479c-b978-71f10ec6701b","_cell_guid":"c16e4ba2-9430-4235-9486-28f143be713c","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#Use the first set of data to predict the occurence of diabetes in second dataset\ndata1=pd.read_csv('../input/korean-genome-and-epidemiology-study-koges/follow_01_data.csv')\ndata2=pd.read_csv('../input/korean-genome-and-epidemiology-study-koges/follow_02_data.csv')\ndata3=pd.read_csv('../input/korean-genome-and-epidemiology-study-koges/follow_03_data.csv')\ndata4=pd.read_csv('../input/korean-genome-and-epidemiology-study-koges/follow_04_data.csv')\ndata5=pd.read_csv('../input/korean-genome-and-epidemiology-study-koges/follow_05_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"396c41bc-c11f-47db-886c-e84a37242eb2","_cell_guid":"4f674833-1199-44cb-93b3-8868d4edac25","trusted":true},"cell_type":"markdown","source":"# 2. Data cleaning and overview"},{"metadata":{"_uuid":"ac1a9d89-aa78-4a80-adc5-5a92d84fac38","_cell_guid":"8b3ca6c1-7fff-4311-a3eb-4db558c36fb1","trusted":true},"cell_type":"markdown","source":"## 2.1. Cleaning Data"},{"metadata":{"_uuid":"6440b2c4-1c42-449c-9a27-ecc2b7bc27d9","_cell_guid":"dcc959e3-25c3-4338-ac81-5089e2f8fce0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Randomize dataset\ndf1=data1.sample(frac=1)\n\n#A list of columns that contains N/A (77777) values which can be converted into zero\nreplace_column=['T01_DRDU','T01_SOJUAM','T01_BEERAM','T01_SMDU','T01_SMAM','T01_PREG','T01_CHILD','T01_PMYN_C']\n\nfor col in replace_column:\n    df1[col].replace(77777.0,0,inplace=True)\n\n#A list of columns that contains either 1 or 2 values and therefore need to be converted into 0 and 1 respectively.\ncategorical_1_2=['T00_SEX','T01_PSM','T01_EXER','T01_HTN','T01_LIP','T01_FMFHT','T01_FMMHT','T01_FMFDM','T01_FMMDM','T01_PREG','T01_CHILD','T01_PMYN_C']\n\ndf1[categorical_1_2]=df1[categorical_1_2].replace({1.0:0,1:0,2.0:1,2:1})\n\n#Remove the samples that has either T2DM history or diagnosed with T2DM (Fasting blood glucose level >=126)\ndf2=df1.drop(df1[(df1.T01_DM==2)|(df1.T01_GLU0>=126)].index)\n\n\n#A list of columns that cannot be used for T2DM prediction\nmissing_column=['T00_DATA_CLASS','T01_EDATE','T01_SMAG','T01_HTNAG','T01_DM','T01_DMAG','T01_LIPAG','T01_FMFHTAG','T01_FMMHTAG','T01_FMFDMAG','T01_FMMDMAG','T01_MNSAG','T01_FPREGAG','T01_FLABAG','T01_PMAG_C','T01_TAKAM','T01_RICEAM','T01_WINEAM','T01_HLIQAM','T01_TAKFQ','T01_RICEFQ','T01_WINEFQ','T01_HLIQFQ']\ndf2.drop(missing_column, axis=1, inplace=True)\n\n\n#A list of columns that are categorical, thus need to be converted using get_dummies functionk\ncategorical=['T01_MARRY','T01_DRINK','T01_SMOKE']\n\n#Replace the unsurveyed(66666) and unanswered(99999) values into nan\ndf3=df2.replace(dict.fromkeys([66666.0,99999.0],None))\n\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b24a25d8-93e1-4099-b93b-84551003b5fd","_cell_guid":"b9a0763c-7480-4796-9865-7bfb74a4e880","trusted":true},"cell_type":"markdown","source":"## 2.2. Data overview"},{"metadata":{"_uuid":"992b6fca-38ba-46f9-8417-2a05f2fe7007","_cell_guid":"e3b0d68b-938e-4808-bc0e-fdf48ba8f679","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"p=df3.hist(figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1bf3584-5016-41e1-9ca6-8e2729e91d7f","_cell_guid":"d429baf8-56f2-4095-ab0f-2d0037286f5a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def missing_plot(dataset, key, name) :\n    null_feat = pd.DataFrame(len(dataset[key]) - dataset.isnull().sum(), columns = ['Count'])\n    percentage_null = pd.DataFrame((len(dataset[key]) - (len(dataset[key]) - dataset.isnull().sum()))/len(dataset[key])*100, columns = ['Count'])\n    percentage_null = percentage_null.round(2)\n\n    trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, text = percentage_null['Count'],  textposition = 'auto',marker=dict(color = '#7EC0EE',\n            line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  name)\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n    \nmissing_plot(df3, 'T00_ID', 'Missing Values (count & %)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ff021cc-c11f-4e3e-8c3b-f326e7aa7f83","_cell_guid":"24e5688b-4373-4727-9dc6-6c527d581d3b","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.style.use('ggplot') # Using ggplot2 style visuals \n\nf, ax = plt.subplots(figsize=(11, 15))\n\nax.set_facecolor('#fafafa')\nax.set(xlim=(-.05, 200))\nplt.ylabel('Variables')\nplt.title(\"Overview Data Set\")\nax = sns.boxplot(data = df3, \n  orient = 'h', \n  palette = 'Set2')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab6b46f7-09c5-4da0-8d46-f76fa6c8be68","_cell_guid":"04041a15-ca80-42a8-81de-fe444d98b2e7","trusted":true},"cell_type":"markdown","source":"## 2.3. Fill in the empty values"},{"metadata":{"_uuid":"902a7a91-6b07-4223-b19b-061a7d390259","_cell_guid":"12d6943c-db54-44ac-a589-b6ad53441169","trusted":true},"cell_type":"markdown","source":"**Replace the nan values by either mean or median value**"},{"metadata":{"_uuid":"9bd0a3fb-783b-4ce1-abe0-46e737c56b22","_cell_guid":"775e1879-d744-46f1-8eab-93f98f891e0a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"col_mean=['T01_HEIGHT','T01_WEIGHT','T01_WAIST','T01_HIP','T01_PULSE','T01_SBP','T01_DBP','T01_HBA1C','T01_GLU0','T01_TCHL','T01_HDL','T01_HBA1C']\nfor header in df3.keys():\n    if df3[header].isna().sum()>0:\n        if header in col_mean:\n            df3[header].fillna(df3[header].mean(), inplace = True)\n        else:\n            df3[header].fillna(df3[header].median(), inplace = True)\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"662bb9a7-31db-4a20-ba68-14a6daf2660e","_cell_guid":"56078a51-45b8-4c85-a1b9-9343c28c578c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"missing_plot(df3, 'T00_ID', 'Missing Values after filling (count & %)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edb104a5-5ef2-4add-9591-3982467b6fcd","_cell_guid":"4220b16a-f71b-4eb6-82f8-0d2f8d0ef203","trusted":true},"cell_type":"markdown","source":"## 2.4. Make the label using the data achieved after 2 years"},{"metadata":{"_uuid":"db723312-7341-425e-a2e7-462efc80839f","_cell_guid":"504b2050-b6e1-43bc-a5a4-502b5fe344ce","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"d2f1=data2.replace(dict.fromkeys([66666.0,77777.0,99999.0],None))\nd2f1.drop(d2f1[(d2f1.T02_DM==None)|(d2f1.T02_GLU0==None)].index, inplace=True)\nd2f1['T2DM']=(d2f1.T02_DM==2)|(d2f1.T02_GLU0>=126)\nT2DM_set=d2f1[['T00_ID','T2DM']].replace(False,0).replace(True,1)\ndf4=df3.merge(T2DM_set, on=\"T00_ID\")\nlabel=df4['T2DM']\nlabel","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e9d3ff8-a048-494e-8304-8a5fd154b5e8","_cell_guid":"49caf062-cc17-4d55-a3a0-80e72b95b4c6","trusted":true},"cell_type":"markdown","source":"## 2.5. Target"},{"metadata":{"_uuid":"a73bab54-218a-460c-b97c-95e3b02b3d83","_cell_guid":"b89b251d-fed3-4ccf-94c4-50d4408c12f1","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# 2 datasets\nD = df4[(df4['T2DM'] != 0)]\nH = df4[(df4['T2DM'] == 0)]\n\nprint(df4['T2DM'].value_counts().values.tolist())\n#------------COUNT-----------------------\ndef target_count():\n    trace = go.Bar( x = df4['T2DM'].value_counts().values.tolist(), \n                    y = ['healthy','diabetic' ], \n                    orientation = 'h', \n                    text=df4['T2DM'].value_counts().values.tolist(), \n                    textfont=dict(size=15),\n                    textposition = 'auto',\n                    opacity = 0.8,marker=dict(\n                    color=['lightskyblue', 'gold'],\n                    line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  'Count of T2DM variable')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n\n#------------PERCENTAGE-------------------\ndef target_percent():\n    trace = go.Pie(labels = ['healthy','diabetic'], values = df4['T2DM'].value_counts(), \n                   textfont=dict(size=15), opacity = 0.8,\n                   marker=dict(colors=['lightskyblue', 'gold'], \n                               line=dict(color='#000000', width=1.5)))\n\n\n    layout = dict(title =  'Distribution of T2DM variable')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n\ntarget_count()\ntarget_percent()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c97c41d-edf1-4d81-9e7a-1ef2f54e8bd9","_cell_guid":"f1821a47-6cf5-46fc-b265-94fa58e4c77a","trusted":true},"cell_type":"markdown","source":"## 2.6. StandardScaler"},{"metadata":{"_uuid":"68822105-e0c7-4a7d-a11d-f50637e99932","_cell_guid":"97561978-6277-43f0-b7a3-ce84096632f5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df4_1=df4.copy(deep=True)\nscale_column = ['T01_HEIGHT','T01_WEIGHT','T01_WAIST','T01_HIP','T01_PULSE','T01_SBP','T01_DBP','T01_CREATININE','T01_AST','T01_ALT','T01_TCHL','T01_HDL','T01_TG','T01_INS0']\nfeatures = df4_1[scale_column]\nfeatures.values\nscaler = StandardScaler()\nfeatures = scaler.fit_transform(features.values)\ndf4_1[scale_column] = features\ndf4_1.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f419191-5316-4e0d-b7d2-51321ed48ced","_cell_guid":"c42bc8ea-6be4-4369-96e7-320a2ce04fca","trusted":true},"cell_type":"markdown","source":"## 2.7. Correlation matrix"},{"metadata":{"_uuid":"461729a1-b167-4004-8275-657096d498fe","_cell_guid":"7f6be152-0189-4201-932a-2853cb720d31","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"colormap = plt.cm.viridis\nplt.figure(figsize=(10,10))\nsns.heatmap(df4_1.corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, annot=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4_1.drop('T2DM', axis=1).corrwith(df4_1.T2DM).plot(kind='bar', grid=True, figsize=(12, 8), \n                                                   title=\"Correlation with T2DM\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"683dda96-a512-43e3-88c4-439fd6e299bd","_cell_guid":"c1ab91de-bbba-4de3-872d-863641d55f2f","trusted":true},"cell_type":"markdown","source":"## 2.8. Convert categorical to seperate columns (get_dummies)"},{"metadata":{"_uuid":"cb8e0f0a-089e-4d4c-97a5-430a66c1834f","_cell_guid":"c18a8abc-6329-43db-9a9b-4b147cbb72e3","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df5=pd.get_dummies(data=df4_1,columns=categorical)\ndf5.drop(columns=['T00_ID','T2DM'], inplace=True)\ndf5.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7753fa79-ef9c-4f89-a9a0-319f3290d459","_cell_guid":"21fa5362-10b7-4065-8971-cffafd420771","trusted":true},"cell_type":"markdown","source":"## 2.9. SMOTE Oversampling"},{"metadata":{"_uuid":"acebc7f4-880b-4283-80e3-061f1118936c","_cell_guid":"547f20b8-9309-4930-911d-9641787f4816","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(df5,label,test_size=1/3,random_state=42, stratify=label)\nsmote=SMOTE(k_neighbors=5)\nsmoted_X_train,smoted_y_train=smote.fit_resample(X_train,y_train)\nsmoted_X_test,smoted_y_test=smote.fit_resample(X_test,y_test)\nsmoted_X_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f83ccf5d-53c1-449c-be40-3515e7d4e0fc","_cell_guid":"a9131a0b-5d21-4125-82c4-d04259c72615","trusted":true},"cell_type":"markdown","source":"# 3. Machine Learning"},{"metadata":{"_uuid":"ab305c29-0154-4d9a-96e3-ffbcb3de425d","_cell_guid":"6e6b83d0-a615-40db-ba24-cd62ed2a800a","trusted":true},"cell_type":"markdown","source":"## 3.1. Linear SVM, Radial SVM, LR, KNN, Decision Tree"},{"metadata":{"_uuid":"5aeb483c-9db7-4ee7-b78f-2701d340df02","_cell_guid":"e9791164-dc40-4e6a-a7f1-8d2ab002a912","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"abc=[]\nclassifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','XGBoost','LightGBM']\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(),DecisionTreeClassifier(),XGBClassifier(),LGBMClassifier()]\nfor i in models:\n    model = i\n    model.fit(smoted_X_train,smoted_y_train)\n    prediction=model.predict(smoted_X_test)\n    abc.append([roc_auc_score(smoted_y_test,prediction),accuracy_score(prediction,smoted_y_test)])\nmodels_dataframe=pd.DataFrame(abc,index=classifiers)   \nmodels_dataframe.columns=['AUC','Accuracy']\nmodels_dataframe","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23c8d871-fb7d-40f2-83d7-809bb1b72544","_cell_guid":"be76795d-9124-4c8b-b7a7-ed466b9e5013","trusted":true},"cell_type":"markdown","source":"## 3.2. Feature Extraction"},{"metadata":{"_uuid":"d5bf803d-4d60-4f0a-ac2e-27d1b2d39605","_cell_guid":"75be2705-392a-4874-ac6d-154e648f544a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nsmote=SMOTE(k_neighbors=5)\nsmoted_X,smoted_y=smote.fit_resample(df5,label)\ndf6=smoted_X.copy(deep=True)\n\n##**Remove the columns with high correlation (abs(x) > 0.8)**\n# def correlation(dataset, threshold):\n#     col_corr = set() # Set of all the names of deleted columns\n#     corr_matrix = dataset.corr()\n#     for i in range(len(corr_matrix.columns)):\n#         for j in range(i):\n#             if (abs(corr_matrix.iloc[i, j]) >= threshold) and (corr_matrix.columns[j] not in col_corr):\n#                 colname = corr_matrix.columns[i] # getting the name of column\n#                 col_corr.add(colname)\n#                 if colname in dataset.columns:\n#                     print('Delete: '+colname+\" \"+str(corr_matrix.iloc[i, j]))\n#                     del dataset[colname] # deleting the column from the dataset\n                    \n# correlation(df6,0.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61737e70-ff44-4955-aa4b-14ef38e8c60e","_cell_guid":"b57cbd84-cb4c-47ad-80d8-c9e4e1627faa","trusted":true},"cell_type":"markdown","source":"**Random Forest Classifier**"},{"metadata":{"_uuid":"2dcb8589-9d6f-46b2-b2fe-dd0ae1f94b95","_cell_guid":"a0da14f0-14db-4c03-9172-8633fb406e16","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nmodel= RandomForestClassifier(n_estimators=100,random_state=0)\nX=df6[df6.columns]\nY=smoted_y\nmodel.fit(X,Y)\nRF_list=pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False)\nRF_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3. PCA on top5 features"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df5_label=df5.copy(deep=True)\ndf5_label['T2DM']=label\nfigure, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\naxis_dic={2:[0,0],3:[0,1],4:[1,0],5:[1,1]}\nplt.subplots_adjust(left=0.125,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.2, \n                    hspace=0.35)\n\nfor num in range(2,6):\n    top_features=list(RF_list[:num].keys())\n    x=df5.loc[:,top_features].values\n    print(top_features) \n    pca = PCA(n_components=2)\n    principalComponents  = pca.fit_transform(x)\n    principalDf = pd.DataFrame(data = principalComponents\n                 , columns = ['principal component 1', 'principal component 2'])\n    finalDf = pd.concat([principalDf, df5_label['T2DM']], axis = 1)\n    subplot=axes[axis_dic.get(num)[0]][axis_dic.get(num)[1]]\n\n    subplot.set_title(str(num)+' component PCA', fontsize = 15)\n    targets = [0,1]\n    colors = ['r', 'g', 'b']\n    for target, color in zip(targets,colors):\n        indicesToKeep = finalDf['T2DM'] == target\n            \n        subplot.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n                   , finalDf.loc[indicesToKeep, 'principal component 2']\n                   , c = color\n                   , s = 50)\n    figure.text(0.5, 0.04, 'Principal Component 1', fontsize = 20, ha='center')\n    figure.text(0.04, 0.5, 'Principal Component 2', fontsize = 20, va='center', rotation='vertical')\n    ax.legend(targets)\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations:**\n1. Using only the top 2 features shows the most stratification"},{"metadata":{"_uuid":"fcc507e3-ca87-4372-8e72-47ffa4260282","_cell_guid":"76b1b3e0-5f42-4373-9986-d0a451b8e23e","trusted":true},"cell_type":"markdown","source":"## 3.4. Re-calculate the models using GLU0 and HBA1C"},{"metadata":{"_uuid":"0741a7b5-ae39-49c8-949f-3ef46ebf6a2a","_cell_guid":"35235734-7b68-4d00-9ed9-b79940f1d47f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df5_label=df5.copy(deep=True)\ndf5_label['T2DM']=label\nsns.lmplot('T01_HBA1C','T01_GLU0', data=df5_label, fit_reg=False, scatter_kws={\"s\":50},markers=[\"o\",\"x\"],hue=\"T2DM\")\nplt.title('HBA1C and GLU0 in 2d plane')\n\nsmoted_X_simple=smoted_X.loc[:,['T01_HBA1C','T01_GLU0']]\nsmoted_X_simple=smoted_X.loc[:,['T01_HBA1C','T01_GLU0']]\n\nsmoted_X_train_simple=smoted_X_train.loc[:,['T01_HBA1C','T01_GLU0']]\nsmoted_X_test_simple=smoted_X_test.loc[:,['T01_HBA1C','T01_GLU0']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d725bad-391c-4f3d-85fd-0a79f245c716","_cell_guid":"f4c54f51-3c58-4cc3-aca1-40c7c956b5c9","trusted":true},"cell_type":"markdown","source":"## 3.5. Cross Validation"},{"metadata":{"_uuid":"8fe18589-70c0-45b2-b1f6-03d4d4c3abe4","_cell_guid":"7bced3c4-b717-4eee-913b-666b8d89c888","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"xyz=[]\nroc=[]\nclassifiers=['Linear Svm','Radial Svm','LR','KNN','Decision Tree','XGBoost','LightGBM']\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(),DecisionTreeClassifier(),XGBClassifier(),LGBMClassifier()]\nfor i in models:\n    model = i\n    cv_result = cross_val_score(model,smoted_X_simple[['T01_HBA1C','T01_GLU0']],smoted_y, scoring = \"roc_auc\")\n    xyz.append(cv_result.mean())\n    roc.append(cv_result)\nnew_models_dataframe=pd.DataFrame(xyz,index=classifiers)   \nnew_models_dataframe.columns=['AUC mean']    \nnew_models_dataframe","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52b260d0-3082-45cd-a636-9b2d972afe02","_cell_guid":"9e3ee6be-b6e3-42ed-8aa6-27ff16296ce5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"box=pd.DataFrame(roc,index=classifiers)\nsns.boxplot(data=box.T)\nsns.set(rc={'figure.figsize':(15.7,8.27)})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36635f9b-939e-4595-a705-c1fd188cf237","_cell_guid":"1540797b-8ce0-4282-a94c-7ff0ecdc34c0","trusted":true},"cell_type":"markdown","source":"The above boxplot shows that XGBoost and LightGBM model perform the best while Radial SVM performs the worst."},{"metadata":{"_uuid":"e92967b9-f322-4854-b666-92b320b3b880","_cell_guid":"d4c3e077-d28d-4168-8a79-f58091a8ae19","trusted":true},"cell_type":"markdown","source":"## 3.6. XGBoost - Decision region"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = XGBClassifier().fit(smoted_X_simple.values,smoted_y.ravel())\nplot_decision_regions(smoted_X_simple.values, smoted_y.values.astype(np.integer), clf=clf, legend=2)\n\n# Adding axes annotations\nplt.xlabel('T01_HBA1C')\nplt.ylabel('T01_GLU0')\nplt.title('XGBoost with Diabetes Data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Decision region plot shows over-fitting\n* To prevent over-fitting, reduce the max_depth (default=6) and num_leaves parameter"},{"metadata":{"_uuid":"b8c7604d-cb4f-4075-ad8c-d0055483a2af","_cell_guid":"822456c1-7f20-4c80-94f1-51086626ee1b","trusted":true},"cell_type":"markdown","source":"## 3.7. Hyperparameter"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 초모수 탐색공간 정의\nparam_space = {'subsample': hp.uniform('subsample', 0.1, 0.9),\n               'learning_rate': hp.uniform('learning_rate', 0.01,0.05)\n              }\n\n# 목적함수 정의\ndef objective_xgb(params):\n    params = {'max_depth': 2,\n              'subsample': params['subsample'],\n              'learning_rate': params['learning_rate']\n             }\n    xgb_clf = XGBClassifier(n_estimators=100, **params) \n    best_score = cross_val_score(xgb_clf, smoted_X_simple[['T01_HBA1C','T01_GLU0']],smoted_y,\n                                 scoring='roc_auc', \n                                 cv=5, \n                                 n_jobs=8).mean()\n    loss = 1 - best_score\n    return loss\n\n\n# 알고리즘 실행\nbest_xgb_param = fmin(fn=objective_xgb, space=param_space, \n            max_evals=50, \n            rstate=np.random.RandomState(777), \n            algo=tpe.suggest)\n\nprint(best_xgb_param)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n1. Optimal XGB param: {'learning_rate': 0.04988810025292616, 'subsample': 0.5780885404563175, 'max_depth'=2}"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"new_xgb=XGBClassifier(max_depth=2, subsample=0.5780885404563175, learning_rate=0.04988810025292616)\n\nxyz=[]\nroc=[]\nclassifiers=['XGBoost']\n\ncv_result = cross_val_score(new_xgb,smoted_X_simple[['T01_HBA1C','T01_GLU0']],smoted_y, scoring = \"roc_auc\")\nxyz.append(cv_result.mean())\nroc.append(cv_result)\n\nnew_models_dataframe2=pd.DataFrame(xyz,index=classifiers)   \nnew_models_dataframe2.columns=['New AUC mean']\nnew_models_dataframe=new_models_dataframe.loc[['XGBoost']].merge(new_models_dataframe2,left_index=True,right_index=True,how='left')\nnew_models_dataframe['Increase']=new_models_dataframe['New AUC mean']-new_models_dataframe['AUC mean']\n\nnew_models_dataframe[['AUC mean','New AUC mean','Increase']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.8. XGBoost (Optimized) - Decision region"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=XGBClassifier(max_depth=2, subsample=0.5780885404563175, learning_rate=0.04988810025292616).fit(smoted_X_simple.values,smoted_y.ravel())\nplot_decision_regions(smoted_X_simple.values, smoted_y.values.astype(np.integer), clf=clf, legend=2)\n\n# Adding axes annotations\nplt.xlabel('T01_HBA1C')\nplt.ylabel('T01_GLU0')\nplt.title('Optimized XGBoost with Diabetes Data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58239992-198a-42ad-96a2-4a681bd88c45","_cell_guid":"5df62a99-36b5-43b2-9522-c58669edc42b","trusted":true},"cell_type":"markdown","source":"# 4. Evaluation"},{"metadata":{"_uuid":"02553b9b-6787-428b-beb7-7f4a75fa5c0e","_cell_guid":"ecde6014-1c93-471b-b034-f20350a6821b","trusted":true},"cell_type":"markdown","source":"## 4.1. Confusion metrix"},{"metadata":{"_uuid":"4cb5869b-8bc5-4687-9f51-00eb5cf3727d","_cell_guid":"0fff4c85-695f-4ba2-8853-5618513b2789","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"smoted_y_pred = clf.predict(smoted_X_test_simple.values)\ncf_matrix=confusion_matrix(smoted_y_test,smoted_y_pred)\npd.crosstab(smoted_y_test, smoted_y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"518a1dde-2fc6-4e03-a71b-6d5328ebce58","_cell_guid":"b889e39c-0cab-4c06-8832-879ba6abb9f5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"p = sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54cf438c-2664-46be-85c1-58016d685d64","_cell_guid":"0ad31a54-f471-4fa6-84f4-006a0ecf529f","trusted":true},"cell_type":"markdown","source":"## 4.2. Classification Report"},{"metadata":{"_uuid":"d81d901c-e9e8-449f-ae11-226e931c0423","_cell_guid":"396adfda-1703-47d3-89c3-2862331e2a90","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(classification_report(smoted_y_test,smoted_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4203939-1920-492d-b759-347b7eadc61f","_cell_guid":"cf1e3b92-7a80-4e35-9670-16b92a2b90b6","trusted":true},"cell_type":"markdown","source":"## 4.3. ROC curve"},{"metadata":{"_uuid":"96984d84-d351-47c4-a8d6-3dabd971a17b","_cell_guid":"157a0602-a0f5-4fcb-bc43-420d2b17e6d5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"smoted_y_pred_proba = clf.predict_proba(smoted_X_test_simple)[:,1]\nfpr, tpr, thresholds = roc_curve(smoted_y_test, smoted_y_pred_proba)\n\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Decision Tree ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ee2d825-fe09-4264-821b-e530a3f4013b","_cell_guid":"4da70b85-ade3-4683-b21a-c48303fc04d3","trusted":true},"cell_type":"markdown","source":"## 4.4. Decision Tree graph"},{"metadata":{"_uuid":"18e2252c-a585-432a-9f03-3e8bd523b531","_cell_guid":"8aef3163-792b-4d51-85b1-d0e6aa992209","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 20)) \nplot_tree(clf, rankdir=\"LR\", ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"**Results**\n* If HbA1C>5.8%, the fasting glucose level cuf-off is 90.5mg/dL\n* If not, the cut-off decrease to 88.5mg/dL\n\n**Interpretation**\n![Diabetes_cutoff](https://cdn.rcsb.org/pdb101/global-health/diabetes-mellitus/files/Blood-Test-Levels-for-Diagnosing-DM_0.PNG)\n* According to American Diabetes Association (2012) guideline, HbA1C>5.7% and fasting glucose>100mg/dL are diagnosed as 'prediabetes', and this is a global standard.\n* However, the fasting glucose cut-off calculated using ML model which is trained with Korean electronic medical records (EMR) was significantly lower than the guideline (88.5-90.5 vs 100mg/dL).\n* The difference could be explained by the ancestrial (genetic) or lifestyle difference, and further studies comparing the groups could elucidate the reason behind the difference. "},{"metadata":{},"cell_type":"markdown","source":"## 6. Usage: Diabetes risk calculator"},{"metadata":{},"cell_type":"markdown","source":"Q) Predict the diabetes risk of a patient with following features:\n* fasting glucose = 140mg/dL\n* HbA1C = 7%"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"example=np.asarray([[6.5,106]])\nprediction=clf.predict_proba(example)[0][1]\nprint('Diabetes risk = '+str(round(prediction*100,1))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da8e980f-9e1d-4519-8475-a8e59feb00bc","_cell_guid":"296dbaec-af20-48e3-953c-51babf4ae5a7","trusted":true},"cell_type":"markdown","source":"## Thank you all !"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}