{"cells":[{"metadata":{},"cell_type":"markdown","source":"##  Data Preparation \nIn this section, \n+ irrelavant and canceled orders are removed from data set;\n+ missing values are analyzed (i.e. rest days and holidays) and filled with the appropriate value (i.e. 0);\n+ trending analysis is analyzed, with dates with outlier values detected and seasonal decomposition conducted; \n+ time series analysis is conducted, showing that the series is not statioanry with the obvious yearly cycle and seasonal cycle; \n+ daily sales records are obtained (see last part of the notebook). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import packages,read csv and combine data from multiple sheets\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sb \n\ndata = pd.read_excel('../input/online-retail-ii-data-set-from-ml-repository/online_retail_II.xlsx',sheet_name=[0,1])\ndata = pd.concat([data[0],data[1]],axis=0)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete canceled orders that start with 'C'\ndata['Success'] = data['Invoice'].apply(lambda x: 'C' not in str(x))\ndata = data[data['Success']==True]\ndata = data.drop('Success',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete replenishing orders \ndata = data[data['Quantity'] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reformat the InvoiceDate to yyyy-mm-dd\ndata['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'].dt.strftime('%Y-%m-%d'))\n\ndata.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete orders on debt (irrelavant on sales)\ndata = data[data['Price'] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtain daily sales \ndata['TotalPrice'] = data['Quantity']*data['Price']\n\ngrp_date = data[['Quantity','InvoiceDate','Price','TotalPrice']].groupby('InvoiceDate')\ngrp_date = grp_date.sum()\n\nsale = grp_date[['TotalPrice']]\nsale.to_csv('DailySalesTrending.csv')\nsale","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing Values ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read daily sales' records\ndata = pd.read_csv('DailySalesTrending.csv')\n\ndata['InvoiceDate'] = data['InvoiceDate'].astype('datetime64[ns]')\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set index to be invoce date and find missing dates \ndata.set_index(data['InvoiceDate'],drop=False,inplace=True)\n\nmissing_date = pd.date_range(start ='2009-12-01', end ='2011-12-09').difference(data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print dates with missting values\nfor date in missing_date:\n    print(date.year,date.month,date.day,date.dayofweek)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are several days without sales shown above. After short analysis, it is found that:\n1. the shop seems not to operate on most Saturdays and holidays;\n1. the shop has Christmas holiday and not operates from 12-24 to 01-03 each year. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# add missing dates and fill them \ndata = data.reindex(pd.date_range(start ='2009-12-01', end ='2011-12-09'))\ndata.fillna(0,inplace=True)\ndata['InvoiceDate'] = data.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add timestamp \ndata['year'] = data['InvoiceDate'].dt.year\ndata['month'] = data['InvoiceDate'].dt.month\ndata['day'] = data['InvoiceDate'].dt.day\ndata['week'] = data['InvoiceDate'].dt.week\ndata['weekday'] = data['InvoiceDate'].dt.weekday\ndata['dayofyear'] = data['InvoiceDate'].dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Analysis ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Overall Trending ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales trending \nf = plt.figure(figsize=(20,6))\nsb.lineplot(x=data.index,y='TotalPrice',data=data).set_title('Sales Trending')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seasonal decomposition    Ref: https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult = seasonal_decompose(data['TotalPrice'], model='additive')\nresult.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The yearly cycle and seasonal cycle are observed. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Yearly Trending ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# yearly trending \nsb.boxplot(x='year',y='TotalPrice',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no obvious yearly trending, except for 2009, in which there is less data. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Outliers ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# outliers within years \nyear = data.groupby('year')\nfor year, df in year:\n    IQR = df['TotalPrice'].quantile(0.75) - df['TotalPrice'].quantile(0.25)\n    median = df['TotalPrice'].median()\n    large_outliers = df[(df['TotalPrice'] > median + 1.5*IQR)]\n    print(large_outliers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ **From October to 10th(From Week 40~49),Dec**, there is a selling peak.\n+ Other selling peaks: 29th, March, one day occuring in Week 23~24 in June, the end of September ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"From the line plot of sales trending, the peaks are observed around Oct, 10 and particularly before Christmas. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Monthly Trending ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# monthly trending \nmonth = data.groupby('month')\nmonth_sum = month.sum()\n\nf = plt.figure(figsize = (12,4))\nax = sb.lineplot(x=month_sum.index,y='TotalPrice',data=month_sum)\nax.set_title('Sales\\' Monthly Trending')\n\nf,axes = plt.subplots(1,2,figsize = (12,5))\nsb.violinplot(x='month',y='TotalPrice',data=data,ax=axes[0])\nsb.boxplot(x='month',y='TotalPrice',data=data,ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sales and day in month \nf,axes = plt.subplots(1,2,figsize = (20,5))\nsb.violinplot(x='day',y='TotalPrice',data=data,ax=axes[0])\nsb.boxplot(x='day',y='TotalPrice',data=data,ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate heatmap of sales \ndata['NormalizedPrice'] = (data['TotalPrice'] - data['TotalPrice'].mean())/data['TotalPrice'].std()\n\nf, axes = plt.subplots(1,3,figsize=(10*3,5))\nfor i, (year, group) in enumerate(data.groupby('year')):\n    hd = group.pivot_table('NormalizedPrice','weekday','week')\n    sb.heatmap(hd,ax=axes[i])\n\ndata = data.drop('NormalizedPrice',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Detailed analysis on sales' peak**:\nThe sales are larger in Week 49, around 2 weeks before Christmas.\nThere are another peaks around Week 39, which might be related to the holiday. \nHolidays are one of the important factors. \n\nPS. It can be verified that the shop doesn't operate on most Saturdays. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Time Series Analysis ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# display auto-correlation graph \nfrom pandas.plotting import autocorrelation_plot as auto_p\nplt.figure(figsize=(20,5))\nf = auto_p(data['TotalPrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nCheck if the time series is stationary by Dickey-Fuller test. \nref: https://machinelearningmastery.com/time-series-data-stationary-python/\n'''\nfrom statsmodels.tsa.stattools import adfuller\n\nX = data['TotalPrice'].values\nresult = adfuller(X)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n\tprint('\\t%s: %.3f' % (key, value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The time series is concluded not to be stationary. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('DataSet.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}