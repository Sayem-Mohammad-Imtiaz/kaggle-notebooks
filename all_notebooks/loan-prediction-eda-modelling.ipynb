{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello Data People i have tried to keep the Kernel as informative as possible ,if you like it leave a upvote ,it really motivates.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Loan Prediction Model**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lets first through some light on what a loan is actually.\n1. A loan is when money is given to another party in exchange for repayment of the loan principal amount plus interest.\n2. Loan terms are agreed to by each party before any money is advanced.\n3. A loan may be secured by collateral such as a mortgage or it may be unsecured such as a credit card.\n4. Revolving loans or lines can be spent, repaid, and spent again, while term loans are fixed-rate, fixed-payment loans.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Why there is a need to create a loan prediction model??**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I believe that when a bank lends a loan to a customer there are many factors which a bank see in order to be sure that will the customer will be able to pay the loan back or not.its easy for a bank if there are less number of people applying for the loan but as we know this is the 20th-century everyday bank will be receiving hundreds of loan request and to make the process easy we can apply Data Science in order for much smoother and Data drove decisions which can increase the chances of the bank to know whom to lend the loan and who are volatile not to lend.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Business Problem**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here I am defining a Business problem as without a problem there is no solution, banks want to simplify the loan process and make it more smooth and want to classify people to whom to lend and whom not to.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Data Source**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The Data have been taken from Kaggle ,the kingdom of Data people.\n\nWhat we will be doing though this Model Building.\n\n1. We will first analyse the Data and try to understand the Features/variables.\n2. We will then Visualize the Data for better understanding.\n3. We will then use the Machine Learning methods to Train and predict.\n4. At last we will define at what accuracy we can classify correctly.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Importing The Library And Data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we will import the libraries each one has a specific role to play.\n\n**Pandas:** pandas is a library written for the Python programming language for data manipulation and analysis.\n\n**Numpy:** NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n\n**Seaborn:** Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n\n**Matplotlib:** Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will read the data with the help of pandas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data=pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\nLoan_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory Data Analysis**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now first check the size of the Data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.shape ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#There is a short way to EDA the data its given below if you like you can use it as it will do all the EDA for you and will give you a output in the HTML format.\n\n\n'''pip install pandas-profiling\nfrom pandas_profiling import ProfileReport\nprof = ProfileReport(Loan_data)\nprof.to_file(output_file='output.html')'''","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now the best step is to look out what is the data types of the features ,if there is some missing values,how much values are there in the feature/variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now lets check how many null values are present in our data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As,we can see we have a Loan_ID as a variable it does not provide any insight about the Data ,so we will remove it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.drop(\"Loan_ID\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now ,we would like to the the statistics like Count,mean,mode,stf,quantiles..etc. of all our our Features/Variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets,see what are the name of the columns of our Data Frame.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting and finding Insights.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"As,we know the credit History Variable is object type lets convert it into object.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data['Credit_History']=Loan_data[\"Credit_History\"].astype(\"object\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking if there are any dublicates.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data.duplicated().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Below plot is a countplot of Loan_status.\n\n* Here we can see there are more cases of rejecting a loan and less case of actually acepting a loan.\n\n* Approximately loan accept is less then 50% of the loan rejected in the Bank.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loan Status.\nfigsize=(7,5)\nsns.countplot(Loan_data[\"Loan_Status\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is the countplot(frequency of Data) of Credit History with Loan Status devided in the Facetgrid.\n\n* The people who have a credit score 1 have a better chance to get a loan.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Credit_History\ngrid=sns.FacetGrid(Loan_data,col=\"Loan_Status\",size=3.5)\ngrid.map(sns.countplot,\"Credit_History\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this is the countplot of the gender with their loan Status.\n\n* Most of the people who got the loan are Male,Female stays low in both the case.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gender\ngrid=sns.FacetGrid(Loan_data,col=\"Loan_Status\",size=3.5)\ngrid.map(sns.countplot,\"Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is the countplot of marriage with their loan status.\n\n* Most of the people who got the loan is Married.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Marriage\ngrid=sns.FacetGrid(Loan_data,col=\"Loan_Status\",size=3.5)\ngrid.map(sns.countplot,\"Married\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this is the countplot of the dependents with their loan Status.\n\n* Most of the poeple who got the loan has 0 dependents.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#dependents \nplt.figure(figsize=(8,5))\nsns.countplot(x=\"Dependents\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this countplot of Education with there loan Status show that:\n\n* most of the people who got the loan is Graduate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Education\nplt.figure(figsize=(7,6))\nsns.countplot(x=\"Education\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this countplot of self employed with their loan status shows that:\n\n* most of the peopel who got the loan is  not self employed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Self employed\nplt.figure(figsize=(8,5))\nsns.countplot(x=\"Self_Employed\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this countplot of property area with loan status shows that:\n\n* most of the people who got the loan lives in semi urban area.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#property area \nplt.figure(figsize=(7,5))\nsns.countplot(x=\"Property_Area\",hue=\"Loan_Status\",data=Loan_data,saturation=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in this barplot we cab see it is grouped by property area and then by education ,which is the plotted by average loan amount on y axis.\n\n* it gives out the insight that:\n\n* Graduate people in all the property area are taking off a high amount of average loan amount. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_mean_amount = Loan_data.groupby(['Property_Area','Education'])['LoanAmount'].mean().reset_index()\n\nplt.figure(figsize=(9,6))\nsns.barplot(x='Property_Area',y='LoanAmount',hue='Education',data=Loan_data)\nplt.xlabel(\"Property Area of Education\")\nplt.ylabel(\"Average loan amount\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets work on the cateagorical data and numerical data seperately now .","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cateagorical_data=[]\nNumerical_data=[]\n\nfor i,c in enumerate(Loan_data.dtypes):\n  if c==object:\n    cateagorical_data.append(Loan_data.iloc[:,i])\n  else:\n      Numerical_data.append(Loan_data.iloc[:,i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cateagorical_data=pd.DataFrame(cateagorical_data).transpose()\nNumerical_data=pd.DataFrame(Numerical_data).transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets see how our Cateagorical Data looks like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cateagorical_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets take a look in Numerical Data we have.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Numerical_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nNow,here we want to fill our Null values in the Cateagorical Data by the most number of repeated values in that Feature Column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cateagorical_data=cateagorical_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\ncateagorical_data.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now,in Case of our Numerical Data we will will the Null values with the Help of Mean of that Feature/variable Column because an average explains the Data more precisely.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Numerical_data=Numerical_data.apply(lambda x:x.fillna(x.mean()))\nNumerical_data.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will import our LabelEncoder so that we can encode our Cateagorical Data into the o and 1 so that further it will be easy to know the correlation among them with the help of correlation matrix.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nLE=LabelEncoder()\n\nLabel_value={\"Y\":0,\"N\":1}\nLabel=cateagorical_data[\"Loan_Status\"]\ncateagorical_data.drop(\"Loan_Status\",axis=1,inplace=True)\nLabel=Label.map(Label_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here,using the fit_transform we are applying the Label_encoding in one go with fitting and transforming.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cateagorical_data:\n  cateagorical_data[i]=LE.fit_transform(cateagorical_data[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now,lets see how our Cateagorical Data looks like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cateagorical_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the Labels,which is our dependent variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now,we will coccat all the Cateagorical data,Numerical Data and label to form a single Data frame named Loan Data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_data=pd.concat([cateagorical_data,Numerical_data,Label],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let us plot the correlation matrix.\n\n* We have seen no feature pose a high correlation with any other feature so there is no need to club or remove any feature.\n\n* Though loan amount and application income have a good correation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.title(\"Correlation Matrix\")\nsns.heatmap(Loan_data.corr(),annot=True,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modelling**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For the process of modelling we have to first split the data into Train and Test data .","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=pd.concat([cateagorical_data,Numerical_data],axis=1)\nY=Label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that we have done the 70% train and 30% split.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=28)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we wil import the models we want to use:\n\n* LogisticRegression\n\n* KNeighborsClassifier\n\n* DecisionTreeClassifier\n\n* RandomForestClassifier\n\n* AdaBoostClassifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Notice that we have kept the random see to 28 so that every time we run it, selects the same randomness and we get the same output.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nmodels={\"LogisticRegression\":LogisticRegression(random_state=28),\n        \"KNeighborsClassifier\":KNeighborsClassifier(),\n        \"DecisionTreeClassifier\":DecisionTreeClassifier(max_depth=1,random_state=28),\n        \"RandomForestClassifier\":RandomForestClassifier(n_estimators=400,oob_score=True,random_state=28,n_jobs=-1),\n        \"AdaBoostClassifier\":AdaBoostClassifier(random_state=28)\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now models have been built we,will like to see how well they perform for that we are suing the 2 score.\n\n* precision_score\n\n* accuracy_score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score,accuracy_score\n\ndef loss(y_true,y_pred,retu=False):\n  pre=precision_score(y_true,y_pred)\n  acc=accuracy_score(y_true,y_pred)\n\n\n  if retu:\n    return pre,acc\n  else:\n      print(' pre: %.3f\\n  acc: %.3f\\n '%(pre,acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At last we will print the accucracy of all the models.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_pred_score(models,x,y):\n  for name,model in models.items():\n    print(name,\" :\")\n    model.fit(x,y)\n    loss(y,model.predict(x))\n    print(\"-\"*30)\n\ntrain_pred_score(models,x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Form the various model we have plot here we can see that AdaBoostClassifier is performing the best as ,it is classifying all the Data points which were not classified in the first stumps and so on.**\n\n\nWe could do a ensemble modelling to (votting) but as our model reached 91% it not recommended to do ensemble,you can try in will enventually will decrease the accuracy.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}