{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Familiar imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import ceil # round numbers up\n%matplotlib inline\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training random forest model\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T15:35:02.424543Z","iopub.execute_input":"2021-08-24T15:35:02.425033Z","iopub.status.idle":"2021-08-24T15:35:03.772668Z","shell.execute_reply.started":"2021-08-24T15:35:02.424988Z","shell.execute_reply":"2021-08-24T15:35:03.771526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Load the data\nNext, we'll load the training and test data.","metadata":{}},{"cell_type":"code","source":"# Load the training data\ntrain = pd.read_csv(\"../input/30-days-of-ml/train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/30-days-of-ml/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:03.774265Z","iopub.execute_input":"2021-08-24T15:35:03.774569Z","iopub.status.idle":"2021-08-24T15:35:08.426915Z","shell.execute_reply.started":"2021-08-24T15:35:03.77454Z","shell.execute_reply":"2021-08-24T15:35:08.425863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA\nlet's see the distribution of the target variable","metadata":{}},{"cell_type":"code","source":"bins = np.arange(0, 12, 0.1)\nsns.displot(train.target, height = 5, aspect = 2, bins = bins)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:08.428802Z","iopub.execute_input":"2021-08-24T15:35:08.429147Z","iopub.status.idle":"2021-08-24T15:35:09.284395Z","shell.execute_reply.started":"2021-08-24T15:35:08.429114Z","shell.execute_reply":"2021-08-24T15:35:09.28286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (20, 15))\n# Mask to hide upper-right part of plot as it is a duplicate\nmask = np.transpose(np.tril(np.ones(train.corr().shape)))\nsns.heatmap(train.corr(), annot = True, center = 0, cmap = 'RdBu', mask = mask)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:09.285976Z","iopub.execute_input":"2021-08-24T15:35:09.286307Z","iopub.status.idle":"2021-08-24T15:35:10.902376Z","shell.execute_reply.started":"2021-08-24T15:35:09.286276Z","shell.execute_reply":"2021-08-24T15:35:10.901013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that target is weakly correlated with all features","metadata":{}},{"cell_type":"code","source":"num_cols = [col for col in train.columns if 'cont' in col] \nnum_cols","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:10.903962Z","iopub.execute_input":"2021-08-24T15:35:10.90444Z","iopub.status.idle":"2021-08-24T15:35:10.913114Z","shell.execute_reply.started":"2021-08-24T15:35:10.904379Z","shell.execute_reply":"2021-08-24T15:35:10.911591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(data, cols, features_type, nrows, ncols, bins='auto', target=None, figsize=None,\n         hspace=None, wspace=None, color = None):\n    '''plot all features vs target or the distribution of features'''\n    if figsize != None:\n        plt.figure(figsize = figsize)\n    for col, plot_num in zip(cols, list(range(1, len(cols)))):\n        plt.subplot(nrows, ncols, plot_num)\n        if hspace != None or wspace != None:\n            plt.subplots_adjust(hspace = hspace, wspace = wspace)\n            \n        if features_type == 'numerical':\n            if target != None:\n                plt.scatter(data[col], data[target])\n                plt.title(col)\n            else:\n                sns.histplot(data[col], bins=bins)\n                \n        if features_type == 'categorical':\n            if target != None:\n                sns.violinplot(data=data, y=col, x=target, color=color, inner='quartile');\n            else:\n                countplot_ratio(x = col, data = data, color = color)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:10.914849Z","iopub.execute_input":"2021-08-24T15:35:10.91535Z","iopub.status.idle":"2021-08-24T15:35:10.927052Z","shell.execute_reply.started":"2021-08-24T15:35:10.915298Z","shell.execute_reply":"2021-08-24T15:35:10.926168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distributions of numerical features","metadata":{}},{"cell_type":"code","source":"n_cols = 4\nn_rows = ceil(len(num_cols)/n_cols)\nbins = np.arange(0, 1.3, 0.02)\nplot(data=train, cols=num_cols, features_type='numerical', nrows=n_rows, ncols=n_cols, hspace=0.3, wspace=0.5, bins=bins,\n    figsize = (15, 15))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:10.928156Z","iopub.execute_input":"2021-08-24T15:35:10.928476Z","iopub.status.idle":"2021-08-24T15:35:17.943057Z","shell.execute_reply.started":"2021-08-24T15:35:10.928446Z","shell.execute_reply":"2021-08-24T15:35:17.94187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's see the distribution of continuous variable vs target","metadata":{}},{"cell_type":"code","source":"n_cols = 4\nn_rows = ceil(len(num_cols)/n_cols)\nplot(data=train, target='target', cols=num_cols, features_type='numerical', nrows=n_rows, ncols=n_cols, hspace=0.3,\n    figsize = (15, 15))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:17.946672Z","iopub.execute_input":"2021-08-24T15:35:17.947053Z","iopub.status.idle":"2021-08-24T15:35:33.400666Z","shell.execute_reply.started":"2021-08-24T15:35:17.94702Z","shell.execute_reply":"2021-08-24T15:35:33.399688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of categorical columns\nobject_cols = [col for col in train.columns if 'cat' in col]\nobject_cols","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:33.402645Z","iopub.execute_input":"2021-08-24T15:35:33.403083Z","iopub.status.idle":"2021-08-24T15:35:33.41181Z","shell.execute_reply.started":"2021-08-24T15:35:33.403035Z","shell.execute_reply":"2021-08-24T15:35:33.410816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distributions of categorical features","metadata":{}},{"cell_type":"code","source":"# function to plot the distribution of categorical variable \n# since the countplot function show the counts of observations in each categorical bin using bars.\ndef countplot_ratio(x = None, data = None, hue = None, ax = None, color = None):\n    # plot the variable\n    ax = sns.countplot(x, data = data, hue = hue, ax = ax, color = color)\n    # names of x labels\n    ax.set_xticklabels(ax.get_xticklabels())\n    # plot title\n    ax.set_title(x + \" Distribution\")\n    # total number of data which used to get the proportion\n    total = float(len(data))\n    # for loop to iterate on the patches\n    for patch in ax.patches:\n        # get the height of the patch which represents the number of observations.\n        height = patch.get_height()\n        # Put text on each patch with the proportion of the observations\n        ax.text(patch.get_x()+patch.get_width()/2,height+4,'{:.2f}%'.format((height/total)*100),weight = 'bold',\n                fontsize = 12,ha = 'center')","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:33.41329Z","iopub.execute_input":"2021-08-24T15:35:33.41361Z","iopub.status.idle":"2021-08-24T15:35:33.425689Z","shell.execute_reply.started":"2021-08-24T15:35:33.41358Z","shell.execute_reply":"2021-08-24T15:35:33.424599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_cols = 2\nn_rows = ceil(len(object_cols)/n_cols)\nbase_color = sns.color_palette(n_colors=2)[1]\nplot(data=train, cols=object_cols, features_type='categorical', nrows=n_rows, ncols=n_cols,\n     hspace=0.5, figsize = (15, 20), color=base_color)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:33.42736Z","iopub.execute_input":"2021-08-24T15:35:33.427688Z","iopub.status.idle":"2021-08-24T15:35:38.539279Z","shell.execute_reply.started":"2021-08-24T15:35:33.427656Z","shell.execute_reply":"2021-08-24T15:35:38.538035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_cols = 3\nn_rows = ceil(len(object_cols)/n_cols)\nplot(data=train, target='target', cols=object_cols, features_type='categorical',\n     nrows=n_rows, ncols=n_cols, hspace=0.5, figsize = (15, 20), color=base_color)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:38.541009Z","iopub.execute_input":"2021-08-24T15:35:38.541453Z","iopub.status.idle":"2021-08-24T15:35:49.677155Z","shell.execute_reply.started":"2021-08-24T15:35:38.541405Z","shell.execute_reply":"2021-08-24T15:35:49.675971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next code cell separates the target (which we assign to y) from the training features (which we assign to features).","metadata":{}},{"cell_type":"code","source":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:49.678801Z","iopub.execute_input":"2021-08-24T15:35:49.679281Z","iopub.status.idle":"2021-08-24T15:35:49.738342Z","shell.execute_reply.started":"2021-08-24T15:35:49.679233Z","shell.execute_reply":"2021-08-24T15:35:49.737333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Prepare the data\nNext, we'll need to handle the categorical columns (cat0, cat1, ... cat9).","metadata":{}},{"cell_type":"code","source":"# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:49.739612Z","iopub.execute_input":"2021-08-24T15:35:49.739931Z","iopub.status.idle":"2021-08-24T15:35:53.907984Z","shell.execute_reply.started":"2021-08-24T15:35:49.739901Z","shell.execute_reply":"2021-08-24T15:35:53.906926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we break off a validation set from the training data.","metadata":{}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:35:53.909335Z","iopub.execute_input":"2021-08-24T15:35:53.909674Z","iopub.status.idle":"2021-08-24T15:35:54.037134Z","shell.execute_reply.started":"2021-08-24T15:35:53.909633Z","shell.execute_reply":"2021-08-24T15:35:54.036214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Train a model\nNow that the data is prepared, the next step is to train a model.","metadata":{}},{"cell_type":"code","source":"# Define the model \nmodel = XGBRegressor(n_estimators=1000, learning_rate=0.03, random_state=1, n_jobs=2)\n\n# Train the model \nmodel.fit(X_train, y_train, early_stopping_rounds = 20, eval_set=[(X_valid, y_valid)], verbose=False)\npreds_valid = model.predict(X_valid)\nprint(mean_squared_error(y_valid, preds_valid, squared=False))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:37:05.052052Z","iopub.execute_input":"2021-08-24T15:37:05.052445Z","iopub.status.idle":"2021-08-24T15:45:48.55073Z","shell.execute_reply.started":"2021-08-24T15:37:05.052409Z","shell.execute_reply":"2021-08-24T15:45:48.549538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the code cell above, we set squared=False to get the root mean squared error (RMSE) on the validation data.","metadata":{}},{"cell_type":"markdown","source":"### Step 5: Submit to the competition\nWe'll begin by using the trained model to generate predictions, which we'll save to a CSV file.","metadata":{}},{"cell_type":"code","source":"# Use the model to generate predictions\npredictions = model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:54:18.608328Z","iopub.execute_input":"2021-08-24T15:54:18.608742Z","iopub.status.idle":"2021-08-24T15:54:21.671792Z","shell.execute_reply.started":"2021-08-24T15:54:18.608703Z","shell.execute_reply":"2021-08-24T15:54:21.670797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}