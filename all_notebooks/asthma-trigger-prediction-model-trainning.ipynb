{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport random\nimport os\nimport tensorflow as tf\nimport math\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport re\nimport tensorflow.keras.applications.efficientnet as eff\nimport tensorflow.keras.applications as tfka\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nimport gc\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom tqdm.notebook import tqdm\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2021-06-19T04:10:39.379341Z","iopub.execute_input":"2021-06-19T04:10:39.379971Z","iopub.status.idle":"2021-06-19T04:10:58.031744Z","shell.execute_reply.started":"2021-06-19T04:10:39.379847Z","shell.execute_reply":"2021-06-19T04:10:58.029924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T04:10:58.034317Z","iopub.execute_input":"2021-06-19T04:10:58.034912Z","iopub.status.idle":"2021-06-19T04:11:04.577397Z","shell.execute_reply.started":"2021-06-19T04:10:58.034848Z","shell.execute_reply":"2021-06-19T04:11:04.575926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration\n# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\nEPOCHS = 10\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [256, 256]\n# Seed\nSEED = 9527\nseed = 9527\n# Learning rate\nLR = 0.0005\n# Verbosity\nVERBOSE = 2\n# Label_dim\nlabel_dim = 1\n\n# dataset path\npath = \"../input/asthma-trigger-dataset/food_ingredients_dataset.csv\"\nimg_path = '../input/food-ingredients-and-recipe-dataset-with-images/Food Images/Food Images/'\nGCS_PATH = KaggleDatasets().get_gcs_path('asthamtest')\n\ntrain_set = tf.io.gfile.glob(GCS_PATH + '/train' + '*.tfrec')\nval_set = tf.io.gfile.glob(GCS_PATH + '/val' + '*.tfrec')\n\n\n# common food allergens\ncommon_allergens = {\n    'cows milk': {'Cheese', 'Butter', 'Margarine', 'Yogurt', 'Cream', 'Ice cream'},\n    'eggs': {'egg'},\n    'tree nuts': {'Brazil nut', 'Almond', 'Cashew', 'Macadamia nut', 'Pistachio','Pine nut','Walnut'},\n    'peanuts': {'peanut'},\n    'shellfish': {'Shrimp','Prawn','Crayfish', 'Lobster', 'Squid', 'Scallops'},\n    'wheat': {'flour', 'wheat', 'pasta', 'noodle', 'bread', 'crust'},\n    'soy': {'soy', 'tofu', 'soya'},\n    'fish': {'fish', 'seafood'}\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-19T04:11:04.580113Z","iopub.execute_input":"2021-06-19T04:11:04.580635Z","iopub.status.idle":"2021-06-19T04:11:05.045893Z","shell.execute_reply.started":"2021-06-19T04:11:04.580581Z","shell.execute_reply":"2021-06-19T04:11:05.04485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \n# Data augmentation function\ndef data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n    return image, label\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"cows_milk\": tf.io.FixedLenFeature([], tf.int64),\n        \"eggs\": tf.io.FixedLenFeature([], tf.int64),\n        \"tree nuts\": tf.io.FixedLenFeature([], tf.int64),\n        \"peanuts\": tf.io.FixedLenFeature([], tf.int64),\n        \"shellfish\": tf.io.FixedLenFeature([], tf.int64),\n        \"wheat\": tf.io.FixedLenFeature([], tf.int64),\n        \"soy\": tf.io.FixedLenFeature([], tf.int64),\n        \"fish\": tf.io.FixedLenFeature([], tf.int64),\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    \n    image = decode_image(example['image'])\n    milk = tf.cast(example['cows_milk'], tf.float32)\n    eggs = tf.cast(example['eggs'], tf.float32)\n    nuts = tf.cast(example['tree nuts'], tf.float32)\n    peanuts = tf.cast(example['peanuts'], tf.float32)\n    shellfish = tf.cast(example['shellfish'], tf.float32)\n    wheat = tf.cast(example['wheat'], tf.float32)\n    soy = tf.cast(example['soy'], tf.float32)\n    fish = tf.cast(example['fish'], tf.float32)\n    # label = [milk, eggs, nuts, peanuts, shellfish, wheat, soy, fish]\n    label = tf.cast(example[target], tf.float32)\n    return  image, label\n\ndef load_dataset(filenames, target, ordered = False):\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n    return dataset\n\n# This function is to get our training tensors\ndef get_training_dataset(filenames, target, ordered = False):\n    dataset = load_dataset(filenames, target, ordered = ordered)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our validation tensors\ndef get_validation_dataset(filenames, target, ordered = True):\n    dataset = load_dataset(filenames, target, ordered = ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) \n    return dataset\n\n# Function to count how many photos we have in\ndef count_data_items(filenames):\n    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(train_set)\nprint(f'Dataset: {NUM_TRAINING_IMAGES} training images')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T04:11:05.047393Z","iopub.execute_input":"2021-06-19T04:11:05.047687Z","iopub.status.idle":"2021-06-19T04:11:05.077936Z","shell.execute_reply.started":"2021-06-19T04:11:05.047653Z","shell.execute_reply":"2021-06-19T04:11:05.076451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for a custom learning rate scheduler with warmup and decay\ndef get_lr_callback():\n    # lr_start   = 0.0000001\n    # lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.0000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < EPOCHS/2:\n            lr = 0.000001 * (BATCH_SIZE - epoch)\n        else:\n            lr = lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback\n\n\n\ndef get_model(mode):\n\n    with strategy.scope():\n\n        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp')\n        print(f'load Model_{mode}')\n        if mode == 'eff0':\n            x = efn.EfficientNetB0(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff1':\n            x = efn.EfficientNetB1(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff2':\n            x = efn.EfficientNetB2(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff3':\n            x = efn.EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff4':\n            x = efn.EfficientNetB4(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff5':\n            x = efn.EfficientNetB5(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff6':\n            x = efn.EfficientNetB6(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'eff7':\n            x = efn.EfficientNetB7(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'ICPV2':\n            x = tfka.InceptionResNetV2(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'ICPV3':\n            x = tfka.InceptionV3(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'XCP':\n            x = tfka.Xception(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'VGG16':\n            x = tfka.VGG16(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'VGG19':\n            x = tfka.VGG19(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 'RN50':\n            x = tfka.ResNet50(weights = 'imagenet', include_top = False)(inp)\n        else:\n            # 'RN101'\n            x = tfka.ResNet101(weights = 'imagenet', include_top = False)(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        \n        output = tf.keras.layers.Dense(label_dim, activation='sigmoid')(x)\n\n        model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n\n        model.compile(\n            optimizer = opt,\n            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n            metrics = [tf.keras.metrics.Precision()]\n            ) \n        \n        return model","metadata":{"execution":{"iopub.status.busy":"2021-06-19T04:11:05.079205Z","iopub.execute_input":"2021-06-19T04:11:05.079527Z","iopub.status.idle":"2021-06-19T04:11:05.10102Z","shell.execute_reply.started":"2021-06-19T04:11:05.079497Z","shell.execute_reply":"2021-06-19T04:11:05.099994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_mapping_check(dataset):\n    counter = 0\n    record = []\n    while counter < dataset.shape[0]-1:\n        row = dataset.loc[counter]\n        img_name = row['Image_Name']\n        img = cv2.imread(img_path+img_name+'.jpg')\n        try:\n            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n        except:\n            record.append(counter)\n        counter+= 1\n    new = dataset.drop(record, axis = 0)\n    new = new.reset_index(drop = True)\n    return new\n\ndef allergens_mapping(row, types):\n    for item in common_allergens[types]:\n        if item.lower() in row.lower():\n                return 1\n    return 0\n\ndef get_weights(target):\n    path = \"../input/food-ingredients-and-recipe-dataset-with-images/Food Ingredients and Recipe Dataset with Image Name Mapping.csv\"\n    df = pd.read_csv(path)\n    df = image_mapping_check(df)\n    df['cows_milk'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'cows milk'))\n    df['eggs'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'eggs'))\n    df['tree nuts'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'tree nuts'))\n    df['peanuts'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'peanuts'))\n    df['shellfish'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'shellfish'))\n    df['wheat'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'wheat'))\n    df['soy'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'soy'))\n    df['fish'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'fish'))\n    x_train, x_val, y_train, y_val = train_test_split(df[['Image_Name']], df.iloc[:,6:14], shuffle = True, random_state = seed, test_size = 0.25)\n    weight_0 = 1\n    weight_1 = (len(y_train)-y_train[target].sum())/y_train[target].sum() *1.5\n\n    \n    class_weights = {\n        0: weight_0, \n        1: weight_1\n    }\n    return class_weights","metadata":{"execution":{"iopub.status.busy":"2021-06-19T04:15:28.982692Z","iopub.execute_input":"2021-06-19T04:15:28.98324Z","iopub.status.idle":"2021-06-19T04:15:28.999117Z","shell.execute_reply.started":"2021-06-19T04:15:28.983199Z","shell.execute_reply":"2021-06-19T04:15:28.997917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate(target):\n\n    # Seed everything\n    seed_everything(SEED)\n    \n    print('\\n')\n    print('-'*50)\n    \n    train_dataset = get_training_dataset(train_set, target, ordered = False)\n    val_dataset = get_validation_dataset(val_set, target, ordered = True)\n    STEPS_PER_EPOCH = count_data_items(train_set) // BATCH_SIZE\n    K.clear_session()\n    model = get_model(mode)\n    # Model checkpoint\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'Model_{mode}_{target}_{SEED}.h5', \n                                                    monitor = 'val_loss', \n                                                    verbose = VERBOSE, \n                                                    save_best_only = True,\n                                                    save_weights_only = True, \n                                                    mode = 'min')\n\n    class_weight = get_weights(target)\n    \n    history = model.fit(train_dataset,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        class_weight=class_weight,\n                        epochs = EPOCHS,\n                        callbacks = [checkpoint, get_lr_callback()], \n                        validation_data = val_dataset,\n                        verbose = VERBOSE)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T21:22:16.665778Z","iopub.execute_input":"2021-06-04T21:22:16.666175Z","iopub.status.idle":"2021-06-04T21:22:16.685338Z","shell.execute_reply.started":"2021-06-04T21:22:16.666131Z","shell.execute_reply":"2021-06-04T21:22:16.684131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = ['eff1','eff2','eff3','eff4','eff5','eff6','eff7','XCP', 'RN50']\ntargets = [\"cows_milk\", \"eggs\", \"tree nuts\", \"peanuts\", \"shellfish\", \"wheat\", \"soy\", \"fish\"]\nfor target in targets:\n    for mode in models:\n        print('prediction target is', target)\n        train_and_evaluate(target)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T02:26:24.635696Z","iopub.execute_input":"2021-06-18T02:26:24.636127Z","iopub.status.idle":"2021-06-18T02:26:24.712599Z","shell.execute_reply.started":"2021-06-18T02:26:24.636045Z","shell.execute_reply":"2021-06-18T02:26:24.711267Z"},"trusted":true},"execution_count":null,"outputs":[]}]}