{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Library required for failed attempt\n# !pip install dirty_cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 1\n### (a) Explain random forest technique.\nRandom forest is a machine learning technique for classification, regression, and other tasks that operates by constructing **multiple decision tress** (_with randomly sampled training data and subset of features_) during the training stage and outputting the class that is the **mode of the classes** (for _classification_ problems), or the **mean of the prediction values** (for _regression_ problems).\n\n### (b) Which types of dataset benefit more from this technique?\n1. It works better for classification problems since that is what decision tress are good at\n2. It works better (than linear regression) when there is no strong linear relation between the features and the target variable\n3. It works better when the dataset is large\n4. It works better with high dimensional data\n5. It also works well with unbalanced data sets\n\n### \\(c\\) Can you use it for dimensionality reduction? If yes, how? (no coding required)\n\nYes. One possible approach is to generate a large number of shallow trees with small subsets of the features against the same target value. The features that frequently get high ranking are more likely to be important.\n\n## Question 2"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import libraries in a separate cell for autocompletion\nimport numpy as np\nimport pandas as pd\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n# import matplotlib.pyplot as plt\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Read all the data to memory\nraw_data = pd.read_csv('/kaggle/input/craigslistVehiclesFull.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (a) Extract Los Angeles information"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop URLs since we are not going to access them anyway in this project\ndf = raw_data.drop(['url', 'image_url'], axis=1)\n# Also drops Vehicle Identification Number.\n# Because while it is very useful in real-life, only 22.7% of the entries have it\n# in our dataset (LA only). Constructing the parser and map it to corresponding fields\n# can be time-consuming and considered out of scope for this midterm.\n# However, it would be interesting to see if having a VIN listed will impact the price\ndf.vin = df.vin.isna()\n# Select the rows that have `city` equals `losangeles`\ndf = df[df.city == 'losangeles']\n# Drop columns related to geolocation, since the region is now fixed\ndf.drop(list(df.filter(regex='state|county|city')), axis=1, inplace=True)\n# Reset the index for easier processing\ndf.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (b) Reduce the number of attributes to those which are more important in price prediction (has the most variance with respect to price)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cor = df.dropna().corr()\ncor_target = abs(cor['price'])\ncor_target.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's interesting to see that longitude has a strong correlation with the price. Although they are all relatively weak correlations, based on the data above, the column `lat` and `weather` can be dropped since they are too weak."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the badly performed numerical columns\ndf.drop(['weather', 'lat'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, the correlation values only give us information about numerical columns. Since we also want to select categorical columns, we decided to compute mutual information and perform an ANOVA test."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Temoprarily drop NaN for feature selection\n_df = df.dropna()\nXtrain = _df.drop(['price'], axis=1).T.to_dict().values()\nYtrain = _df['price']\n# Vectorize the categorical values\ndv = DictVectorizer()\ndv.fit(Xtrain)\n\nX_vec = dv.transform(Xtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scores = mutual_info_classif(X_vec, Ytrain)\n\nfor score, fname in sorted(zip(feature_scores, dv.get_feature_names()), reverse=True)[:10]:\n    print(fname, score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_scores = f_classif(X_vec, Ytrain)[0]\n\ncount = 0\nfor score, fname in sorted(zip(feature_scores, dv.get_feature_names()), reverse=True):\n    if np.isinf(score):\n        continue\n    if count == 10:\n        break\n    print(fname, score)\n    count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that \\[odometer, long, year, condition, drive, type\\] are some of the most related features based on mutual information (`vin` won't be included since it was crafted for exploration only, as mentioned before). While the `make` column also provides important information based on the ANOVA test result, it is too dirty to use directly. Therefore, we will select the above most significant columns, and preserve `make` for further processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_lite = df[['price', 'odometer', 'long', 'year', 'condition', 'drive', 'type', 'make']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (c) Deal with lost data and outliners (Data cleaning)\nJust to be safe, we decided to start only with rows that does not have missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cleaned = df_lite.dropna()\ndf_cleaned = df_cleaned[df_cleaned.price > 100]\ndf_cleaned.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (d) Shuffle the dataset and split it into a training set and test set (e.g. 80% training 20% test)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess the categorical columns\nencoded = pd.get_dummies(df_cleaned.drop(['make'], axis=1))  # drop `make` column for now\nX = encoded.drop(['price'], axis=1)\ny = encoded['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=569)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (e) Use your favourite machine learning language and packages and train a decision tree to predict a used car price. Be aware of overfitting and prune your tree if needed.\nTuning the `max_depth` and `min_samples_split` should help reduce overfitting. Therefore, we can perform a grid search to find the best parameter set."},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    'max_depth':range(3,20),\n    'min_samples_split':range(2,20),\n    'min_samples_leaf':range(1,20),\n    'max_features':[None, 'sqrt']\n}\nreg = GridSearchCV(DecisionTreeRegressor(), parameters, cv=10, n_jobs=4)\nreg.fit(X=X_train, y=y_train)\ntree_model = reg.best_estimator_\nprint (reg.best_score_, reg.best_params_) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (f) Report the training performance using 10-fold cross validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"means = reg.cv_results_['mean_test_score']\nstds = reg.cv_results_['std_test_score']\nmean, std, params = list(zip(means, stds, reg.cv_results_['params']))[reg.best_index_]\nprint(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (g) Report the testing performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"modelPred = tree_model.predict(X_test)\nmse = mean_squared_error(y_test, modelPred)\nprint('MSE: ', mse)\nrmse = np.sqrt(mse)\nprint('RMSE:', rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently, the performance is not great. One of the possible reasons is that we discarded the `make` and `vin` column for simplicity. Since the model of the vehicle should be a major factor when determining the price, losing such information could impact the performance greatly.\n\nIn the future, we can attempt to write a VIN parser to reliably extract vehicle information and populate the columns accordingly. We can also try to use NLP techniques to extract keywords from the `make` column to make it cleaner."},{"metadata":{},"cell_type":"markdown","source":"### Appendix: Failed Attempts with Similarity Encoding\nIn order to make use of the `make` column, we attempted to use similarity encoding to deal with the dirty categorical data. However, it seems that scikit-learn changed the function signature of `_check_X` in `OneHotEncoder` class, which is used by the `dirty_cat` library. Attempting to bypass the said function forcibly resulted in no success."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"```python\nclean_columns = {\n    'odometer': 'numerical',\n    'long': 'numerical',\n    'year': 'numerical',\n    'condition': 'one-hot',\n    'vin': 'numerical',\n    'drive': 'one-hot',\n    'type': 'one-hot'\n}\n\nencoding_methods = ['one-hot', 'target', 'similarity']\ndirty_column = 'make'\n\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom dirty_cat import SimilarityEncoder, TargetEncoder\n\nencoders_dict = {\n    'one-hot': OneHotEncoder(handle_unknown='ignore', sparse=False),\n    'similarity': SimilarityEncoder(similarity='ngram'),\n    'target': TargetEncoder(handle_unknown='ignore'),\n    'numerical': FunctionTransformer(None, validate=True)}\n\ndef make_pipeline(encoding_method):\n    # static transformers from the other columns\n    transformers = [(enc + '_' + col, encoders_dict[enc], [col])\n                    for col, enc in clean_columns.items()]\n    # adding the encoded column\n    transformers += [(encoding_method, encoders_dict[encoding_method],\n                      [dirty_column])]\n    pipeline = Pipeline([\n        # Use ColumnTransformer to combine the features\n        ('union', ColumnTransformer(\n            transformers=transformers,\n            remainder='drop')),\n        ('scaler', StandardScaler(with_mean=False)),\n        ('clf', DecisionTreeRegressor())\n    ])\n    return pipeline\n```"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"```python\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nall_scores = dict()\n\ncv = KFold(n_splits=10, random_state=569, shuffle=True)\nscoring = 'r2'\nfor method in encoding_methods:\n    pipeline = make_pipeline(method)\n    scores = cross_val_score(pipeline, X, y, cv=cv, scoring=scoring)\n    print('{} encoding'.format(method))\n    print('{} score:  mean: {:.3f}; std: {:.3f}\\n'.format(\n        scoring, np.mean(scores), np.std(scores)))\n    all_scores[method] = scores\n```"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}