{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Learning How to use Keras for Deep Learning"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing some libraries\nimport pandas as pd\nimport numpy as np\n\n# Import keras\nfrom keras.models import Sequential \nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\n# Import from sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"url = \"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\"\npima_data = pd.read_csv(url)\npima_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting a random seed\nseed = 7\nnp.random.seed(seed)\n\n# Seperating predictors and response variable.\nX = pima_data.iloc[:,0:8]\ny = pima_data.iloc[:,8]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will create our model :-\n\n1. We have 8 input neurons corresponding to 8 input variables.\n2. weight intilization will be done using a uniform distribution.\n3. For the hidden layers we will use 'relu' activation function.\n4. For output layer we will use 'sigmoid' activation function.\n\nWe will also calculate our validation accuracy on 33% of the hold out data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create model \nmodel = Sequential()\n# First hidden layer with 12 neurons.\nmodel.add(Dense(12, input_dim = 8, kernel_initializer = 'uniform', activation = 'relu'))\n# Second hidden layer with 8 neurons\nmodel.add(Dense(8, kernel_initializer = 'uniform', activation = 'relu'))\n# Output layer with 11 neuron.\nmodel.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile model\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\nmodel.fit(X, y, validation_split = 0.33, epochs = 150, batch_size = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(X,y)\nprint(\"%s %.2f%%\" %(model.metrics_names[1], scores[1] * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid Search for Hyperparamter\n\nThe Keras library provides a convenient wrapper for deep learning models to be used as classification or regression estimators in scikit-learn.\n\nWe are trying to optimize the 4 hyperparameters :-\n1. Optimizer.\n2. weight intializer.\n3. No. of epochs.\n4. Mini batches."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting a random seed\nseed = 7\nnp.random.seed(seed)\n\ndef create_model(kernel_initializer = 'glorot_uniform', optimizer = 'rmsprop'):\n    model = Sequential()\n    model.add(Dense(12, input_dim = 8, kernel_initializer = kernel_initializer, activation = 'relu'))\n    model.add(Dense(8, kernel_initializer = kernel_initializer, activation = 'relu'))\n    model.add(Dense(1, kernel_initializer = kernel_initializer, activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n    return model\n\n# Create a model from KerasClassifier\nmodel = KerasClassifier(build_fn = create_model, verbose = 0)\n\n# Grid Search epochs, batch_size and optimizer.\noptimizers = ['adam','rmsprop']\nkernel_initializer = ['glorot_uniform', 'normal','uniform']\nepochs = (50,100,150)\nbatches = (5,10,20)\n\nparam_grid = dict(optimizer = optimizers, kernel_initializer = kernel_initializer,\n                 nb_epoch = epochs, batch_size = batches)\ngrid = GridSearchCV(estimator = model, param_grid = param_grid)\ngrid_result = grid.fit(X,y)\n\nprint(\"Best search %f using %s\" %(grid_result.best_score_, grid_result.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}