{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Star Classification: Detailed EDA - Machine Learning\nWelcome to this kernel community, in this kernel we're going to explore the star classification dataset using visualization tools and pandas. And then we're going to try several types of machine learning algorithms and find the best.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Table of Content\n1. Preparing Environment\n1. Data Overview\n    * Checking Missing Data\n    * Class Distribution\n    * Temperature - Type Relation\n    * R - Type Relation\n    * L - Type Relation\n    * A_M - Type Relation\n1. Preparing Data\n    * One Hot Encoding\n    * Scaling Between 0 and 1\n    * Train Test Splitting\n1. Machine Learning\n1. Conclusion","metadata":{}},{"cell_type":"markdown","source":"# 1. Preparing Environment\nIn this section we're going to import libraries and import the data.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings  as wrn\nwrn.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/star-type-classification/Stars.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Overview\nIn this section we're going to take a look at the data in order to understand it properly. But before starting I'll define some functions to ease our jobs.","metadata":{}},{"cell_type":"code","source":"import random\ndef getRandomColor():\n    R,G,B = random.randint(0,255),random.randint(0,255),random.randint(0,255)\n    return (R,G,B)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getRandomPalette():\n    palettes = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', \n                'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG',\n                'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu',\n                'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', \n                'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r',\n                'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray',\n                'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r',\n                'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', \n                'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', \n                'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', \n                'vlag', 'vlag_r', 'winter', 'winter_r']\n    return random.choice(palettes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Are there any problem in the data?","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We don't have a missing data\n* All data types seem true, so we can move on and check the class distribution.","metadata":{}},{"cell_type":"markdown","source":"### Class Distribution","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(6,4))\nplt.title(\"Class Distribution\")\nsns.countplot(data[\"Type\"],palette=\"twilight\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We have 6 classes and 40 sample for each class. \n* Data is insanely balanced. \n","metadata":{}},{"cell_type":"markdown","source":"### Temperature - Type (Target) Relation","metadata":{}},{"cell_type":"code","source":"temp_by_class = data.groupby(\"Type\")[\"Temperature\"].mean()\ntemp_by_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(6,4))\nplt.title(\"Temperature - Type Relation\")\nsns.barplot(temp_by_class.index,temp_by_class.values,palette=getRandomPalette())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* As we can see there are differences between the classes so this feature might be good for our classification problem.","metadata":{}},{"cell_type":"markdown","source":"### L - Type (Target) Relation\n","metadata":{}},{"cell_type":"code","source":"l_by_class = data.groupby(\"Type\")[\"L\"].mean()\nl_by_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(6,4))\nplt.title(\"L - Type Relation\")\nsns.barplot(l_by_class.index,l_by_class.values,palette=getRandomPalette())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Class 0,1,2 have really small values, 3 has a small value but it's bigger than 0,1,2.\n* Class 4,5 have really big values.\n\nSo this feature might be good as well to create a model for this mission.","metadata":{}},{"cell_type":"markdown","source":"### R - Type (Target) Relation\n","metadata":{}},{"cell_type":"code","source":"r_by_class = data.groupby(\"Type\")[\"R\"].mean()\nr_by_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(6,4))\nplt.title(\"R - Type Relation\")\nsns.barplot(r_by_class.index,r_by_class.values,palette=getRandomPalette())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Class 0,1,2,3 have small values.\n* Class 4 has a small value as well but it's bigger than others.\n* Class 5 has a really big value so this feature might be descriptive.","metadata":{}},{"cell_type":"markdown","source":"### A_M - Type (Target) Relation","metadata":{}},{"cell_type":"code","source":"am_by_class = data.groupby(\"Type\")[\"A_M\"].mean()\nam_by_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(6,4))\nplt.title(\"A_M - Type Relation\")\nsns.barplot(am_by_class.index,am_by_class.values,palette=getRandomPalette())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Although there is no big differences this feature might be descriptive as well, so we won't drop it too.","metadata":{}},{"cell_type":"markdown","source":"# Preparing Data\nIn this section we're going to prepare our data and make it ready to use in a machine learning model. Let's take a look at the dataframe again to understand what we need to do.","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* As you see we have two categorical features: Color and Spectral_Class. \n* So we should one hot encode those features.","metadata":{}},{"cell_type":"code","source":"data = pd.get_dummies(data,[\"Spectral_Class\",\"Type\"])\ndata.head()           ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* And now as we see, our features need to be scaled because there are really big scale differences between them.","metadata":{}},{"cell_type":"markdown","source":"* We'll use this formula to scale our data between 1 and 0\n\n**(value - min(data)) /( max(data) - min(data))**","metadata":{}},{"cell_type":"code","source":"data_scaled = (data - np.min(data)) / (np.max(data) - np.min(data))\ndata_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now let's split our target and descriptive data.","metadata":{}},{"cell_type":"code","source":"X = np.asarray(data_scaled.drop(\"Type\",axis=1))\nY = np.asarray(data_scaled.Type,dtype=int)\nprint(X.shape)\nprint(Y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* And now we can split our dataset into test and train set.","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,random_state=42)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning\nIn this section we're going to fit a machine learning model using our little dataset.","metadata":{}},{"cell_type":"code","source":"def compareModels(classifiers,data,test_data):\n    result_dict = {}\n    for clf in classifiers:\n        clf.fit(data[0],data[1])\n        result_dict[str(type(clf))] = clf.score(test_data[0],test_data[1])\n    return result_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = compareModels([SVC(),\n                         LinearSVC(),\n                         GaussianNB(),\n                         BernoulliNB(),\n                         AdaBoostClassifier(DecisionTreeClassifier()),\n                         RandomForestClassifier()\n                        ],\n                        (x_train,y_train),\n                        (x_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We have a small dataset so results might be misleading, but even though we created nice models.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\nThanks for your attention, if you have a question please ask me in the comment section and mention me. I'll return to you as soon as possible.\n","metadata":{}}]}