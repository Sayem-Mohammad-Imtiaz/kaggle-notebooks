{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lang: BASIC (Assembly is tommorow) ðŸ˜„\nCovers:\n- Loss Function\n- Backprop\n- Activation Functions\n- Example:Predicting a pulsar\n- Resources","metadata":{}},{"cell_type":"markdown","source":"# 1. Realm of ML","metadata":{}},{"cell_type":"markdown","source":"<img class=\"fit-picture\"\n     src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Fig-X_All_ML_as_a_subfield_of_AI.jpg/220px-Fig-X_All_ML_as_a_subfield_of_AI.jpg \"\n     alt=\"Grapefruit slice atop a pile of other slices\" width=512>  \n## Currently AIâ‰ˆMLâ‰ˆDL","metadata":{}},{"cell_type":"markdown","source":"# Loss Functions\n- Grant said it as a cost function\n- Remember $r^{2}$ and residuals? - we are essentially minimizing residuals by changing the weights\n","metadata":{}},{"cell_type":"markdown","source":"# Predicting Pulsar Stars\n#### Use the HTRU 2 dataset to predict pulsars.","metadata":{}},{"cell_type":"code","source":"\n#Imports\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import optim\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split, DataLoader, TensorDataset\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.253901Z","iopub.execute_input":"2021-06-03T11:41:06.254353Z","iopub.status.idle":"2021-06-03T11:41:06.593275Z","shell.execute_reply.started":"2021-06-03T11:41:06.254263Z","shell.execute_reply":"2021-06-03T11:41:06.592537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download the dataset and initialize the dataset.\n - If you are on Kaggle, add [this](https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star) dataset- avoids redownloading the dataset each time.\n - Otherwise uncomment the next two lines of code.","metadata":{}},{"cell_type":"markdown","source":"#### Extract the csv file - if you downloaded the dataset.","metadata":{}},{"cell_type":"markdown","source":"### Load the data from the .csv file \nWe just need to use the pandas library's read_csv() function\n","metadata":{}},{"cell_type":"code","source":"filename = \"../input/pulsar-dataset-htru2/HTRU_2.csv\" #Change as needed.\ndf = pd.read_csv(filename)\ndf.columns = [\"Mean of the integrated profile\",\n              \"Standard deviation of the integrated profile\",\n              \"Excess kurtosis of the integrated profile\",\n              \"Skewness of the integrated profile\",\n              \"Mean of the DM-SNR curve\",\n              \"Excess kurtosis of the DM-SNR curve\",\n              \"Skewness of the DM-SNR\",\n              \"Skewness of the DM-SNR curve\",\n              \"target_class\"]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.595745Z","iopub.execute_input":"2021-06-03T11:41:06.59614Z","iopub.status.idle":"2021-06-03T11:41:06.697552Z","shell.execute_reply.started":"2021-06-03T11:41:06.596101Z","shell.execute_reply":"2021-06-03T11:41:06.696785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T11:41:06.69887Z","iopub.execute_input":"2021-06-03T11:41:06.699345Z","iopub.status.idle":"2021-06-03T11:41:06.719183Z","shell.execute_reply.started":"2021-06-03T11:41:06.699307Z","shell.execute_reply":"2021-06-03T11:41:06.718191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T11:41:06.720783Z","iopub.execute_input":"2021-06-03T11:41:06.721194Z","iopub.status.idle":"2021-06-03T11:41:06.765662Z","shell.execute_reply.started":"2021-06-03T11:41:06.721127Z","shell.execute_reply":"2021-06-03T11:41:06.76452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Dataset for Training\nWe need to convert the dataframe to Pytorch Tensors using numpy arrays.","metadata":{}},{"cell_type":"code","source":"inputs_df=df.drop(\"target_class\",axis=1)#Easiest way to get inputs- we just need everything but the targets_class \ninputs_arr=inputs_df.to_numpy()\ntargets_df=df[\"target_class\"] #Easiest way to get outputs-need just targets_class\ntargets_arr=targets_df.to_numpy()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.769532Z","iopub.execute_input":"2021-06-03T11:41:06.769817Z","iopub.status.idle":"2021-06-03T11:41:06.775678Z","shell.execute_reply.started":"2021-06-03T11:41:06.769793Z","shell.execute_reply":"2021-06-03T11:41:06.774005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#output variables.\ninputs=torch.from_numpy(inputs_arr).type(torch.float64)\ntargets=torch.from_numpy(targets_arr).type(torch.long)\ninputs.shape, targets.shape","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.77993Z","iopub.execute_input":"2021-06-03T11:41:06.780427Z","iopub.status.idle":"2021-06-03T11:41:06.790841Z","shell.execute_reply.started":"2021-06-03T11:41:06.780365Z","shell.execute_reply":"2021-06-03T11:41:06.789354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create the dataset.","metadata":{}},{"cell_type":"code","source":"dataset=TensorDataset(inputs, targets)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.792827Z","iopub.execute_input":"2021-06-03T11:41:06.793456Z","iopub.status.idle":"2021-06-03T11:41:06.800763Z","shell.execute_reply.started":"2021-06-03T11:41:06.793383Z","shell.execute_reply":"2021-06-03T11:41:06.79917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split the dataset into training and validation","metadata":{"trusted":true}},{"cell_type":"code","source":"num_rows=df.shape[0]\nval_percent = .1 # How much of the dataset \nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.802579Z","iopub.execute_input":"2021-06-03T11:41:06.803085Z","iopub.status.idle":"2021-06-03T11:41:06.811799Z","shell.execute_reply.started":"2021-06-03T11:41:06.802987Z","shell.execute_reply":"2021-06-03T11:41:06.81003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use the random_split function to split dataset into 2 parts of the desired length","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2)#Ensure that we get the same validation each time.\ntrain_ds, val_ds = random_split(dataset, (train_size, val_size))\ntrain_ds[5]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.813848Z","iopub.execute_input":"2021-06-03T11:41:06.814498Z","iopub.status.idle":"2021-06-03T11:41:06.830442Z","shell.execute_reply.started":"2021-06-03T11:41:06.814439Z","shell.execute_reply":"2021-06-03T11:41:06.829231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set a batch size.  \nI am going to pick 200, but adjust this to you needs.","metadata":{}},{"cell_type":"code","source":"batch_size=200","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.832601Z","iopub.execute_input":"2021-06-03T11:41:06.8332Z","iopub.status.idle":"2021-06-03T11:41:06.838459Z","shell.execute_reply.started":"2021-06-03T11:41:06.833153Z","shell.execute_reply":"2021-06-03T11:41:06.837336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data and transfer data to GPU, if available.","metadata":{}},{"cell_type":"code","source":"# PyTorch data loaders\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=3, pin_memory=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.841189Z","iopub.execute_input":"2021-06-03T11:41:06.84174Z","iopub.status.idle":"2021-06-03T11:41:06.850503Z","shell.execute_reply.started":"2021-06-03T11:41:06.841693Z","shell.execute_reply":"2021-06-03T11:41:06.848535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transfer to GPU","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.852651Z","iopub.execute_input":"2021-06-03T11:41:06.853283Z","iopub.status.idle":"2021-06-03T11:41:06.865757Z","shell.execute_reply.started":"2021-06-03T11:41:06.853123Z","shell.execute_reply":"2021-06-03T11:41:06.864734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get device\ndevice=get_default_device()\ndevice","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.869811Z","iopub.execute_input":"2021-06-03T11:41:06.870147Z","iopub.status.idle":"2021-06-03T11:41:06.89811Z","shell.execute_reply.started":"2021-06-03T11:41:06.870116Z","shell.execute_reply":"2021-06-03T11:41:06.896844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now wrap our training and validation data loaders using DeviceDataLoader for automatically transferring batches of data to the GPU (if available).\n","metadata":{}},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.899761Z","iopub.execute_input":"2021-06-03T11:41:06.900562Z","iopub.status.idle":"2021-06-03T11:41:06.908081Z","shell.execute_reply.started":"2021-06-03T11:41:06.900512Z","shell.execute_reply":"2021-06-03T11:41:06.906555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create a Model","metadata":{}},{"cell_type":"code","source":"class HTRU2Model(nn.Module):\n    def __init__(self,):\n        super(HTRU2Model,self).__init__()\n        self.fc1 = nn.Linear(8, 16)\n        self.fc2 = nn.Linear(16, 16)\n        self.fc3 = nn.Linear(16, 2)\n        self.softmax = nn.Softmax(dim=1)\n    def forward(self, x):\n        x = x.float()\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = self.fc3(x)\n        x = self.softmax(x)\n        return x\n    def training_step(self, batch):\n        inputs, targets = batch \n        out = self(inputs)                  # Generate predictions\n        loss = F.cross_entropy(out, targets) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch \n        out = self(inputs)                    # Generate predictions\n        loss = F.cross_entropy(out, targets)   # Calculate loss\n        acc = accuracy(out, targets)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))   \n\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-03T11:41:06.910002Z","iopub.execute_input":"2021-06-03T11:41:06.91081Z","iopub.status.idle":"2021-06-03T11:41:06.92586Z","shell.execute_reply.started":"2021-06-03T11:41:06.910686Z","shell.execute_reply":"2021-06-03T11:41:06.924971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=to_device(HTRU2Model(),device)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:41:06.926862Z","iopub.execute_input":"2021-06-03T11:41:06.927158Z","iopub.status.idle":"2021-06-03T11:41:08.671368Z","shell.execute_reply.started":"2021-06-03T11:41:06.927134Z","shell.execute_reply":"2021-06-03T11:41:08.670366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Training the Model","metadata":{}},{"cell_type":"markdown","source":"#### Accuracy, evaluation, and fit function","metadata":{}},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:41:08.672801Z","iopub.execute_input":"2021-06-03T11:41:08.673197Z","iopub.status.idle":"2021-06-03T11:41:08.679297Z","shell.execute_reply.started":"2021-06-03T11:41:08.673156Z","shell.execute_reply":"2021-06-03T11:41:08.678469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=optim):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:41:08.680713Z","iopub.execute_input":"2021-06-03T11:41:08.681116Z","iopub.status.idle":"2021-06-03T11:41:08.692828Z","shell.execute_reply.started":"2021-06-03T11:41:08.681078Z","shell.execute_reply":"2021-06-03T11:41:08.691872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get the initial accuracy and loss**","metadata":{}},{"cell_type":"code","source":"history = [evaluate(model, val_dl)]\nhistory","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:41:08.694134Z","iopub.execute_input":"2021-06-03T11:41:08.694781Z","iopub.status.idle":"2021-06-03T11:41:09.003794Z","shell.execute_reply.started":"2021-06-03T11:41:08.694739Z","shell.execute_reply":"2021-06-03T11:41:09.002911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train!\n> | The Parameters are listed below. ","metadata":{}},{"cell_type":"code","source":"epochs = 100\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = optim.SGD","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:43:55.350716Z","iopub.execute_input":"2021-06-03T11:43:55.35112Z","iopub.status.idle":"2021-06-03T11:43:55.356567Z","shell.execute_reply.started":"2021-06-03T11:43:55.351088Z","shell.execute_reply":"2021-06-03T11:43:55.355189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train and add to history\n> Here you can see some progress bar bling!","metadata":{}},{"cell_type":"code","source":"%%time\nhistory += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:43:57.433716Z","iopub.execute_input":"2021-06-03T11:43:57.434048Z","iopub.status.idle":"2021-06-03T11:45:12.194679Z","shell.execute_reply.started":"2021-06-03T11:43:57.434005Z","shell.execute_reply":"2021-06-03T11:45:12.19358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stats and charts!","metadata":{}},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \ndef plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:42:10.940155Z","iopub.execute_input":"2021-06-03T11:42:10.940556Z","iopub.status.idle":"2021-06-03T11:42:10.950522Z","shell.execute_reply.started":"2021-06-03T11:42:10.940513Z","shell.execute_reply":"2021-06-03T11:42:10.949535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:42:10.95239Z","iopub.execute_input":"2021-06-03T11:42:10.952786Z","iopub.status.idle":"2021-06-03T11:42:11.120236Z","shell.execute_reply.started":"2021-06-03T11:42:10.952745Z","shell.execute_reply":"2021-06-03T11:42:11.119427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:42:11.121896Z","iopub.execute_input":"2021-06-03T11:42:11.122242Z","iopub.status.idle":"2021-06-03T11:42:11.238566Z","shell.execute_reply.started":"2021-06-03T11:42:11.122207Z","shell.execute_reply":"2021-06-03T11:42:11.23774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_lrs(history)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-03T11:42:11.240096Z","iopub.execute_input":"2021-06-03T11:42:11.240454Z","iopub.status.idle":"2021-06-03T11:42:11.377537Z","shell.execute_reply.started":"2021-06-03T11:42:11.240419Z","shell.execute_reply":"2021-06-03T11:42:11.376706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model.pth\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T11:49:03.580494Z","iopub.execute_input":"2021-06-03T11:49:03.580829Z","iopub.status.idle":"2021-06-03T11:49:03.591624Z","shell.execute_reply.started":"2021-06-03T11:49:03.580799Z","shell.execute_reply":"2021-06-03T11:49:03.590491Z"},"trusted":true},"execution_count":null,"outputs":[]}]}