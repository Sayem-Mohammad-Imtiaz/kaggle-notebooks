{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Big Data Project \n#STEP 1 : IMPORT NECESSARY LIBRARIES ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud,STOPWORDS\nstopwords = set(STOPWORDS)\n\nfrom textblob import TextBlob\n\nimport re\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 2 : READ DESIRED CSV FILE TO INVESTIGATE  DATA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading data\ndf=pd.read_csv('/kaggle/input/coronavirus-covid19-tweets-late-april/2020-04-16 Coronavirus Tweets.CSV')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 3 : INVESITGATE DATA SOURCE FOR COUNTIRES WITH SIMILAR ATTRIBUTES","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display columns\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to view country codes needed first start by making a copy of the datset then dropping columns\ntweet = df.copy()\ntweet.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\ntweet = tweet.dropna()\ntweet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 4: EXTRACT DATA TO BE USED IN PROJECT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a new subset dataset that houses all data for both US & CN to be used for comparison\nus_cn_dataset = pd.DataFrame(df[(df.country_code == \"CN\") | (df.country_code == \"US\") & (df.lang == \"en\")])\nus_cn_dataset.drop(['status_id','user_id','screen_name','source','reply_to_status_id','reply_to_user_id','is_retweet','place_full_name','place_type','reply_to_screen_name','is_quote','followers_count','friends_count','account_lang','account_created_at','verified'],axis=1, inplace = True)\nus_cn_dataset.to_csv('us_ca_data.csv')\nus_cn_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 5: READ AND CLEAN DATA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_cn_dataset = pd.read_csv(\"./us_ca_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data preprocessing\n\nfor i in range(us_cn_dataset.shape[0]):\n    us_cn_dataset[\"text\"][i] = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(#[A-Za-z0-9]+)\", \" \", us_cn_dataset[\"text\"][i]).split()).lower()\nus_cn_dataset[\"text\"].head()\n\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 6: PREPARE SENTIMENT ANALYSIS ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#update stop words for better word cloud data \nstopwords.update([\"https\", \"name\", \"dtype\", \"text\", \"she\", \"whether\", \"ft\", \"in\"])\n#Removing Stop Words\nus_cn_dataset['text'] = us_cn_dataset['text'].apply(lambda tweets: ' '.join([word for word in tweets.split() if word not in stopwords]))\nus_cn_dataset['text'].head() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sentiment analysis of positive negative and neutral on us_cn dataset\nus_cn_dataset['sentiment'] = ' '\nus_cn_dataset['polarity'] = None\nfor i,tweets in enumerate(us_cn_dataset.text) :\n    blob = TextBlob(tweets)\n    us_cn_dataset['polarity'][i] = blob.sentiment.polarity\n    if blob.sentiment.polarity > 0 :\n        us_cn_dataset['sentiment'][i] = 'positive'\n    elif blob.sentiment.polarity < 0 :\n        us_cn_dataset['sentiment'][i] = 'negative'\n    else :\n        us_cn_dataset['sentiment'][i] = 'neutral'\n#us_cn_dataset.head()\nprint(us_cn_dataset.sentiment.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 7 : DISPLAY SENTIMENT IN WORD CLOUD ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#word cloud function\ndef show_wordcloud(data , title = None):\n    \n    wordcloud = WordCloud(background_color='black',stopwords=stopwords,max_words=200,max_font_size=40).generate(str(data))\n  \n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    plt.title(title, size = 25)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word cloud representation of sentiment analysis for both us&cn \npos = us_cn_dataset['text'][us_cn_dataset['sentiment'] == 'positive']\nshow_wordcloud(pos , 'POSITIVE')\n\nneg = us_cn_dataset['text'][us_cn_dataset['sentiment'] == 'negative']\nshow_wordcloud(neg , 'NEGATIVE')\n\nneutral = us_cn_dataset['text'][us_cn_dataset['sentiment'] == 'neutral']\nshow_wordcloud(neutral , 'NEUTRAL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#STEP 8: COMPARE SENTIMENT SEPARATELY ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a new subset dataset for US to be used for comparison\nus_dataset = pd.DataFrame(us_cn_dataset[(us_cn_dataset.country_code == \"US\") & (us_cn_dataset.lang == \"en\")])\nprint(us_dataset.sentiment.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word cloud representation of sentiment analysis for US \npos = us_dataset['text'][us_dataset['sentiment'] == 'positive']\nshow_wordcloud(pos , 'POSITIVE')\n\nneg = us_dataset['text'][us_dataset['sentiment'] == 'negative']\nshow_wordcloud(neg , 'NEGATIVE')\n\nneutral = us_dataset['text'][us_dataset['sentiment'] == 'neutral']\nshow_wordcloud(neutral , 'NEUTRAL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a new subset dataset for CN to be used for comparison\ncn_dataset = pd.DataFrame(us_cn_dataset[(us_cn_dataset.country_code == \"CN\") & (us_cn_dataset.lang == \"en\")])\nprint(cn_dataset.sentiment.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# word cloud representation of sentiment analysis for CN \npos = cn_dataset['text'][cn_dataset['sentiment'] == 'positive']\nshow_wordcloud(pos , 'POSITIVE')\n\nneg = cn_dataset['text'][cn_dataset['sentiment'] == 'negative']\nshow_wordcloud(neg , 'NEGATIVE')\n\nneutral = cn_dataset['text'][cn_dataset['sentiment'] == 'neutral']\nshow_wordcloud(neutral , 'NEUTRAL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#END OF PROJECT ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}