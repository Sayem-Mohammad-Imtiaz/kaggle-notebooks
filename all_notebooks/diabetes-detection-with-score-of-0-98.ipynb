{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings  as ws\nws.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/diabetes-data-set/diabetes-dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nsns.countplot(df[\"Outcome\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above graph clearly shows the class imbalance ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data \nfrom sklearn.model_selection import train_test_split\nX = df.drop(columns = \"Outcome\")\ny = df[\"Outcome\"]\nX_train , X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 42, stratify = y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model to the training data\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfor model in [ \n    DummyClassifier,\n    LogisticRegression,\n    DecisionTreeClassifier,\n    KNeighborsClassifier,\n    GaussianNB,\n    SVC,\n    RandomForestClassifier,\n    xgboost.XGBClassifier,\n]:\n    cls = model()\n    kf = KFold(n_splits = 5, random_state = 45)\n    score = cross_val_score(cls, X_train_scaled, y_train, cv = kf, scoring=\"roc_auc\")\n    print(\n        f\"{model.__name__:22}  AUC: \"\n        \n        f\"\\t {score.mean():.3f} STD: {score.std():.2f}\"\n        \n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Withour any certain hyper param tuning the Random_Forest Model is best\n# leta get model working\n\nrfe = RandomForestClassifier(n_estimators=1000, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the Random Forest Model\nprint (\"Accuacy on test set is \", round(rfe.score(X_test_scaled, y_test) * 100, 2), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\nprint(\"precision Score is \", round (precision_score(y_test, rfe.predict(X_test_scaled)) * 100 , 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Feature importance is \\n\" )\nfor i,j in zip(X_train.columns.to_list(), rfe.feature_importances_.tolist()):\n    if(i == \"DiabetesPedigreeFunction\"):\n        print (i , \"\\t \\t \", j)\n    elif(i==\"Age\" or i ==\"BMI\"):\n        print (i , \"\\t \\t \\t\\t\\t\", j)\n    else :   \n        print (i , \"\\t \\t \\t \\t\", j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we seleted the model we can try the hyperparam tuning\nfrom sklearn.model_selection import GridSearchCV\n\nnew_rfe = RandomForestClassifier()\n\nparams = {\n     \"max_features\": [0.4, \"auto\"],\n     \"n_estimators\": [15, 200, 500, 1000],\n     \"min_samples_leaf\": [1, 0.1],\n     \"random_state\": [42],\n}\n\ncvs = GridSearchCV(new_rfe, params, n_jobs = -1).fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cvs.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cvs.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cvs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting the model with best params\nrfe_final = RandomForestClassifier(\n**{'max_features': 0.4, 'min_samples_leaf': 1, 'n_estimators': 1000, 'random_state': 42}\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe_final.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rfe_final.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(precision_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nsns.heatmap(confusion_matrix(y_test, y_pred), annot =True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print Roc_auc_score\nfrom sklearn.metrics import roc_auc_score\nprint(roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# This is Cool :) ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Please upvote it !! It wll motivate me to create content more like this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}