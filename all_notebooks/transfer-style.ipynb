{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        \nfrom keras import backend as K\nfrom keras.preprocessing.image import load_img, save_img, img_to_array\nfrom keras.applications import vgg19\nfrom keras.models import Model\nimport keras\nfrom tensorflow.keras import models\nimport tensorflow.compat.v1 as tf\n\nfrom tqdm import tqdm\n\nimport time\n\nfrom scipy.optimize import fmin_l_bfgs_b\n\nimport matplotlib.pyplot as plt\n\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.compat.v1.enable_eager_execution()\n# K.clear_session()\n# tf.compat.v1.reset_default_graph()\ntf.disable_v2_behavior()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirr_style = '../input/best-artworks-of-all-time/images/images/'\ndirr_photo = '../input/image-classification/validation/validation/travel and adventure/'\n# dirr_photo = '../input/image-classification/images/images/travel and  adventure/'\n\ndirr_folder = sorted(os.listdir('../input/image-classification/validation/validation/travel and adventure/'))\n# dirr_folder = sorted(os.listdir('../input/image-classification/images/images/travel and  adventure/'))\n\nnum = 4\nimage_path = os.path.join(dirr_photo, dirr_folder[num])\nstyle_path = dirr_style + 'Vincent_van_Gogh/Vincent_van_Gogh_368.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 8))\n\nfig.add_subplot(1, 2, 1)\nplt.title('Пример изображения')\nim = load_img(image_path)\nplt.imshow(im)\n\nfig.add_subplot(1, 2, 2)\nplt.title('Пример стиля')\nim = load_img(style_path)\nplt.imshow(im)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"width, height = load_img(image_path).size\n\nimg_height = 400\nimg_width = 500\n# img_width = int(width * img_height / height)\n(width, height), (img_width, img_height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"width / img_width, height / img_height","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(model, image_path, rows, cols):\n    img = load_img(image_path, target_size=(rows, cols))\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = model.preprocess_input(img)\n    return img\n\ndef deprocess_image(x):\n    # центрирование\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    # в RGB из BGR\n    x = x[:, :, ::-1]\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = K.variable(preprocess_image(vgg19, image_path, img_height, img_width))\nstyle = K.variable(preprocess_image(vgg19, style_path, img_height, img_width))\ncombination_image = K.placeholder((1, img_height, img_width, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(image), type(combination_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# конкатенированный тензор из трёх фото\ninput_tensor = K.concatenate([image, style, combination_image], axis=0)\n\n# модель\nmodel = vgg19.VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combination_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def content_loss(base, combination):\n    return K.sum(K.square(combination - base))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gram_matrix(x):\n    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n    gram = K.dot(features, K.transpose(features))\n    return gram\n\n\ndef style_loss(style, combination):\n    S = gram_matrix(style)\n    C = gram_matrix(combination)\n    channels = 3\n    size = img_height * img_width\n    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def total_variation_loss(x):\n    a = K.square(\n        x[:, :img_height - 1, :img_width - 1, :] - x[:, 1:, :img_width - 1, :])\n    b = K.square(\n        x[:, :img_height - 1, :img_width - 1, :] - x[:, :img_height - 1, 1:, :])\n    return K.sum(K.pow(a + b, 1.25))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отображение названий слоёв в тензоры \noutputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n\n# название слоя для функции потерь содержимого\ncontent_layer = 'block5_conv2'\n\n# названия слоёв для функции потерь стиля\nstyle_layers = [\n    'block1_conv1',\n    'block2_conv1',\n    'block3_conv1',\n    'block4_conv1',\n    'block5_conv1'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lay = outputs_dict[content_layer]\nlay","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# веса для взвешенной суммы функций потерь\ntotal_variation_weight = 1e-4\nstyle_weight = 1.\ncontent_weight = 0.025","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Про loss = loss + ...\n\nhttps://stackoverflow.com/questions/65705507/variable-value-not-supported-problem-python"},{"metadata":{"trusted":true},"cell_type":"code","source":"# потеря\nloss = K.variable(0.)\n\n# shape слоя потерь содержимого\nlayer_features = outputs_dict[content_layer]\n\n# исходное изображение - первое\ntarget_image_features = layer_features[0, :, :, :]\n\n# полученное изображение (которое хотим приблизить) - третье\ncombination_features = layer_features[2, :, :, :]\n\n# потеря += потеря содержимого\nloss = loss + content_weight * content_loss(target_image_features, combination_features)\n# loss += content_weight * content_loss(target_image_features, combination_features)\n\n# для каждого слоя, используемого для вычисления потерь стиля\nfor layer_name in style_layers:\n    # shape слоя\n    layer_features = outputs_dict[layer_name]\n    # изображение стиля - второе\n    style_reference_features = layer_features[1, :, :, :]\n    # полученное изображение\n    combination_features = layer_features[2, :, :, :]\n    # потеря += потеря стиля для данного слоя\n    loss = loss + (style_weight / len(style_layers)) * style_loss(style_reference_features, combination_features)\n    \n# потеря += потеря вариации (аналог регуляризации потерь)\nloss = loss + total_variation_weight * total_variation_loss(combination_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combination_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# градиенты сгененированного изображения относительно функции потерь\ngrads = K.gradients(loss, combination_image)[0]\n\n# функция для получения потерь и градиентов\nfetch_loss_and_grads = K.function([combination_image], [loss, grads])\n\n# класс, вычисляющий значения потерь и градиентов одновременно для BFGS\nclass Evaluator(object):\n\n    def __init__(self):\n        self.loss_value = None\n        self.grads_values = None\n\n    def loss(self, x):\n        assert self.loss_value is None\n        x = x.reshape((1, img_height, img_width, 3))\n        outs = fetch_loss_and_grads([x])\n        loss_value = outs[0]\n        grad_values = outs[1].flatten().astype('float64')\n        self.loss_value = loss_value\n        self.grad_values = grad_values\n        return self.loss_value\n\n    def grads(self, x):\n        assert self.loss_value is not None\n        grad_values = np.copy(self.grad_values)\n        self.loss_value = None\n        self.grad_values = None\n        return grad_values\n\nevaluator = Evaluator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_prefix = 'style'\nresult_prefix2 = 'origin'\niterations = 5\n\nx = preprocess_image(vgg19, image_path, img_height, img_width)\n# сохранить исходное изображение (img_height, img_width)\nimg = deprocess_image(x[0].copy())\nfname = result_prefix2 + f'_it_{num}.png'\nsave_img(path=fname, x=img, data_format='channels_last')\n\nx = x.flatten()\n\nfor i in tqdm(range(iterations)):\n    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x, fprime=evaluator.grads, maxfun=20)\n\n# сохранить полученное изображение\nimg = x.copy().reshape((img_height, img_width, 3))\nimg = deprocess_image(img)\nfname = result_prefix + f'_it_{num}.png'\nsave_img(path=fname, x=img, data_format='channels_last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 8))\nlist_images = [\n    load_img(image_path, target_size=(img_height, img_width)),\n    load_img(style_path, target_size=(img_height, img_width)),\n    img\n]\n\nfor ax, im in zip(axes.flatten(), list_images):\n    ax.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -r files.zip ./","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}