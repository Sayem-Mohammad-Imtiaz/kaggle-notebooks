{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Segmenting and Clustering Airbnb Listings in Berlin, Germany¶\n"},{"metadata":{},"cell_type":"markdown","source":"## Data Science  Project\n\nMohamed Abdul Fatah\n\n"},{"metadata":{},"cell_type":"markdown","source":"# 1 Introduction/Business Problem"},{"metadata":{},"cell_type":"markdown","source":"### Airbnb has successfully disrupted the traditional hospitality industry as more and more travelers decide to use Airbnb as their primary accommodation provider. Since its beginning in 2008, Airbnb has seen an enormous growth, with the number of rentals listed on its website growing exponentially each year. In Germany, no city is more popular than Berlin. That implies that Berlin is one of the hottest markets for Airbnb in Europe, with over 22,552 listings as of November 2018.\n\n#### Although Airbnb listings provide enough information about the shared space, there is less information about the nearby location. For example, travelers might be interested in what kind of venues are close to the accommodation they book.In addition, travelers cannot filter Airbnb listings based on the nearby venues. In other words, each time travelers make a search for an accommodation using the Airbnb community, they may want to get direct information about the venues in the area and a list of similar Airbnb listings with same venue categories nearby.\n\n### The main objective of this project is to explore, segment and cluster Airbnb listings in Berlin, Germany. I will use the Foursquare API to explore the areas around the Airbnb listings in Berlin. I will use the explore function to get the most common venue categories for each Airbnb listing, and then use this feature together with the prices to group the listings into clusters. I will use the k-means clustering algorithm to complete this task. Finally, I will use the Folium library to visualize the listings in Berlin and their emerging clusters."},{"metadata":{},"cell_type":"markdown","source":"# Data\n\n## * Foursquare API: to get the most common venues of given Airbnb listing.\n\n## * Airbnb Data Collection : Here is the data provided for each Airbnb listing. Each link downloads a zip file of the data for a named city or region; in my case this is Berlin, Germany. The zip file holds one or more csv files. Each csv file represents a single ”survey” or ”scrape” of the Airbnb web site for that city. The data is collected from the public Airbnb web sit. Each csv file contains the attributes as follows:\n\n### * room_id: A unique number identifying an Airbnb listing\n\n### * host_id: A unique number identifying an Airbnb host.\n\n### * room_type: One of ”Entire home/apt”, ”Private room”, or ”Shared room” borough: A sub-region of the city or search area for which the survey is carried out. The borough is taken from a shapefile of the city that is obtained independently of the Airbnb web site. For some cities, there is no borough information; for others the borough may be a number.\n\n### * neighborhood: As with borough: a sub-region of the city or search area for which the survey is carried out. For cities that have both, a neighborhood is smaller than a borough. For some cities there is no neighborhood information.\n\n### * reviews: The number of reviews that a listing has received. Airbnb has said that 70% of visits end up with a review, so the number of reviews can be used to estimate the number of visits. Note that such an estimate will not be reliable for an individual listing (especially as reviews occasionally vanish from the site), but over a city as a whole it should be a useful metric of traffic.\n\n### * overall_satisfaction: The average rating (out of five) that the listing has received from those visitors who left a review. accommodates: The number of guests a listing can accommodate. bedrooms: The number of bedrooms a listing offers. price: The price for a night stay. In early surveys, there may be some values that were recorded by month.\n\n### * minstay: The minimum stay for a visit, as posted by the host.\n\n### * latitude and longitude: The latitude and longitude of the listing as posted on the Airbnb site: this may be off by a few hundred meters.\n\n### * last_modified: the date and time that the values were read from the Airbnb web site\n\n## Airbnb data is used to get the coordinates (latitude and longitude), neighbourhood and price for each listing in Berlin, Germany. Having this information, I can leverage Foursquare API to explore the areas around the Airbnb listings and get the most common venue categories for each listing. Venue categories together with the price are used to segment the listings into similar clusters\n\n\n## If you don't want the details, just scroll to the end of the project, you'll see a map with average price range per night for each neighborhood and the cluster of quarters with the most common venues displayed \n\n"},{"metadata":{},"cell_type":"markdown","source":"# Methodology\n\n\n# 1- Airbnb Data Wrangling: Clean and Transform"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\n!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes}\nimport folium # plotting library\n\nprint('Folium installed')\nprint('Libraries imported.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import numpy as np # library to handle data in a vectorized manner\nimport time\n#import pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n#import folium # map rendering library\nimport folium # map rendering library\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nimport seaborn as sns\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\nprint('Libraries imported.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get the Airbnb data of listings in Berlin  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the Airbnb data of listings in Berlin"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ndf_s = pd.read_csv('/kaggle/input/berlin-airbnb-data/listings_summary.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's get important feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_keep = ['id','host_has_profile_pic','host_since',\n                   'latitude', 'longitude','property_type', 'room_type', 'accommodates', 'bathrooms',  \n                   'bedrooms', 'bed_type', 'amenities', 'price', 'cleaning_fee',\n                   'security_deposit', 'minimum_nights',  \n                   'instant_bookable', 'cancellation_policy','availability_365','neighbourhood_cleansed','neighbourhood_group_cleansed']\ndf_s= df_s[columns_to_keep].set_index('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cheak missing data "},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_s.isnull().sum().sort_values(ascending = False)\npercent = (df_s.isnull().sum()/df_s.isnull().count()*100).sort_values(ascending = False)\nmissing_df_s  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df_s.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's convert string true and false to numeric"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert f,t to 0 or 1\ndf_s['instant_bookable'] = df_s['instant_bookable'].map({'f':0,'t':1})\n#fill f for N/A in host_has_profile_pic column for further correct mapping\nset(df_s['host_has_profile_pic'])\ndf_s['host_has_profile_pic'].fillna('f',inplace=True)\n#Convert f,t to 0 or 1\ndf_s['host_has_profile_pic'] = df_s['host_has_profile_pic'].map({'f':0,'t':1})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's Remove $ from price"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove $ from price, fee columns and convert to float\ndf_s['price'] = df_s['price'].str.replace('$', '').str.replace(',', '').astype(float)\ndf_s['cleaning_fee'] = df_s['cleaning_fee'].str.replace('$', '').str.replace(',', '').astype(float)\ndf_s['security_deposit'] = df_s['security_deposit'].str.replace('$', '').str.replace(',', '').astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's fill nan values with median"},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning_fee cleanup of N/a replace with median value\ndf_s['cleaning_fee'].fillna(df_s['cleaning_fee'].median(), inplace=True)\n#security_deposit cleanup of N/a replace with median value\ndf_s['security_deposit'].fillna(df_s['security_deposit'].median(), inplace=True)\n#cleanup bathroom , bedroom columns\ndf_s['bathrooms'].fillna(1,inplace=True)\ndf_s['bedrooms'].fillna(1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's cheak missing data "},{"metadata":{"trusted":true},"cell_type":"code","source":"total = df_s.isnull().sum().sort_values(ascending = False)\npercent = (df_s.isnull().sum()/df_s.isnull().count()*100).sort_values(ascending = False)\nmissing_df  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## lets remove any outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check distribution of price column\ndf_s.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s['price'].describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# * 75% of prices are near 70 $ so i will drop prices above 180 and also drop the min price like 0 & 1\n\n# * min prices is 0\n\n# * max prices is 9000 $\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s.drop(df_s[ (df_s.price > 180) | (df_s.price == 0) | (df_s.price == 1) ].index, axis=0, inplace=True)\n\ndf_s['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Explore and Visualize Airbnb Berlin Data"},{"metadata":{},"cell_type":"markdown","source":"## lets have a look at airbnb rent price statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplot of price column\nred_square = dict(markerfacecolor='r', markeredgecolor='r', marker='.')\ndf_s['price'].plot(kind='box', xlim=(0, 180), vert=False, flierprops=red_square, figsize=(15,3));\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.distplot(df_s['price'],bins=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Airbnb rent price statistics shows The price ranges are between 25 to 75 $ "},{"metadata":{},"cell_type":"markdown","source":"## Price range distribution among the room types"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='room_type',y='price',data = df_s)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Price range distribution among the bedrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='bedrooms', y= 'price', data=df_s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We notice here that the more rooms there are, the more price increases"},{"metadata":{},"cell_type":"markdown","source":"## let's have a look at number of Listingsin in each Neighbourhood group "},{"metadata":{"trusted":true},"cell_type":"code","source":"nh = df_s['neighbourhood_group_cleansed'].value_counts().reset_index()\nnh.columns = ['neighbourhood_group_cleansed' ,'Count']\nnh['Percent'] = nh['Count']/nh['Count'].sum() * 100\nnh.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Friedrichshain-Kreuzberg Neighbourhood group seems to have more Listings in the dataset, with 24%"},{"metadata":{},"cell_type":"markdown","source":"## let's have a look at the frist five popular neighborhoods among the listings?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nax = sns.countplot(x=\"neighbourhood_group_cleansed\", hue=\"neighbourhood_group_cleansed\", data=df_s,\n              order=df_s['neighbourhood_group_cleansed'].value_counts().iloc[:5].index)\nplt.title('Popular Neighborhoods')\nplt.ylabel('Count')\nplt.xlabel('neighbourhood_group_cleansed')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We notice here that the most popular neighborhoods are each following in order from the first to the fifth:\n1 Friedrichshain-Kreuzberg\n\n2 Mitte\n\n3 Neukölln\n\n4 Pankow\t\n\n5 Charlottenburg-Wilm"},{"metadata":{},"cell_type":"markdown","source":"## let's have a look at the most occupied room types among the listings?"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"room_type\", data=df_s)\nplt.title('Room Type distribution')\nplt.xlabel('Room Type')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## lets'have a look at the Room type distribution in the neighborhood groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nax = sns.countplot(x=\"room_type\", data=df_s,hue=\"neighbourhood_group_cleansed\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets break up amenties that will help in drawing a correlation to price better as amenties might impact price\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#nominal_categorical bed_type and property_type\nfor i in [\"bed_type\",\"property_type\",\"cancellation_policy\"]:\n    x = df_s[[i]]\n    x.room_type = pd.Categorical(x[i])\n    del df_s[i]\n    dummies = pd.get_dummies(x, prefix = i)\n    df_s = pd.concat([df_s,dummies], axis=1)\n\n    df_s.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s['Laptop_friendly_workspace'] = df_s['amenities'].str.contains('Laptop friendly workspace')\ndf_s['TV'] = df_s['amenities'].str.contains('TV')\ndf_s['Family_kid_friendly'] = df_s['amenities'].str.contains('Family/kid friendly')\ndf_s['Host_greets_you'] = df_s['amenities'].str.contains('Host greets you')\ndf_s['Smoking_allowed'] = df_s['amenities'].str.contains('Smoking allowed')\ndf_s['Hot_water'] = df_s['amenities'].str.contains('Hot water')\ndf_s['Fridge'] = df_s['amenities'].str.contains('Refrigerator')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s['No_of_amentities'] = df_s['amenities'].apply(lambda x:len(x.split(',')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## dropping amenities as we have inferred above as different categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping amenities as we have inferred above as different categories\ndropped = ['amenities']\ndf_s.drop(dropped,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert false,true to 0 or 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert false,true to 0 or 1\ndf_s['Laptop_friendly_workspace'] = df_s['Laptop_friendly_workspace'].astype(int)\ndf_s['TV'] = df_s['TV'].astype(int)\ndf_s['Family_kid_friendly'] = df_s['Family_kid_friendly'].astype(int)\ndf_s['Host_greets_you'] = df_s['Host_greets_you'].astype(int)\ndf_s['Smoking_allowed'] = df_s['Smoking_allowed'].astype(int)\ndf_s['Hot_water'] = df_s['Hot_water'].astype(int)\ndf_s['Fridge'] = df_s['Fridge'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets also calculate distances from city center,airport and railway station that will again help in drawing a correlation to price"},{"metadata":{},"cell_type":"markdown","source":"### from city center"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate distance from central berlin\ndef haversine_distance_central(row):\n    berlin_lat,berlin_long = radians(52.5200), radians(13.4050)\n    R = 6373.0\n    long = radians(row['longitude'])\n    lat = radians(row['latitude'])\n    \n    dlon = long - berlin_long\n    dlat = lat - berlin_lat\n    a = sin(dlat / 2)**2 + cos(lat) * cos(berlin_lat) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    return R * c","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### from airport"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate distance from airport\ndef haversine_distance_airport(row):\n    berlin_lat,berlin_long = radians(52.3733), radians(13.5064)\n    R = 6373.0\n    long = radians(row['longitude'])\n    lat = radians(row['latitude'])\n    \n    dlon = long - berlin_long\n    dlat = lat - berlin_lat\n    a = sin(dlat / 2)**2 + cos(lat) * cos(berlin_lat) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    return R * c","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## from berlin railway station"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate distance from berlin railway station\ndef haversine_distance_rail(row):\n    berlin_lat,berlin_long = radians(52.5073), radians(13.3324)\n    R = 6373.0\n    long = radians(row['longitude'])\n    lat = radians(row['latitude'])\n    \n    dlon = long - berlin_long\n    dlat = lat - berlin_lat\n    a = sin(dlat / 2)**2 + cos(lat) * cos(berlin_lat) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n    return R * c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sin, cos, sqrt, atan2, radians","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s['distance_central'] = df_s.apply(haversine_distance_central,axis=1)\ndf_s['distance_airport'] = df_s.apply(haversine_distance_airport,axis=1)\ndf_s['distance_railways'] = df_s.apply(haversine_distance_rail,axis=1)\ndf_s['distance_avg'] = ( df_s['distance_central'] + df_s['distance_airport'] + df_s['distance_railways'] )/3.0\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we are ready to see price is dependent on how many factors for top 1000 properties; so first I will sort by price descending and then generate a correlation matrix "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_s.sort_values(by='price',ascending=False,axis=0,inplace=True) #sorting frame by price desc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_top10000 = df_s.head(10000)\ndf_top1000 = df_s.head(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"white\")\ncorr = df_s.corr()\n\n# generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(25, 15))\n\n# generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\":.5},cbar=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## price seems to depend largely on following factors\n\n## * No. of ameneties\n\n## * Is it family or kids friendly\n\n## * Cleaning fee\n\n## * how many guests it can accomodate\n\n## * price is not much dependent on distance"},{"metadata":{},"cell_type":"markdown","source":"# I create also a map for the different Airbnb listing in Berlin. To do that, I work with Folium, a Python visualization library, solely developed for visualizing geospatial data. I use Folium library to visualize geographic details of Berlin and the Airbnb listings and I create a map of Berlin with Airbnb listings superimposed on top. I use latitude and longitude values to get the map below:"},{"metadata":{},"cell_type":"markdown","source":"## let's plot all top 1000 properties and check where they are concentratedon a map [central berlin, railway station or airport]"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting a base map\nlat = 52.509\nlong = 13.381\nbase = folium.Map(location=[lat,long], zoom_start=12) #base map setting\nbase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neighbourhoods = folium.map.FeatureGroup()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat_long_list = [[52.520,13.405],[52.373,13.506],[52.507,13.332]] #locatioms of central berlin , railway stn, airport","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(lat_long_list)):\n    neighbourhoods.add_child(\n        folium.CircleMarker(\n        lat_long_list[i],\n        radius = 16,\n        color='yellow',\n        fill=True,\n        fill_color='red',\n        fill_opacity=0.6\n        )\n    )\nbase.add_child(neighbourhoods)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for inc_lat,inc_long in zip(df_top1000.longitude,df_top1000.latitude):\n    neighbourhoods.add_child(\n    folium.CircleMarker(\n    [inc_long,inc_lat],\n    radius = 6,\n    color='red',\n    fill=True,\n    fill_color='yellow',\n    fill_opacity=0.6\n    )\n)\nbase.add_child(neighbourhoods)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## the map plot indicates that the top 1000 properties are around central berlin railway station and very few near airports\n## This is also evident from below distribution plots where properties are mostly around central berlin & railway station"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nax0 = fig.add_subplot(2, 2, 1)\nax1 = fig.add_subplot(2, 2, 2)\nax2 = fig.add_subplot(2, 2, 3)\n\nsns.distplot(df_top1000[\"distance_central\"], bins=10, kde=False,ax=ax0)\nax0.set_title('Distances central berlin to apartments')\nax0.set_xlabel('distance_central')\nax0.set_ylabel('#properties')\n\nsns.distplot(df_top1000[\"distance_railways\"], bins=10, kde=False,ax=ax1)\nax1.set_title('Distances railway station to apartments')\nax1.set_xlabel('distance_railways')\nax1.set_ylabel('#properties')\n\nsns.distplot(df_top1000[\"distance_airport\"], bins=10, kde=False,ax=ax2)\nax2.set_title('Distances airport to apartments')\nax2.set_xlabel('distance_airport')\nax2.set_ylabel('#properties')\n\nplt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's extract the data about neighbourhood_cleansed,neighbourhood_group_cleansed, latitudes and longitudes"},{"metadata":{"trusted":true},"cell_type":"code","source":"Berlin_data = df_s[['neighbourhood_cleansed','neighbourhood_group_cleansed', 'latitude', 'longitude','price']].reset_index(drop=True)\nBerlin_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The dataframe has {} neighbourhood_group_cleansed and {} neighborhoods.'.format(\n        len(Berlin_data['neighbourhood_group_cleansed'].unique()),\n        Berlin_data.shape[0]\n    )\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's extract the data about the 5 most popular neighborhood in berlin"},{"metadata":{"trusted":true},"cell_type":"code","source":"Belin_c = df_s[df_s.neighbourhood_group_cleansed.isin(['Mitte','Friedrichshain-Kreuzberg','Pankow','Neukölln','Charlottenburg-Wilm.'])]\n    \nBelin_c.head()    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Belin_c.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"address =  'Berlin, Germany'\n\ngeolocator = Nominatim(user_agent=\"my-application\", timeout=10)\nBerlin_location = geolocator.geocode(address)\n\nprint('The geograpical coordinate of Berlin are {}, {}.'.format(Berlin_location.latitude, Berlin_location.longitude))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nBerlin_map=folium.Map(location=[Berlin_location.latitude,Berlin_location.longitude], zoom_start=12)\nBerlin_map\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's explore the first neighborhood in our dataframe"},{"metadata":{},"cell_type":"markdown","source":"## Get the neighborhood's latitude and longitude values.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"address = 'Berlin' \n\ngeolocator = Nominatim(user_agent=\"my-application\", timeout=10)\nparis_location = geolocator.geocode(address)\n\nprint('The geograpical coordinate of Berlin are {}, {}.'.format(Berlin_location.latitude, Berlin_location.longitude))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Foursquare Credentials and Version"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"CLIENT_ID = 'C50U5PW0KUQFAYG3VW3C3OTKWLKYAMDVDPEKKC3COOAML32M' # your Foursquare ID\nCLIENT_SECRET = 'FQW0AQA0PF52RSL5ZQ3YSHMI2O4QQWYDGVTC5HJ2WFCTO4VI' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First, let's create the GET request URL"},{"metadata":{"trusted":true},"cell_type":"code","source":"LIMIT = 100 # limit of number of venues returned by Foursquare API\n\n\nradius = 500 # define radius\n\n# create URL\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    Berlin_location.latitude, \n    Berlin_location.longitude, \n    radius, \n    LIMIT)\nurl # display URL","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Send the GET request and examine the resutls"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"results = requests.get(url).json()\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we are ready to clean the json and structure it into a pandas dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## And how many venues were returned by Foursquare?"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define function to get venues around the neighborhoods"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getNearbyVenues(results, names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name'],\n            v['venue']['id']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category',\n                  'Venue id'         ]\n    \n    return(nearby_venues)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get venues data of the neighbourhood_cleansed"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n\nBerlin_venues = getNearbyVenues(results, names=Belin_c['neighbourhood_cleansed'],\n                                   latitudes=Belin_c['latitude'],\n                                   longitudes=Belin_c['longitude']\n                                  )\n           ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Berlin_venues.shape)\nBerlin_venues.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check how many venues were returned for each neighborhood"},{"metadata":{"trusted":true},"cell_type":"code","source":"Berlin_venues.groupby('Neighborhood').count().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's find out how many unique categories can be curated from all the returned venues"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} uniques categories.'.format(len(Berlin_venues['Venue Category'].unique())))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyze Each Neighborhood"},{"metadata":{},"cell_type":"markdown","source":"### Encode the Neighborhood"},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding\nBerlin_onehot = pd.get_dummies(Berlin_venues, prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nBerlin_onehot['Neighborhood'] = Berlin_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [Berlin_onehot.columns[-1]] + list(Berlin_onehot.columns[:-1])\nBerlin_onehot = Berlin_onehot[fixed_columns]\n\nBerlin_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## And let's examine the new dataframe size"},{"metadata":{"trusted":true},"cell_type":"code","source":"Berlin_onehot.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"},{"metadata":{"trusted":true},"cell_type":"code","source":"Berlin_grouped = Berlin_onehot.groupby('Neighborhood').mean().reset_index()\nBerlin_grouped.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's confirm the new size"},{"metadata":{"trusted":true},"cell_type":"code","source":"Berlin_grouped.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's print each neighborhood along with the top 5 most common venues"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"num_top_venues = 5\n\nfor hood in Berlin_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = Berlin_grouped[Berlin_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's put that into a pandas dataframe\nFirst, let's write a function to sort the venues in descending order."},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now let's create the new dataframe and display the top 10 venues for each neighborhood."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = Berlin_grouped['Neighborhood']\n\nfor ind in np.arange(Berlin_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(Berlin_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## let's Count the number of venues for each venue category in the neighborhoods\n## top 5 most common venues"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_no_top_venue = Berlin_venues[['Neighborhood','Venue Category','Venue']].groupby(['Neighborhood','Venue Category']).count()\ndf_no_top_venue.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cluster Neighborhoods\n## Run k-means to cluster the neighborhood into 3 clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# set number of clusters\nkclusters = 3\nBerliln_grouped_clustering = Berlin_grouped.drop('Neighborhood', 1)\nBerliln_grouped_clustering.head()\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Berliln_grouped_clustering)\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Berliln_grouped_clustering.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nBerlin_merged = df_s\n\n# merge Berlin_grouped with Berlin_data to add latitude/longitude for each neighborhood\nBerlin_merged = Berlin_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='neighbourhood_cleansed')\nBerlin_merged.head() # check the last columns!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finally, let's visualize the resulting clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"latitude=52.5170365\nlongitude=13.3888599\n# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(Berlin_merged['latitude'], Berlin_merged['longitude'], Berlin_merged['neighbourhood_cleansed'], Berlin_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n\n       \nmap_clusters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examine Clusters\n## i will examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories"},{"metadata":{},"cell_type":"markdown","source":"##  Cluster 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster1 = Berlin_merged.loc[Berlin_merged['Cluster Labels'] == 0, Berlin_merged.columns[[0,1,2,3] + list(range(4, Berlin_merged.shape[1]))]]\nprint(cluster1.shape[0], \"neighborhood(s) in Cluster 1\")\ncluster1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Cluster 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster2 = Berlin_merged.loc[Berlin_merged['Cluster Labels'] == 1, Berlin_merged.columns[[0,1,2,3] + list(range(4, Berlin_merged.shape[1]))]]\nprint(cluster2.shape[0], \"neighborhood(s) in Cluster 2\")\ncluster2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster3 = Berlin_merged.loc[Berlin_merged['Cluster Labels'] == 2, Berlin_merged.columns[[0,1,2,3] + list(range(3, Berlin_merged.shape[1]))]]\nprint(cluster3.shape[0], \"neighborhood(s) in Cluster 3\")\ncluster3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****# Name the clusters\n## 1. Cluster 1 could be \"Restaurant & Bar\"\n\n## 2. Cluster 2 could be \" Lots of Hotel\"\n\n## 3. Cluster 3 could be \"Diverse Entertainment\"\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Discussion and Recommendations\n## k-means partitioned the Airbnb listings into 5 groups since we specified the algorithm to generate 5 clusters. The Airbnb listings in each cluster are similar to each other in terms of the features included in the dataset.\n\n## I check the centroids values by averaging the features and get the top most common venues in each cluster.\n\n"},{"metadata":{},"cell_type":"markdown","source":"****\n# Conclusion\n\n## I have combined Airbnb listings and Foursquare data to provide useful information to travelers in Berlin about the location and the most common venues they can visit in an area of 500 meters around their accommodation.\n\n## I have grouped the Airbnb listings around Berlin lake into 5 clusters based on similar venues and price levels. Travelers could leverage the clusters to filter listings according to their price preferences and the most common venues. In other words, travelers could search Airbnb listings according to location or venues they would like to visit, close to their accommodation.\n\nThe project is available on GitHub [5]"},{"metadata":{},"cell_type":"markdown","source":"# This is the end of project"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}