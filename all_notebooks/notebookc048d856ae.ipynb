{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d704767e-34a0-48cf-03a1-743f8e953d33"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a941aa62-2e5a-a7d9-077b-a35052670b7e"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom time import time\nfrom sklearn.metrics import f1_score\n\n# Read student data\nstudent_data = pd.read_csv(\"../input/student-data.csv\")\nprint (\"Student data read successfully!\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41a60af0-6985-170b-971e-f288c731524c"},"outputs":[],"source":"n_students = len(student_data.index)\nn_features = student_data.shape[1]\n\n# TODO: Calculate passing students\nn_passed = student_data[student_data[\"passed\"]==\"yes\"].count()[\"sex\"]\n\n# TODO: Calculate failing students\nn_failed = student_data[student_data[\"passed\"]==\"no\"].count()[\"sex\"]\n\n# TODO: Calculate graduation rate\ngrad_rate = float(n_passed)/float(n_students)*100\n\n# Print the results\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8e8e128-ce24-0017-20da-9c47cbd704c4"},"outputs":[],"source":"feature_cols = list(student_data.columns[:-1])\ntarget_col = student_data.columns[-1] \n\n# Show the list of columns\n#print \"Feature columns:\\n{}\".format(feature_cols)\n#print \"\\nTarget column: {}\".format(target_col)\n\n# Separate the data into feature data and target data (X_all and y_all, respectively)\nX_all = student_data[feature_cols]\ny_all = student_data[target_col]\n\n# Show the feature information by printing the first five rows\nprint (\"\\nFeature values:\")\nprint (X_all.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2d1d8f4-e505-0593-3aba-3583d9bce196"},"outputs":[],"source":"def preprocess_features(X):\n    ''' Preprocesses the student data and converts non-numeric binary variables into\n        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n    \n    # Initialize new output DataFrame\n    output = pd.DataFrame(index = X.index)\n\n    # Investigate each feature column for the data\n    for col, col_data in X.iteritems():\n        \n        # If data type is non-numeric, replace all yes/no values with 1/0\n        if col_data.dtype == object:\n            col_data = col_data.replace(['yes', 'no'], [1, 0])\n\n        # If data type is categorical, convert to dummy variables\n        if col_data.dtype == object:\n            # Example: 'school' => 'school_GP' and 'school_MS'\n            col_data = pd.get_dummies(col_data, prefix = col)  \n        \n        # Collect the revised columns\n        output = output.join(col_data)\n    \n    return output\n\nX_all = preprocess_features(X_all)\n#print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd8efc85-7ef7-3124-41ed-20ddc6ed1a2c"},"outputs":[],"source":"import matplotlib.pyplot as plt\nfrom sklearn import cross_validation\nfrom sklearn import tree\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97d237e6-1257-4c98-1cc8-be63dd009551"},"outputs":[],"source":"import matplotlib.pyplot as pl\nimport numpy as np\nimport sklearn.learning_curve as curves\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cross_validation import ShuffleSplit, train_test_split\nfrom sklearn.neural_network import MLPClassifier\n\ndef NN_Curve_Layer(X, y):\n    \"\"\" Calculates the performance of several models with varying sizes of training data.\n        The learning and testing scores for each model are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Generate the training set sizes increasing by 50\n    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n\n    # Create the figure window\n    fig = pl.figure(figsize=(10,7))\n\n    # Create three different models based on max_depth\n    for k, layer in enumerate([1,2,3,4]):\n        \n        # Create a Decision tree regressor at max_depth = depth\n        clf = MLPClassifier(hidden_layer_sizes=layer)\n\n        # Calculate the training and testing scores\n        sizes, train_scores, test_scores = curves.learning_curve(clf, X, y, \\\n            cv = cv, train_sizes = train_sizes, scoring = 'accuracy')\n        \n        # Find the mean and standard deviation for smoothing\n        train_std = np.std(train_scores, axis = 1)\n        train_mean = np.mean(train_scores, axis = 1)\n        test_std = np.std(test_scores, axis = 1)\n        test_mean = np.mean(test_scores, axis = 1)\n\n        # Subplot the learning curve \n        \n        ax = fig.add_subplot(2, 2, k+1)\n        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Cross-Validation Score')\n        ax.fill_between(sizes, train_mean - train_std, \\\n            train_mean + train_std, alpha = 0.15, color = 'r')\n        ax.fill_between(sizes, test_mean - test_std, \\\n            test_mean + test_std, alpha = 0.15, color = 'g')\n        \n        # Labels\n        ax.set_title('hidden layer = %s'%(layer))\n        ax.set_xlabel('Number of Training Points')\n        ax.set_ylabel('Score')\n        ax.set_xlim([0, X.shape[0]*0.8])\n        ax.set_ylim([-0.05, 1.05])\n    \n    # Visual aesthetics\n    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n\n    fig.suptitle('Neural Network Classifier Learning Performances', fontsize = 16, y = 1.03)\n    fig.tight_layout()\n    fig.show()\n\ndef NN_Curve_Action(X, y):\n    \"\"\" Calculates the performance of several models with varying sizes of training data.\n        The learning and testing scores for each model are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Generate the training set sizes increasing by 50\n    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n\n    # Create the figure window\n    fig = pl.figure(figsize=(10,7))\n\n    # Create three different models based on max_depth\n    for k, act in enumerate['identity', 'logistic', 'tanh', 'relu']:\n        \n        # Create a Decision tree regressor at max_depth = depth\n        clf = MLPClassifier(activation=act)\n\n        # Calculate the training and testing scores\n        sizes, train_scores, test_scores = curves.learning_curve(clf, X, y, \\\n            cv = cv, train_sizes = train_sizes, scoring = 'accuracy')\n        \n        # Find the mean and standard deviation for smoothing\n        train_std = np.std(train_scores, axis = 1)\n        train_mean = np.mean(train_scores, axis = 1)\n        test_std = np.std(test_scores, axis = 1)\n        test_mean = np.mean(test_scores, axis = 1)\n\n        # Subplot the learning curve \n        \n        ax = fig.add_subplot(2, 2, k+1)\n        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Cross-Validation Score')\n        ax.fill_between(sizes, train_mean - train_std, \\\n            train_mean + train_std, alpha = 0.15, color = 'r')\n        ax.fill_between(sizes, test_mean - test_std, \\\n            test_mean + test_std, alpha = 0.15, color = 'g')\n        \n        # Labels\n        ax.set_title('activation = %s'%(act))\n        ax.set_xlabel('Number of Training Points')\n        ax.set_ylabel('Score')\n        ax.set_xlim([0, X.shape[0]*0.8])\n        ax.set_ylim([-0.05, 1.05])\n    \n    # Visual aesthetics\n    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n\n    fig.suptitle('Neural Network Classifier Learning Performances', fontsize = 16, y = 1.03)\n    fig.tight_layout()\n    fig.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09eb47be-b6cb-c3a4-2816-df0046eee3bd"},"outputs":[],"source":"NN_Curve_Layer(X_all, y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de73d804-f20c-7a6c-93be-bc23c7362ad9"},"outputs":[],"source":"NN_Curve_Action(X_all, y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb21ed80-fe00-c055-7c41-72bf2034f543"},"outputs":[],"source":"def NN_Curve_Action(X, y):\n    \"\"\" Calculates the performance of several models with varying sizes of training data.\n        The learning and testing scores for each model are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Generate the training set sizes increasing by 50\n    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n\n    # Create the figure window\n    fig = pl.figure(figsize=(10,7))\n\n    # Create three different models based on max_depth\n    for k, act in enumerate(['identity', 'logistic', 'tanh', 'relu']):\n        \n        # Create a Decision tree regressor at max_depth = depth\n        clf = MLPClassifier(activation=act)\n\n        # Calculate the training and testing scores\n        sizes, train_scores, test_scores = curves.learning_curve(clf, X, y, \\\n            cv = cv, train_sizes = train_sizes, scoring = 'accuracy')\n        \n        # Find the mean and standard deviation for smoothing\n        train_std = np.std(train_scores, axis = 1)\n        train_mean = np.mean(train_scores, axis = 1)\n        test_std = np.std(test_scores, axis = 1)\n        test_mean = np.mean(test_scores, axis = 1)\n\n        # Subplot the learning curve \n        \n        ax = fig.add_subplot(2, 2, k+1)\n        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Cross-Validation Score')\n        ax.fill_between(sizes, train_mean - train_std, \\\n            train_mean + train_std, alpha = 0.15, color = 'r')\n        ax.fill_between(sizes, test_mean - test_std, \\\n            test_mean + test_std, alpha = 0.15, color = 'g')\n        \n        # Labels\n        ax.set_title('activation = %s'%(act))\n        ax.set_xlabel('Number of Training Points')\n        ax.set_ylabel('Score')\n        ax.set_xlim([0, X.shape[0]*0.8])\n        ax.set_ylim([-0.05, 1.05])\n    \n    # Visual aesthetics\n    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n\n    fig.suptitle('Neural Network Classifier Learning Performances', fontsize = 16, y = 1.03)\n    fig.tight_layout()\n    fig.show()\ndef NN_Validation_layer(X, y):\n    \"\"\" Calculates the performance of the model as model complexity increases.\n        The learning and testing errors rates are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Vary the max_depth parameter from 1 to 10\n    layer = np.arange(1,10)\n\n    # Calculate the training and testing scores\n    clf = DecisionTreeClassifier()\n    train_scores, test_scores = curves.validation_curve(clf, X, y, \\\n        param_name = \"hidden_layer_sizes\", param_range = layer, cv = cv, scoring = 'accuracy')\n\n    # Find the mean and standard deviation for smoothing\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n\n    # Plot the validation curve\n    pl.figure(figsize=(7, 5))\n    pl.title('Neural Network Classifier Validation Performance')\n    pl.plot(max_depth, train_mean, 'o-', color = 'r', label = 'Training Score')\n    pl.plot(max_depth, test_mean, 'o-', color = 'g', label = 'Validation Score')\n    pl.fill_between(max_depth, train_mean - train_std, \\\n        train_mean + train_std, alpha = 0.15, color = 'r')\n    pl.fill_between(max_depth, test_mean - test_std, \\\n        test_mean + test_std, alpha = 0.15, color = 'g')\n    \n    # Visual aesthetics\n    pl.legend(loc = 'lower right')\n    pl.xlabel('Hidden Layer')\n    pl.ylabel('Score')\n    pl.ylim([-0.05,1.05])\n    pl.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6deb388-5163-de8c-98d9-b7c8e8f6700e"},"outputs":[],"source":"NN_Curve_Action(X_all, y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d029d87-b06a-0bd2-837a-5072e4fabc91"},"outputs":[],"source":"NN_Validation_layer(X_all,y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0dec09c-08eb-f0f0-02dd-52a5ceec89f2"},"outputs":[],"source":"def NN_Validation_layer(X, y):\n    \"\"\" Calculates the performance of the model as model complexity increases.\n        The learning and testing errors rates are then plotted. \"\"\"\n    \n    # Create 10 cross-validation sets for training and testing\n    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n\n    # Vary the max_depth parameter from 1 to 10\n    layer = np.arange(1,10)\n\n    # Calculate the training and testing scores\n    clf = MLPClassifier()\n    train_scores, test_scores = curves.validation_curve(clf, X, y, \\\n        param_name = \"hidden_layer_sizes\", param_range = layer, cv = cv, scoring = 'accuracy')\n\n    # Find the mean and standard deviation for smoothing\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n\n    # Plot the validation curve\n    pl.figure(figsize=(7, 5))\n    pl.grid()\n    pl.title('Neural Network Classifier Validation Performance')\n    pl.plot(layer, train_mean, 'o-', color = 'r', label = 'Training Score')\n    pl.plot(layer, test_mean, 'o-', color = 'g', label = 'Validation Score')\n    pl.fill_between(layer, train_mean - train_std, \\\n        train_mean + train_std, alpha = 0.15, color = 'r')\n    pl.fill_between(layer, test_mean - test_std, \\\n        test_mean + test_std, alpha = 0.15, color = 'g')\n    \n    # Visual aesthetics\n    pl.legend(loc = 'lower right')\n    pl.xlabel('Hidden Layer')\n    pl.ylabel('Score')\n    pl.ylim([-0.05,1.05])\n    pl.show()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edaeaa3c-ae39-375e-5ac1-a416539d253d"},"outputs":[],"source":"NN_Validation_layer(X_all, y_all)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25ca51f1-9e77-4b49-cf12-2826ba3b395f"},"outputs":[],"source":"def train_classifier(clf, X_train, y_train):\n    ''' Fits a classifier to the training data. '''\n    \n    # Start the clock, train the classifier, then stop the clock\n    start = time()\n    clf.fit(X_train, y_train)\n    end = time()\n    \n    # Print the results\n    print \"Trained model in {:.4f} seconds\".format(end - start)\n\n    \ndef predict_labels(clf, features, target):\n    ''' Makes predictions using a fit classifier based on F1 score. '''\n    \n    # Start the clock, make predictions, then stop the clock\n    start = time()\n    y_pred = clf.predict(features)\n    end = time()\n    \n    # Print and return results\n    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n    return f1_score(target.values, y_pred)\n\n\ndef train_predict(clf, X_train, y_train, X_test, y_test):\n    ''' Train and predict using a classifer based on F1 score. '''\n    \n    # Indicate the classifier and the training set size\n    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n    \n    # Train the classifier\n    train_classifier(clf, X_train, y_train)\n    \n    # Print the results of prediction for both training and testing\n    print (\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n    print (\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22c7f28a-bce1-a361-bb37-230f23f3a18a"},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.cross_validation import ShuffleSplit, train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n#from sklearn import \n\nX_train, X_test, y_train, y_test = train_test_split(X_all,y_all,test_size=0.2,random_state=42)\n# TODO: Initialize the three models\nclf_A = tree.DecisionTreeClassifier()\nclf_B = GradientBoostingClassifier()\nclf_C = SVC()\nclf_D = KNeighborsClassifier()\n\n\n# TODO: Execute the 'train_predict' function for each classifier and each training set size\ntrain_predict(clf_A, X_train, y_train, X_test, y_test)\ntrain_predict(clf_B, X_train, y_train, X_test, y_test)\ntrain_predict(clf_C, X_train, y_train, X_test, y_test)\ntrain_predict(clf_D, X_train, y_train, X_test, y_test)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}