{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is Recommendation System ?\nRecommender/recommendation system is a subclass of information filtering system that seeks to predict the rating/ preference a user would give to an item.\n\nThey are primarily used in applications where a person/ entity is involved with a product/ service. To further improve their experience with this product, we try to personalize it to their needs. For this we have to look up at their past interactions with this product.\n\n*In one line* -> **Specialized content for everyone.**\n\n*For further info, [Wiki](https://en.wikipedia.org/wiki/Recommender_system#:~:text=A%20recommender%20system%2C%20or%20a,would%20give%20to%20an%20item.)*\n\n## Types of Recommender System\n* 1). Popularity Based\n* 2). Classification Based\n* 3). Content Based\n* 4). Collaborative Based\n* 5). Hybrid Based (Content + Collaborative)\n* 6). Association Based Rule Mining\n\n# Content based recommender system\nRecommends content based on product description. Here we would convert movie titles into a vector to find its cosine similarity. Similar movie would have a high cosine similarity and thus would be recommended to the user.\n\n# Import packages and dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We would use Rake package, Rake stands for Rapid Automatic Keyword Extraction algorithm which is a domain independent keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and it's co-occurrance with other words in the text.\n\n*Credits to -> [csurfer](https://github.com/csurfer/rake-nltk)*","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false},"cell_type":"code","source":"!pip install rake_nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom rake_nltk import Rake\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer #tokenizes a collection of words extracted from a text doc\nfrom ast import literal_eval #This evaluates whether an expresion is a Python datatype or not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data = pd.read_csv('../input/imdb-extensive-dataset/IMDb movies.csv')\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#There are many null values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets convert all Null values into 'missing value'\ndata = data.fillna('missing value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recommend movies based on a director/ writer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recommend movies based on a director (Pls give full names)\n#rec_director = input('Enter director you want to be recommended movies of: ')\nrec_director = 'Christopher Nolan'\ndata[data['director'] == rec_director]\n\n#Recommend movies based on a writer (Pls give full names)\n#rec_writer = input('Enter writer you want to be recommended movies of: ')\n#data[data['writer'] == rec_writer]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recommend movies based on actor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#rec_actor = input('Enter actor you want to be recommended movies of: ')\nrec_actor = 'Ryan Gosling'\nrec_actor = data[data['actors'].str.contains(rec_actor)] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rec_actor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Things to do:**\n* Impute all missing values\n* Extract only relevant columns\n* Convert all columns into lower case\n* Split all names into comma separated\n* Combine director, writer, actor names, production company into 1 word respectively this will be used for text extraction","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Extract relevant columns that would influence a movie's rating based on the content.\n\n#Due to memory issue using just 3k data. You can try this code on Google Colabs for better performance\ndata1 = data[['title','genre','director','actors','description']].head(3000)\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remember the more columns you extract here more are the chances of overfitting as movies recommended will also take into account director, writer, production_company and et all. These features may be irrelevant to a user who wants to be recommended a movie based on his preferences.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Impute all missing values\ndata1 = data1.fillna('missing value')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Convert all columns into lower case\ndata1 = data1.applymap(lambda x: x.lower() if type(x) == str else x)\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Use genre as a list of words\ndata1['genre'] = data1['genre'].map(lambda x: x.split(','))\ndata1['genre']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Similarily lets separate names into first and last name with commas\ndata1[['director','actors']] = data1[['director','actors']].applymap(lambda x: x.split(',')) #apply map used for more than 1 column, map for 1 column\ndata1[['director','actors']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Combine director, actor names into 1 word respectively this will be used for text extraction\n\nfor index,row in data1.iterrows():\n    row['actors'] = [x.replace(' ','') for x in row['actors']]\n    row['director'] = [x.replace(' ','') for x in row['director']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For content based movie recommendation we have to use NLP techniques like \n* Keyword extraction -> Extract keywords from description\n* Bag of Words Creation -> Extracting all words from a row into a Bag\n* Count Vectorizer -> Count frequency of words from this BOW\n* Cosine Similarity -> Find cosine similarity between all movie titles\n\n\n\n\n# Keyword Extraction\nKeyword extraction is automatic detection of terms that best describe the subject of a document. We will use Rake to extract keywords from description.\n\n*For more info -> [Wiki](https://en.wikipedia.org/wiki/Keyword_extraction)*\n\n**Things to do:**\n* Create a empty list Keywords\n* Loop across all rows to extract all keywords from description\n* Create a dictionary with keywords and all their scores\n* Append 'keywords' column into dataframe","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Create a empty list Keywords\ndata1['keywords'] = ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Loop across all rows to extract all keywords from description\nfor index, row in data1.iterrows():\n    description = row['description']\n    \n    #instantiating Rake by default it uses English stopwords from NLTK and discards all punctuation chars\n    r = Rake()\n    \n    #extract words by passing the text\n    r.extract_keywords_from_text(description)\n    \n    #get the dictionary with key words and their scores\n    keyword_dict_scores = r.get_word_degrees()\n    \n    #assign keywords to new columns\n    row['keywords'] = list(keyword_dict_scores.keys())\n    \n#drop description","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data1.set_index('title', inplace = True)\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bag of Words Creation\n\nThis is an important technique used in NLP and other such information retrieval programs to create a bag of words concerning a text *(in our case its 'title')* Here the occurence of every word is used as a feature for training a classifier.\n\n*For more info, -> [Wiki](https://en.wikipedia.org/wiki/Bag-of-words_model)*\n\n**Things to do:**\n* Create empty list of bow\n* Iterate over all rows combining genre with director & actor names","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data1['bow'] = ''\ncolumns = data1.columns\nfor index, row in data1.iterrows():\n    words = ''\n    for col in columns:\n        words = words + ' '.join(row[col])+ ' '\n        row['bow'] = words\n        \n\n#Use below code if you do not want to include director name into bow\n    #for col in columns:\n        #if col != 'director':\n            #words = words + ' '.join(row[col])+ ' '\n        #else:\n            #words = words + row[col]+ ' '\n        #row['bow'] = words\n\n    \n#df1.drop(columns = [col for col in df1.columns if col!= 'bag_of_words'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Count Vectorizer\n\nConvert a collection of text documents to a matrix of token counts. It's a data table that is obtained after normalization of next-generation sequencing data.\n\n*For more info -> [Count Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)*\n\n**Things to do:**\n* Instantiate & Fit CountVectorizer into 'bow' -> to create count_matrix this is useful for cosine similarity\n* 'title' column is an Index as we saw above, hence we convert 'title' column as Series -> to use 'title' as an ordered numerical list\n* Understand the count_matrix -> Check its shape and type\n* Convert sparse count_matrix to dense vector -> To reduce complexity, *For more info -> [Sparse Matrices](https://machinelearningmastery.com/sparse-matrices-for-machine-learning/)*\n* Dense matrix for a sample row\n* Check all words in the vocabulary\n* Generate cosine similarity for count_matrix","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#instantiating and generating the count matrix\ncount = CountVectorizer()\ncount_matrix = count.fit_transform(data1['bow'])\n\n#create a Series for movie titles so they are associated to an ordered numerical list, we will use this later to match index\nindices = pd.Series(data1.index)\nindices[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Shape count_matrix\ncount_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"type(count_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Convert sparse count_matrix to dense vector\nc = count_matrix.todense()\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_kg_hide-output":true},"cell_type":"code","source":"#Print count_matrix for 0th row\nprint(count_matrix[0,:]) #This shows all words and their frequency in bow of 0th row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Gives vocabulary of all words in 'bow' and their counts\ncount.vocabulary_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculate Cosine similarity","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#generating the cosine similarity matrix\n\ncosine_sim = cosine_similarity(count_matrix, count_matrix)\ncosine_sim","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recommend top n movies given a movie name\n\n**Things to do:**\n* Create empty list\n* Get index of the movie that matches this title\n* Find highest cosine_sim this title shares with other titles extracted earlier and save it in a Series\n* Get indexes of the 'n' most similar movies\n* Populate list with titles of n matching movies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets build a function that takes in movie and recommends top n movies\n\ndef recommendations(title,n,cosine_sim = cosine_sim):\n    recommended_movies = []\n    \n    #get index of the movie that matches the title\n    idx = indices[indices == title].index[0]\n    \n    #find highest cosine_sim this title shares with other titles extracted earlier and save it in a Series\n    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n    \n    #get indexes of the 'n' most similar movies\n    top_n_indexes = list(score_series.iloc[1:n+1].index)\n    print(top_n_indexes)\n    \n    #populating the list with titles of n matching movie\n    for i in top_n_indexes:\n        recommended_movies.append(list(data1.index)[i])\n    return recommended_movies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#movie = input(\"Enter the movie name you wished to be recommended similar movies: \").lower()\nmovie = 'cleopatra'\n#n = int(input(\"How many movies do you want to be recommended: \"))\nn = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"recommendations(movie, n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What is the index of the movie you requested ?**","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"indices[indices == movie].index[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What is the cosine similarity this movie shares with all other movies ?**","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"pd.Series(cosine_sim[indices[indices == movie].index[0]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Thus we can recommend movies based on their content.***","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}