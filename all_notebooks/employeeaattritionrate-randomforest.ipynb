{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing the data and preparing it for modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import data analysis tools \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we've got our tools for data analysis ready, we can import the data and start to explore it.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/hackerearth-employee-attrition/Train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data Info : \", df.info())\nprint(\"__________________________________________________\")\nprint(\"Data Describe : \",df.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape[0],df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the no. of unique items present in the categorical column\ndf.select_dtypes('object').nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the label \ndf.Attrition_rate.plot.hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the Effect of age on employee’s Performnce\n\n\nper=df[['Gender','growth_rate']].groupby(['Gender']).agg('median')\nper","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"per.T.plot(kind=\"bar\",figsize=(10\n                               ,5));\nplt.title(\"Growth Rate\");\nplt.ylabel(\"Rate\");\nplt.legend(loc=\"upper left\")\nplt.xticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a plot\npd.crosstab(df.Gender, df.Attrition_rate).plot(kind=\"bar\", figsize=(15,5), color=[\"salmon\", \"lightblue\"])\n\n# Add some attributes to it\nplt.title(\"Attrition Rate  Frequency for Sex\")\nplt.xlabel(\"Gender\")\nplt.ylabel(\"Rate\")\nplt.legend([\"Female\", \"Male\"])\nplt.xticks(rotation=0); # keep the labels on the x-axis vertical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a plot\npd.crosstab(df.Education_Level, df.Attrition_rate).plot(kind=\"bar\", figsize=(15,5), color=[\"salmon\", \"lightblue\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n# Visualizing the number of male and female in the data set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.countplot(df['Gender'], palette = 'bone')\nplt.title('Comparison of Males and Females', fontweight = 30)\nplt.xlabel('Gender')\nplt.ylabel('Count');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing the different groups in the data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nsns.countplot(df['Hometown'], palette = 'pink')\nplt.title('Comparison of various groups', fontweight = 30, fontsize = 20)\nplt.xlabel('Groups')\nplt.ylabel('count');\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nsns.countplot(df['Relationship_Status'], palette = 'pink')\nplt.title('Comparison of various groups', fontweight = 30, fontsize = 20)\nplt.xlabel('Groups')\nplt.ylabel('count');\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets check the Effect of age on employee’s Performnce\n\n\nper=df[['Relationship_Status','Attrition_rate']].groupby(['Relationship_Status']).agg('sum')\nper","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"per.T.plot(kind=\"bar\",figsize=(10,5));\nplt.title(\"Relationship Status\");\nplt.ylabel(\"Rates\");\nplt.legend(loc=\"upper right\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# These columns contain strings\nfor label,content in df.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will turn all of the string values into category values\nfor label,content in df.items():\n    if pd.api.types.is_string_dtype(content):\n        df[label]=content.astype(\"category\").cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Gender.cat.categories\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All of our data is categorical and thus we can now turn the categories into numbers, however let's check missing values...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()/len(df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill missing values\nFrom our experience with machine learning models. We know two things:\n\n1- All of our data has to be numerical.\n\n2- There can't be any missing values\n\nAnd as we've seen using df_tmp.isna().sum() our data still has plenty of missing values.\n\nLet's fill them.\n\nFilling numerical values first\nWe're going to fill any column with missing values with the median of that column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for label,content in df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for which numeric columns have null values\nfor label,content in df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numeric rows with the median\nfor label,content in df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Fill missing numeric values with median since it's more robust than the mean\n            df[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if there's any null values\nfor label, content in df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling and turning categorical variables to numbers\nNow we've filled the numeric values, we'll do the same with the categorical values at the same time as turning them into numbers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn categorical variables into numbers\nfor label, content in df.items():\n    # Check columns which *aren't* numeric\n    if not pd.api.types.is_numeric_dtype(content):\n         \n        # We add the +1 because pandas encodes missing categories as -1\n        df[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now all of our data is numeric and there are no missing values, we should be able to build a machine learning model!\n\nLet's reinstantiate our trusty RandomForestRegressor.\n\nThis will take a few minutes which is too long for interacting with it. So what we'll do is create a subset of rows to work with.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n# Instantiate model\nmodel = RandomForestRegressor(n_jobs=-1)\n\n# Fit the model\nmodel.fit(df.drop(\"Attrition_rate\", axis=1), df.Attrition_rate.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score the model\nmodel.score(df.drop(\"Attrition_rate\", axis=1), df.Attrition_rate.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting data into train/valid sets\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the data set into training and test sets\nx=df.drop(\"Attrition_rate\", axis=1)\ny=df.Attrition_rate.values\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.20, random_state = 42)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building an evaluation function\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create evaluation function (the competition uses Root Mean Square Log Error)\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error\ndef rmsle(y_test, y_preds):\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n\n# Create function to evaluate our model\ndef show_scores(model):\n    train_preds = model.predict(x_train)\n    val_preds = model.predict(x_val)\n    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n              \"Valid MAE\": mean_absolute_error(y_val, val_preds),\n              \"Training RMSLE\": rmsle(y_train, train_preds),\n              \"Valid RMSLE\": rmsle(y_val, val_preds),\n              \"Training R^2\": model.score(x_train, y_train),\n              \"Valid R^2\": model.score(x_val, y_val)}\n    return scores\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing our model on a subset (to tune the hyperparameters)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change max samples in RandomForestRegressor\nmodel = RandomForestRegressor(n_jobs=-1,\n                              max_samples=2000)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cutting down the max number of samples each tree can see improves training time\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(model)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter tuning with RandomizedSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# Different RandomForestClassifier hyperparameters\nrf_grid = {\"n_estimators\": np.arange(10, 100, 10),\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2),\n           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"]\n           }\n\nrs_model = RandomizedSearchCV(RandomForestRegressor(),\n                              param_distributions=rf_grid,\n                              n_iter=2,\n                              cv=5,\n                              verbose=True)\n\nrs_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train a model with the best parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ideal_model = RandomForestRegressor(n_estimators=80,\n                                    min_samples_leaf=4,\n                                    min_samples_split=17,\n                                    max_features='auto',\n                                    n_jobs=-1\n                                )\nideal_model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(ideal_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions on test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/hackerearth-employee-attrition/Test.csv\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing the data\nOur model has been trained on data formatted in the same way as the training data.\n\nThis means in order to make predictions on the test data, we need to take the same steps we used to preprocess the training data to preprocess the test data.\n\nRemember: Whatever you do to the training data, you have to do to the test data.\n\nLet's create a function for doing so (by copying the preprocessing steps we used above).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in df_test.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in df_test.items():\n        if not pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(df):\n     \n    # Fill numeric rows with the median\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                \n                df[label] = content.fillna(content.median())\n                \n        # Turn categorical variables into numbers\n        if not pd.api.types.is_numeric_dtype(content):\n            if pd.api.types.is_string_dtype(content):\n                df[label]=content.astype(\"category\").cat.as_ordered()\n            \n            # We add the +1 because pandas encodes missing categories as -1\n            df[label] = pd.Categorical(content).codes+1        \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=preprocess_data(df_test)\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on the test dataset using the best model\ntest_preds=ideal_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create DataFrame compatible with Kaggle submission requirements\ndf_preds=pd.DataFrame()\ndf_preds['Employee_ID']=df_test[\"Employee_ID\"]\ndf_preds[\"Attrition_rate\"] = test_preds\ndf_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_preds.to_csv(\"predictions.csv\",\n               index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find feature importance of our best model\nideal_model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function for plotting feature importance\ndef plot_features(columns, importances, n=20):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importance\": importances})\n          .sort_values(\"feature_importance\", ascending=False)\n          .reset_index(drop=True))\n    \n    sns.barplot(x=\"feature_importance\",\n                y=\"features\",\n                data=df[:n],\n                orient=\"h\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features(x_train.columns, ideal_model.feature_importances_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(ideal_model.feature_importances_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}