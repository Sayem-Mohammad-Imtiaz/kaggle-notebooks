{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task: Descriptive Analysis\n\n### Task Details\n\n1. Load the data from the CSV files\n2. Explore each dataset - columns, counts, basic stats\n3. Understand the domain context and explore underlying patterns in the data\n4. Explore the data and try to answer questions like -\n    * What is the mean value of daily yield?\n    * What is the total irradiation per day?\n    * What is the max ambient and module temperature?\n    * How many inverters are there for each plant?\n    * What is the maximum/minimum amount of DC/AC Power generated in a time interval/day?\n    * Which inverter (`SOURCE_KEY`) has produced maximum DC/AC power?\n    * Rank the inverters based on the DC/AC power they produce\n    * Is there any missing data?\n\nYou might have to pre-process the data to allow for some of the analysis (hint: date and time)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Task 1. Load the data from the CSV files\n\ndf_p1_gen = pd.read_csv(\"../input/solar-power-generation-data/Plant_1_Generation_Data.csv\")\ndf_p1_sen = pd.read_csv(\"../input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv\")\ndf_p2_gen = pd.read_csv(\"../input/solar-power-generation-data/Plant_2_Generation_Data.csv\")\ndf_p2_sen = pd.read_csv(\"../input/solar-power-generation-data/Plant_2_Weather_Sensor_Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting basic overview of 1 dataset with .info()\n\nprint(df_p1_gen.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying to get same information by hand\n\ndef df_info(df):\n    cols_data = \"\\n\".join([f\"{i}. '{col}' - {df[col].dtype}, Non-null: {df[col].count()}\" for i, col in enumerate(df.columns, 1)])\n    return f\"Number of Rows: {len(df.index)}\\nColumns (n: {df.columns.size}): \\n{cols_data}\"\n\n\nprint(\"Generator Data (Plant 1)\\n\", df_info(df_p1_gen), sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Sensor Data (Plant 1)\\n\", df_info(df_p1_sen), sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Generator Data (Plant 2)\\n\", df_info(df_p2_gen), sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_p1_gen.index) - len(df_p2_gen.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Sensor Data (Plant 2)\\n\", df_info(df_p2_sen), sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From preliminary info\n\n\n1. **Generator Data (Plant 1)**: 68788 entries, 7 columns\n\n2. **Sensor Data (Plant 1)**: 3182 entries, 6 columns (3 of them same as from Generator Data - DATE_TIME, PLANT_ID, SOURCE_KEY)\n\n3. **Generator Data (Plant 2)**: 67698 entries, 7 columns (same columns as Plant 1)\n\n4. **Sensor Data (Plant 2)**: 3259 entries, 6 columns (same columns as Plant 1)\n\n\n--> No null values in any columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# More detailed view of Data from Plant 1's generator\n\ndf_p1_gen.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of unqiue SOURCE_KEYs (generators)\n\nprint(\"Number of unique generators:\", df_p1_gen[\"SOURCE_KEY\"].unique().size)\nprint(df_p1_gen[\"SOURCE_KEY\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks like lots of zeroes in DC_POWER, AC_POWER, and DAILY_YIELD columns\n\np1_gen_zeroes_count_dc = df_p1_gen[\"DC_POWER\"].value_counts()[0]\np1_gen_zeroes_count_ac = df_p1_gen[\"AC_POWER\"].value_counts()[0]\np1_gen_zeroes_count_dy = df_p1_gen[\"DAILY_YIELD\"].value_counts()[0]  # Suffix 'dy' = DAILY_YIELD\n\nprint(\"Number of zeroes in columns: \")\nfor colname in [\"DC_POWER\", \"AC_POWER\", \"DAILY_YIELD\"]:\n    print(f\"{colname}: {df_p1_gen[colname].value_counts()[0]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of zeroes in DC_POWER column = Number of zeroes in AC_POWER column\n\n31951/68778 = ~0.46 --> 46% of all DC_POWER/AC_POWER values are 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the values of DC_POWER and AC_POWER are 0 in the same rows\n\np1_gen_dc_zero = df_p1_gen[df_p1_gen.DC_POWER == 0]\n\nprint(f\"Number of rows: {len(p1_gen_dc_zero)}\")\nprint(f\"Number of zeroes in AC_POWER column: {p1_gen_dc_zero['AC_POWER'].value_counts()[0]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both are 31951, which means AC_POWER and DC_POWER are indeed zero in the same rows. \n\n* 46% of all rows have zero value of AC_POWER and DC_POWER\n* If DC_POWER is 0, AC_POWER is always 0 and vice versa.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check how DAILY_YIELD varies when DC_POWER and AC_POWER are 0\n\np1_gen_dc_zero[\"DAILY_YIELD\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"18558 out of 18696 zero values for DAILY_YIELD are when AC_POWER and DC_POWER are zero","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_gen_dc_zero.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"--> The mean for `DAILY_YIELD` has dropped from 3295.968 to 2941.022\n\n--> Standard deviation has increased from 3145.178 to 3564.440\n\n--> While there are many 0.00 values, the max value for `DAILY_YIELD` from the whole dataset is also the max value here (9163.0000), median has gone down from ~2658 to 0.0, but the 75% percentile value has increased from 6258 to 6705.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p2_sen.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total irradiation per day\n\np1_total_irrad, p2_total_irrad = df_p1_sen[\"IRRADIATION\"].sum(), df_p2_sen[\"IRRADIATION\"].sum()\n\nprint(f\"Plant 1: {p1_total_irrad}\", f\"Plant 2: {p2_total_irrad}\", sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of inverters in each plant\n\np1_invs, p2_invs = df_p1_gen[\"SOURCE_KEY\"].unique().size, df_p2_gen[\"SOURCE_KEY\"].unique().size\n\nprint(f\"Plant 1: {p1_invs}\", f\"Plant 2: {p2_invs}\", sep=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_gen_total_dc = df_p1_gen.groupby(\"SOURCE_KEY\")[\"DC_POWER\"].sum().sort_values(ascending=False)\nprint(p1_gen_total_dc, \"\\n\")\n\n# Since sorted in descending order, first element will be max\np1_gen_max_dc_inv = p1_gen_total_dc.keys()[0]\np1_gen_max_dc = p1_gen_total_dc[0]\nprint(f\"Inverter with max DC power in Plant 1: {p1_gen_max_dc_inv} ({p1_gen_max_dc})\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p2_gen_total_dc = df_p2_gen.groupby(\"SOURCE_KEY\")[\"DC_POWER\"].sum().sort_values(ascending=False)\nprint(p2_gen_total_dc, \"\\n\")\n\np2_gen_max_dc_inv = p2_gen_total_dc.keys()[0]\np2_gen_max_dc = p2_gen_total_dc[0]\nprint(f\"Inverter with max DC power in Plant 2: {p2_gen_max_dc_inv} ({p2_gen_max_dc})\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(p1_gen_dc_zero[\"SOURCE_KEY\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Would be better if we had proper datetime field instead of datetime as string. \n# Then we can see at what times was the power generation zero\n\np1_gen_dc_by_dt = df_p1_gen.groupby(\"DATE_TIME\")[\"DC_POWER\"].sum().sort_values(ascending=False)\n\nprint(p1_gen_dc_by_dt.describe())\nprint(p1_gen_dc_by_dt.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inverter with maximum DC_POWER in any 15 minutes\n\ndf_p1_gen[\"DATE_TIME\"][df_p1_gen[\"DC_POWER\"].idxmax()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For doing \"time\" operations with the DATE_TIME column, I tried to convert it to a\n# more standard format with pd.to_datetime, but it was giving some errors while trying to convert that to time\n# This approach is straightforward and easy\n\ndf_p1_gen_dt_to_time = df_p1_gen[\"DATE_TIME\"].apply(lambda x: x[-5:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_gen_with_time = df_p1_gen.copy()\ndf_p1_gen_with_time[\"TIME\"] = df_p1_gen_dt_to_time\n\ndf_p1_gen_with_time.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looping over it is slow!!\n\ndf_p1_gen_6_to_20 = df_p1_gen_with_time[[True if int(row[\"TIME\"][:2]) > 6 and int(row[\"TIME\"][:2]) < 20 else False for index, row in df_p1_gen_with_time.iterrows()]]\ndf_p1_gen_6_to_20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_gen_with_time[df_p1_gen_with_time.DC_POWER == 0.0][\"TIME\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For most times in day, the number of failures is in single digit or 0\n# On some days, sunset happened before 20:00 and therefore their count is more\n\ndf_p1_gen_6_to_20_dc_zero = df_p1_gen_6_to_20[df_p1_gen_6_to_20.DC_POWER == 0.0]\n\nprint(df_p1_gen_6_to_20_dc_zero.head())\nprint(df_p1_gen_6_to_20_dc_zero[\"TIME\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_gen[\"DATE_TIME\"] = pd.to_datetime(df_p1_gen[\"DATE_TIME\"], format=\"%d-%m-%Y %H:%M\")\ndf_p1_gen[\"DATE\"] = df_p1_gen[\"DATE_TIME\"].apply(lambda x: x.date())\ndf_p1_gen[\"TIME\"] = df_p1_gen[\"DATE_TIME\"].apply(lambda x: x.time())\n\nprint(df_p1_gen[\"DATE\"])\nprint(df_p1_gen[\"TIME\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing data with matplotlib\n\nfrom matplotlib import pyplot as plt\n\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot shows that DC_POWER and AC_POWER are linearly related!\n# y = mx + c\n\nplt.scatter(x=df_p1_gen[\"DC_POWER\"], y=df_p1_gen[\"AC_POWER\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nplt.plot(df_p1_gen[\"DATE_TIME\"], df_p1_gen[\"DC_POWER\"])\nplt.plot(df_p1_gen[\"DATE_TIME\"], df_p1_gen[\"AC_POWER\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_gen_dc_by_date = df_p1_gen.groupby(\"DATE\")[\"DC_POWER\"].sum()\n\nplt.figure(figsize=(12, 10))\nplt.bar(df_p1_gen_dc_by_date.keys(), df_p1_gen_dc_by_date)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fix the 1st generator data (DC_POWER was 10x the correct one)\n\ndf_p1_gen.DC_POWER = df_p1_gen.DC_POWER.apply(lambda x: x*0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nplt.plot(df_p1_gen[\"DATE_TIME\"], df_p1_gen[\"DC_POWER\"])\nplt.plot(df_p1_gen[\"DATE_TIME\"], df_p1_gen[\"AC_POWER\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nplt.plot(df_p2_gen[\"DATE_TIME\"], df_p2_gen[\"DC_POWER\"])\nplt.plot(df_p2_gen[\"DATE_TIME\"], df_p2_gen[\"AC_POWER\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p2_gen.DATE_TIME = pd.to_datetime(df_p2_gen.DATE_TIME)\ndf_p2_gen[\"DATE\"] = df_p2_gen.DATE_TIME.apply(lambda x: x.date())\ndf_p2_gen[\"TIME\"] = df_p2_gen.DATE_TIME.apply(lambda x: x.time())\n\ndf_p2_gen.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_gen_both = pd.concat([df_p1_gen, df_p2_gen])\n\ndf_gen_both.info()\ndf_gen_both.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What is the maximum AC/DC power generated by an inverter in a time interval / day?\n\nfrom collections import deque\n\ndef get_max_per_arbitrary_time(df: pd.DataFrame, param: str, td: np.timedelta64) -> tuple:\n    queues_map = {}  # dict[ str -> deque[np.datetime64] ]\n    sum_map = {}\n    max_q_map = {}\n    max_sum_map = {}\n\n    for ind, row in df[ [\"SOURCE_KEY\", \"DATE_TIME\", param] ].iterrows():\n        key = row[\"SOURCE_KEY\"]\n\n        if queues_map.get(key):\n            if row[\"DATE_TIME\"] - df[\"DATE_TIME\"][queues_map[key][0]] < td:\n                queues_map[key].append(ind)\n                sum_map[key] += row[param]\n            else:\n                while len(queues_map[key]) > 0 and not row[\"DATE_TIME\"] - df[\"DATE_TIME\"][queues_map[key][0]] < td:\n                    queues_map[key].popleft()\n                    sum_map[key] -= df[param][queues_map[key][0]]\n    \n                queues_map[key].append(ind)\n                sum_map[key] += row[param]\n        else:\n            queues_map[key] = deque()\n            queues_map[key].append(ind)\n            sum_map[key] = row[param]\n        \n        if sum_map[key] > max_sum_map.get(key, 0):\n            max_sum_map[key] = sum_map[key]\n            max_q_map[key] = (queues_map[key][0], queues_map[key][-1])\n\n    print(sum_map)\n    print(max_sum_map)\n    print(max_q_map)\n    print(queues_map)\n    \n    return (max_sum_map, max_q_map)\n\n                        \n#     for key, df_for_key in df.groupby(\"SOURCE_KEY\"):\n#         queues_map[key] = deque()\n#         queues_map[key].append(df_for_key[\"DATE_TIME\"])\n#         sum_map[key] = df_for_key[param]\n#         temp_deq = deque()\n\n#         for ind, row in df_for_key[1:].iterrows():\n#             if sum_map[key] > max_sum_map.get(key, 0):\n#                 max_sum_map[key] = sum_map[key]\n#                 max_q_map[key] = queues_map[key][0]  # Only store the start\n\n#             if row[\"DATE_TIME\"] - queues_map[key][0] <= td:\n#                 queues_map[key].append(row[\"DATE_TIME\"])\n#                 sum_map[key] += row[param]\n#                 temp_deq.append(ind)\n#             else:\n#                 while True:\n#                     if len(queues_map[key]) > 0:\n#                         if row[\"DATE_TIME\"] - queues_map[key][0] <= td:\n#                             queues_map[key].append(row[\"DATE_TIME\"])\n#                             sum_map[key] += row[param]\n#                             temp_deq.append(ind)\n#                             break\n#                         else:\n#                             queues_map[key].popleft()\n#                             sum_map[key] -= df[param][temp_deq.popleft()]\n#                     else:\n#                         queues_map[key].append(row[\"DATE_TIME\"])\n#                         sum_map[key] = row[param]\n#                         break\n    \n#     print(queues_map)\n#     print(max_q_map)\n#     print(max_sum_map)\n\n#     return max_sum_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Takes around 23 seconds for p1_gen dataset. Perhaps could be made faster!? (O(n^2) if pandas has constant lookup time)\nfrom datetime import datetime, timedelta\n\nbefore = datetime.now()\nmax_sum_df_p1_gen_new = get_max_per_arbitrary_time(df_p1_gen, \"DC_POWER\", timedelta(days=1))\nafter = datetime.now()\n\nprint(f\"Time taken: {(after - before).seconds} seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_dc_pow_1_day, max_dc_pow_start_and_end_ind = max_sum_df_p1_gen_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_gen.groupby([\"SOURCE_KEY\", \"DATE\"])[\"DC_POWER\"].sum().groupby(\"SOURCE_KEY\").max().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The values printed by this are slightly more than those given by the above command which gives \n# the max DC_POWER for any given SOURCE_KEY in one day\n# This proves the validity of the algorithm (which gives the max power for a inverter within any duration of 24 hours)\n\nprint(max_dc_pow_1_day[\"adLQvlD726eNBSB\"])\nprint(max_dc_pow_1_day[\"1IF53ai7Xc0U56Y\"])\nprint(max_dc_pow_1_day[\"bvBOhCH3iADSZry\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_dc_pow_dts = dict([(key, (df_p1_gen[\"DATE_TIME\"][indices[0]], df_p1_gen[\"DATE_TIME\"][indices[1]])) for key, indices in max_dc_pow_start_and_end_ind.items()])\n\nmax_dc_pow_dts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_sen[\"DATE_TIME\"] = pd.to_datetime(df_p1_sen[\"DATE_TIME\"])\ndf_p2_sen[\"DATE_TIME\"] = pd.to_datetime(df_p2_sen[\"DATE_TIME\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_sen.info()\n\ndf_p2_sen.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_sen.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p2_sen.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's visualize the data to see what we got\n\nplt.figure(figsize=(12, 8))\nplt.grid((1, 1))\n\nplt.scatter(x=df_p1_sen[\"AMBIENT_TEMPERATURE\"], y=df_p1_sen[\"MODULE_TEMPERATURE\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.grid((1, 1))\n\nplt.plot(df_p1_sen[\"DATE_TIME\"], df_p1_sen[\"IRRADIATION\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.grid((1, 1))\n\nplt.scatter(x=df_p1_sen[\"MODULE_TEMPERATURE\"], y=df_p1_sen[\"IRRADIATION\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_gen.DAILY_YIELD.mean(), df_p2_gen.DAILY_YIELD.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p1_sen[\"DATE\"] = df_p1_sen[\"DATE_TIME\"].apply(lambda x: x.date())\ndf_p2_sen[\"DATE\"] = df_p2_sen[\"DATE_TIME\"].apply(lambda x: x.date())\n\np1_sen_total_irrad = df_p1_sen.groupby(\"DATE\")[\"IRRADIATION\"].sum()\np2_sen_total_irrad = df_p2_sen.groupby(\"DATE\")[\"IRRADIATION\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_sen_total_irrad.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p2_sen_total_irrad.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Some other notes:**\n\n* Lots of 0s in **DC_POWER** and **AC_POWER** columns in generator data for both plants - not missing data. It is because at night, the power produced is 0\n* **DC_POWER** and **AC_POWER** are linearly related (`y = mx + c`). Coefficient and bias can be approxmiated with linear regression\n* Missing data: there is no missing data in the form of `np.NaN` (or null values), but some generator values and some weather data is missing completely (there is no row for some `DATE_TIME`s which should be there if all readings were recorded). So readings were not taken at those times and that can be called the missing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's calculate number of missing readings\n\np1_max_minus_min_dt = (df_p1_gen[\"DATE_TIME\"].max() - df_p1_gen[\"DATE_TIME\"].min())\np1_max_minus_min_minutes = p1_max_minus_min_dt.days * 24 * 60 + p1_max_minus_min_dt.seconds / (60.)\np1_ideal_readings_per_inverter = p1_max_minus_min_minutes / 15\n\np2_max_minus_min_dt = (df_p2_gen[\"DATE_TIME\"].max() - df_p2_gen[\"DATE_TIME\"].min())\np2_max_minus_min_minutes = p2_max_minus_min_dt.days * 24 * 60 + p2_max_minus_min_dt.seconds / (60.)\np2_ideal_readings_per_inverter = p2_max_minus_min_minutes / 15\n\np1_ideal_readings_per_inverter, p2_ideal_readings_per_inverter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_gen_missing_readings_per_inverter = df_p1_gen[\"SOURCE_KEY\"].value_counts().apply(lambda x: p1_ideal_readings_per_inverter - x)\np2_gen_missing_readings_per_inverter = df_p2_gen[\"SOURCE_KEY\"].value_counts().apply(lambda x: p2_ideal_readings_per_inverter - x)\n\nprint(p1_gen_missing_readings_per_inverter)\nprint(p2_gen_missing_readings_per_inverter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}