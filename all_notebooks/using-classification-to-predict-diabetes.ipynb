{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing the libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking Null values in dataset\n**First of all we will check is there any null or nan value in our dataset.For This I will use two methods.**\n\n1. By using inbuilt method of our data ,i.e., isnull() method\n2. By using heatmap function of seaborn library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()\nsns.heatmap(dataset.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we can see here that there is no null value. But if we see our data there is one problem some the columns like Glucose, BloodPressure, SkinThickness, Insulin and BMI.So actually these column have nan values which are represented by 0.So we will treat it after making our independent and dependent variables.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As there is no categorical data so we need not to take care of categorical or string data**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Making our dependent and independent features\nNow making our dependent and independent features to test our model and predict for future values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.iloc[:, 0:8].values\ny = dataset.iloc[:, 8].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Taking care of missing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = SimpleImputer(missing_values=0, strategy='mean')\nimputer.fit(X[:, 1:6])\nX[:, 1:6] = imputer.transform(X[:, 1:6])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the dataset into the Training set and Test set\n**Here I had given a 20% of my whole dataset to the test data as we want to feed the maximum of our data to our training set so that our model can predict with a very high accuracy**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying feature scaling on test and train dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the train dataset ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy')\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting the Test set results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = classifier.predict(X_test)\nprint('Confusion Matrix :')\nprint(confusion_matrix(y_test, y_pred_test)) \nprint('Accuracy Score :',accuracy_score(y_test, y_pred_test))\nprint('Report : ')\nprint(classification_report(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**And here we have achieved an accuracy of around 78% on our test dataset by using random forest classifier.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}