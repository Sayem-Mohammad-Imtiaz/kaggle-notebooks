{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Homelessness analysis (Homeless in the US in recent years)\nThis file analyzes homelessness data. The data comes from HUD (Housing and Urban Development), the U.S. Census Bureau (for the population of each state), and MIT (for red vs blue states). The exact links and access dates are in the readme.txt file.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport datetime as dt\nimport os\nimport statsmodels.api as sm\nfrom IPython.display import display\n%matplotlib inline\npd.options.display.max_rows=5000 \npd.options.display.max_columns=50","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### dfbeds -- the no. of beds dataframe\nThe number of shelter beds is imported -- there are too many columns in this file to be useful, so the \"total beds (ES,TH,SH)\" is the only column used -- this is the number of 'shelter beds', including ES (Emergency Shelter), TH (Transitional Housing), and SH (Safe Haven). There's one sheet per year in the workbook. The headings and the way of aggregating data was not completely consistent, so this is reflected in the data cleaning below."},{"metadata":{"trusted":true},"cell_type":"code","source":"excel_sheet='2008'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',\n                      index_col=0,header=[0,1],sheet_name=excel_sheet) \n# the excel workbook has many sheets but here we access the one called\" 2008\"\n# the first column has state abbreviations, so it is used as the \"index\" for the dataframe\n# each column has a multi-index based on top 2 rows of excel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is too much data, so only work with the first column only -- by assigning to a series the first column of data only.\ns2008=dftmp[('Total Beds (ES,TH,SH)','Total Year-Round Beds (ES,TH,SH)')] # this is the 1st column, now it's a series # multindex on cols, 1st col = rows\ns2008.name='2008'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s2008.head() # a series with the index being state name abbrev's and the values being no. of beds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now do the same for the rest of the sheets.\n\nexcel_sheet='2009'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2009=dftmp[('Total Beds (ES,TH,SH)','Total Year-Round Beds (ES,TH,SH)')]\ns2009.name='2009'\n\nexcel_sheet='2010'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2010=dftmp[('Total Beds (ES,TH,SH)','Total Year-Round Beds (ES,TH,SH)')]\ns2010.name='2010'\n\nexcel_sheet='2011'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2011=dftmp[('Total Beds (ES,TH,SH)','Total Year-Round Beds (ES,TH,SH)')]\ns2011.name='2011'\n\nexcel_sheet='2012'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2012=dftmp[('Total Beds (ES,TH,SH)','Total Year-Round Beds (ES,TH,SH)')]\ns2012.name='2012'\n\n# sheet 2013 was a bit different in the header rows, so this set of statements is a bit different.\n# also, the total no. of yr. round beds included \"RRH\" so I had to subtract that out for consistency.\nexcel_sheet='2013'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,skiprows=[0],sheet_name=excel_sheet) \ndftmp['tot']=dftmp['Total Year-Round Beds (ES,TH,RRH,SH)']-dftmp['Total Year-Round RRH Beds']\ns2013=dftmp['tot']\ns2013.name='2013'\n\n# sheet 2014 and subsequent sheets had extra spaces in names, so these sets of statements are a bit different:\nexcel_sheet='2014'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2014=dftmp[('Total Beds (ES, TH, SH)','Total Year-Round Beds (ES, TH, SH)')]\ns2014.name='2014'\n\nexcel_sheet='2015'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2015=dftmp[('Total Beds (ES, TH, SH)','Total Year-Round Beds (ES, TH, SH)')]\ns2015.name='2015'\n\nexcel_sheet='2016'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2016=dftmp[('Total Beds (ES, TH, SH)','Total Year-Round Beds (ES, TH, SH)')]\ns2016.name='2016'\n\nexcel_sheet='2017'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2017=dftmp[('Total Beds (ES, TH, SH)','Total Year-Round Beds (ES, TH, SH)')]\ns2017.name='2017'\n\nexcel_sheet='2018'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2018=dftmp[('Total Beds (ES, TH, SH)','Total Year-Round Beds (ES, TH, SH)')]\ns2018.name='2018'\n\nexcel_sheet='2019'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Housing-Inventory-Count-by-State.xlsx',index_col=0,header=[0,1],sheet_name=excel_sheet) \ns2019=dftmp[('Total Beds (ES, TH, SH)','Total Year-Round Beds (ES, TH, SH)')]\ns2019.name='2019'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There are 50 states, so each series below should have about 50 entries -- but there are about 55 -- this is because\n# the data includes places like Wash. D.C. (not a state) -- also there are more entries after the 2015 year.\nfor item in [s2008,s2009,s2010,s2011,s2012,s2013,s2014,s2015,s2016,s2017,s2018,s2019]:\n             print(item.name,' ',len(item))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# these are supposed to be states, but may include territories etc. -- what was added after 2016? It turns out that there's\n# an entry for \"MP\", which is maybe is \"Northern Marianas\" -- a territory -- anyway below I found out what this was.\nsetA=set(s2016.index)\nsetB=set(s2017.index)\nsetB-setA # the order actually matters here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here is what a typical series looks like. Some entries, like the one for Wash. DC and the \"totals\" are \n# extraneous & will be deleted\ns2016","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine all of the series above into a single dataframe, with the years as column headings.\n# each series has the name \"2008\", \"2009\", etc. so this is done implicitly below.\n# first I combine 2008 and 2009 using merge into dftmp (temporary dataframe), then I add a year each time.\ndftmp = pd.merge(s2008,s2009,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2010,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2011,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2012,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2013,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2014,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2015,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2016,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2017,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2018,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2019,left_index=True,right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop anything that's not recognizable as a state -- this gets rid of territories etc.\nstate_list = ['AK','AL','AR','AZ','CA','CO','CT','DE','FL','GA',\n             'HI','IA','ID','IL','IN','KS','KY','LA','MA','MD',\n             'ME','MI','MN','MO','MS','MT','NC','ND','NE','NH',\n             'NJ','NM','NV','NY','OH','OK','OR','PA','RI','SC',\n             'SD','TN','TX','UT','VA','VT','WA','WI','WV','WY']\nsetA=set(state_list) # make a \"set\" from the state abbreviations\nsetB=set(dftmp.index) # make a \"set\" from the indices for the big dataframe\ndrop_list = setB-setA # whatever is in setB but NOT in setA, get ready to drop it\ndfbeds = dftmp.drop(drop_list) # take the temp dataset dftmp, drop extraneous items, reassign to \"dfbeds\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transpose and rename index/column -- index is still year, a string value\ndfbeds = dfbeds.T\ndfbeds.index.name='year'\ndfbeds.columns.name='state'\ndfbeds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the index for dfbeds is still a bunch of strings like \"2008\" so make a range of years and make those the indices instead.\nrng=pd.period_range('2008','2019',freq='Y')\ndfbeds.set_index(rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfbeds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### people dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is a bit redundant and could've been put into a loop, but for each sheet in the Excel workbook,\n# take the data and put it into a series, each row in the series is a state (or other entity), the name\n# of each series is the year in question, and the data is the number of homeless people.\nexcel_sheet='2008'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2008=dftmp['Overall Homeless, 2008']\ns2008.name=excel_sheet\n\nexcel_sheet='2009'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet)\ns2009=dftmp['Overall Homeless, 2009']\ns2009.name=excel_sheet\n\nexcel_sheet='2010'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet)\ns2010=dftmp['Overall Homeless, 2010']\ns2010.name=excel_sheet\n\nexcel_sheet='2011'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2011=dftmp['Overall Homeless, 2011']\ns2011.name=excel_sheet\n\nexcel_sheet='2012'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2012=dftmp['Overall Homeless, 2012']\ns2012.name=excel_sheet\n\nexcel_sheet='2013'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2013=dftmp['Overall Homeless, 2013']\ns2013.name=excel_sheet\n\nexcel_sheet='2014'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2014=dftmp['Overall Homeless, 2014']\ns2014.name=excel_sheet\n\nexcel_sheet='2015'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2015=dftmp['Overall Homeless, 2015']\ns2015.name=excel_sheet\n\nexcel_sheet='2016'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2016=dftmp['Overall Homeless, 2016']\ns2016.name=excel_sheet\n\nexcel_sheet='2017'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2017=dftmp['Overall Homeless, 2017']\ns2017.name=excel_sheet\n\nexcel_sheet='2018'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2018=dftmp['Overall Homeless, 2018']\ns2018.name=excel_sheet\n\nexcel_sheet='2019'\ndftmp = pd.read_excel('../input/homeless-in-america-version-2-20102019/2007-2019-Point-in-Time-Estimates-by-state.xlsx',index_col=0,header=[0],sheet_name=excel_sheet) \ns2019=dftmp['Overall Homeless, 2019']\ns2019.name=excel_sheet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine all of them into a single dataframe, years are column headings.\n# this is about what I did before for the dataframe dfbeds.\ndftmp = pd.merge(s2008,s2009,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2010,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2011,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2012,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2013,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2014,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2015,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2016,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2017,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2018,left_index=True,right_index=True)\ndftmp = pd.merge(dftmp,s2019,left_index=True,right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as I did with dfbeds, drop anything that's not recognizable as a state\nstate_list = ['AK','AL','AR','AZ','CA','CO','CT','DE','FL','GA',\n             'HI','IA','ID','IL','IN','KS','KY','LA','MA','MD',\n             'ME','MI','MN','MO','MS','MT','NC','ND','NE','NH',\n             'NJ','NM','NV','NY','OH','OK','OR','PA','RI','SC',\n             'SD','TN','TX','UT','VA','VT','WA','WI','WV','WY']\nsetA=set(state_list)\nsetB=set(dftmp.index)\ndrop_list = setB-setA\ndfnohome=dftmp.drop(drop_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transpose and rename index/column -- index is still year, a string value\ndfnohome = dfnohome.T\ndfnohome.index.name='year'\ndfnohome.columns.name='state'\ndfnohome.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnohome.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# those entries should have been integers above, but they're called \"objects\". Converting:\ndfnohome=dfnohome.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rng=pd.period_range('2008','2019',freq='Y') # as with dfbeds, make the entries for years a range of years, not strings\ndfnohome.set_index(rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnohome.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### populations by state"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the populations by state\nmy_cols=[4,7,8,9,10,11,12,13,14,15,16]\nmy_names=['state_name','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019']\ndftmp = pd.read_csv('../input/homeless-in-america-version-2-20102019/nst-est2019-alldata.csv',skiprows=1,usecols=my_cols,names=my_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp # show first ten rows -- extraneous entries will be dropped.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp.state_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp.state_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# form a dictionary of abbreviations for all 50 states based on a csv file\ndftmp2 = pd.read_csv('../input/homeless-in-america-version-2-20102019/state_abbrev_dict.csv',index_col=None,header=None,names=['state','abbrev'])\nabbr_dict = dict(zip(dftmp2.state,dftmp2.abbrev))\n\n# use this dictionary to convert full names of states into their abbreviated counterparts\nx=dftmp.state_name # the column \"state_name\" gets put into a list\ny=[]\nfor item in x:\n    val = abbr_dict.get(item,'NOTASTATE') # look in dictionary \"abbr_dict\"and assign abbreviation or else the string \"NOTASTATE\"\n    y.append(val)\ndftmp['state']=y # make a NEW column called \"state\" -- it has the abbreviations and also some \"NOTASTATE\" entries\n\n# now drop everthing that's not a state (e.g., Puerto Rico)\ndftmp = dftmp[dftmp['state'] != 'NOTASTATE']\n# now dump the 'state_name' column\ndftmp.drop('state_name',axis=1,inplace=True)\n# now make the state col (really the state's abbreviated name) the index\ndftmp.set_index('state',inplace=True)\n# see McKinney book on 'period' -- make the column names actual years, not strings that represent years\nrng=pd.period_range('2010','2019',freq='Y')\ndftmp.columns=rng\ndfpop=dftmp.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfpop.head() # still needs to be transposed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfpop=dfpop.T # transposing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfpop.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### analysis\nThe analysis below has not been closely scrutinized lately, but at this point there are three dataframes you can work with:\ndfbeds -- no. of beds available\ndfnohome -- no. of homeless people\ndfpop -- populations of states"},{"metadata":{"trusted":true},"cell_type":"code","source":"# It would be good to know the no. of homeless normalized by each state's population.\n# obviously, there are less homeless in alaska than california, but how many do we have relative to state's residents?\n# get homeless and population data into same shape -- the former has two more rows (years) than the latter:\ndftmp1 = dfnohome[2:].copy()\n# here's another temporary datafile:\ndftmp2 = dfpop.copy()\n# make a copy of dftmp1, but with the intention of overwriting every value, keeping only columns and index values:\ndfhomepop = dftmp1.copy()\ndfhomepop=dfhomepop.astype(float) # but the values I'm replacing will be floats, so change this here\n\n# go through each row and column, form a new value, assign it -- this is the no. of homeless per 100,000 residents:\nfor i in range(0,len(dftmp1)):\n    for j in range(0,len(dftmp1.columns)):\n        xlabel=dftmp1.index[i]\n        ylabel=dftmp1.columns[j]\n        homeless = dftmp1.loc[xlabel].loc[ylabel]\n        statepop = dftmp2.loc[xlabel].loc[ylabel]\n        x = homeless/statepop*100000.0\n        dfhomepop.loc[xlabel][ylabel]=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfhomepop.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp3 = dfhomepop.iloc[-1] # get last year (2019) date only\ndftmp4 = dftmp3.sort_values() # sort this series out\nsns.set_style('whitegrid')\nfig,axis=plt.subplots(nrows=1,ncols=1,figsize=(6,9))\nsns.barplot(x=dftmp4.values,y=dftmp4.index,color='cyan',ax=axis)\naxis.set_title('homeless per 100,000 residents (by state) (2019 only)')\naxis.set_xlabel('')\naxis.set_ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# no. of shelter beds per homeless:\ndftmp5 = dfbeds.copy()\n# here's another temporary datafile:\ndftmp6 = dfnohome.copy()\n# make a copy of dftmp5, but with the intention of overwriting every value, keeping only columns and index values:\ndfbedhome = dftmp5.copy()\ndfbedhome=dfbedhome.astype(float) # but the values I'm replacing will be floats, so change this here\n\n# go through each row and column, form a new value, assign it -- this is the no. of homeless per 100,000 residents:\nfor i in range(0,len(dftmp5)):\n    for j in range(0,len(dftmp5.columns)):\n        xlabel=dftmp5.index[i]\n        ylabel=dftmp5.columns[j]\n        beds = dftmp5.loc[xlabel].loc[ylabel]\n        nohome = dftmp6.loc[xlabel].loc[ylabel]\n        x = beds/nohome*1.0\n        dfbedhome.loc[xlabel][ylabel]=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfbedhome.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftmp7 = dfbedhome.iloc[-1] # get last year (2019) date only\ndftmp8 = dftmp7.sort_values() # sort this series out\nsns.set_style('whitegrid')\nfig,axis=plt.subplots(nrows=1,ncols=1,figsize=(6,9))\nsns.barplot(x=dftmp8.values,y=dftmp8.index,color='cyan',ax=axis)\naxis.set_title('beds per homeless person (by state) (2019 only)')\naxis.set_xlabel('')\naxis.set_ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# maybe states with the most homeless people per 100,000 residents have the lowest bed-to-homeless ratios?\ns = dfhomepop.iloc[9] # get latest yr's data for homeless per 100,000\ndftmp10 = pd.DataFrame(s) # convert to dataframe so merge can happen\ns = dfbedhome.iloc[11] # beds per homeless as series\ndftmp11 = pd.DataFrame(s) # as dataframe\ndftmp12 = dftmp10.merge(dftmp11,left_index=True,right_index=True)\ndftmp12.columns=['homelessper100000','bedsperhomeless'] # this is a dataframe with states as index and two columns\ndftmp12.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axis=plt.subplots(nrows=1,ncols=1,figsize=(6,6))\nx=dftmp12.homelessper100000.astype('float')\ny=dftmp12.bedsperhomeless.astype('float')\nsns.regplot(x=x,y=y)\nplt.xlabel('homeless per 100,000 residents')\nplt.ylabel('beds per homeless person')\nplt.annotate('HI',xy=(450,0.4),size=15)\nplt.annotate('NY',xy=(450,0.9),size=15)\nplt.annotate('OR',xy=(335,0.42),size=15)\nplt.annotate('CA',xy=(337,0.28),size=15);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x2 = sm.add_constant(x) # if y intercept is assumed non-zero, then need this.\nmodel = sm.OLS(y,x2).fit()\npred = model.predict(x2)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stuff you can get from the linear model\nb = model.params[0]\nm = model.params[1]\nrsqared=model.rsquared\nrsqradj=model.rsquared_adj\npred =model.fittedvalues;\n#model.params gets all of these, maybe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sm.stats.linear_rainbow.__doc__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm.stats.linear_rainbow(model) # if 2nd of these values is low (say less than 0.05, linear fit may be good)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this shows that seaborn's regplot and statsmodels OLS fit both do the same thing.\nfig,axis=plt.subplots(nrows=1,ncols=1,figsize=(6,6))\n\nsns.regplot(x=x,y=y)\nsns.lineplot(x=x,y=pred)\n\nplt.xlabel('homeless per 100,000 residents')\nplt.ylabel('beds per homeless person')\nplt.annotate('HI',xy=(450,0.4),size=15)\nplt.annotate('NY',xy=(450,0.9),size=15)\nplt.annotate('OR',xy=(335,0.42),size=15)\nplt.annotate('CA',xy=(337,0.28),size=15)\nmy_text = 'weak correlation:\\nrsqradj = %.2f'%(rsqradj)\nplt.annotate(my_text,xy=(200,1.2),size=15);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show the three time-trending values, population, no. homeless, no. beds -- but for aggregate of 50 states\nSnohomeTOT = dfnohome.sum(axis=1)\nSnohomeTOT=SnohomeTOT[2:] # population data doesn't start until 2010, so truncate this item to match\nSbedsTOT=dfbeds.sum(axis=1)\nSbedsTOT=SbedsTOT[2:] # population data doesn't start until 2010, so truncate this item to match\nSpopTOT=dfpop.sum(axis=1)\nrng=pd.period_range('2010','2019',freq='Y')\n\nfig,axes=plt.subplots(nrows=3,ncols=1,sharex=True,figsize=(6,9))\n#plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.4)\n\nsns.lineplot(x=rng.to_timestamp(),y=SpopTOT/1E6,marker='o',ax=axes[0])\naxes[0].set_ylabel('US population (millions)')\n\nsns.lineplot(x=rng.to_timestamp(),y=SnohomeTOT,marker='o',ax=axes[1])\naxes[1].set_ylabel('no. of homeless in US')\n\nsns.lineplot(x=rng.to_timestamp(),y=SbedsTOT,marker='o',ax=axes[2])\naxes[2].set_ylabel('no. of shelter beds in US')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalized by 2010 data:\nSnohomeTOTNORM = SnohomeTOT/SnohomeTOT[0]\nSbedsTOTNORM=SbedsTOT/SbedsTOT[0]\nSpopTOTNORM=SpopTOT/SpopTOT[0]\nrng=pd.period_range('2010','2019',freq='Y')\n\nfig,axes=plt.subplots(nrows=3,ncols=1,sharex=True,figsize=(6,9))\n#plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.4)\n\nsns.lineplot(x=rng.to_timestamp(),y=SpopTOTNORM,marker='o',ax=axes[0])\naxes[0].set_ylabel('US population\\n(normalized to 2010 data)')\n\nsns.lineplot(x=rng.to_timestamp(),y=SnohomeTOTNORM,marker='o',ax=axes[1])\naxes[1].set_ylabel('homeless in US\\n(normalized to 2010 data)')\n\nsns.lineplot(x=rng.to_timestamp(),y=SbedsTOTNORM,marker='o',ax=axes[2])\naxes[2].set_ylabel('shelter beds in US\\n(normalized to 2010 data)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Sratio = SbedsTOT/SnohomeTOT # overall, the no. of beds to homeless seems to be improving a bit, at least until 2018","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Sratio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axis=plt.subplots(nrows=1,ncols=1,figsize=(6,6))\nrng=pd.period_range('2010','2019',freq='Y')\nsns.lineplot(x=rng.to_timestamp(),y=Sratio,marker='o',ax=axis)\naxis.set_ylabel('beds per homeless person (all of US)');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfbedhome.head() # beds per homeless person","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do states that are blue (democrats) have a better or worse ratio than the red states (republicans)? 2019 values only\n# THIS DOES NOT WORK RIGHT NOW.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}