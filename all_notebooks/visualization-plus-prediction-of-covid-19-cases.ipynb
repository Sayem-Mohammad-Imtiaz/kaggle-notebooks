{"cells":[{"metadata":{"id":"huADqnK6uXtU","outputId":"94b3ebd1-662a-4cdd-9fea-2dc9bf1187d8","trusted":true},"cell_type":"code","source":"\n\nimport pandas as pd\ndata = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\ndata_deaths = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\ndata_rec = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\nprint(data.head(10))\nprint(data_deaths.head(10))\nprint(data_rec.head(10))\nprint(data.shape)\nprint(data_deaths.shape)\nprint(data_rec.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"vpShj_F9uXtY","outputId":"4b8f6d27-f99a-4aa7-d200-6532f340248f","trusted":true},"cell_type":"code","source":" pip install folium","execution_count":null,"outputs":[]},{"metadata":{"id":"4Y7Y7b1_uXtb","trusted":true},"cell_type":"code","source":"import folium\nfrom folium.plugins import MarkerCluster\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"id":"LBkIAcYDuXtd","trusted":true},"cell_type":"code","source":"data['Total Confirmed Cases']= data.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"id":"IB-ybciru2rl"},"cell_type":"markdown","source":""},{"metadata":{"id":"X7IGjS_vcja5","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"TcY0sLILuXtf","outputId":"4379fd93-6899-4a38-abd7-bd799ad4bb9f","trusted":true},"cell_type":"code","source":"print(data[data['Country/Region'] == 'United Kingdom'])\nlocations = data[['Lat', 'Long']]\nlocationlist = locations.values.tolist()\n\nlen(locationlist)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Visualization: ***\n\nAfter running the below code we will get a map.If we click on the icons on the map, it will get zoomed into the map and countries will appear. We can select which ever country we want. Upon hovering on each country we get the total number of confirmed cases and deaths in that particular country. If we click that country we get graphs showing trend in deaths and number of confirmed corona cases from start till yesterday."},{"metadata":{"id":"oh9o9_LSuXti","outputId":"a49ad4a4-fda2-4b84-8fbc-cb73030e0e2a","trusted":true},"cell_type":"code","source":"from folium.features import DivIcon\nmap2 = folium.Map(location=[0, 0], tiles='CartoDB dark_matter', zoom_start=2)\n\nmarker_cluster = MarkerCluster().add_to(map2)\n\ndef add_graphs(point):  \n  import altair as alt\n  y = list(data.iloc[point,4:].values)\n  y_deaths = list(data_deaths.iloc[point,4:].values)\n  a = len(y)+1\n  c = len(y_deaths) + 1\n  y = pd.DataFrame(y)\n  #yinsert(1, \"Deaths\", y_deaths, True)\n  y_deaths = pd.DataFrame(y_deaths)\n  y.columns = ['Number']\n  y['Days'] = range(1,a)\n  y_deaths.columns = ['Number']\n  y_deaths['Days'] = range(1,c)\n  y_deaths['Legend'] = 'Confirmed Deaths'\n  y['Legend'] = 'Confirmed Cases'\n  #print(y.shape)\n\n  #py.append(y_deaths,ignore_index=True)\n  df_mix = pd.concat([y, y_deaths])\n  #print(df_mix .shape)\n  #print(df_mix .head(300))\n  b = alt.Chart(df_mix).mark_line().encode(x='Days',y='Number',color = 'Legend')\n  #b = alt.Chart(y).mark_line().encode(x='Days',y='Cases')\n  # = alt.Chart(y_deaths).mark_line(color = 'red').encode(x='Days',y='Cases')\n  #e = b + d\n  b = b.to_json('vega.json')\n  return b\n\nfor point in range(0, len(locationlist)):\n  if(str(data['Province/State'][point]) == 'nan'):\n    folium.Marker(locationlist[point],icon=folium.Icon(color = 'black',icon_color='red', icon='asterisk', angle=0, prefix='fa'),popup=folium.Popup(max_width=500).add_child(folium.VegaLite(add_graphs(point), width=400, height=250)),tooltip=(data['Country/Region'][point] + \", \" +'Cases: '+ str(data['Total Confirmed Cases'][point]))).add_to(marker_cluster)\n  else:\n    folium.Marker(locationlist[point],icon=folium.Icon(color = 'black',icon_color='red', icon='asterisk', angle=0, prefix='fa'),popup=folium.Popup(max_width=400).add_child(folium.VegaLite(add_graphs(point), width=400, height=250)), tooltip=(data['Country/Region'][point] + \", \" + 'Province: ' + str(data['Province/State'][point])+\", \" +'Cases: '+ str(data['Total Confirmed Cases'][point]))).add_to(marker_cluster)\nmap2\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"yvdb612FuXtk","outputId":"35373e0f-de37-4079-c2f2-e61425468a58","trusted":true},"cell_type":"code","source":"## RNN for Covid_19 Data\nimport numpy\nimport matplotlib.pyplot as plt\nfrom pandas import read_csv\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back):\n\tdataX, dataY = [], []\n\tfor i in range(len(dataset)-look_back-1):\n\t\ta = dataset[i:(i+look_back), 0]\n\t\tdataX.append(a)\n\t\tdataY.append(dataset[i + look_back, 0])\n\treturn numpy.array(dataX), numpy.array(dataY)\n# fix random seed for reproducibility\nnumpy.random.seed(7)\n# load the dataset\ndataset = data.iloc[223,4:].values\ndataset = dataset.reshape(-1, 1)\ndataset = dataset.astype('float32')\nprint(\"Data is \",dataset.shape)\n# normalize the dataset\n#scaler = MinMaxScaler(feature_range=(0, 1))\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.95)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n# reshape into X=t and Y=t+1\nlook_back = 1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n# reshape input to be [samples, time steps, features]\nprint(\"Shapeeee. \",trainX.shape)\ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=150, batch_size=1, verbose=2)\n# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n# shift train predictions for plotting\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict","execution_count":null,"outputs":[]},{"metadata":{"id":"jn-2XYBbNzUr","outputId":"e29fb418-dce5-4fff-967d-20c8cd00f785","trusted":true},"cell_type":"code","source":"plt.plot(scaler.inverse_transform(dataset),label='Original')\nplt.plot(trainPredictPlot,label = 'Training')\nplt.plot(testPredictPlot,label = 'Testing')\nplt.ylabel('Confirmed Corona Cases in UK')\nplt.xlabel('Days')\nplt.legend(loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9E-sYVhXBYY6","outputId":"48e7c633-3732-4e2f-e6ba-0dd057649d95","trusted":true},"cell_type":"code","source":"## Prdeiction of Confirmed Corona Cases in UK for next 5 days \nprint(len(testX))\nprint(testX[2])\ntest = testX[2]\npred = []\nfor i in range(5):\n  x_input = test.reshape((1, 1, 1))\n  fut = model.predict(x_input, verbose=0)\n  test = fut\n  nor= scaler.inverse_transform(fut)\n  list(nor)\n  print(type(nor))\n  print(nor)\n  pred.append(nor)\nprint(pred)\nprint(len(pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction of confirmed cases in UK for next 5 days**"},{"metadata":{"id":"9spRfxU7CCMr","outputId":"32fe280e-e000-426a-923c-1b0b36c21d10","trusted":true},"cell_type":"code","source":"print(\" Prediction of number of Confirmed Cases in UK for the next five days are the following:\")\nprint(\" Day 1=%d \\n Day 2=%d \\n Day 3=%d \\n Day 4=%d \\n Day 5=%d  \" % (pred[4],pred[3],pred[2],pred[1],pred[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Covid.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}