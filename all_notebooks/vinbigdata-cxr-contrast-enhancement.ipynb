{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Import library modul\n# Pre-processing\nimport skimage.io as io\nfrom skimage.transform import  rescale,resize\nfrom skimage.util import img_as_uint,img_as_ubyte\nfrom skimage.color import rgb2gray\nfrom skimage import exposure\nimport os\nimport numpy as np\nimport cv2\nfrom math import log10, sqrt\nfrom wand.image import Image\n\n# Extract features\nimport scipy.io as sio\nfrom scipy.stats import skew\nfrom scipy.stats import kurtosis\nfrom skimage.feature import greycomatrix\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom skimage.filters import unsharp_mask, threshold_local\nfrom skimage.morphology import closing, opening, square\nfrom skimage.segmentation import clear_border\nfrom skimage.measure import label, regionprops\nfrom skimage.color import label2rgb\nimport matplotlib.patches as mpatches\nfrom tqdm.notebook import tqdm\n\n# Train model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import KernelPCA\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport tensorflow as tf\nfrom sklearn.metrics import roc_curve, auc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# =============================================================================\n# im2double\n# =============================================================================\ndef im2double(img):\n    \"\"\" convert image to double format \"\"\"\n    min_val = np.min(img.ravel())\n    max_val = np.max(img.ravel())\n    out = (img.astype('float') - min_val) / (max_val - min_val)\n    return out\n\n# =============================================================================\n# compute_14_features\n# =============================================================================\ndef features_14(region):\n    \"\"\" Compute 14 features \"\"\"\n    temp_array=region.reshape(-1)\n    all_pixels=temp_array[temp_array!=0]\n#    Area\n    Area = np.sum(all_pixels)\n#    mean\n    density = np.mean(all_pixels)\n#   Std\n    std_Density = np.std(all_pixels)\n#   skewness\n    Skewness = skew(all_pixels)\n#   kurtosis\n    Kurtosis = kurtosis(all_pixels)\n#   Energy\n    ENERGY =np.sum(np.square(all_pixels))\n#   Entropy\n    value,counts = np.unique(all_pixels, return_counts=True)\n    p = counts / np.sum(counts)\n    p =  p[p!=0]\n    ENTROPY =-np.sum( p*np.log2(p));\n#   Maximum\n    MAX = np.max(all_pixels)\n#   Mean Absolute Deviation\n    sum_deviation= np.sum(np.abs(all_pixels-np.mean(all_pixels)))\n    mean_absolute_deviation = sum_deviation/len(all_pixels)\n#   Median\n    MEDIAN = np.median(all_pixels)\n#   Minimum\n    MIN = np.min(all_pixels)\n#   Range\n    RANGE = np.max(all_pixels)-np.min(all_pixels)\n#   Root Mean Square\n    RMS = np.sqrt(np.mean(np.square(all_pixels))) \n#    Uniformity\n    UNIFORMITY = np.sum(np.square(p))\n\n    features = np.array([Area, density, std_Density,\n        Skewness, Kurtosis,ENERGY, ENTROPY,\n        MAX, mean_absolute_deviation, MEDIAN, MIN, RANGE, RMS, UNIFORMITY])\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Inisialisasi directory\nbase_dir = '../input/vinbigdata-chest-xray-resized-png-256x256'\nsecond_dir = '../input/set-targeted-vinbigdata-chest-xray-resized'\ntrain_dir = f'{base_dir}/train/'\ntest_dir = f'{base_dir}/test/'\noutput_dir = '.'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(f'{second_dir}/labeld_train.csv', delimiter=',')\ndf_train = pd.DataFrame(train_csv)\nclass_normal = df_train[df_train['class_id']==0]\nclass_abnormal = df_train[df_train['class_id']==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('ori')\nfeatures=np.empty([1,70])#feature pool\n# output_file = ['ori, global, adapt, um']\nfor i in range(2):\n    label_class = i # 0:Normal, 1: Abnormal\n    if label_class ==  0:\n        output_filename = 'normal'\n        enumerate_class = class_normal\n    else:\n        output_filename = 'abnormal'\n        enumerate_class = class_abnormal\n        \n    for idx, img_name in enumerate(enumerate_class['image_id']):\n#         if(idx%1000 ==0): print(idx)\n        # Pre-processing image\n        img_ori = plt.imread(train_dir+img_name+'.png')\n        im8bit=img_as_ubyte(img_ori)\n        # Extracting feature\n        imrescale_2=(im8bit-np.min(im8bit))/(np.max(im8bit)-np.min(im8bit))\n        textures=features_14(imrescale_2) #texture features\n\n        glcms = greycomatrix(im8bit, [1], [0, 90, 180, 270]) #GLCM in eight directions\n        glcm_features_4 = np.concatenate((features_14(im2double(glcms[:, :, 0, 0])), \n                                      features_14(im2double(glcms[:, :, 0, 1])),\n                                      features_14(im2double(glcms[:, :, 0, 2])),\n                                      features_14(im2double(glcms[:, :, 0, 3]))), axis=0)\n\n        textures=np.concatenate((textures,glcm_features_4), axis=0).reshape(1,70)\n        features=np.concatenate((features,textures), axis=0)\n    features=np.delete(features, 0, 0)\n    features=np.concatenate((features,label_class*np.ones(len(features)).reshape(len(features),1)), axis=1)\n    sio.savemat('ori'+output_filename+'.mat', {'features': features})\n    features=[]\n    features=np.empty([1,70])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('global')\nfeatures=np.empty([1,70])#feature pool\n# output_file = ['ori, global, adapt, um']\nfor i in range(2):\n    label_class = i # 0:Normal, 1: Abnormal\n    if label_class ==  0:\n        output_filename = 'normal'\n        enumerate_class = class_normal\n    else:\n        output_filename = 'abnormal'\n        enumerate_class = class_abnormal\n        \n    for idx, img_name in enumerate(enumerate_class['image_id']):\n#         if(idx%1000 ==0): print(idx)\n        # Pre-processing image\n        img_ori = plt.imread(train_dir+img_name+'.png')\n        imhist=exposure.equalize_hist(img_ori)#global hist\n        im8bit=img_as_ubyte(img_ori)\n#       \n        # Extracting feature\n        imrescale_2=(im8bit-np.min(im8bit))/(np.max(im8bit)-np.min(im8bit))\n        textures=features_14(imrescale_2) #texture features\n\n        glcms = greycomatrix(im8bit, [1], [0, 90, 180, 270]) #GLCM in eight directions\n        glcm_features_4 = np.concatenate((features_14(im2double(glcms[:, :, 0, 0])), \n                                      features_14(im2double(glcms[:, :, 0, 1])),\n                                      features_14(im2double(glcms[:, :, 0, 2])),\n                                      features_14(im2double(glcms[:, :, 0, 3]))), axis=0)\n\n        textures=np.concatenate((textures,glcm_features_4), axis=0).reshape(1,70)\n        features=np.concatenate((features,textures), axis=0)\n    features=np.delete(features, 0, 0)\n    features=np.concatenate((features,label_class*np.ones(len(features)).reshape(len(features),1)), axis=1)\n    sio.savemat('global'+output_filename+'.mat', {'features': features})\n    features=[]\n    features=np.empty([1,70])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('adapt')\nfeatures=np.empty([1,70])#feature pool\n# output_file = ['ori, global, adapt, um']\nfor i in range(2):\n    label_class = i # 0:Normal, 1: Abnormal\n    if label_class ==  0:\n        output_filename = 'normal'\n        enumerate_class = class_normal\n    else:\n        output_filename = 'abnormal'\n        enumerate_class = class_abnormal\n        \n    for idx, img_name in enumerate(enumerate_class['image_id']):\n#         if(idx%1000 ==0): print(idx)\n        # Pre-processing image\n        img_ori = plt.imread(train_dir+img_name+'.png')\n        imhist=exposure.equalize_adapthist(img_ori, clip_limit=0.3)#adapt hist\n        im8bit=img_as_ubyte(img_ori)\n#       \n        # Extracting feature\n        imrescale_2=(im8bit-np.min(im8bit))/(np.max(im8bit)-np.min(im8bit))\n        textures=features_14(imrescale_2) #texture features\n\n        glcms = greycomatrix(im8bit, [1], [0, 90, 180, 270]) #GLCM in eight directions\n        glcm_features_4 = np.concatenate((features_14(im2double(glcms[:, :, 0, 0])), \n                                      features_14(im2double(glcms[:, :, 0, 1])),\n                                      features_14(im2double(glcms[:, :, 0, 2])),\n                                      features_14(im2double(glcms[:, :, 0, 3]))), axis=0)\n\n        textures=np.concatenate((textures,glcm_features_4), axis=0).reshape(1,70)\n        features=np.concatenate((features,textures), axis=0)\n    features=np.delete(features, 0, 0)\n    features=np.concatenate((features,label_class*np.ones(len(features)).reshape(len(features),1)), axis=1)\n    sio.savemat('adapt'+output_filename+'.mat', {'features': features})\n    features=[]\n    features=np.empty([1,70])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('um')\nfeatures=np.empty([1,70])#feature pool\n# output_file = ['ori, global, adapt, um']\nfor i in range(2):\n    label_class = i # 0:Normal, 1: Abnormal\n    if label_class ==  0:\n        output_filename = 'normal'\n        enumerate_class = class_normal\n    else:\n        output_filename = 'abnormal'\n        enumerate_class = class_abnormal\n        \n    for idx, img_name in enumerate(enumerate_class['image_id']):\n#         if(idx%1000 ==0): print(idx)\n        # Pre-processing image\n        img_ori = Image(filename=train_dir+img_name+'.png')\n        img_ori.unsharp_mask(radius=8, sigma=4, amount=3, threshold=0.01)\n        img_um = np.array(img_ori)[:,:,0]\n        im8bit=img_as_ubyte(img_um)\n#       \n        # Extracting feature\n        imrescale_2=(im8bit-np.min(im8bit))/(np.max(im8bit)-np.min(im8bit))\n        textures=features_14(imrescale_2) #texture features\n\n        glcms = greycomatrix(im8bit, [1], [0, 90, 180, 270]) #GLCM in eight directions\n        glcm_features_4 = np.concatenate((features_14(im2double(glcms[:, :, 0, 0])), \n                                      features_14(im2double(glcms[:, :, 0, 1])),\n                                      features_14(im2double(glcms[:, :, 0, 2])),\n                                      features_14(im2double(glcms[:, :, 0, 3]))), axis=0)\n\n        textures=np.concatenate((textures,glcm_features_4), axis=0).reshape(1,70)\n        features=np.concatenate((features,textures), axis=0)\n    features=np.delete(features, 0, 0)\n    features=np.concatenate((features,label_class*np.ones(len(features)).reshape(len(features),1)), axis=1)\n    sio.savemat('um'+output_filename+'.mat', {'features': features})\n    features=[]\n    features=np.empty([1,70])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# file_mat_normal = ['orinormal, globalnormal, adaptnormal, umnormal']\n# file_mat_abnormal = ['oriabnormal, globalabnormal, adaptabnormal, umabnormal']\nnormal_features=sio.loadmat(os.path.join(output_dir,'globalnormal.mat')) \nnormal_features=normal_features['features'] \n\nabnormal_features=sio.loadmat(os.path.join(output_dir,'globalabnormal.mat')) \nabnormal_features=abnormal_features['features']\n\nX=np.concatenate((normal_features[:,:-1],abnormal_features[:,:-1]), axis=0)#data\ny=np.concatenate((normal_features[:,-1],abnormal_features[:,-1]), axis=0)#target\n\n# =============================================================================\n# normalization\n# =============================================================================\nmin_max_scaler=MinMaxScaler()\nX = min_max_scaler.fit_transform(X) \n# =============================================================================\n# feature reduction (K-PCA)\n# =============================================================================\ntransformer = KernelPCA(n_components=64, kernel='linear')\nX = transformer.fit_transform(X)\n# =============================================================================\n# devide data into test,train, and validation sets\n# =============================================================================\n# y = to_categorical(y)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=1)\n\n# X_train, X_val, y_train, y_val = train_test_split(\n#     X_train, y_train, test_size=0.25, random_state=1)\n\n# Model\nsvm_classifier = SVC(kernel='rbf')\nsvm_classifier.fit(X_train, y_train)\ny_pred = svm_classifier.predict(X_test)\n\nhasil_conf = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(hasil_conf)\nhasil_report = classification_report(y_test, y_pred)\nprint(\"Classification Report:\",)\nprint (hasil_report)\nhasil_score = accuracy_score(y_test,y_pred)\nprint(\"Accuracy:\",hasil_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pywt\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), 0)\n\ndef wavelet_denoising(x, wavelet='haar', level=2):\n    coeff = pywt.wavedec(x, wavelet, mode='symmetric')\n    sigma = (1/0.6745) * madev(coeff[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='soft') for i in coeff[1:])\n    return pywt.waverec(coeff, wavelet, mode='symmetric')\n\nfig = plt.figure(figsize=(30, 30))\ni = 0\nj = 0\nfor i in range(4):\n    for idx, img_name in enumerate(class_normal['image_id'][:5]):\n        # Pre-processing image\n        img_ori = plt.imread(train_dir+img_name+'.png') \n        im8bit=img_as_ubyte(img_um)\n        if j<4:\n            im8bit=img_as_ubyte(img_ori)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            plt.imshow(im8bit, label='original', cmap='gray')\n        elif j<8:\n            imhist=exposure.equalize_hist(img_ori)#global hist\n            im8bit=img_as_ubyte(imhist)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            plt.imshow(im8bit, label='global', cmap='gray')\n        elif j<12:\n            imhist=exposure.equalize_adapthist(img_ori, clip_limit=0.3)#adapt hist\n            im8bit=img_as_ubyte(imhist)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            plt.imshow(im8bit, label='adapt', cmap='gray')\n        else:\n            img_ori = Image(filename=train_dir+img_name+'.png')\n            img_ori.unsharp_mask(radius=8, sigma=4, amount=3, threshold=0.01)\n            img_um = np.array(img_ori)[:,:,0]\n            im8bit=img_as_ubyte(img_um)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            plt.imshow(im8bit, label='unhsaped_mask', cmap='gray')\n        j+=1\nplt.savefig('image_norm.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pywt\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), 0)\n\ndef wavelet_denoising(x, wavelet='haar', level=2):\n    coeff = pywt.wavedec(x, wavelet, mode='symmetric')\n    sigma = (1/0.6745) * madev(coeff[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='soft') for i in coeff[1:])\n    return pywt.waverec(coeff, wavelet, mode='symmetric')\n\nfig = plt.figure(figsize=(30, 30))\ni = 0\nj = 0\nfor i in range(4):\n    for idx, img_name in enumerate(class_normal['image_id'][:5]):\n        # Pre-processing image\n        img_ori = plt.imread(train_dir+img_name+'.png') \n        im8bit=img_as_ubyte(img_um)\n        if j<4:\n            im8bit=img_as_ubyte(img_ori)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            hist = np.histogram(im8bit, bins=np.arange(0, 256))\n            sig_filtered = wavelet_denoising(hist[0])\n            # showing image\n            plt.plot(hist[1][:-1], hist[0], lw=2, color='steelblue')\n            plt.plot(sig_filtered, label= 'wavelet filter', color='red')\n        elif j<8:\n            imhist=exposure.equalize_hist(img_ori)#global hist\n            im8bit=img_as_ubyte(imhist)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            hist = np.histogram(im8bit, bins=np.arange(0, 256))\n            sig_filtered = wavelet_denoising(hist[0])\n            # showing image\n            plt.plot(hist[1][:-1], hist[0], lw=2, color='steelblue')\n            plt.plot(sig_filtered, label= 'wavelet filter', color='red')\n        elif j<12:\n            imhist=exposure.equalize_adapthist(img_ori, clip_limit=0.3)#adapt hist\n            im8bit=img_as_ubyte(imhist)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            hist = np.histogram(im8bit, bins=np.arange(0, 256))\n            sig_filtered = wavelet_denoising(hist[0])\n            # showing image\n            plt.plot(hist[1][:-1], hist[0], lw=2, color='steelblue')\n            plt.plot(sig_filtered, label= 'wavelet filter', color='red')\n        else:\n            img_ori = Image(filename=train_dir+img_name+'.png')\n            img_ori.unsharp_mask(radius=8, sigma=4, amount=3, threshold=0.01)\n            img_um = np.array(img_ori)[:,:,0]\n            im8bit=img_as_ubyte(img_um)\n            # Adds a subplot at the 1st position\n            fig.add_subplot(5,4, j+1)\n            hist = np.histogram(im8bit, bins=np.arange(0, 256))\n            sig_filtered = wavelet_denoising(hist[0])\n            # showing image\n            plt.plot(hist[1][:-1], hist[0], lw=2, color='steelblue')\n            plt.plot(sig_filtered, label= 'wavelet filter', color='red')\n        j+=1\nplt.savefig('hist_image_norm.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, img_name in enumerate(df_train['image_id'][54:55]):\n        # Pre-processing image\n        img_ori = plt.imread(train_dir+img_name+'.png')\n        img_ori=exposure.equalize_adapthist(img_ori, clip_limit=0.2)\n        th = [cv2.threshold(img, np.mean(img), 255, cv2.THRESH_BINARY_INV)[1] for img in tqdm(img_ori)]\n        img_ori2 = np.array(th)[:,:,0]\n        img_ori2 = closing(img_ori2, square(4))\n        img_ori2 = opening(img_ori2, square(10))\n        img_ori2 = closing(img_ori2, square(1))\n        img_ori2 = img_ori2.astype(int)\n        cleared = clear_border(img_ori2)\n        \n        plt.imshow(cleared,cmap='gray')\n        \n        # label image regions\n        label_image = label(cleared)\n        # to make the background transparent, pass the value of `bg_label`,\n        # and leave `bg_color` as `None` and `kind` as `overlay`\n        image_label_overlay = label2rgb(label_image, image=cleared, bg_label=0)\n\n        fig, ax = plt.subplots(figsize=(10, 6))\n        ax.imshow(img_ori, cmap='gray')\n\n        for region in regionprops(label_image):\n            # take regions with large enough areas\n            if region.area >= 1000:\n                # draw rectangle around segmented coins\n                minr, minc, maxr, maxc = region.bbox\n                rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n                                          fill=False, edgecolor='red', linewidth=2)\n                ax.add_patch(rect)\n\n        ax.set_axis_off()\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}