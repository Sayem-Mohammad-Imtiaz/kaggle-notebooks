{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport seaborn\nimport collections\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Reading data\ndef read_data():    \n    true_data = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")\n    fake_data = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")\n    true_data['fake'] = 0\n    fake_data['fake'] = 1\n    \n    return pd.concat([fake_data, true_data]).reset_index(drop = True)\n\ndata = read_data()\n\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fake news analyses\nfake_news = data[data.fake == 1]\n\n\n\n\n#common words from fake news\n\n#some bad words.\nbad_words = ['a','the','and',\n             's','he','she',\n             'have','has','to',\n             'new','all','any',\n             'as','of','to','on',\n             'in','at','that',\n             'this','is','are'\n             'for','it','was',\n             'were','for','with',\n             'his','be','by',\n             'are','is','they',\n             'not','i','who','where',\n             'from','t','we','they',\n             'you','an','about','then',\n             'her','or','what','will',\n             'but','would','been',\n             'their','if','people',\n             'when','out','had',\n             'one','said','more','just',\n             'our','can','so','there',\n             'which','like','no','after',\n             'up','because','also','do','how',\n             'than','even','over','into','other',\n             'him','only','news','being','us','some','against',\n             're','should','state','these',\n             'get','them','could','don',\n             'time','now','its','going','while',\n             'many','first','most','via','make','told',\n             'my','very','those','your','during','house',\n             'did','made','know','two','think','before',\n             'last','may','back'\n            ] \n\n\nwords = []\ncommon_words = []\nfor news in fake_news.text:\n    for word in news.split():\n        lower_word = word.lower()\n        if lower_word not in bad_words:\n            words.append(lower_word)\n    \nfor item,count in collections.Counter(words).items():\n    if count > 5000:\n        common_words.append({'word':item,'count':count})\n\ntop_commons = sorted(common_words, key=lambda w: w['count'],reverse=True) \n\n#VISUALIZATONS\n\n#TOP 10 COMMON WORDS FROM FAKE NEWS\nfig, (ax1, ax2) = plt.subplots(1, 2,figsize=(20,5))\n\nax1.title.set_text('TOP 10 COMMON WORDS FROM FAKE NEWS')\nplt.setp(ax1.xaxis.get_majorticklabels(), rotation='vertical')\nax1.bar([data['word'] for data in top_commons[0:10]],\n        [data['count'] for data in top_commons[0:10]])\n\n#fake news subject counts\nfake_news_acc_subject = fake_news.subject\n\nax2.title.set_text('FAKE NEWS SUBJECT COUNTS')\nax2 = fake_news_acc_subject.value_counts().plot(kind='bar');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FAKE NEW CLASSIFICATION\n\n\n#logistic regression\nx_train,x_test,y_train,y_test = train_test_split(data['text'], data['fake'], test_size=0.2, random_state=40)\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,4)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}