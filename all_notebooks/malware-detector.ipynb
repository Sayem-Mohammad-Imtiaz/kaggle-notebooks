{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Feature Analysis**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('/kaggle/input/malware-analysis-datasets-top1000-pe-imports/top_1000_pe_imports.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"innocent= data.loc[data['malware']==0]\ninnocent.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counts= data['malware'].value_counts()\n\nprint(\"Malicious Samples: \", counts[1])\nprint(\"Benign Samples: \", counts[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nlabels=['Malicious', 'Benign']\nsizes=[data['malware'].value_counts()[1],\n     data['malware'].value_counts()[0]]\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels,)\nax1.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Automatic Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data['malware']\nx=data.drop(['malware','hash'],axis=1)\n#dropping hash as it is a (mosty unique) character value, cannot be mapped into feature space.\n\n#x.head()\n#y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=ExtraTreesClassifier(n_estimators=50, random_state=15372)\n#Setting random state, else predictions vary everytime\nmodel.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selections= SelectFromModel(model,prefit=True)\nx_new=selections.transform(x)\nprint('Number of features: %d' %(x_new.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_features= x_new.shape[1]\nindices = np.argsort(model.feature_importances_)[::-1][:nb_features]\nfor f in range(nb_features):\n    number = f+1\n    feature_name = ''.join(x.columns[indices[f]])\n    feature_importance = model.feature_importances_[indices[f]]\n    print('   %d.\\t%s \\t%f' % (number, feature_name, (feature_importance * 100)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing Purposes \n#print(indices)\n#print(x.iloc[[1],[957]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Our Analysis: Top 1000 PE Headers\n\nmsvcrt.dll -\n\n1. _cexit 8.280818\n2. _controlfp 3.025105\n3. _getmainargs 1.754543\n4. _initterm 1.724222\n5. _p__fmode 1.655268\n6. exit 1.607496\n7. _p__commode 1.430197\n8. _set_app_type 1.413838\n9. _exit 1.263665\n10. _onexit 0.981152\n11. _XcptFilter 0.709312\n12. _setusermatherr 0.688940\n\nImportant Indicators while doing analysis:(my opinion based on my experience)\n\n1. VirtualAlloc\n2. VirtualProtect\n3. GetModuleHandleA\n4. ExitProcess\n5. RegCloseKey\n6. GetCurrentProcessId\n7. TerminateProcess\n8. LoadLibraryA\n9. GetCurrentProcess\n10. malloc\n11. VirtualFree\n12. free\n13. MapVirtualKeyA\n14. MapVirtualKeyW\n15. SetWindowsHookExA\n16. SetWindowsHookExW\n\nThere a couple of more interestung dll's that are used by malwares like WSOC which is used to communicate with the command and control center","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Feature Analysis: Malicious v. Benign Samples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('/kaggle/input/malware-analysis-datasets-top1000-pe-imports/top_1000_pe_imports.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['hash'],axis=1)\ndata.info() #dropping hash; to get all integer values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flag=0\nfor column in data.columns.tolist():\n    if data[column].nunique()!=2:\n        print(column+ \" has more than 2 unique values\")\n        flag=1\n\nif flag==0:\n    print(\"All columns have 2 values only\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mal= data.loc[data['malware']==1]\nbenign= data.loc[data['malware']==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index= data.columns.tolist()\ncolumns=['Benign=0', 'Benign=1', 'Malicious=0', 'Malicious=1', 'Difference']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(index=index, columns=columns)\ndf = df.fillna(0)\n#df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a dataframe with the percentage of benign and malicious samples corresponding to 0 and 1 respectively for each column\n\nfor column in data.columns.tolist():\n    df.loc[[column],['Benign=1']]= np.round((benign[column].sum()/benign.shape[0]*100),2)\n    df.loc[[column],['Benign=0']]= np.round(((benign.shape[0]-benign[column].sum())/benign.shape[0]*100),2)\n    df.loc[[column],['Malicious=1']]= np.round((mal[column].sum()/mal.shape[0]*100),2)\n    df.loc[[column],['Malicious=0']]= np.round(((mal.shape[0]-mal[column].sum())/mal.shape[0]*100),2)\n    df.loc[[column],['Difference']]= abs(np.round((((benign[column].sum()/benign.shape[0])- (mal[column].sum()/mal.shape[0]))*100 ),2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sorting with respect to differences, to get the most different values\n\ndf=df.sort_values('Difference', ascending=False)\ndf=df.drop(['malware']) #Obviously, this column will be different\n#df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Comparision\n\nComparing the performance of our model with all features of the dataset, and important features selected automatically in sk-learn.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('/kaggle/input/malware-analysis-datasets-top1000-pe-imports/top_1000_pe_imports.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data(dataframe):\n    y= dataframe['malware']\n    X= dataframe.drop(['malware'], axis=1)\n    print(\"X Shape: \", X.shape)\n    print(\"Y Shape: \", y.shape)\n    X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=2)\n    \n    return (X, y, X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model, X_val, y_val, predictions):\n    print(\"Confusion Matrix: \\n\", confusion_matrix(y_val, predictions))\n    print(\"Precision:\", precision_score(y_val, predictions))\n    print(\"Recall:\",recall_score(y_val, predictions))\n    print(\"F1 Score:\", f1_score(y_val, predictions))\n    return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Automatically Selected Important Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df= data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= df['malware']\nX= df.drop(['hash','malware'], axis=1)\n#Remove hash, it is always a unique character string- MODEL WILL NOT TRAIN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=50, random_state=3)\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find Important features\nimportances= pd.DataFrame({'Feature': X_train.columns, 'Importance': np.round((rf.feature_importances_ * 100),3)})\nimportances= importances.sort_values('Importance', ascending=False).set_index('Feature')\n\nimportances.loc[importances['Importance']> 0.2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features= importances.loc[importances['Importance']> 0.2].index.to_list()\nmal= ['malware']\ncolumns= features + mal\n\ncolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keep only important features\n\ndf=data[columns]\n\n#df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y, X_train, X_test, y_train, y_test= create_data(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100, \n                            random_state=3, \n                            bootstrap= True,\n                            max_depth= 110,\n                            max_features= 3,\n                            min_samples_leaf= 2,\n                            min_samples_split= 3)\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= rf.predict(X_test)\n\nprint(\"Train Accuracy:\",rf.score(X_train, y_train) )#accuracy\nprint( \"Test Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores= cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy') #5 fold\n\nprint(\"Scores: \", scores)\nprint(\"Mean: \", scores.mean())\nprint(\"Standard Deviation: \", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross Validation Evaluation\n\nprint(\"Cross Validation Evaluation:\\n\")\npredictions = cross_val_predict(rf, X_train, y_train, cv=3)\nevaluation(rf, X_train, y_train, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Set Evaulation\n\nprint(\"\\nTest Set Evaluation:\\n\")\ny_pred = rf.predict(X_test)\nevaluation(rf, X_test, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing and Tuning the Model\nUsing our selected features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('/kaggle/input/malware-analysis-datasets-top1000-pe-imports/top_1000_pe_imports.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= data[['OpenProcess', 'GetCurrentProcess', 'GetProcessHeap','ReadFile', 'CreateFileW', 'WriteFile', 'FindFirstFileW', 'FindNextFileW', 'SetWindowsHookExW', 'GetAsyncKeyState', 'GetForegroundWindow', 'GetKeyState', 'MapVirtualKeyW', 'VirtualAlloc', 'VirtualProtect', 'GetModuleHandleA', 'ExitProcess', 'RegCloseKey','GetCurrentProcessId', 'malware']]\n#df.columns.to_list()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= df['malware']\nX= df.drop(['malware'], axis=1)\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=2)\n#print(X_train.shape, X_test.shape)\n#print(y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Classifier\n\nrf = RandomForestClassifier(n_estimators=50, random_state=3)\nrf.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import cross_val_score, cross_val_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= rf.predict(X_test)\n\nprint(\"Train Accuracy:\",rf.score(X_train, y_train) )\nprint( \"Test Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#since accuracy is pretty high (97.8%), will check on cross validation\n\nscores= cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy') #5 fold\n\nprint(\"Scores: \", scores)\nprint(\"Mean: \", scores.mean())\nprint(\"Standard Deviation: \", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Still pretty good accuracy, so checking Out of Bag score\n\nrf = RandomForestClassifier(n_estimators=50, oob_score = True, random_state=3)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n\nprint(\"OOB score:\", round(rf.oob_score_, 4)*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model, X_val, y_val, predictions):\n    print(\"Confusion Matrix: \\n\", confusion_matrix(y_val, predictions))\n    print(\"Precision:\", precision_score(y_val, predictions))\n    print(\"Recall:\",recall_score(y_val, predictions))\n    print(\"F1 Score:\", f1_score(y_val, predictions))\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross Val Evaluation\n\nprint(\"Cross Validation:\\n\")\npredictions = cross_val_predict(rf, X_train, y_train, cv=3)\nevaluation(rf, X_train, y_train, predictions)\n\n\n#Confusion matrix: [[TN, FP], [FN,TP]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing Evaluation\n\nprint(\"Test Set:\\n\")\ny_pred = rf.predict(X_test)\nevaluation(rf, X_test, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"High Precision= Low false positive rate\nHigh Recall= Low false negative rate\n\nSo I am seeing some false positives. But good news is that we have VVV high true positives and VVV low false negatives, which is required for a Malware Detector","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking what Features are deamed important by the classifier; cross check with how it relates to Bhat's Stuff\n\nimportances= pd.DataFrame({'Feature': X_train.columns, 'Importance': np.round(rf.feature_importances_,3)})\nimportances= importances.sort_values('Importance', ascending=False).set_index('Feature')\n\nimportances\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Current parameters in use\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rf.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameters I want to work on:\n\n1. bootstrap = method for sampling data points (with or without replacement) (False= entire dataset used to make trees)\n2. max_depth = max number of levels in each decision tree (More depth may lead to single leaf nodes in each tree, less depth may not be sufficient enough to capture the info)\n3. max_features = max number of features considered for splitting a node\n4. n_estimators = number of trees in the forest\n5. min_samples_split = min number of data points placed in a node before the node is split (how many samples are needed to split the node)\n6. min_samples_leaf = min number of data points allowed in a leaf node (helps smoothen the model)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing diff values: each iteration, algo chooses a different combination of features\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\npprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier() #Base Model\nrf_random = RandomizedSearchCV(estimator = rf, \n                               param_distributions = random_grid, \n                               n_iter = 100, \n                               cv = 3, \n                               verbose=2, \n                               random_state=42,\n                               n_jobs = -1)\n\n# 3 folds of cross validation, more cv reduces overfitting but increases run time.\n# n_jobs=-1 uses all processors in parallel\n# Verbosity helps log the output. https://stats.stackexchange.com/questions/153823/what-is-verbose-in-scikit-learn-package-of-python","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Will take a while to run\nrf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show best parameters\nrf_random.best_params_\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Found Best Parameters:\n\n1. n_estimators: 1600\n2. min_samples_split: 10\n3. min_samples_leaf: 2\n4. max_features: sqrt\n5. max_depth: 80\n6. bootstrap: True","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [1, 2, 3],\n    'min_samples_split': [8,10],\n    'n_estimators': [1400, 1600, 1800]\n}\n# Create a based model\nrf = RandomForestClassifier()\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best Parameters:\n\n1. 'bootstrap': True,\n2. 'max_depth': 110,\n3. 'max_features': 3,\n4. 'min_samples_leaf': 2,\n5. 'min_samples_split': 10,\n6. 'n_estimators': 1600","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Malware Detector (Final)\n\n(After Tuning)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('/kaggle/input/malware-analysis-datasets-top1000-pe-imports/top_1000_pe_imports.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= data[['OpenProcess', 'LoadLibraryA', 'GetProcessHeap', 'ShellExecuteW', 'VirtualFree', 'GetDC', 'IsDebuggerPresent', 'malloc', 'FindNextFileA', 'free', 'GetAsyncKeyState', 'GetTickCount', 'exit', '_cexit', 'VirtualAlloc', 'VirtualProtect', 'GetModuleHandleA', 'ExitProcess', 'RegCloseKey','GetCurrentProcessId', 'malware']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= df['malware']\nX= df.drop(['malware'], axis=1)\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=2)\n#print(X_train.shape, X_test.shape)\n#print(y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=1600, \n                            random_state=3, \n                            bootstrap= True,\n                            max_depth= 110,\n                            max_features= 3,\n                            min_samples_leaf= 2,\n                            min_samples_split= 10)\nrf.fit(X_train,y_train)\n\n#If Bootstrap is False then OOB is not available","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= rf.predict(X_test)\n\nprint(\"Train Accuracy:\",rf.score(X_train, y_train) )#accuracy\nprint( \"Test Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores= cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy') #5 fold\n\nprint(\"Scores: \", scores)\nprint(\"Mean: \", scores.mean())\nprint(\"Standard Deviation: \", scores.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(model, X_val, y_val, predictions):\n    print(\"Confusion Matrix: \\n\", confusion_matrix(y_val, predictions))\n    print(\"Precision:\", precision_score(y_val, predictions))\n    print(\"Recall:\",recall_score(y_val, predictions))\n    print(\"F1 Score:\", f1_score(y_val, predictions))\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross Validation Evaluation\n\nprint(\"Cross Validation Evaluation:\\n\")\npredictions = cross_val_predict(rf, X_train, y_train, cv=3)\nevaluation(rf, X_train, y_train, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Set Evaulation\n\nprint(\"\\nTest Set Evaluation:\\n\")\ny_pred = rf.predict(X_test)\nevaluation(rf, X_test, y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}