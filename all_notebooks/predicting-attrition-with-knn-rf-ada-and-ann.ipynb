{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8c497b8f-b39d-c092-2d6c-ed6750402074"},"source":"Hello everyone, I'm fairly new to Kaggle and the area of machine learning fascinates me so I'd love to get feedback from this kernel, criticism is welcome! Here's my attempt.\n\nUpon reading the data using Pandas, I realized that I was often getting KeyErrors because the leading column header, Age, had a specific unseen character in the header name. I found there was a /ufeff character which I had to avoid reading, so StackOverflow suggested I use the 'utf-8-sig' econding parameter."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"576c7b59-f8f3-c90e-a90c-616f15426af0"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\n#Get data\ndata = pd.read_csv('../input/WA_Fn-UseC_-HR-Employee-Attrition.csv', encoding='utf-8-sig')"},{"cell_type":"markdown","metadata":{"_cell_guid":"8f03f06b-7682-5020-1583-510f3b129234"},"source":"Upon manually investigating the dataframe, I now realized that there was some series that provided no real information for my analysis; which I found to be EmployeeCount, EmployeeNumber, Over18 and StandardHours. I did make note that the StandardHours was 80, which meant a typical biweekly pay period (which is important information for later). I also saved the income data into new dataframes for later analysis.\n\nI also noticed that a few series had numerical values which were orders of magnitude larger than others. I decided to normalize the data to reduce feature favoring."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f5a6f8b-4b55-c4b5-4b6d-79d14d31ad7c"},"outputs":[],"source":"#Drop columns irrelevant to our analysis\ndrop_columns = ['EmployeeCount','EmployeeNumber','Over18','StandardHours']\ndata = data.drop(drop_columns, axis=1)\n\n#Investigate relationship between incomes\nmnth_inc = data['MonthlyIncome']\nmnth_rte = data['MonthlyRate']\ndly_rte = data['DailyRate']\nhly_rte = data['HourlyRate']\n\n#Normalize the large income data for HourlyRate, DailyRate, MonthlyRate and MonthlyIncome\nnorm_col = ['HourlyRate','DailyRate','MonthlyRate','MonthlyIncome']\nfor col in norm_col:\n    data[col] = (data[col] - data[col].mean())/ data[col].std()"},{"cell_type":"markdown","metadata":{"_cell_guid":"33549585-a2de-4951-ef5e-73411ff19614"},"source":"Next I separated the target label and convert to binary numerical data. Additionally, I then identified the categorical series and separated them from the main data. I then one-hot encoded the categorical data and combined the two dataframes."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3bfbc4bb-2845-9017-3e4c-41aec8d7e201"},"outputs":[],"source":"#Convert categorical features to numerical features\nle = LabelEncoder()\nattrition = data['Attrition']\nattrition = le.fit_transform(attrition)\ndata.drop('Attrition', axis=1, inplace=True)\n\ncat_col = data.select_dtypes(include=['object']).columns.values\ndata_col = data[cat_col]\ndata.drop(cat_col, axis=1, inplace=True)\n\n#One hot encode categorical data and combine dataframes\ndata_col = pd.get_dummies(data_col)\ndata = pd.concat([data, data_col], axis=1).as_matrix() "},{"cell_type":"markdown","metadata":{"_cell_guid":"3621776a-fcc5-4dec-53e4-8c3fae9669f8"},"source":"When I looked at the income/rate values for the employees I noticed that there really wasn't a correlation between them. One would expect that the DailyRate would be about 8 * HourlyRate and the MonthlyRate would be 21.67 * DailyRate, (21.67 being the average working days per month), all of this not taking into account over time yet. When I looked into this further some interesting results were found."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"111e1c90-8be4-d08a-3367-9a31e44b76bf"},"outputs":[],"source":"#Visiualize the 'questionable' income correlations\nf, ((p1, p2), (p3, p4)) = plt.subplots(2,2,figsize=(12,10))\np1.hist(dly_rte / hly_rte, bins=12, edgecolor='k')\np1.set_xlabel('Hours Needed for Daily Rate')\np2.hist(mnth_rte / dly_rte, edgecolor='k')\np2.set_xlabel('Days Needed for Monthly Rate')\np3.hist((mnth_rte * 12 / 26) / (hly_rte * 80), bins=30, edgecolor='k')\np3.set_xlabel('Monthly rate normalized against 80 hour pay period')\np4.hist(mnth_inc/mnth_rte, bins=30, edgecolor='k')\np4.set_xlabel('Ratio of Monthly Income to Monthly Rate')\nf.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"3787c16d-0b70-3f92-5ff2-d4bda99268a0"},"source":"**Note: I do realize that the data is synthetic and therefore not truly representative of real data.**\n\nFirstly, I assumed all rate/income data was gross income.\n\nFrom the charts we see some interesting correlations:\n1. There were employees working 30+ hours a day, some 40+.\n2. There were employees working 100+ days a month, some 150+.\n3. This correlation makes sense. I'd expect to see an 'almost' normal distribution centered at 1 since the ratio (MonthlyRate x 12 months / 26 pay periods) / (HourlyRate x 80 hours per pay period) should equal 1.\n4. There were employees making 2+ times their MonthlyRate as a MonthlyIncome, some 8+.\n\nI decided to train my models excluding all rate/income data except one at a time (Hourly, then Daily, then MonthlyRate, then MonthlyIncome). Oddly enough, I got the best accuracy when all rate/income data was included in training. This puzzles me, but it is synthetic data so the inherent randomness of the information could somehow all work itself out. Who knows.\n\n\nFinally, I chose my models (KNN, RF and AdaBoost) and trained then. I also compared them against an ANN in Keras."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d2e835b-52df-513f-40a1-b7d784f80ab4"},"outputs":[],"source":"#Choose our classifiers\nrfc = RandomForestClassifier(n_estimators=1000, random_state=0, max_features=.1, max_depth=15)\nada = AdaBoostClassifier(random_state=0)\nknn = KNeighborsClassifier()\n\nrfc_accuracy = cross_val_score(rfc, data, attrition, cv=5)\nada_accuracy = cross_val_score(ada, data, attrition, cv=5)\nknn_accuracy = cross_val_score(knn, data, attrition, cv=5)\n\n#Create an ANN using Keras and Tensorflow backend\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\n\ndef ANN_Classifier():\n    cl = Sequential()\n    cl.add(Dense(20, activation='relu', kernel_initializer='random_normal',  input_shape=(data.shape[1],)))\n    cl.add(Dropout(0.1))\n    cl.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n    \n    adm = Adam()\n    \n    cl.compile(optimizer=adm, loss='binary_crossentropy', metrics=['accuracy'])\n    return cl\n\nann = KerasClassifier(build_fn=ANN_Classifier, batch_size=100, epochs=150, verbose=0)\nann_accuracy = cross_val_score(ann, data, attrition, cv=20)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7a8c1807-af0a-0ca6-fb0b-bc7f529a5e51"},"source":"Finally, the accuracies were as follows:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3c04ecfc-d770-9f40-61df-02321c59ce1b"},"outputs":[],"source":"print('Max RandomForest Accuracy: {:.4f}'.format(rfc_accuracy.max()))\nprint('Max AdaBoost Accuracy: {:.4f}'.format(ada_accuracy.max()))\nprint('Max KNN Accuracy: {:.4f}'.format(knn_accuracy.max()))\nprint('Max ANN Accuracy: {:.4f}'.format(ann_accuracy.max()))"},{"cell_type":"markdown","metadata":{"_cell_guid":"cc924d7e-7ae5-70d4-e037-31737156aa1b"},"source":"I welcome any questions, comments, feedback or advice. It helps me learn and improve."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}