{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello\nI will use some of what I learned‚Ä¶‚Ä¶.or copied üôÇ from chapter 2 of Hands on ML by Aur√©lien G√©ron to create a prediction model.\n\nFor any comments please take it easy on me. I work in accounting and have been programming for a little over 2 years. üôÇ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Imports and looking at the data**\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.impute import SimpleImputer\n\nHOUSING_PATH = \"/kaggle/input/usa-housing/\"\nFILE_NAME = \"USA_Housing.csv\"\n\ndef load_data(housing_path = HOUSING_PATH, file_name = FILE_NAME):\n    csv_path = os.path.join(housing_path, file_name)\n    return pd.read_csv(csv_path)\n\nhousing = load_data()\n\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets check the summary of columns count and data types of the DataFrame.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The DataFrame is made up of 5000 rows. Luckily for us we have no missing values. We also see that all of the columns contain numbers(floats) except the ‚ÄúAddress‚Äù column.\n\nThe median income or average income is usually the main indicator for housing prices. We have an ‚ÄúAvg. Area Income‚Äù column in the DataFrame. Let‚Äôs create a category by using the ‚ÄúAvg. Area Income‚Äù column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will turn the labels into integers instead of floats\nhousing[\"income_cat\"] = pd.cut(housing[\"Avg. Area Income\"],\n                               bins=[0, 40000, 60000, 80000, 90000, 110000],\n                               labels=[1, 2, 3, 4, 5])\n\npd.cut(housing[\"Avg. Area Income\"],\n             bins=[0, 40000, 60000, 80000, 90000, 110000]).value_counts()\n\nhousing[\"income_cat\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create a train and test set for our prediction model**\n\nIt is good practice to set aside a test set and not look at it. If we don‚Äôt then we may fall prey to data snooping. I got the simplest explanation on data snooping from quantitrader.com .On their website is says ‚ÄúData snooping refers to statistical inference that the researcher decides to perform after looking at the data‚Äú.\n\nSince we have 5 categories in our data it is important that we draw out samples in proportion to those categories. This is referred to as stratified sampling. It means that the sample should be representative of the overall population. The below shows how the data is split by percentage between the 5 categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"income_cat\"].value_counts() / len(housing) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above we see that category 3 represents most of the population with 65.44%. Now lets do some stratified sampling.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"split = StratifiedShuffleSplit(n_splits=1,test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing,housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]\n\n# Drop the 'income_cat' so that the data is back to its original state\nfor set in (strat_train_set,strat_test_set):\n    set.drop([\"income_cat\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualize data to gain insights**\n\nBefore we start lets create a copy of our training set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = strat_train_set.copy()\nhousing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let‚Äôs see how much each attribute(column) correlates with the ‚ÄúPrice‚Äù","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = housing.corr()\ncorr_matrix[\"Price\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As mentioned earlier,median income or average income is usually the main indicator for housing prices. By looking at the above correlations it shows that indeed ‚ÄúAvg. Area Income‚Äù has the best correlation to the ‚ÄúPrice‚Äù.\n\nWe can visualize how the 3 top attributes correlate with the house price via a scatter matrix.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nattributes = [\"Price\", \"Avg. Area Income\", \"Avg. Area House Age\", \"Area Population\"]\npd.plotting.scatter_matrix(housing[attributes],figsize=(12,8))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can zoom in to the ‚ÄúAvg. Area Income‚Äù and ‚ÄúPrice‚Äù since it shows the most promise.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot(kind=\"scatter\", x=\"Avg. Area Income\", y=\"Price\", alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above reveals a strong correlation as the points are not too dispersed.  We can use the Avg. Area Income in our prediction model to determine the house prices.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Prepare data for the machine learning algorithm**\n\nFirst we need to separate the predictors and the labels because we do not want to apply the same transformations to them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = strat_train_set.drop(\"Price\", axis=1)\nhousing_labels = strat_train_set[\"Price\"].copy()\nhousing\nhousing_labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We do not have any missing data in our DataFrame. But you might get another data set that has missing values. Therefore we need to account for that missing by using Scikit-Learn‚Äôs Imputer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = SimpleImputer(strategy=\"median\")\nhousing_num = housing.drop(\"Address\",axis=1)\nimputer.fit(housing_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All we are saying here is that if we encounter a missing value, we want to replace that missing value with the median value. We can check to see if the median value is indeed being used be executing the below code.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer.statistics_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_num.median().values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both results are the same which is what we wanted. Now we can use the trained imputer to transform the training set by replacing the missing values by the learned medians. This won‚Äôt do anything for this data set because it has no missing values but it will be very handy for data sets with missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Returns a Numpy array\nX = imputer.transform(housing_num)\n# Turn the array into a Pandas DataFrame\nhousing_tr = pd.DataFrame(X,columns=housing_num.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let‚Äôs now build a small pipeline. The pipeline in the Hands on ML book is bigger than what we are going to do here. The Pipeline class helps to execute the data transformation steps in the right order. We will also include scaling in our data using Scikit-Learn‚Äôs StandardScalar.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\npipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"std_scaler\", StandardScaler()),\n])\n\nhousing_tr = pipeline.fit_transform(housing_num)\nhousing_tr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Select and Train a model**\n\nI found out though practice(the few models I built) and by listening to Dr Eugene Dubossarsky that the RandomForestRegressor is best most cases.  Because of this I‚Äôm not going to show how different models compare with each other. So let‚Äôs create a model, fit it and get save some prediction and actual values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmy_model = RandomForestRegressor()\nmy_model.fit(housing_tr, housing_labels)\n\n# Get some data and some labels. That last 10 instances\nsome_data = housing_num.iloc[:10]\nsome_labels = housing_labels.iloc[:10]\n\nsome_data_prepared = pipeline.transform(some_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let‚Äôs calculate some indicators like MSE(mean squared error) and RMSE(root mean squared error).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nhousing_predictions = my_model.predict(housing_tr)\nmy_model_mse = mean_squared_error(housing_labels,housing_predictions)\nmy_model_rmse = np.sqrt(my_model_mse)\n\n\"Model Root Mean Squared Error:\", my_model_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The price range of a house is between USD15,938 and USD2,469,065 which is huge. The RMSE is equal to USD45,104 which means a typical prediction error will be around USD45,104. Is the RMSE to big? I don‚Äôt think so but lets use cross validation before we predict and then see.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nmy_model_scores = cross_val_score(RandomForestRegressor(),\n                  housing_tr,housing_lables,scoring=\"neg_mean_squared_error\",cv=10)\nmy_model_rmse_scores = np.sqrt(-my_model_scores)\n\ndef display_scores(scores):\n    print(\"Mean: \", scores.mean())\n    print(\"Standard deviation: \", scores.std())\n\ndisplay_scores(my_model_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get standard deviation of US4,704 . Is that good or bad? I think it‚Äôs good.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Predictions**\n\nFinally we can do some predictions and compare with actual prices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set prediction price and actual price variables\npredictions = np.ceil(my_model.predict(some_data_prepared))\nactuals = np.ceil(list(some_labels))\n\nfor p, a in list(zip(predictions, actuals)):\n    percentage_diff = (a - p) / a * 100\n    percentage_diff = round(percentage_diff,2)\n    print(\"Prediction:\", int(p), \"Actual:\", int(a), \"Percentage difference:\", percentage_diff)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The percentage difference is ranges between -2.2% to 4.3% which comes to a 6-7% variance. Is it good? I think so again. Maybe you can build a better one. Maybe I missed something that you can see and improve on. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}