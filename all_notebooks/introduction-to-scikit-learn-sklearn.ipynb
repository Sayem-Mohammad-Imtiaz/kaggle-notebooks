{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to Scikit-Learn (Sklearn)\n\nThis notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn Library\n\n**What is Covered:**\n\n0. An end-to-end scikit learn workflow\n1. Getting the data ready\n2. Choose the right estimator/algorithm/model for the problem\n3. Fit the model and use it to make prediction on the data\n4. Evaluating a model\n5. Improve a model\n6. Save and load a trained model\n7. Putting it all together","metadata":{}},{"cell_type":"code","source":"# standard imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0. An end-to-end Scikit-Learn workflow","metadata":{}},{"cell_type":"code","source":"# 1. Getting the data ready\nheart_disease = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv')\nheart_disease.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create X (features)\nX = heart_disease.drop(\"target\", axis=1)\n\n# Create y (label matrix)\ny = heart_disease[\"target\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Choose the right model and hyperparameters\nfrom sklearn.ensemble import RandomForestClassifier\nclf =  RandomForestClassifier()\n\n# We'll keep the default hyperparameters\nclf.get_params()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Fit the model to the data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nclf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prediction\ny_preds = clf.predict(X_test)\ny_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Evaluate the model on the training data and the test data\nclf.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(classification_report(y_test, y_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Improve a model\n\n# try different amount of an n_estimators\nnp.random.seed(42)\nfor i in range(10, 100, 10):\n    print(f\"Trying model with {i} estimators . . .\")\n    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\", end='\\n________________\\n')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Save a model and load it\nimport pickle\n\npickle.dump(clf, open(\"random_forest_model_1.pkl\", \"wb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = pickle.load(open('./random_forest_model_1.pkl', 'rb'))\nloaded_model.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Getting our data ready to be used by machine learning\n\nThree main things to do:\n1. Split the data into features and labels (usually called `X` and `y`)\n2. Filling (also called imputing) or diregarding missing values\n3. Converting non-numerical values to numerical values (also called feature encoding)","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Making sure the data is all numerical","metadata":{}},{"cell_type":"code","source":"car_sales = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended.csv')\ncar_sales.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_sales.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into X/y\nX = car_sales.drop('Price', axis=1)\ny = car_sales['Price']\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn Categories into numbers\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# Categorical features\ncategorical_features = ['Make', 'Colour']\ndoor_feature = ['Doors']\n\none_hot = OneHotEncoder()\ntransformer = ColumnTransformer([\n    ('one_hot', one_hot, categorical_features),\n], remainder='passthrough')\n\ntransformed_X = transformer.fit_transform(X)\npd.DataFrame(transformed_X).head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nX_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Dealing with missing values\n\n1. Fill them with some value\n2. Remove the samples with missing data altogether","metadata":{}},{"cell_type":"code","source":"car_sales_missing = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended-missing-data.csv')\ncar_sales_missing.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the rows with no labels\ncar_sales_missing.dropna(subset=['Price'], inplace=True)\ncar_sales_missing.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into X & y\nX = car_sales_missing.drop('Price', axis=1)\ny = car_sales_missing['Price']\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"car_sales_missing.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill missing values with Scikit-Learn\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Fill categorical values with `missing` and numerical values with mean\ncat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\ndoor_imputer = SimpleImputer(strategy='constant', fill_value=4)\nnum_imputer = SimpleImputer(strategy='mean')\n\n# Define columns\ncat_features = ['Make', 'Colour']\ndoor_feature = ['Doors']\nnum_features = ['Odometer (KM)']\n\n# Create an imputer\nimputer = ColumnTransformer([\n    ('cat_imputer', cat_imputer, cat_features),\n    ('door_imputer', door_imputer, door_feature),\n    ('num_imputer', num_imputer, num_features)\n])\n\n# Transform the data\nfilled_X = imputer.fit_transform(X)\nfilled_X_df = pd.DataFrame(filled_X, columns=['Make', 'Colour', 'Doors', 'Odometer (KM)'])\npd.DataFrame(filled_X).isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert data to numbers\n# Turn the categories into numbers\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ncategorical_features = ['Make', 'Colour', 'Doors']\none_hot = OneHotEncoder()\ntransformer = ColumnTransformer([\n    ('one_hot',\n     one_hot,\n     categorical_features)\n], remainder='passthrough')\n\ntransformed_X = transformer.fit_transform(filled_X_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit a model\nnp.random.seed(42)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Choosing the right estimator for our problem","metadata":{}},{"cell_type":"markdown","source":"\n<a href='https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html' target='_blank'><img src='https://scikit-learn.org/stable/_static/ml_map.png' style='width: 1000px;' id='ml_map'></a>","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Picking a machine learning model for our regression problem","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# import boston housing dataset\nfrom sklearn.datasets import load_boston\n\nboston = load_boston()\nboston_df = pd.DataFrame(data=boston['data'], columns=boston['feature_names'])\nboston_df['target'] = pd.Series(boston['target'])\nboston_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boston_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's try the ridge regression model\nfrom sklearn.linear_model import Ridge\n\n# Setup random seed\nnp.random.seed(42)\n\n# Create the data\nX = boston_df.drop('target', axis=1)\ny = boston_df['target']\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Instantiate the Ridge model\nmodel = Ridge()\nmodel.fit(X_train, y_train)\n\n# Check the score of the ridge model on test data\nmodel.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How do we improve this score?\n\nWhat if Ridge was not working?","metadata":{}},{"cell_type":"code","source":"# Let's try RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Setup random seed\nnp.random.seed(42)\n\n# Create the data\nX = boston_df.drop('target', axis=1)\ny = boston_df['target']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Instantiate RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(X_train, y_train)\n\n# Evalute the model (Check the score for RandomForestRegressor)\nrf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Choosing an estimator for classfication problems","metadata":{}},{"cell_type":"code","source":"heart_disease = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv')\nheart_disease.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart_disease.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check [the ml map](#ml_map)\n\nthe map advises to use <a href='https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC' target='_blank'>linear svc</a>","metadata":{}},{"cell_type":"code","source":"# Import the linear svc estimator class\nfrom sklearn.svm import LinearSVC\n\n# Setup random seed\nnp.random.seed(42)\n\n# prepare the data\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Instantiate the model\nclf = LinearSVC()\n\n# fit the model\nclf.fit(X_train, y_train)\n\n# score the model\nclf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets' check ensemble classifier","metadata":{}},{"cell_type":"code","source":"# Import RandomForestClassifier estimator class\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Setup random seed\nnp.random.seed(42)\n\n# Make the data\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Initialize and fit the model\nclf = RandomForestClassifier().fit(X_train, y_train)\n\n# Score the model\nclf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Fit the model/algorithm and use it to make predictions\n\n### 3.1 Fittig the model to the data\n\n### 3.2 Making predictions using a machine learning model\ntwo ways to make predictions\n1. `predict()`\n2. `predict_proba()`","metadata":{}},{"cell_type":"code","source":"# use a trained model to make predictions\ny_preds = clf.predict(X_test)\ny_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = np.array(y_test)\ny_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare predictions to truth labels\nnp.mean(y_preds == y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n# returns the mean accuracy on the given data and labels\naccuracy_score(y_test, y_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make predictions with `predict_proba()`\n","metadata":{}},{"cell_type":"code","source":"# predic_probab return probabilities of a classification label\nclf.predict_proba(X_test[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's predict on the same data\nclf.predict(X_test[:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`predict()` can also be used for regression models","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\n# Create the data\nX = boston_df.drop('target', axis=1)\ny = boston_df['target']\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Initialize and fit the model\nmodel = RandomForestRegressor().fit(X_train, y_train)\n\n# Make predictions\ny_preds = model.predict(X_test)\ny_preds[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comare predictions to the truth\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test, y_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Evaluating a machine learning model\n\nThree way to evaluate scikit learn model/estimator:\n1. Estimator `score` method\n2. The `scoring` parameter\n3. Problem-specific metric functions\n\n### 4.1 Evaluating a model with `score` method","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nnp.random.seed(42)\n\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nclf = RandomForestClassifier().fit(X_train, y_train).fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2 Evaluating a model using a `scoring` parameter","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nclf = RandomForestClassifier().fit(X_train, y_train)\n\nclf.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cross_val_score(clf, X, y, cv=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`scoring` parameter is set to `None` by default\n\nWhen `scoring` is set to `None`, default evaluation metric is used, that is `score` in case of classifier","metadata":{}},{"cell_type":"code","source":"cross_val_score(clf, X, y, cv=5, scoring=None)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.1 Classification model evaluation metrics\n1. Accuracy\n2. Area under the curve\n3. confusion matrix\n4. classification report","metadata":{}},{"cell_type":"markdown","source":"**Accuracy**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\nclf = RandomForestClassifier()\n\naccuracy_cv_score = cross_val_score(clf, X, y, cv=5)\naccuracy_cv_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Heart disease classifier cross-validated accuracy {np.mean(accuracy_cv_score) *100 :.2f} %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Area under the receiver operating charactristic curve (AUC/ROC)**\n* Area under curve (AUC)\n* ROC Curve\n\nROC curves are a comparison of a model's true positive rate (tpr) versus a model's false positive rate (fpr)\n* True positive = model predicts 1 when truth is 1\n* False positive = model predicts 1 when truth is 0\n* True negative = model predicts 0 when truth is 0\n* False negative = model predicts 0 when truth is 1\n\nTrue Positive Rate = $\\frac{True Positive}{True Positive + False Negative}$\n\nFalse Negative Rate = $\\frac{False Positive}{False Positive + True Negative}$\n\n**See <a href='https://www.youtube.com/watch?v=4jRBRDbJemM'>this video</a>**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Initialize and fit the model\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\n\n# Make predictions with probabilities\ny_probs = clf.predict_proba(X_test)\n\ny_probs[:7], y_probs.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_probs_positive = y_probs[:,1]\ny_probs_positive[:7]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, y_probs_positive)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to plot ROC curve\nimport matplotlib.pyplot as plt\n\ndef plot_roc_curve(fpr, tpr):\n    \"\"\"\n    Plots a ROC curve given the false positive rate (frp)\n    and true positive rate (tpr) of a model\n    \"\"\"\n    # plot roc curve\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    # plot line with predictive power\n    plt.plot([[0, 0],\n              [1, 1]],\n             color='darkblue',\n             linestyle='--',\n             label='Guessing')\n    # Customize the plot\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    \n\n\nplot_roc_curve(fpr, tpr)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**\nA confusion matrix is a quick way to compute the labels a model\npredicts and the actual labels it was supposed to predict\n\nIn essence, giving you an idea of where the model is getting confused.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ny_preds = clf.predict(X_test)\n\nconfusion_matrix(y_test, y_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(clf, X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classification Report**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Where precision and recall become valuable\n\ndisease_true = np.zeros(10000)\ndisease_true[0] = 1  # only one positive case\n\ndisease_preds = np.zeros(10000)\n\npd.DataFrame(classification_report(disease_true,\n                                   disease_preds,\n                                   output_dict=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To summarize classification metrics\n* **Accuracy** is a good measure if all classes are balanaced (e.g. same amount of samples which are labeld 0 of 1)\n* **Precision** and **recall** become more important when classes are impbalanced\n* if false positive predictions are worse than false negatives, aim for higher precision\n* if false negative predictions are worse than false positives, aim for higher recall\n* **F1 Score** is a combination of precision and recall","metadata":{}},{"cell_type":"markdown","source":"### 4.2.2 Regression model evaluation metrics\nModel evaluation metrics documentation - https://scikit-learn.org/stable/modules/model_evaluation.html\n\n1 - R^2 or Coeficient of Determination.</br>\n2 - Mean Absolute Error (MAE)</br>\n3 - Mean Squared Error (MSE)\n\n**R^2**</br>\nCompares your model predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1.\nIf all the model does is predict the mean of the target, its R^2 value would be 0.\nIf the model perfectly predicts a range of numbers, its R^2 value would be 1.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\nX = boston_df.drop('target', axis=1)\n\ny = boston_df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nmodel = RandomForestRegressor().fit(X_train, y_train)\n\nmodel.score(X_test, y_test)  # Default Metric is R^2 (the coeficient of determination)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nr2_score(y_test, np.random.randint(0, 9, size=(len(y_test), 1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Absolute Error**</br>\nis the average of the absolute differences between predictions and actual values.\nIt gives you an idea of how wrong your model's predictions are.","metadata":{}},{"cell_type":"code","source":"# Mean Absolute Error\nfrom sklearn.metrics import mean_absolute_error\n\ny_preds = model.predict(X_test)\n\nmae = mean_absolute_error(y_test, y_preds)\nmae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Squared Error**</br>\n","metadata":{}},{"cell_type":"code","source":"# Mean Squaed Error\nfrom sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(y_test, y_preds)\nmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.3 Finally using the `scoring` parameter","metadata":{}},{"cell_type":"markdown","source":"#### 4.2.3.1 Classifier model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\nclf = RandomForestClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accuracy**","metadata":{}},{"cell_type":"code","source":"cv_acc = cross_val_score(clf, X, y, cv=5)\ncv_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average cross validated accuracy (accuracy is the default metric for scoring randomforestclassifier)\nprint(f\"The average cross validated accuracy is {np.mean(cv_acc)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Precision**","metadata":{}},{"cell_type":"code","source":"cv_precision = cross_val_score(clf, X, y, cv=5, scoring='precision')\ncv_precision","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average cross validated precision\nprint(f\"The average cross validated precision is {np.mean(cv_precision)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Recall**","metadata":{}},{"cell_type":"code","source":"cv_recall = cross_val_score(clf, X, y, cv=5, scoring='recall')\ncv_recall","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The average cross validated cross recall is {np.mean(cv_recall)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**F1**","metadata":{}},{"cell_type":"code","source":"cv_f1 = cross_val_score(clf, X, y, cv=5, scoring='f1')\ncv_f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The average cross validated cross f1 is {np.mean(cv_f1)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.2.3.2 Regression model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\nX = boston_df.drop('target', axis=1)\ny = boston_df['target']\n\nmodel = RandomForestRegressor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**R^2**","metadata":{}},{"cell_type":"code","source":"cv_r2 = cross_val_score(model, X, y, cv=5, scoring=None)  # with None, score default that is R^2 is used\n\ncv_r2, np.mean(cv_r2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Absolute Error**","metadata":{}},{"cell_type":"code","source":"cv_mae = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')  # neg because the convention is higher is better\n\ncv_mae, np.mean(cv_mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mean Squared Error**","metadata":{}},{"cell_type":"code","source":"cv_mse = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\ncv_mse, np.mean(cv_mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Improving a model\nFirst Predictions = Baseline Predictions</br>\nFirst Model = Base Model\n\nFrom a data perspective:</br>\n* Could we collect more data? (generally, the more data, the better)\n* Could we improve our data?\n\nFrom a model perspective\n* Is there a better model we could use\n* Could we improve the current model by tuning hyperparameters","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Three ways to adjust hyperparameters**\n1. By hand \n2. Randomly with RandomSearchCV\n3. Exhaustively with GridSearchCV","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Turning hyperparameters by hand\nDivide the data into train, validation, and test sets\n\nWe are going to try and adjust:\n\n* `max_depth`\n* `max_features`\n* `min_samples_leaf`\n* `min_samples_split`\n* `n_estimators`","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\ndef evaluate_preds(y_true, y_preds):\n    \"\"\"\n    performs evaluation comparison on y_true labels vs. y_pred labels\n    on a classification model\n    \"\"\"\n    accuracy = accuracy_score(y_true, y_preds)\n    precision = precision_score(y_true, y_preds)\n    recall = recall_score(y_true, y_preds)\n    f1 = f1_score(y_true, y_preds)\n    metrics_dic = {'accuracy': round(accuracy, 2),\n                   'precision': round(precision, 2),\n                   'recall': round(recall, 2),\n                   'f1': round(f1, 2)\n                  }\n    \n    return metrics_dic\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2 Hyperparameter Tuning with RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\ngrid = {'n_estimators': [10, 100, 200, 1000, 5000, 10000],\n        'max_depth': [None, 5, 10, 20, 30],\n        'max_features': ['auto', 'sqrt'],\n        'min_samples_split': [2, 4, 6],\n        'min_samples_leaf': [1, 2, 4]}\n\nnp.random.seed(42)\n\n# Split into X, y\nheart_disease_shuffled = heart_disease.sample(frac=1)\nX = heart_disease_shuffled.drop('target', axis=1)\ny = heart_disease_shuffled['target']\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Instantiate a RandomForestClassifier\nclf = RandomForestClassifier()\n\n# Setup RandomizedSearchCV\nrs_clf = RandomizedSearchCV(estimator=clf,\n                            param_distributions=grid,\n                            n_iter=3,  # number of models to try\n                            cv=5,\n                            verbose=2\n                           )\n\n# Fit the RandomizedSearchCV version of clf\nrs_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_clf.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions with the best hyperparameters\nrs_y_preds = rs_clf.predict(X_test)\n\n# Evaluate the predictions\nrs_metrics = evaluate_preds(y_test, rs_y_preds)\nrs_metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 Hyperparameter tuning with GridSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ngrid_2 = {'n_estimators': [100],\n        'max_depth': [5, 10],\n        'max_features': ['auto'],\n        'min_samples_split': [2],\n        'min_samples_leaf': [2, 4]}\n\nnp.random.seed(42)\n\n# Split into X, y\nheart_disease_shuffled = heart_disease.sample(frac=1)\nX = heart_disease_shuffled.drop('target', axis=1)\ny = heart_disease_shuffled['target']\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Instantiate a RandomForestClassifier\nclf = RandomForestClassifier()\n\n# Setup RandomizedSearchCV\ngs_clf = GridSearchCV(estimator=clf,\n                            param_grid=grid_2,\n                            cv=5,\n                            verbose=2\n                           )\n\n# Fit the RandomizedSearchCV version of clf\n\ngs_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_clf.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_y_preds = gs_clf.predict(X_test)\n\n# Evbaluate the predictions\ngs_metrics = evaluate_preds(y_test, gs_y_preds)\ngs_metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Saving and loading trained machine learning models\nTo ways to save and load machine learning models</br>\n1. With python's `pickle` module\n2. With the `joblib` module","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Pickle**","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# save an existing model to file\npickle.dump(gs_clf, open('gs_random_forest_model_1.pkl', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load a saved model\nloaded_pickle_model = pickle.load(open('gs_random_forest_model_1.pkl', 'rb'))\n\n# Make some predictions\nloaded_pickle_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**joblib**","metadata":{}},{"cell_type":"code","source":"from joblib import dump, load\n\n# Save model to file\ndump(gs_clf, filename='gs_random_forest_model_1.joblib')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import a saved joblib model\nloaded_joblib_model = load(filename='gs_random_forest_model_1.joblib')\n\n# Make some predictions\nloaded_joblib_model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**If the model is large, in case of scikit-learn, it is more efficient to use joblib than to use pickle**","metadata":{}},{"cell_type":"markdown","source":"## 7. Putting it all together!","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended-missing-data.csv')\ndata.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"STEPS:\n   1. Fill the missing data\n   2. Convert data to number\n   3. Build a model on the data\n   \n<a href='https://colab.research.google.com/drive/1AX3Llawt0zdjtOxaYuTZX69dhxwinFDi?usp=sharing#scrollTo=KTyDN_BOb0Al'>source</a>","metadata":{}},{"cell_type":"code","source":"# Getting data ready\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Modeling\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\n# Setup random seed\nimport numpy as np\nnp.random.seed(42)\n\n# import data and drop rows with missing labels\ndata = pd.read_csv('https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended-missing-data.csv')\ndata.dropna(subset=['Price'], inplace=True)\n\n\n# Define different features and transformer pipeline\n\n# Define categorical columns\ncategorical_features = [\"Make\", \"Colour\"]\n# Create categorical transformer (imputes missing values, then one hot encodes them)\ncategorical_transformer = Pipeline(steps=[\n  ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n  ('onehot', OneHotEncoder(handle_unknown='ignore'))                                         \n])\n\n# Define door feature\ndoor_feature = [\"Doors\"]\n# Create door transformer (fills all door missing values with 4)\ndoor_transformer = Pipeline(steps=[\n  ('imputer', SimpleImputer(strategy='constant', fill_value=4)),\n])\n\n# Define numeric features\nnumeric_features = [\"Odometer (KM)\"]\n# Create a transformer for filling all missing numeric values with the mean\nnumeric_transformer = Pipeline(steps=[\n  ('imputer', SimpleImputer(strategy='mean'))  \n])\n\n# Setup preprocessing steps (Fill missing values, then convert to numbers)\n# Create a column transformer which combines all of the other transformers \n# into one step\npreprocessor = ColumnTransformer(\n    transformers=[\n      # (name, transformer_to_use, features_to_use transform)\n      ('categorical', categorical_transformer, categorical_features),\n      ('door', door_transformer, door_feature),\n      ('numerical', numeric_transformer, numeric_features)\n])\n\n# Create a preprocessing and modeling pipeline\n# Create the preprocessing and modelling pipeline\nmodel = Pipeline(steps=[('preprocessor', preprocessor), # this will fill our missing data and make sure it's all numbers\n                        ('model', RandomForestRegressor())]) # this will model our data\n\n# Split data\nX = data.drop('Price', axis=1)\ny = data['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Fit and score the model\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Use `GridSearchCV` or `RandomizedSearchCV` with pipeline**","metadata":{}},{"cell_type":"code","source":"# Use GridSearchCV with our pipeline\npipe_grid = {\n    \"preprocessor__numerical__imputer__strategy\": ['mean', 'median'],\n    \"model__n_estimators\": [100],\n    \"model__max_depth\": [None, 5],\n    \"model__max_features\": ['auto'],\n    \"model__min_samples_split\": [2]\n}\n\ngs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=1)\ngs_model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_model.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Practice:\nhttps://github.com/mrdbourke/zero-to-mastery-ml/blob/master/section-2-data-science-and-ml-tools/scikit-learn-exercises.ipynb","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}