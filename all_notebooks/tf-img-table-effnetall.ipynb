{"cells":[{"metadata":{"id":"OXdYLVgzqHlD","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nimport pandas as pd\nimport tensorflow as tf\n!pip install efficientnet\nfrom efficientnet import tfkeras as efn\n#from skimage.color import rgb2hsv\nimport gc\n#import cv2\nsize = (224,224)\nbatch_size = 4\nfrom PIL import Image\n# os.environ['KAGGLE_USERNAME'] = \"kunduruanil\" # username from the json file\n# os.environ['KAGGLE_KEY'] = \"8aeec45db3771cf1b773905fcc521e6e\" # key from the json file\n# !kaggle datasets download -d cdeotte/jpeg-melanoma-256x256 # api copied from kaggle\n# os.listdir(os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"id":"aVLtB7eAtjHS","trusted":true},"cell_type":"code","source":"# !unzip \"jpeg-melanoma-256x256.zip\"\n# base = os.getcwd()\n# os.listdir(base)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = \"../input/jpeg-melanoma-256x256/\"\nos.listdir(base)","execution_count":null,"outputs":[]},{"metadata":{"id":"_9wCZ8zMudTt","trusted":true},"cell_type":"code","source":"train = pd.read_csv(base + \"/train.csv\")\nprint(train.shape)\ntrain['sex']=train['sex'].replace({\"male\":1,\"female\":0})\ntrain['age_approx']=train['age_approx'].fillna(train['age_approx'].mean())\ntrain['anatom_site_general_challenge']=train['anatom_site_general_challenge'].fillna(train['anatom_site_general_challenge'].mode())\ns = train['anatom_site_general_challenge'].value_counts()/train.shape[0]\ntrain['anatom_site_general_challenge'] = train['anatom_site_general_challenge'].replace(s.to_dict())\n#td = train[['sex',\"age_approx\",\"anatom_site_general_challenge\"]]\ndel s\ngc.collect()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Hizr-wg0uxzx","trusted":true},"cell_type":"code","source":"df_0 = train[train['target']==1].sample(84,random_state=42)\ndf_1 = train[train['target']==0].sample(10000,random_state=42)\ntrain = train.drop(df_0.index)\ntrain = train.drop(df_1.index)\nval=pd.concat([df_0,df_1])\nval=val.reset_index()\nprint(val.shape)\ntd_val = val[['sex',\"age_approx\",\"anatom_site_general_challenge\"]]\nval_filenames = base + \"/train/\" + val[\"image_name\"] +\".jpg\"\nval_labels = val['target']\ntd_val.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"cu0xJ_mjuzLZ","trusted":true},"cell_type":"code","source":"df_0=train[train['target']==0].sample(15000,random_state=42)\ndf_1=train[train['target']==1]\ntrain=pd.concat([df_0,df_1])\ntrain=train.reset_index()\nprint(train.shape)\ntrain_filenames = base + \"/train/\" + train[\"image_name\"] +\".jpg\"\nlabels = train['target']\ntd_train = train[['sex',\"age_approx\",\"anatom_site_general_challenge\"]]\nprint(td_train.shape)\ndel train,val\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"4gOSPY_NZ9z1","trusted":true},"cell_type":"code","source":"val = pd.concat([val_filenames,val_labels ], axis=1)\ntrain = pd.concat([train_filenames,labels ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"DTXC0aP5akGR","trusted":true},"cell_type":"code","source":"class Mygenarator(tf.keras.utils.Sequence):\n    \n    def __init__(self,df,td,x_col,y_col=None,batch_size=2,num_classes=None,size=(224,224,3),shuffle=True):\n        self.df = df\n        self.td = td\n        self.x_col = x_col\n        self.y_col = y_col\n        self.size = size\n        self.indices = df.index.tolist()\n        self.batch_size = batch_size\n        self.num_classes = num_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        \n    def on_epoch_end(self):\n        self.index = np.arange(len(self.indices))\n        if self.shuffle == True:\n            np.random.shuffle(self.index)\n            \n    def __len__(self):\n     # Denotes the number of batches per epoch\n        return len(self.indices) // self.batch_size\n    \n    \n    def __getitem__(self, index):\n        # Generate one batch of data\n        # Generate indices of the batch\n        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n        # Find list of IDs\n        batch = [self.indices[k] for k in index]\n        # Generate data\n        X, y = self.__get_data(batch)\n        return X, y\n    \n    def __get_data(self, batch):\n        # X.shape : (batch_size, *dim)\n        # We can have multiple Xs and can return them as a list\n        X1 = np.empty((self.batch_size,*self.size))\n        X2 = np.empty((self.batch_size,3))\n        y = np.empty((self.batch_size), dtype=int)\n        # Generate data\n        for i, id in enumerate(batch):\n         # Store sample\n            X1[i,] = self.read_img(self.df.loc[id,self.x_col])\n            X2[i,] = self.td.loc[id,:].values\n            y[i] = self.df.loc[id,self.y_col]\n            \n        return {\"imgIn\":X1,\"tabIn\":X2}, y\n    \n    def hair_removal(self,image):\n      grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n      # kernel for morphologyEx\n      kernel = cv2.getStructuringElement(1,(17,17))\n      # apply MORPH_BLACKHAT to grayScale image\n      blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n      # apply thresholding to blackhat\n      _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n\n      # inpaint with original image and threshold image\n      final_image = cv2.inpaint(image,threshold,1,cv2.INPAINT_TELEA)\n      final_image = cv2.cvtColor(final_image,cv2.COLOR_BGR2RGB)\n      return final_image\n\n    def read_img(self,file):\n      #image = cv2.imread(file)\n      #image = cv2.resize(image,self.size[:-1])\n      im = np.array(Image.open(file).resize(size))/255.0\n      #return self.hair_removal(image)\n      return im","execution_count":null,"outputs":[]},{"metadata":{"id":"n0po2YtOaovx","trusted":true},"cell_type":"code","source":"val_data = Mygenarator(df=val,td=td_val,x_col=\"image_name\",y_col=\"target\")\ntrain_data = Mygenarator(df=train,td=td_train,x_col=\"image_name\",y_col=\"target\")","execution_count":null,"outputs":[]},{"metadata":{"id":"DNiMNXfau81k","trusted":false},"cell_type":"code","source":"# dataset = tf.data.Dataset.from_tensor_slices((train_filenames, labels))\n# def _parse_function(filename, label):\n#     img = tf.io.read_file(filename)\n#     img = tf.image.decode_jpeg(img, channels=3)\n#     img = tf.image.resize(img, [*size])\n#     img = tf.image.per_image_standardization(img)\n#     img = tf.image.convert_image_dtype(img, tf.float32)\n#     return img, label\n# AUTOTUNE=tf.data.experimental.AUTOTUNE\n# dataset = dataset.map(_parse_function,num_parallel_calls=AUTOTUNE)\n# dataset = dataset.shuffle(buffer_size=10000,reshuffle_each_iteration=True)\n# dataset = dataset.batch(batch_size)\n# dataset = dataset.cache()","execution_count":null,"outputs":[]},{"metadata":{"id":"ZbJqMrWUxo0W","trusted":false},"cell_type":"code","source":"# val_data = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n# val_data = val_data.map(_parse_function,num_parallel_calls=AUTOTUNE)\n# val_data = val_data.shuffle(buffer_size=10000,reshuffle_each_iteration=True)\n# val_data = val_data.batch(batch_size)\n# val_data = val_data.cache()","execution_count":null,"outputs":[]},{"metadata":{"id":"Ejix7haJxE8K","trusted":true},"cell_type":"code","source":"class LossAndaucPrintingCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n      msg = \"\\n\"\n      for k,v in logs.items():\n        msg = msg + \" \" + str(k) + \" : \" + str(round(v,3))\n      print(msg)","execution_count":null,"outputs":[]},{"metadata":{"id":"O12DTO6qxuuu","trusted":true},"cell_type":"code","source":"def get_model():\n    model_input = tf.keras.Input(shape=(*size, 3), name='imgIn')\n    tab_input = tf.keras.Input(shape=(3,),name=\"tabIn\")\n    dummy = tf.keras.layers.Lambda(lambda x:x)(model_input)\n    outputs = []    \n    for i in range(8):\n        constructor = getattr(efn, f'EfficientNetB{i}')\n \n        x = constructor(include_top=False, weights='imagenet', \n                        input_shape=(*size, 3), \n                        pooling='avg')(dummy)\n        y = tf.keras.layers.Dense(100)(tab_input)\n        y = tf.keras.layers.BatchNormalization()(y)\n        y = tf.keras.layers.Activation(\"relu\")(y)\n        y = tf.keras.layers.Dropout(0.4)(y)\n        y = tf.keras.layers.Dense(100)(y)\n        y = tf.keras.layers.BatchNormalization()(y)\n        y = tf.keras.layers.Activation(\"relu\")(y)\n        y = tf.keras.layers.Dropout(0.4)(y)\n        concatenated = tf.keras.layers.concatenate([x, y], axis=-1)\n        con =  tf.keras.layers.Dense(100, activation='relu')(concatenated)\n        con = tf.keras.layers.BatchNormalization()(con)\n        con = tf.keras.layers.Activation(\"relu\")(con)\n        con = tf.keras.layers.Dropout(0.4)(con)\n        output = tf.keras.layers.Dense(1,name=f'Effnet{i}')(con)\n        output = tf.keras.layers.Activation(\"sigmoid\")(output)\n        outputs.append(output)\n \n    model = tf.keras.Model([model_input,tab_input], outputs, name='aNetwork')\n    model.compile(optimizer='adam',loss = tf.keras.losses.BinaryCrossentropy(\n    label_smoothing = 0.05),metrics=[tf.keras.metrics.Accuracy(),tf.keras.metrics.AUC(name='auc')])\n    #tf.keras.metrics.AUC(name='auc')\n    return model\nmodel = get_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"KBD8QSv_27Fr","trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"id":"AxXSI0KqdcVg","trusted":false},"cell_type":"code","source":"#model.load_weights(save_path)","execution_count":null,"outputs":[]},{"metadata":{"id":"3R2kPGlDyUmA","trusted":true},"cell_type":"code","source":"model.fit(train_data,epochs=1,validation_data=val_data, \n          callbacks=[tf.keras.callbacks.ModelCheckpoint(os.path.join(os.getcwd(),\"effall\"),   \n                                                       save_weights_only=True), \n              tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3),LossAndaucPrintingCallback()])","execution_count":null,"outputs":[]},{"metadata":{"id":"83F2xVmJ-wMl","trusted":false},"cell_type":"code","source":"test = pd.read_csv(base+\"/test.csv\")\ntest_files =  base + \"/test/\" + test[\"image_name\"] +\".jpg\"","execution_count":null,"outputs":[]},{"metadata":{"id":"5oviAws4-1YK","trusted":false},"cell_type":"code","source":"test_files[:-2].shape","execution_count":null,"outputs":[]},{"metadata":{"id":"S8PydH9Ex8dN","trusted":false},"cell_type":"code","source":"testset = tf.data.Dataset.from_tensor_slices((test_files))\nAUTOTUNE=tf.data.experimental.AUTOTUNE\ndef _parse(filename):\n    img = tf.io.read_file(filename)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [*size])\n    img = tf.image.per_image_standardization(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    return img\ntestset = testset.map(_parse,num_parallel_calls=AUTOTUNE)\ntestset = testset.batch(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"J-UsDp04yXdl","trusted":false},"cell_type":"code","source":"pred = np.array([])\npred1 = np.array([])\nfor d in testset:\n  a = np.array([i.reshape(-1,) for i in model.predict(d)])>=0.5\n  pred1 = np.concatenate((pred,[1.0 if i>=4 else 0.0 for i in a.sum(axis=0)]),axis=None)\n  pred = np.concatenate((pred,np.array([i.reshape(-1,) for i in model.predict(d)]).mean(axis=0)),axis=None)\npred.shape,pred1.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"tddJm_yrcd8m","trusted":false},"cell_type":"code","source":"test['target']=pred1\ntest[['image_name',\"target\"]].to_csv(drive_path+\"/subeffv1.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ao3kfKGPyabx","trusted":false},"cell_type":"code","source":"test['target']=pred\ntest[['image_name',\"target\"]].to_csv(drive_path+\"/subeffv2.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"PZZVeJYBMIP1","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}