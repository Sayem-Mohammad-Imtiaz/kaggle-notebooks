{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In this project, I had finished some EDA process,and Utilized four predictive models( logistic regression, Support vector machine, random forest and neural network) and evaluate."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn=pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.columns.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"# check type and null value "},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change totalcharges's type(object) to float64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn['TotalCharges']=pd.to_numeric(churn['TotalCharges'],errors = 'coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete the first column (customerID)\nchurn.head()\nchurn_d=churn.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transfrom yes,no to 1,0\nchurn_d['Churn'].replace(to_replace='Yes',value=1,inplace=True) \nchurn_d['Churn'].replace(to_replace='No',value=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get_dummy \nchurn_dum= pd.get_dummies(churn_d)\nchurn_dum.columns.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of our target value : churn "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Churn\",data=churn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the result, the dataset is imbalance, which would make our accuracy measurement untenable, when \nwe evaluate the model, we prefer to use recall or f1 to judge."},{"metadata":{},"cell_type":"markdown","source":"# Correlation Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8)) \nchurn_corr = churn_dum.corr()['Churn'].sort_values(ascending=False).plot(kind='bar', \n                                                                         title ='Correlation between Churn & variables'\n                                                                        )\nchurn_corr.set_xlabel('category',fontsize=20) \nchurn_corr.set_ylabel('correlation',fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8), dpi= 80) \nsns.heatmap(churn.corr(), xticklabels=churn.corr().columns, \n            yticklabels=churn.corr().columns, cmap='RdYlGn', center=0, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 3 positive correlated variables : contract month_to_month, online_security_No, tech_support_No, \nTop 3 negative correlated variables:  tenure, contract_2_year, internet_servive_no, streaming_service_NO \n\nSome interetsing things:\n\n1.contract_month_to_month and contract_2year have totally diﬀerent inﬂuences.\n\n2.monthly charge and total_charge have opposite eﬀects on churn\n\n3.total_charge and tenure has strong relationship (0.83)\n\n4.absence of online security and tech support seem to be positively correlated with churn\n\n5.customer with no internet service are less likely to churn. \n\n6.difference among payment methods.\n\n..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# more exploration ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Churn & Contract"},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in churn['Contract'].unique():\n    print(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contract_types = (churn['Contract'].value_counts(normalize=True) * 100).keys().tolist() \ncontract_propotion = (churn['Contract'].value_counts(normalize=True) * 100).values.tolist()\nfor i in range(3):\n    contract_propotion[i]=round(contract_propotion[i],2)\ntext= ['{} %'.format(x) for x in contract_propotion]\nprint(contract_types)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the result shows that majority of cutsomers have month_month contract(55.11%)\nThen visualize the churn rate for different groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"month_to_month =churn.loc[churn['Contract']=='Month-to-month'] \nm2m = int(round((month_to_month['Churn'].value_counts(normalize=True) * 100)['Yes']))\none_year =churn.loc[churn['Contract']=='One year'] \noney = int(round((one_year['Churn'].value_counts(normalize=True) * 100)['Yes']))\ntwo_year =churn.loc[churn['Contract']=='Two year'] \ntwoy = int(round((two_year['Churn'].value_counts(normalize=True) * 100)['Yes']))\nchurn_rate = [m2m, oney, twoy] \nretention_rate = [100 - m2m, 100 - oney, 100 - twoy]\nprint(contract_types,'\\n',contract_propotion,'\\n',churn_rate,'\\n',retention_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visulize the result above \n\nplt.figure(figsize=(8,6)) \nchurn_label=['{} %'.format(x) for x in churn_rate] \nretention_label=['{} %'.format(x) for x in retention_rate]\np1=plt.bar(contract_types,churn_rate,color='yellow', hatch=\"*\") \np2=plt.bar(contract_types, retention_rate,bottom=churn_rate,color='#FFE4C4')\nplt.ylim(0,100) \nplt.ylabel('churn and retention rate') \nplt.xlabel('contract type')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the area of yellow with star represents churn rate. According to the bar chart, people with month to month contract are much easier to churn.\nM2M > 2 year > 1 year"},{"metadata":{},"cell_type":"markdown","source":"# Churn & Charge & Contract"},{"metadata":{},"cell_type":"markdown","source":"install plotly from terminal\n\n****pip install plotly\n\nhttps://plot.ly/python/plotly-express/"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px \nfig = px.histogram(churn, x=\"Churn\", y=\"MonthlyCharges\", color='Churn', facet_col=\"Contract\", histfunc='avg')\nfig.update_layout(title_text='Average Monthly Cost by Contract Type')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"nomatter which type of contract customer chooses, increasing average monthly charges, much easier to churn, "},{"metadata":{},"cell_type":"markdown","source":"# Churn & Tenure & Contract"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tenure: Number of months the customer has stayed with the company\nchurn[\"tenure\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, a1=plt.subplots(nrows=1,ncols=1,sharey=True,figsize=(8,4))\nfor type in contract_types:\n    for ai in [a1]:\n        for title in ['M-to-M','One-year','Two-year']:\n            a=sns.distplot(churn[churn['Contract']==type]['tenure'],ax=ai)\n            a.set_xlabel('Tenure_month')\n            a.set_ylabel('proportion of customer') \n            a.set_title('Churn & Tenure')\nfig.legend(labels=['M-to-M','one-year','two-year'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"for people who only has a monthly contract tend to has a shorter tenure and longer in a two year contract,\n\nlonger time, more loyal, \n\nso we might need to adjust some strategies for the short contract with conditions and terms."},{"metadata":{},"cell_type":"markdown","source":"# Churn & Service "},{"metadata":{"trusted":true},"cell_type":"code","source":"# build a list of service including all...\n\nservice=['PhoneService','MultipleLines','InternetService','OnlineSecurity', \n         'OnlineBackup','DeviceProtection', 'TechSupport','StreamingTV','StreamingMovies']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(nrows=3,ncols=3,figsize=(12,10)) \n\nfor i,item in enumerate(service):\n    if i <3:\n        ax=churn[item].value_counts().plot(kind='bar',ax=axes[i,0]) \n    if i >= 3 and i < 6:\n        ax=churn[item].value_counts().plot(kind='bar',ax=axes[i-3,1]) \n    if i>=6:\n        ax=churn[item].value_counts().plot(kind='bar',ax=axes[i-6,2]) \n    ax.set_title(item)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from all the figures above (except phone service)\nabsence of online security and tech support ... and etc. seem to be abviously positively correlated with churn. \nthat when this service == 'Yes', they are less likely to churn \n\ndata visualization results are accord with the result (1,2,3,4) of correlation analysis, \nAfter EDA, I would build some classification model and evaluate.\n\n(Logistic model, random forest, support vector machine, neural netwrok)"},{"metadata":{},"cell_type":"markdown","source":"# logistic model "},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_dum.head() # get_dummy before","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# choose variables \nx=churn_dum.drop(columns=['Churn']) \ny=churn_dum['Churn'] \n#normalization \nfrom sklearn.preprocessing import MinMaxScaler \nfeatures=x.columns.values \nscaler=MinMaxScaler(feature_range=(0,1)) \nscaler.fit(x) \nx=pd.DataFrame(scaler.transform(x)) \nx.columns=features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression \nmodel=LogisticRegression() \nresult=model.fit(x_train,y_train)\n\nfrom sklearn import metrics\nlg_pred=model.predict(x_test)\nprint(metrics.accuracy_score(y_test,lg_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report \nlg_report= classification_report(y_test, lg_pred) \nprint(lg_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=101) \nmodel_r=RandomForestClassifier(n_estimators=100,random_state=50, oob_score=True) \nmodel_r.fit(x_train,y_train) \nrf_pred=model_r.predict(x_test)\nprint(metrics.accuracy_score(y_test,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_report=classification_report(y_test, rf_pred)\nprint(rf_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I would explore and find the most appropiate tree numbers (n_estomators)"},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_score =[] \nfor i in range(1,102):\n    i_loop= RandomForestClassifier(n_estimators=i, random_state=101) \n    i_loop.fit(x_train,y_train) \n    loop_pre=i_loop.predict(x_test) \n    rand_score.append(metrics.accuracy_score(y_test,loop_pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,102),rand_score)\nplt.xlabel(\"Range\") \nplt.ylabel(\"accuracy score\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 79 trees around"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_r=RandomForestClassifier(n_estimators=79,random_state=101, oob_score=True)\nmodel_r.fit(x_train,y_train) \nrf_new_pred=model_r.predict(x_test)\nprint(metrics.accuracy_score(y_test,rf_new_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only a little bit improvement ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_new_report=classification_report(y_test, rf_new_pred)\nprint(rf_new_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_coef=model_r.feature_importances_ \nweight=pd.Series(rand_coef,index=x.columns.values)\nweight.sort_values(ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"same: TOTAL charges, tenure and monthlycharges, contract .. are highly possive related with churn result \n\nseems no change for recall and f1 LOL"},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_model = SVC(random_state=101)\nsvc_model.fit(x_train, y_train) \naccuracy_svc = svc_model.score(x_test, y_test)\nprint(accuracy_svc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_pred=svc_model.predict(x_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nsvm_report=classification_report(y_test,svm_pred) \nprint(svm_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head() # has been standardalized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential \nfrom keras.layers import Dense \nfrom keras import optimizers \nmodel_nn = Sequential() \nsgd= optimizers.SGD(lr=0.01) # (set learning rate)\n# first time, no gradient descend, so might be the reason learning rate is too fast, thus...set it as 0.01","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nn.add(Dense(45, activation= 'relu', input_dim=45)) \nmodel_nn.add(Dense(22, activation='relu'))\nmodel_nn.add(Dense(11, activation='relu')) \nmodel_nn.add(Dense(6, activation='relu')) \nmodel_nn.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nn.compile(loss='binary_crossentropy',optimizer='SGD',metrics=['accuracy']) \nhistory= model_nn.fit(x_train, y_train,\n                      batch_size=30, epochs=50, validation_data=(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_1=model_nn.evaluate(x_test,y_test)\nresult_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict=history.history\nhistory_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_value=history_dict['loss'] \nval_loss_values= history_dict['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.clf() \nepochs=range(1,len(loss_value)+1)\nplt.plot(epochs,loss_value,'bo',label='Training loss') \nplt.plot(epochs,val_loss_values,'b',label='Validation loss') \nplt.title('Training and validation loss') \nplt.xlabel('Epochs') \nplt.ylabel('loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Accroding to the graph, it is reasonable to use epochs=50 where has the least loss ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_pred = model_nn.predict(x_test)\nnn_pred[1:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def threshold(nn_pred):\n    lst_threshold=[] \n    for i in nn_pred:\n        if i >=0.5:\n            i=1 \n            lst_threshold.append(i)\n        else: \n            i=0 \n            lst_threshold.append(i)\n    return lst_threshold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nfor report precision, recall and f1,\nClassification metrics can't handle a mix of binary and continuous targets !!!!\n\nbuild threshold rule for neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_pred_new = threshold(nn_pred) \nnn_pred_new[1:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_report=classification_report(y_test,nn_pred_new)\nprint(nn_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n--------------------Logistic Regression-----------------\\n',lg_report, \n      '\\n----------------------Random Forest---------------------\\n',rf_report, \n      '\\n----------------- Support Vector Machine----------------\\n',svm_report, \n      '\\n---------------------Neural Network---------------------\\n',nn_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"in the view of accuracy: **Neural network(0.8109)> SVM (0.8085) > logistic regression (0.8076)>random forest(0.7981)**\nIn fact, i think the four models are all good predictor (over 0.8). however,because the **data is imbalanced!**, i prefer \nto compare the  recall and f1-score rather than accuracy!!\n\nbesides, the **precision is more important than recall in this customer churn prediction project, **\nfor we take more care on dicovering the targeted customers precisely and make eﬀective strategies.( precision: P=TP/(TP+FP) )\nand classifing loyal customers into churn group would not make any loss.\n\nThus, logistic regression and support vector machine, neural network are a little bit better. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}