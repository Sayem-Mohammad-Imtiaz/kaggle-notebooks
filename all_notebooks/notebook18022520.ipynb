{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport string\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url='../input/data-scientist-jobs/DataScientist.csv'\ndata = pd.read_csv(url, encoding=\"utf-8\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data['Rating'].dtypes\nprint(data.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop columns: index (1), Competitors (15), Easy Apply (16)\ndel data['index']\ndel data['Unnamed: 0']\ndel data['Competitors']\ndel data['Easy Apply']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max.columns\", None)\npd.set_option(\"max_colwidth\", 15)\npd.set_option(\"display.precision\",2)\nprint(data)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create two new columns Salary_Lo Salary_Hi, from Salary Estimate (4)\n#data['Salary Estimate'][2] # $111K-$181K (Glassdoor est.)\n\n# remove extra text\ndata['Salary Estimate'] = data['Salary Estimate'].str.split(' ').str[0] # all text after the space\ndata['Salary Estimate'] = data['Salary Estimate'].str.split('(').str[0] # in the case of no space\n\n# split on '-' into two columns\ndata[['Salary_Lo','Salary_Hi']] = data['Salary Estimate'].str.split('-', n=1, expand=True)\n\n# remove punctuation ($) and change the K into the 000 it represents\ndata['Salary_Lo'] = data['Salary_Lo'].str.replace('[{}]'.format(string.punctuation), '')\ndata['Salary_Hi'] = data['Salary_Hi'].str.replace('[{}]'.format(string.punctuation), '')\ndata['Salary_Lo'] = data['Salary_Lo'].str.replace('K',\"000\")\ndata['Salary_Hi'] = data['Salary_Hi'].str.replace('K',\"000\")\n\n# make the columns behave as int\ndata[\"Salary_Lo\"] = data['Salary_Lo'].astype('int')\ndata[\"Salary_Hi\"] = data['Salary_Hi'].astype('int')\n\n#data[['Salary Estimate','Salary_Lo','Salary_Hi']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Create two new columns City, State/Country, from Location (8)\ndata[['Location_City','Location_State_Country']] = data['Location'].str.split(',', n=1, expand=True)\n\n#data[['Location','Location_City','Location_State_Country']]\n\n#Create two new columns City, State/Country, from Headquarters (9) \ndata['Headquarters'] = data['Headquarters'].str.replace('-1','-1,-1') # take care of single values for two columns\ndata[['Headquarters_City','Headquarters_State_Country']] = data['Headquarters'].str.split(',', n=1, expand=True)\n\n#data[['Headquarters','Headquarters_City','Headquarters_State_Country']]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create two new columns Size_From, Size_To, from Size (10)\ndata['Size'] = data['Size'].str.replace('-1','-1 to -1') # take care of single values for two columns \ndata['Size'] = data['Size'].str.replace('Unknown','-1 to -1') # replace Unknown with '-1'\ndata['Size'] = data['Size'].str.replace(\"+\",\" to 20000\") # replace + sign with arbitrary figure\ndata['Size'] = data['Size'].str.split('+').str[0] # all text after the space\ndata[['Size_From','Size_To']] = data['Size'].str.split('to', n=1, expand=True)\ndata['Size_From'] = data['Size_From'].str.strip()\ndata['Size_To'] = data['Size_To'].str.strip()\n\ndata['Size_To'] = data['Size_To'].str.split(' ').str[0] # all text after the space\n\n# make the columns behave as int\ndata[\"Size_From\"] = data['Size_From'].astype('int')\ndata[\"Size_To\"] = data['Size_To'].astype('int')\ndata[['Size_From','Size_To']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalise ['Revenue'] \"Unknown / Non-Applicable\" and \"-1\"     TOTAL:  1392 \ndata['Revenue'] = data['Revenue'].str.replace('Unknown / Non-Applicable','-1') # replace Unknown with '-1'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean up company name\ndata['Company Name'] = data['Company Name'].str.split(\"\\n\").str[0] # all text after the \\n\n#data['Company Name'] = data['Company Name'].str.replace('MÃ©decins Sans FrontiÃ¨res','Médecins Sans Frontières')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Company Name']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testrow = 374\ndata['Size'][testrow]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Size_From'][testrow]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Size_To'][testrow]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove replaced columns\ndel data['Salary Estimate']\ndel data['Headquarters']\ndel data['Location']\ndel data['Size']\ndata.head","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max.columns\", 3)\npd.set_option(\"max_colwidth\", None)\npd.set_option(\"display.precision\", 2)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"industry_list = data['Industry'].unique().tolist()\nsector_list = data['Sector'].unique().tolist()\ncompany_list = data['Company Name'].unique().tolist()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(company_list)\n#company_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(sector_list),\" sectors, \",len(industry_list), \" industries and \", len(company_list), \" unique companies.\" )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv(r'data_scientists.csv')\n\n# Import a module to display a link to the file\nfrom IPython.display import FileLink\n# Import a module to delete the file\nimport os\n# Create a download function\ndef csv_download_link(data, csv_file_name, delete_prompt=True):\n    \"\"\"Display a download link to load a data frame as csv within a Jupyter notebook\n\n    Parameters\n    ----------\n    df : pandas data frame\n    csv_file_name : str\n    delete_prompt : bool\n    \"\"\"\n    data.to_csv(csv_file_name, index=False)\n    display(FileLink(csv_file_name))\n    if delete_prompt:\n        a = input('Press enter to delete the file after you have downloaded it.')\n        os.remove(csv_file_name)\n# Use the function to diplay a download link\ncsv_download_link(data, 'data_scientists.csv') # uncomment this line ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sets lower case \ndata['Job Description'] = data['Job Description'].str.lower()  \n\n# make a set of the job_skills \nskills_list = [\"java\",\"python\",\" c \",\"scala\",\"spark\",\"django\",\"golang\",\"pig\",\n               \"cloud\",\"azure\",\"aws\",\"ec2\",\"selenium\",\"nlp\",\"sas\",\n               \"sql\",\"hadoop\",\"mapreduce\",\"git\",\"matlab\",\"pandas\",\" r \",\n               \"amplitude\",\"big data\",\"tableau\",\"powerbi\",\"excel\",\n               \"tensorflow\",\"keras\",\"pytorch\",\"scrapy\",]\neducation_list = [\"phd\",\"master\",\"bachelor\",\"graduate\",\"md\",\n                  \"pharmd\",\"ba\",\"bs\",\"ma\",\"ms\"] # extra\ndb_list = [\"postgresql\",\"mysql\",\"mssql\",\"mongo\",\"nosql\"]\ntwo_word_skills = [\"neural network\",\"machine learning\", \"data mining\",\n                   \"map reduce\", \"business intelligence\", \"post doctoral\"]\nother_skills = [\"wire-framing\"]\njob_skills = set(skills_list)\njob_skills.update(education_list)\njob_skills.update(db_list)\n\n# total of occurances of two word skills in list\nfor idx, word in enumerate(two_word_skills):\n    info = data['Job Description'].str.contains(two_word_skills[idx]).sum()\n    print (idx, word, info)\n    \n\n# add the two word skill as a one word skill for the later set comparisons\n# uses list to replace instances of significant word with space in between\nfor idx, word in enumerate(two_word_skills):           \n    current_word = two_word_skills[idx]\n    data['Job Description'] = data['Job Description'].str.replace(current_word,current_word.replace(\" \",\"\"))\n    other_skills.append(current_word.replace(\" \",\"\"))\njob_skills.update(other_skills)\n\n# create a list column that contains skill set\nwords = data['Job Description'].str.lower().str.findall(\"\\w+\")\n\nprint(job_skills)\n\ni=0\nfor x in words:\n    newset = x                                         # sets deal with unique values nicely \n    words[i] = list(job_skills.intersection(newset))   # add the words showing up in both sets presented\n    if len(words[i])==0:                               # catch an empty list passed to dataframe\n        item = 'no skill noted'\n        words[i].append(item)\n    i = i+1  # increment row number\n    \n#type(x) #debug\n\ndata['Job Skills'] = words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"There are \", sum('no skill noted' in s for s in data['Job Skills']), \" job postings with no discernable skills!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print column\ndata['Job Skills']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#verify that a particular row has the correct details\nrow_number = 3872\nrow_number = row_number - 2\nprint(data['Job Skills'][row_number] , data['Job Description'][row_number])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the two word list has been taken care of - this is just for debugging and that it is to demonstrate to the marker\nfor idx, word in enumerate(two_word_skills):\n    info = data['Job Description'].str.contains(two_word_skills[idx]).sum()\n    print (idx, word, info)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"states = data['Location_State_Country'].unique().tolist()\ncity = data['Location_City'].unique().tolist()\nstates[8] = \"UK\"\nstate_set = set(states) \ncity_set = set(city) \nprint(\"There are \", (len(city_set)) ,\" unique cities and \", (len(state_set)) , \" unique states.\")\nstates[8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using a pandas plot\nlow_salary = data.groupby('Location_State_Country')['Salary_Hi'].plot.hist(bins=11) \nhigh_salary = data.groupby('Location_State_Country')['Salary_Lo'].plot.hist(bins=11)\n\n# This is difficult to comprehend","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using a pandas plot\n\nlow_salary = data.groupby('Location_State_Country')['Salary_Hi'].mean().plot.hist(bins=11, stacked=True, histtype='stepfilled') \nhigh_salary = data.groupby('Location_State_Country')['Salary_Lo'].mean().plot.hist(bins=11, stacked=True, histtype='step')\n\n# This is also difficult to understand","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shows a comparison mean of all of the salaries in each unique state/country using matlab type plots\n\nlowest_salary =  data.groupby('Location_State_Country')['Salary_Lo']\nhighest_salary =  data.groupby('Location_State_Country')['Salary_Hi']\n\nplt.plot(states, lowest_salary.mean())\nplt.plot(states, highest_salary.mean())\n\nplt.title('Mean Highest and Lowest salary vs. state', fontsize=14)\nplt.xlabel('State', fontsize=14)\nplt.ylabel('Salary', fontsize=14)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shows average of all of the salaries in each unique state/country as bar plot using classes\n\nlowest_salary =  data.groupby('Location_State_Country')['Salary_Lo']\nhighest_salary =  data.groupby('Location_State_Country')['Salary_Hi']\nlabels = states\n\nx = np.arange(len(labels))  #\nwidth = 0.4\n\nfig, ax = plt.subplots()\nfig.set_figheight(6)\nfig.set_figwidth(18)\n\nrects1 = ax.bar(x - width/2, lowest_salary.mean(), width, label='Lowest Salary')\nrects2 = ax.bar(x + width/2, highest_salary.mean(), width, label='Highest Salary')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Salary')\nax.set_title('Mean Salary In Each State')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.set\nax.legend()\n\nax.bar_label(rects1, padding=3)\nax.bar_label(rects2, padding=3)\n\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"states\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shows average of all of the salaries in each unique state/country as bar plot using classes\n\nlowest_salary =  data.groupby('Location_State_Country')['Salary_Lo']\nhighest_salary =  data.groupby('Location_State_Country')['Salary_Hi']\nlabels = states\n\nx = np.arange(len(labels))  #\nwidth = 0.8\n\nfig, ax = plt.subplots()\nfig.set_figheight(6)\nfig.set_figwidth(10)\n\nrects1 = ax.bar(x , lowest_salary.count(), width, label='Number of Jobs')\n#rects2 = ax.bar(x + width/2, highest_salary.count(), width, label='Highest Salary')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Job number')\nax.set_title('Number of jobs In Each State')\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.set\nax.legend()\n\nax.bar_label(rects1, padding=3)\n#ax.bar_label(rects2, padding=3)\n\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a terrible one which doesnt anything\nplt.plot(data['Salary_Hi'], data['Size_To'])\nplt.title('Size of Company vs. Hi Salary', fontsize=14)\nplt.xlabel('Highest Salary', fontsize=14)\nplt.ylabel('Company Size', fontsize=14)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for a plot word cloud\ndef plot_cloud(wordcloud):\n    plt.figure(figsize=(20, 10))\n    plt.imshow(wordcloud) \n    plt.axis(\"off\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\ndata['Job Words'] = data['Job Skills'].apply(lambda x: ', '.join(x))\ndata['Job Words'] = data['Job Words'].str.replace(',', '')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = \"\"\nfor string in data['Job Words']:\n    addwords = str(string)\n    words = words + addwords\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# the word cloud package needs to be imported\nfrom wordcloud import WordCloud, STOPWORDS\n\nwordcloud = WordCloud(width = 1550, height = 1300, random_state=1, background_color='black', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(words)\nplot_cloud(wordcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['company_age'] = 2021 - data['Founded']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['company_age']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Average_Salary'] = ((data['Salary_Hi'] + data['Salary_Lo']) /2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Hi \", data['Salary_Hi'][4], \" Lo \", data['Salary_Lo'][4], \" Average: \", data['Average_Salary'][4])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nsns.regplot(x=\"company_age\", y=\"Average_Salary\", data=data);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.groupby('Job Title').agg({'Average_Salary':'mean'}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.groupby('Location_State_Country')['Average_Salary'].mean().sort_values().tail(15)\nx.plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}