{"cells":[{"metadata":{},"cell_type":"markdown","source":"### The goal of this notebook is to train a learning algorithm to classify COVID vs. non-COVID lung X-rays using fastai for PyTorch. It is an adaptation of [Lesson 1](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson1-pets.ipynb) in the fast.ai course.  ","execution_count":null},{"metadata":{"id":"Np_1ZCSsmlMV","trusted":true},"cell_type":"code","source":"#preamble\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"wtTDcVcQmlMi","outputId":"e0e1c966-e403-489d-a1d5-9954a32346bb","trusted":true},"cell_type":"code","source":"#load modules\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nimport os\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"id":"TMR_dGAVmlMt","trusted":true},"cell_type":"code","source":"#let's start with bs = 16\n bs = 16   ","execution_count":null,"outputs":[]},{"metadata":{"id":"5pr4mhOH5OpE","outputId":"7757de1f-35f3-4630-ef2c-315742a08089","trusted":true},"cell_type":"code","source":"#file paths\nprint('files in folder',os.listdir(\"../input/covid-chest-xray/\"))\npath=\"../input/covid-chest-xray/\"\npath_anno=path + 'annotations/'\npath_img=path + 'images/'\nprint('annotation directory:',path_anno,'\\nimage directory',path_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames=get_image_files(path_img)\nfnames[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Description\nBrowsing through the [COVID Chest Xray data preview on the Kaggle page](https://www.kaggle.com/bachrr/covid-chest-xray), I noticed there are coronal and axial scans in this dataset. \n\nSee: https://en.wikipedia.org/wiki/Anatomical_plane\n\nLet's just look at the coronal X ray images. \n\nFirst, we'll look at the metadata file to filter out the images we don't want. \nBy the end of this next few blocks, we'll have a list of only the image files of interest. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#explore the data and filter the images we want\nmetadf=pd.read_csv(path + 'metadata.csv' )\nprint(metadf.columns)\nmetadf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's see how many of each different type of scan we have \nmetadf.groupby(['modality','view']).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To give a consistent view to our machine learning algorithm, let's do just X-rays with a PA view.\n\nPA stands for back (Posterior) to front (Anterior) \n\nThis next cell gives us all the file names, which is what we set out to do with this data filtering step.\n\nAlso, let's get the labels associated with these xrays, and count up how many we have of each case.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xray_PA_fnames=path_img + metadf[(metadf.modality=='X-ray')&(metadf.view=='PA')].filename\nlabels=metadf[(metadf.modality=='X-ray')&(metadf.view=='PA')].finding\nmetadf[(metadf.modality=='X-ray')&(metadf.view=='PA')].groupby('finding').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The majority of images in this database are of COVID-19 patients. \n\nPlus, we can expect there could be an issue with distinguishing COVID-19 from Acute Respiratory Disease Syndrome (ARDS). There is some debate in the medical community currently whether COVID-19 presents as ARDS or if the symptoms currently being classified as ARDS in association with COVID-19 is a unique illness. \n\nWith that in mind, let's train the neural network to distinguish between {ARDS, COVID-19, COVID-19,ARDS} vs everything else. \n\nAs I make my databunch, I'm going to change the labels so that it reflects the two classes that I want to train: \"COVID_ARDS\" and \"Other\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels=labels.copy()\nclass_labels.replace(to_replace=['COVID-19','ARDS','COVID-19, ARDS'], value='COVID_ARDS',inplace=True)\nclass_labels.replace(class_labels[class_labels!='COVID_ARDS'],value='Other',inplace=True)\nclass_labels.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make the databunch and visualize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_lists(path_img, xray_PA_fnames, labels=class_labels, ds_tfms=get_transforms(), \n                                 size=224, bs=bs).normalize(imagenet_stats)\n\ndata.show_batch(rows=4, figsize=(15,11))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.classes)\nlen(data.classes),data.c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Train the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn=cnn_learner(data, models.resnet34, metrics=accuracy)\nlearn.model","execution_count":null,"outputs":[]},{"metadata":{"id":"SWC9qK-1mlPJ","outputId":"da26c1a1-b71f-4479-e1fe-a4c8ad289fd0","trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4)","execution_count":null,"outputs":[]},{"metadata":{"id":"t-WrmmuKmlPM","trusted":true},"cell_type":"code","source":"learn.model_dir='/kaggle/working/'\nlearn.save('stage-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(9, figsize=(15,11))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix(figsize=(10,10), dpi=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.most_confused(min_val=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unfreezing, fine-tuning, and learning rates\nOur model is somewhat working as we expect. Let's train the model some more. ","execution_count":null},{"metadata":{"id":"CpDjVAcK6uN1","trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"id":"YGQD1jjk6xAz","outputId":"eb31bd1e-5889-43b0-b71b-592dab703680","trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('stage-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"id":"MbvwePkE60U8","outputId":"d5fbabde-5cb2-4317-eba3-8b78d51a0f52","trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(2, max_lr=slice(3e-5,3e-4))","execution_count":null,"outputs":[]},{"metadata":{"id":"UFekOr7A63DU","outputId":"777f9088-cace-4448-ca84-f02262e617cd","trusted":false},"cell_type":"markdown","source":"### Let's try training with resnet50\nto achieve better performance","execution_count":null},{"metadata":{"id":"TKoANWxT7W1N","trusted":true},"cell_type":"code","source":"data = ImageDataBunch.from_lists(path_img, xray_PA_fnames, labels=class_labels, ds_tfms=get_transforms(), \n                                 size=224, bs=bs).normalize(imagenet_stats)\nlearn = cnn_learner(data, models.resnet50, metrics=accuracy)","execution_count":null,"outputs":[]},{"metadata":{"id":"JbLjVtnE_AFy","trusted":true},"cell_type":"code","source":"learn.model_dir='/kaggle/working/'\nlearn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"id":"aa1eyLmI7Yg7","outputId":"0fd86484-4d11-40cf-cb9d-f77b70327978","trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The error rate has stabilized. Given this network, these parameters, and dataset, perhaps that is the best it will do. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('stage-1-50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('stage-1-50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(3, max_lr=slice(3e-5,3e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('stage-1-50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)","execution_count":null,"outputs":[]},{"metadata":{"id":"6HWD6YjbmlPc","outputId":"4f30ab47-11d2-4128-e47e-9e18dec21ec0","trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix(figsize=(10,10), dpi=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\nThere is a little bit less confusion with resnet50. But overall, the network at this stage can classify COVID_ARDS the majority of the time, but not to a level that would be satisfactory for clinical implementation.\n\nPossible areas of improvement: \n* supplement this with more images in the \"Other\" category to balance the representatives in the training and validation sets\n* at least one image is mislabeled (not a PA view); check for others \n* subject matter expertise would be helpful to understand what features are unique to COVID_ARDS vs. the other categories. in other words, is it reasonable for any network to do better than this, and what are the features we would expect it to find ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}