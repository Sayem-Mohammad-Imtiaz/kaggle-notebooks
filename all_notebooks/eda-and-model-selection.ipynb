{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objective\n\nAn automobile company has plans to enter new markets with their existing products (P1, P2, P3, P4 and P5). After intensive market research, theyâ€™ve deduced that the behavior of new market is similar to their existing market.\n\nContent\nIn their existing market, the sales team has classified all customers into 4 segments (A, B, C, D ). Then, they performed segmented outreach and communication for different segment of customers. This strategy has work exceptionally well for them. They plan to use the same strategy on new markets and have identified 2627 new potential customers.\n\nYou are required to help the manager to predict the right group of the new customers.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\ndata=pd.read_csv('/kaggle/input/customer/Train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As ID column is not useful in dividing customers into segment because ID is any random value thus have no correlations with the segmentation , we could drop ID column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['ID'],inplace=True,axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Numbers of non-null instances of each attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Segmentation.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting labels to categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"label=pd.Categorical(data.Segmentation,categories=['A','B','C','D']).codes\ndata.drop(['Segmentation'],axis=1,inplace=True)\nlabel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train Test split of data and label"},{"metadata":{},"cell_type":"markdown","source":"## Gender "},{"metadata":{},"cell_type":"markdown","source":"### Analysing and finding relations of the segmentation with gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Gender.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(data.Gender,hue=label,palette='Dark2')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As there is no null value in the gender column we could easily assign\nmale as 0 and\nfemale as 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Gender=pd.Categorical(data.Gender,categories=['Male','Female'],ordered=True).codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Marital status"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Ever_Married.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 140 unknown values so we could assign them to most common marital status"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Ever_Married.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As most of the people are married filling the empty space with 'yes'"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Ever_Married'].fillna('Yes',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(data.Ever_Married,hue=label,palette='PuBuGn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Ever_Married=pd.Categorical(data.Ever_Married,categories=['No','Yes'],ordered=True).codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Graduated"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Graduated.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"78 values in Graduated columns are empty so we would again apply same stategy and the maximum occuring value of the column would be set at the empty space "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Graduated.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Graduated.fillna('Yes',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.Graduated,hue=label,palette='winter_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph gives information that non graduated customers are  categorised as category D , in the mean time the graduated customers are categorised as category C most likely."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Graduated=pd.Categorical(data.Graduated,categories=['No','Yes'],ordered=True).codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Profession"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Profession.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Profession.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above table specifies that customers are mainly artist and healthcare"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Profession.fillna('Artist',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nsns.countplot(data.Profession,hue=label,palette='twilight_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph signifies that Artist and Executive are generally categorised as category C and Healthcare worker and other are generally  categorised as category D."},{"metadata":{"trusted":true},"cell_type":"code","source":"profession=pd.get_dummies(data.Profession)\ndata.drop(['Profession'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profession","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.join(profession)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## spending score "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Spending_Score.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data.Spending_Score,hue=label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph informs about that low budget people are mostly been classified in category D"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Spending_Score=pd.Categorical(data.Spending_Score,categories=['Low','Average','High'],ordered=True).codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## var_1"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Var_1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Var_1.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Var_1.fillna('Cat_6',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.countplot(data.Var_1,hue=label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Var_1=pd.Categorical(data.Var_1).codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## working experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Work_Experience.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Work_Experience.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The missing value of work_experience customer, can be treated as zero experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Work_Experience.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.hist(data.Work_Experience)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Family size "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Family_Size.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Family_Size.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling the column with the previous appeared value"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Family_Size.fillna(method='ffill',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.hist(data.Family_Size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Age.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the max age of the customer is {0} \\n the minimum age of the customer is {1}\".format(max(data.Age),min(data.Age)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(data.Age,label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.hist(data.Age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above graphs of Age,work experience and family size are screwed.\nso we could use MinMaxScaler to normalize  group of data between the range of 0 to 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"# data=pd.DataFrame([data],columns=data.columns)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_data=pd.DataFrame(label,columns=['label'])\ncorrelation_data=correlation_data.join(data)\ncorrelation_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.heatmap(correlation_data.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-validation spliting of dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,val_data,train_label,val_label=train_test_split(data,label,test_size=0.2,random_state=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Selection "},{"metadata":{},"cell_type":"markdown","source":"We select DecisionTreeClassifer as the first classifier, with max_depth of 10 to avoid overfittig of data."},{"metadata":{},"cell_type":"markdown","source":"### DecisionTreeClassifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier1=DecisionTreeClassifier(max_depth=10)\nclassifier1.fit(train_data,train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"To evaluate the performace of train data on the model \\n\",classification_report(train_label,classifier1.predict(train_data)))\nprint(\"To evaluate the performace of validatation data on the model \\n\",classification_report(val_label,classifier1.predict(val_data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Though the overall accuracy of the classifier don't seems great but works pleasant well in identifing the category 'D' customer with accuracy of about 65%.The main reason here is lack of availability of data as category 'D' have quit larger data as compared with others thus have a little more accuracy."},{"metadata":{},"cell_type":"markdown","source":"### RandomForestClassifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier2=RandomForestClassifier(max_depth=9)\nclassifier2.fit(train_data,train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"To evaluate the performace of train data on the model \\n\",classification_report(train_label,classifier2.predict(train_data)))\nprint(\"To evaluate the performace of validation data on the model \\n\",classification_report(val_label,classifier2.predict(val_data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomForestClassifier is better classifier model here as it gives a quit better accuracy in classifying each categories."},{"metadata":{},"cell_type":"markdown","source":"### LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier3=LogisticRegression(tol=0.01,max_iter=1000)\nclassifier3.fit(train_data,train_label)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"To evaluate the performace of train data on the model \\n\",classification_report(train_label,classifier3.predict(train_data)))\nprint(\"To evaluate the performace of validation data on the model \\n\",classification_report(val_label,classifier3.predict(val_data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Though accuracy is not only metrics to judge a model ,but here it give quit clear idea the RandomForestClassifier(with accuracy of 54%) is better algorithm for the given datasets ."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}