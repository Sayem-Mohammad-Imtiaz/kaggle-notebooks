{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The purpose of this notebook is to visualize IPL data and make intuitions from it"},{"metadata":{},"cell_type":"markdown","source":"# **1)Loading the dataset**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/iplcricket-league-dataset-for-beginner-analaysis/IPL_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head() #Top 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns #columns present in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we may observe, there are 14 columns in  our dataset out of which 2 columns are of no use to us. i.e. the unnamed columns."},{"metadata":{},"cell_type":"markdown","source":"# **2)Importing Matplotlib.pyplot and seaborn**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3)Making sense of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, 11 of the useful columns are of the type object which have to be converted into int type while feeding it to any sort of machine learning model"},{"metadata":{},"cell_type":"markdown","source":"# 4)Encoding the data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(df['Team1'][0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=[]\nfor i in df['Team1']:\n    l.append(i.strip())\ndf['Team1']=l\nl=[]\nfor i in df['Team2']:\n    l.append(i.strip())\ndf['Team2']=l #removing the extra spaces","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l1=df['Team1'].unique()\nl2=df['Team2'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_l1={}\nx=0\nfor i in l1:\n    en_l1[i]=x\n    x=x+1      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the encoded values"},{"metadata":{"trusted":true},"cell_type":"code","source":"en_l1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Team1']=df['Team1'].map(en_l1)\ndf['Team2']=df['Team2'].map(en_l1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)#dropping unnamed columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=[]\nlis=df['Toss'].unique()\nfor i in lis:\n    l.append(i)\nd_l={}\nx=0\nfor i in l:\n    s=i[0]\n    if(s=='8' or s=='4' or s=='.'):\n        d_l[i]=int(10000)\n    else:\n        d_l[i]=int(x)\n        x=x+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We may notice that there are few rows such as '8:00PM' and '4:00 PM' ,we'll have to handel these cases by giving a large value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Toss']=df['Toss'].map(d_l)\nd_l\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have encoded the team names and removed unnamed colums from out dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"l=df['Place'].unique()\nx=0\nen_pl={}\nfor i in l:\n    en_pl[i]=x\n    x=x+1\ndf['Place']=df['Place'].map(en_pl)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have TossDecision,Result,Tied,won_runs and won_wickets left to encode."},{"metadata":{"trusted":true},"cell_type":"code","source":"lis=df['Tied'].unique()\nprint(\"Match\" in lis[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d={}\nfor i in lis:\n    if(type(i)== float):\n        d[i]=0\n    elif (\"Match abandoned\" in i):\n        d[i]=1\n    elif(\"Match tied\" in i):\n        d[i]=2\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Tied']=df['Tied'].map(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['won_runs'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis=df['won_runs'].unique()\nd={}\nfor i in lis:\n    if(type(i)==float):\n        d[i]=0\n    else:\n        d[i]=int(i[0:3])\ndf['won_runs']=df['won_runs'].map(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis=df['won_wickets'].unique()\nd={}\nfor i in lis:\n    if(type(i)==float):\n        d[i]=0\n    else:\n        d[i]=int(i[0:3])\ndf['won_wickets']=df['won_wickets'].map(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis=df['Result'].unique()\nl=[]\nfor r in lis:\n    l.append(r.split(\" won\")[0])\ns=[]\nfor i in df['Result']:\n    s.append(i.split(\" won\")[0].lower())\ndf['Result']=s      \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_l={}\nx=0\nfor i in l1:\n    en_l[i.lower()]=x\n    x=x+1\nfor i in l:\n    if (\"Match abandoned\" in i):\n        en_l[i]=20\n    elif(\"Match tied\" in i):\n        en_l[i]=21\n   \ndf['Result']=df['Result'].map(en_l)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_l1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see ,we have converted all the useful columns into int or float by encoding except Toss and TossDecision is still of the type object "},{"metadata":{"trusted":true},"cell_type":"code","source":"dec={'bat':1,'bowl':2}\ndf['TossDecision']=df['TossDecision'].map(dec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have finished encoding all the required information"},{"metadata":{},"cell_type":"markdown","source":"# Data Visualisation"},{"metadata":{},"cell_type":"markdown","source":"Let's see which team played the most number of matches. We have 2 rows for teams - Team1 and Team2"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Team1'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Team2'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll have to add the two "},{"metadata":{"trusted":true},"cell_type":"code","source":"teams=df['Team1'].value_counts().sort_index()+df['Team2'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.bar([0,1,2,3,4,5,6,7,8,9,10,11,12],teams,color='g',width=0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"en_l1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this we may notice that 4)Mumbai Indians have played the most number of matches, but we may notice that Pune Warriors and Rising Pune Supergiant are the same team.I haven't taken that into account"},{"metadata":{},"cell_type":"markdown","source":"Let's now see which year had most number of matches"},{"metadata":{"trusted":true},"cell_type":"code","source":"year=df['Year'].value_counts().sort_index()\nplt.figure(figsize=(10,10))\nplt.pie(year,labels=[2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019],autopct='%1.2f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2012 and 2013 had the most number of mathes and, 2009 and 2008 had the least number of matches scheduled."},{"metadata":{"trusted":true},"cell_type":"code","source":"dec=df['TossDecision'].value_counts().sort_index()\nplt.figure(figsize=(10,10))\nplt.bar(['Bat','bowl'],dec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost 50% of the teams that won the toss decided to bowl first!"},{"metadata":{},"cell_type":"markdown","source":"Finally, let's use seaborn to plot a heatmap to determine the relation between different columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(),vmax=1,annot=True,fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For our dataset, there isn't much inference that can be made from the heatmap \nThe negative values depicts inverse relation whereas positive values depict direct values."},{"metadata":{},"cell_type":"markdown","source":"This is just an introduction to basic data cleaning and data visualization a lot of things can be made with the resourses available.\nI hope this notebook was useful and you can use it as a reference for your future projects\n\n**Adios amigos!**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}