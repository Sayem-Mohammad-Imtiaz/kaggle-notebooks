{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%config Completer.use_jedi = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{},"cell_type":"markdown","source":"Features, statistics and correlations."},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath =\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\"\nheart_features = pd.read_csv(filepath)\nheart_features.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_features.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_features['time'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport seaborn as sns\nplt.style.use('ggplot') # default plot style.\n\nfrom scipy import stats\nfrom scipy.stats import norm\nnumeric_columns = ['age','anaemia','creatinine_phosphokinase','diabetes','ejection_fraction','high_blood_pressure',\n                  'platelets','serum_creatinine','serum_sodium','sex',\n                  'smoking','time','DEATH_EVENT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_data = heart_features.loc[:, numeric_columns].corr()\n\nplt.figure(figsize=(20,12))\nsns.heatmap(corr_data, annot=True, fmt='.3f',cmap='coolwarm',square=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"This is the most important part, here we use the PCA, create the *vulnerability* and the *stress* feature. With this the model improves from 74% to 81%."},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_features['vulnerability'] = heart_features['age']/heart_features['time']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_features['stress'] = (heart_features['smoking']+\n                            heart_features['serum_creatinine']+\n                            heart_features['high_blood_pressure'])/heart_features['time']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nmy_pipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('reducer', PCA(n_components=2)),\n])\n\nhf_red = my_pipe.fit_transform(heart_features.drop(['DEATH_EVENT'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hf_full = pd.concat([pd.DataFrame(hf_red),heart_features], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = hf_full.drop(['DEATH_EVENT'], axis=1)\ny = hf_full[[\"DEATH_EVENT\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(y_train, return_counts=True)\nprint (np.asarray((unique, counts)).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop=counts[0]/counts[1] #sin oversample\nprop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.experimental import enable_hist_gradient_boosting  # noqa\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nclf = HistGradientBoostingClassifier().fit(X_train, y_train)\nclf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nimport xgboost as xgb\ndtrain = xgb.DMatrix(\n        X_train,\n        y_train    )\n\ndtest = xgb.DMatrix(\n        X_test,\n        y_test    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrained_model = xgb.train(\n                        {\n                          'eta': 0.1,#0.1 learning rate 0.01 clasico               \n                          'colsample_bytree' : 1, #? 0.1 best 0.8 previus, 0.5 better than 0.8, 0.1 worst roc,1 best ROC\n                          'sample_type': 'weighted',\n                          'min_child_weight':1,#1 is the default\n                          'max_delta_step':1,#0 for imbalanced data, [1,10], 1 is the best\n                          'max_depth': 20,#10-precavido, 30 m치s auc con 5 tambien fue bueno, 0 FN y 32409, a mayor profundidad mejor va siendo el modelo 50 max\n                          'subsample': 0.8,#0.8\n                          'objective': 'binary:logistic',#classificator\n                          'n_estimators':1,#10,100*,1000 es lo mismo\n                          'scale_pos_weight':174.85470085470087,#prop entre label:1 y label:0\n                          'num_parallel_tree':2,#1 lo traje de los 2 en paralelo, 2 fue mejor FP,15 ha sido el mejor, ya 30 empeora\n                          'gamma': 10,#20\n                          'alpha' : 20,#10 velocity\n                          'lambda': 50,#50 overfitting L2 regularization\n                          'silent': True,\n                          'verbose_eval': False,\n                          'tree_method':'hist',#auto? hist is very good  \n                          'grow_policy':'depthwise',#default depthwise, only aviable with hist tree\n                          'max_bin':200   #default 256,more, better splits, worst computing time             \n                        },\n                        dtrain,\n                        num_boost_round=100, evals=[(dtrain, 'train'),(dtest,'test')])#,early_stopping_rounds=120)#100-140   early stopping = 10% total epochs(50/500)\n                          #1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = trained_model.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance, plot_tree\n\nplot_importance(trained_model, max_num_features=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Threshold selection"},{"metadata":{},"cell_type":"markdown","source":"Find the best threshold."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom matplotlib import pyplot\n\nfpr, tpr, thresholds = roc_curve(y_test, prediction)\n# calculate the g-mean for each threshold\ngmeans = np.sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = np.argmax(gmeans)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n# plot the roc curve for the model\npyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\npyplot.plot(fpr, tpr, marker='.', label='XGBoost')\npyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\n# show the plot\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def threshold(predictions,th):\n  \"\"\"\n  predictions: array con los valores de las predicciones de clases, no booleano\n  th: threshold desde el cual decimos si la predicci칩n es 1 o es 0\n  Esta funci칩n nos permite ajustar el threshold de las predicciones para hacer el modelo m치s relajado o precavido\n  \"\"\"\n  pred =np.zeros(len(predictions))\n  for i in range(len(predictions)):\n    if (predictions[i]<=th):\n      pred[i]=0\n    else:\n      pred[i]=1\n  return pred\npredictions = threshold(prediction,thresholds[ix])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_test, predictions)\nprint(\"Auc en el test : \", auc) #0.719, con pca2 y f 0.805","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(y_test, predictions)\nprint(\"Accuracy on the test: \", acc)#0.727, con pca 2 y feature 0.808","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nconfusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}