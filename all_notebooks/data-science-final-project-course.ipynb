{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import cm\nimport matplotlib.pyplot as plt\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split , GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report , recall_score ,  precision_score\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Preparation:**"},{"metadata":{},"cell_type":"markdown","source":"Lets prepare our data for modeling"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read data\n\nflight_details_janury_2019 = pd.read_csv('/kaggle/input/flight-delay-prediction/Jan_2019_ontime.csv')\n\nflight_details_janury_2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the columns:\nflight_details_janury_2019.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check type of columns:\nflight_details_janury_2019.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets understand what we are looking to predict:\n* We have dataset of flights from januray 2019 and we want to predict if some flight will delayed or not. \n* In our dataset, we have 2 columns of delay: 1 column for departure delay [DEP_DEL15], and 1 column for arrivel delay [ARR_DEL15] \n* We want to predict if someflight will delayed in any time - arrival or departure. So lets create new classifier, named under \"delayed\" with 2 result:\n\n1.  Delayed - 1 the flight will delay\n2.  Delayed - 0 the flight will not delay"},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_details_janury_2019['DELAYED'] = (flight_details_janury_2019['ARR_DEL15'].astype(bool) | flight_details_janury_2019['DEP_DEL15'].astype(bool)).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to remove the canceled and diverted flights, because we are looking for flights that succesfuly departed"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of rows before deleted 'Cancelled' column and `DIVERTED` is \" + str(flight_details_janury_2019.shape[0]) )\n\nflight_details_janury_2019.drop(flight_details_janury_2019[flight_details_janury_2019.CANCELLED == 1].index, inplace=True)\n\nflight_details_janury_2019.drop(flight_details_janury_2019[flight_details_janury_2019.DIVERTED == 1].index, inplace=True)\n\nprint(\"The number of rows after deleted 'Cancelled' column and `DIVERTED` is \" + str(flight_details_janury_2019.shape[0]) )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets get rid of unuseful columns, that not impact on our results:\n* **OP_CARRIER_AIRLINE_ID** - The id of the airline , because we will use the name of airline , for correltions and plots , more clearly to understand ariline name code than the airline id , and after that we will convert the name to numeric value\n* **TAIL_NUM** - dosnt give us any information\n* **OP_CARRIER_FL_NUM** - dosnt give us any information\n* **ORIGIN_AIRPORT_ID** , **'ORIGIN_AIRPORT_ID'** ,**ORIGIN_AIRPORT_SEQ_ID','DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID'** - we have instead the origin and destination airport ATA code , more clearly for understading in plots.\n* **Unnamed: 21** - Unrelevant column\n* **OP_CARRIER** - same as OP_UNIQUE_CARRIER\n* **DEP_DEL15** - We convert the DEP and ARR to DELAYED Column\n* **ARR_DEL15** - We convert the DEP and ARR to DELAYED Column\n* **CANCELED**  - We check only for delayed flight , so Canceled flight are dont relevant\n* **DIVERTED**  - We check only for delayed flight , so Canceled flight are dont relevant"},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_details_janury_2019.drop(['OP_CARRIER_AIRLINE_ID','TAIL_NUM','OP_CARRIER_FL_NUM','ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID','DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID','Unnamed: 21','OP_CARRIER','ARR_DEL15','DEP_DEL15','CANCELLED', 'DIVERTED'], axis='columns', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets check distribution of our target variable:**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_details_janury_2019['DELAYED'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are very highly difference between the rows with value 1 and 0 , so we should decrease our rows with value 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into positive and negative\npos = flight_details_janury_2019.loc[flight_details_janury_2019.DELAYED == 1]\nneg = flight_details_janury_2019.loc[flight_details_janury_2019.DELAYED == 0]\n\n# Merge the balanced data\ndata = pd.concat([pos, neg.sample(n = len(pos))], axis = 0)\n\n# Shuffle the order of data\nflight_details_janury_2019 = data.sample(n = len(data)).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_details_janury_2019['DELAYED'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets rename names if needed for more readble:"},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_details_janury_2019 = flight_details_janury_2019.rename(columns={\"OP_UNIQUE_CARRIER\": \"AIRLINE_CODE\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for some Null/Na values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"flight_details_janury_2019.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the data is clean , we dont have any null values."},{"metadata":{},"cell_type":"markdown","source":"**Summerize**:"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"The Data types is:\")\nflight_details_janury_2019.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Our final data include: \" + str(flight_details_janury_2019.shape[0]) + \" Rows and \" + str(flight_details_janury_2019.shape[1]) + \" Columns\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" flight_details_janury_2019.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Final Data Format:**\n\nAfter we carefully analyzing each data points, This is the final data:\n\n* DAY_OF_MONTH - Day of Month\n* DAY_OF_WEEK - Day of Week\n* AIRLINE_CODE - Airline Carrier Code\n* ORIGIN - Origin airport location\n* DEST - Destination airport location\n* DEP_TIME - Actual Departure Time (local time: hhmm)\n* DEP_TIME_BLK - Time Block Departure (hhmm-hhmm)\n* ARR_TIME - Actual Arrivel Time (local time: hhmm)\n* DISTANCE - Distance between airports (miles)\n* DELAYED - Classifier - 1 If flight delayed, else - 0"},{"metadata":{},"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n"},{"metadata":{},"cell_type":"markdown","source":"Histograms:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nflight_details_janury_2019.hist(figsize= (15, 14))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" flight_details_janury_2019.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets look for some corelations between the features and our classifier for better understanding,\nand learn a more about our features.** \n\n"},{"metadata":{},"cell_type":"markdown","source":"First Lets see if there some dfference between airline companies delay, due to result we can understand if there problem with spesific company."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count delayes by company\ncount_delayed=flight_details_janury_2019.groupby('AIRLINE_CODE')['DELAYED'].apply(lambda x: (x==1).sum()).reset_index(name='Number Delayed')\n\ncolor = cm.inferno_r(np.linspace(.4, .8, 30))\n\ncount_delayed= count_delayed.sort_values(\"Number Delayed\" , ascending=[False])\ncount_delayed.plot.bar(x='AIRLINE_CODE', y='Number Delayed', color=color , figsize=(12,7))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation between the day of the month to number of delays:"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_days_delayed=flight_details_janury_2019.groupby('DAY_OF_MONTH')['DELAYED'].apply(lambda x: (x==1).sum()).reset_index(name='Number Delayed')\nplt.figure(figsize=(10, 6))\nplt.xticks(monthly_days_delayed['DAY_OF_MONTH'])\nplt.plot(monthly_days_delayed['DAY_OF_MONTH'],monthly_days_delayed['Number Delayed'])\nplt.ylabel('Delayed')\nplt.xlabel('Day in month')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets see if there any corellation between the distance and delays:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate the precent of delays with average distance:\navg_distance_delay = flight_details_janury_2019[flight_details_janury_2019['DELAYED'] == 1]['DISTANCE'].values.mean()\n#Calculate the precent of delays without average distance:\navg_distance_without_delay = flight_details_janury_2019[flight_details_janury_2019['DELAYED'] == 0]['DISTANCE'].values.mean()\n\nprint(\"Avergae Distance with delay: \" + str(avg_distance_delay) + \" mile\")\nprint(\"Avergae Distance without delay: \"+ str(avg_distance_without_delay) +\" mile\")\n\nlabels = ['Distance With Delay', 'Distance Without Delay']\nsizes = [avg_distance_delay,avg_distance_without_delay]\ncolors = ['yellowgreen', 'gold']\ntexts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, autopct='%1.1f%%')\nplt.legend(labels, loc=\"best\")\nplt.axis('equal')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see in wich day are the higher number of delays:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the data for the days adays_values\ndays_values = flight_details_janury_2019.groupby('DAY_OF_WEEK')['DELAYED'].apply(lambda x: (x==1).sum()).reset_index(name='Number Delayed')\ndays_values.sort_values(\"DAY_OF_WEEK\" )\n\ndays_values['DAY_OF_WEEK'] = days_values['DAY_OF_WEEK'].map({1: 'Sun', 2: 'Mon', 3:'Thu',4:'Wed',5:'Thr',6:'Fri',7:'Sat'})\n\ndf = pd.DataFrame({'Days':days_values['DAY_OF_WEEK'],'Delayed':days_values['Number Delayed']})\nax = df.plot.barh(x='Days',y='Delayed',figsize=(12,7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to encode our categorial Variabels before we move to modeling:\n* OP_UNIQUE_CARRIER\n* ORIGIN\n* DEST\n* DEST_TIME_BLK"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_categories(features):\n    lb_make = LabelEncoder()\n    for i in range(len(features)):\n        flight_details_janury_2019[features[i]] = lb_make.fit_transform(flight_details_janury_2019[features[i]])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_categories(['AIRLINE_CODE','ORIGIN','DEST','DEP_TIME_BLK',])\nflight_details_janury_2019.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Collerations between our features:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 10))\nsns.heatmap(flight_details_janury_2019.corr(), annot = True, cmap = 'coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"Lets first create Test set and Train set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create test and train:\nfeature_names = ['DAY_OF_MONTH','DAY_OF_WEEK','AIRLINE_CODE','ORIGIN','DEST','DEP_TIME','DEP_TIME_BLK','ARR_TIME','DISTANCE']\nX =  flight_details_janury_2019[feature_names].values\ny =  flight_details_janury_2019['DELAYED'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 350,max_depth=14,min_samples_leaf=15,min_samples_split=5, n_jobs=-1)\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GradientBoosting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingClassifier()\ngb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(max_depth=15)\ndt.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AdaBoostClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ab = AdaBoostClassifier()\nab.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate"},{"metadata":{},"cell_type":"markdown","source":"Evaluating of accuarcy of our models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Acurracy of each model\ndef get_accuracy(model):\n        pred = model[0].predict(X_test)\n        check_overfitting(model)\n        return accuracy_score(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_overfitting(model):\n        pred = model[0].predict(X_test)\n        over_fit_check_pred = model[0].predict(X_train)\n        print('Checking '+ model[1] + ' Overffiting:')\n        print('Train Accuracy ' + str(accuracy_score(y_train, over_fit_check_pred)))\n        print('Test Accuracy ' + str(accuracy_score(y_test, pred)))\n        print('--------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the confusion matrix for each model:\ndef get_confusion_matrix(model):\n    from sklearn.metrics import plot_confusion_matrix\n    class_names=['Delay-False','Delay-true']\n    disp = plot_confusion_matrix(model[0], X_test, y_test,\n                                     display_labels=class_names, values_format='d',\n                                     cmap=model[2])\n    precision = precision_score(y_test, model[0].predict(X_test), average='binary')\n    recall = recall_score(y_test, model[0].predict(X_test), average='binary')\n    print('Avg Precision:' +  str(precision))\n    print('Avg Recall:' + str(recall))\n    \n    disp.ax_.set_title(model[1])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Save the accuracy\nmodels = [[rf,'Random Forest',plt.cm.Blues],[gb,'Gradient Boosting',plt.cm.Greens],[dt,'Decision Tree',plt.cm.Reds],[ab,'AdaBoost',plt.cm.Oranges]]\naccuracy = []\nfor model in models:\n    accuracy.append(get_accuracy(model))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show the confusion matrix for each model with Recall and Precision"},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    get_confusion_matrix(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot accurcay of each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nmodel_names = ['Random Forest','Gradient Boosting','Decision Tree','AdaBoost']\nax = sns.barplot(x = model_names, y =accuracy)\n\naccuracy_dic = dict(zip(model_names, accuracy))\n\nfor p, value in zip(ax.patches, list(accuracy_dic.values())):\n    _x = p.get_x() + p.get_width() / 2\n    _y = p.get_y() + p.get_height() + 0.008\n    ax.text(_x, _y, round(value, 3), ha=\"center\") \n\nplt.xlabel(\"Models\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model vs. Accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, rf.predict(X_test), target_names=['Delayed','Not Delayed']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Importance:****"},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\nfeatures = list(flight_details_janury_2019.columns)\nindices = np.argsort(importances)[::-1]\n\nnames = [features[i] for i in indices]\n\nplt.figure(figsize=(15,5))\nplt.bar(range(X_train.shape[1]), importances[indices])\nplt.xticks(range(X_train.shape[1]), names, rotation=30, fontsize = 10)\nplt.title(\"Feature Importance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that Random Forest give us the best accuracy. Lets try to change our params for Random forset, and maybe we will get better result."},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameter tuning for RandomForest**"},{"metadata":{},"cell_type":"markdown","source":" the optimization takes 20 minutes. for avoid long run time ,you can see the code and the  result in report\n\n"},{"metadata":{},"cell_type":"markdown","source":"Test again the model after we did some optimization and find good parameters:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the older accur:\nrf_old_accur = accuracy[0]\n\nrf = RandomForestClassifier(n_estimators=200, min_samples_split=5, max_features='sqrt', max_depth=45)\nrf.fit(X_train,y_train)\n\npred = rf.predict(X_test)\nrf_new_accur = accuracy_score(y_test, pred)\n\nprint(\"The Accuracy of RandomForest Model before tuning: \" + str(rf_old_accur))\nprint(\"The Accuracy of RandomForest Model after tuning: \" + str(rf_new_accur))\n\nprint(\"Increase of : \" + str(100-((rf_old_accur * 100 ) / rf_new_accur ))+' %')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}