{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hospital Readmissions Prediction"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from PIL import Image\nImage.open('../input/images/diabet.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Diabetes, which is at the forefront of diseases of the age, is a disease that plays a leading role in the formation of many deadly diseases and is very common all over the world.\n\nIt is important to know whether a patient can be readmitted in a hospital. In this project, we tried predict whether diabetes patients will return to the hospital or not by using machine learning algorithms."},{"metadata":{},"cell_type":"markdown","source":"# Content\n\nThe data set represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks.\n\nThe following steps were followed in this project;\n<ol> \n    <li><a href='#1'>Exploratory Data Analysis</a></li>\n    <li><a href='#2'>Visualization</a></li>\n    <li><a href='#3'>Feature Engineering</a></li>\n        <ul>     \n         <li>Missing Value Handling</li>\n         <li>Outlier Handling</li>\n         <li>Encoding</li>\n        </ul> \n    <li><a href='#4'>Splitting Train-Validation-Test</a></li>\n    <li><a href='#5'>Modelling</a></li>\n        <ul>     \n         <li> Logistic Regression</li>\n         <li> Random Forest Classifier</li>\n         <li> GradientBoosting Classifier</li>\n         <li> XGboost Classifier</li>\n         <li> Light-GBM Classifier</li>\n         <li> CatBoost Classifier</li>\n        </ul>\n    <li><a href='#6'>Feature Importance</a></li>\n    <li><a href='#7'>Hyperparameter Tuning</a></li>\n    <li><a href='#8'>Predict Results</a></li>\n    <li><a href='#9'>Conclusion</a></li>\n    <li><a href='#10'>References</a></li>\n</ol> "},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"1\"></a> 1. Exploratory Data Analysis\n\n## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Visualization\nimport missingno as msno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\n# Metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score,f1_score,recall_score,mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.metrics import classification_report\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n# !pip install catboost\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/diabetes/diabetic_data.csv\")\ndef display_all(data):\n    with pd.option_context(\"display.max_row\", 100, \"display.max_columns\", 100):\n        display(data)\ndisplay_all(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variable Description\n\n<span style='font-weight:bold;color:#561225'>Encounter ID:</span> Unique identifier of an encounter\n    \n<span style='font-weight:bold;color:#561225'>Patient number:</span> Unique identifier of a patient\n    \n<span style='font-weight:bold;color:#561225'>Race Values:</span> Caucasian, Asian, African American, Hispanic, and other\n    \n<span style='font-weight:bold;color:#561225'>Gender Values:</span> male, female, and unknown/invalid\n    \n<span style='font-weight:bold;color:#561225'>Age:</span> Grouped in 10-year intervals: 0, 10), 10, 20), …, 90, 100)\n   \n<span style='font-weight:bold;color:#561225'>Weight:</span> Weight in pounds\n  \n<span style='font-weight:bold;color:#561225'>Admission type:</span> Integer identifier corresponding to 9 distinct values, for example, emergency, urgent, elective, newborn, and not available\n \n<span style='font-weight:bold;color:#561225'>Discharge disposition:</span> Integer identifier corresponding to 29 distinct values, for example, discharged to home, expired, and not available\n\n<span style='font-weight:bold;color:#561225'>Admission source:</span> Integer identifier corresponding to 21 distinct values, for example, physician referral, emergency room, and transfer from a hospital\n\n<span style='font-weight:bold;color:#561225'>Time in hospital:</span> Integer number of days between admission and discharge\n\n<span style='font-weight:bold;color:#561225'>Payer code :</span> Integer identifier corresponding to 23 distinct values, for example, Blue Cross/Blue Shield, Medicare, and self-pay Medical\n\n<span style='font-weight:bold;color:#561225'>Medical specialty:</span> Integer identifier of a specialty of the admitting physician, corresponding to 84 distinct values, for example, cardiology, internal medicine, family/general practice, and surgeon\n\n<span style='font-weight:bold;color:#561225'>Number of lab procedures:</span> Number of lab tests performed during the encounter\n\n<span style='font-weight:bold;color:#561225'>Number of procedures:</span> Numeric Number of procedures (other than lab tests) performed during the encounter\n\n<span style='font-weight:bold;color:#561225'>Number of medications:</span> Number of distinct generic names administered during the encounter\n\n<span style='font-weight:bold;color:#561225'>Number of outpatient visits:</span> Number of outpatient visits of the patient in the year preceding the encounter\n\n<span style='font-weight:bold;color:#561225'>Number of emergency visits:</span> Number of emergency visits of the patient in the year preceding the encounter\n\n<span style='font-weight:bold;color:#561225'>Number of inpatient visits:</span> Number of inpatient visits of the patient in the year preceding the encounter\n\n<span style='font-weight:bold;color:#561225'>Diagnosis 1:</span> The primary diagnosis (coded as first three digits of ICD9); 848 distinct values\n\n<span style='font-weight:bold;color:#561225'>Diagnosis 2:</span> Secondary diagnosis (coded as first three digits of ICD9); 923 distinct values\n\n<span style='font-weight:bold;color:#561225'>Diagnosis 3:</span> Additional secondary diagnosis (coded as first three digits of ICD9); 954 distinct values\n\n<span style='font-weight:bold;color:#561225'>Number of diagnoses :</span> Number of diagnoses entered to the system 0%\n\n<span style='font-weight:bold;color:#561225'>Glucose serum test :</span> result Indicates the range of the result or if the test was not taken. Values: “>200,” “>300,” “normal,” and “none” if not measured\n\n<span style='font-weight:bold;color:#561225'>A1c test result :</span> Indicates the range of the result or if the test was not taken. Values: “>8” if the result was greater than 8%, “>7” if the result was greater than 7% but less than 8%, “normal” if the result was less than 7%, and “none” if not measured.\n\n<span style='font-weight:bold;color:#561225'>Change of medications :</span> Indicates if there was a change in diabetic medications (either dosage or generic name). Values: “change” and “no change”\n\n<span style='font-weight:bold;color:#561225'>Diabetes medications :</span> Indicates if there was any diabetic medication prescribed. Values: “yes” and “no” 24 features for medications For the generic names: <span style='font-weight:bold'>metformin, repaglinide, nateglinide, chlorpropamide, glimepiride, acetohexamide, glipizide, glyburide, tolbutamide, pioglitazone, rosiglitazone, acarbose, miglitol, troglitazone, tolazamide, examide, sitagliptin, insulin, glyburide-metformin, glipizide-metformin, glimepiride- pioglitazone, metformin-rosiglitazone, and metformin- pioglitazone, </span> the feature indicates whether the drug was prescribed or there was a change in the dosage. Values: “up” if the dosage was increased during the encounter, “down” if the dosage was decreased, “steady” if the dosage did not change, and “no” if the drug was not prescribed\n\n<span style='font-weight:bold;color:#123456'>Readmitted:</span> Days to inpatient readmission. Values: “<30” if the patient was readmitted in less than 30 days, “>30” if the patient was readmitted in more than 30 days, and “No” for no record of readmission"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IDs_mapping = pd.read_csv(\"../input/id-mapping/IDs_mapping.csv\")\n        \ndisplay_all(IDs_mapping.head(67))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target Distribution (Readmitted)"},{"metadata":{},"cell_type":"markdown","source":"Target content changed to 1-0\n\nThe outcome we are looking at is whether the patient gets readmitted to the hospital within 30 days or not.\n\nThe variable actually has <30, >30 and No Readmission categories. To reduce our problem to a binary classification, we combined the readmission after 30 days and no readmission into a single category:\n\nNO and >30: 0 <br>\n<30 : 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.readmitted = [1 if each=='<30' else 0 for each in data.readmitted]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(nrows=1,ncols=2, figsize=(12,5))\nlabels=['0','1']\nsns.countplot(x=data.readmitted, data=data, palette=\"pastel\",ax=ax[0], edgecolor=\".3\")\ndata.readmitted.value_counts().plot.pie(autopct=\"%1.2f%%\", ax=ax[1], colors=['#66a3ff','#facc99'], \n                                        labels=labels, explode = (0, 0.05), startangle=120,\n                                        textprops={'fontsize': 12, 'color':'#0a0a00'})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.replace('?', np.nan , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Information about Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(data,sort='descending',color='#66a9bc')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Representation of missing values, unique values, etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"def Missing_Values(data):\n    variable_name = []\n    total_value = []\n    total_missing_value = []\n    missing_value_rate = []\n    unique_value_list = []\n    total_unique_value = []\n    data_type = []\n    \n    for col in data.columns:\n        variable_name.append(col)\n        data_type.append(data[col].dtype)\n        total_value.append(data[col].shape[0])\n        total_missing_value.append(data[col].isnull().sum())\n        missing_value_rate.append(round(data[col].isnull().sum()/data[col].shape[0],4))\n        unique_value_list.append(data[col].unique())\n        total_unique_value.append(len(data[col].unique()))\n        \n    missing_data=pd.DataFrame({\"Variable\":variable_name,\\\n                               \"#_Total_Value\":total_value,\\\n                               \"#_Total_Missing_Value\":total_missing_value,\\\n                               \"%_Missing_Value_Rate\":missing_value_rate,\\\n                               \"Data_Type\":data_type,\"Unique_Value\":unique_value_list,\\\n                               \"Total_Unique_Value\":total_unique_value\n                              })\n    \n    missing_data = missing_data.set_index(\"Variable\")\n    return missing_data.sort_values(\"#_Total_Missing_Value\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_info = Missing_Values(data)\ndata_info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Types of data measurement scales"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dictionary = pd.read_csv('../input/dataset/var.csv', sep=';')\ndata_dictionary = data_dictionary.set_index(\"variable_name\")\ndata_dictionary.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data_info['Variable_Structure'] = np.array(data_dictionary[\"Variable_Structure\"])\ndata_info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns that would not give information were removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = ['examide' , 'citoglipton', 'weight','encounter_id','patient_nbr','payer_code','medical_specialty']  \ndata.drop(drop_list,axis=1, inplace=True)\ndata_info.drop(drop_list, axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Determination of numerical columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = list(data_info.loc[(data_info.loc[:,\"Variable_Structure\"]==\"numeric\")].index)\nlen(numerical_columns), numerical_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Determination of categorical columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = list(data_info.loc[(data_info.loc[:,\"Variable_Structure\"]==\"nominal\")].index)\nlen(categorical_columns), categorical_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"2\"></a>2. Visualization"},{"metadata":{},"cell_type":"markdown","source":"## Outlier Visualization With BoxPlot:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot_for_outlier(df,columns):\n    count = 0\n    fig, ax =plt.subplots(nrows=2,ncols=4, figsize=(16,8))\n    for i in range(2):\n        for j in range(4):\n            sns.boxplot(x = df[columns[count]], palette=\"Wistia\",ax=ax[i][j])\n            count = count+1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"boxplot_for_outlier(data,numerical_columns)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(data[numerical_columns].corr(), annot=True, linewidths=0.5,linecolor=\"black\", fmt= '.2f',ax=ax,cmap=\"coolwarm\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.gender.replace('Unknown/Invalid', np.nan , inplace=True)\ndata.dropna(subset=['gender'], how='all', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.gender.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(nrows=1,ncols=2, figsize=(12,5))\nlabels=['Female','Male']\nsns.countplot(x=data.gender, data=data, palette=\"pastel\",ax=ax[0], edgecolor=\".3\")\ndata.gender.value_counts().plot.pie(autopct=\"%1.2f%%\", ax=ax[1], colors=['#66a3ff','#facc99'], \n                                        labels=labels, explode = (0, 0.05), startangle=120,\n                                        textprops={'fontsize': 12, 'color':'#0a0a00'})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gender, Age and Race Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual_list = ['gender','age','race']\nfig, ax =plt.subplots(nrows=1,ncols=3,figsize=(24,8))\ncount =0\nfor i in visual_list:\n    sns.countplot(data[i], hue=data.readmitted, palette='YlOrBr', ax=ax[count]);\n    count = count+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Examination and visualization of the effect of the target variable on insulin variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(by = \"insulin\").readmitted.mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(figsize=(10,4))\nsns.countplot(x=\"insulin\", hue=\"readmitted\", data=data, palette=\"YlOrBr\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization of the insulin variable according to the age variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_list = list(data.age.unique())\nsns.catplot(x=\"insulin\", hue=\"age\", data=data, kind=\"count\", height=6, aspect=2, palette=\"gnuplot\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"3\"></a>3. Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"## Missing Value Filling"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"race\"].fillna(data[\"race\"].mode()[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"race\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.loc[~data.discharge_disposition_id.isin([11,13,14,19,20,21])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Diagnostics 1-2-3 Transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"diag_list = ['diag_1','diag_2','diag_3']\n\nfor col in diag_list:\n    data[col].fillna('NaN', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef transformFunc(value):\n    value = re.sub(\"V[0-9]*\", \"0\", value) # V \n    value = re.sub(\"E[0-9]*\", \"0\", value) # E \n    value = re.sub('NaN', \"-1\", value) # Nan \n    return value\n\ndef transformCategory(value):\n    if value>=390 and value<=459 or value==785:\n        category = 'Circulatory'\n    elif value>=460 and value<=519 or value==786:\n        category = 'Respiratory'\n    elif value>=520 and value<=579 or value==787:\n        category = 'Digestive'\n    elif value==250:\n        category = 'Diabetes'\n    elif value>=800 and value<=999:\n        category = 'Injury'          \n    elif value>=710 and value<=739:\n        category = 'Musculoskeletal'   \n    elif value>=580 and value<=629 or value==788:\n        category = 'Genitourinary'\n    elif value>=140 and value<=239 :\n        category = 'Neoplasms'\n    elif value==-1:\n        category = 'NAN'\n    else :\n        category = 'Other'\n\n    return category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in diag_list:\n    data[col] = data[col].apply(transformFunc)\n    data[col] = data[col].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in diag_list:\n    data[col] = data[col].apply(transformCategory)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of Diag_1, Diag_2 and Diag_3 Variables by Target Variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(nrows=3,ncols=1,figsize=(15,12))\ncount =0\nfor i in diag_list:\n    sns.countplot(data[i], hue=data.readmitted, palette='Spectral', ax=ax[count], order = data[i].value_counts().index);\n    count = count+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Local Outlier Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\nclf = LocalOutlierFactor(n_neighbors = 2 , contamination = 0.1)\nclf.fit_predict(data[numerical_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores = clf.negative_outlier_factor_\ndf_scores[0:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sort(df_scores)[0:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold_value = np.sort(df_scores)[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_tf = df_scores > threshold_value\noutlier_tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = data[df_scores > threshold_value]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[df_scores < threshold_value]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom encoding for the 21 Drug Features\ndrugs = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'pioglitazone',\n        'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide', 'metformin-pioglitazone',\n        'metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin', 'troglitazone', 'tolbutamide', 'acetohexamide']\n\nfor col in drugs:\n    data[col] = data[col].replace(['No','Steady','Up','Down'],[0,1,1,1])\n    data[col] = data[col].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A1Cresult and max_glu_serum\ndata['A1Cresult'] = data['A1Cresult'].replace(['>7','>8','Norm','None'],[1,1,0,-99])\ndata['max_glu_serum'] = data['max_glu_serum'].replace(['>200','>300','Norm','None'],[1,1,0,-99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot Encoding Race and Id's \none_hot_data = pd.get_dummies(data, columns=['race'], prefix=[\"enc\"])\n\ncolumns_ids = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']\n\none_hot_data[columns_ids] = one_hot_data[columns_ids].astype('str')\none_hot_data = pd.get_dummies(one_hot_data, columns=columns_ids)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"4\"></a>4. Train-Test Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = one_hot_data.copy()\nX = df.drop(columns=\"readmitted\", axis=1)\nY = df.readmitted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_enc = OrdinalEncoder()\nX_train.age = ordinal_enc.fit_transform(X_train.age.values.reshape(-1, 1))\nX_test.age = ordinal_enc.transform(X_test.age.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in diag_list:\n    label_enc = LabelEncoder()\n    X_train[col] = label_enc.fit_transform(X_train[col])\n    X_test[col] = label_enc.fit_transform(X_test[col]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary = ['change', 'diabetesMed', 'gender']\n\nfrom category_encoders import BinaryEncoder\nbinary_enc = BinaryEncoder(cols=binary)\nbinary_enc.fit_transform(X_train)\nX_train = binary_enc.fit_transform(X_train)\nX_test = binary_enc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resampling techniques — Undersample majority class\n\nSince we have an unbalanced dataset, We will use sampling technique."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\nX = pd.concat([X_train, y_train], axis=1)\n\nnot_readmitted = X[X.readmitted==0]\nreadmitted = X[X.readmitted==1]\n\nnot_readmitted_sampled = resample(not_readmitted,\n                                replace = False, \n                                n_samples = len(readmitted),\n                                random_state = 42)\n\ndownsampled = pd.concat([not_readmitted_sampled, readmitted])\n\ndownsampled.readmitted.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train = downsampled.readmitted\nX_train = downsampled.drop('readmitted', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-Validation Splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"5\"></a>5. Modelling"},{"metadata":{},"cell_type":"markdown","source":"## Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score,f1_score\nfrom sklearn.metrics import confusion_matrix as cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_specificity(y_actual, y_pred, thresh):\n    # calculates specificity\n    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n\ndef print_report(y_actual, y_pred, thresh):\n    \n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    precision = precision_score(y_actual, (y_pred > thresh))\n    fscore = f1_score(y_actual,(y_pred > thresh) )\n    specificity = calc_specificity(y_actual, y_pred, thresh)\n    print('AUC:%.3f'%auc)\n    print('accuracy:%.3f'%accuracy)\n    print('recall:%.3f'%recall)\n    print('precision:%.3f'%precision)\n    print('fscore:%.3f'%fscore)\n    print('specificity:%.3f'%specificity)\n    print(' ')\n    return auc, accuracy, recall, precision,fscore, specificity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresh = 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Selection: Baseline Models"},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model = LogisticRegression(solver = \"liblinear\",class_weight=\"balanced\",random_state = 42).fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_preds = log_model.predict_proba(X_train)[:,1]\ny_val_preds = log_model.predict_proba(X_val)[:,1]\n\nprint(\"Logistic Regression\")\nprint('Training:')\nlr_train_auc, lr_train_accuracy, lr_train_recall, \\\n    lr_train_precision, lr_train_fscore, lr_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nlr_val_auc, lr_val_accuracy, lr_val_recall, \\\n    lr_val_precision,lr_val_fscore, lr_val_specificity = print_report(y_val,y_val_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\npredictions = log_model.predict(X_train)\ntrain_score = round(accuracy_score(y_train, predictions), 3)\ncm_train = cm(y_train, predictions)\n\npredictions = log_model.predict(X_val)\nval_score = round(accuracy_score(y_val, predictions), 3)\ncm_val = cm(y_val, predictions)\n\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \nsns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\nax1.set_xlabel('Predicted Values')\nax1.set_ylabel('Actual Values')\nax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\nsns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\nax2.set_xlabel('Predicted Values')\nax2.set_ylabel('Actual Values')\nax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest_model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=100, max_depth=3)\nrandom_forest_model.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"y_train_preds = random_forest_model.predict_proba(X_train)[:,1]\ny_val_preds = random_forest_model.predict_proba(X_val)[:,1]\n\nprint(\"Random Forest\")\nprint('Training:')\nrf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision,rf_train_fscore, rf_train_specificity =print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nrf_val_auc, rf_val_accuracy, rf_val_recall, rf_val_precision,rf_val_fscore, rf_val_specificity = print_report(y_val,y_val_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\npredictions = random_forest_model.predict(X_train)\ntrain_score = round(accuracy_score(y_train, predictions), 3)\ncm_train = cm(y_train, predictions)\n\npredictions = random_forest_model.predict(X_val)\nval_score = round(accuracy_score(y_val, predictions), 3)\ncm_val = cm(y_val, predictions)\n\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \nsns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\nax1.set_xlabel('Predicted Values')\nax1.set_ylabel('Actual Values')\nax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\nsns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\nax2.set_xlabel('Predicted Values')\nax2.set_ylabel('Actual Values')\nax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_model = GradientBoostingClassifier(random_state=42)\ngradient_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_preds = gradient_model.predict_proba(X_train)[:,1]\ny_val_preds = gradient_model.predict_proba(X_val)[:,1]\n\nprint(\"Gradient Boosing\")\nprint('Training:')\ngbc_train_auc, gbc_train_accuracy, gbc_train_recall, gbc_train_precision,gbc_train_fscore, gbc_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\ngbc_val_auc, gbc_val_accuracy, gbc_val_recall, gbc_val_precision, gbc_val_fscore, gbc_val_specificity = print_report(y_val,y_val_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\npredictions = gradient_model.predict(X_train)\ntrain_score = round(accuracy_score(y_train, predictions), 3)\ncm_train = cm(y_train, predictions)\n\npredictions = gradient_model.predict(X_val)\nval_score = round(accuracy_score(y_val, predictions), 3)\ncm_val = cm(y_val, predictions)\n\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \nsns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\nax1.set_xlabel('Predicted Values')\nax1.set_ylabel('Actual Values')\nax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\nsns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\nax2.set_xlabel('Predicted Values')\nax2.set_ylabel('Actual Values')\nax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBOOST Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = XGBClassifier(random_state=42, n_jobs=-1,max_depth=3)\nxgb_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_preds = xgb_model.predict_proba(X_train)[:,1]\ny_val_preds = xgb_model.predict_proba(X_val)[:,1]\n\nprint(\"XGBOOST\")\ny_train_preds = gradient_model.predict_proba(X_train)[:,1]\ny_val_preds = gradient_model.predict_proba(X_val)[:,1]\n\nprint(\"Gradient Boosing\")\nprint('Training:')\nxgb_train_auc, xgb_train_accuracy, xgb_train_recall, xgb_train_precision, xgb_train_fscore, xgb_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nxgb_val_auc, xgb_val_accuracy, xgb_val_recall, xgb_val_precision,xgb_val_fscore, xgb_val_specificity = print_report(y_val,y_val_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\npredictions = xgb_model.predict(X_train)\ntrain_score = round(accuracy_score(y_train, predictions), 3)\ncm_train = cm(y_train, predictions)\n\npredictions = xgb_model.predict(X_val)\nval_score = round(accuracy_score(y_val, predictions), 3)\ncm_val = cm(y_val, predictions)\n\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \nsns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\nax1.set_xlabel('Predicted Values')\nax1.set_ylabel('Actual Values')\nax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\nsns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\nax2.set_xlabel('Predicted Values')\nax2.set_ylabel('Actual Values')\nax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Light-GBM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nlgbm_model = LGBMClassifier(random_state = 42,max_depth=3)\nlgbm_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_preds = lgbm_model.predict_proba(X_train)[:,1]\ny_val_preds = lgbm_model.predict_proba(X_val)[:,1]\n\nprint(\"LGBM\")\nprint('Training:')\nlgbm_train_auc, lgbm_train_accuracy,lgbm_train_recall, lgbm_train_precision,lgbm_train_fscore,lgbm_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nlgbm_val_auc, lgbm_val_accuracy, lgbm_val_recall, lgbm_val_precision,lgbm_val_fscore,lgbm_val_specificity = print_report(y_val,y_val_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\npredictions = lgbm_model.predict(X_train)\ntrain_score = round(accuracy_score(y_train, predictions), 3)\ncm_train = cm(y_train, predictions)\n\npredictions = lgbm_model.predict(X_val)\nval_score = round(accuracy_score(y_val, predictions), 3)\ncm_val = cm(y_val, predictions)\n\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \nsns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\nax1.set_xlabel('Predicted Values')\nax1.set_ylabel('Actual Values')\nax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\nsns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\nax2.set_xlabel('Predicted Values')\nax2.set_ylabel('Actual Values')\nax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CATBOOST Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_model = CatBoostClassifier(random_state = 42, max_depth=3)\ncat_model.fit(X_train, y_train,verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_preds = cat_model.predict_proba(X_train)[:,1]\ny_val_preds = cat_model.predict_proba(X_val)[:,1]\n\nprint(\"CATBOOST\")\nprint('Training:')\ncatb_train_auc, catb_train_accuracy,catb_train_recall, catb_train_precision,catb_train_fscore,catb_train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\ncatb_val_auc,catb_val_accuracy, catb_val_recall, catb_val_precision,catb_val_fscore,catb_val_specificity = print_report(y_val,y_val_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\n\npredictions = cat_model.predict(X_train)\ntrain_score = round(accuracy_score(y_train, predictions), 3)\ncm_train = cm(y_train, predictions)\n\npredictions = cat_model.predict(X_val)\nval_score = round(accuracy_score(y_val, predictions), 3)\ncm_val = cm(y_val, predictions)\n\nfig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) \nsns.heatmap(cm_train, annot=True, fmt=\".0f\",ax=ax1)\nax1.set_xlabel('Predicted Values')\nax1.set_ylabel('Actual Values')\nax1.set_title('Train Accuracy Score: {0}'.format(train_score), size = 15)\nsns.heatmap(cm_val, annot=True, fmt=\".0f\",ax=ax2)\nax2.set_xlabel('Predicted Values')\nax2.set_ylabel('Actual Values')\nax2.set_title('Validation Accuracy Score: {0}'.format(val_score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyze results baseline models"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_models_results = pd.DataFrame({'classifier':['LOJ','LOJ','RF','RF','GBM','GBM','XGB','XGB','LGBM','LGBM','CATB','CATB'],\n                           'data_set':['train','val']*6,\n                          'auc':[lr_train_auc, lr_val_auc,rf_train_auc,rf_val_auc,gbc_train_auc,gbc_val_auc,xgb_train_auc,xgb_val_auc,lgbm_train_auc,lgbm_val_auc,catb_train_auc,catb_val_auc,],\n                          'accuracy':[lr_train_accuracy, lr_val_accuracy,rf_train_accuracy,rf_val_accuracy,gbc_train_accuracy,gbc_val_accuracy,xgb_train_accuracy,xgb_val_accuracy,lgbm_train_accuracy,lgbm_val_accuracy,catb_train_accuracy,catb_val_accuracy,],\n                          'recall':[lr_train_recall, lr_val_recall,rf_train_recall,rf_val_recall,gbc_train_recall,gbc_val_recall,xgb_train_recall,xgb_val_recall,lgbm_train_recall,lgbm_val_recall,catb_train_recall,catb_val_recall,],\n                          'precision':[lr_train_precision, lr_val_precision,rf_train_precision,rf_val_precision,gbc_train_precision,gbc_val_precision,xgb_train_precision,xgb_val_precision,lgbm_train_precision,lgbm_val_precision,catb_train_precision,catb_val_precision,],\n                          'fscore':[lr_train_fscore, lr_val_fscore,rf_train_fscore,rf_val_fscore,gbc_train_fscore,gbc_val_fscore,xgb_train_fscore,xgb_val_fscore,lgbm_train_fscore,lgbm_val_fscore,catb_train_fscore,catb_val_fscore,],\n                          'specificity':[lr_train_specificity, lr_val_specificity,rf_train_specificity,rf_val_specificity,gbc_train_specificity,gbc_val_specificity,xgb_train_specificity,xgb_val_specificity,lgbm_train_specificity,lgbm_val_specificity,catb_train_specificity,catb_val_specificity,]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_models_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6)) \nax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=base_models_results)\nax.set_xlabel('Classifier',fontsize = 15)\nax.set_ylabel('AUC', fontsize = 15)\nax.tick_params(labelsize=15)\n\n# Put the legend out of the figure\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"6\"></a>6. Feature Importance"},{"metadata":{},"cell_type":"markdown","source":"## Feature İmportance with Light-GBM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nplt.rcParams[\"figure.figsize\"] = (18, 10)\nlgb.plot_importance(lgbm_model)\n\nfeature_imp = pd.Series(lgbm_model.feature_importances_, index = X_train.columns)\nbest_features = feature_imp.nlargest(25)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"best_features.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_importance = X_train[best_features.index]\nX_val_importance = X_val[best_features.index]\nX_test_importance = X_test[best_features.index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"7\"></a>7. Hyperparameter Tuning"},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {\"max_depth\": [2,5,8],\n             \"n_estimators\": [100,200,500,700],\n             \"max_features\": [3,5,8],\n             \"min_samples_split\":[2,5,10]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rf_cv_model = GridSearchCV(rf, rf_params, cv=3, n_jobs=-1, verbose=2).fit(X_train_importance, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"rf_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rf_tuned =RandomForestClassifier(max_depth=5,\n                                 max_features=5,\n                                 min_samples_split=5,\n                                 n_estimators=500).fit(X_train_importance, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_preds = random_forest_model.predict_proba(X_train)[:,1]\ny_val_preds = random_forest_model.predict_proba(X_val)[:,1]\n\nprint('Baseline Random Forest')\nrf_train_auc_base = roc_auc_score(y_train, y_train_preds)\nrf_val_auc_base = roc_auc_score(y_val, y_val_preds)\n\nprint('Training AUC:%.3f'%(rf_train_auc_base))\nprint('Validation AUC:%.3f'%(rf_val_auc_base))\n\nprint('Optimized Random Forest')\ny_train_preds_random = rf_tuned.predict_proba(X_train_importance)[:,1]\ny_val_preds_random = rf_tuned.predict_proba(X_val_importance)[:,1]\n\nrf_train_auc = roc_auc_score(y_train, y_train_preds_random)\nrf_val_auc = roc_auc_score(y_val, y_val_preds_random)\n\nprint('Training AUC:%.3f'%(rf_train_auc))\nprint('Validation AUC:%.3f'%(rf_val_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ligth-GBM Classifier Model Tuning"},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm=LGBMClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm_params = {\"learning_rate\":[0.01,0.1,0.05],\n              \"n_estimators\": [100,200,500],\n               \"subsample\":[0.1,0.2],\n              \"max_depth\":[2,3,5,8]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm_cv_model=GridSearchCV(lgbm,lgbm_params,cv=3,n_jobs=-1,verbose=2).fit(X_train_importance,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lgbm_tuned=LGBMClassifier(learning_rate=0.1,max_depth=2,n_estimators=200,subsample= 0.1).fit(X_train_importance, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_preds = lgbm_model.predict_proba(X_train)[:,1]\ny_val_preds = lgbm_model.predict_proba(X_val)[:,1]\n\nprint('Baseline LGBM')\nlgbm_train_auc_base = roc_auc_score(y_train, y_train_preds)\nlgbm_val_auc_base = roc_auc_score(y_val, y_val_preds)\n\nprint('Training AUC:%.3f'%(lgbm_train_auc_base))\nprint('Validation AUC:%.3f'%(lgbm_val_auc_base))\n\nprint('Optimized LGBM')\ny_train_preds_lgbm = lgbm_tuned.predict_proba(X_train_importance)[:,1]\ny_val_preds_lgbm = lgbm_tuned.predict_proba(X_val_importance)[:,1]\n\nlgbm_train_auc = roc_auc_score(y_train, y_train_preds_lgbm)\nlgbm_val_auc = roc_auc_score(y_val, y_val_preds_lgbm)\n\nprint('Training AUC:%.3f'%(lgbm_train_auc))\nprint('Validation AUC:%.3f'%(lgbm_val_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CATBOOST Classifier Model Tuning"},{"metadata":{"trusted":false},"cell_type":"code","source":"catb=CatBoostClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"catb_params={\"iterations\":[200,500,1000],\n            \"learning_rate\":[0.05,0.1],\n            \"depth\":[4,5,8]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"catb_cv_model=GridSearchCV(catb,catb_params, cv=3, n_jobs=-1,  verbose=2).fit(X_train_importance,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"catb_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"catb_tuned =CatBoostClassifier(depth=5,iterations=200,learning_rate=0.05).fit(X_train_importance, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train_preds = cat_model.predict_proba(X_train)[:,1]\ny_valid_preds = cat_model.predict_proba(X_val)[:,1]\n\nprint('Baseline CATBOOST')\ncatb_train_auc_base = roc_auc_score(y_train, y_train_preds)\ncatb_val_auc_base = roc_auc_score(y_val, y_val_preds)\n\nprint('Training AUC:%.3f'%(catb_train_auc_base))\nprint('Validation AUC:%.3f'%(catb_val_auc_base))\n\nprint('Optimized CATBOOST')\ny_train_preds_catb = catb_tuned.predict_proba(X_train_importance)[:,1]\ny_val_preds_catb = catb_tuned.predict_proba(X_val_importance)[:,1]\n\ncatb_train_auc = roc_auc_score(y_train, y_train_preds_catb)\ncatb_val_auc = roc_auc_score(y_val, y_val_preds_catb)\n\nprint('Training AUC:%.3f'%(catb_train_auc))\nprint('Validation AUC:%.3f'%(catb_val_auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Tuning Results"},{"metadata":{"trusted":false},"cell_type":"code","source":"data_results = pd.DataFrame({'classifier':['RF','RF','LGBM','LGBM','CATB','CATB'],\n                           'data_set':['base','optimized']*3,\n                          'auc':[rf_val_auc_base,rf_val_auc,\n                                 lgbm_val_auc_base,lgbm_val_auc,\n                                 catb_val_auc_base,catb_val_auc,],\n                          })","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ax = sns.barplot(x=\"classifier\", y=\"auc\", hue=\"data_set\", data=data_results)\nax.set_xlabel('Classifier',fontsize = 15)\nax.set_ylabel('AUC', fontsize = 15)\nax.tick_params(labelsize=15)\n# Put the legend out of the figure\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Roc-Auc Comparison of Models"},{"metadata":{"trusted":false},"cell_type":"code","source":"classifiers = [ rf_tuned,\n                lgbm_tuned,\n                catb_tuned]\n\n# Define a result table as a DataFrame\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n\n# Train the models and record the results\nfor cls in classifiers:\n    yproba = cls.predict_proba(X_test_importance)[::,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\n\n# Set name of the classifiers as index labels\nresult_table.set_index('classifiers', inplace=True)\nresult_table.sort_values('auc',ascending=False,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='black', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"False Positive Rate\", fontsize=14)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=14)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':10}, loc='lower right')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def test_scores(y_actual, y_pred, thresh):\n    \n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    \n    return auc, accuracy, recall\n\n\nclassifiers = [ rf_tuned,\n                lgbm_tuned,\n                catb_tuned]\n\n# Define a result table as a DataFrame\ntest_result = pd.DataFrame(columns=['classifiers', 'accuracy','recall','auc'])\n\n# Train the models and record the results\nfor cls in classifiers:\n    y_test_preds = cls.predict_proba(X_test_importance)[:,1]\n    \n    test_auc, test_accuracy, test_recall = test_scores(y_test,y_test_preds, 0.5) # thresh = 0.5\n    \n    test_result = test_result.append({'classifiers':cls.__class__.__name__,\n                                        'accuracy':test_accuracy, \n                                        'recall':test_recall, \n                                        'auc':test_auc}, ignore_index=True)\n\n\n# Set name of the classifiers as index labels\ntest_result.set_index('classifiers', inplace=True)\ntest_result.sort_values('auc',ascending=False,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import plotly.graph_objs as go\n\ntrace1=go.Bar(\n                x=test_result.index,\n                y=test_result.accuracy,\n                name=\"Accuracy\",\n                marker= dict(color = 'rgba(100, 20, 30, 0.7)',\n                            line=dict(color='rgb(0,0,0)',width=1.9)),\n                text=round(test_result.accuracy,3),textposition='auto')\ntrace2=go.Bar(\n                x=test_result.index,\n                y=test_result.recall,\n                name=\"Recall\",\n                marker=dict(color = 'rgba(56, 140, 200, 0.7)',\n                           line=dict(color='rgb(0,0,0)',width=1.9)),\n                text=round(test_result.recall,3),textposition='auto')\ntrace3=go.Bar(\n                x=test_result.index,\n                y=test_result.auc,\n                name=\"AUC\",\n                marker=dict(color = 'rgba(120, 180, 20, 0.7)',\n                           line=dict(color='rgb(0,0,0)',width=1.9)),\n                text=round(test_result.auc,3),textposition='auto')\n\nedit_df=[trace1,trace2,trace3]\nlayout = { 'barmode':'group',\n           'title_text':'Accuracy, Recall and AUC Plot Readmitted' }\n\nfig= go.Figure(data=edit_df,layout=layout)\n#plt.savefig('graph.png')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"8\"></a>8. Prediction Result"},{"metadata":{},"cell_type":"markdown","source":"## Model Selection: Best Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_model = catb_tuned\n\ny_train_preds = best_model.predict_proba(X_train_importance)[:,1]\ny_valid_preds = best_model.predict_proba(X_val_importance)[:,1]\ny_test_preds = best_model.predict_proba(X_test_importance)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"thresh = 0.5\n\nprint('Training:')\ntrain_auc, train_accuracy, train_recall, train_precision, train_fscore, train_specificity = print_report(y_train,y_train_preds, thresh)\nprint('Validation:')\nval_auc, val_accuracy, val_recall, val_precision, val_fscore,val_specificity = print_report(y_val,y_val_preds, thresh)\nprint('Test:')\ntest_auc, test_accuracy, test_recall, test_precision, test_fscore, test_specificity = print_report(y_test,y_test_preds, thresh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import roc_curve \n\nfpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_preds)\nauc_train = roc_auc_score(y_train, y_train_preds)\n\nfpr_val, tpr_val, thresholds_val = roc_curve(y_val, y_val_preds)\nauc_val = roc_auc_score(y_val, y_val_preds)\n\nfpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_preds)\nauc_test = roc_auc_score(y_test, y_test_preds)\n\nfig, ax = plt.subplots(figsize=(10,6)) \nplt.plot(fpr_train, tpr_train, 'r-',label ='Train AUC:%.3f'%auc_train)\nplt.plot(fpr_val, tpr_val, 'b-',label ='Valid AUC:%.3f'%auc_val)\nplt.plot(fpr_test, tpr_test, 'g-',label ='Test AUC:%.3f'%auc_test)\nplt.plot([0,1],[0,1],'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"9\"></a>9. Conclusion\n\nBased on the Auc results observed in the best classifier train, validation and test set results. It was observed that the best model was Catboost. The test result was almost %67 succesful. it was concluded that %67 of the patients who returned to the patient within 30 days returned and predicted correctly."},{"metadata":{},"cell_type":"markdown","source":"# <a id=\"10\"></a>10. References\n\n* https://www.kaggle.com/iabhishekofficial/prediction-on-hospital-readmission\n* https://github.com/andrewwlong/diabetes_readmission"},{"metadata":{},"cell_type":"markdown","source":"### <p style='font-weight:bold;color:#123456'><i>I hope you find this kernel useful. If you like it please do an upvote.</i><p>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}