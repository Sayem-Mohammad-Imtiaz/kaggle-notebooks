{"cells":[{"metadata":{},"cell_type":"markdown","source":"**МОДЕЛЬ ПРОГНОЗИРОВАНИЯ ВОЗВРАТА КРЕДИТОВ**"},{"metadata":{},"cell_type":"markdown","source":"Импортируем все необходимые библиотеки и функции"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np,collections as cl, matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.multiclass import unique_labels","execution_count":152,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для начала считаем данные из файла"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/hmeq.csv')","execution_count":153,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В выборке есть пустые значения. Для простоты удалим все строки, в которых есть пустые значения."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(how='any', inplace=True)","execution_count":154,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Далее применим базовые процедуры предобработки данных, такие как нормализация и дискретизация. Нормализовывать мы будем все числовые признаки по Z-показателю (масштабирование данных на основе среднего значения признака и стандартного отклонения). После нормализации разобъем числовые признаки на группы равной ширины при помощи функции Cut. "},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"for column in data:\n    if column not in ['BAD','REASON','JOB']:         \n        mean=data[column].mean()       \n        std=data[column].std()       \n        data[column]=[(x-mean)/std for x in data[column]]\n        data[column]=pd.cut(data[column],20)    ","execution_count":155,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Используем LabelEncoder, чтобы заменить группу её номером."},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nfor column in data.columns:\n    encc = le.fit(data[column].astype(str))  \n    tr = le.transform(data[column].astype(str))\n    data[column]=tr","execution_count":156,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Запишем целевой признак в отдельную переменную и удалим соотвествующий столбец из первоначальной выборки"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.copy()\nbad=data['BAD']\ndel data['BAD']","execution_count":157,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разделим выборку на тренировочную и тестирующую (33% от изначального размера выборки)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data, bad, test_size=0.33, random_state=42)   ","execution_count":158,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Используем 3 классификатора для оценки работы модели. Первый из них - это DesicionTreeClassifier. Для оценки работы классификаторов мы используем accuracy, precision, recall и f1-score."},{"metadata":{"trusted":true},"cell_type":"code","source":"clrTree = DecisionTreeClassifier(max_depth = 3)\nclrTree = clrTree.fit(x_train, y_train)\npred = list(clrTree.predict(x_test))   \nprecision=precision_score(y_test,pred)\nrecall=recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nprint(\"Accuracy decisiontree = {0:.5f}\".format(clrTree.score(x_test,y_test)))\nprint(\"Precision= {0:.5f}\\nRecall = {1:.5f}\\nF1={2:.5f}\\n\".format(precision,recall,f1))","execution_count":159,"outputs":[{"output_type":"stream","text":"Accuracy decisiontree = 0.93699\nPrecision= 0.94118\nRecall = 0.32000\nF1=0.47761\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Аналогичный код и для классификатора KNeighborsClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh = KNeighborsClassifier(n_neighbors=5)\nneigh.fit(x_train, y_train) \npred = list(neigh.predict(x_test))  \nprecision=precision_score(y_test,pred)\nrecall=recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nprint(\"Accuracy KNeighborsClassifier = {0:.5f}\".format(neigh.score(x_test,y_test)))\nprint(\"Precision= {0:.5f}\\nRecall = {1:.5f}\\nF1={2:.5f}\\n\".format(precision,recall,f1))","execution_count":160,"outputs":[{"output_type":"stream","text":"Accuracy KNeighborsClassifier = 0.92619\nPrecision= 0.87500\nRecall = 0.21000\nF1=0.33871\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Третьим классификатором возьмем RandomForestClassifier"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(max_depth=10)\nrf.fit(x_train, y_train)\npred = list(rf.predict(x_test))  \nprecision=precision_score(y_test,pred)\nrecall=recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nprint(\"Accuracy RandomForestClassifier = {0:.5f}\".format(rf.score(x_test,y_test)))\nprint(\"Precision= {0:.5f}\\nRecall = {1:.5f}\\nF1={2:.5f}\\n\".format(precision,recall,f1))","execution_count":161,"outputs":[{"output_type":"stream","text":"Accuracy RandomForestClassifier = 0.94149\nPrecision= 0.97297\nRecall = 0.36000\nF1=0.52555\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Все три классификатора дают довольно неплохие результаты по accuracy, однако recall оставляет желать лучшего. В частности, это можно объяснить тем, что значения целевой переменной не являются сбалансированными. Значения, соотвествующие возврату кредита, составляют около 80% от всех значений целевой переменной. Для улучшения recall прибегнем к одной фишечке. В данной модели 0 - кредит будет возвращен, 1 - кредит не вернут. Заменим нули на единицы, а единицы на нули. В таком случае 0 будет означать, что кредит не вернут, а 1, соотвественно, что кредит вернут. Также стоит обратить внимание, что среди трех классификаторов наилучший результат дает RandomForest."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_index=data1[data1[\"BAD\"]==0].index\none_index=data1[data1[\"BAD\"]==1].index\ndata1['BAD'].loc[zero_index] = 1\ndata1['BAD'].loc[one_index] = 0\nbad=data1['BAD']\ndel data1['BAD']","execution_count":162,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Повторим тот же эксперимент с теми же классификаторами."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data1, bad, test_size=0.33, random_state=42)   \n\nclrTree = DecisionTreeClassifier(max_depth = 3)\nclrTree = clrTree.fit(x_train, y_train)\npred = list(clrTree.predict(x_test))   \nprecision=precision_score(y_test,pred)\nrecall=recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nprint(\"Accuracy decisiontree = {0:.5f}\".format(clrTree.score(x_test,y_test)))\nprint(\"Precision= {0:.5f}\\nRecall = {1:.5f}\\nF1={2:.5f}\\n\".format(precision,recall,f1))\n\nneigh = KNeighborsClassifier(n_neighbors=5)\nneigh.fit(x_train, y_train) \npred = list(neigh.predict(x_test))  \nprecision=precision_score(y_test,pred)\nrecall=recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nprint(\"Accuracy KNeighborsClassifier = {0:.5f}\".format(neigh.score(x_test,y_test)))\nprint(\"Precision= {0:.5f}\\nRecall = {1:.5f}\\nF1={2:.5f}\\n\".format(precision,recall,f1))\n\nrf = RandomForestClassifier(max_depth=10)\nrf.fit(x_train, y_train)\npred = list(rf.predict(x_test))  \nprecision=precision_score(y_test,pred)\nrecall=recall_score(y_test,pred)\nf1 = f1_score(y_test,pred)\nprint(\"Accuracy RandomForestClassifier = {0:.5f}\".format(rf.score(x_test,y_test)))\nprint(\"Precision= {0:.5f}\\nRecall = {1:.5f}\\nF1={2:.5f}\\n\".format(precision,recall,f1))","execution_count":163,"outputs":[{"output_type":"stream","text":"Accuracy decisiontree = 0.93699\nPrecision= 0.93686\nRecall = 0.99802\nF1=0.96648\n\nAccuracy KNeighborsClassifier = 0.92619\nPrecision= 0.92732\nRecall = 0.99703\nF1=0.96092\n\nAccuracy RandomForestClassifier = 0.94329\nPrecision= 0.94299\nRecall = 0.99802\nF1=0.96973\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Невооруженным глазом заметно, что recall заметно вырос, что повлияло и на f1-score. Примененная фишечка сделала модели прогнозирования возврата кредита намного лучше. Если сравнить классификаторы между собой, то снова лучший результат выдал RandomForest, однако в этот раз f1-score всех трех классификаторов не так сильно отличаются, как в предыдущем эксперименте."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}