{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import packages and libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english')) \nfrom nltk.tokenize import word_tokenize\nfrom nltk.util import ngrams\nimport gensim\nimport re\nfrom collections import Counter, defaultdict\nfrom wordcloud import WordCloud, STOPWORDS\nRANDOM_SEED = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combine all the csv files and remove account identifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        df = pd.read_csv(os.path.join(dirname, filename), index_col=None, header=0)\n        df = df[(df['lang']=='en') & (df['country_code'] == 'US')]\n        row, cols = df.shape\n        date = [filename[0:10]]*row\n        df['date_of_tweet'] = date\n        tweets.append(df)\n        \ntweets_en_US = pd.concat(tweets, axis=0, ignore_index=True)\ndel tweets\n\n# random samples of tweets \nprint(tweets_en_US.text.sample(5))\n\n# print columns of dataframe\n# print(tweets_en_US.columns)\n\n#drop columns with user sensitive information \ntweets_en_US_encrypted =tweets_en_US.copy()\ntweets_en_US_encrypted.drop(['status_id','user_id','screen_name','source','reply_to_status_id',\n                                    'reply_to_user_id','is_retweet','place_full_name','place_type',\n                                    'reply_to_screen_name','is_quote','followers_count','friends_count',\n                                    'account_lang','account_created_at','verified'],axis=1, inplace = True)\nprint(tweets_en_US_encrypted.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\n**1. Let us begin by anayzing the length of tweets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_len = tweets_en_US_encrypted['text'].str.split().apply(lambda x: len(x))\n\nplt.figure(figsize = (6,6))\nsns.distplot(tweets_len, bins = 20, kde = 'False',)\nplt.xlabel('Length of Tweets')\nplt.title('Distribution of length of Tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The distribution for length of Tweets is a right-skewed one.*"},{"metadata":{},"cell_type":"markdown","source":"**2. Let us look at the distribution of Tweets over the days**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_en_US_encrypted.sort_values('date_of_tweet', inplace=True)\n\nplt.figure(figsize=(12,8))\nsns.countplot(y = tweets_en_US_encrypted['date_of_tweet'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Twitter users were tweeting much more actively at the end of March in comparison to the first 15 days of April*"},{"metadata":{},"cell_type":"markdown","source":"# Cleanup Tweets \n\nRemove Stopwords, Punctuations, Emoticons, URLS\n\nKeep Hashtags and Mentions (We will be using those later!)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\npunct = string.punctuation\n\nimport emoji\n\ndef deEmojify(text):\n    allchars = [str for str in text]\n    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n    clean_text = ' '.join([str for str in text.split() \n                           if not any(i in str for i in emoji_list)])\n    return clean_text\n\ndef removeURL(text):\n    clean_text = re.sub(r\"http\\S+\", \"\", text)\n    return clean_text\n\ndef tokenize_tweets(dataframe):\n    tokenized_data = []\n    for i,tweet in enumerate(dataframe['text']):\n        sentence = []\n        tweet = deEmojify(tweet)\n        tweet = removeURL(tweet)\n        for w in tweet.split():\n            if w.lower() not in stop_words and w not in punct and w!='&amp;':\n                sentence.append(w.lower())\n        dataframe['text'][i] = ' '.join(sentence)\n        tokenized_data.append(sentence)       \n    return tokenized_data, dataframe\n\ntweets_US_tokenized, tweets_en_US_encrypted = tokenize_tweets(tweets_en_US_encrypted)\nprint(tweets_en_US_encrypted['text'][:5])\nprint(tweets_US_tokenized[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\ndef show_WordCloud(data_list, title = None):\n    data_list_compiled = ''\n    data_list_compiled += \" \".join(data_list)+\" \"\n    wordcloud = WordCloud(background_color = 'white', max_words = 200, min_font_size = 8, max_font_size=40).generate(str(data_list_compiled))\n    \n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n    \ndef top_list_elements(list_data, N = 20):\n    \"\"\"returns a dictionary of hashtags and the number of times they have been used\"\"\"\n    count =Counter(list_data)\n    top_elements = dict(sorted(count.items(), key = lambda x:x[1], reverse = True)[:N])\n    return top_elements","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Let's look at the top Hashtags used.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_Hashtags(tokenized_data):\n    \"\"\" returns list of hashtags used \"\"\"\n    list_hashtag = []\n    for tweets in tokenized_data:\n        list_hashtag.append([w for w in tweets if w.startswith('#')])\n    return [item for sublist in list_hashtag for item in sublist]\n\ntweets_Hashtag = extract_Hashtags(tweets_US_tokenized)\ntop_N_Hashtags = top_list_elements(tweets_Hashtag, N=100)\n\nplt.figure(figsize = (10, 6))\nsns.barplot(x = list(top_N_Hashtags.values())[:20], y = list(top_N_Hashtags.keys())[:20])\nplt.show()\n\nplt.figure(figsize = (16, 16))\nshow_WordCloud(list(top_N_Hashtags.keys()))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Let's look at the top mentions.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_Mentions(tokenized_data):\n    \"\"\" returns list of mentions used \"\"\"\n    list_mentions = []\n    for tweets in tokenized_data:\n        list_mentions.append([w for w in tweets if w.startswith('@')])\n    return [item for sublist in list_mentions for item in sublist]\n\ntweets_mentions = extract_Mentions(tweets_US_tokenized)\ntop_N_Mentions = top_list_elements(tweets_mentions, N=50)\n\nplt.figure(figsize = (10, 6))\nsns.barplot(x = list(top_N_Mentions.values())[:20], y = list(top_N_Mentions.keys())[:20])\nplt.show()\n\nplt.figure(figsize = (16, 16))\nshow_WordCloud(list(top_N_Mentions.keys()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract the sentiments of these tweets\n\nCourtesy: Notebook by Kartik Mohan [https://www.kaggle.com/kartikmohan1999/covid19-sentiment-analysis](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntweets_en_US_encrypted['sentiment'] = ' '\ntweets_en_US_encrypted['polarity'] = None\nfor i,tweets in enumerate(tweets_en_US_encrypted.text) :\n    blob = TextBlob(tweets)\n    tweets_en_US_encrypted['polarity'][i] = blob.sentiment.polarity\n    if blob.sentiment.polarity > 0 :\n        tweets_en_US_encrypted['sentiment'][i] = 'positive'\n    elif blob.sentiment.polarity < 0 :\n        tweets_en_US_encrypted['sentiment'][i] = 'negative'\n    else :\n        tweets_en_US_encrypted['sentiment'][i] = 'neutral'\ntweets_en_US_encrypted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,8))\nsns.countplot(x = tweets_en_US_encrypted['date_of_tweet'], hue = 'sentiment', \n              data = tweets_en_US_encrypted, palette = 'cool', saturation = 0.5)\nplt.xticks(Rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The sentiment of tweeets is positive every day in the given period. However, towards mid April tweeter users were much less active and percentage of positive tweets diminished as well.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsns.distplot(tweets_en_US_encrypted['polarity'], bins = 30)\nplt.xlabel('Polarity',size = 15)\nplt.ylabel('Frequency',size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We can see a fatter tail of the polarity in the positive direction.* "},{"metadata":{"trusted":true},"cell_type":"code","source":"pos = tweets_en_US_encrypted['text'][tweets_en_US_encrypted['sentiment'] == 'positive']\nneutral = tweets_en_US_encrypted['text'][tweets_en_US_encrypted['sentiment'] == 'neutral']\nneg = tweets_en_US_encrypted['text'][tweets_en_US_encrypted['sentiment'] == 'negative']\n\ndef extract_list(dataframe):\n    data = []\n    for tweet in dataframe:\n        data.append(tweet.split())\n    return data\n\npos_list = extract_list(pos)\nneu_list = extract_list(neutral)\nneg_list = extract_list(neg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. See the top hashtags in tweets of different sentiments.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Hashtags in tweets of different sentiments\n\npos_Hashtag = extract_Hashtags(pos_list)\ntop_N_pos_Hashtags = top_list_elements(pos_Hashtag, N=100)\nplt.figure(figsize = (10,16))\nsns.barplot(x = list(top_N_pos_Hashtags.values())[49:], y = list(top_N_pos_Hashtags.keys())[49:], \n            palette = 'cool', saturation = 0.5)\nplt.title('Top 51-100 Positive Hashtags')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neu_Hashtag = extract_Hashtags(neu_list)\ntop_N_neu_Hashtags = top_list_elements(neu_Hashtag, N=100)\nplt.figure(figsize = (10,16))\nsns.barplot(x = list(top_N_neu_Hashtags.values())[49:], y = list(top_N_neu_Hashtags.keys())[49:], \n            palette = 'cool', saturation = 0.5)\nplt.title('Top 51-100 Neutral Hashtags')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_Hashtag = extract_Hashtags(neg_list)\ntop_N_neg_Hashtags = top_list_elements(neg_Hashtag, N=100)\nplt.figure(figsize = (10,16))\nsns.barplot(x = list(top_N_neg_Hashtags.values())[49:], y = list(top_N_neg_Hashtags.keys())[49:], \n            palette = 'cool', saturation = 0.5)\nplt.title('Top 51-100 Negative Hashtags')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Differences in hashtags used are apparent only if we skip the top 50 hashtags.*"},{"metadata":{},"cell_type":"markdown","source":"**6. See the top mentions in tweets of different sentiments.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the mentions in tweets of different sentiments\npos_mention = extract_Mentions(pos_list)\ntop_N_pos_Mentions = top_list_elements(pos_mention, N=200)\nplt.figure(figsize = (16,10))\nshow_WordCloud(top_N_pos_Mentions , 'POSITIVE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neu_mention = extract_Mentions(neu_list)\ntop_N_neu_Mentions = top_list_elements(neu_mention, N=200)\nplt.figure(figsize = (16,10))\nshow_WordCloud(top_N_neu_Mentions , 'NEUTRAL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_mention = extract_Mentions(neg_list)\ntop_N_neg_Mentions = top_list_elements(neg_mention, N=200)\nplt.figure(figsize = (16,10))\nshow_WordCloud(top_N_neg_Mentions , 'NEGATIVE')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**7. See the words used in tweets of different sentiments**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nshow_WordCloud(pos , 'POSITIVE')\n\nplt.figure(figsize = (10,10))\nshow_WordCloud(neutral , 'NEUTRAL')\n\nplt.figure(figsize = (10,10))\nshow_WordCloud(neg , 'NEGATIVE')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize similarity through t-SNE\n\nTrain a Word2Vec model using the given corpus"},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\n\ndef train_w2v(tokenized_corpus):\n    w2v_model = Word2Vec(min_count = 20, sample = 0.05, negative = 10)\n    w2v_model.build_vocab(tokenized_corpus)\n    w2v_model.train(tokenized_corpus, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n    print('Trained....')\n    return w2v_model\n\nw2v_model = train_w2v(tweets_US_tokenized)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perform t-SNE and visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\ndef tsne_plot(model, word_list):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in word_list:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_N_Hashtags = top_list_elements(extract_Hashtags(tweets_US_tokenized), N=200)\ntsne_plot(w2v_model, list(top_N_Hashtags.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_N_Mentions = top_list_elements(extract_Mentions(tweets_US_tokenized), N=200)\ntsne_plot(w2v_model, list(top_N_Mentions.keys()))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}