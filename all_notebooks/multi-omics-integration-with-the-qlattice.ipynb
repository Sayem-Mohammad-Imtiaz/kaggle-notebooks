{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Prediction of Breast Cancer Severity with Multi-Omics Data","metadata":{}},{"cell_type":"markdown","source":"Can the QLattice reveal hidden mechanisms underlying breast cancer severity using multi-omics data (mutations, copy numbes, gene expression and protein levels)? ","metadata":{}},{"cell_type":"markdown","source":"![Breast Cancer Paper](https://els-jbs-prod-cdn.jbs.elsevierhealth.com/cms/attachment/de466e25-32e8-48dd-8f69-cee69e28b345/fx1.jpg)","metadata":{}},{"cell_type":"markdown","source":"**The Dataset**\n\n* 705 breast tumour samples (611 patients survived, 94 patients died)\n","metadata":{}},{"cell_type":"markdown","source":"\nFour Data Types (n features):\n* Copy Number Variations (860)\n* Somatic Mutations (249)\n* Gene Expression (604)\n* Protein Expression (223)\n\n**Total: 1936 features**","metadata":{}},{"cell_type":"markdown","source":"![The Data Types](https://d1g9yur4m4naub.cloudfront.net/image-handler/ts/20210121043242/ri/673/picture/2021/1/shutterstock_695774158.jpg)","metadata":{}},{"cell_type":"markdown","source":"The dataset is described in detail in the paper: https://www.cell.com/cell/fulltext/S0092-8674(15)01195-2.","metadata":{}},{"cell_type":"markdown","source":"# Python imports\nIn this notebook we will use only three python modules: the `feyn` module to access the QLattice, and the `pandas` module to access the data, and sklearn to split the data in test/train sets","metadata":{}},{"cell_type":"code","source":"#The feyn Python module is not installed on Kaggle by default so we have to pip install it first. \n#__Note__: the pip install will fail unless you enable *Internet* in the *settings* to the right --->\n!pip install feyn","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:50:34.524637Z","iopub.execute_input":"2021-07-10T04:50:34.525082Z","iopub.status.idle":"2021-07-10T04:50:44.188653Z","shell.execute_reply.started":"2021-07-10T04:50:34.525044Z","shell.execute_reply":"2021-07-10T04:50:44.187469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import feyn\nimport pandas as pd\nimport sklearn.model_selection","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:50:44.191161Z","iopub.execute_input":"2021-07-10T04:50:44.191482Z","iopub.status.idle":"2021-07-10T04:50:45.260349Z","shell.execute_reply.started":"2021-07-10T04:50:44.191451Z","shell.execute_reply":"2021-07-10T04:50:45.259272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the dataset","metadata":{}},{"cell_type":"code","source":"data = '/kaggle/input/brca-multiomics-tcga/data.csv'\ndf = pd.read_csv(data)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:50:45.26202Z","iopub.execute_input":"2021-07-10T04:50:45.262338Z","iopub.status.idle":"2021-07-10T04:50:45.798198Z","shell.execute_reply.started":"2021-07-10T04:50:45.262306Z","shell.execute_reply":"2021-07-10T04:50:45.796955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target balance\nLet's have a quick look at the balance of target variable","metadata":{}},{"cell_type":"code","source":"df[\"vital.status\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:51:30.471778Z","iopub.execute_input":"2021-07-10T04:51:30.472203Z","iopub.status.idle":"2021-07-10T04:51:30.48557Z","shell.execute_reply.started":"2021-07-10T04:51:30.472168Z","shell.execute_reply":"2021-07-10T04:51:30.484214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target variable is pretty unbalanced. Let's make sure we account for that when we split our data into train and test. We want to make sure to have the same ratio of cases/controls in both.","metadata":{}},{"cell_type":"code","source":"train, test = sklearn.model_selection.train_test_split(df,stratify=df[\"vital.status\"], train_size=.66, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:51:31.305627Z","iopub.execute_input":"2021-07-10T04:51:31.306121Z","iopub.status.idle":"2021-07-10T04:51:31.331699Z","shell.execute_reply.started":"2021-07-10T04:51:31.306083Z","shell.execute_reply":"2021-07-10T04:51:31.330636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Allocate a QLattice\nThe actual QLattice is a quantum simulator that runs on Abzu's hardware, but we can allocate one to use for our analysis with a single line of code. Hopefully the following line will get us one.","metadata":{}},{"cell_type":"code","source":"ql = feyn.connect_qlattice()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:51:34.358498Z","iopub.execute_input":"2021-07-10T04:51:34.358944Z","iopub.status.idle":"2021-07-10T04:51:36.059909Z","shell.execute_reply.started":"2021-07-10T04:51:34.358907Z","shell.execute_reply":"2021-07-10T04:51:36.059117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Search for the best model\n\nWe are now ready to instruct the QLattice to search for the best mathematical model to explain the data. Here we use the high-level convenience function that does everything with sensible defaults: https://docs.abzu.ai/docs/guides/essentials/auto_run.html.\n\nFor more detailed control, we could use the primitives: https://docs.abzu.ai/docs/guides/primitives/using_primitives.html","metadata":{"execution":{"iopub.status.busy":"2021-07-01T12:32:57.200226Z","iopub.execute_input":"2021-07-01T12:32:57.200568Z","iopub.status.idle":"2021-07-01T12:32:57.20888Z","shell.execute_reply.started":"2021-07-01T12:32:57.200541Z","shell.execute_reply":"2021-07-01T12:32:57.20756Z"}}},{"cell_type":"markdown","source":"### Let's start simple. We constrain the model to have 3 edges (e.g. 2 features and one interaction)\nEssentially, we're asking the question \"which two features best describe my data and how do they relate to eachother?\".","metadata":{}},{"cell_type":"code","source":"ql.reset(random_seed=42)\nmodels = ql.auto_run(train, output_name=\"vital.status\", kind=\"classification\", max_complexity=3, n_epochs=25)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T04:51:36.485727Z","iopub.execute_input":"2021-07-10T04:51:36.486355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models[0].plot(train, test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is already a pretty good model given that a random forest only scores around AUC=0.66 (using hundreds of features and not being interpretable).","metadata":{}},{"cell_type":"markdown","source":"### Let's see what's going on in the model - Partial Plots","metadata":{}},{"cell_type":"code","source":"# Training Data\nmodels[0].plot_partial2d(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test Data\nmodels[0].plot_partial2d(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice, the model generalises well on unseen data!","metadata":{}},{"cell_type":"markdown","source":"### Looking at the ROC curve","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:46:22.795628Z","iopub.execute_input":"2021-07-09T11:46:22.79606Z","iopub.status.idle":"2021-07-09T11:46:22.800933Z","shell.execute_reply.started":"2021-07-09T11:46:22.79601Z","shell.execute_reply":"2021-07-09T11:46:22.799323Z"}}},{"cell_type":"code","source":"models[0].plot_roc_curve(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's look at some other machine-learning methods","metadata":{}},{"cell_type":"code","source":"rf = feyn.reference.RandomForestClassifier(train, output_name=\"vital.status\", random_state = 42)\ngb = feyn.reference.GradientBoostingClassifier(train, output_name=\"vital.status\", random_state = 42)\nlr = feyn.reference.LogisticRegressionClassifier(train, output_name=\"vital.status\", max_iter=10000, random_state = 42)\n\nrf.plot_roc_curve(test, label=\"Random Forest\")\ngb.plot_roc_curve(test, label=\"Gradient Boosting\")\nlr.plot_roc_curve(test, label=\"Logistic Regression\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Multi-Omics Capabilities of the QLattice","metadata":{}},{"cell_type":"markdown","source":"### What happens when I let the QLattice explore for a while?\nIn this example I'm loading in a model that was trained for 200 iterations (using criterion = \"bic\" and max_complexity = 7). This took around 30 minutes on my machine (M1 Macbook Air 2021).","metadata":{}},{"cell_type":"code","source":"multi_model = feyn.Model.load(\"/kaggle/input/brca-multiomics-tcga/model_200its_md2_bic_0.model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_model.plot(train, test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice AUC! Interestingly, this model includes three different data types: Gene expression (rs), copy numbers (cn) and mutations (mu).\nWe didn't even have to do anything special to the data, the QLattice figured out the correct normalisations itself!","metadata":{}},{"cell_type":"markdown","source":"### Looking at people without TNXB mutations\nIn people **without** TNXB mutations both high APOB and VWDE gene expression are associated with death.","metadata":{}},{"cell_type":"code","source":"multi_model.plot_partial2d(df, fixed = {\"mu_TNXB\" : 0, \"cn_ANKRD30B\" : -1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Looking at TNXB mutation carriers\nIn people **with** a TNXB mutation only high APOB is required for a case to be fatal.","metadata":{}},{"cell_type":"code","source":"multi_model.plot_partial2d(df, fixed = {\"mu_TNXB\" : 1, \"cn_ANKRD30B\" : -1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The QLattice identified a **genetic switch**, i.e., a mutation in a gene (TNXB) that seems to drive cancer severity. In the top figure, we show the decision boundary for non-TNXB mutation carriers: Here, individuals with high APOB and VWDE gene-expression seem to be at risk of dying.\nIn the bottom figure, we show the predictions for TNXB-mutation carriers. Here, high levels of APOB are predicted to be detrimental, no matter the levels of VWDE.\n","metadata":{}},{"cell_type":"markdown","source":"## Conclusion","metadata":{"execution":{"iopub.status.busy":"2021-07-09T14:17:07.342271Z","iopub.execute_input":"2021-07-09T14:17:07.342683Z","iopub.status.idle":"2021-07-09T14:17:07.346754Z","shell.execute_reply.started":"2021-07-09T14:17:07.342649Z","shell.execute_reply":"2021-07-09T14:17:07.345751Z"}}},{"cell_type":"markdown","source":"The QLattice seamlessly provides insights into complex datasets and outperforms traditional machine-learning methods.","metadata":{}}]}