{"cells":[{"metadata":{"_uuid":"385e43a763cf2a2e696526612151db7c079f8909"},"cell_type":"markdown","source":"# Convolutional Neural Networks with Image Augmentation","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2586e6624621731384bd5dda484058cedb8bf859"},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/american_sign_language.PNG\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7edbefdee7d8c7ec18be7f29ca2cb9180399b75b"},"cell_type":"markdown","source":"## About the Data","execution_count":null},{"metadata":{"_uuid":"fed611598feffec2b2024c5dcf4fd057b6e2d1eb"},"cell_type":"markdown","source":"The original MNIST image dataset of handwritten digits is a popular benchmark for image-based machine learning methods but researchers have renewed efforts to update it and develop drop-in replacements that are more challenging for computer vision and original for real-world applications. As noted in one recent replacement called the Fashion-MNIST dataset, the Zalando researchers quoted the startling claim that \"Most pairs of MNIST digits (784 total pixels per sample) can be distinguished pretty well by just one pixel\". To stimulate the community to develop more drop-in replacements, the Sign Language MNIST is presented here and follows the same CSV format with labels and pixel values in single rows. The American Sign Language letter database of hand gestures represent a multi-class problem with 24 classes of letters (excluding J and Z which require motion).\n\nThe full introduction can be seen here: \n[https://www.kaggle.com/datamunge/sign-language-mnist/home](https://www.kaggle.com/datamunge/sign-language-mnist/home)","execution_count":null},{"metadata":{"_uuid":"e53bedce4f0d76a8b8e03f25d130fb96d3fd70d8"},"cell_type":"markdown","source":"This type of computations may be long, so I start with timer setting to know how much time the script will take.","execution_count":null},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true,"_uuid":"918bc1d5feda674e2428e9c740539635197194e5"},"cell_type":"code","source":"import time\nfrom time import perf_counter as timer\nstart = timer()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43610b28fcb6c9bd7cb7faf5e16b5b7036e2d63e"},"cell_type":"markdown","source":"Importing necessary modules:","execution_count":null},{"metadata":{"trusted":true,"_uuid":"bbcbb713210c674a54142d4ade11072985c94754","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb5c20f48c81e25a233ee3ef539433af879d0030"},"cell_type":"markdown","source":" ## Data Load and Check","execution_count":null},{"metadata":{"trusted":true,"_uuid":"ecbdbd9051c8426eee31ff37a30ad9748d9c2c2a"},"cell_type":"code","source":"train = pd.read_csv('../input/sign_mnist_train.csv')\ntest = pd.read_csv('../input/sign_mnist_test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbe6f2e87e4242776b8fece230f5f793bb244bba"},"cell_type":"markdown","source":"What are our data dimensions?","execution_count":null},{"metadata":{"trusted":true,"_uuid":"8c2df551d7a771cb4fdc25b574a48a1652f251f0"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81fbe2142a6a125bb488c4855e10627537c326ee"},"cell_type":"markdown","source":"Here we can look at original photographs:","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"20bf62e3f3bd4132b3334e4351182b9f95dd3f1f"},"cell_type":"code","source":"Image(\"../input/amer_sign2.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b4e745e346f02d6cae12b2518281311c947aab3","collapsed":true},"cell_type":"markdown","source":"Our `train` set is reworked to reduce a data size. In particular all images are in grayscale and their sizes are 28 * 28 pixels. I will show pictures  in a few steps.","execution_count":null},{"metadata":{"_uuid":"926e5f5b91cc9dc0f4b58f68f7082b9634b9ce3d"},"cell_type":"markdown","source":"## Data Preprocessing\nLet us start to extract information from our data. At first I take a look at labels.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"c08c24f5b0f18610feb7fbf0d7772792f78dac8d"},"cell_type":"code","source":"labels = train['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b97bf1309270da6695095e295886882e8c3c8af"},"cell_type":"code","source":"unique_val = np.array(labels)\nnp.unique(unique_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46e4bfa083095d0ee14048250875952381d7060b"},"cell_type":"markdown","source":"Is our data balanced?","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"7f35db6e0ad4d62e93e82d932dea132ccd17d361"},"cell_type":"code","source":"plt.figure(figsize = (18,8))\nsns.countplot(x =labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2806c29690539d6c1fad7a1c3e0aad98656e000"},"cell_type":"markdown","source":"As you can see all output numbers are about the same.\n\nFor our CNN network  I'm to create an output array with Label Binarizer from the labels.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"a4d3cdc7d27b21bc1b5db6337162e28fd809ff73"},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_binrizer = LabelBinarizer()\nlabels = label_binrizer.fit_transform(labels)\nlabels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8271969b6aa7e2f39c9b0cb50e622a80b0317a4"},"cell_type":"markdown","source":"Now I drop the label column from the 'train' set and will work with the rest of data.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"cf73d03f610be9f134a3ee5e35301b1da4626d02"},"cell_type":"code","source":"train.drop('label', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70c52bd461c45292cfda21aff61154009214e281"},"cell_type":"markdown","source":"Now let us take out the image information from `train` object and put in into numpy array. What is a data type, range and dimensions?","execution_count":null},{"metadata":{"trusted":true,"_uuid":"b25a4af6ed60a970d5f530f4c94aca2e0c2554de"},"cell_type":"code","source":"images = train.values\nprint(images.dtype, np.round(images.min(), 4), np.round(images.max(), 4), images.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d73108efa38f76b1fb2da496a623a1fc70a4c53f"},"cell_type":"markdown","source":"Let us see provided images using first 5 rows. ","execution_count":null},{"metadata":{"trusted":true,"_uuid":"3381e5155295c437768c05889ac3fe5b449a1c7d","scrolled":true,"_kg_hide-input":false},"cell_type":"code","source":"plt.style.use('grayscale')\nfig, axs = plt.subplots(1, 5, figsize=(15, 4), sharey=True)\nfor i in range(5): \n        axs[i].imshow(images[i].reshape(28,28))\nfig.suptitle('Grayscale images')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba7bfbf01786a077db6287f795469308e2e37044"},"cell_type":"markdown","source":"We are to normalize the data before applying CNN. Our data values range is from 0 to 255, so to normalize I divide every entry by 225.\n","execution_count":null},{"metadata":{"trusted":true,"_uuid":"a2998dd21e53a4f15514277995491eafc5f6b235"},"cell_type":"code","source":"images =  images/255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9a790e5481d031d8e554ec4728aa2707c6dc18a"},"cell_type":"markdown","source":"For validation during a model fitting we need to divide our train set in two parts. ","execution_count":null},{"metadata":{"trusted":true,"_uuid":"46a16c55efbcd4009beb4a197031e24b4d3dd31f"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, stratify = labels, random_state = 7)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1fbfd6092d7714f8608679a28b490ea2cc1013b"},"cell_type":"markdown","source":"Now I need to reshape our rows as square tables because I want to use a Convolution Neural Network method.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"71e6153e26b5389e6133b8aeee86164cd66ed465"},"cell_type":"code","source":"x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ca7ff22abf6130778af7ec7e8c1062365b1a5179"},"cell_type":"markdown","source":"## Convolutional Neural Network Model, or CNN\nFor CNN I am using keras library here.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"3ec82309ac0cd088766cfccd095401d706c09462"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d6db165b0ca7701969b6ab373182e475dfdf8c9"},"cell_type":"markdown","source":"Setting a number of classes,  a batch size and a number of epochs.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"4321e7c0755b03a7ed072cab088d02b27f3f734f"},"cell_type":"code","source":"num_classes = 24\nbatch_size = 125\nepochs = 50","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9156d1c064ac92c66b00f259eb90a0783f5f1ad"},"cell_type":"markdown","source":"Here goes the CNN in all its beauty!","execution_count":null},{"metadata":{"trusted":true,"_uuid":"31b10d7abd4b28e7de20a46bab97b87bdf797fdb"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, kernel_size=(4,4), activation = 'relu', input_shape=(28, 28 ,1), padding='valid' ))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, kernel_size = (4, 4), activation = 'relu', padding='valid' ))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dense(num_classes, activation = 'softmax'))\nmodel.compile(loss = keras.losses.categorical_crossentropy, optimizer='nadam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d5c799216945b8b180c43ad0cf947ae537e4027"},"cell_type":"markdown","source":"This part is for image augmentation during model fitting.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"b3f7e5cbaf7fd6a0b87cbaa2a91febc373fa41ae"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(shear_range = 0.25,\n                                   zoom_range = 0.15,\n                                   rotation_range = 15,\n                                   brightness_range = [0.15, 1.15],\n                                   width_shift_range = [-2,-1, 0, +1, +2],\n                                   height_shift_range = [ -1, 0, +1],\n                                   fill_mode = 'reflect')\ntest_datagen = ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09a12be4ae958bb6d441da191840e817eb6c97df"},"cell_type":"markdown","source":"And now it runs!","execution_count":null},{"metadata":{"trusted":true,"_uuid":"f8017080980e9d0e1a97782e518e502ba3e71b13","scrolled":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b07d264253d428797b08bd4046386ff2da0fb521"},"cell_type":"markdown","source":"You see below how accuracy values improve with each epoch.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"fb2775e7f90958e544d84c476bcb52bd985e6395"},"cell_type":"code","source":"plt.style.use('tableau-colorblind10')\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.ylim(0.80, 1.05)\nplt.title(\"Accuracy\")\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train','test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f16f3a253826a51b7ad38bb2576bf200173581f"},"cell_type":"markdown","source":"Let's validate with the test data. At first it must be preprocessed in the same way as our data for model fitting. It means that  we are to remove its label column,  divide all values by 225 and rows should be reshaped as square arrays.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"e486c080ea745082f91ca1d2cfc0aac975afdd3b"},"cell_type":"code","source":"test_labels = test['label']\ntest.drop('label', axis = 1, inplace = True)\ntest_images = test.values/255\ntest_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\ntest_images = np.array([i.flatten() for i in test_images])\ntest_labels = label_binrizer.fit_transform(test_labels)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\ntest_images.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e4a7b58496038c7d5b33b30e5039cd6f283369e"},"cell_type":"markdown","source":"Here are predictions and an accuracy on our provided test set.","execution_count":null},{"metadata":{"trusted":true,"_uuid":"27670fc85328b772e9cf2446f091be92bf85c44b"},"cell_type":"code","source":"y_pred = model.predict(test_images)\nfrom sklearn.metrics import accuracy_score\ny_pred = y_pred.round()\naccuracy_score(test_labels, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c06ce8efc9b99d13dd90e13f899e3cfa00f39fd8"},"cell_type":"markdown","source":"An accuracy may fluctuate due to randomness of applyed methods. \n\n### My time count","execution_count":null},{"metadata":{"trusted":true,"_uuid":"5ea8e028946c030cc36a7bab5eb0e2c0dd8eb84c"},"cell_type":"code","source":"end = timer()\nelapsed_time = time.gmtime(end - start)\nprint(\"Elapsed time:\")\nprint(\"{0} minutes {1} seconds.\".format(elapsed_time.tm_min, elapsed_time.tm_sec))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}