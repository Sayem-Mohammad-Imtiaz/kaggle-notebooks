{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install seaborn==0.11.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"Pregnancies\", col=\"Outcome\", multiple=\"dodge\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"Insulin\", col=\"Outcome\", multiple=\"dodge\", kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"BMI\", hue=\"Outcome\",  kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"BloodPressure\", hue=\"Outcome\", kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"Age\", col=\"Outcome\", multiple=\"dodge\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"Glucose\", hue=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"SkinThickness\", col=\"Outcome\", multiple=\"dodge\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(df,x=\"DiabetesPedigreeFunction\", hue=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf[[\"SkinThickness_S\", \"Insulin_S\", \"Glucose_S\", \"BloodPressure_S\", \"BMI_S\"]] = scaler.fit_transform(df[[\"SkinThickness\", \"Insulin\", \"Glucose\", \"BloodPressure\", \"BMI\"]])\n\nsns.scatterplot(data=df, x=\"DiabetesPedigreeFunction\", y=\"SkinThickness_S\", hue=\"Outcome\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.var()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"Outcome\", \"SkinThickness_S\", \"Insulin_S\", \"Glucose_S\", \"Age\", \"BMI_S\", \"BloodPressure_S\", \"DiabetesPedigreeFunction\", \"Pregnancies\"]\nsns.pairplot(data=df[features], hue=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[features].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outcome\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_original_data():\n    X = df[[\"BloodPressure\", \"Glucose\", \"SkinThickness\", \"Insulin\", \"BMI\", \"Age\", \"Pregnancies\", \"DiabetesPedigreeFunction\"]]\n    y = df[\"Outcome\"]\n    X.corr()\n    return X, y\n\ndef get_min_max_scaled_data():\n    X = df[[\"BloodPressure_S\", \"Glucose_S\", \"SkinThickness_S\", \"Insulin_S\", \"BMI_S\", \"Age\", \"Pregnancies\", \"DiabetesPedigreeFunction\"]]\n    y = df[\"Outcome\"]\n    X.corr()\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nimport pprint\n\ndef logistic_regression(X_train, y_train, X_test, y_test):\n    model = LogisticRegression(solver=\"newton-cg\", random_state=0)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    precision = precision_score(y_test, y_pred)\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1_s = f1_score(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred)\n    \n    #print(f\"features: {X_train.columns}\")\n    #print(f\"Coef:\\n {model.coef_}\")\n    \n    return round(accuracy,2), round(precision,2), round(recall, 2), round(f1_s, 2)\n\ndef k_nearest_neighbors(X_train, y_train, X_test, y_test, n_neighbors):\n    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    precision = precision_score(y_test, y_pred)\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1_s = f1_score(y_test, y_pred)\n    cm = confusion_matrix(y_test, y_pred)\n    return round(accuracy,2), round(precision,2), round(recall, 2), round(f1_s, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_original, y_original = get_original_data()\nX_scaled, y_scaled = get_min_max_scaled_data()\ndef train_knn_original_data(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    accuracy = []\n\n    for i in range(2, 20):\n        result = k_nearest_neighbors(X_train, y_train, X_test, y_test, i)\n        accuracy.append((i, result[0], result[1], result[2]))\n        print(f\"neighbors: {i}, accuracy: {result[0]}, precision: {result[1]}, recall:  {result[2]}, f1: {result[3]}\")\n        \ndef train_logistic_regression_original(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    accuracy = []\n    result = logistic_regression(X_train, y_train, X_test, y_test)\n    print(result[0], result[1], result[2], result[3])\n    \n\ndef train_knn_scaled_data(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    accuracy = []\n\n    for i in range(2, 20):\n        result = k_nearest_neighbors(X_train, y_train, X_test, y_test, i)\n        accuracy.append((i, result[0], result[1], result[2]))\n        print(f\"neighbors: {i}, accuracy: {result[0]}, precision: {result[1]}, recall:  {result[2]}, f1: {result[3]}\")\n        \ndef train_logistic_regression_scaled(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    accuracy = []\n    result = logistic_regression(X_train, y_train, X_test, y_test)\n    print(result[0], result[1], result[2], result[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train knn on original data\")\ntrain_knn_original_data()\n\nprint(f\"Train LR on original data\")\ntrain_logistic_regression_original()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"=================== Exclude SkinThickness and BloodPressure from original ===========================\")\nprint(f\"Train knn on original data\")\ntrain_knn_original_data([\"SkinThickness\", \"BloodPressure\", \"DiabetesPedigreeFunction\"])\n\nprint(f\"Train LR on original data\")\ntrain_logistic_regression_original([\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"============================== Scaled Data ====================================\")\nprint(f\"Train knn on scaled data\")\ntrain_knn_scaled_data()\n\nprint(f\"Train LR on scaled data\")\ntrain_logistic_regression_scaled()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"=================== Exclude SkinThickness_S and BloodPressure_S ===========================\")\nprint(f\"Train knn\")\ntrain_knn_scaled_data([\"BloodPressure_S\"])\nprint(\"Train LR\")\ntrain_logistic_regression_scaled([\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree ###"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndef decision_tree(X_train, X_test, y_train, y_test, depth):\n    model = DecisionTreeClassifier(random_state=0, max_depth=depth)\n    clf = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    precision = precision_score(y_test, y_pred)\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1_s = f1_score(y_test, y_pred)\n    return accuracy, precision, recall, f1_s\n\ndef train_decision_tree_original(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    for i in range(2, 10):\n        result = decision_tree(X_train, X_test, y_train, y_test, i)\n        print(i, result[0], result[1], result[2], result[3])\n        \ndef train_decision_tree_scaled(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    for i in range(2, 10):\n        result = decision_tree(X_train, X_test, y_train, y_test, i)\n        print(i, result[0], result[1], result[2], result[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Original Data\")\ntrain_decision_tree_original()\n\nprint(f\"\\nOriginal Data Drop Cols\")\ntrain_decision_tree_original([\"SkinThickness\", \"BloodPressure\"])\n\nprint(f\"\\n Scaled Data\")\ntrain_decision_tree_scaled()\n\nprint(f\"\\n Scaled Data Drop Cols\")\ntrain_decision_tree_scaled([\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest ###"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ndef random_forest(X_train, X_test, y_train, y_test, depth):\n    model = RandomForestClassifier(max_depth=depth, random_state=0)\n    clf = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    precision = precision_score(y_test, y_pred)\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1_s = f1_score(y_test, y_pred)\n    return round(accuracy,2), round(precision, 2), round(recall, 2), round(f1_s,2)\n\ndef train_random_forest_original(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    for i in range(2, 15):\n        result = random_forest(X_train, X_test, y_train, y_test, i)\n        print(i, result[0], result[1], result[2], result[3])\n        \ndef train_random_forest_scaled(cols=None):\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.20, random_state=42)\n    if cols is not None:\n        X_train = X_train.drop(cols, axis=1)\n        X_test = X_test.drop(cols, axis=1)\n    for i in range(2, 15):\n        result = random_forest(X_train, X_test, y_train, y_test, i)\n        print(i, result[0], result[1], result[2], result[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Original Data\")\ntrain_random_forest_original()\n\nprint(f\"\\nOriginal Data Drop Cols\")\ntrain_random_forest_original([\"BloodPressure\"])\n\nprint(f\"\\n Scaled Data\")\ntrain_random_forest_scaled()\n\nprint(f\"\\n Scaled Data Drop Cols\")\ntrain_random_forest_scaled([\"SkinThickness_S\", \"BloodPressure_S\"])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}