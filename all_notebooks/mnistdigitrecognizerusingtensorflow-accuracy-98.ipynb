{"cells":[{"metadata":{},"cell_type":"markdown","source":"Please upvote if you find it useful."},{"metadata":{},"cell_type":"markdown","source":"## Loading required Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nimport tensorflow as tf\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport os\nos.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read data from CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_file = \"../input/train.csv\"\ntest_file = \"../input/test.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(test_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train = pd.read_csv(train_file)\nimages_test = pd.read_csv(test_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separate train and test Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train=np.array(images_train['label']).reshape(-1,1)\n#labels_test=np.array(images_test['label']).reshape(-1,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One hot encoding of labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot=OneHotEncoder()\nonehot.fit(labels_train)\nlabels_train=onehot.transform(labels_train)\n#labels_test=onehot.transform(labels_test)\nlabels_train=labels_train.toarray()\n#labels_test=labels_test.toarray()\n\n# convert train and test data to an array\nimages_train=np.array(images_train.iloc[:, 1:]).reshape(42000,784)\nimages_test=np.array(images_test.iloc[:, :]).reshape(28000,784)\n\n# Convert all the values between 0 and 1\nimages_train=images_train/255\nimages_test=images_test/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Tensorflow Placeholder for input parameters and label"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_ph = tf.placeholder(tf.float32, shape=[None, 784]) \n    \ny_ph = tf.placeholder(tf.float32, shape=[None, 10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utility functionn to pass weights and bias to network layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def weight_variable(shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### utility function to create convolutions and pooling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv2d(x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# originally an image is simply a flat array of 784 numbers representing pixels\n# we are reshaping it to original dimension of 28x28X1 , had this been a colored image. \n# there will be 3 channels instead of just 1 on the third dimension\nx_image = tf.reshape(x_ph, [-1, 28, 28, 1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### we create 32 convolutions at first layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"W_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here we use Relu as activation function "},{"metadata":{"trusted":true},"cell_type":"code","source":"h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### create 64 convolutions at second layer and pass the previous 32 convolutions as input"},{"metadata":{"trusted":true},"cell_type":"code","source":"W_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After first pooling size reduce to 7x7"},{"metadata":{"trusted":true},"cell_type":"code","source":"h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n\nW_fc1 = weight_variable([7 * 7 * 64, 1024]) # the layer has 1024 nodes\nb_fc1 = bias_variable([1024])\n\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### keep_prob is the drop while back_propagating"},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_prob = tf.placeholder(tf.float32)\n\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W_fc2 = weight_variable([1024, 200]) # second layer has 200 nodes\nb_fc2 = bias_variable([200])\n\nh_fc2= tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\nh_fc2_drop=tf.nn.dropout(h_fc2,keep_prob)\n\nW_fc3 = weight_variable([200, 100]) # the output has 10 nodes(the target labels)\nb_fc3 = bias_variable([100])\n\n\nh_fc3= tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\nh_fc3_drop=tf.nn.dropout(h_fc3,keep_prob)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### use logits function at the output layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nW_fc4 = weight_variable([100, 10]) # the output has 10 nodes(the target labels)\nb_fc4 = bias_variable([10])\n\n\ny_conv_logits=tf.matmul(h_fc3_drop, W_fc4) + b_fc4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adam Optimizer is used as gradient descent to train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = tf.reduce_mean(\n    tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_ph, \n                                            logits=y_conv_logits))\n\ntrain_step = tf.train.AdamOptimizer().minimize(loss)\n\ncorrect_prediction = tf.equal(tf.argmax(y_conv_logits, 1),\n                              tf.argmax(y_ph, 1))\n\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\ntest_labels_predicted=tf.argmax(y_conv_logits, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    \n    for i in range(1000):\n        rand_int=np.random.choice(range(42000),100)\n        x_train_batch=images_train[rand_int]\n        y_train_batch=labels_train[rand_int]\n        # checking accuracy for every 100 iteration\n        if i % 100 == 0:\n            train_accuracy = accuracy.eval(feed_dict={x_ph: x_train_batch, y_ph: y_train_batch, keep_prob: 1.0})\n            #test_accuracy=accuracy.eval(feed_dict={x_ph: images_test, y_ph: labels_test, keep_prob: 1.0})\n            print('step %d, training accuracy %g & testing accuracy g' % (i, train_accuracy))\n            \n        train_step.run(feed_dict={x_ph: x_train_batch, y_ph: y_train_batch, keep_prob: 0.5})\n\n   # print('test accuracy %g' % accuracy.eval(feed_dict={x_ph: images_test, y_ph: labels_test, keep_prob: 1.0}))\n    test_labels_predicted=sess.run(test_labels_predicted,feed_dict={x_ph:images_test,keep_prob:1.0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.crosstab(np.argmax(labels_test,axis=1),test_labels_predicted)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Number of false predictions "},{"metadata":{"trusted":true},"cell_type":"code","source":"#t=np.argmax(labels_test,axis=1)!=test_labels_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#len([i for i,x in enumerate(t) if x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind=2352\nsample_image = images_test[ind] \nsample_image = np.array(sample_image, dtype='float')\npixels = sample_image.reshape((28, 28))\nplt.imshow(pixels, cmap='gray')\nplt.show()\nprint('predicted label:',test_labels_predicted[ind])\n#print('real label:',np.argmax(labels_test[ind]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"ImageId\": list(test.index+1),\n        \"Label\": test_labels_predicted\n        })\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}