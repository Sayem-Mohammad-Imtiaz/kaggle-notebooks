{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Changelog\n\n### Version 18\n\n* Use additional dataset from https://www.kaggle.com/shymammoth/shopee-reviews\n* No longer modify y_train\n\n### Version 14\n\n* Replace Bag of Words (BoW) with TF-IDF\n\n### Version 13\n\n* Use NaiveBayes\n* Use Bigram\n* Change all y_train rating 4->5\n\n### Version 12\n\n* Replace TF-IDF with Bag of Words (BoW)\n\n### Version 11\n\n* Change replace char & delete remove char\n* Set `min_df=20` for TF-IDF\n* Use SVM (with GridSearchCV)\n* Enable replace/remove char\n\n### Version 6\n\n* Add Confusion Matrix\n* Set `min_df=5` for TF-IDF\n* Import library used to set SEED\n* Lemmatization for EN & Stemming for ID\n* Disable replace/remove char\n* Revert RandomForestClassifier parameter\n\n### Version 5\n\n* Change RandomForestClassifier parameter\n* Set SEED\n\n### Version 4\n\n* Use RandomForestClassifier\n* `min_df=20` for TF-IDF\n* Change generic model function position\n\n### Version 3\n\n* Fix submission.csv column name\n\n### Version 2\n\n* Use MultinomialNB\n\n### Version 1\n\n* Initialize code","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyenchant pysastrawi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget http://archive.ubuntu.com/ubuntu/pool/main/libr/libreoffice-dictionaries/hunspell-id_6.4.3-1_all.deb\n!dpkg -i hunspell-id_6.4.3-1_all.deb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt update && apt install -y enchant libenchant1c2a hunspell hunspell-en-us libhunspell-1.6-0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport os\nimport gc\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport enchant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('NLTK version:', nltk.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lha /kaggle/input\n!ls -lha /kaggle/input/student-shopee-code-league-sentiment-analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/student-shopee-code-league-sentiment-analysis/train.csv')\ndf_train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train2 = pd.read_csv('/kaggle/input/shopee-reviews/shopee_reviews.csv')\n\ndef to_int(r):\n    try:\n        return np.int32(r)\n    except:\n        return np.nan\n\ndf_train2['label'] = df_train2['label'].apply(to_int)\ndf_train2 = df_train2.dropna()\ndf_train2['label'] = df_train2['label'].astype(np.int32)\ndf_train2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/student-shopee-code-league-sentiment-analysis/test.csv')\ndf_test.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([df_train['review'], df_train2['text']], axis=0)\nX_train = X_train.reset_index(drop=True)\ny_train = pd.concat([df_train['rating'], df_train2['label']], axis=0)\ny_train = y_train.reset_index(drop=True)\n\nX_test = df_test['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Class weight","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_count = y_train.value_counts().sort_index().to_list()\ntotal_rating = sum(rating_count)\nlowest_rating_count = min(rating_count)\nrating_weight = [lowest_rating_count/rc for rc in rating_count]\n\nprint(rating_count)\nprint(total_rating)\nprint(rating_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = np.empty((total_rating,))\nfor i in range(total_rating):\n    class_weight[i] = rating_weight[y_train[i] - 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n\nlemmatizer = WordNetLemmatizer() # for en\nfactory = StemmerFactory() # for id\nstemmer = factory.create_stemmer() # for id\n\ntweet_tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n\neng_dict = enchant.Dict('en')\nind_dict = enchant.Dict('id_ID')\n\ndef remove_char(text):\n    text = re.sub(r'[^a-z ]', ' ', text)\n    return text\n\n\ndef stem_lemma(tokens):\n    new_token = []\n    for token in tokens:\n        if eng_dict.check(token):\n            new_token.append(lemmatizer.lemmatize(token))\n        elif ind_dict.check(token):\n            new_token.append(stemmer.stem(token))\n        else:\n            new_token.append(token)\n    return new_token\n\ndef upper_or_lower(tokens):\n    new_token = []\n    for token in tokens:\n        total_lower = len(re.findall(r'[a-z]',token))\n        total_upper = len(re.findall(r'[A-Z]',token))\n        if total_lower == 0 or total_upper == 0:\n            new_token.append(token)\n        elif total_lower > total_upper:\n            new_token.append(token.lower())\n        else:\n            new_token.append(token.upper())\n    return new_token\n    \n\ndef preprocess(X):\n    X = X.apply(tweet_tokenizer.tokenize)\n    X = X.apply(lambda token: [t for t in token if t != ''])\n    X = X.apply(upper_or_lower)\n    X = X.apply(stem_lemma)\n#     X = X.apply(lambda token: ' '.join(token)) # need to join token because sklearn tf-idf only accept string, not list of string\n    \n#     X = X.apply(remove_char)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = preprocess(X_train)\nX_test = preprocess(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word representation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nbow_vectorizer = TfidfVectorizer(lowercase=False, ngram_range=(1,2), analyzer=lambda t:t, min_df=5, sublinear_tf=True)\n\nX_train = bow_vectorizer.fit_transform(X_train)\nX_test = bow_vectorizer.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, f1_score, confusion_matrix\n\ndef predict(model, X):\n    y = model.predict(X)\n    return y\n\ndef metrics(y_true, y_pred):\n    print('F1 Score :', f1_score(y_true, y_pred, average='macro'))\n    print(classification_report(y_true, y_pred))\n\n    cm = confusion_matrix(y_true, y_pred)\n    cm = pd.DataFrame(cm, [1,2,3,4,5], [1,2,3,4,5])\n\n    sns.heatmap(cm, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MultinomialNB","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\nclf.fit(X_train, y_train, class_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = predict(clf, X_train)\nmetrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = predict(clf, X_test)\n\ndf_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\ndf_submission.to_csv('submission_MultinomialNB.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ComplementNB","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import ComplementNB\nclf = ComplementNB()\nclf.fit(X_train, y_train, class_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = predict(clf, X_train)\nmetrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = predict(clf, X_test)\n\ndf_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\ndf_submission.to_csv('submission_ComplementNB.csv', index=False)\n\ndf_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForestClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n\n# clf = RandomForestClassifier(random_state=SEED)\n# clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train_pred = predict(clf, X_train)\n# metrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_test_pred = predict(clf, X_test)\n\n# df_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\n# df_submission.to_csv('submission.csv', index=False)\n\n# df_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.svm import SVC\n\n# clf = SVC(kernel='rbf', C=1, cache_size=10240)\n# clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train_pred = predict(clf, X_train)\n# metrics(y_train, y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_test_pred = predict(clf, X_test)\n\n# df_submission = pd.concat([df_test['review_id'], pd.Series(y_test_pred, name='rating')], axis=1)\n# df_submission.to_csv('submission.csv', index=False)\n\n# df_submission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}