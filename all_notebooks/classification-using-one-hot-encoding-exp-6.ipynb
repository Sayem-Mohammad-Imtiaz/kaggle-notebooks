{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the Data","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/titanic/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understand the data","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove columns which you think is not required for learning ","metadata":{}},{"cell_type":"code","source":"r=['PassengerId','Name','Ticket','Cabin']\ndf1=df.drop(r,axis=1).copy()\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deal with missing data\n\nAge,Cabin and Embarked are missing","metadata":{}},{"cell_type":"code","source":"df1.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1[\"Embarked\"].mode()[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing Embarked values with most common value\n\ndf1[\"Embarked\"]=df1[\"Embarked\"].fillna(df1[\"Embarked\"].mode()[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1[\"Age\"]=df1[\"Age\"].fillna(df1[\"Age\"].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode Categorical values","metadata":{}},{"cell_type":"code","source":"df1.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc=['Sex','Embarked']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Encoded Columns","metadata":{}},{"cell_type":"code","source":"dummy=pd.get_dummies(df1[cc])\ndummy.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove CC and replace it with encoded data","metadata":{}},{"cell_type":"code","source":"df1=df1.drop(cc,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.concat([df1,dummy],axis=1)\ndf2.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Divide into features and Target","metadata":{}},{"cell_type":"code","source":"X=df2.iloc[:,1:]\ny=df2.iloc[:,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check whether target is balanced or not","metadata":{}},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Run classification without scaling","metadata":{}},{"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.model_selection import train_test_split\nsn=[]\nscore=[]\nfor i in range(1,100):\n    X_train, X_test, y_train, y_test = train_test_split(X, y,  stratify=y,  test_size=0.25)  # split\n    dtc = tree.DecisionTreeClassifier(random_state=0)# model selection\n    dtc.fit(X_train, y_train)# model learning\n    sn.append(i)\n    score.append(dtc.score(X_test,y_test))\n\nresult=pd.DataFrame()\nresult[\"SN\"]=sn\nresult[\"Score\"]=score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(\"r1.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use minmax scaler","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\nminmax_scale=preprocessing.MinMaxScaler(feature_range=(0,1))\n\nX_minmax=minmax_scale.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_minmax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1=pd.DataFrame(columns=X.columns,data=X_minmax)\nX1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sn=[]\nscore=[]\nfor i in range(1,100):\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X1, y,  stratify=y,  test_size=0.25)\n    dtc = tree.DecisionTreeClassifier(random_state=0)\n    dtc.fit(X_train, y_train)\n    sn.append(i)\n    score.append(dtc.score(X_test,y_test))\n\nresult=pd.DataFrame()\nresult[\"SN\"]=sn\nresult[\"Score\"]=score\nprint(result)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(\"r2.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets use standard scaler and see what happens","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nscaler=preprocessing.StandardScaler()\nX_stdscale=scaler.fit_transform(X)\nX_stdscale","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X2=pd.DataFrame(columns=X.columns,data=X_stdscale)\nX2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nsn=[]\nscore=[]\n#acc=[]\nfor i in range(1,100):\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X2, y,  stratify=y,  test_size=0.25)\n    dtc = tree.DecisionTreeClassifier(random_state=0)\n    dtc.fit(X_train, y_train)\n    sn.append(i)\n    score.append(dtc.score(X_test,y_test))\n    #y_pred=dtc.predict(X_test)\n    #acc.append(metrics.accuracy_score(y_test, y_pred))\n\nresult=pd.DataFrame()\nresult[\"SN\"]=sn\nresult[\"Score\"]=score\n#result[\"Accuracy\"]=acc\nprint(result)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv(\"r3.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deep Learning","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Dense(units=8, input_shape=(10,), activation='relu'),\n    Dense(units=8, activation='relu'),\n    Dense(units=7, activation='sigmoid')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=Adam(learning_rate=0.0001), \n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    x=X_train, \n    y=y_train, \n    batch_size=10, \n    epochs=30, \n    shuffle=True, \n    verbose=2\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict with model","metadata":{}},{"cell_type":"code","source":"y_test.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model.predict_classes(X_test)\ndf=pd.DataFrame()\ndf[\"Actual\"]=y_test.values\ndf[\"Predicted\"]=predictions\ncorrect_predictions = np.nonzero(predictions == y_test.values)[0]\nincorrect_predictions = np.nonzero(predictions != y_test.values)[0]\nprint(len(correct_predictions),\" classified correctly\")\nprint(len(incorrect_predictions),\" classified incorrectly\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=30)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\nclf.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\ny_pred=clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes","metadata":{}},{"cell_type":"code","source":"#Import Gaussian Naive Bayes model\nfrom sklearn.naive_bayes import GaussianNB\n\n#Create a Gaussian Classifier\nnb = GaussianNB()\n\n# Train the model using the training sets\nnb.fit(X_train,y_train)\n\n#Predict Output\nnb.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine","metadata":{}},{"cell_type":"code","source":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\nsv = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nsv.fit(X_train, y_train)\n\n#Predict the response for test dataset\n# y_pred = clf.predict(X_test)\nnb.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbors=2)\n\n# Train the model using the training sets\nmodel.fit(X_train, y_train)\n\nmodel.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Boosting ","metadata":{}},{"cell_type":"code","source":"#Import Gradient Boosting Classifier model\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#Create Gradient Boosting Classifier\ngb = GradientBoostingClassifier()\n\n#Train the model using the training sets\ngb.fit(X_train, y_train)\n\n#Predict the response for test dataset\ngb.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}