{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Extending Logistic Regression - LoL Diamond Ranked Matches\n\n\n# 1. Business Understanding\n\n### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u><code>About League of Legends:</code></u>\n    \n   Developed by Riot Studios, League of Legends, or \"LoL\", is an online multiplayer video-game that is available to Windows/MacOS users. LoL consists 2 teams ('Blue &amp; 'Red') facing each other, where the main objective is to destroy the opposing teams 'Nexus', or home base, while facing obstacles like destroying damage dealing towers &amp; eliminating players throughout the way. Perks &amp; gold are able to be obtained by players/teams through completing tasks such as eliminating players, enemy creeps, or dragons. Players then spend the gold to purchase items that help raise the power of their abilities.\n    \n   League of Legends offers different game modes, such as ranked. In this game mode, players are given a rank based off of the number of wins + the number of games played. \"Diamond\" is one of the highest ranks a player may obtain and is known to be extremely competitive. A ranked game on average lasts 30-45 minutes. The dataset we will be using contains the first 10 minute analytics of each team for different diamond ranked matches. \n    \n### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u><code>Measure of Success</code></u>\n    \n   Once the data is analyzed, third parties, or teams/players, would be able to conceptualize the level of priority different attributes have during early stages of diamond ranked matches. With the first 10-minutes of each game being critical, they could then use this information to adjust their strategy to one proven to win matches. In order for this data to be useful and trusted by third parties in specific situations such as playing at professional level, the data would have to render at least a 70% accuracy. The reason for it being 70% and not any higher is because as mentioned this data only include the first 10 minutes of a game (average full game: 30-45 minutes). We leave a 30% error gap for any changes of pace the winning team might have for the remaining time of the game (~67%).\n    \n   Additionally, players who are accustomed to playing as the 'jungle' role (a player role that focuses on obtaining objective eliminations within the jungle areas of the map) can use this analyzed data to better understand the impact elite monsters have on winning games.\n\n-------------------------------------\n    \nDataset [Kaggle]: __[First 10 minutes of diamond ranked League of Legends matches](https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min)__\n\nQuestion Of Interest : As of the first 10 minutes, which team will win?\n    \n-----------------------------------","metadata":{}},{"cell_type":"markdown","source":"# 2. Data Understanding\n\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Data Description","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Load in the dataset into a dataframe\ndf = pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')\n\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------------------------\n\nPrinting out the information about the dataframe we are able to see that there are a\ntotal of 9,879 instances, and 39 attributes.\n\nAdditionally we are able to see that there are 19 of the same attributes for each\nthe blue & red team (columns 1-19 are the same as 20-38).\n\nAttributes for each team includes :\n- Wards placed & destroyed\n- Total number of kills, deaths, & assists\n- First Bloods (1st elimination of the game)\n- Total : towers destroyed, gold, experience\n- Average : level, CS per minute, & gold per minute\n- Difference in gold & experience between the teams\n- Objective eliminations : elite monsters(dragons, heralds), minions, & jungle minions\n\nAttributes such as total gold, experience, objectives eliminations, towers destroyed, etc.\nwill be of type integer (int64) because they will always be whole numbers. Attributes involving\naverages such as cs per minute, gold per minute, & level, should be the only of double-precision floating-point\nformat (float64).\n\nThe data type for \"blueWins\" and \"first bloods\" could be changed to be of type boolean, but because we are wanting to\nvisualize these attributes later on, optimally it is best to keep these as integer data types. As a result,\nthe data types presented for each attribute are correct and should not be changed.\n\nBelow is a brief description of some of the key attributes.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# describe dataframe\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"| Variable | Description | Type | Range |\n| -------- | ----------- | ---- | ----- |\n| **blueWins** (target) | whether blue team won or not | Discrete | [0] red team won; [1] blue team won; |\n| WardsPlaced / WardsDestroyed | number of total wards placed or destroyed by team | Continuous | [placed] 5 - 250; [destroyed] 0 - 27 |\n| FirstBlood | team with the first kill of game | Discrete | [0] did not get first kill; [1] team obtained first kill |\n| Kills / Deaths / Assists | total number of kills, deaths, or assists of team | Continuous | [kills] 0 - 22; [deaths] 0 - 22; [assists] 0 - 29 |\n| TowersDestroyed | total number of towers destroyed by team | Continuous | 0 - 2 |\n| TotalGold | total gold obtained by team | Continuous | 11,000 - 25,000 |\n| AvgLevel | average level of all players on team | Continuous | 4.5 - 8.5 |\n| TotalExperience | total experience points accumulated by team | Continuous | 10,000 - 24,000 |\n| CSPerMin | average creep score per minute | Continuous | 10.0 - 30.0 |\n| GoldPerMin | average gold obtained per minute | Continuous | 1,100.0 - 2,000.0 |","metadata":{}},{"cell_type":"markdown","source":"## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Normalizing the Dataset","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# --- Encode the Categorical, discrete variables ---\nencoders = dict()\ncategorical_headers = ['blueFirstBlood','redFirstBlood']\n\nlabel_encoder = LabelEncoder()\ndf.blueWins = label_encoder.fit_transform(df.blueWins)\n\nencoders['blueFirstBlood'] = LabelEncoder()\ndf['blueFirstBlood' + '_int'] = encoders['blueFirstBlood'].fit_transform(df['blueFirstBlood'])\n\nencoders['redFirstBlood'] = LabelEncoder()\ndf['redFirstBlood' + '_int'] = encoders['redFirstBlood'].fit_transform(df['redFirstBlood'])\n\n\n# --- Scale the Numeric, continuous variables ---\nnumeric_headers = df.drop(['blueWins','blueFirstBlood','redFirstBlood'], axis=1)\n\nfor column in numeric_headers:\n    df[column] = df[column].astype(np.float)\n    ss = StandardScaler()\n    df[column] = ss.fit_transform(df[column].values.reshape(-1, 1))\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n---------------\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Data Quality\n\nUsing the `missingno` package, we are able to additionally confirm that all the data is complete\nand there is no missing entries with the dataset. If there was missing data, we could impute the\nmissing values by using the k-nearest neighbor. But if an instance was missing a majority of its\nattributes, it would be removed from the dataset.\n\nThe number of unique values in the column \"gameId\" is printed to verify that all instances\nare weighted equally.","metadata":{}},{"cell_type":"code","source":"import missingno as mn\n\nmn.matrix(df)\n\n# Count unique values in column 'gameId' of the dataframe\nprint('Number of unique values in column \"gameId\" : ', df['gameId'].nunique())\n\ndup_df = df.replace(to_replace=-1,value=np.nan)\n\ndup_df = dup_df.duplicated()\nprint('Duplicates : ', len(df[dup_df]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n------------------------------\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 Cleaning the Dataset\n\nAfter confirming there are no duplicates in the data, the \"gameId\" column can be removed since it\nwill have no impact on the results.\n\nUsing the correlation feature from the `pandas` package, for each team we find the names of\nattributes that correlate most with winning (correlation >= 7%). The names of these attributes\nare stored in a array for later use.\n\nLastly, two dataframes are created to hold the attributes at instances when blue team wins, and\nwhen blue team loses.","metadata":{}},{"cell_type":"code","source":"del df['gameId']\n\nred_col = df.corr()[df.corr()['blueWins'] <= -0.07].index.values\nblue_col = df.corr()[df.corr()['blueWins'] >= 0.07].index.values\n\n# Create dataframes for the 2 possible outcomes :\ndf_win  = df[df[\"blueWins\"]==1]     # Blue Team Win  /  Red Team Lost\ndf_lose = df[df[\"blueWins\"]==0]     # Red Team Win   /  Blue Team Lost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n-------------------\n\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.5 Creating Training & Test Data\n\nUsing Scikit-learn's \n<a href=\"https://scikit-learn.org/stable/modules/cross_validation.html\" target=\"_top\"><b>cross-validation modules</b></a>\nwe are able to split our dataset for training and testing purposes. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Create X data & y target dataframe's\nif 'blueWins' in df:\n    y = df['blueWins'].values\n    del df['blueWins']\n    X = df.to_numpy()\n\n\n# Divide the data: 80% Training & 20% Testing.  \nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n\nprint(\"Training Set\", \"\\n   - Data Shape:\",X_train.shape,\"\\n   - Target Shape:\",y_train.shape)\nprint(\"\\nTesting Set\",\"\\n   - Data Shape:\",X_test.shape ,\"\\n   - Target Shape:\",y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We perform a split within our dataset: 80% will be used for training, and 20% for testing. The 80/20 split is appropriate for\nthe dataset because recall that the end goal is for users to be able to determine the probabilities of them winning their\non-going game, or in other words we will only be predicting the win probability of __ONE__ game.\n\nAdditionally if a 90/10 split was applied it would also be appropriate to use as well. With League of Legends being a\nstrategy based game, our prediction algorithm essentially uses the training data to find which combination of \nobjectives/attributes have the biggest impact/correlation withing winning games. These game winning objectives/attributes could\nbe found quite early on during training, but we need to account that these objectives/attributes can be wrong in certain\ninstances due to the fact of the dataset only containing attributes for the first 10 minutes. So as the size of the training\nset increases, the amount of fine-tunning performed increases, thus rendering a higher accuracy when predicting through the\ntesting dataset.","metadata":{}},{"cell_type":"markdown","source":"\n-----------------------------\n\n# 3. Modeling\n\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1 Custom Logistic Regression Classifier","metadata":{}},{"cell_type":"code","source":"from numpy import ma\nfrom numpy.linalg import pinv\nfrom scipy.special import expit\nfrom scipy.optimize import fmin_bfgs\nfrom sklearn.metrics import accuracy_score\n\nclass Custom_LogisticRegression:\n    def __init__(self, eta, solver='lbfgs', penalty='l2', C=1, max_iter=100):\n        self.eta = eta            # Step Size\n        self.solver = solver      # Steepest Descent / Stochastic Gradient Descent / Newton's Method\n        self.penalty = penalty    # No Reg / L1 Reg / L2 Reg / Both L1 & L2\n        self.C = C                # Adjustable cost \n        self.max_iter = max_iter  # Number of times gradient will updated\n        # self.w_                 # weights \n        \n    def __str__(self):\n        if(hasattr(self,'w_')):\n            return 'Custom Logistic Regression Object with coefficients:\\n'+ str(self.w_)\n        else:\n            return 'Untrained Custom Logistic Regression Object'\n        \n    # return bias term if requested\n    @staticmethod\n    def _add_bias(X):   \n        return np.hstack((np.ones((X.shape[0],1)),X))\n    \n    # Activation Function\n    @staticmethod\n    def _sigmoid(theta):\n        return expit(theta)\n    \n    # Regularizes the gradient function according to self.penalty\n    def regularize(self,gradient):\n        gradient = gradient.reshape(self.w_.shape)\n        \n        # No Regularization \n        if self.penalty == 'none':\n            return gradient;\n        \n        # L1 Regularization\n        if self.penalty == 'l1':\n            gradient[1:] += np.sign(self.w_[1:]) * self.C\n            return gradient\n        \n        # L2 Regularization\n        if self.penalty == 'l2':\n            gradient[1:] += -2 * self.w_[1:] * self.C\n            return gradient\n        \n        # Both L1 & L2 Regularization  \n        if self.penalty == 'elasticnet':\n            gradient[1:] = (gradient[1:] + (np.sign(self.w_[1:]) * self.C)) + (gradient[1:] + ((-2 * self.w_[1:]) * self.C))\n            return gradient\n        \n    \n    def _get_gradient(self,X,y):\n        \n        # SGD = Stochastic Gradient Descent\n        if self.solver == 'SGD': \n            idx = int(np.random.rand()*len(y)) \n            ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n            gradient = X[idx] * ydiff[:,np.newaxis]                  # convert ydiff into column vector & multiply through\n            gradient = self.regularize(gradient);\n            \n            return gradient;\n        \n        # Hessian = Rank One Hessian Approximation \n        if self.solver == 'Hessian':\n            g = self.predict_proba(X,add_bias=False).ravel()  # get sigmoid value for all classes\n            hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n\n            ydiff = y-g \n            gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through \n            gradient = self.regularize(gradient) \n        \n            return pinv(hessian) @ gradient\n        \n    # Returns the probability of y being equal to 1\n    def predict_proba(self,X, add_bias=True):\n        Xb = self._add_bias(X) if add_bias else X\n        return self._sigmoid(Xb @ self.w_) \n    \n    # Return predicted values\n    def predict(self,X):\n        return (self.predict_proba(X)>0.5)\n    \n    def fit(self, X, y):\n        Xb = self._add_bias(X)\n        n_samples, n_features = Xb.shape\n        \n        # lbfgs = Least-memory BFGS\n        if self.solver == 'lbfgs':\n            self.w_ = fmin_bfgs(LBFGS.obj_function,              # Optimization function\n                                np.zeros((n_features,1)),        # initialization of np array\n                                fprime=LBFGS.obj_gradient,       # gradient function\n                                args=(Xb,y,self.C,self.penalty), # Additional args required for gradient/objective function\n                                gtol=1e-03,                      # stopping criteria for gradient, |v_k|\n                                maxiter=self.max_iter,           \n                                disp=False)\n            self.w_ = self.w_.reshape((n_features,1))\n            \n        if self.solver == 'SGD' or self.solver == 'Hessian':\n            self.w_ = np.zeros((n_features,1))\n            \n            for _ in range(self.max_iter):\n                gradient = self._get_gradient(Xb,y)\n                self.w_ += gradient*self.eta","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LBFGS or Least-memory BFGS (Part of Quasi-Newton Method family)\nclass LBFGS(Custom_LogisticRegression):\n    \n    # Activation Function\n    @staticmethod\n    def obj_function(w,X,y,C,p):\n        g = expit(X @ w)\n        return -np.sum(ma.log(g[y==1]))-np.sum(ma.log(1-g[y==0])) + C*sum(w**2)\n\n    @staticmethod\n    def obj_gradient(w,X,y,C,p):\n        ydiff = y - expit(X @ w)\n        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n        gradient = gradient.reshape(w.shape)\n        \n        # To align w/ sklearn conventions, lbfgs only handles L2 or no penalty\n        if p == 'none':\n            return -gradient;\n        if p == 'l2':\n            gradient[1:] += -2 * w[1:] * C\n            return -gradient","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n----------------------\n\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2 Custom Classifier Training","metadata":{}},{"cell_type":"code","source":"# Visualize the performance of the classifier using a lolipop plot w/ markers \ndef CustomTrainer(custom_LR):\n    costs = np.logspace(-5,1,20)\n    \n    accur = np.zeros((costs.size,1))     # accuracies depending on on each Cost value \n    c_val = np.zeros((costs.size,1))     # stores all cost values\n    \n    i = 0\n    for x in costs:\n        custom_LR.C=x                    # Update the cost value \n        c_val[i] = x\n        custom_LR.fit(X_train,y_train)   # Fit according to training data\n        yhat = custom_LR.predict(X_test) # Predict according to testing data\n        accur[i] = np.array(accuracy_score(y_test,yhat))\n        i = i + 1\n    # Prepare Data\n    df_tb = pd.DataFrame({'vals' : accur.reshape(-1)})\n    df_tb['c'] = c_val.reshape(-1)\n    df_tb['colors'] = 'red'              # Highest Validation Accuracy : Green & Lowest will be Red\n    df_tb.loc[df_tb.vals == (np.amax(df_tb.vals)), 'colors'] = 'green'\n    # Draw Plot\n    fig, ax = plt.subplots(figsize=(15,10), dpi=80)\n    ax.vlines(x=df_tb.index, ymin=0, ymax=df_tb.vals,color=df_tb.colors, alpha=0.7, linewidth=4)\n    ax.scatter(x=df_tb.index, y=df_tb.vals, s=75,color=df_tb.colors, alpha=0.7)\n   \n    # Labels, Title, YLimit \n    ax.set_xticks(range(0,len(costs)))\n    ax.set_xticklabels(['%.4f'%(ct) for ct in costs], rotation='vertical')\n    ax.set_xlabel('C')\n    ax.set_ylabel('Validation Accuracy')\n    ax.set_title(str(custom_LR.solver) + ' Custom Logistic Regression Trainer')\n    ax.set_ylim(0,0.8)\n    \n    # Annotate\n    for row in df_tb.itertuples():\n        ax.text(row.Index, row.vals + 0.02, s=round(row.vals,4),\n                horizontalalignment='center', verticalalignment='bottom',\n                fontsize=10)\n    \n    plt.grid(linestyle='--', alpha=0.5)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.1 Training with Stochastic Gradient Descent (SGD)","metadata":{}},{"cell_type":"code","source":"%%time\nsgd = Custom_LogisticRegression(eta=1, solver='SGD', penalty='l1')\nsgd.fit(X_train, y_train)\nyhat = sgd.predict(X_test)\nprint('Accuracy of:', accuracy_score(y_test,yhat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgd_Custom = Custom_LogisticRegression(eta=1,solver='SGD')\nsgd_Trained = CustomTrainer(sgd_Custom)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.2 Training with Rank-One Hessian (Quasi-Newton Method)","metadata":{}},{"cell_type":"code","source":"%%time\nhessian = Custom_LogisticRegression(eta=2, solver='Hessian', penalty='l1', C=0.1, max_iter=2)\nhessian.fit(X_train, y_train)\nyhat = hessian.predict(X_test)\nprint('Accuracy of:', accuracy_score(y_test,yhat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hessian_Custom = Custom_LogisticRegression(eta=1,solver='Hessian', max_iter=20)\nhessian_Trained = CustomTrainer(hessian_Custom)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.3 Training with Least-Memory BFGS (LBFGS) (Quasi-Newton Method)","metadata":{}},{"cell_type":"code","source":"%%time\nlbfgs = Custom_LogisticRegression(eta=1,max_iter=1)\nlbfgs.fit(X_train, y_train)\nyhat = lbfgs.predict(X_test)\nprint('Accuracy of:',accuracy_score(y_test,yhat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlbfgs = Custom_LogisticRegression(eta=1,max_iter=1)\nlbfgs.fit(X_train, y_train)\nyhat = lbfgs.predict(X_test)\nprint('Accuracy of:',accuracy_score(y_test,yhat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the 3 custom optimization procedures implemented it is to be noted that 2 instances are created, 1 that outputs the time\nand accuracy (v1), and then the other one is used to visualize the performance of various cost values (v2). The biggest\ndifferent between them is that \"data snooping\" was heavily involved with optimizing the parameters for v1. The v2 instance for\nthe hessian took the largest hit in regards to computation time. This is because for the v2 instances, default parameters were\nused (default max iterations for the Lfbgs/Hessian procedures were lowered to avoid compile errors). The LBFGS optimization procedure on the other hand was not affected at all, as confirmed by the lolipop plot. Is it also to be noted that because data snooping was performed in the v1 instances, they performed overall much better than v2 instances in regards to accuracy.   ","metadata":{}},{"cell_type":"markdown","source":"\n------------------------------\n\n## &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.3 Comparing Classifier Performance\n\nAlthough the hessian optimization technique rendered out the highest validation accuracy of all custom implementations, the time it took to compute this accuracy should be noted. Not too far behind the hessian in regards to accuracy is the Least-memory BFGS (LBFGS) implementation with a difference of ~0.1%. After looking at the LBFGS runtime the best performing procedure is without a doubt a clear winner. It renders in ${\\frac{1}{10}}$th of the time the hessian did!","metadata":{}},{"cell_type":"markdown","source":"### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.3.1 Custom LM-BFGS vs. Scikit LM-BFGS","metadata":{}},{"cell_type":"code","source":"%%time\n# Visualize the performance differences in terms of training time and classification performance.\nfrom sklearn.linear_model import LogisticRegression as SK_LogisticRegression\n\nlbfgs_sk = SK_LogisticRegression(max_iter=1) \nlbfgs_sk.fit(X_train,y_train)\nyhat = lbfgs_sk.predict(X_test)\nprint('Accuracy of:',accuracy_score(y_test,yhat))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlbfgs_sk2= SK_LogisticRegression(max_iter=109) \nCustomTrainer(lbfgs_sk2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlbfgs_custom = Custom_LogisticRegression(eta=1,max_iter=1)\nlbfgs_custom.fit(X_train, y_train)\nyhats = lbfgs_custom.predict(X_test)\nprint('Accuracy of:',accuracy_score(y_test,yhats))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlbfgs_custom2 = Custom_LogisticRegression(eta=1, max_iter=1)\nCustomTrainer(lbfgs_custom2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nAs you can see from the results above, our the Scikit learn is **MUCH** more faster than the custom LM-BFGS implementation created earlier. I decided to use the same parameters for both functions just so the comparison fair and neither has a disadvantage. But as shown above, the Scikit learn implemenation takes nearly $\\frac{1}{3}$rd of the time ours implementation took.  \n","metadata":{}},{"cell_type":"markdown","source":"\n------------------------\n\n# 4. Deployment\n\nIn regards to which logistic regression implementation would third parties prefer? With the parameters in both implemenations being identical and the results being significantly different, third parties would much rather prefer using the scikit learn implementation. I completely advise for this to be done, aside from it running much faster than the custom implementation of LM-BFGS, the validation percentage is the exact same. Also looking at the generated lolipop plots, noticed how for the custom implementation only 1 iteration was made, while for the Scikit-learn implementation it was iterated over 100 times, and it still managed to perform at a manageble time, although time itself isn't much a factor for third parties interested.","metadata":{}},{"cell_type":"markdown","source":"\n---------------------\n\n## References\n\n\nKaggle. League of Legends Diamond Ranked Games (First 10 Minutes).\nhttps://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min (Accessed 3-9-2021)\n\nScikit-learn. Cross-validation. https://scikit-learn.org/stable/modules/cross_validation.html (Accessed 3-9-2021)\n","metadata":{}}]}