{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"PCOS_inf = pd.read_csv(\"../input/polycystic-ovary-syndrome-pcos/PCOS_infertility.csv\",encoding='latin 1')\nPCOS_data = pd.read_csv(\"../input/vandithaaa/data without infertility _final.csv\",encoding='latin 1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After loading the data, lets print the data to have a look at the data. Remember, We are not looking at the features in the data. We are just making sure that all the data has been loaded correctly"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there is 1 null value in `Marraige Status (Yrs)`"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data[PCOS_data['Marriage Status (Yrs)'].isnull()].T\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data['Marriage Status (Yrs)'].fillna(PCOS_data['Marriage Status (Yrs)'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_data['Fast food (Y/N)'].fillna(PCOS_data['Fast food (Y/N)'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like we can just drop the last erroneous column and go ahead with the analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_inf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PCOS_inf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging the two dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.merge(PCOS_data,PCOS_inf, on='Patient File No.', suffixes={'','_y'},how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns = ['Sl No', 'Patient File No.', 'PCOS (Y/N)', 'Age (yrs)', 'Weight (Kg)',\n       'Height(Cm)', 'BMI','Pulse rate(bpm)',\n       'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)', 'Cycle length(days)',\n       'Marriage Status (Yrs)', 'Pregnant(Y/N)', 'No of aborptions',\n       'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)', 'Waist(inch)',\n       'Waist/Hip_Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',\n       'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)',\n       'hair growth(Y/N)', 'Skin darkening (Y/N)', 'Hair loss(Y/N)',\n       'Pimples(Y/N)', 'Fast food (Y/N)', 'Reg Exercise(Y/N)',\n       'BP Systolic(mmHg)', 'BP Diastolic(mmHg)', 'Follicle No (L)',\n       'Follicle No (R)', 'Avg Fsize(L) (mm)', 'Avg Fsize(R) (mm)','Insulin levels (ÂµIU/ml)',\n       'Endometrium (mm)', 'Sl.No_y', 'PCOS(Y/N)_y','I_beta-HCG(mIU/mL)_y', 'II_beta-HCG(mIU/mL)_y', 'AMH(ng/mL)_y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Sl.No_y', 'PCOS(Y/N)_y','AMH(ng/mL)_y'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have successfully loaded the data. "},{"metadata":{},"cell_type":"markdown","source":"# Fitting a Model"},{"metadata":{},"cell_type":"markdown","source":"Before fitting the model, we will have to split our data into **train**, **valid** and **test** sets. We can use sklearn's train_test_split function to split our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\ntarget = data['PCOS (Y/N)']\ndata.drop('PCOS (Y/N)',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,7))\nsns.countplot(target)\nplt.title('Data imbalance')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test, y_train, y_test = train_test_split(data, target, test_size=0.15, random_state=1, stratify = target)\nX_train,X_valid, y_train, y_valid =  train_test_split(X_train, y_train, test_size=0.3, random_state=1, stratify=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndef print_scores(m):\n    res = [roc_auc_score(y_train,m.predict_proba(X_train)[:,1]),roc_auc_score(y_valid,m.predict_proba(X_valid)[:,1])]\n    for r in res:\n        print(r)\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf = RandomForestClassifier(n_jobs=-1,n_estimators=150,max_features='sqrt',min_samples_leaf=10)\nrf.fit(X_train,y_train)\nprint_scores(rf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import roc_curve\ny_pred_proba = rf.predict_proba(X_valid)[:,1]\nfpr, tpr, thresholds = roc_curve(y_valid, y_pred_proba)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,7))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=11) ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are getting a high roc auc score, lets start with out Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_fi(m, df):\n    return pd.DataFrame({'col': df.columns, 'imp': m.feature_importances_}).sort_values('imp',ascending=False)\n\n#lets get the feature importances for training set\nfi = get_fi(rf,X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_fi(df):\n    df.plot('col','imp','barh',figsize=(10,10))\n    \nplot_fi(fi)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}