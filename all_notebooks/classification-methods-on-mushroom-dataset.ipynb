{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mushroom Classification Using Different Classifiers"},{"metadata":{},"cell_type":"markdown","source":"#### In this project, we will examine the data and create a machine learning algorithm that will detect if the mushroom is edible or poisonous by its specifications like cap shape, cap color, gill color, etc. using different classifiers.\n#### The dataset used in this project is \"mushrooms.csv\" which contains 8124 instances of mushrooms with 22 features like cap-shape, cap-surface, cap-color, bruises, odor, etc."},{"metadata":{},"cell_type":"markdown","source":"### Importing the packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # plotting graphs for visualizations\nimport matplotlib.pyplot as plt # plotting graphs for visualizations\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the csv file of the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examining the Data"},{"metadata":{},"cell_type":"markdown","source":"#### After importing the data, to learn more about the dataset, we'll use .head() .info() and .describe() methods."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shape of the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dataset shape:\",df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the count of edible and poisonous mushrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"class\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = df.iloc[:,0].value_counts()\nplt.figure(figsize=(8,7))\nsns.barplot(count.index, count.values, alpha=0.8, palette=\"prism\")\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Class', fontsize=12)\nplt.title('Number of poisonous/edible mushrooms')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The dataset is balanced."},{"metadata":{},"cell_type":"markdown","source":"# Data Manipulation"},{"metadata":{},"cell_type":"markdown","source":"#### The data is categorial so we'll convert it with LabelEncoder to transfer to ordinal."},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder=LabelEncoder()\nfor column in df.columns:\n    df[column] = labelencoder.fit_transform(df[column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The column \"veil-type\" is 0 and not contributing to the data so we remove it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop([\"veil-type\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick look at the characteristics of the data"},{"metadata":{},"cell_type":"markdown","source":"#### The violin plot below represents the distribution of the classification characteristics. It is possible to see that \"gill-color\" property of the mushroom breaks to two parts, one below 3 and one above 3, that may contribute to the classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_div = pd.melt(df, \"class\", var_name=\"Characteristics\")\nfig, ax = plt.subplots(figsize=(16,6))\np = sns.violinplot(ax = ax, x=\"Characteristics\", y=\"value\", hue=\"class\", split = True, data=df_div, inner = 'quartile', palette = 'Set1')\ndf_no_class = df.drop([\"class\"],axis = 1)\np.set_xticklabels(rotation = 90, labels = list(df_no_class.columns));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's look at the correlation between the variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(),linewidths=.1,cmap=\"Purples\", annot=True)\nplt.yticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Usually, the least correlating variable is the most important one for classification. In this case, \"gill-color\" has -0.53 so let's look at it closely."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['class', 'gill-color']].groupby(['gill-color'], as_index=False).mean().sort_values(by='class', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Lets look closely at the feature \"gill-color\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_var = df[['class', 'gill-color']]\nnew_var = new_var[new_var['gill-color']<=3.5]\nsns.factorplot('class', col='gill-color', data=new_var, kind='count', size=4.5, aspect=.8, col_wrap=4);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_var=df[['class', 'gill-color']]\nnew_var=new_var[new_var['gill-color']>3.5]\n\nsns.factorplot('class', col='gill-color', data=new_var, kind='count', size=4.5, aspect=.8, col_wrap=4);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing the Data"},{"metadata":{},"cell_type":"markdown","source":"#### Setting X and y axis and splitting the data into train and test respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['class'], axis=1)  \ny = df[\"class\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Methods"},{"metadata":{},"cell_type":"markdown","source":"## 1. Decision Tree Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n\ndot_data = export_graphviz(dt, out_file=None, \n                         feature_names=X.columns,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature importances"},{"metadata":{},"cell_type":"markdown","source":"#### By all methods examined before the feature that is most important is \"gill-color\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_list = X.columns.values\nfeature_importance = dt.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nplt.figure(figsize=(8,7))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center', color =\"red\")\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting and estimating the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_dt = dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Decision Tree Classifier report: \\n\\n\", classification_report(y_test, y_pred_dt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Accuracy: {}%\".format(round(dt.score(X_test, y_test)*100, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix for Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_dt)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Decision Tree Classifier')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Logistic Regression Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver=\"lbfgs\", max_iter=500)\nlr.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(lr.score(X_test, y_test)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification report of Logistic Regression Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_lr = lr.predict(X_test)\nprint(\"Logistic Regression Classifier report: \\n\\n\", classification_report(y_test, y_pred_lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix for Logistic Regression Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_lr)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Logistic Regression Classifier')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. KNN Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nbest_Kvalue = 0\nbest_score = 0\n\nfor i in range(1,10):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    if knn.score(X_test, y_test) > best_score:\n        best_score = knn.score(X_train, y_train)\n        best_Kvalue = i\n        \nprint(\"Best KNN Value: {}\".format(best_Kvalue))\nprint(\"Test Accuracy: {}%\".format(round(best_score*100,2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification report of KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_knn = knn.predict(X_test)\nprint(\"KNN Classifier report: \\n\\n\", classification_report(y_test, y_pred_knn))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix for KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_knn)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for KNN Classifier')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. SVM Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=42, gamma=\"auto\")\nsvm.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(svm.score(X_test, y_test)*100, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification report of SVM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_svm = svm.predict(X_test)\nprint(\"SVM Classifier report: \\n\\n\", classification_report(y_test, y_pred_svm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix for SVM Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_svm)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for SVM Classifier')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Naive Bayes Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(nb.score(X_test, y_test)*100, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification report of Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_nb = nb.predict(X_test)\nprint(\"Naive Bayes Classifier report: \\n\\n\", classification_report(y_test, y_pred_nb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix for Naive Bayes Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_nb)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Naive Bayes Classifier')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Random Forest Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(rf.score(X_test, y_test)*100, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification report of Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf = rf.predict(X_test)\nprint(\"Random Forest Classifier report: \\n\\n\", classification_report(y_test, y_pred_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix for Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_rf)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Random Forest Classifier');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{},"cell_type":"markdown","source":"### Predicting some of the X_test results and matching it with true i.e. y_test values using Decision Tree Classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = dt.predict(X_test)\n\nprint(preds[:36])\nprint(y_test[:36].values)\n\n# 0 - Edible\n# 1 - Poisonous","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we can see the predicted and the true values match 100%."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"### From the confusion matrix, we saw that our train and test data is balanced.\n### Most of classfication methods hit 100% accuracy with this dataset."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}