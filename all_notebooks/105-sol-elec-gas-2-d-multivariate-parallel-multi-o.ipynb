{"cells":[{"metadata":{},"cell_type":"markdown","source":"These notebooks are based on the excellent article by Jason Brownlee:\nHow to Develop Convolutional Neural Network Models for Time Series Forecasting.  \nhttps://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/"},{"metadata":{},"cell_type":"markdown","source":"test 105 : test prediction solarpower with *multivariate mulitiple parallel series* and multi-output CNN\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\nimport tensorflow as tf\nimport keras\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('tf version:',tf.__version__,'\\n' ,'keras version:',keras.__version__,'\\n' ,'numpy version:',np.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This notbook uses :  \ntf version: 2.0.0-beta1 ;\n keras version: 2.2.4 ; \n numpy version: 1.16.4 "},{"metadata":{"trusted":true},"cell_type":"code","source":"# load previous prediction results\npredicted_data = pd.read_hdf('../input/104-sol-elec-gas-2-c-multivariate-parallel-series/predicted_data4.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsolarpower = pd.read_csv(\"../input/solarpanelspower/PV_Elec_Gas3.csv\",header = None,skiprows=1 ,names = ['date','cum_power','Elec_kW', \n                                                                            'Gas_mxm'], sep=',',usecols = [0,1,2,3],\n                     \n                     parse_dates={'dt' : ['date']}, infer_datetime_format=True,index_col='dt')\nprint(solarpower.head(2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make cum_power stationary\n\nsolarpower2 = solarpower.shift(periods=1, freq='D', axis=0)\nsolarpower['cum_power_shift'] = solarpower2.loc[:,'cum_power']\nsolarpower['day_power'] = solarpower['cum_power'].values - solarpower['cum_power_shift']\nsolarpower.iloc[0:1].day_power.value = 0.\nA = solarpower.dropna()\ndel A['cum_power'], A['cum_power_shift']\nsolarpower = A","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solarpower.head(2), solarpower.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = solarpower[:'2019-10-28']\nX_valid = solarpower['2019-10-29':'2020-10-27'] # is 365 days\nX_train.shape, X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.tail(2), X_valid.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# we devide the series into multiple input and output patterns\n\ndef my_split_window(array, window):\n    '''\n    the array has the columns (features) that we use as input.\n    Returns array X with the features windowed in shape (number of windows, window, n_features)\n    and array y with n_features\n    '''\n    X = []\n    y = []\n    n_steps = len(array) - window\n    for step in range(n_steps):\n        X_w = []\n        for i in range(window):\n            X_w.append(array[step + i])\n        X.append(X_w)\n        y.append(array[step + window])\n    X = np.array(X)\n    y = np.array(y)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test my_split_window\ndf = pd.DataFrame()\ndf['feature1'] = [10,20,30,40,50,60,70,80,90]\ndf['feature2'] = [11,21,31,41,51,61,71,81,91]\ndf['feature3'] = [26, 46, 66, 86, 106, 126, 146, 166, 186]\nfeatures_test = ['feature1','feature2','feature3']\narray = np.array(df[features_test])\n# print(array[:3])\nwindow = 3\nX_, y_ = my_split_window(array, window)\nX_, y_\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_.shape, y_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# apply my_split_window on daily solar power with a window of 365 days (we do not make account for leap years)\n\nwindow = 365\nfeatures = X_train.columns.values\narray = np.array(X_train[features])\nX, y = my_split_window(array,  window)\n# print a sample\nfor i in range(3):\n    print(X[i][-2:], y[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to use a one-dimensional Convolutional Neural Network (1D CNN). Just like in a CNN for images,  \na 1D CNN extracts features. It is very usefull in timeseries. More info is on the links:  \nhttps://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/  \nhttps://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/  \n"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# model for Multiple parallel series input and prediction of one timestep parallel features\n# Each output series can be handled by a separate output CNN model (multi-output-cnn)\n# we have an input shape = (number of windows, window, n_features) \n#  and we have a window size of one year (365 days) \n\nn_features = X.shape[2]\nwindow = 365\n# define model\ndef input_model(window, n_features):\n    visible = tf.keras.layers.Input(shape=(window, n_features))\n    cnn = tf.keras.layers.BatchNormalization()(visible)\n    cnn = tf.keras.layers.Conv1D(filters=32, kernel_size=2, activation='relu')(cnn)\n    cnn = tf.keras.layers.MaxPooling1D(pool_size=2)(cnn)\n    cnn = tf.keras.layers.Flatten()(cnn)\n    cnn = tf.keras.layers.BatchNormalization()(cnn)\n    cnn_model = tf.keras.layers.Dense(50, activation='relu')(cnn)\n    return visible, cnn_model\n\n# we define one output layer for each feature\ndef output_3f_model(visible, cnn_model):\n    output1 = tf.keras.layers.Dense(1)(cnn_model)\n    output2 = tf.keras.layers.Dense(1)(cnn_model)\n    output3 = tf.keras.layers.Dense(1)(cnn_model)\n    model = tf.keras.Model(inputs=visible, outputs = [output1, output2, output3])\n    return model\n\nvisible, cnn_model = input_model(window, n_features)\nmodel = output_3f_model(visible, cnn_model)\n\nmodel.compile(optimizer='adam', loss='mae')\n# separate output\ny1 = y[:, 0].reshape((y.shape[0], 1))\ny2 = y[:, 1].reshape((y.shape[0], 1))\ny3 = y[:, 2].reshape((y.shape[0], 1))\n\n# fit model\nhistory = model.fit(X, [y1, y2, y3], epochs=200, verbose=0)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predicting next year based on data of X_valid to see if model is ok\n# the model expects an input of shape(n_time steps = window size, n_features)\ny_hat = []\nX_input =  np.array(X_train[-365:]) #  next value based on data of last year\nX_input = X_input.reshape(1, X_input.shape[0], X_input.shape[1]) # input must have 3 dimensions\nx_input=X_input\nfor i in range(365):\n    new_x = np.array(X_valid.iloc[i])\n    new_x = new_x.reshape(1, x_input.shape[0], x_input.shape[2])\n    x_input = np.concatenate((x_input[:, -364:], new_x), axis=1)\n    y_hat.append(model.predict(x_input, verbose=0))\n\n\ny_hat = np.array(y_hat)\n\ny_hat = y_hat.reshape(y_hat.shape[0],y_hat.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"\nplt.plot(y_hat[:,2], label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"first_r2_score = r2_score(y_true, y_hat[:,2]) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_hat[:,2])\nprint('r2_score %.5f' % first_r2_score)\nprint('mae %.2f' % first_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 100 epochs : 0.42520212661926315","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# but the cumulative power is actually much more intersting.#\n# It tells us what the the total expected solar power of that year will be. #"},{"metadata":{"trusted":false},"cell_type":"code","source":"def cumulate(series, start=0):\n    '''\n    start is the starting cumulative power, the series is the daily solar power\n    a list with daily cumulative power is the result\n    '''\n    cum = [start]\n    for i in range(len(series)):\n        sum_plus = cum[i] + series[i]\n        cum.append(sum_plus)\n    return cum","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_hat[:,2])\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.2f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# what if we add a feature?\nWe can make an extra feature by adding Elecricty and Gas"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = X_train.copy()\nX_valid = X_valid.copy()\nX_train['Gas_plus_Elek'] = X_train.Gas_mxm + X_train.Elec_kW\nX_valid['Gas_plus_Elek'] = X_valid.Gas_mxm + X_valid.Elec_kW","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# apply my_split_window on daily solar power with a window of 365 days (we do not make account for leap years)\n\nwindow = 365\nfeatures = X_train.columns.values\narray = np.array(X_train[features])\nX, y = my_split_window(array,  window)\n# print a sample\nfor i in range(3):\n    print(X[i][-2:], y[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# model for Multiple parallel series input and prediction of one timestep parallel features\n# Each output series can be handled by a separate output CNN model (multi-output-cnn)\n# we have an input shape = (number of windows, window, n_features) \n#  and we have a window size of one year (365 days) \n\nn_features = X.shape[2]\nwindow = 365\n# define model\nvisible, cnn_model = input_model(window, n_features)\n\n# we define one output layer for each feature\ndef output_4f_model(visible, cnn_model):\n    output1 = tf.keras.layers.Dense(1)(cnn_model)\n    output2 = tf.keras.layers.Dense(1)(cnn_model)\n    output3 = tf.keras.layers.Dense(1)(cnn_model)\n    output4 = tf.keras.layers.Dense(1)(cnn_model)\n    model = tf.keras.Model(inputs=visible, outputs = [output1, output2, output3, output4])\n    return model\n\nmodel = output_4f_model(visible, cnn_model)\n\nmodel.compile(optimizer='adam', loss='mae')\n# separate output\ny1 = y[:, 0].reshape((y.shape[0], 1))\ny2 = y[:, 1].reshape((y.shape[0], 1))\ny3 = y[:, 2].reshape((y.shape[0], 1))\ny4 = y[:, 3].reshape((y.shape[0], 1))\n# fit model\nhistory = model.fit(X, [y1, y2, y3, y4], epochs=200, verbose=0)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predicting next year\n# the model expects an input of shape(n_time steps = window size, n_features)\ny_hat = []\nX_input =  np.array(X_train[-365:]) #  next value based on data of last year\nX_input = X_input.reshape(1, X_input.shape[0], X_input.shape[1]) # input must have 3 dimensions\nx_input=X_input\nfor i in range(365):\n    new_x = np.array(X_valid.iloc[i])\n    new_x = new_x.reshape(1, x_input.shape[0], x_input.shape[2])\n    x_input = np.concatenate((x_input[:, -364:], new_x), axis=1)\n    y_hat.append(model.predict(x_input, verbose=0))\n    \ny_hat = np.array(y_hat)\ny_hat = y_hat.reshape(y_hat.shape[0],y_hat.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nplt.plot(y_hat[:,2], label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"first_r2_score = r2_score(y_true, y_hat[:,2]) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_hat[:,2])\nprint('r2_score %.5f' % first_r2_score)\nprint('mae %.2f' % first_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_hat[:,2])\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.5f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# prediction based on prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# model for Multiple parallel series input and prediction of one timestep parallel features\n# Each output series can be handled by a separate output CNN model (multi-output-cnn)\n# we have an input shape = (number of windows, window, n_features) \n#  and we have a window size of one year (365 days) \n\nn_features = X.shape[2]\nwindow = 365\n# define model\nvisible, cnn_model = input_model(window, n_features)\n\n# we define one output layer for each feature\ndef output_4f_model(visible, cnn_model):\n    output1 = tf.keras.layers.Dense(1)(cnn_model)\n    output2 = tf.keras.layers.Dense(1)(cnn_model)\n    output3 = tf.keras.layers.Dense(1)(cnn_model)\n    output4 = tf.keras.layers.Dense(1)(cnn_model)\n    model = tf.keras.Model(inputs=visible, outputs = [output1, output2, output3, output4])\n    return model\n\nmodel = output_4f_model(visible, cnn_model)\n\nmodel.compile(optimizer='adam', loss='mae')\n# separate output\ny1 = y[:, 0].reshape((y.shape[0], 1))\ny2 = y[:, 1].reshape((y.shape[0], 1))\ny3 = y[:, 2].reshape((y.shape[0], 1))\ny4 = y[:, 3].reshape((y.shape[0], 1))\n# fit model\nhistory = model.fit(X, [y1, y2, y3, y4], epochs=5000, verbose=0)\n\n# graph of the loss shows convergence\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.title('loss')\nplt.xlabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# predict next year based on prediction of next step\n# predicting next year\n# the model expects an input of shape(1, n_time steps = window size, n_features)\ny_hat = []\nX_input =  np.array(X_train[-365:]) #  next last value is predicted value\nX_input = X_input.reshape(1, window, n_features) # input must have 3 dimensions\nfor i in range(365):\n    y_hat.append((model.predict(X_input, verbose=0)))\n    #print(np.array(y_hat).shape)\n    new_X = np.array(y_hat[i])[:,0,0]\n    #print(new_X)\n    new_X = new_X.reshape(1, 1,new_X.shape[0])\n    X_input = np.concatenate((X_input[:, -364:], new_X), axis=1)\n    X_input = X_input.reshape(1, window, n_features)\ny_hat = np.array(y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nplt.plot(y_hat[:,2,0,0], label='predicted_power')\n\ny_true = X_valid.day_power.values\nplt.plot(y_true, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"first_r2_score = r2_score(y_true, y_hat[:,2,0,0]) # Best possible score is 1.0 \nfirst_mae = mean_absolute_error(y_true, y_hat[:,2,0,0])\nprint('r2_score %.5f' % first_r2_score)\nprint('mae %.2f' % first_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_true_cumulative = cumulate(y_true)\ny_predicted_cumulative = cumulate(y_hat[:,2,0,0])\n\nplt.plot(y_predicted_cumulative, label='predicted_power')\nplt.plot(y_true_cumulative, label='true_power')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"true_cumulative_power_after_one_year = int(y_true_cumulative[-1])\npredicted_cumulative_power_after_one_year = int(y_predicted_cumulative[-1])\nprint('true cumulative power after one year:', true_cumulative_power_after_one_year)\nprint('predicted cumulative power after one year:', predicted_cumulative_power_after_one_year)\n\nacc_one_year = 1- (true_cumulative_power_after_one_year - predicted_cumulative_power_after_one_year)/true_cumulative_power_after_one_year\nacc_one_year = acc_one_year * 100\n\nprint('accuracy after one year: %.2f' %  acc_one_year,'%')\nprint('r2 score %.5f ' % r2_score(y_true_cumulative, y_predicted_cumulative))\nprint('mae  %.2f' % mean_absolute_error(y_true_cumulative, y_predicted_cumulative))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predicted_data['105_4f_CNN_multi_ouput_5000epochs'] = y_hat[:,2,0,0]\npredicted_data.to_hdf('predicted_data5.hdf5',key='predicted_data', table='true',mode='a')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}