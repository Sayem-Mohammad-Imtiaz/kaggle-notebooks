{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/employee-attrition/HR-Employee-Attrition.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in df.columns:\n    print(f\"{column}: Number of unique values {df[column].nunique()}\")\n    print(\"==========================================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=\"columns\", inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_col = []\nfor column in df.columns:\n    if df[column].dtype == object and len(df[column].unique()) <= 30:\n        object_col.append(column)\n        print(f\"{column} : {df[column].unique()}\")\n        print(df[column].value_counts())\n        print(\"====================================\")\nobject_col.remove('Attrition')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(object_col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()\ndf[\"Attrition\"] = label.fit_transform(df.Attrition)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc_col = []\nfor column in df.columns:\n    if df[column].dtypes != object and df[column].nunique() < 30:\n        print(f\"{column} : {df[column].unique()}\")\n        disc_col.append(column)\n        print(\"====================================\")\ndisc_col.remove('Attrition')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_col = []\nfor column in df.columns:\n    if df[column].dtypes != object and df[column].nunique() > 30:\n        print(f\"{column} : Minimum: {df[column].min()}, Maximum: {df[column].max()}\")\n        cont_col.append(column)\n        print(\"====================================\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\n\nfor i, column in enumerate(disc_col, 1):\n    plt.subplot(4, 4, i)\n    df[df[\"Attrition\"] == 0][column].hist(bins=35, color='blue', label='Attrition = NO', alpha=0.6)\n    df[df[\"Attrition\"] == 1][column].hist(bins=35, color='red', label='Attrition = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\n\nfor i, column in enumerate(cont_col, 1):\n    plt.subplot(2, 4, i)\n    df[df[\"Attrition\"] == 0][column].hist(bins=35, color='blue', label='Attrition = NO', alpha=0.6)\n    df[df[\"Attrition\"] == 1][column].hist(bins=35, color='red', label='Attrition = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 30))\nsns.heatmap(df.corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":15})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = df.corr().nlargest(20, \"Attrition\").Attrition.index\nplt.figure(figsize=(15, 15))\nsns.heatmap(df[col].corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":10})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('Attrition', axis=1).corrwith(df.Attrition).plot(kind='barh', figsize=(10, 7))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_col = [column for column in df.drop('Attrition', axis=1).columns if df[column].nunique() < 20]\ndata = pd.get_dummies(df, columns=dummy_col, drop_first=True, dtype='uint8')\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape)\n\n# Remove duplicate Features\ndata = data.T.drop_duplicates()\ndata = data.T\n\n# Remove Duplicate Rows\ndata.drop_duplicates(inplace=True)\n\nprint(data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('Attrition', axis=1).corrwith(data.Attrition).sort_values().plot(kind='barh', figsize=(10, 30))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_correlation = data.drop('Attrition', axis=1).corrwith(data.Attrition).sort_values()\nmodel_col = feature_correlation[np.abs(feature_correlation) > 0.02].index\nlen(model_col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nX = data.drop('Attrition', axis=1)\ny = data.Attrition\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,\n                                                    stratify=y)\n\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)\nX_test_std = scaler.transform(X_test)\nX_std = scaler.transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_imp(df, model):\n    fi = pd.DataFrame()\n    fi[\"feature\"] = df.columns\n    fi[\"importance\"] = model.feature_importances_\n    return fi.sort_values(by=\"importance\", ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.value_counts()[0] / y_test.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stay = (y_train.value_counts()[0] / y_train.shape)[0]\nleave = (y_train.value_counts()[1] / y_train.shape)[0]\n\nprint(\"===============TRAIN=================\")\nprint(f\"Staying Rate: {stay * 100:.2f}%\")\nprint(f\"Leaving Rate: {leave * 100 :.2f}%\")\n\nstay = (y_test.value_counts()[0] / y_test.shape)[0]\nleave = (y_test.value_counts()[1] / y_test.shape)[0]\n\nprint(\"===============TEST=================\")\nprint(f\"Staying Rate: {stay * 100:.2f}%\")\nprint(f\"Leaving Rate: {leave * 100 :.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score\n\ndef evaluate(model, X_train, X_test, y_train, y_test):\n    y_test_pred = model.predict(X_test)\n    y_train_pred = model.predict(X_train)\n\n    print(\"TRAINIG RESULTS: \\n===============================\")\n    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\n    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\n    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n\n    print(\"TESTING RESULTS: \\n===============================\")\n    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\n    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\n    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Logistic Regression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr_clf = LogisticRegression(solver='liblinear', penalty='l1')\nlr_clf.fit(X_train_std, y_train)\n\nevaluate(lr_clf, X_train_std, X_test_std, y_train, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, roc_curve\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"g--\", label=\"Recall\")\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc=\"upper left\")\n    plt.title(\"Precision/Recall Tradeoff\")\n    \n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], \"k--\")\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    \n    \nprecisions, recalls, thresholds = precision_recall_curve(y_test, lr_clf.predict(X_test_std))\nplt.figure(figsize=(14, 25))\nplt.subplot(4, 2, 1)\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n\nplt.subplot(4, 2, 2)\nplt.plot(precisions, recalls)\nplt.xlabel(\"Precision\")\nplt.ylabel(\"Recall\")\nplt.title(\"PR Curve: precisions/recalls tradeoff\");\n\nplt.subplot(4, 2, 3)\nfpr, tpr, thresholds = roc_curve(y_test, lr_clf.predict(X_test_std))\nplot_roc_curve(fpr, tpr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_dict = {\n    'Logistic Regression': {\n        'Train': roc_auc_score(y_train, lr_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, lr_clf.predict(X_test)),\n    },\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}