{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n<h3><font color='black'>Data Mining Project </font></h3>\nGabriel Anand Sundalkar\n1001774881"},{"metadata":{},"cell_type":"markdown","source":"#                          <center style='color:blue'><u> BoardGameGeek Reviews</u></center>  "},{"metadata":{},"cell_type":"markdown","source":"### Table of Content: \n* [Introduction](#Introduction)\n* [Data Exploring](#Data_Exploring)\n* [Data Processing](#Data_Processing)\n* [Data Exploration](#Data_Exploration)\n* [Train Test Split](#train_test_split)\n\n* [Text preprocessing](#Text_preprocessing)\n    * [Count Vectorizer](#CountVectorizer) \n    * [TfidfVectorizer (Term Frequency times Inverse Document Frequency)](#TfidfVectorizer)\n        \n* [Model Selectoin](#Model_Selectoin)\n    * [Linear and Logistic Regression](#Linear_and_Logistic_Regression)\n    * [Linear Classifiers](#Linear_Classifiers)\n    * [Support Vector Machine](#Support_Vector_Machine)\n    * [Linear Support Vector Machine](#Linear_Support_Vector_Machine)\n    * [Naive Bayes Classifier](#Naive_Bayes_Classifier)\n    * [Decision Tree Classifier](#Decision_Tree_Classifier)\n    * [Ensemble Model](#Ensemble_Model)\n        * [Boosting Models](#Boosting_Models)\n        * [Random Forest Classifier](#Random_Forest_Classifier)\n        \n* [hyperparameter Tuning ](#hyperparameter_Tuning)\n     * [Grid Search Cross Validation](#GridSearchCV)\n     * [Randomized Search Cross Validation](#RandomizedSearchCV)\n        \n* [Results](#Results)\n* [References](#References)"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Introduction\" style='color:blue'>Introduction</h1>"},{"metadata":{},"cell_type":"markdown","source":"\n\n\nThe goal of this project is to showcase our dataminning skills by building a classifier\n\nThe present work is the result of putting together many posts and code documentation\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"import sys\nimport re \nimport sklearn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import decomposition, ensemble\nfrom sklearn import tree\n\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error \nfrom sklearn import linear_model, preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import model_selection, preprocessing, metrics\nfrom sklearn.model_selection import cross_val_score , train_test_split\n\nimport nltk\nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom collections import defaultdict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id = \"Data_Description\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Data_Exploring\" style='color:blue'>Data Description</h1>"},{"metadata":{},"cell_type":"markdown","source":"\n\n The source of the data is Kaggle https://www.kaggle.com/jvanelteren/boardgamegeek-reviews.\n \n The data was extracted the 2020-08-19 (As it is constanly updated)\n \n The data spread over 3 CSV files:\n \n- <i>games_detailed_info.csv</i>  (with 56 columns and 17063) : \nThis file has a many detials about all type of board games, exmaples: are  the game rank, number of plyers,    number of user rated, time requried for the game, desiner and some instructions.    \n*** \n-  <i>bgg-13m-reviews.csv</i> (with 6 columns and 13170073):\nprovids the user names with there reviews and rating for each game.\n*** \n- <i>2019-08-19.csv</i> (9 columns and 17065) : \nThis file contain more precisis information for each game the game name ,year, rank and number of users rated. "},{"metadata":{},"cell_type":"markdown","source":"### Load Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"detailed_df = pd.read_csv('./data/games_detailed_info.csv',low_memory=False)  # for the interpretuer to deterimne datatype it take hight memorey\nreviews_df = pd.read_csv('./data/bgg-15m-reviews.csv')\nranking_df = pd.read_csv('./data/2020-08-19.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" detailed_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reviews_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ranking_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"detailed_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ranking_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reviews_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id = \"Data_Processing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Data_Processing\" style='color:blue'> Data Processing </h1>"},{"metadata":{},"cell_type":"markdown","source":"\nData cleaing and data process is the first phase of a data science project, in fact real data is messy, and include missing parts, hence we need to remove and correct the missing data, so that our eventual machine learning model doesn't learn from noise, thus reducing the performance of the end model\n\nwe are going to drop all the missing columns and the missing reviews. Then we are going to merge all the data frames together to produce one data frame with all the required features.\n\n"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# count the missing data\ndetailed_df.isnull().sum(), ranking_df.isnull().sum(), reviews_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Drop all the coulmns with missing values and the redundent/uneeded once for our classfiaction problem\nmissing_columns_names = [\n    'Unnamed: 0',   \n    \"Children's Game Rank\", 'Commodore 64 Rank','Customizable Rank', 'Family Game Rank','Party Game Rank', \n    'Abstract Game Rank','Accessory Rank', 'Amiga Rank','Arcade Rank', 'Atari ST Rank',                     \n    'RPG Item Rank', 'Strategy Game Rank', 'Thematic Rank', 'Video Game Rank',        \n    'boardgamedesigner', 'boardgameexpansion',  'boardgamefamily',  'boardgameimplementation', \n    'War Game Rank', 'alternate', 'boardgameartist', 'boardgamecategory', 'boardgamecompilation',             \n    'boardgameintegration', 'boardgamemechanic','boardgamepublisher', 'description','image',                               \n    'suggested_language_dependence', 'suggested_playerage', 'thumbnail','type' \n]\ndetailed_df = detailed_df.drop(axis=1, index=None, columns=missing_columns_names)\nranking_df = ranking_df.drop(axis=1, index=None, columns=['URL','Thumbnail'])\nreviews_df = reviews_df.drop(axis=1 ,columns=['Unnamed: 0']) \nreviews_df = reviews_df.dropna(axis=0 ,subset=['comment'])    # Drop all missing reviews ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nJoin the dataframes using common column 'id'\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"ranking_detailed_df = pd.merge(left=ranking_df, right=detailed_df, left_on='ID', right_on='id') # inner join","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"joint_df = pd.merge(left=reviews_df, right=ranking_detailed_df, how='left', left_on='ID', right_on='ID') # left join\nprint(f'The joined dataset shape {joint_df.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bivariable analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.heatmap(joint_df.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"Average\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"rating\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"averageweight\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"Rank\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"numweights\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"stddev\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_df[\"Bayes average\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above visualization we can:\n\n    1- eleminate variable with negative correlation with target variable\n    2- elimianate variables that are strongly correlated (have same information, hence their presence will give more weight to the same information and thus bias the model)"},{"metadata":{"trusted":false},"cell_type":"code","source":"joint_df['playes_num'] = joint_df['maxplayers'] - joint_df['minplayers']\njoint_df['play_time'] = joint_df['maxplaytime'] - joint_df['minplaytime']\njoint_df['Time'] = joint_df[['playingtime','play_time']].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"joint_reviews_renking_detailed = joint_df[['Name','Year','rating','numweights','usersrated', 'numcomments','user','comment', 'wanting', 'wishing', 'trading', 'owned','Time','playes_num','minage']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"joint_reviews_renking_detailed = joint_reviews_renking_detailed.dropna(axis=0)\njoint_reviews_renking_detailed = joint_reviews_renking_detailed.drop_duplicates(subset=None, keep=\"first\", inplace=False)\njoint_reviews_renking_detailed.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Data_Exploration\" style='color:blue'>Data Exploration</h1>"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(9, 7))\nsns.set(color_codes=\"True\")\nsns.distplot(joint_reviews_renking_detailed[\"rating\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"joint_reviews_renking_detailed.rating.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rate_group = joint_reviews_renking_detailed.groupby(['rating'])\nname_group = joint_reviews_renking_detailed.groupby(['Name'])\nyear_group = joint_reviews_renking_detailed.groupby(['Year'])\nuser_group = joint_reviews_renking_detailed.groupby(['user'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(joint_reviews_renking_detailed['rating'].nunique())   \nprint(joint_reviews_renking_detailed['Name'].nunique()) \nprint(joint_reviews_renking_detailed['Year'].nunique()) \nprint(joint_reviews_renking_detailed['user'].nunique()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(joint_reviews_renking_detailed.rating.mode().value_counts())\nprint(joint_reviews_renking_detailed.Name.mode().value_counts())\nprint(joint_reviews_renking_detailed.Year.mode().value_counts())\nprint(joint_reviews_renking_detailed.user.mode().value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring the top 30 games"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\njoint_reviews_renking_detailed.loc[joint_reviews_renking_detailed['comment'].notna()]['Name'].value_counts()[:30].plot(kind='bar')\nplt.xlabel('Name')\nplt.ylabel('Review Count')\nplt.title('Top 30 Most Reviewed Board Games')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id = \"Text_preprocessing\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Text_preprocessing\" style='color:blue'>Text preprocessing</h1>"},{"metadata":{},"cell_type":"markdown","source":"\nThe comment column contain expressive text, but we need to process it into a form that can be handled by the model, this is part of the natural language processing (NLP)\n\nTo process the text we:\n\n    - Remove the stop words.\n    - Remove the punctuations.\n    - Convert text to lower case.\n    - Drop words with frequency less than 5.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"stop_words = set(stopwords.words('english')) \nreplace_signs = re.compile('[/(){}\\[\\]\\|@,;]')    # Remove characteris from dict \nreplace_digit = re.compile('[^0-9a-z #+_]')       # Remove digits from dict\nwords = set(nltk.corpus.words.words())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Helpers functions to process text\ndef tokenize_remove_punctuations(sentences):               \n    wordfreq = defaultdict(lambda : 0)\n    for sentence in sentences:\n        words = nltk.RegexpTokenizer(r\"\\w+\").tokenize(sentence.lower())                                                 # len(word)>2   \n        for word in words: \n            if word in stop_words or word.isdigit() or len(word) < 1 or not word.isalpha():\n                continue\n            wordfreq[word] += 1\n    return wordfreq \n\n\ndef sort_words_freq(frequencies):                        \n    return dict(sorted(frequencies.items(), key=lambda word: word[1], reverse=True))\n \ndef delete_threshold(wordfreq): \n    return {word: frequency for word, frequency in wordfreq.items() if frequency > 5}\n  \ndef vector_matrix_review(X):\n    sentence_vectors = []\n    for txt,i  in zip(X,y):\n        sentence_tokens = nltk.RegexpTokenizer(r\"\\w+\").tokenize(txt)\n        sent_vec = []\n        for token in wordfreq_sorted_X:   \n            if token in sentence_tokens:\n                sent_vec.append(1)\n            else:\n                sent_vec.append(0)\n        sentence_vectors.append([sent_vec,i])\n    return sentence_vectors    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x = tokenize_remove_punctuations(joint_reviews_renking_detailed['comment'])\nx = sort_words_freq(x)\nx = delete_threshold(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nLet's print the top 50 words in the dictionary,\n"},{"metadata":{},"cell_type":"markdown","source":"## Split out Training Set and Test Set "},{"metadata":{"trusted":false},"cell_type":"code","source":"X = joint_reviews_renking_detailed['comment'].sample(6000) #frac = 0.10 # this is less than 10% of the dataset \ny = joint_reviews_renking_detailed['rating'].astype(int).sample(6000) # convert all float to a intger for classification ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id = \"CountVectorizer\"></a>"},{"metadata":{},"cell_type":"markdown","source":"# CountVectorizer"},{"metadata":{"trusted":false},"cell_type":"code","source":"from nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer \n\n\nclass LemmaTokenizer:\n    def __init__(self):\n         self.wnl = WordNetLemmatizer()\n    def __call__(self, doc):\n         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n\n# credits to [https://scikit-learn.org/stable/modules/feature_extraction.html] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# convert our text documents to a matrix of token counts\nvect = CountVectorizer(min_df=5,lowercase=True,ngram_range=(1, 2), stop_words=stopwords.words('english') + list(string.punctuation))                     \nX_train_0 = vect.fit_transform(X_train)\nX_test_0 = vect.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id = \"TfidfVectorizer\"></a>"},{"metadata":{},"cell_type":"markdown","source":"# TfidfVectorizer (Term Frequency times Inverse Document Frequency)"},{"metadata":{"trusted":false},"cell_type":"code","source":"tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.75, smooth_idf=True, stop_words=stopwords.words('english') + list(string.punctuation))    \nX_train_1 = tfidf.fit_transform(X_train)\nX_test_1 = tfidf.transform(X_test)      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Model_Selectoin\" style='color:blue'>Model Selectoin</h1>"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"classifiers = [\n    linear_model.LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000),\n    svm.LinearSVC(),\n    MultinomialNB(),\n    SGDClassifier(),\n    ensemble.AdaBoostClassifier(),\n    DecisionTreeClassifier(),\n    ensemble.RandomForestClassifier(n_estimators = 100)\n]\n\n\nfor item in classifiers:\n    print(item)\n    model = item\n    model.fit(X_train_0, y_train)\n    \n    y_train_pred = model.predict(X_train_0)\n    print(\"training Score = \",model.score(X_train_0,y_train))   #training score\n    print(\"Train Mean Squer Error =  \", mean_squared_error(y_train_pred.astype(int), y_train))\n    \n    y_pred = model.predict(X_test_0)\n    print(\"test Score = \", accuracy_score(y_pred.astype(int), y_test))    #test score\n    print(\"Test Mean Squer Error =  \", mean_squared_error(y_pred.astype(int), y_test),\"\\n\")\n       \n    \n    plt.figure(figsize=(10, 8))\n    sns.set(color_codes=\"True\")\n    sns.distplot(y_test.values[:15], color='b', label= 'Actual', kde_kws={'bw':1.1})   # its shows only the first 15 data point\n    sns.distplot(y_pred[:15], color='orange', label='Predicted', kde_kws={'bw':1.1})\n    plt.legend()\n    plt.show() \n    print(\"\\n---------------------------------------------------------------------------------\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"classifiers = [\n    linear_model.LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=1000), # to handle the FutureWarning\n    svm.LinearSVC(),   \n    SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=1000, tol=None),\n    MultinomialNB(),\n    DecisionTreeClassifier(),\n    ensemble.AdaBoostClassifier(),\n    ensemble.RandomForestClassifier(n_estimators = 100)\n]\n\n\n\nfor item in classifiers:\n    print(item)\n    model = item\n    model.fit(X_train_1, y_train)\n    \n    y_train_pred = model.predict(X_train_1)\n    print(\"training Score = \",model.score(X_train_1,y_train))   #training score\n    print(\"Train Mean Squer Error =  \", mean_squared_error(y_train_pred.astype(int), y_train))\n    \n    y_pred = model.predict(X_test_1)\n    print(\"test Score = \", accuracy_score(y_pred.astype(int), y_test))    #test score\n    print(\"Test Mean Squer Error =  \", mean_squared_error(y_pred.astype(int), y_test), \"\\n\")\n    \n    \n    plt.figure(figsize=(10, 8))\n    sns.set(color_codes=\"True\")\n    sns.distplot(y_test.values[:15], color='b', label= 'Actual', kde_kws={'bw':1.1})\n    sns.distplot(y_pred[:15], color='orange', label='Predicted', kde_kws={'bw':1.1})\n    plt.legend()\n    plt.show() \n    \n    \n    \n    print(\"\\n---------------------------------------------------------------------------------\\n\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"|    | Logistic Regression | Linear support vector classifier | Decision Tree Classifier | RandomForestClassifier |\n|:--:|:---------------------:|:---------------------:       |:---------------------:   |:---------------------: |\n| Training Score |   0.735   |         0.807                |        0.948             |        0.948            | \n| Test Score     |   0.212   |         0.200                |        0.192              |        0.338            | \n\n***\n\n|    | Multinomial Niave Bayes |  Stochastic Gradient Descent | AdaBoostClassifier       | \n|:--:|:---------------------:  |:---------------------:       |:---------------------:   |\n| Training Score |   0.509     |         0.793                |        0.265             | \n| Test Score     |   0.228     |         0.186                |        0.268             | \n\n\n"},{"metadata":{},"cell_type":"markdown","source":"Let's Have a closer look to the numbers"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"y_test=\" ,y_test.values[:15] ,\"y_pred=\", y_pred[:15])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict the first review as an example "},{"metadata":{"trusted":false},"cell_type":"code","source":"print(joint_reviews_renking_detailed['comment'][0],\"Actual rating is\", joint_reviews_renking_detailed['rating'][0])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"\n# you can try diffrent text to perdict \n\nmodel = ensemble.RandomForestClassifier(n_estimators = 100)\nmodel.fit(X_train_1, y_train)\ny_pred = model.predict(X_test_1)    \n    \ny_pred1 = model.predict(tfidf.transform([\"Currently, this sits on my list as my favorite game\"]))\nprint(\"test Score = \",y_pred1.astype(int))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id = \"hyperparameter_Tuning\"></a>"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"hyperparameter_Tuning\" style='color:blue'>hyperparameter Tuning and Model Optimization</h1>"},{"metadata":{},"cell_type":"markdown","source":"### Cross Validation "},{"metadata":{},"cell_type":"markdown","source":"### Training Visualizations and Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"\nContinue with our best model <i>RandomForestClassifier</i>, we are going to look at the confusion matrix, and show the discrepancies between predicted and actual labels. The confusion matrix is a great way to see which categories model is mixing.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"\nprint(metrics.classification_report(y_test, y_pred))\nprint(\"Confusion matrix \\n\", confusion_matrix( y_test, np.array(y_pred))) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are some labels almost are not mentioned 1,2,3,4,5 and 10. Non of these appaer in the prediaction result. Becuase, the model is not good enough, the data is imbalanced and the sample size we took is small. "},{"metadata":{},"cell_type":"markdown","source":"\n<a id =\"GridSearchCV\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Grid Search Cross Validation"},{"metadata":{"trusted":false},"cell_type":"code","source":"\n# Parameter estimation using grid search with cross-validation\n\nX = joint_reviews_renking_detailed['comment'].sample(6000) # this is 10% of the dataset \ny = joint_reviews_renking_detailed['rating'].astype(int).sample(6000) # convert all float to a intger for classification \n#split for 30% test set, 70% train set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\ntfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.75, smooth_idf=True, \n                    stop_words=stopwords.words('english') + list(string.punctuation))    \n                    \nX_trainT = tfidf.fit_transform(X_train)\nX_testT = tfidf.transform(X_test)  \n\n\nfrom sklearn.model_selection import GridSearchCV\n\ntuned_parameters = [\n{'n_estimators': [10, 25], 'max_features': [5, 10], \n 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n]\n\n    \nrf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10, scoring='neg_mean_squared_error')\nrf.fit(X_trainT, y_train)\n\n#best_estimator_ returns the best estimator chosen by the search\n#print(rf.best_estimator_)\nprint()\nprint(\"best_parameters\", rf.best_params_)\n\nmeans = rf.cv_results_['mean_test_score'][rf.best_index_]\nstds = rf.cv_results_['std_test_score'][rf.best_index_]\n#params = rf.cv_results_['params']\n#print(\"mean , std )\" % (mean, std))\nprint()\n\ny_true, y_pred = y_test, rf.predict(X_testT)\nprint(classification_report(y_true, y_pred.astype(int)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy is still low, "},{"metadata":{},"cell_type":"markdown","source":"### Mean squared error (MSE )"},{"metadata":{},"cell_type":"markdown","source":"Mean squared error measures the average of the squared error between the actual and predicted value.\nThe closer value to zero the more efficient estimator we have. The value of 2.95 indicates the distance between the actual rating and the predicted rating which still not good enough. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"\ngrid_best= rf.best_estimator_.predict(X_testT)\nMSE = np.square(np.subtract(y_test,y_pred)).mean()   # calculate Mean squared error\nprint('The model error is', round(MSE, 2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mean Absolute Percentage Error (MAPE)"},{"metadata":{},"cell_type":"markdown","source":"MAPE is another performance metric similar to MSE, but this one represents percentages."},{"metadata":{"trusted":false},"cell_type":"code","source":"\ngrid_best= rf.best_estimator_.predict(X_testT)\nerrors = abs(grid_best - y_test)\nmape = np.mean(100 * (errors / y_test))\naccuracy = 100 - mape    \nprint('The final accuracy of', round(accuracy, 2),'%')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<a id =\"RandomizedSearchCV\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## Randomized Search Cross Validation"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Parameter estimation using Randomized Search with cross-validation\n\n\nX = joint_reviews_renking_detailed['comment'].sample(6000) # this is 10% of the dataset \ny = joint_reviews_renking_detailed['rating'].astype(int).sample(6000) #frac = 0.7\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\ntfidf = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.75, smooth_idf=True, \n                    stop_words=stopwords.words('english') + list(string.punctuation))    \n                    \nX_trainTT = tfidf.fit_transform(X_train)\nX_testTT = tfidf.transform(X_test)  \n\n\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\n# Minimum number of samples required to split a node\nmin_samples_split = [5, 10]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split}\n\n\n\nrf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n                               param_distributions = random_grid, n_iter = 5, cv = 10, \n                               verbose=2, random_state=42, scoring='neg_mean_squared_error')\n# Fit the random search model\nrf_random.fit(X_trainTT, y_train)\nrandom_best= rf_random.predict(X_trainTT)\n\n\n# best random model \nprint(rf_random.best_estimator_)\n\n# best combination of parameters of random search\nprint(rf_random.best_params_)\n\n\n#this is the RMSE\nfinal_mse = mean_squared_error(y_train, random_best)\nfinal_rmse = np.sqrt(final_mse)\nprint('The best model on training set has a RMSE of', round(final_rmse, 2))\n\n    \n# Credits goes to     \n#https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n#https://www.kaggle.com/emanueleamcappella/random-forest-hyperparameters-tuning  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#import scipy\n#scipy.test() clean memory ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"final_model = rf_random.best_estimator_\n# Predicting test set results\nfinal_pred = final_model.predict(X_testTT)\nfinal_mse = mean_squared_error(y_test, final_pred)\nfinal_rmse = np.sqrt(final_mse)\nprint('The final RMSE on the test set is', round(final_rmse, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#calculate accuracy\nerrors = abs(final_pred - y_test)\n# Calculate mean absolute percentage error (MAPE)\nmape = np.mean(100 * (errors / y_test))\n# Calculate and display accuracy\naccuracy = 100 - mape    \n#print result\nprint('The final model accuracy on the test set is', round(accuracy, 2),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Results\" style='color:blue'>Results and Futuer Work</h1>"},{"metadata":{},"cell_type":"markdown","source":"TfidfVectorizer is more efficatve than using only CounterVectorizer. The most performant machine learing models are: \n* Linear SVC \n* Decision Tree Classifier\n* SGD Classifier\n* Random Forest Classifier"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"Challenges\" style='color:blue'>Challenges</h1>"},{"metadata":{},"cell_type":"markdown","source":"\nWe experienced many challenges during this work, usually preparing the data time the most time, then working to improve the model accuracy and tuning the model parameters. The challenged we faced are:\n\n* Understanding data \n* Computation ressources (a larger grid search would need more computation power)\n* Feature extraction \n* Improving score\n\n"},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"References\" style='color:blue'>References</h1>"},{"metadata":{},"cell_type":"markdown","source":"* https://www.kaggle.com/ngrq94/boardgamegeek-reviews-data-preparation\n \n* https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n \n* https://monkeylearn.com/text-classification/\n\n* https://www.kaggle.com/emanueleamcappella/random-forest-hyperparameters-tuning\n\n* https://guneetkohli.github.io/machine-learning/board-game-reviews/#.XqK_ky-z1QI\n\n* https://docs.google.com/viewer?a=v&pid=sites&srcid=YWltcy5hYy50enxhaW1zLXRhbnphbmlhLWFyY2hpdmV8Z3g6YmI1ODkxYjEwOGQ4NGVi\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}