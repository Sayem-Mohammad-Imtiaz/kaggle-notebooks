{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading dataset and priniting top 5 rows\ntop50 = pd.read_csv('/kaggle/input/top50spotify2019/top50.csv', encoding='cp1252')\ntop50.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the statistics of dataset for numerical variables\ntop50.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the statistics of dataset for categorical variables\ntop50.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping the Unnamed fiels as it adds no value to our analysis\ntop50=top50.drop('Unnamed: 0', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking If Null Values Exist\ntop50.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DataAnalysis\n#Checking Most Popular Genre\n\ntop50['Genre'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Histogram of Genre  \nplt.figure(figsize=(15,10))\nsns.countplot(top50['Genre'])\nplt.title('Distribution by Genre')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine related Genres as many variations of each genre are present in data set\n# Selecting rows where Genre contains the word \"pop\"\nsns.countplot(top50[top50['Genre'].str.contains('pop')]['Genre'])\nplt.title('Distribution by Pop Genre')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.loc[top50['Genre'].str.contains('pop', case=False), 'Genre'] = 'Pop'\ntop50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50['Genre'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.loc[top50['Genre'].str.contains('hip', case=False), 'Genre'] = 'Hip Hop'\ntop50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.loc[top50['Genre'].str.contains('rap', case=False), 'Genre'] = 'Rap'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.loc[top50['Genre'].str.contains('reggaeton', case=False), 'Genre'] = 'Reggaeton'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50['Genre'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking pairplots of all variables first. \nplt.figure(figsize=(20,10))\nsns.pairplot(top50, hue='Genre')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (20, 10))\nsns.heatmap(top50.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.drop('Track.Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.drop('Artist.Name', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing library for label encoding the Genre Data. \nfrom sklearn.preprocessing import LabelEncoder\n# creating object for label encoding. \nle = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the Genre column. \ntop50.Genre = le.fit_transform(top50.Genre)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top50.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the distribution of target variable. \nplt.figure(figsize=(20,10))\nsns.distplot(top50.Popularity)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the Features and Targets datasets. \nX = top50[['Genre', 'Beats.Per.Minute', 'Energy', 'Danceability',\n       'Loudness..dB..', 'Liveness', 'Valence.', 'Length.', 'Acousticness..',\n       'Speechiness.']]\n\ny = top50.Popularity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing library for Train Test split. \nfrom sklearn.model_selection import train_test_split\n# Creating the splits. \nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing library for standard scaling\nfrom sklearn.preprocessing import StandardScaler\n# Creating the scaler object\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the Training and Testing Data. \nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n# Checking the dimensions of the training and testing sets. \nprint(\"Training Feature data : \", X_train.shape)\nprint(\"Training Feature data : \", X_test.shape)\nprint(\"Training Feature data : \", y_train.shape)\nprint(\"Testing Target data : \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the training data. \nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the libraries .\nfrom sklearn.linear_model import LinearRegression\n# Creating the object\nregressor = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model. \nregressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the test results. \ny_pred = regressor.predict(X_test)\n# Checking the predictions. \ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the actuals\ny_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dataframe of features and coefficients. \noutput = {'Features': X.columns, 'Coefficient': regressor.coef_}\noutput_df = pd.DataFrame(output)\noutput_df.sort_values('Coefficient')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking RMSE\n\n# Import libraries. \nfrom sklearn.metrics import mean_squared_error\n\n# Checking the RMSE\nmean_squared_error(y_pred, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the intercept\nregressor.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the RFE Library. \nfrom sklearn.feature_selection import RFE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 5\n# We select 5 as we have total 10 variables, hence 5 looks to be a good number,\n# Considering we do not loose much information from the functional perspective as well .. !! \nrfe = RFE(regressor, 5) # running RFE\nrfe = rfe.fit(X_train, y_train) # Fitting the training data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the columns with RFE\nlist(zip(X.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating new set of features. \nX_new = X[['Genre', 'Energy', 'Valence.', 'Length.', 'Speechiness.']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the Training and Testing Data. \nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n# Creating the object\nregressor_rfe = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model. \nregressor_rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the predictions. \ny_pred_rfe = regressor_rfe.predict(X_test)\n# Checking the RMSE\nmean_squared_error(y_pred_rfe, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the intercept\nregressor_rfe.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dataframe of features and coefficients. \noutput_rfe = {'Features': X_new.columns, 'Coefficient': regressor_rfe.coef_}\noutput_df_rfe = pd.DataFrame(output_rfe)\noutput_df_rfe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will compare the differences as well, if possible. \nprediction_diff = y_pred_rfe - y_test\ncheck_predictions = {'Predictions': y_pred_rfe, 'Actuals': y_test, 'Difference': prediction_diff}\ncheck_predictions_df = pd.DataFrame(check_predictions)\ncheck_predictions_df.sort_values('Difference')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure(figsize=(20,10))\nplt.scatter(y_test,y_pred)\nfig.suptitle('Actuals v/s Predicted', fontsize=20)              # Plot heading \nplt.xlabel('Actuals', fontsize=18)                          # X-label\nplt.ylabel('Predicted', fontsize=16)  ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}