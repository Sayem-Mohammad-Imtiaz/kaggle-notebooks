{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"true = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\nfake = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true['label'] = 'fake'\nfake['label'] = 'true'\n\ndata = pd.concat([true, fake], axis = 0)\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[['text', 'label']]\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('length of dataset is:' ,len(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.isnull().any(axis = 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnp.sum(data.isnull().any(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set(style = 'whitegrid')\ncarrier_count = data['label'].value_counts()\nsns.barplot(carrier_count.index, carrier_count.values, alpha = 0.9)\nplt.title('Distribution of label')\nplt.xlabel('Carrier')\nplt.ylabel('Number of Occurances')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].value_counts().plot(kind = 'pie', autopct = '%1.1f%%', figsize = (8,8)).legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].value_counts().plot(kind = 'pie', autopct = '%1.1f%%', figsize = (8,8)).legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['text'].str.contains('america'), 'text'] = 'american'\ndata.loc[data['text'].str.contains('americans'), 'text'] = 'american'\ndata.loc[data['text'].str.contains('youore'), 'text'] = 'you are'\ndata.loc[data['text'].str.contains('youre'), 'text'] = 'you are'\ndata.loc[data['text'].str.contains('years'), 'text'] = 'year'\ndata.loc[data['text'].str.contains('break'), 'text'] = 'breakingnews'\ndata.loc[data['text'].str.contains('breaking'), 'text'] = 'breakingnews'\ndata.loc[data['text'].str.contains('caused'), 'text'] = 'cause'\ndata.loc[data['text'].str.contains('causes'), 'text'] = 'cause'\ndata.loc[data['text'].str.contains('county'), 'text'] = 'country'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'].str.find('american').value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for letter in '1234567890.(/':\n    data['text'] = data['text'].str.replace(letter, ' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nenglish_punctuations = string.punctuation\npunctuations_list = english_punctuations + english_punctuations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuations(text):\n    translator = str.maketrans('','', punctuations_list)\n    return text.translate(translator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef remove_repeating_char(text):\n    return re.sub(r'(.)\\1+', r'\\1', text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def processPost(text): \n\n    text = re.sub('@[^\\s]+', ' ', text)\n    \n\n    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',text)\n\n    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n\n    text= remove_punctuations(text)\n    text=remove_repeating_char(text)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data['text'].apply(lambda x: processPost(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\ntokenizer = RegexpTokenizer(r'\\w+')\ndata['text'] = data['text'].apply(tokenizer.tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstopwords_list = set(stopwords.words(\"english\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = data['text'].apply(lambda x: [item for item in x if item not in stopwords_list])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_words = [word for tokens in data['text'] for word in tokens]\nsentence_lengths = [len(tokens) for tokens in data['text']]\n\nvocab = sorted(list(set(all_words)))\n\nprint(len(all_words), len(vocab))\nprint( max(sentence_lengths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ncounter = Counter(all_words)\ncounter.most_common(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counted_words = counter.most_common(25)\n\nword = []\ncounts = []\nfor letter, count in counted_words:\n    word.append(letter)\n    counts.append(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nsns.barplot(word, counts, alpha = 0.9)\nplt.xticks(rotation = 90)\nplt.title(\"Frequency of most common words\")\nplt.xlabel(\"Most common words\")\nplt.ylabel(\"count of words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data[data['label'] == 'true']\nneg = data1['text']\nneg_string = []\nfor t in neg:\n    neg_string.append(t)\nneg_str = pd.Series(neg_string).map(str)\nneg_str = str(neg_str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(width = 1600, height = 800, max_font_size = 200).generate(neg_str)\nplt.figure(figsize = (12,10))\nplt.imshow(wordcloud, interpolation = \"bilinear\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data[data['label'] == 'fake']\nneg = data2['text']\nneg_str = []\nfor t in neg:\n    neg_str.append(t)\nneg_str = pd.Series(neg_str).map(str)\nneg_str = str(neg_str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 1600, height = 800, max_font_size = 200).generate(neg_str)\nplt.figure(figsize = (12,10))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf = True,\n    strip_accents = 'unicode',\n    analyzer = 'word',\n    token_pattern = r'\\w{1,}',\n    stop_words = 'english',\n    ngram_range = (1,1),\n    max_features = 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unigramdataGet = word_vectorizer.fit_transform(data['text'].astype('str'))\nunigramdataGet = unigramdataGet.toarray()\nvocab = word_vectorizer.get_feature_names()\nunigramdata = pd.DataFrame(np.round(unigramdataGet,1), columns = vocab)\nunigramdata[unigramdata>0] = 1\nunigramdata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab[0:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(unigramdata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.reset_index(drop = True, inplace = True)\ndata = data.drop(columns = ['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\nselector = SelectKBest(chi2, k = 700)\nselector.fit(unigramdata, data['label'])\n\nunigramdata = selector.transform(unigramdata)\nunigramdata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = unigramdata\ny = data['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nsvc = LinearSVC(C = 1, max_iter = 500)\nsvc = svc.fit(X_train, y_train)\nsvc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1 = svc.predict(X_test)\ndm = svc.score(X_test, y_test)\nprint('Accuracy Score - {:.2f}'.format(dm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CR = classification_report(y_test, y_pred1)\nprint(CR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\nCR = confusion_matrix(y_test, y_pred1)\nprint(\"Confusion Matrix:-\")\nprint(CR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(svc,X_test, y_test)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raf = RandomForestClassifier(min_samples_leaf = 20, min_samples_split = 20, random_state = 100)\nraf = raf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1 = raf.predict(X_test)\nrf = raf.score(X_test, y_test)\nprint(\"Accuracy score is {:0.2f}\".format(rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CR = classification_report(y_test, y_pred1)\nprint(\"Classification Report is :-\")\nprint(CR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CR = confusion_matrix(y_test, y_pred1)\nprint(CR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(raf, X_test, y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nEns = VotingClassifier(estimators = [('SVM', svc),\n                                    ('raf', raf)], voting = 'hard')\nEns = Ens.fit(X_train, y_train)\nEns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1 = Ens.predict(X_test)\nacc = Ens.score(X_test, y_test)\nacc","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}