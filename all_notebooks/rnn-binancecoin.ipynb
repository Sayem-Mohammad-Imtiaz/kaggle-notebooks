{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nfrom torch.autograd import Variable\nfrom sklearn.preprocessing import MinMaxScaler\nimport random\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T08:33:48.549683Z","iopub.execute_input":"2021-07-28T08:33:48.550055Z","iopub.status.idle":"2021-07-28T08:33:48.560672Z","shell.execute_reply.started":"2021-07-28T08:33:48.550026Z","shell.execute_reply":"2021-07-28T08:33:48.559626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The objective for this notebook is to provide a LSTM model to predict the Binance price and the change of Binance price. \nThe model needs the X and Y data.\nX: [X1,X2,X3] where X1 is the Binance Price in day one, X2 is the Binance price in two day ,...\nY: [X4] is the Binance Price in the fourth day. \nThe idea is that the LSTM model recibe a sample of X and predict the price for de next day. For example, following the previous examples recibe the data of the \nfirst three days and predict the price for the fourth day.\n","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/binance-coin-data/Binance Coin - Historic data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:32:04.847773Z","iopub.execute_input":"2021-07-28T08:32:04.848167Z","iopub.status.idle":"2021-07-28T08:32:04.867427Z","shell.execute_reply.started":"2021-07-28T08:32:04.848133Z","shell.execute_reply":"2021-07-28T08:32:04.866507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:32:11.50014Z","iopub.execute_input":"2021-07-28T08:32:11.500578Z","iopub.status.idle":"2021-07-28T08:32:11.531596Z","shell.execute_reply.started":"2021-07-28T08:32:11.500546Z","shell.execute_reply":"2021-07-28T08:32:11.53046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking NaN values\ndata.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:32:30.442831Z","iopub.execute_input":"2021-07-28T08:32:30.443211Z","iopub.status.idle":"2021-07-28T08:32:30.451181Z","shell.execute_reply.started":"2021-07-28T08:32:30.443182Z","shell.execute_reply":"2021-07-28T08:32:30.450074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_price = data['Price(in dollars)']\ndata_change = data['Change%']","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:33:08.21135Z","iopub.execute_input":"2021-07-28T08:33:08.21178Z","iopub.status.idle":"2021-07-28T08:33:08.218495Z","shell.execute_reply.started":"2021-07-28T08:33:08.211747Z","shell.execute_reply":"2021-07-28T08:33:08.217247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(data_price, label = 'Price Evolution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:33:53.328587Z","iopub.execute_input":"2021-07-28T08:33:53.328935Z","iopub.status.idle":"2021-07-28T08:33:53.617477Z","shell.execute_reply.started":"2021-07-28T08:33:53.328909Z","shell.execute_reply":"2021-07-28T08:33:53.616784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_change = data['Change%']\nplt.plot(data_change, label = 'Changing Evolution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:34:04.539319Z","iopub.execute_input":"2021-07-28T08:34:04.53973Z","iopub.status.idle":"2021-07-28T08:34:04.684632Z","shell.execute_reply.started":"2021-07-28T08:34:04.539697Z","shell.execute_reply":"2021-07-28T08:34:04.683675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_price = np.array([[i] for i in data_price])\ndata_change = np.array([[i] for i in data_change])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:34:30.809009Z","iopub.execute_input":"2021-07-28T08:34:30.809438Z","iopub.status.idle":"2021-07-28T08:34:30.820317Z","shell.execute_reply.started":"2021-07-28T08:34:30.80939Z","shell.execute_reply":"2021-07-28T08:34:30.819091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This function separate the data into two grups: X and Y. \ndef sliding_windows(data, seq_length):\n    x = []\n    y = []\n\n    for i in range(len(data)-seq_length-1):\n        _x = data[i:(i+seq_length)]\n        _y = data[i+seq_length]\n        x.append(_x)\n        y.append(_y)\n\n    return np.array(x),np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:53:31.188238Z","iopub.execute_input":"2021-07-28T08:53:31.188672Z","iopub.status.idle":"2021-07-28T08:53:31.195562Z","shell.execute_reply.started":"2021-07-28T08:53:31.188638Z","shell.execute_reply":"2021-07-28T08:53:31.194459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = MinMaxScaler()\ntraining_data = sc.fit_transform(data_price)  #Data Normalization\n\n\nseq_length = 6 ##Hiperparamter that determinates how many data goes into the LSTM model. \n#For example: if we have a seq_length = 2 the X data will be (X1,X2) where X1 is the price in the day one and X2 the price in the day two. The Y value for this sample will be the third day or X3. \n#That separation of data in X and Y samples take place in the sliding_windows function\nx, y = sliding_windows(training_data, seq_length)\n\ntrain_size = int(len(y) * 0.70) #70% train\ntest_size = len(y) - train_size\n\ndataX = Variable(torch.Tensor(np.array(x)))\ndataY = Variable(torch.Tensor(np.array(y)))\n\nrandom_indexs_train = random.sample(range(0,len(x)),train_size)\nrandom_indexs_test = [i for i in range(len(x)) if i not in random_indexs_train]\n\ntrainX = Variable(torch.Tensor(np.array(x[random_indexs_train])))\ntrainY = Variable(torch.Tensor(np.array(y[random_indexs_train])))\n\ntestX = Variable(torch.Tensor(np.array(x[random_indexs_test])))\ntestY = Variable(torch.Tensor(np.array(y[random_indexs_test])))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:53:01.128256Z","iopub.execute_input":"2021-07-28T08:53:01.128681Z","iopub.status.idle":"2021-07-28T08:53:01.161867Z","shell.execute_reply.started":"2021-07-28T08:53:01.128649Z","shell.execute_reply":"2021-07-28T08:53:01.160813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model\n","metadata":{}},{"cell_type":"code","source":"class LSTM(nn.Module):\n\n    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n        super(LSTM, self).__init__()\n        \n        self.num_classes = num_classes\n        self.num_layers = num_layers\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.seq_length = seq_length\n        \n        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n                            num_layers=num_layers, batch_first=True)\n        \n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        h_0 = Variable(torch.zeros(\n            self.num_layers, x.size(0), self.hidden_size))\n        \n        c_0 = Variable(torch.zeros(\n            self.num_layers, x.size(0), self.hidden_size))\n        \n        # Propagate input through LSTM\n        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n        \n        h_out = h_out.view(-1, self.hidden_size)\n        \n        out = self.fc(h_out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:37:59.769887Z","iopub.execute_input":"2021-07-28T08:37:59.770512Z","iopub.status.idle":"2021-07-28T08:37:59.77905Z","shell.execute_reply.started":"2021-07-28T08:37:59.770477Z","shell.execute_reply":"2021-07-28T08:37:59.778286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"num_epochs = 1500\nlearning_rate = 0.0075\n\ninput_size = 1\nhidden_size = 8\nnum_layers = 1\nnum_classes = 1\nlstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n#Criterion default:  MSE\n#Optimizer default: Adam\ncriterion = torch.nn.MSELoss()    \noptimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\nfor epoch in range(num_epochs):\n  outputs = lstm(trainX)\n  optimizer.zero_grad()\n  \n  # obtain the loss function\n  loss = criterion(outputs, trainY)\n  \n  loss.backward()\n  \n  optimizer.step()\n  if epoch % 100 == 0:\n    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:38:36.235816Z","iopub.execute_input":"2021-07-28T08:38:36.236501Z","iopub.status.idle":"2021-07-28T08:38:47.798602Z","shell.execute_reply.started":"2021-07-28T08:38:36.23646Z","shell.execute_reply":"2021-07-28T08:38:47.79782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evalutation","metadata":{}},{"cell_type":"code","source":"lstm.eval()\ntrain_predict = lstm(dataX)\n\ndata_predict = train_predict.data.numpy()\ndataY_plot = dataY.data.numpy()\n\ndata_predict = sc.inverse_transform(data_predict)\ndataY_plot = sc.inverse_transform(dataY_plot)\n\n\n\nplt.plot(dataY_plot)\nplt.plot(data_predict)\nplt.suptitle('Price prediction')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:39:12.710961Z","iopub.execute_input":"2021-07-28T08:39:12.711563Z","iopub.status.idle":"2021-07-28T08:39:12.872522Z","shell.execute_reply.started":"2021-07-28T08:39:12.711514Z","shell.execute_reply":"2021-07-28T08:39:12.871786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Training the model to predict the change","metadata":{}},{"cell_type":"code","source":"sc = MinMaxScaler()\ntraining_data = sc.fit_transform(data_change)\n\n\nseq_length = 6 ##Hiperparamter that determinates how many data goes into the LSTM model. \n#For example: if we have a seq_length = 2 the X data will be (X1,X2) where X1 is the price in the day one and X2 the price in the day two. The Y value for this sample will be the third day or X3. \n#That separation of data in X and Y samples take place in the sliding_windows function\nx, y = sliding_windows(training_data, seq_length)\n\ntrain_size = int(len(y) * 0.70) #70% train\ntest_size = len(y) - train_size\n\ndataX = Variable(torch.Tensor(np.array(x)))\ndataY = Variable(torch.Tensor(np.array(y)))\n\nrandom_indexs_train = random.sample(range(0,len(x)),train_size)\nrandom_indexs_test = [i for i in range(len(x)) if i not in random_indexs_train]\n\ntrainX = Variable(torch.Tensor(np.array(x[random_indexs_train])))\ntrainY = Variable(torch.Tensor(np.array(y[random_indexs_train])))\n\ntestX = Variable(torch.Tensor(np.array(x[random_indexs_test])))\ntestY = Variable(torch.Tensor(np.array(y[random_indexs_test])))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:46:04.066627Z","iopub.execute_input":"2021-07-28T08:46:04.067059Z","iopub.status.idle":"2021-07-28T08:46:04.097894Z","shell.execute_reply.started":"2021-07-28T08:46:04.06702Z","shell.execute_reply":"2021-07-28T08:46:04.096884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 2500\nlearning_rate = 0.01\n\ninput_size = 1\nhidden_size = 10\nnum_layers = 1\nnum_classes = 1\nlstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n#Criterion default:  MSE\n#Optimizer default: Adam\ncriterion = torch.nn.MSELoss()    \noptimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\nfor epoch in range(num_epochs):\n  outputs = lstm(trainX)\n  optimizer.zero_grad()\n  \n  # obtain the loss function\n  loss = criterion(outputs, trainY)\n  \n  loss.backward()\n  \n  optimizer.step()\n  if epoch % 100 == 0:\n    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:47:27.42784Z","iopub.execute_input":"2021-07-28T08:47:27.42825Z","iopub.status.idle":"2021-07-28T08:47:50.031321Z","shell.execute_reply.started":"2021-07-28T08:47:27.428217Z","shell.execute_reply":"2021-07-28T08:47:50.030365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm.eval()\ntrain_predict = lstm(dataX)\n\ndata_predict = train_predict.data.numpy()\ndataY_plot = dataY.data.numpy()\n\ndata_predict = sc.inverse_transform(data_predict)\ndataY_plot = sc.inverse_transform(dataY_plot)\n\n\n\nplt.plot(dataY_plot)\nplt.plot(data_predict)\nplt.suptitle('Change prediction')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T08:47:53.808438Z","iopub.execute_input":"2021-07-28T08:47:53.808846Z","iopub.status.idle":"2021-07-28T08:47:53.980335Z","shell.execute_reply.started":"2021-07-28T08:47:53.808812Z","shell.execute_reply":"2021-07-28T08:47:53.97919Z"},"trusted":true},"execution_count":null,"outputs":[]}]}