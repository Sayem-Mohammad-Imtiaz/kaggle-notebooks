{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Learning with Feature Scaling: Comparison between a Logistic Regession and a Random Forest Classification model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, r2_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The data set we are going to work on regards bike rental data in Toronto:","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('../input/bike-rental-toronto/bikes_sharing.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let's consider that any date in which the bike rental count is over 200 to be \"high count\", and also convert the datetime column from string to actual datetime:","metadata":{}},{"cell_type":"code","source":"data[\"high_count\"] = data[\"count\"]>200\ndata[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\ndata[\"hour\"] = data[\"datetime\"].dt.hour\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Choosing the independent (x) and dependent (y) variables:","metadata":{}},{"cell_type":"code","source":"X = data[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'hour']]\ny=data['high_count']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performing a train/test split in order to avoid overfitting:","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now, since the variables show a big difference in terms of maximum and minimum values, a feature scaling is necessary to increase model accuracy:","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The first model we are going to perform on the train data is a Logistic Regression:","metadata":{}},{"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train_scaled,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = logmodel.predict(X_test_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_acc=accuracy_score(y_test,predictions)\nlog_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now, the second model we are going to perform is a Random Forest Classifier and compare to the Logistic Regression accuracy:","metadata":{}},{"cell_type":"code","source":"X = data[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'hour']]\ny=data['high_count']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\nrf_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = rf_clf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_acc=accuracy_score(y_test,pred)\nrf_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Printing a confusion matrix in order to display the correct and incorrect predictions of the Random Forest Classifier model:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\nwith plt.style.context(\"default\"):\n  fig = plt.figure(figsize=(20,15))\n  ax = plot_confusion_matrix(rf_clf, X_test, y_test, values_format=\"\", cmap=\"Blues\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## In the Random Forest Classification model, we can also print a function called \"Feature Importance\", which shows the importance of each predictor on the resulting y variable:","metadata":{}},{"cell_type":"code","source":"df_imp = pd.DataFrame(rf_clf.feature_importances_, index=X_train.columns, columns=[\"Feature Importance\"]).sort_values(\"Feature Importance\", ascending=False)\ndf_imp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We can clearly see that the \"hour\" feature shows the greatest importance in the classification model","metadata":{}},{"cell_type":"markdown","source":"## Displaying the accuracy results of both the Logistic Regression and the Random Forest models:","metadata":{}},{"cell_type":"code","source":"result=pd.DataFrame([log_acc,rf_acc],index=['Log Model Accuracy','Random Forest Accuracy'],columns=['Value'])\nresult","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## It can be concluded that the Random Forest model showed better accuracy.","metadata":{}}]}