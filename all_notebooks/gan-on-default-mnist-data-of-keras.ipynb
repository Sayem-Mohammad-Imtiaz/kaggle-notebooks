{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This kernel does not do anything new. It uses GAN (Generative Adversarial Network) which is a neural net to create digits that look like the data.\nTHIS IS PURELY A PRACTICE KERNEL.\nI've used the default data present in keras because there are too many mnist data and kernels in kaggle. It's confusing.\n\nThanks to Renu Khandelwal for her code in https://medium.com/datadriveninvestor/generative-adversarial-network-gan-using-keras-ce1c05cfdfd3\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I did initially try to pick up the kaggle data but alas!"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/mnist_train.csv\")\nprint(train.shape)\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import mnist\ndef load_data():\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n    \n    # convert shape of x_train from (60000, 28, 28) to (60000, 784) \n    # 784 columns per row\n    x_train = x_train.reshape(60000, 784)\n    return (x_train, y_train, x_test, y_test)\n(X_train, y_train,X_test, y_test)=load_data()\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import adam\ndef adam_optimizer():\n    return adam(lr=0.0002, beta_1=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Dropout, Input\nfrom keras.models import Model,Sequential\nfrom tqdm import tqdm\nfrom keras.layers.advanced_activations import LeakyReLU","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_generator():\n    generator=Sequential()\n    generator.add(Dense(units=256,input_dim=100))\n    generator.add(LeakyReLU(0.2))\n    \n    generator.add(Dense(units=512))\n    generator.add(LeakyReLU(0.2))\n    \n    generator.add(Dense(units=1024))\n    generator.add(LeakyReLU(0.2))\n    \n    generator.add(Dense(units=784, activation='tanh'))\n    \n    generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n    return generator\ng=create_generator()\ng.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_discriminator():\n    discriminator=Sequential()\n    discriminator.add(Dense(units=1024,input_dim=784))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.3))\n       \n    \n    discriminator.add(Dense(units=512))\n    discriminator.add(LeakyReLU(0.2))\n    discriminator.add(Dropout(0.3))\n       \n    discriminator.add(Dense(units=256))\n    discriminator.add(LeakyReLU(0.2))\n    \n    discriminator.add(Dense(units=1, activation='sigmoid'))\n    \n    discriminator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n    return discriminator\nd =create_discriminator()\nd.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_gan(discriminator, generator):\n    discriminator.trainable=False\n    gan_input = Input(shape=(100,))\n    x = generator(gan_input)\n    gan_output= discriminator(x)\n    gan= Model(inputs=gan_input, outputs=gan_output)\n    gan.compile(loss='binary_crossentropy', optimizer='adam')\n    return gan\ngan = create_gan(d,g)\ngan.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_generated_images(epoch, generator, examples=100, dim=(10,10), figsize=(10,10)):\n    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n    generated_images = generator.predict(noise)\n    generated_images = generated_images.reshape(100,28,28)\n    plt.figure(figsize=figsize)\n    for i in range(generated_images.shape[0]):\n        plt.subplot(dim[0], dim[1], i+1)\n        plt.imshow(generated_images[i], interpolation='nearest')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.savefig('gan_generated_image %d.png' %epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tqdm as tqdm\nfrom tqdm import _tqdm_pandas\nfrom tqdm import tnrange\n\ndef training(epochs=1, batch_size=128):\n    \n    #Loading the data\n    (X_train, y_train, X_test, y_test) = load_data()\n    batch_count = X_train.shape[0] / batch_size\n    \n    # Creating GAN\n    generator= create_generator()\n    discriminator= create_discriminator()\n    gan = create_gan(discriminator, generator)\n    \n    for e in range(1,epochs+1 ):\n        print(\"Epoch %d\" %e)\n        for _ in tnrange(batch_size):\n        #generate  random noise as an input  to  initialize the  generator\n            noise= np.random.normal(0,1, [batch_size, 100])\n            \n            # Generate fake MNIST images from noised input\n            generated_images = generator.predict(noise)\n            \n            # Get a random set of  real images\n            image_batch =X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n            \n            #Construct different batches of  real and fake data \n            X= np.concatenate([image_batch, generated_images])\n            \n            # Labels for generated and real data\n            y_dis=np.zeros(2*batch_size)\n            y_dis[:batch_size]=0.9\n            \n            #Pre train discriminator on  fake and real data  before starting the gan. \n            discriminator.trainable=True\n            discriminator.train_on_batch(X, y_dis)\n            \n            #Tricking the noised input of the Generator as real data\n            noise= np.random.normal(0,1, [batch_size, 100])\n            y_gen = np.ones(batch_size)\n            \n            # During the training of gan, \n            # the weights of discriminator should be fixed. \n            #We can enforce that by setting the trainable flag\n            discriminator.trainable=False\n            \n            #training  the GAN by alternating the training of the Discriminator \n            #and training the chained GAN model with Discriminatorâ€™s weights freezed.\n            gan.train_on_batch(noise, y_gen)\n            \n        if e == 1 or e % 20 == 0:\n           \n            plot_generated_images(e, generator)\n#training(400,128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training(400,128)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The output is not statisfactory. Let's try with more epochs"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"training(1000,128)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Voila! the digits are absolutely recognizable."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}