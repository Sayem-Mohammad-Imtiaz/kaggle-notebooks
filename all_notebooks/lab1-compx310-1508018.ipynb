{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T02:12:56.587954Z","iopub.execute_input":"2021-07-15T02:12:56.588422Z","iopub.status.idle":"2021-07-15T02:12:56.606567Z","shell.execute_reply.started":"2021-07-15T02:12:56.588357Z","shell.execute_reply":"2021-07-15T02:12:56.605514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Name: Connor Welham\nID: 1508018","metadata":{}},{"cell_type":"code","source":"#Loading the dataset\ndf = pd.read_csv('/kaggle/input/wisconsin-breast-cancer-cytology-features/wisconsin_breast_cancer.csv')\ndf.fillna(0, inplace=True)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:12:56.608199Z","iopub.execute_input":"2021-07-15T02:12:56.608508Z","iopub.status.idle":"2021-07-15T02:12:56.66015Z","shell.execute_reply.started":"2021-07-15T02:12:56.60848Z","shell.execute_reply":"2021-07-15T02:12:56.659154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the head of the data\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:12:56.662316Z","iopub.execute_input":"2021-07-15T02:12:56.662628Z","iopub.status.idle":"2021-07-15T02:12:56.681414Z","shell.execute_reply.started":"2021-07-15T02:12:56.662598Z","shell.execute_reply":"2021-07-15T02:12:56.680419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualising the data as a pairplot\nimport seaborn as sns\nsns.pairplot(data=df, hue='class')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:12:56.683228Z","iopub.execute_input":"2021-07-15T02:12:56.683496Z","iopub.status.idle":"2021-07-15T02:13:29.716973Z","shell.execute_reply.started":"2021-07-15T02:12:56.683471Z","shell.execute_reply":"2021-07-15T02:13:29.715957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The pairplot shows that there is no natural classifier","metadata":{}},{"cell_type":"code","source":"#Setting X to all features except \"class\"\nX = df.iloc[:, 1:-1]\nX \n#Setting Y to \"class\" feature\ny = df.iloc[:, -1]\ny","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:13:29.71836Z","iopub.execute_input":"2021-07-15T02:13:29.718666Z","iopub.status.idle":"2021-07-15T02:13:29.728862Z","shell.execute_reply.started":"2021-07-15T02:13:29.718635Z","shell.execute_reply":"2021-07-15T02:13:29.727798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting into train and test with with test_size=0.2, or 20%, and using random_state=YOUR_ID\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1508018)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:13:29.73076Z","iopub.execute_input":"2021-07-15T02:13:29.731187Z","iopub.status.idle":"2021-07-15T02:13:29.747455Z","shell.execute_reply.started":"2021-07-15T02:13:29.731148Z","shell.execute_reply":"2021-07-15T02:13:29.746751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train an SVC classifier on the train set\nfrom sklearn.svm import SVC\nm = SVC()\nm\nm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:13:29.74856Z","iopub.execute_input":"2021-07-15T02:13:29.748846Z","iopub.status.idle":"2021-07-15T02:13:29.765302Z","shell.execute_reply.started":"2021-07-15T02:13:29.748819Z","shell.execute_reply":"2021-07-15T02:13:29.764356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predict for the test set\np = m.predict(X_test)\nprint(p[:10])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:13:58.08444Z","iopub.execute_input":"2021-07-15T02:13:58.085031Z","iopub.status.idle":"2021-07-15T02:13:58.093632Z","shell.execute_reply.started":"2021-07-15T02:13:58.084995Z","shell.execute_reply":"2021-07-15T02:13:58.092431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check that predictions match data\nprint(y_test[:10])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:14:00.142084Z","iopub.execute_input":"2021-07-15T02:14:00.142447Z","iopub.status.idle":"2021-07-15T02:14:00.14803Z","shell.execute_reply.started":"2021-07-15T02:14:00.142413Z","shell.execute_reply":"2021-07-15T02:14:00.147026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" As shown by the predictionbs and the actual data, the two match which means we have correctly predicted the class of the last 10 data","metadata":{}},{"cell_type":"code","source":"#Generate a confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, p))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:13:29.789505Z","iopub.execute_input":"2021-07-15T02:13:29.78998Z","iopub.status.idle":"2021-07-15T02:13:29.801173Z","shell.execute_reply.started":"2021-07-15T02:13:29.789929Z","shell.execute_reply":"2021-07-15T02:13:29.799557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7 data points were incorrectly classified. 3 of the data points were predicted to be class 0, but were actually class 1. 4 data points were predicted to be class 1, but were actually class 0.","metadata":{}},{"cell_type":"code","source":"#Generate a classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, p))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:13:29.802648Z","iopub.execute_input":"2021-07-15T02:13:29.802975Z","iopub.status.idle":"2021-07-15T02:13:29.818031Z","shell.execute_reply.started":"2021-07-15T02:13:29.802945Z","shell.execute_reply":"2021-07-15T02:13:29.817034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Precision:\nFor the data that was predicted to not have cancer, 97% do in fact not have cancer.\nFor the data that was predicted to have cancer, 92% do in fact have cancer.\n\nRecall:\nFor the data that did not have cancer, 96% were correctly predicted to not have cancer.\nFor the data that did have cancer, 94% were correctly predicted to have cancer.\n\nFl-score:\nFl score is the average of the precision and recallm of that class. Class 0 has a higher f1-score of 96% compared to class 1 which has 93%.\n\nSupport:\nSupport is the number of cases in each class that are being tested. 90 cases were from class 0 and 50 cases were from class 1.","metadata":{}}]}