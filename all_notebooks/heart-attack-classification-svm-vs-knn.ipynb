{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Column Information\n* Age (age) is the age of candidate\n* Sex (sex) has numeric values. 1 denotes male and 0 denotes female\n* Chest Pain (cp) pain has values between 0-3. The types of angina that are described in the research paper. The higher the number, the lesser are the odds of heart attack\n* Resting Blood Pressure (trtbps) is normal pressure with no exercise\n* Cholesterol (chol) means the blockage for blood supply in the blood vessels\n* Fasting Blood Pressure (fbs) is blood sugar taken after a long gap between a meal and the test. Typically, it's taken before any meal in the morning\n* Rest ECG (restecg) results means ECG values taken while person is on rest which means no exercise and normal functioning of heart is happening\n* Maximum Heart Rate (thalachh) achieved\n* Exercise Induced Angina (exng) is chest pain while exercising or doing any physical activity\n* ST Depression (oldpeak) is the difference between value of ECG at rest and after exercise\n* ST Slope (slp) is the tangent to the depression value\n* Number of Major Blood Vessels (caa) supplying blood to heart blocked\n* Types of Thalassemia (thall)\n* Heart Attack (target) where 1 denotes Heart Attack suffered and 0 where it did not take place","metadata":{}},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"df_eda = df.copy()\ndf_eda.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nsns.set()\nsns.set(rc={'figure.figsize':(15,10)})\nprint(df_eda.sex.value_counts())\n\nsns.catplot(x='sex', kind='count', data=df_eda)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(x='age', hue='sex', kde=True, data=df_eda)\nplt.show()\nplt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_eda.target.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot, plot\n\nlabels = df_eda[df_eda['target'] == 1]['sex'].value_counts().index\npie1 = df_eda[df_eda['target'] == 1]['sex'].value_counts().values\n\n\nfig = {\n  \"data\": [\n    {\n      \"values\": pie1,\n      \"labels\": labels,\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"\",\n      \"hoverinfo\":\"label+percent+name+value\",\n      \"hole\": .2,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Distribution of Target by Gender\",\n        \"annotations\": [\n            { \"font\": { \"size\": 25},\n              \"showarrow\": True,\n              \"text\": \"DEATH\",\n                \"x\": 1,\n                \"y\": 1,\n            },\n        ]\n    }\n}\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_eda.hist(figsize=(12,9))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"X = df.drop('target', axis=1)\ny = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaler.fit(X)\nX_scaled = scaler.transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting Data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n\nprint(X_train.shape)\nprint(X_valid.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Prediction","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVC","metadata":{}},{"cell_type":"code","source":"svc = SVC(C=100, kernel='linear')\nsvc.fit(X_train, y_train)\nprint(\"Score of Train : \", svc.score(X_train, y_train))\nprint(\"Score of Validation : \", svc.score(X_valid, y_valid))\n\ny_pred = svc.predict(X_test)\nsvc_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", svc_accuracy)\nprint(classification_report(y_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", rf.score(X_train, y_train))\nprint(\"Score of Validation Model : \", rf.score(X_valid, y_valid))\n\ny_pred = rf.predict(X_test)\nrf_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", rf_accuracy)\nprint(classification_report(y_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boosting","metadata":{}},{"cell_type":"code","source":"gbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", gbc.score(X_train, y_train))\nprint(\"Score of Test Model : \", gbc.score(X_valid, y_valid))\n\ny_pred = gbc.predict(X_test)\ngbc_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", gbc_accuracy)\nprint(classification_report(y_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decission Tree","metadata":{}},{"cell_type":"code","source":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", dtc.score(X_train, y_train))\nprint(\"Score of Test Model : \", dtc.score(X_test, y_test))\n\ny_pred = dtc.predict(X_test)\ndtc_accuracy = accuracy_score(y_pred, y_test)\nprint(classification_report(y_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\n\nprint(\"Score of Trained Model : \", knn.score(X_train, y_train))\nprint(\"Score of Test Model : \", knn.score(X_valid, y_valid))\n\ny_pred = knn.predict(X_test)\nknn_accuracy = accuracy_score(y_pred, y_test)\nprint(\"Score of Test : \", knn_accuracy)\nprint(classification_report(y_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_model = ['SVC', 'Random Forest', 'Gradient Boosting', 'Decision Tree', 'KNN']\naccuracy = [svc_accuracy, rf_accuracy, gbc_accuracy, dtc_accuracy, knn_accuracy]\n\nfor i in range(len(label_model)):\n    print(\"{} accuracy : {}\".format(label_model[i], accuracy[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,9))\nplt.bar(label_model, accuracy)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM VS KNN ","metadata":{}},{"cell_type":"code","source":"accuracy_val = []\nfor i in range(10,15,1):\n    model = KNeighborsClassifier(n_neighbors=i)\n    model.fit(X_train, y_train)\n    model_pred = model.predict(X_test)\n    accuracy = accuracy_score(model_pred, y_test)\n    accuracy_val.append(accuracy)\nplt.figure(figsize=(12,9))\nplt.plot(range(10,15,1), accuracy_val)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_val = []\nfor i in [100, 200, 300, 400, 500]:\n    model = SVC(C = i, kernel='linear')\n    model.fit(X_train, y_train)\n    model_pred = model.predict(X_test)\n    accuracy = accuracy_score(model_pred, y_test)\n    accuracy_val.append(accuracy)\nplt.figure(figsize=(12,9))\nplt.plot([100, 200, 300, 400, 500], accuracy_val)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}