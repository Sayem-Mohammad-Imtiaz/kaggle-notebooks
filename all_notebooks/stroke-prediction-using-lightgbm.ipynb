{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing the Dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# droppping 'id' as its of no use for predicting\ndf.drop('id',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we have 201 values of bmi missing we have to fill these before predicting as bmi can be an important index","metadata":{}},{"cell_type":"code","source":"# dataframe of those having bmi NaN\nbmi_none=df[df['bmi'].isna()==True]\nbmi_none['stroke'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filling all the nan values using mean values of particular category(0,1)\ndf1=df[df['stroke']==1].fillna(df['bmi'][df['stroke']==1].mean())\ndf2=df[df['stroke']==0].fillna(df['bmi'][df['stroke']==0].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concatenating 2 dataframes into a final one\nresult_df=pd.concat([df1,df2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df['stroke'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df,hue=\"stroke\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since this dataset is imbalanced we have to balance it using sampling techniques","metadata":{}},{"cell_type":"code","source":"# doing one-hot encoding of categorical variables\nresult_df=pd.get_dummies(result_df,drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=result_df[['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi',\n       'gender_Male', 'gender_Other', 'ever_married_Yes',\n       'work_type_Never_worked', 'work_type_Private',\n       'work_type_Self-employed', 'work_type_children', 'Residence_type_Urban',\n       'smoking_status_formerly smoked', 'smoking_status_never smoked',\n       'smoking_status_smokes']]\ny=result_df['stroke']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using SMOTE for oversampling","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsampling=SMOTE()\nx,y=sampling.fit_resample(x,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we will use lightGBM which is decision tree based algorithm there is no need to scale values","metadata":{}},{"cell_type":"markdown","source":"### Model Building using LightGBM","metadata":{}},{"cell_type":"markdown","source":"LightGBM is a gradient boosting model that uses tree-based algorithms. It is much faster than the usual tree-based algorithms like Decision Trees, Random Forests, etc. It has the following advantages over the traditional machine learning algorithms.\n\n* Faster training speed with better efficiency. \n* Lower memory usage.\n* Supports GPU processing. \n* Highly scalable and efficiently handles large datasets","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=lgb.Dataset(x_train,label=y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Setting Parameters","metadata":{}},{"cell_type":"code","source":"param = {'num_leaves':100, 'objective':'binary','max_depth':5,'learning_rate':.05}\nparam['metric'] = ['auc']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training of model\nlgbm=lgb.train(param,train_data,5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making Predictions","metadata":{}},{"cell_type":"code","source":"y_pred=lgbm.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds=[]\nfor i in y_pred:\n    if i>0.5:\n        y_preds.append(1)\n    else:\n        y_preds.append(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating Results","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_preds,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_preds,y_test),annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}