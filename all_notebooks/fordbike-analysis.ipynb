{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019 =pd.read_csv('../input/ford-gobike-2019feb-tripdata/201902-fordgobike-tripdata.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.Data extraction"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"bike2019.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bike2019.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019[bike2019.start_station_name.isnull()][[\"start_station_name\",\"start_station_latitude\",\"start_station_longitude\",\"end_station_name\",\"end_station_latitude\",\"end_station_longitude\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019[bike2019.start_station_name.isnull()].equals(bike2019[bike2019.end_station_name.isnull()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With every start station that's missing, the end station is also missing"},{"metadata":{},"cell_type":"markdown","source":"# Same Longtiude and Latitude for missing Start stations and End stations so we can use google maps to findout where the location is exactly and substitute the start station name and id with that location and give a random ID -Same goes with end station and end station ID-\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019[\"start_time\"]= pd.to_datetime(bike2019[\"start_time\"])\nbike2019[\"end_time\"]= pd.to_datetime(bike2019[\"end_time\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check = bike2019['start_time'] + pd.to_timedelta(bike2019['duration_sec'], unit='s')\ncheck","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"differnce = pd.concat([bike2019['end_time'],check,bike2019['end_time']-check],axis=1)\ndiffernce.columns = [\"End_time\",\"Calculated End_time\",\"Absoulte Difference\"]\ndiffernce","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime, timedelta \nprint(\"Minimum Difference:\",differnce[\"Absoulte Difference\"].min())\nprint(\"Mean Difference:\",differnce[\"Absoulte Difference\"].mean())\nprint(\"Max Difference:\",differnce[\"Absoulte Difference\"].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Average Difference is less than 0.5 seconds, so the columns Duration, Start_Time and End_time are very accurate"},{"metadata":{},"cell_type":"markdown","source":"# Age and Birth Year"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average Age:\", 2021- bike2019.member_birth_year.mean())\nprint(\"Average Male Age:\", 2021- bike2019[bike2019[\"member_gender\"]==\"Male\"].member_birth_year.mean())\nprint(\"Average Female Age:\", 2021- bike2019[bike2019[\"member_gender\"]==\"Female\"].member_birth_year.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ages are very close to each other, so we could just fill the missing values with the average age\n\nNote that: Some birthdates are of people way too old, more than 90 years! those records could either be omitted or depending if ford were collecting data from the 1900s"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill Null values with average age\nbike2019[\"member_birth_year\"] =bike2019[\"member_birth_year\"].fillna(round(bike2019[\"member_birth_year\"].mean())).astype('int32')\nbike2019[\"member_birth_year\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019[\"member_gender\"].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fill Missing Gender randomly\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019[\"member_gender\"]= bike2019[\"member_gender\"].fillna(np.random.choice([\"Male\",\"Female\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# For now drop the ~200 records with missing Start/End stations"},{"metadata":{"trusted":true},"cell_type":"code","source":"bike2019.dropna().info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\ndf = bike2019.dropna(axis=0)\ndf[[\"member_gender\",\"bike_share_for_all_trip\",\"user_type\",\"start_station_name\",\"end_station_name\"]] =df[[\"member_gender\",\"bike_share_for_all_trip\",\"user_type\",\"start_station_name\",\"end_station_name\"]].apply(preprocessing.LabelEncoder().fit_transform)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\n\n# calculate the correlation matrix\ncorr = df.corr()\n\n# plot the heatmap\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)\ncmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n\ndef magnify():\n    return [dict(selector=\"th\",\n                 props=[(\"font-size\", \"7pt\")]),\n            dict(selector=\"td\",\n                 props=[('padding', \"0em 0em\")]),\n            dict(selector=\"th:hover\",\n                 props=[(\"font-size\", \"12pt\")]),\n            dict(selector=\"tr:hover td:hover\",\n                 props=[('max-width', '200px'),\n                        ('font-size', '12pt')])\n]\n\ncorr.style.background_gradient(cmap, axis=1)\\\n    .set_properties(**{'max-width': '80px', 'font-size': '15pt'})\\\n    .set_caption(\"Hover to magify\")\\\n    .set_precision(2)\\\n    .set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# As we can see from the Correlation Matrix,\n1. The bikeshare is correlated with the start/end station,meaning some areas are more likely to have more bike shares than others\n2. Gender is pretty much uncorrelated with anything else\n3. User type (Customer/Subscriber) is marginally correlated with the duration of the trip"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}