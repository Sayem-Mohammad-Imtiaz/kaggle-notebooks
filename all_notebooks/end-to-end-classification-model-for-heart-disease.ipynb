{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification Model made by ~ Saket Prakash","metadata":{}},{"cell_type":"markdown","source":"## Predicting Heart Disease using Machine Learning \n\nThis notebook uses Python based  machine learning and data science libraries in an attempt to create a machine learning model which is capable of predicting whether or not a person has heart disease based on their medical attributes.\n\nThe approach followed in building the model are:\n\n1. Problem Definition\n2. Data\n3. Evaluation\n4. Features\n5. Modelling\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Problem Definition\n\nThis model involves predicting whether a person has heart disease or not base on the data which is provided. This is a **Classification** problem as we can see that this falls into a category whether the result belongs to one class or not. So, the problem definition in this model is can we predict that the patient has heart disease or not. Therefore, this problem lies in the category of **Binary Classification** i.e. (heart disease = 1, no heart disease = 0)\n\n## 2. Data\n\nThe original data is of Cleaveland data from the UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/heart+Disease \n\nThis original data set contains contains 76 attributes(also called features) and there are many attributes which are not necessary for this model.\n\nIt also has a compressed version with 14 features(13 independent features & 1 dependent feature) on kaggle which is sufficient for creating a model. So, I've taken the data from kaggle. https://www.kaggle.com/ronitf/heart-disease-uci\n\n## 3. Evaluation\n\nThe evaluation metric is specified at the beginning of the model. So, if the model is 90% accurate in predicting the correct result then it will be considered otherwise not. \nTherefore,  our **evaluation metric** = 90% \n\nThe Evaluation metrics used here are \n* Confusion matrix\n* ROC-AUC Curve\n* classification_report\n* accuracy_score\n* precision_score\n* f1_score\n* recall_score\n\n## 4. Features\n\nIn this section we explore the features of the data and observe what description it is providing which might be useful in predicting the target variable. This may involve some research on internet as well but the most common way to know about the different parts of data is from the **data dictionary**\n\n# The Heart Disease Data Dictionary\n\n1. age - age in years\n2. sex - (1 = male; 0 = female)\n3. cp - chest pain type\n   * 0: Typical angina: chest pain related decrease blood supply to the heart\n   * 1: Atypical angina: chest pain not related to heart\n   * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n   * 3: Asymptomatic: chest pain not showing signs of disease\n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n   * anything above 130-140 is typically cause for concern\n5. chol - serum cholestoral in mg/dl\n   * serum = LDL + HDL + .2 * triglycerides\n   * above 200 is cause for concern\n6. fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n   * '>126' mg/dL signals diabetes\n7. restecg - resting electrocardiographic results\n   * 0: Nothing to note\n   * 1: ST-T Wave abnormality\n      * can range from mild symptoms to severe problems\n      * signals non-normal heart beat\n   * 2: Possible or definite left ventricular hypertrophy\n      * Enlarged heart's main pumping chamber\n8. thalach - maximum heart rate achieved\n9. exang - exercise induced angina (1 = yes; 0 = no)\n10. oldpeak - ST depression induced by exercise relative to rest\n    * looks at stress of heart during excercise\n    * unhealthy heart will stress more\n11. slope - the slope of the peak exercise ST segment\n    * 0: Upsloping: better heart rate with excercise (uncommon)\n    * 1: Flatsloping: minimal change (typical healthy heart)\n    * 2: Downslopins: signs of unhealthy heart\n12. ca - number of major vessels (0-3) colored by flourosopy\n    * colored vessel means the doctor can see the blood passing through\n    * the more blood movement the better (no clots)\n13. thal - thalium stress result\n    * 1,3: normal\n    * 6: fixed defect: used to be defect but ok now\n    * 7: reversable defect: no proper blood movement when excercising\n14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)\n\n\nNote : WE DON't HAVE ANY UNIQUE PATIENT ID NUMBER.","metadata":{}},{"cell_type":"markdown","source":"## Getting started with importing the tools required to perform the EDA(Exploratory Data Analysis) on the dataset and then moving onto the Modelling part\n\nTools imported:\n1. Pandas - for data analysis\n2. NumPy - for numerical operations\n3. Matplotlib and Seaborn - for plotting graphs and visualization of data\n4. Scikit Learn - for data modelling","metadata":{}},{"cell_type":"code","source":"# Importing the libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Importing libraries from scikit learn for data spliting and modelling and evaluation of the model\n\n# Models\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Model Evaluation\n\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\nfrom sklearn.metrics import plot_roc_curve,roc_curve\nfrom sklearn.metrics import confusion_matrix,classification_report\n\n\n# Additional\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.352085Z","iopub.execute_input":"2021-07-17T14:08:04.352447Z","iopub.status.idle":"2021-07-17T14:08:04.36286Z","shell.execute_reply.started":"2021-07-17T14:08:04.352415Z","shell.execute_reply":"2021-07-17T14:08:04.361702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the data set","metadata":{}},{"cell_type":"code","source":"df= pd.read_csv('../input/heart-disease-uci/heart.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.364781Z","iopub.execute_input":"2021-07-17T14:08:04.365277Z","iopub.status.idle":"2021-07-17T14:08:04.386452Z","shell.execute_reply.started":"2021-07-17T14:08:04.365174Z","shell.execute_reply":"2021-07-17T14:08:04.385369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the dataframe\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.388549Z","iopub.execute_input":"2021-07-17T14:08:04.388914Z","iopub.status.idle":"2021-07-17T14:08:04.395915Z","shell.execute_reply.started":"2021-07-17T14:08:04.388881Z","shell.execute_reply":"2021-07-17T14:08:04.394868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are 303 rows and 14 columns**","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Data Analysis\n\nAfter inserting the dataframe, now it is time to explore the data. This includes comparing the columns of feature data with one another and comparing it with the target variable. This can be done by referring to the data dictionary which is specified in the feature section. This EDA does not have any specific methodology but there are some things that much be taken care before we start the modelling. Thus, EDA is an important step. The common workflow for EDA is \n\n1. Check if the data has any missing values and see how we can deal with it\n2. Check if there are features which can be removed or added to improve the model\n\nNow, lets start the EDA...\n","metadata":{}},{"cell_type":"code","source":"# Viewing the first 10 rows of the dataframe\n\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.397419Z","iopub.execute_input":"2021-07-17T14:08:04.397814Z","iopub.status.idle":"2021-07-17T14:08:04.423889Z","shell.execute_reply.started":"2021-07-17T14:08:04.397782Z","shell.execute_reply":"2021-07-17T14:08:04.422793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the number of Positive(1) and Negative(0) values in the target column of our dataframe\n\ndf['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.425178Z","iopub.execute_input":"2021-07-17T14:08:04.425489Z","iopub.status.idle":"2021-07-17T14:08:04.433027Z","shell.execute_reply.started":"2021-07-17T14:08:04.425459Z","shell.execute_reply":"2021-07-17T14:08:04.432211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Positive and Negative target samples in percentages\n\ndf['target'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.43438Z","iopub.execute_input":"2021-07-17T14:08:04.43467Z","iopub.status.idle":"2021-07-17T14:08:04.449056Z","shell.execute_reply.started":"2021-07-17T14:08:04.434641Z","shell.execute_reply":"2021-07-17T14:08:04.448252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that the number of Positive(1) and Negative(0) value of samples are balanced\nas the percentage of **1's** are **54.45 %** and percentage of **0's** are **45.54%**.","metadata":{}},{"cell_type":"code","source":"# Plotting the value counts of target \n\ndf['target'].value_counts().plot(kind = 'bar',color=['darkblue','salmon'])\nplt.xticks(rotation=0)\nplt.ylabel('Count')\nplt.xlabel('Target');\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.450458Z","iopub.execute_input":"2021-07-17T14:08:04.450771Z","iopub.status.idle":"2021-07-17T14:08:04.656972Z","shell.execute_reply.started":"2021-07-17T14:08:04.450741Z","shell.execute_reply":"2021-07-17T14:08:04.655541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting quick insights of our dataframe\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.659801Z","iopub.execute_input":"2021-07-17T14:08:04.66027Z","iopub.status.idle":"2021-07-17T14:08:04.677309Z","shell.execute_reply.started":"2021-07-17T14:08:04.660221Z","shell.execute_reply":"2021-07-17T14:08:04.675991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"info() function gives us the insights that there are no missing values in the dataframe as it says **NON-NULL** and all the data types are int and float types i.e. all the data are **Numeric** in nature.","metadata":{}},{"cell_type":"code","source":"# Alternate way to know whether the datafram has missing values or not\n\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.679552Z","iopub.execute_input":"2021-07-17T14:08:04.679982Z","iopub.status.idle":"2021-07-17T14:08:04.696068Z","shell.execute_reply.started":"2021-07-17T14:08:04.679933Z","shell.execute_reply":"2021-07-17T14:08:04.695235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"isna().sum() returns the number of missing values in each column. In our dataset we don't have any missing values. ","metadata":{}},{"cell_type":"code","source":"# Alternate way to get quick insights of the dataframe\n\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.697238Z","iopub.execute_input":"2021-07-17T14:08:04.697873Z","iopub.status.idle":"2021-07-17T14:08:04.766939Z","shell.execute_reply.started":"2021-07-17T14:08:04.697837Z","shell.execute_reply":"2021-07-17T14:08:04.765791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"describe() function returns some important insights such as the count in each column, mean, standard deviation,minimum and maximum value of each column. It also provides the information about the 25, 50 and 75 percentiles in that column. So, this is an important function.","metadata":{}},{"cell_type":"code","source":"# Counting the number of male and female\n\ndf['sex'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.768561Z","iopub.execute_input":"2021-07-17T14:08:04.769195Z","iopub.status.idle":"2021-07-17T14:08:04.779435Z","shell.execute_reply.started":"2021-07-17T14:08:04.769145Z","shell.execute_reply":"2021-07-17T14:08:04.77822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**male - 1\nfemale - 0**","metadata":{}},{"cell_type":"markdown","source":"## Heart Disease Frequency according to sex","metadata":{}},{"cell_type":"code","source":"# Comparing target column with sex column(using crosstab)\n\npd.crosstab(df['target'],df['sex'])","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.781205Z","iopub.execute_input":"2021-07-17T14:08:04.781873Z","iopub.status.idle":"2021-07-17T14:08:04.80946Z","shell.execute_reply.started":"2021-07-17T14:08:04.781824Z","shell.execute_reply":"2021-07-17T14:08:04.808299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By comparing the target column with sex column we get insights that how many men have heart disease **(sex = 1,target = 1)** i.e. **93** and how many men do not have heart disease **(sex =1, target = 0)**  i.e. **114**. In Case of women who have heart disease **(sex = 0, target = 1)** i.e. **72** and women who do not have heart disease **(sex = 0, target = 0)** i.e. **24**.","metadata":{}},{"cell_type":"code","source":"# Plotting the crosstab\npd.crosstab(df['target'],\n            df['sex']).plot(kind='bar',\n                            figsize=(10,6),\n                            color=['darkblue','salmon']);\n\nplt.xlabel('0 - No Heart Disease 1 - Heart Disease')\nplt.ylabel('Count')\nplt.title('Heart Disease Frequency for Sex')\nplt.legend(['Female','Male'])\nplt.xticks(rotation=0);","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:04.81107Z","iopub.execute_input":"2021-07-17T14:08:04.811728Z","iopub.status.idle":"2021-07-17T14:08:05.073789Z","shell.execute_reply.started":"2021-07-17T14:08:04.81168Z","shell.execute_reply":"2021-07-17T14:08:05.072747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Age vs Max Heart Rate for Heart Disease\n\nNow, combining two independent variable i.e. Age and Max Heart Rate(thalach column) and comparing it with the target vatiable of Heart Disease i.e. 0 for no Heart Disease and 1 for Heart Disease.","metadata":{}},{"cell_type":"markdown","source":"## Plotting age vs max heart rate using scatter plots\n\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\n\n# plotting scatter plot for positive Heart Disease\n\nplt.scatter(x=df['age'][df['target']==1],\n            y=df['thalach'][df['target']==1],\n            c='r',\n            label='Heart Disease')\n\n# plotting scatter plot for negative Heart Disease\n\nplt.scatter(x=df['age'][df['target']==0],\n            y=df['thalach'][df['target']==0],\n            c='g',\n            label='No Heart Disease',\n            alpha=0.8)\n\n#Customizing the plot\n\nplt.xlabel('Age')\nplt.ylabel('Max Heart Rate')\nplt.title('Age vs Max Heart Rate for Heart Disease')\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:05.075208Z","iopub.execute_input":"2021-07-17T14:08:05.075805Z","iopub.status.idle":"2021-07-17T14:08:05.441253Z","shell.execute_reply.started":"2021-07-17T14:08:05.075761Z","shell.execute_reply":"2021-07-17T14:08:05.440145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the age distribution for Heart Disease with histogram\n\nfig,ax = plt.subplots()\nax=plt.hist(df['age'],color='k',rwidth=0.97)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Histogram plot of Age Distribution')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:05.442481Z","iopub.execute_input":"2021-07-17T14:08:05.442777Z","iopub.status.idle":"2021-07-17T14:08:05.714051Z","shell.execute_reply.started":"2021-07-17T14:08:05.44275Z","shell.execute_reply":"2021-07-17T14:08:05.71305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Heart Disease frequency according to Chest Pain\ncp - chest pain type\n*  0: Typical angina: chest pain related decrease blood supply to the heart\n*  1: Atypical angina: chest pain not related to heart\n*  2: Non-anginal pain: typically esophageal spasms (non heart related)\n*  3: Asymptomatic: chest pain not showing signs of disease","metadata":{}},{"cell_type":"code","source":"# combining chest pain with target\n\npd.crosstab(df['cp'],df['target'])","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:05.715462Z","iopub.execute_input":"2021-07-17T14:08:05.715759Z","iopub.status.idle":"2021-07-17T14:08:05.739972Z","shell.execute_reply.started":"2021-07-17T14:08:05.715731Z","shell.execute_reply":"2021-07-17T14:08:05.738791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the crosstab\n\npd.crosstab(df['cp'],df['target']).plot(kind='bar',figsize=(10,6),color=['darkblue','salmon'])\n\nplt.title('Frequency of Heart Disease according to Chest Pain')\nplt.xlabel('Chest Pain Type')\nplt.ylabel('Count')\nplt.legend(['No Heart Disease','Heart Disease'])\nplt.xticks(rotation=0);","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:05.744834Z","iopub.execute_input":"2021-07-17T14:08:05.745369Z","iopub.status.idle":"2021-07-17T14:08:06.03985Z","shell.execute_reply.started":"2021-07-17T14:08:05.745305Z","shell.execute_reply":"2021-07-17T14:08:06.038832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the correlation matrix of the data frame","metadata":{}},{"cell_type":"code","source":"#Correlation matrix\n\ncorr_matrix = df.corr()\n\n# Plotting the correlation matrix in seaborn heatmap\n\nfig, ax = plt.subplots(figsize=(14,9))\nax = sns.heatmap(corr_matrix,annot=True,fmt='.2f',linewidth=0.5,cmap='winter')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:06.042756Z","iopub.execute_input":"2021-07-17T14:08:06.043204Z","iopub.status.idle":"2021-07-17T14:08:07.585739Z","shell.execute_reply.started":"2021-07-17T14:08:06.043156Z","shell.execute_reply":"2021-07-17T14:08:07.584562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We've done enough EDA and now it's time for creating a baseline model and check the accuracy and other metrics so that we can decide which model to pick.**","metadata":{}},{"cell_type":"markdown","source":"# 5.Modelling\n\nThree models to be used:\n1. KNeighborsclassifier\n2. Logistic Regression\n3. RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"# Looking into our dataset\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.587342Z","iopub.execute_input":"2021-07-17T14:08:07.587869Z","iopub.status.idle":"2021-07-17T14:08:07.607277Z","shell.execute_reply.started":"2021-07-17T14:08:07.587819Z","shell.execute_reply":"2021-07-17T14:08:07.606029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting this dataframe into Feature variable(X) and Target variable(y)\n\nX = df.drop('target',axis=1)    #dropping the target column\n\ny = df['target']                #selecting only the target column ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.608979Z","iopub.execute_input":"2021-07-17T14:08:07.609644Z","iopub.status.idle":"2021-07-17T14:08:07.621872Z","shell.execute_reply.started":"2021-07-17T14:08:07.609595Z","shell.execute_reply":"2021-07-17T14:08:07.62052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing the feature variables\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.623561Z","iopub.execute_input":"2021-07-17T14:08:07.624255Z","iopub.status.idle":"2021-07-17T14:08:07.651881Z","shell.execute_reply.started":"2021-07-17T14:08:07.624203Z","shell.execute_reply":"2021-07-17T14:08:07.650327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.653908Z","iopub.execute_input":"2021-07-17T14:08:07.654397Z","iopub.status.idle":"2021-07-17T14:08:07.668127Z","shell.execute_reply.started":"2021-07-17T14:08:07.65433Z","shell.execute_reply":"2021-07-17T14:08:07.667091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into test and train sets\n\nnp.random.seed(42) # random seed\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.669507Z","iopub.execute_input":"2021-07-17T14:08:07.669816Z","iopub.status.idle":"2021-07-17T14:08:07.682714Z","shell.execute_reply.started":"2021-07-17T14:08:07.669788Z","shell.execute_reply":"2021-07-17T14:08:07.681833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.684117Z","iopub.execute_input":"2021-07-17T14:08:07.684566Z","iopub.status.idle":"2021-07-17T14:08:07.711261Z","shell.execute_reply.started":"2021-07-17T14:08:07.684534Z","shell.execute_reply":"2021-07-17T14:08:07.710181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.713084Z","iopub.execute_input":"2021-07-17T14:08:07.713536Z","iopub.status.idle":"2021-07-17T14:08:07.720932Z","shell.execute_reply.started":"2021-07-17T14:08:07.713488Z","shell.execute_reply":"2021-07-17T14:08:07.720157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.721936Z","iopub.execute_input":"2021-07-17T14:08:07.722325Z","iopub.status.idle":"2021-07-17T14:08:07.746271Z","shell.execute_reply.started":"2021-07-17T14:08:07.722294Z","shell.execute_reply":"2021-07-17T14:08:07.745516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.747299Z","iopub.execute_input":"2021-07-17T14:08:07.747965Z","iopub.status.idle":"2021-07-17T14:08:07.755622Z","shell.execute_reply.started":"2021-07-17T14:08:07.747932Z","shell.execute_reply":"2021-07-17T14:08:07.754421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape , X_test.shape , y_train.shape  ,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.757553Z","iopub.execute_input":"2021-07-17T14:08:07.758061Z","iopub.status.idle":"2021-07-17T14:08:07.769945Z","shell.execute_reply.started":"2021-07-17T14:08:07.758012Z","shell.execute_reply":"2021-07-17T14:08:07.768817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fitting the X train and y train data in the three models and checking the accuracy for the baseline models\n\n* Model 1 - LogisticRegression\n* Model 2 - KNeighborsClassifier\n* Model 3 - RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"# For LogisticRegression\n\nclf_logreg = LogisticRegression(C=1,solver='liblinear')\n\n# Fitting the X train and y train data in LogisticRegression\n\nclf_logreg.fit(X_train,y_train);\n\n# Accuracy score for LogisticRegression on test data\n\naccuracy_logreg = clf_logreg.score(X_test,y_test)\naccuracy_logreg","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.771666Z","iopub.execute_input":"2021-07-17T14:08:07.772029Z","iopub.status.idle":"2021-07-17T14:08:07.791296Z","shell.execute_reply.started":"2021-07-17T14:08:07.771998Z","shell.execute_reply":"2021-07-17T14:08:07.79021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For KneighborsClassifier\n\nclf_knn = KNeighborsClassifier()\n\n# Fitting the X train and y train data in KNeighborsClassifier\n\nclf_knn.fit(X_train,y_train)\n\n# Accuracy score for KNeighborsClassifier on test data\n\naccuracy_knn = clf_knn.score(X_test,y_test)\naccuracy_knn\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.792806Z","iopub.execute_input":"2021-07-17T14:08:07.793098Z","iopub.status.idle":"2021-07-17T14:08:07.809917Z","shell.execute_reply.started":"2021-07-17T14:08:07.793068Z","shell.execute_reply":"2021-07-17T14:08:07.808849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For RandomForestClassifier\n\nclf_rf = RandomForestClassifier()\n\n# Fitting the X train and y train data in RandomForestClassifier\nclf_rf.fit(X_train,y_train);\n\n# Accuracy score for RandomForestClassifier on test data\n\naccuracy_rf = clf_rf.score(X_test,y_test)\naccuracy_rf","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:07.811214Z","iopub.execute_input":"2021-07-17T14:08:07.811571Z","iopub.status.idle":"2021-07-17T14:08:08.031492Z","shell.execute_reply.started":"2021-07-17T14:08:07.81154Z","shell.execute_reply":"2021-07-17T14:08:08.030423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Creating an accuracy data frame and plotting a bar plot\nmodels = pd.Series(['LogisticRegression','KNeighborsClassifier','RandomForestClassifier'])\naccuracy = pd.Series([accuracy_logreg, accuracy_knn, accuracy_rf])\naccuracy_df = pd.DataFrame({\"models\":models,\"accuracy\":accuracy})","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.032669Z","iopub.execute_input":"2021-07-17T14:08:08.032964Z","iopub.status.idle":"2021-07-17T14:08:08.039874Z","shell.execute_reply.started":"2021-07-17T14:08:08.032936Z","shell.execute_reply":"2021-07-17T14:08:08.038888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_df","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.041744Z","iopub.execute_input":"2021-07-17T14:08:08.04223Z","iopub.status.idle":"2021-07-17T14:08:08.059811Z","shell.execute_reply.started":"2021-07-17T14:08:08.042182Z","shell.execute_reply":"2021-07-17T14:08:08.058488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Baseline accuracy bar plot of models\n\nplt.bar(accuracy_df['models'],height = accuracy_df['accuracy'] );","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.061344Z","iopub.execute_input":"2021-07-17T14:08:08.061681Z","iopub.status.idle":"2021-07-17T14:08:08.239695Z","shell.execute_reply.started":"2021-07-17T14:08:08.06165Z","shell.execute_reply":"2021-07-17T14:08:08.23866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Tuning","metadata":{}},{"cell_type":"markdown","source":"## Hyperparameter Tuning of KNeignborsClassifier","metadata":{}},{"cell_type":"code","source":"## KNeighborsClassifier is tuned by changing the n_neighbors in a loop\n\n# setting up a random seed\n\nnp.random.seed(42)\n\n# selecting a range of neighbors\n\nneighbors = np.arange(1,30,1)\n\n# Setting up kn classifier\n\nknn = KNeighborsClassifier()\n\n# Creating lists to append test and training scores\n\ntest_scores = []\ntrain_scores = []\n\n## creating a loop for different neighbors\n\nfor i in neighbors:\n    \n    knn = KNeighborsClassifier(n_neighbors = i)\n    \n    # fitting the knn to train data set\n    \n    knn.fit(X_train,y_train)\n    \n    # appending train scores\n    \n    train_scores.append(knn.score(X_train,y_train))\n    \n    # appending test scores\n    \n    test_scores.append(knn.score(X_test,y_test))\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.240986Z","iopub.execute_input":"2021-07-17T14:08:08.241276Z","iopub.status.idle":"2021-07-17T14:08:08.939801Z","shell.execute_reply.started":"2021-07-17T14:08:08.241248Z","shell.execute_reply":"2021-07-17T14:08:08.938714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_scores","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.94117Z","iopub.execute_input":"2021-07-17T14:08:08.941523Z","iopub.status.idle":"2021-07-17T14:08:08.948577Z","shell.execute_reply.started":"2021-07-17T14:08:08.941489Z","shell.execute_reply":"2021-07-17T14:08:08.947385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_scores","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.950327Z","iopub.execute_input":"2021-07-17T14:08:08.95076Z","iopub.status.idle":"2021-07-17T14:08:08.961182Z","shell.execute_reply.started":"2021-07-17T14:08:08.950716Z","shell.execute_reply":"2021-07-17T14:08:08.960026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting the testing and training scores vs n_neighbors \n\nplt.plot(neighbors,train_scores,c='r',label = 'Train scores')\nplt.plot(neighbors,test_scores,c='b',label = 'Test scores')\nplt.xlabel('Number of neigbors')\nplt.ylabel('Model Scores')\nplt.legend();\nprint(f'Maximum Test Score of KNeighborsClassifier: {max(test_scores)*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:08.962686Z","iopub.execute_input":"2021-07-17T14:08:08.963089Z","iopub.status.idle":"2021-07-17T14:08:09.248647Z","shell.execute_reply.started":"2021-07-17T14:08:08.963052Z","shell.execute_reply":"2021-07-17T14:08:09.247449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tuning the hyperparameters of LogisticRegression and RandomForestClassifier\n\nWe can tune these models using **1. RandomizedGridCV and 2.GridSearchCV**\n\nFirstly we will be tuning the hyperparameters using the RandomizedSearchCV and check which model provides the better score, which will then be followed by GridSearchCV for further improvement in hyperparameters to improve the score.","metadata":{}},{"cell_type":"markdown","source":"### Creating the RandomizedSearch grid for LogisticRegression and RandomForestClassifier \n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Grid for LogisticRegression\nrs_logreg_grid = { \"C\": np.logspace(-4,4,20),\n             \"solver\":['liblinear']}\n\n# Grid for RandomForestClassifier\n\nrs_rf_grid = { \"n_estimators\": np.arange(100,500,50),\n         \"max_depth\":[None,3,5,10,12,15],\n         \"min_samples_leaf\": np.arange(1,20,2),\n         \"min_samples_split\": np.arange(2,20,2)}","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:09.250345Z","iopub.execute_input":"2021-07-17T14:08:09.2508Z","iopub.status.idle":"2021-07-17T14:08:09.258397Z","shell.execute_reply.started":"2021-07-17T14:08:09.250756Z","shell.execute_reply":"2021-07-17T14:08:09.25699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For LogisticRegression","metadata":{}},{"cell_type":"code","source":"# setting up random seed\n\nnp.random.seed(42)\n\n# Setting up random hyperparameter search using RandomizedSearch\n\nrs_logreg = RandomizedSearchCV(LogisticRegression(),param_distributions=rs_logreg_grid,cv=5,n_iter=20,verbose=True)\n\n# fitting training data to RandomizedSearchCV\n\nrs_logreg.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:09.260325Z","iopub.execute_input":"2021-07-17T14:08:09.260781Z","iopub.status.idle":"2021-07-17T14:08:10.01428Z","shell.execute_reply.started":"2021-07-17T14:08:09.260735Z","shell.execute_reply":"2021-07-17T14:08:10.013186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_logreg.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:10.015558Z","iopub.execute_input":"2021-07-17T14:08:10.015847Z","iopub.status.idle":"2021-07-17T14:08:10.022012Z","shell.execute_reply.started":"2021-07-17T14:08:10.015819Z","shell.execute_reply":"2021-07-17T14:08:10.020963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_logreg.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:10.023831Z","iopub.execute_input":"2021-07-17T14:08:10.024174Z","iopub.status.idle":"2021-07-17T14:08:10.039016Z","shell.execute_reply.started":"2021-07-17T14:08:10.024141Z","shell.execute_reply":"2021-07-17T14:08:10.0378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For RandomForestClassifier","metadata":{}},{"cell_type":"code","source":"# setting up random seed\n\nnp.random.seed(42)\n\n# Setting up hyperparameter search for RandomForestClassifier using RandomizedSearchCv\n\nrs_rf = RandomizedSearchCV(RandomForestClassifier(),param_distributions = rs_rf_grid,cv=5,n_iter=20,verbose=True)\n\n# Fitting the training data to RandomizedSearch model\n\nrs_rf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:08:10.040645Z","iopub.execute_input":"2021-07-17T14:08:10.040977Z","iopub.status.idle":"2021-07-17T14:09:02.436527Z","shell.execute_reply.started":"2021-07-17T14:08:10.040948Z","shell.execute_reply":"2021-07-17T14:09:02.435466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_rf.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:02.441179Z","iopub.execute_input":"2021-07-17T14:09:02.441499Z","iopub.status.idle":"2021-07-17T14:09:02.447336Z","shell.execute_reply.started":"2021-07-17T14:09:02.441471Z","shell.execute_reply":"2021-07-17T14:09:02.446434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_rf.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:02.449182Z","iopub.execute_input":"2021-07-17T14:09:02.4495Z","iopub.status.idle":"2021-07-17T14:09:02.483469Z","shell.execute_reply.started":"2021-07-17T14:09:02.449472Z","shell.execute_reply":"2021-07-17T14:09:02.482434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning with GridSearchCV","metadata":{}},{"cell_type":"markdown","source":"**Since our LogisticRegression Model has more accuracy, we will use GridSearchCV on LogisticRegression**","metadata":{}},{"cell_type":"code","source":"# Creating a grid for GridSearchCV\n\ngrid_logreg = { 'C': np.logspace(-4,4,30),\n               'solver':['liblinear']}","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:02.484844Z","iopub.execute_input":"2021-07-17T14:09:02.485144Z","iopub.status.idle":"2021-07-17T14:09:02.491192Z","shell.execute_reply.started":"2021-07-17T14:09:02.485115Z","shell.execute_reply":"2021-07-17T14:09:02.490226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up hyperparameter search with GridSearchCV for LogisticRegression\n\ngs_logreg = GridSearchCV(LogisticRegression(),param_grid = grid_logreg,cv=5,verbose=True)\n\n# Fitting the training data into GridSearch Cross validation\n\ngs_logreg.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:02.492331Z","iopub.execute_input":"2021-07-17T14:09:02.492731Z","iopub.status.idle":"2021-07-17T14:09:03.579471Z","shell.execute_reply.started":"2021-07-17T14:09:02.492689Z","shell.execute_reply":"2021-07-17T14:09:03.578609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_logreg.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.580742Z","iopub.execute_input":"2021-07-17T14:09:03.581052Z","iopub.status.idle":"2021-07-17T14:09:03.587587Z","shell.execute_reply.started":"2021-07-17T14:09:03.581023Z","shell.execute_reply":"2021-07-17T14:09:03.586505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs_logreg.score(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.588911Z","iopub.execute_input":"2021-07-17T14:09:03.589237Z","iopub.status.idle":"2021-07-17T14:09:03.605004Z","shell.execute_reply.started":"2021-07-17T14:09:03.589196Z","shell.execute_reply":"2021-07-17T14:09:03.6039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating our tuned Model i.e. LogisticRegression","metadata":{}},{"cell_type":"markdown","source":"### Making Predictions with our tuned model\n\n","metadata":{}},{"cell_type":"code","source":"y_preds = gs_logreg.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.606447Z","iopub.execute_input":"2021-07-17T14:09:03.606915Z","iopub.status.idle":"2021-07-17T14:09:03.620559Z","shell.execute_reply.started":"2021-07-17T14:09:03.606866Z","shell.execute_reply":"2021-07-17T14:09:03.619279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.622002Z","iopub.execute_input":"2021-07-17T14:09:03.622304Z","iopub.status.idle":"2021-07-17T14:09:03.638637Z","shell.execute_reply.started":"2021-07-17T14:09:03.622276Z","shell.execute_reply":"2021-07-17T14:09:03.637193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.640403Z","iopub.execute_input":"2021-07-17T14:09:03.640841Z","iopub.status.idle":"2021-07-17T14:09:03.65505Z","shell.execute_reply.started":"2021-07-17T14:09:03.640747Z","shell.execute_reply":"2021-07-17T14:09:03.653954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now Comparing the Predicted values(y_preds) with the Actual values(y_test) using different evaluation metrics","metadata":{}},{"cell_type":"code","source":"# Plotting ROC-AUC Curve\n\nplot_roc_curve(gs_logreg,X_test,y_test);","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.656603Z","iopub.execute_input":"2021-07-17T14:09:03.656924Z","iopub.status.idle":"2021-07-17T14:09:03.928954Z","shell.execute_reply.started":"2021-07-17T14:09:03.656894Z","shell.execute_reply":"2021-07-17T14:09:03.92785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Confusion matrix\n\nconfusion_matrix(y_preds,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.930427Z","iopub.execute_input":"2021-07-17T14:09:03.930727Z","iopub.status.idle":"2021-07-17T14:09:03.938325Z","shell.execute_reply.started":"2021-07-17T14:09:03.930696Z","shell.execute_reply":"2021-07-17T14:09:03.937185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting confusion matrix using seaborn heatmap\nsns.set(font_scale=1.1)\nsns.heatmap(confusion_matrix(y_preds,y_test),annot=True,cmap='winter')\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values');\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:03.939845Z","iopub.execute_input":"2021-07-17T14:09:03.940143Z","iopub.status.idle":"2021-07-17T14:09:04.34411Z","shell.execute_reply.started":"2021-07-17T14:09:03.940114Z","shell.execute_reply":"2021-07-17T14:09:04.343074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metric Evaluation using Cross Validation","metadata":{}},{"cell_type":"code","source":"## getting the best parameters of our tuned model\n\ngs_logreg.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.345642Z","iopub.execute_input":"2021-07-17T14:09:04.346042Z","iopub.status.idle":"2021-07-17T14:09:04.352965Z","shell.execute_reply.started":"2021-07-17T14:09:04.345999Z","shell.execute_reply":"2021-07-17T14:09:04.352002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up a classifier with the best paramaters\n\nclf=LogisticRegression(C= 0.20433597178569418, solver= 'liblinear')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.35461Z","iopub.execute_input":"2021-07-17T14:09:04.355299Z","iopub.status.idle":"2021-07-17T14:09:04.3697Z","shell.execute_reply.started":"2021-07-17T14:09:04.355256Z","shell.execute_reply":"2021-07-17T14:09:04.368663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validated accuracy\n\ncross_val_score(clf,X,y,cv=5,scoring='accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.37112Z","iopub.execute_input":"2021-07-17T14:09:04.371441Z","iopub.status.idle":"2021-07-17T14:09:04.425858Z","shell.execute_reply.started":"2021-07-17T14:09:04.371402Z","shell.execute_reply":"2021-07-17T14:09:04.424833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mean cross validated accuracy\n\ncv_accuracy = cross_val_score(clf,X,y,cv=5,scoring='accuracy').mean()\ncv_accuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.427007Z","iopub.execute_input":"2021-07-17T14:09:04.427294Z","iopub.status.idle":"2021-07-17T14:09:04.471456Z","shell.execute_reply.started":"2021-07-17T14:09:04.427267Z","shell.execute_reply":"2021-07-17T14:09:04.470657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validated Precision\n\ncross_val_score(clf,X,y,cv=5,scoring='precision')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.472479Z","iopub.execute_input":"2021-07-17T14:09:04.472894Z","iopub.status.idle":"2021-07-17T14:09:04.522055Z","shell.execute_reply.started":"2021-07-17T14:09:04.472864Z","shell.execute_reply":"2021-07-17T14:09:04.521327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean cross validated Precision\n\ncv_precision = cross_val_score(clf,X,y,cv=5,scoring='precision').mean()\ncv_precision","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.523195Z","iopub.execute_input":"2021-07-17T14:09:04.523666Z","iopub.status.idle":"2021-07-17T14:09:04.572302Z","shell.execute_reply.started":"2021-07-17T14:09:04.523619Z","shell.execute_reply":"2021-07-17T14:09:04.571503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validated F1 score\ncross_val_score(clf,X,y,cv=5,scoring='f1')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.573449Z","iopub.execute_input":"2021-07-17T14:09:04.573911Z","iopub.status.idle":"2021-07-17T14:09:04.62267Z","shell.execute_reply.started":"2021-07-17T14:09:04.573865Z","shell.execute_reply":"2021-07-17T14:09:04.62176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean cross validated f1 score\n\ncv_f1 = cross_val_score(clf,X,y,cv=5,scoring='f1').mean()\ncv_f1","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.623863Z","iopub.execute_input":"2021-07-17T14:09:04.624165Z","iopub.status.idle":"2021-07-17T14:09:04.67648Z","shell.execute_reply.started":"2021-07-17T14:09:04.624137Z","shell.execute_reply":"2021-07-17T14:09:04.675561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cross validated recall score\n\ncross_val_score(clf,X,y,cv=5,scoring='recall')","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.677729Z","iopub.execute_input":"2021-07-17T14:09:04.67803Z","iopub.status.idle":"2021-07-17T14:09:04.730176Z","shell.execute_reply.started":"2021-07-17T14:09:04.677999Z","shell.execute_reply":"2021-07-17T14:09:04.728891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean Cross validated Recall score\n\ncv_recall = cross_val_score(clf,X,y,cv=5,scoring='recall').mean()\ncv_recall","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.732052Z","iopub.execute_input":"2021-07-17T14:09:04.732651Z","iopub.status.idle":"2021-07-17T14:09:04.786481Z","shell.execute_reply.started":"2021-07-17T14:09:04.732601Z","shell.execute_reply":"2021-07-17T14:09:04.78545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Putting the metrics into a data frame\n\nmetrics = pd.DataFrame({\"Accuracy Score\": cv_accuracy,\n                      \"Precision Score\":cv_precision,\n                      \"F1 Score\": cv_f1,\n                      \"Recall Score\":cv_recall},index=[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.787743Z","iopub.execute_input":"2021-07-17T14:09:04.788061Z","iopub.status.idle":"2021-07-17T14:09:04.79397Z","shell.execute_reply.started":"2021-07-17T14:09:04.788032Z","shell.execute_reply":"2021-07-17T14:09:04.792918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Plotting the cross validated scores\nplt.figure(figsize=(5,3))\nmetrics.T.plot(kind='bar',legend=False)\nplt.xticks(rotation=0)\nplt.title('Cross Validated Scores');","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:04.795323Z","iopub.execute_input":"2021-07-17T14:09:04.795738Z","iopub.status.idle":"2021-07-17T14:09:05.003394Z","shell.execute_reply.started":"2021-07-17T14:09:04.795706Z","shell.execute_reply":"2021-07-17T14:09:05.00241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Importance \n\n**Feature Importance tells us which features contributes the most in the model to predict the correct values**","metadata":{}},{"cell_type":"code","source":"gs_logreg.best_params_\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:05.004666Z","iopub.execute_input":"2021-07-17T14:09:05.004966Z","iopub.status.idle":"2021-07-17T14:09:05.011205Z","shell.execute_reply.started":"2021-07-17T14:09:05.004935Z","shell.execute_reply":"2021-07-17T14:09:05.010257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up the classifier i.e. LogisticRegression with best parameters\n\nclf = LogisticRegression(C= 0.20433597178569418, solver= 'liblinear')\n\n# Fitting the training data\nclf.fit(X_train,y_train);","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:05.012584Z","iopub.execute_input":"2021-07-17T14:09:05.012924Z","iopub.status.idle":"2021-07-17T14:09:05.029288Z","shell.execute_reply.started":"2021-07-17T14:09:05.012892Z","shell.execute_reply":"2021-07-17T14:09:05.027749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:05.031033Z","iopub.execute_input":"2021-07-17T14:09:05.031403Z","iopub.status.idle":"2021-07-17T14:09:05.05539Z","shell.execute_reply.started":"2021-07-17T14:09:05.031337Z","shell.execute_reply":"2021-07-17T14:09:05.054372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Match coef's of features to columns\nfeature_dict = dict(zip(df.columns, list(clf.coef_[0])))\nfeature_dict","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:05.057277Z","iopub.execute_input":"2021-07-17T14:09:05.057724Z","iopub.status.idle":"2021-07-17T14:09:05.067922Z","shell.execute_reply.started":"2021-07-17T14:09:05.057681Z","shell.execute_reply":"2021-07-17T14:09:05.066805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize feature importance\nfeature_df = pd.DataFrame(feature_dict, index=[0])\nfeature_df.T.plot.bar(title=\"Feature Importance\", legend=False);","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:09:05.069735Z","iopub.execute_input":"2021-07-17T14:09:05.070161Z","iopub.status.idle":"2021-07-17T14:09:05.387817Z","shell.execute_reply.started":"2021-07-17T14:09:05.070116Z","shell.execute_reply":"2021-07-17T14:09:05.386718Z"},"trusted":true},"execution_count":null,"outputs":[]}]}