{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook I will demonstrate the process of model building and selection to predict used bike prices.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:02.144151Z","iopub.execute_input":"2021-08-12T04:17:02.144494Z","iopub.status.idle":"2021-08-12T04:17:02.148835Z","shell.execute_reply.started":"2021-08-12T04:17:02.144464Z","shell.execute_reply":"2021-08-12T04:17:02.147833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data\n\nI will split the data into training and testing, and in the model building phase I will only use the training set. Imagine the testing set as \"new\" data that I can't see at all before I finish building my models.","metadata":{}},{"cell_type":"code","source":"full_data = pd.read_csv('../input/used-bikes-prices-in-india/Used_Bikes.csv')\nX, y = full_data.drop('price', axis = 1), full_data['price']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 2207)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:02.242644Z","iopub.execute_input":"2021-08-12T04:17:02.243004Z","iopub.status.idle":"2021-08-12T04:17:02.317986Z","shell.execute_reply.started":"2021-08-12T04:17:02.242974Z","shell.execute_reply":"2021-08-12T04:17:02.317007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:02.319265Z","iopub.execute_input":"2021-08-12T04:17:02.319541Z","iopub.status.idle":"2021-08-12T04:17:02.335209Z","shell.execute_reply.started":"2021-08-12T04:17:02.319514Z","shell.execute_reply":"2021-08-12T04:17:02.33431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()\n\n## No missing value\n## 3 continuous and 4 categorical predictors","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:02.342262Z","iopub.execute_input":"2021-08-12T04:17:02.34257Z","iopub.status.idle":"2021-08-12T04:17:02.367241Z","shell.execute_reply.started":"2021-08-12T04:17:02.342538Z","shell.execute_reply":"2021-08-12T04:17:02.36628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:02.368582Z","iopub.execute_input":"2021-08-12T04:17:02.368906Z","iopub.status.idle":"2021-08-12T04:17:02.376647Z","shell.execute_reply.started":"2021-08-12T04:17:02.368877Z","shell.execute_reply":"2021-08-12T04:17:02.375616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Response","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (10, 5))\nsns.histplot(y_train, kde = True, ax = ax[0]).set_title('Price')\nsns.histplot(y_train, kde = True, log_scale = True, ax = ax[1]).set_title('Price, in log-scale')\nplt.show()\n\n## The distribution of response variable is skewed,\n# so maybe it's a good idea? to try transforming the response using log later.","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:02.392179Z","iopub.execute_input":"2021-08-12T04:17:02.39249Z","iopub.status.idle":"2021-08-12T04:17:04.724295Z","shell.execute_reply.started":"2021-08-12T04:17:02.392462Z","shell.execute_reply":"2021-08-12T04:17:04.723426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Continuous predictor","metadata":{}},{"cell_type":"code","source":"sns.jointplot(\n    x = np.log1p(X_train['power']),\n    y = np.log(y_train),\n    kind = 'reg'\n)\n\nsns.jointplot(\n    x = np.log1p(X_train['age']),\n    y = np.log(y_train),\n    kind = 'reg'\n)\n\nsns.jointplot(\n    x = np.log1p(X_train['kms_driven']),\n    y = np.log(y_train),\n    kind = 'reg'\n)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:04.725641Z","iopub.execute_input":"2021-08-12T04:17:04.725935Z","iopub.status.idle":"2021-08-12T04:17:11.736586Z","shell.execute_reply.started":"2021-08-12T04:17:04.725899Z","shell.execute_reply":"2021-08-12T04:17:11.735667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessors","metadata":{}},{"cell_type":"code","source":"from sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n\n# mapper that transforms each specified column\n# with the specified preprocessor/transformer\n# note that I don't include bike names on this preprocessor\n# because I want to drop it entirely\npreprocessor = DataFrameMapper([\n    (['kms_driven'], FunctionTransformer(np.log1p)),\n    (['age'], FunctionTransformer(np.log1p)),\n    (['power'], FunctionTransformer(np.log1p)),\n    (['city'], OneHotEncoder(handle_unknown = 'ignore')),\n    (['brand'], OneHotEncoder(handle_unknown = 'ignore'))\n], df_out = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:11.738362Z","iopub.execute_input":"2021-08-12T04:17:11.738657Z","iopub.status.idle":"2021-08-12T04:17:11.744862Z","shell.execute_reply.started":"2021-08-12T04:17:11.738627Z","shell.execute_reply":"2021-08-12T04:17:11.743874Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"## Regularized regression using cross-validation and grid search to choose\n## the best value of regularization term.\n\nfrom sklearn.linear_model import Lasso, Ridge\n\nalphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\nlasso = Lasso()\nridge = Ridge()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:11.746487Z","iopub.execute_input":"2021-08-12T04:17:11.746805Z","iopub.status.idle":"2021-08-12T04:17:11.75584Z","shell.execute_reply.started":"2021-08-12T04:17:11.746753Z","shell.execute_reply":"2021-08-12T04:17:11.754938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Joining into pipeline\n\nPreprocessor and model is joined into a pipeline. Raw data then can be fed into the pipeline. The preprocessors, transformers, models inside the pipeline will work automatically (we need not to transform manually etc.)","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\nlasso_pipeline = Pipeline([\n    ('prep', preprocessor),\n    ('clf', lasso)\n])\n\nridge_pipeline = Pipeline([\n    ('prep', preprocessor),\n    ('clf', ridge)\n])","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:11.756803Z","iopub.execute_input":"2021-08-12T04:17:11.757146Z","iopub.status.idle":"2021-08-12T04:17:11.76708Z","shell.execute_reply.started":"2021-08-12T04:17:11.757117Z","shell.execute_reply":"2021-08-12T04:17:11.766216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wrapping the grid search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nlasso_gs = GridSearchCV(\n    lasso_pipeline,\n    {\n        'clf__alpha': alphas\n    },\n    scoring = 'neg_mean_squared_error'\n)\n\nridge_gs = GridSearchCV(\n    ridge_pipeline,\n    {\n        'clf__alpha': alphas\n    },\n    scoring = 'neg_mean_squared_error'\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:11.76838Z","iopub.execute_input":"2021-08-12T04:17:11.768784Z","iopub.status.idle":"2021-08-12T04:17:11.777485Z","shell.execute_reply.started":"2021-08-12T04:17:11.768744Z","shell.execute_reply":"2021-08-12T04:17:11.776715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation score on training set\n\nThis is just to demonstrate how I can gauge/evaluate the performance of my model only using the training set. Remember, up until now, I haven't seen the test set yet! ;)","metadata":{}},{"cell_type":"code","source":"%%capture --no-display --no-stdout\n# This just jupyter magic\n# to suppress so many ConvergenceWarnings that becomes\n# annoying to read.\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error, make_scorer\n\n# I have to define RMSE manually because regression models in\n# sklearn have R^2 as default scoring method.\n# Also, sklearn only provides -RMSE instead of RMSE.\nRMSE_score = make_scorer(mean_squared_error, squared = False)\n\nlasso_score = cross_val_score(\n    lasso_gs,\n    X_train, y_train,\n    scoring = RMSE_score\n)\n\nridge_score = cross_val_score(\n    ridge_gs,\n    X_train, y_train,\n    scoring = RMSE_score\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:17:11.778751Z","iopub.execute_input":"2021-08-12T04:17:11.779159Z","iopub.status.idle":"2021-08-12T04:35:20.915443Z","shell.execute_reply.started":"2021-08-12T04:17:11.779117Z","shell.execute_reply":"2021-08-12T04:35:20.914344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_score = pd.DataFrame({\n    'lasso': lasso_score,\n    'ridge': ridge_score\n})\n\n_score.loc['mean'] = _score.mean()\n_score","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:35:20.91852Z","iopub.execute_input":"2021-08-12T04:35:20.919253Z","iopub.status.idle":"2021-08-12T04:35:20.942278Z","shell.execute_reply.started":"2021-08-12T04:35:20.919204Z","shell.execute_reply":"2021-08-12T04:35:20.941112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n\n# Fitting the model using entire data\nlasso_pipeline.fit(X_train, y_train)\nridge_pipeline.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:35:20.94412Z","iopub.execute_input":"2021-08-12T04:35:20.944535Z","iopub.status.idle":"2021-08-12T04:35:31.844243Z","shell.execute_reply.started":"2021-08-12T04:35:20.944495Z","shell.execute_reply":"2021-08-12T04:35:31.843037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The final test","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nlasso_pred = lasso_pipeline.predict(X_test)\nridge_pred = ridge_pipeline.predict(X_test)\n\nprint(\"Lasso test RMSE:\", mean_squared_error(y_test, lasso_pred, squared = False))\nprint(\"Ridge test RMSE:\", mean_squared_error(y_test, ridge_pred, squared = False))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T04:35:31.849989Z","iopub.execute_input":"2021-08-12T04:35:31.852784Z","iopub.status.idle":"2021-08-12T04:35:32.434871Z","shell.execute_reply.started":"2021-08-12T04:35:31.852725Z","shell.execute_reply":"2021-08-12T04:35:32.433861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks for visiting my notebook!","metadata":{}}]}