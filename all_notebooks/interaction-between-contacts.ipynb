{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Analysing the interaction between Hillary Clinton's contacts\n\nWorking on Hillary Clinton's emails is a good occasion to analyse if there is an interaction between her contacts :\n\nTo do so, an analysis will be lead over the emails she sent, and received. The fact that she is the sender or the receiver is not so important. What matters is who she interacts with. We will gather all the emails and group them by contact. The following analysis will be text mining, mainly divided into 4 steps :\n- Compute the term frequency of each term in each person's emails (using TFIDF)\n- Compute the cosinus similarity to point out the distance between each person's emails, and build groups\n- Prune if necessary\n- Visualize this new information through a graph\n\n## Fetching the data  \nTo get the required data, sqlite3 will be used. Required fields for this analysis are as follow:\n- the sender\n- the receiver\n- the email content"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import sqlite3\nimport pandas as pd\nimport numpy as np\ncon = sqlite3.connect('../input/database.sqlite')\n\nemails = pd.read_sql_query(\"\"\"\nSELECT p.Name Sender,\n       e.SenderPersonId Id_sender, e.MetadataTo, e.ExtractedBodyText text,\n       a.PersonId\nFROM Emails e\nINNER JOIN Persons p ON e.SenderPersonId=p.Id \nLEFT OUTER JOIN Aliases a ON lower(e.MetadataTo)=a.Alias\n\"\"\", con)\n\npersons = pd.read_sql_query(\"\"\"\nSELECT Id, Name\nFROM Persons \n\"\"\", con)\npersonsDict = {}\nfor i in persons.values:\n    personsDict[i[0]] = i[1]"},{"cell_type":"markdown","metadata":{},"source":"## Cleaning the data and setting things ready\n\nWhat is interesting through this analysis is to focus on who Hillary Clinton is communicating with, whether she is the sender or the receiver. This is why it necessary to first compute the data in order to set a final Id_Contact.\n\nWhen Hillary Clinton is the email receiver, things are quite easy because sqllite gives us the sender ID. When Hillary Clinton is the sender, things are a little more tricky. This step also allow us to clean a little the data, and remove the emails where Hillary Clinton is the sender, but there is no trace of who is the receiver."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def computeSender(item):\n    # Sender is Hillary Clinton\n    if item.Id_sender == 80 and item.MetadataTo != '' and np.isnan(item.PersonId):\n        tab = item.MetadataTo.split(',')\n        name = tab[1].strip() + ' ' + tab[0].strip() \n        tmp = pd.read_sql_query(\"SELECT Id, Name FROM Persons WHERE Name='\"+ name +\"'\", con)\n        # A person was found\n        if not tmp.empty:\n            item.PersonId = tmp['Id'][0]\n    # Create the new Contact column\n    if item.Id_sender == 80:\n        item['Id_Contact'] = item.PersonId\n    else:\n        item['Id_Contact'] = item.Id_sender\n    return item\nprint(\"Number of emails before cleaning : \",emails.shape[0])\n\ndata = emails.apply(computeSender, axis=1);\n\n# Remove the not found persons\ndata = data[(~np.isnan(data.PersonId)) | (data.Id_sender != 80)]\ndata = data[data.Id_Contact != 80]\ndata['Id_Contact'] = data['Id_Contact'].apply(lambda i : personsDict[int(i)])\n\nprint(\"Number of emails after cleaning : \",data.shape[0])\nprint(\"Number of unique contacts : \", data['Id_Contact'].unique().shape[0])"},{"cell_type":"markdown","metadata":{},"source":"## Grouping email content by contact\n\nNext step is to get the emails, and group them by contact. In the end, each contact will have all the emails content he sent or received."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"corpusTmp = {}\ncorpus = {}\n\nfor i, email in enumerate(data.values):\n    corpusTmp[email[5]] = corpusTmp.get(email[5], \"\") + email[3]\n    \nocc = []\nfor key, val in corpusTmp.items():\n    if int(len(val)) > 10:\n        corpus[key] = val\ncontacts = list(corpus.keys())"},{"cell_type":"markdown","metadata":{},"source":"# Using NLTK to clean our data and compute TFIDFs\n\nBefore we calcul the TFIDFs, we need to tokenize the content grouped by contact. Tokenization will take car of pruning stop words. Stemming is also an important step to improve precision."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import nltk\nimport string\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.stem.porter import PorterStemmer\n\nstemmer = PorterStemmer()\n\ndef stem_tokens(tokens, stemmer):\n    stemmed = []\n    for item in tokens:\n        stemmed.append(stemmer.stem(item))\n    return stemmed\n\ndef tokenize(text):\n    tokens = nltk.word_tokenize(text)\n    stems = stem_tokens(tokens, stemmer)\n    return stems\n\nfor contactId, text in corpus.items():\n    lowers = text.lower()\n    no_punctuation = lowers.translate(string.punctuation)\n    corpus[contactId] = no_punctuation\n        \n# because documents are of different size, it is important to normalize !\ntfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english', norm='l2')\ntfs = tfidf.fit_transform(corpus.values())"},{"cell_type":"markdown","metadata":{},"source":"# Computing distance between contacts\n\nTo calculate the cosinus similarities, we calculate the distance between all the combinaisons of contact pairs.\n\nIn this analysis, we will focus on the best relationships that might exist between Hillary Clinton's contacts. This is why we introduced 2 parameters :\n- threshold : minimum cosinus similarity we will take into account\n- limit : maximal number of contacts that a contact ca be linked to (we keep the \"n\" best similarities)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.metrics.pairwise import cosine_similarity\nimport operator\nsimilarity = cosine_similarity(tfs[0:len(contacts)], tfs)\n\nlinks = {}\nthreshold = 0.5\nlimit = 5\nx = []\ncontactsGraph = []\n\nfor i in range(len(contacts)):\n    tmp = {}\n    for j in range(i):\n        if similarity[int(i),int(j)] > threshold:\n            contactsGraph.append(int(i))\n            contactsGraph.append(int(j))\n            tmp[\"%s/%s\" % (contacts[int(i)],contacts[int(j)])] = similarity[int(i),int(j)]\n    tmp = sorted(tmp.items(), key=operator.itemgetter(1), reverse=True)\n    for i in range(limit):\n        if i < len(tmp):\n            links[tmp[i][0]] = tmp[i][1]"},{"cell_type":"markdown","metadata":{},"source":"# Vizualisation\n\nIn order to vizualize, we will create graphs because this kind of plot suits the best to see the link between Hillary Clinton's contacts."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"%pylab inline\n%matplotlib inline\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nmatplotlib.rcParams['figure.figsize'] = (50, 50)\nG=nx.Graph()\n\nfor key, val in links.items():\n    n1, n2 = key.split('/')\n    G.add_edge(n1, n2, weight=round(val, 3))\n\nnodes = dict()\nfor i in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n    nodes[i] = [(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] < i and d['weight'] >= round(i-0.1, 2)]\n\npos=nx.spring_layout(G)\n\nnx.draw_networkx_nodes(G,pos,node_size=0,node_color='yellow')\n\nfor key, val in nodes.items():\n    nx.draw_networkx_edges(G,pos,edgelist=val, width=1, style='dashed') \n\nnx.draw_networkx_labels(G,pos,font_size=18,font_family='sans-serif')\n\nplt.axis('off')\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"# Analysing the result graph : unexpected results\n\nTo view bette the graph, right-click on it and select \"open in new window\". There, you will see it full sized.\n\nBasically, the analysis results did not go as i would have expected. I thought I would see groups of contacts, meaning that Hillary Clinton's contacts are gathered by topics. After performing the cosinus calculation for different thresholds and different limits, I realized that there is just 1 group gathering all the contacts. \n\nThis could be explained as follow : The emails chosen for the analysis have some close content. It is then impossible to cluster them by topics. Maybe the emails chosen for the analysis were dealing with the same subject. A quick look at other Kaggle submission that focused on Hillary Clinton's topics show that actually, the emails subjects are quite similar."},{"cell_type":"markdown","metadata":{},"source":"# Analysis brought other information\n\nThe vizualisation of the graphs showed something else, also very interesting. After playing around with thresholds and limits, I could see some kind of a structure. A few contacts are very much more connected than others. The number of connections they have is clearly significant, and we can easlily see hotspots on the graphs. \n\nI could reproduce this with various thresholds (from 0.2 to 0.9), always showing the same results.\n\nSo, what could this mean ?\n\nAt this step, I miss information to adress further conclusions, but it would appear that Hillary Clinton does not interact with her contacts as equal. Through the emails they have send and received, some of them may share topics with more contacts than others, acting a bit like relays. So, what gives them their ability to gather so many contacts ? Are thoses contacts mentoring some specific topics ?\n\nA further analysis could be lead to get deeper into what kind of relationship Hillary Clinton shares with those 5 persons, and why they stand out from the crowd so significantly."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}