{"cells":[{"metadata":{"_uuid":"6ccacd01f0e78bb2c678df76aebf961fcf51eae3"},"cell_type":"markdown","source":"# Import libraries"},{"metadata":{"trusted":true,"_uuid":"7ee73fe995ed86c8aba968624918e225041cc493"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7149952fb0f2851e9ec1058c959db3776246a612"},"cell_type":"markdown","source":"# Import dataset"},{"metadata":{"trusted":true,"_uuid":"066f073b1cf7ea4e5daf49a323563ed14879f38d"},"cell_type":"code","source":"dataset = pd.read_csv('../input/master.csv')\nX = dataset.drop(['suicides/100k pop', 'suicides_no', 'country-year'], axis=1) #delete some \"duplicate\" features\ny = dataset['suicides/100k pop']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d82c54c5c2112a1888072f0299e1000a4dabd8b9"},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":false,"_uuid":"b9f2c21fc962c255112a808216d4ae10f099d6af"},"cell_type":"code","source":"X[' gdp_for_year ($) '] = X[' gdp_for_year ($) '].str.replace(',', '').astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"19c57c9533cc68060b41d673cc41d92ef3318d84"},"cell_type":"code","source":"#X #is gdp for year relevant?","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b931827ddc2fe562962e1c8aa9b937798b68db0"},"cell_type":"markdown","source":"# Investigate correlation"},{"metadata":{"_uuid":"4bc536ec8a9ec0f0436c392eaa734028424f6cb1"},"cell_type":"markdown","source":"##### Nothing seems to be linearly correlated so I'll leave all the independent variables in"},{"metadata":{"trusted":false,"_uuid":"83c92f341429e23eaedd7252ec1f4c1bf22e123d"},"cell_type":"code","source":"import seaborn as sns\ncorr = X.corr()\nsns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6d2c0ae64baa3e4b8b1a94030fa7674dcab85c54"},"cell_type":"code","source":"plt.scatter(X['gdp_per_capita ($)'], X[' gdp_for_year ($) '])\n#I'll keep both these in. Some countries like the Soviet Union had a hight GDP per capita but did not distibute the wealth","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3fb7674c524890ca8cc896d356d1c33402cdea30"},"cell_type":"code","source":"plt.scatter(X['population'], X[' gdp_for_year ($) '])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6a6dfebcb3333c84bf1baffff68569afd459d0e4"},"cell_type":"code","source":"plt.scatter(X['gdp_per_capita ($)'], X['HDI for year'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3e2ba39235f930b2d660406dbf0954e81a911b8"},"cell_type":"markdown","source":"# Check for outliers"},{"metadata":{"trusted":false,"_uuid":"3f88c45615705dd779d7a7a993e03a39b9951632"},"cell_type":"code","source":"X.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e999ea7f34d7dd488cf1fe83edba2e6f3d92fb20"},"cell_type":"code","source":"plt.scatter(X[' gdp_for_year ($) '], y) #seem to be outliers above suicide rates of 125 and over based on gdp and hdi. let's drop them","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"86ef9bdf21353f71fd09b3713a3de916e17e5fbd"},"cell_type":"code","source":"X = X[y < 125]\ny = y[y < 125]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bd086cc5ed1d0acae89b75ce5b6ffad5b3a9e60a"},"cell_type":"code","source":"numeric_features = ['year','HDI for year', ' gdp_for_year ($) ', 'population',\n                   'gdp_per_capita ($)']\ncategorical_features = ['country', 'sex', 'age', 'generation']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"95bf6e328ec323323a302a7df471c741fa892fb1"},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Imputer, OneHotEncoder, StandardScaler #these all appear to come because HDI wasn't available prior to 2\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', Imputer(missing_values='NaN', strategy='mean')),\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder())\n])\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\nclf = Pipeline(steps=[('preprocessor', preprocessor)])\nX = clf.fit_transform(X)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"636c6fbeda8e340589985e1be8d3243a596e0d96"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ade1c1bdaba9bd672a132c08be7eb6ebf41aeb8"},"cell_type":"markdown","source":"# Try linear regression"},{"metadata":{"trusted":false,"_uuid":"83a436658bd251454ad2858aae1ca8d7a54eb4b5"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression(fit_intercept=False)\nregressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0385d4507fc7079c8121dae5e9cc9d1e83405a9b"},"cell_type":"code","source":"y_pred_test = regressor.predict(X_test)\ny_pred_train = regressor.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97a87b9c8d2e078e59e50e9bea3cb1187db377a0"},"cell_type":"markdown","source":"# Evaluate performance"},{"metadata":{"trusted":false,"_uuid":"2386a855df44f3ca9a65219f9a365be882daff3d"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nrms_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\nrms_train = np.sqrt(mean_squared_error(y_train, y_pred_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f01d848744265dadc6cac48ffaa66e224706cfe9"},"cell_type":"code","source":"print('The RMSE of the test set is: ' + rms_test.astype(str))\nprint('The RMSE of the training set is: ' + rms_train.astype(str))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f3325794eda122995d94afa66da8eff01920d69"},"cell_type":"markdown","source":"# Try backwards elimination"},{"metadata":{"trusted":false,"_uuid":"57868dfd45e04174674c3bd1ec41b69a589b45d6"},"cell_type":"code","source":"X_train.shape\n#X_train = np.append(np.ones((22256, 1)).astype(int), values=X_train, axis=1) #Add constants","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e98bdd44ae1209d2f4ab4862e00304e527b0cdcc"},"cell_type":"code","source":"# import statsmodels.formula.api as sm\n# def backwardElimination(x, sl):\n#     numVars = len(x[0])\n#     for i in range(0, numVars):\n#         regressor_OLS = sm.OLS(y, x).fit()\n#         maxVar = max(regressor_OLS.pvalues).astype(float)\n#         if maxVar > sl:\n#             for j in range(0, numVars - i):\n#                 if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n#                     x = np.delete(x, j, 1)\n#     regressor_OLS.summary()\n#     return x\n \n# SL = 0.05\n# X_opt = X_train.todense()\n# X_Modeled = backwardElimination(X_opt, SL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"20d80a802d609a0c69449bd6b0f2c25d24757bd5"},"cell_type":"code","source":"#X_Mod","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4b81d81e6c6a3500290dd9af34462d9dcaec727b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}