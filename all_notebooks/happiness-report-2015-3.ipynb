{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.1"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"f4db5d6c88af6863efc8e885cb933af32872cbd7","trusted":false,"_cell_guid":"20b198ea-f0d2-4e94-be53-5fbcea557812","_execution_state":"idle"},"source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nfrom sklearn.model_selection import cross_val_score","outputs":[],"cell_type":"code","execution_count":1},{"metadata":{"_uuid":"255ef12607455e3491f7da762d9ea51289a0ec73","collapsed":false,"trusted":false,"_cell_guid":"15d28469-9584-4383-a0e4-cdf5dc198f37","_execution_state":"idle"},"source":"#importing datset\n\ndataset = pd.read_csv(\"../input/2015.csv\")\n\n#Plotting the correlation using matshow() and heatmap\n\nc = dataset.corr()\nplt.matshow(c)\nplt.xticks(range(len(c.columns)), c.columns)\nplt.yticks(range(len(c.columns)), c.columns)","outputs":[],"cell_type":"code","execution_count":2},{"metadata":{"_uuid":"3cc55c24576c6c82470bc736e21730a7f7ff7770","collapsed":false,"trusted":false,"_cell_guid":"6caf73f4-bec7-49f2-944f-d93d299b0e98","_execution_state":"idle"},"source":"sns.heatmap(c)","outputs":[],"cell_type":"code","execution_count":3},{"metadata":{"_uuid":"7ec31e621fd77d6cfb4723bedb5115d06e5184b7","collapsed":false,"trusted":false,"_cell_guid":"ebe9aa1c-0a1d-4c59-8811-23ab81ba6365","_execution_state":"idle"},"source":"# Calculating the average happiness scores region wise and plotting them\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv(\"../input/2015.csv\")\n\ns = dataset.groupby(['Region'])[ 'Happiness Score'].mean()\n\ndf = pd.DataFrame(s)\ndf.index is s.index\ndf['Region'] = df.index\n#s.reindex(index = [0,1,2,3,4,5,6,7,8,9])\n\nsns.stripplot(x=\"Region\", y=\"Happiness Score\", data=df, jitter=True)\nplt.xticks(rotation=90)\n\n#North America and Australia & New Zealand seem to be the happiest regions","outputs":[],"cell_type":"code","execution_count":2},{"metadata":{"_uuid":"d318a506d9386ce8325b8fad4db8bc171b9336ff","collapsed":false,"trusted":false,"_cell_guid":"e32e9006-ba95-4989-b453-25925056eb6a","_execution_state":"idle"},"source":"# Plotting the happiness scores on the world map\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\ndata = dict(type = 'choropleth', \n           locations = dataset['Country'],\n           locationmode = 'country names',\n           z = dataset['Happiness Score'], \n           text = dataset['Country'],\n           colorbar = {'title':'Happiness'})\nlayout = dict(title = 'Global Happiness', \n             geo = dict(showframe = False, \n                       projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\nplot(choromap3)","outputs":[],"cell_type":"code","execution_count":5},{"metadata":{"_uuid":"f0f9c71ed1157fdbee111fb6f9c9ef0589097fc9","collapsed":false,"trusted":false,"_cell_guid":"040c6ed1-b601-48b9-bced-66ea17a4f23e","_execution_state":"idle"},"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\n\ndataset = pd.read_csv(\"../input/2015.csv\")\n\n# K-MEANS CLUSTERING\n\nX = dataset.iloc[:, 4:12].values\n\nY = dataset.iloc[:, 3].values\n    \n#K-MEANS CLUSTERING\n# Using the Elbow Method to find the optimal number of clusters\n\nwcss = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    km.fit(X)\n    wcss.append(km.inertia_)\nplt.plot(range(1,11), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n# Applying K-Means to the dataset\n\nkm = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\nn_km = km.fit_predict(X)\n\n#Plotting the CLustering results\n\npca_2 = PCA(2)\nplot_columns = pca_2.fit_transform(X)\nplt.scatter(x = plot_columns[:,0], y = plot_columns[:,1], c = km.labels_)\nplt.xlabel(\"Canonical Variable 1\")\nplt.ylabel(\"Canonical Variable 2\")\nplt.title(\"Scatterplot for Clustering\")\nplt.show()\n\n#Splitting the dataset into training set and test set\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n\n#Feature Scaling\n\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)\n\n#Fitting MULTIPLE LINEAR REGRESSION to the training set\n\nregressor = LinearRegression()\nregressor.fit(X_train, Y_train)\n\n#Predicting the test set results\n\ny_pred = regressor.predict(X_test)\n\n#Plotting the predictions against original values\n\nplt.scatter(Y_test,y_pred)\nplt.xlabel(\"Original Value\")\nplt.ylabel(\"Predicted Value\")\nplt.show()\n\nprint('Coefficients: \\n', regressor.coef_)\n# The mean squared error\nprint(\"Mean squared error: %.2f\"\n      % np.mean((regressor.predict(X_test) - Y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regressor.score(X_test, Y_test))\n\n# Applying k-Fold Cross Validation\n\naccuracies = cross_val_score(estimator = regressor, X = X_train, y = Y_train, cv = 10)\naccuracies.mean()\naccuracies.std()","outputs":[],"cell_type":"code","execution_count":2},{"metadata":{"_uuid":"3ebde9fdc8b463e4d459a449ebd2fcd4afa31a8c","collapsed":false,"trusted":false,"_cell_guid":"2b04bd69-4510-40d0-87e6-2085b1d71245","_execution_state":"idle"},"source":"","outputs":[],"execution_count":null,"cell_type":"code"}]}