{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset=pd.read_csv(\"../input/predicting-churn-for-bank-customers/Churn_Modelling.csv\")\n\nx=dataset.iloc[:,3:13]\ny=dataset.iloc[:,13]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets Encode Geography And Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"geography=pd.get_dummies(x[\"Geography\"],drop_first=True)\ngender=pd.get_dummies(x[\"Gender\"],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pd.concat([x,geography,gender],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Drop Unnecessary columns\nx=x.drop(['Geography','Gender'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In ANN feature scaling is very important so that all inputs are at a comparable range and only the weights assigned to them are, in fact, the only factor which makes a difference on the predicted value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n#scales test train to float data type from unknown datatype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets Make ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Randomly initialise the weights with small numbers close to zero but not zero. This will be done by our Dense function.\n\nDistribute features of the first observation, from your dataset, per each node in the input layer. Thus, eleven independent variables will be added to our input layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialising the ANN\nclassifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding the input layer\n\nunits - number of nodes to add to the hidden layer.\n\nTip: units should be the average of nodes in the input layer (11 nodes) and the number of nodes in the output layer (1 node). For this case is 11+1/2 = 6\n\nkernel_initializer - randomly initialize the weight with small numbers close to zero, according to uniform distribution.\n\nactivation - Activation function.\n\ninput_dim - number of nodes in the input layer, that our hidden layer should be expecting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 11 ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'he_uniform', activation = 'relu'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To define the first hidden layer, we firstly will have to define an activation function. The best one is the Rectifier Function and we’ll choose this one for the hidden layers. Furthermore, also by using a Sigmoid function to the output layer will allow us to calculate the probabilities of the different class (leaving or staying the bank). In the end, we will be able to rank the customers by their probability to leave the bank.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cost Function : Measure the generated error by comparing the predicted value with the true value.\n\nCompiling the ANN -\n\noptimizer — algorithm to use to find the best weights that will make our system powerful\n\nloss — Loss function within our optimizer algorithm\n\nmetric — criteria to evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the ANN\nclassifier.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Back-Propagation: from the output to the input layer, the calculated error is back-propagated and the weights get updated according to the influence they had on the error. The learning rates indicate how much these weights are updated.\n\nReinforcement Learning : Update weights at each observation or Batch Learning : Update the weights after each batch of observations\n\nWhen the system has gone through the whole training dataset, an epoch has been run."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the ANN to the Training set\nclassifier.fit(x_train, y_train, batch_size = 10, epochs = 100  )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"batch_size : number of observations after which we update the weights\n\nepochs: How many times you train your model"},{"metadata":{},"cell_type":"markdown","source":"# Prediction Time !"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting the Test set results\ny_pred = classifier.predict(x_test)\n\n#Threshold of 50%\ny_pred = (y_pred>0.5)\n\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**According to our model the first five customer will not leave the bank while the sixth on the rank will.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making the COnfusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(y_pred,y_test)\nscore","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}