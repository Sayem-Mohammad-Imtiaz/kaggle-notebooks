{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing packages for the necessary purposes\n\n# Data manipulation/analysis\nimport numpy as np\nimport keras \nimport pandas as pd\nimport tensorflow as tf\n\n# Text preprocessing\nimport re\nimport nltk\nimport string\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Modelling\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, LSTM, Activation,Flatten,Bidirectional,GlobalMaxPool1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.initializers import glorot_uniform\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style=\"whitegrid\", context='talk')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing and understanding data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  **Preprocessing of text**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convering sentiment values to either 0 or 1\n# Positive = 1 and negative = 0\n\ndef convert_sentiment(word):\n    if word == 'positive':\n        new_value = 1\n    else:\n        new_value = 0    \n    return new_value\n\ndata['new_sentiment'] = data['sentiment'].apply(convert_sentiment)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing punctutation. We use string.punctuation in python which consists of !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', string.punctuation))\n\ndata['without_punctuation'] = data['review'].apply(lambda text: remove_punctuation(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing stopwords\nstopword_list=nltk.corpus.stopwords.words('english')\ndef remove_stopwords(text):\n    return \" \".join([word for word in str(text).split() if word not in stopword_list])\n\ndata[\"without_stop\"] = data['without_punctuation'].apply(lambda text: remove_stopwords(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stemming\nstemmer = PorterStemmer()\ndef stem_words(text):\n    return \" \".join([stemmer.stem(word) for word in text.split()])\n\ndata['stemmed'] = data['without_stop'].apply(lambda text: stem_words(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing URLs\ndef remove_url(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'', text)\n\ndata['no_url'] = data['stemmed'].apply(lambda text: remove_url(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing html strips\ndef remove_html(text):\n    return BeautifulSoup(text, \"lxml\").text\n\ndata['no_html'] = data['no_url'].apply(lambda text: remove_html(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting to lower case\ndata['final_reviews'] = data['no_html'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding max and min length of reviews to decide on a suitable length to implement padding\nmeasurer = np.vectorize(len)\nmax_len = measurer(data['final_reviews']).max(axis=0)\nmin_len = measurer(data['final_reviews']).min(axis=0)\nmean_len = measurer(data['final_reviews']).mean(axis=0)\n\nprint(max_len)\nprint(min_len)\nprint(mean_len)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Spitting data into the train and test datasets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the number of positive and negative sentiment values available\ndata['new_sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Since we have a balanced dataset, we can proceed to split the dataset with 80% of data in the train dataset and 20% of data in the test dataset.\nReview_train=data.final_reviews[:40000]\nS_train=data.new_sentiment[:40000]\n\nReview_test=data.final_reviews[40000:]\nS_test=data.new_sentiment[40000:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Processing text to be inputted into a model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tokenization \n#We also specify the max number of words in the dictionary and a token to represent words that are out of the vocabulary/dictionary (OOV)\n\nvocab_size= 4000\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(Review_train)\ntokenizer.fit_on_texts(Review_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Representing each review in terms of the numbers that represent each word in it\nR_train_input = tokenizer.texts_to_sequences(Review_train)\nR_test_input = tokenizer.texts_to_sequences(Review_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inserting padding for sequences\nmaxlen = 700\nR_train_input = pad_sequences(R_train_input, maxlen=maxlen, padding = 'post')\nR_test_input = pad_sequences(R_test_input, maxlen=maxlen, padding = 'post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the data column into an array to make further implementations easier\nR_train = np.array(R_train_input)\nS_train = np.array(S_train)\nR_test = np.array(R_test_input)\nS_test = np.array(S_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Creating the model**\n\n* Simple model \n* LSTM\n* Bidirectional LSTM\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Simple model\nembedding_dim =32\nmodel = keras.Sequential([\n    Embedding(vocab_size, embedding_dim, input_length=maxlen),\n    Flatten(),\n    Dense(100, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')])\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 20\nmodel.fit(R_train, S_train, epochs=num_epochs,batch_size = 64, validation_split=0.1, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(R_test, S_test, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiple directional lstm model\nembedding_dim = 32\nmodel_multiple_bidi_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,embedding_dim, input_length=maxlen),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n    tf.keras.layers.Dense(1, activation='sigmoid')])\n\nmodel_multiple_bidi_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel_multiple_bidi_lstm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 5\nmodel_multiple_bidi_lstm.fit(R_train, S_train, epochs=num_epochs,batch_size = 64, validation_split=0.1, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_multiple_bidi_lstm.evaluate(R_test, S_test, batch_size=64)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}