{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Задача класифікації пацієнтів щодо схильності до серцевих нападів.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Предметною областю є медицина, а саме - кардіологія (серцеві напади). Нашою метою є класифікація пацієнтів за наданими в датасеті характеристиками для прогнозування, чи схильні вони до серцевого нападу.\n\nВикористовуємо датасет з відкритого ресурсу, Kaggle: https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset\n\nОзнайомимось попередньо з даними файлу:\n- Age: вік пацієнта\n- Sex: стать пацієнта\n- exang: стенокардія, спричинена фізичними вправами (1 = так; 0 = ні)\n- ca: кількість основних суден (0-3)\n- cp: Біль у грудях тип болю в грудях\n- Value 1: типова стенокардія\n- Value 2: атипова стенокардія\n- Value 3: неангінозний біль\n- Value 4: безсимптомно\n- trtbps: артеріальний тиск у спокої (у мм рт. ст.)\n- chol: холесторал у мг / дл, отриманий за допомогою датчика ІМТ\n- fbs: (цукор у крові натще> 120 мг / дл) (1 = істинно; 0 = хибно)\n- rest_ecg: результати електрокардіографічного спокою\n- Value 0: нормальне\n- Value 1: наявність аномалії хвилі ST-T (інверсія зубця T та / або підвищення ST або депресія> 0,05 мВ)\n- Value 2: показ імовірної або певної гіпертрофії лівого шлуночка за критеріями Естеса\n- thalach: досягнутий максимальний пульс\n- target: 0 = менше шансів серцевого нападу 1 = більше шансів серцевого нападу\n\nДля вирішення задачі використовуватимемо такі бібліотеки як pandas, numpy, sklearn, seaborn та інші.\n\nЩодо ML-алгоритму, плануємо застосувати декілька, щоб порівняти результати та обрати найефективніший.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport pandas_profiling as pp\n\nimport seaborn as sns\nimport numpy as np\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n!pip install pywaffle\nfrom pywaffle import Waffle\nfrom sklearn import tree\nimport sklearn.metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport warnings\nfrom yellowbrick.classifier import ClassificationReport\nfrom yellowbrick.classifier import ConfusionMatrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndf = pd.read_csv(os.path.join('/kaggle/input/heart-attack-analysis-prediction-dataset/','heart.csv'))\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# видаляємо дублікати\ndf = df.drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Попередньо побачили, що в датасеті немає рядків з пропущеними записами, тож функція FillNa не знадобиться.","metadata":{}},{"cell_type":"code","source":"# застосування   описової   статистики\ndf.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# проведення  кореляційного  та  причинно-наслідкового  аналізів \ndf.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# конструювання  ознак\n\ndf = df[df.chol<380]\ndf = df[df.trtbps<190]\ndf = df[df.thalachh>75]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# розбиття   набору   даних   на   тренувальний та  тестовий  набори  даних\n\nX = df.drop('output', axis = 1)\ny = df.output\nX = StandardScaler().fit(X).transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.info(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.info(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для вирішення посталеної задачі будемо використовувати 5 типових методів методів:\n- DecisionTreeClassifier(Це навчання є одним з підходів моделювання прогнозів, які використовуються в статистиці, інтелектуальному аналізі даних і навчанні машин. Моделі дерев, в яких цільова змінна може приймати дискретний набір значень, називаються деревами класифікації)\n- GaussianNB(простий імовірнісний класифікатор, заснований на застосуванні теореми Байеса зі строгими (наївними) припущеннями про незалежність.)\n- XGBClassifier(До важливих властивостей XGBoost, які відрізняють її від інших алгоритмів підсилювання градієнту, належать: Розумне штрафування дерев, Пропорційне скорочування листових вузлів, Ньютонове підсилювання, Додатковий параметр рандомізації, Втілення на окремих, розподілених системах, та позаядрових обчисленнях.)\n- LogisticRegression(це статистична модель, використовувана для прогнозування ймовірності виникнення деякої події шляхом його порівняння з логістичної кривої. Ця регреcсія видає відповідь у вигляді ймовірності бінарного події (1 або 0).)\n- RandomForestClassifier(ансамблевий метод машинного навчання для класифікації, регресії та інших завдань, які оперують за допомогою побудови численних дерев прийняття рішень під час тренування моделі і продукують моду для класів (класифікацій) або усереднений прогноз (регресія) побудованих дерев. Недоліком є схильність до перенавчання.)\n\nДля порівняння ефективності роботи моделей будемо враховувати:\n- матрицю помилок\n- trainning та test accuracy(У багаторабельній класифікації ця функція обчислює точність підмножини: набір лейблів, передбачених для зразка, повинен точно відповідати відповідному набору лейблів у y_true.)\n- precision(також називається позитивна прогностична цінність - це частка відповідних інстанцій серед витків екземплярів)\n- recall(також називається чутливість - це частка відповідних випадків, які були отримані)\n- f1(у статистичному аналізі бінарної класифікації F-оцінка або F-міра є кількістю точних тестів)","metadata":{}},{"cell_type":"code","source":"Image(filename='/kaggle/input/images/form.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename='/kaggle/input/images/from2.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Імплементація обраних методів моделювання","metadata":{}},{"cell_type":"code","source":"# DecisionTreeClassifier\n\nmodel = tree.DecisionTreeClassifier(max_depth=15)\nclf = model.fit(X_train, y_train)\ny_predict=clf.predict(X_train)\ntrain_accuracy = sklearn.metrics.accuracy_score(y_predict, y_train)\ny_valid=clf.predict(X_test)\ny_dt=y_valid\ntest_accuracy = sklearn.metrics.accuracy_score(y_valid, y_test)\n\nfig=plt.figure(figsize=(12,5))\nfig = plt.subplot(121)\nplt.title(\"Confusion metric\")\nsns.heatmap(confusion_matrix(y_test, y_valid), annot = True)\nfig = plt.subplot(122)\nclasses = [\"No Heart Attack\",\"Heart Attack\"]\nvisualizer = ClassificationReport(model, classes=classes, support=True)\nvisualizer.fit(X_train, y_train)       \nvisualizer.score(X_test, y_test)        \nvisualizer.show()  \n\nprint(\"Training accuracy\",train_accuracy)\nprint(\"Test accuracy\",test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GaussianNB\n\nmodel = GaussianNB()\nclf = model.fit(X_train, y_train)\ny_predict=clf.predict(X_train)\ntrain_accuracy = sklearn.metrics.accuracy_score(y_predict, y_train)\ny_valid=clf.predict(X_test)\ny_nb=y_valid\ntest_accuracy = sklearn.metrics.accuracy_score(y_valid, y_test)\n\nfig=plt.figure(figsize=(12,5))\nfig = plt.subplot(121)\nplt.title(\"Confusion metric\")\nsns.heatmap(confusion_matrix(y_test, y_valid), annot = True)\nfig = plt.subplot(122)\nclasses = [\"No Heart Attack\",\"Heart Attack\"]\nvisualizer = ClassificationReport(model, classes=classes, support=True)\nvisualizer.fit(X_train, y_train)       \nvisualizer.score(X_test, y_test)        \nvisualizer.show()  \n\nprint(\"Training accuracy\",train_accuracy)\nprint(\"Test accuracy\",test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBClassifier\n\nmodel = XGBClassifier()\nclf = model.fit(X_train, y_train)\ny_predict=clf.predict(X_train)\ntrain_accuracy = sklearn.metrics.accuracy_score(y_predict, y_train)\ny_valid=clf.predict(X_test)\ny_xg=y_valid\ntest_accuracy = sklearn.metrics.accuracy_score(y_valid, y_test)\n\nfig=plt.figure(figsize=(12,5))\nfig = plt.subplot(121)\nplt.title(\"Confusion metric\")\nsns.heatmap(confusion_matrix(y_test, y_valid), annot = True)\nfig = plt.subplot(122)\nclasses = [\"No Heart Attack\",\"Heart Attack\"]\nvisualizer = ClassificationReport(model, classes=classes, support=True)\nvisualizer.fit(X_train, y_train)       \nvisualizer.score(X_test, y_test)        \nvisualizer.show()  \n\nprint(\"Training accuracy\",train_accuracy)\nprint(\"Test accuracy\",test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LogisticRegression\n\nmodel = LogisticRegression()\nclf = model.fit(X_train, y_train)\ny_predict=clf.predict(X_train)\ntrain_accuracy = sklearn.metrics.accuracy_score(y_predict, y_train)\ny_valid=clf.predict(X_test)\ny_lr=y_valid\ntest_accuracy = sklearn.metrics.accuracy_score(y_valid, y_test)\n\nfig=plt.figure(figsize=(12,5))\nfig = plt.subplot(121)\nplt.title(\"Confusion metric\")\nsns.heatmap(confusion_matrix(y_test, y_valid), annot = True)\nfig = plt.subplot(122)\nclasses = [\"No Heart Attack\",\"Heart Attack\"]\nvisualizer = ClassificationReport(model, classes=classes, support=True)\nvisualizer.fit(X_train, y_train)       \nvisualizer.score(X_test, y_test)        \nvisualizer.show()  \n\nprint(\"Training accuracy\",train_accuracy)\nprint(\"Test accuracy\",test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=3000)\nclf = model.fit(X_train, y_train)\ny_predict=clf.predict(X_train)\ntrain_accuracy = sklearn.metrics.accuracy_score(y_predict, y_train)\ny_valid=clf.predict(X_test)\ny_rf=y_valid\ntest_accuracy = sklearn.metrics.accuracy_score(y_valid, y_test)\n\nfig=plt.figure(figsize=(12,5))\nfig = plt.subplot(121)\nplt.title(\"Confusion metric\")\nsns.heatmap(confusion_matrix(y_test, y_valid), annot = True)\nfig = plt.subplot(122)\nclasses = [\"No Heart Attack\",\"Heart Attack\"]\nvisualizer = ClassificationReport(model, classes=classes, support=True)\nvisualizer.fit(X_train, y_train)       \nvisualizer.score(X_test, y_test)        \nvisualizer.show()  \n\nprint(\"Training accuracy\",train_accuracy)\nprint(\"Test accuracy\",test_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_df = pd.DataFrame(data=[f1_score(y_test,y_lr),accuracy_score(y_test, y_lr), recall_score(y_test, y_lr), precision_score(y_test, y_lr), roc_auc_score(y_test, y_lr)], \n             columns=['Logistic Regression'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nrf_df = pd.DataFrame(data=[f1_score(y_test,y_rf),accuracy_score(y_test, y_rf), recall_score(y_test, y_rf),precision_score(y_test, y_rf), roc_auc_score(y_test, y_rf)], \n             columns=['Random Forest Score'],index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nnb_df = pd.DataFrame(data=[f1_score(y_test,y_nb),accuracy_score(y_test, y_nb), recall_score(y_test, y_nb), precision_score(y_test, y_nb), roc_auc_score(y_test, y_nb)], \n             columns=['Naive Bayes'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\n\nxg_df = pd.DataFrame(data=[f1_score(y_test,y_xg),accuracy_score(y_test, y_xg), recall_score(y_test, y_xg), precision_score(y_test, y_xg), roc_auc_score(y_test, y_xg)], \n             columns=['XG Boost'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\ndt_df = pd.DataFrame(data=[f1_score(y_test,y_dt),accuracy_score(y_test, y_dt), recall_score(y_test, y_dt), precision_score(y_test, y_dt), roc_auc_score(y_test,y_dt)], \n             columns=['Decision Tree'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\n\n\ndf_models = round(pd.concat([lr_df,rf_df,nb_df,dt_df,xg_df], axis=1),3)\ncolors = [\"bisque\",\"ivory\",\"sandybrown\",\"steelblue\",\"lightsalmon\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nbackground_color = \"white\"\n\nfig = plt.figure(figsize=(18,26))\ngs = fig.add_gridspec(4, 2)\ngs.update(wspace=0.1, hspace=0.5)\nax0 = fig.add_subplot(gs[0, :])\n\nsns.heatmap(df_models.T, cmap=colormap,annot=True,fmt=\".1%\",vmin=0,vmax=0.95, linewidths=2.5,cbar=False,ax=ax0,annot_kws={\"fontsize\":16})\nfig.patch.set_facecolor(background_color)\nax0.set_facecolor(background_color) \n\nax0.text(0,-0.5,'Model Comparison',fontsize=20,fontweight='bold',fontfamily='serif')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Бачимо з таблиці порівняння моделей, що найкраще себе показали Логістична регресія та Випадковий ліс, але, в цілому, всі моделі дають гарний результат","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}