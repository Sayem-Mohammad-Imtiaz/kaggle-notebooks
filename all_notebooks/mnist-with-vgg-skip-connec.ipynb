{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This Notebook is about MNIST with VGG + Skip connection👨‍🎓\n\nSince the first block of VGG detect the edges, I wanted to use this information when predicting the label.\n\nMy main ideas are\n\n* Deep layers (**VGG 16**)\n* First block is important (**Skip connection**)\n\n## 1. Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_data = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\ntest_data = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')\n\n# X\ntrain_labels = train_data.label\ntest_labels = test_data.label\n# y\ntrain_images = train_data.iloc[:, 1:].to_numpy()\ntest_images = test_data.iloc[:, 1:].to_numpy()\n\nprint('Train size : ' , train_labels.shape)\nprint('Test  size : ', test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data Preprocessing\n\n### What to do \n\n#### 1) Data Handling : reshape the data (600000, 784) to (60000,28,28)\n\n#### 2) Data Handling : Rescale 0~255 to 0~1 \n\n#### 3) Data Handling : 28 x 28 size is too small. make the size double 56 x 56\n\n#### 4) Data Handling :It is gray scale. Lets make it RGB channels.\n\n#### 5) Data Handling :I will use valid data. \n\n#### 6) Data Handling :y to categorical. 123456789 --> One hot encoding\n\n|Data|size|\n|---|---|\n|train|50000|\n|valid|10000|\n|test|10000|\n\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# For X \n\nimport numpy as np\n\n# 1. Reshape \ntrain_images = train_images.reshape((60000, 28, 28))\ntest_images = test_images.reshape((10000, 28, 28))\n\n\n# 2. Sacle\ntrain_images = train_images.astype('float32')/255\ntest_images = test_images.astype('float32')/255\n\n# 3. Bigger size. (becuase image is 2D, we have to repeat on axises 1 and 2 )\ntrain_images = np.repeat(train_images, 2, axis=1) \ntrain_images = np.repeat(train_images, 2, axis=2)\n\ntest_images = np.repeat(test_images, 2, axis=1)\ntest_images = np.repeat(test_images, 2, axis=2)\n\n# 4. GrayScale to  RGB\ntrain_images = np.stack((train_images,) * 3, axis=-1)\ntest_images = np.stack((test_images,) * 3, axis=-1)\n\n\n# 5. Valid \nvalid_images = train_images[50000:]\ntrain_images = train_images[:50000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For y\n\nfrom keras.utils import to_categorical\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\nvalid_labels = train_labels[50000:]\ntrain_labels = train_labels[:50000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG 16 layers + Skip connected layers\n\nI want to preserve the output of first block when prediction.\n\nSo I used the concept skip gram and added i to the last of the Convolutions.\n\nHere is the structure of my VGG 16 + Skip connection\n\n<br>\n\n\n![images](https://github.com/fxnnxc/prography-6th-deep-beomjinPark/blob/master/images/vgg16.png?raw=true)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten, Add\nfrom keras.models import Model\n\n# VGG16 + Skip Connection\n_input = Input((56,56,3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\nshortcut = pool1 # Skip connection\nshortcut = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(shortcut)\nshortcut  = MaxPooling2D((16, 16))(shortcut)\n\n\nconv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\nconv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\npool2  = MaxPooling2D((2, 2))(conv4)\n\nconv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\nconv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\nconv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\npool3  = MaxPooling2D((2, 2))(conv7)\n\nconv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\nconv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\nconv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\npool4  = MaxPooling2D((2, 2))(conv10)\n\nconv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\nconv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\nconv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\npool5  = MaxPooling2D((2, 2))(conv13)\n\nadd = Add()([shortcut, pool5]) # Skip connection joined\n\nflat   = Flatten()(add)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\nvgg16_skip_model  = Model(inputs=_input, outputs=output)\n\n# VGG16 \n_input = Input((56,56,3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\n\nconv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\nconv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\npool2  = MaxPooling2D((2, 2))(conv4)\n\nconv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\nconv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\nconv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\npool3  = MaxPooling2D((2, 2))(conv7)\n\nconv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\nconv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\nconv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\npool4  = MaxPooling2D((2, 2))(conv10)\n\nconv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\nconv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\nconv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\npool5  = MaxPooling2D((2, 2))(conv13)\n\nflat   = Flatten()(pool5)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\nvgg16_model  = Model(inputs=_input, outputs=output)\n\n\n# CNN \n_input = Input((56,56,3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\nflat   = Flatten()(pool1)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\ncnn_model  = Model(inputs=_input, outputs=output)\n\n# Dense\n_input = Input((56,56,3)) \nflat   = Flatten()(_input)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(10, activation=\"softmax\")(dense2)\n\ndense_model  = Model(inputs=_input, outputs=output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vgg16_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training \nfrom keras import optimizers\n\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']\noptimizer = optimizers.RMSprop(lr=1e-5)\nbatch_size = 128\nepochs = 5\n\n#VGG16_skip\nvgg16_skip_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory1 = vgg16_skip_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)\n\n#VGG16\nvgg16_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory2 = vgg16_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)\n\n#CNN\ncnn_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory3 = cnn_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)\n\n#Dense\ndense_model.compile(optimizer= optimizer,\n                loss=loss,\n                metrics = metrics)\n\n\nhistory4 = dense_model.fit(x=train_images, y=train_labels,\n                        validation_data=(valid_images, valid_labels),\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistories = [history1, history2, history3, history4]\ncolors = ['red','blue','green', 'orange']\nlegends = ['VGG16+skip', 'VGG16','CNN', 'Dense']\nf =  plt.figure(figsize=(10,10))\n\nfor i, history in enumerate(histories):\n\n    try:\n          acc = history.history['accuracy']\n          val_acc = history.history['val_accuracy']\n    except:\n          acc = history.history['acc']\n          val_acc = history.history['val_acc']\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n\n    plt.plot(epochs, acc,'--', color=colors[i], label=legends[i]+'Train')\n    plt.plot(epochs, val_acc, color=colors[i], label=legends[i]+'Validation')\n    plt.title('Validation accuracy')\n    plt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = vgg16_skip_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"vgg16_skip\", \"test_acc\", test_acc, \"test_loss\", test_loss)\n\ntest_loss, test_acc = vgg16_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"vgg16     \", \"test_acc\", test_acc, \"test_loss\", test_loss)\n\ntest_loss, test_acc = cnn_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"cnn       \", \"test_acc\", test_acc, \"test_loss\", test_loss)\n\ntest_loss, test_acc = dense_model.evaluate(test_images, test_labels, verbose=2)\nprint(\"dense     \", \"test_acc\", test_acc, \"test_loss\", test_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thank you for reading my notebook.\n\n## Feel free to comment on any things like misspell and ideas! 😀","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}