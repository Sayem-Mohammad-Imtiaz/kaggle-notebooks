{"cells":[{"metadata":{},"cell_type":"markdown","source":"The goal of this notebook is do two things:\n1. Some general, basic exploration of the dataset to become familiar with columns and potential issues. I include functions for loading the data as well\n2. Use cosine similarity with the scispacy package to find articles related to the task questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scispacy\n!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_ner_bc5cdr_md-0.2.4.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport json\nimport gc\nfrom glob import glob\n\nimport scispacy\nimport spacy\nimport en_ner_bc5cdr_md\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\npd.set_option('max_columns', 100)\nfrom IPython.core.display import display, HTML\ndisplay(HTML('<style>.container { width:100% !important; }</style>'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the datasets and combine them.\n## Heavily based off the work by xhulu"},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_ref(r):\n    return '\\n'.join(['{0}-{1}:{2}'.format(x['start'],x['end'],x['ref_id']) for x in r])\n\ndef format_author(author):    \n    return \" \".join([author['first'], \" \".join(author['middle']), author['last']])\n\ndef json_reader(file):\n    #takes a json file, processes the body, ref, and bib data into a dataframe\n    with open(file) as f:\n        j = json.load(f)\n        \n    #format the body text so the sections are clear, but it's easy to view the whole thing\n    body_text = '\\n\\n'.join(['<section {}> '.format(n) + x['section'] + '\\n\\n' + x['text'] for n,x in enumerate(j['body_text'])])\n    ref_spans = '\\n\\n'.join(['<section {}> '.format(n) + x['section'] + '\\n\\n' + format_ref(x['ref_spans']) for n,x in enumerate(j['body_text'])])\n    cite_spans = '\\n\\n'.join(['<section {}> '.format(n) + x['section'] + '\\n\\n' + format_ref(x['cite_spans']) for n,x in enumerate(j['body_text'])])\n    \n    #format references in a similar way\n    ref_data = '\\n\\n'.join([k + '\\n\\n' + v['text'] + '\\n\\nlatex- {}'.format(v['latex']) for k,v in j['ref_entries'].items()])\n\n    #put the bibliography together, and format the authors\n    for k in j['bib_entries']:\n        j['bib_entries'][k]['author_list'] = ', '.join([format_author(a) for a in (j['bib_entries'][k]['authors'])])\n\n    bib_keys = ['ref_id', 'title', 'author_list', 'year', 'venue', 'volume', 'issn', 'pages', 'other_ids']\n    bib_data = '\\n\\n'.join([', '.join([str(x[k]) for k in bib_keys]) for _,x in j['bib_entries'].items()])\n\n    df = pd.DataFrame(index=[0], data={'body_text':body_text, \n                                            'cite_spans':cite_spans, \n                                            'ref_spans':ref_spans,\n                                            'ref_data': ref_data,\n                                            'bib_data': bib_data,\n                                            'paper_id': j['paper_id']})\n    \n    return df\n\n\ndef parse_folder(data_folder):\n    filelist = glob('/kaggle/input/CORD-19-research-challenge/{0}/{0}/*'.format(data_folder))\n    filelist.sort()\n    print('{} has {} files'.format(data_folder, len(filelist)))\n\n    df_ls=[]\n    for n,file in enumerate(filelist):\n        if n%1000==0:\n            print(n,file[-46:])\n        df = json_reader(file)\n        df_ls.append(df)\n    return pd.concat(df_ls)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#go through each of the four folders of json files and put everything into one dataframe\n#takes around 3-4min to complete\ndf_ls = []\nfor folder in ['comm_use_subset', 'noncomm_use_subset', 'custom_license', 'biorxiv_medrxiv']:\n    t = parse_folder(folder)\n    df_ls.append(t)\ndf = pd.concat(df_ls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\nmeta.rename(columns={'sha':'paper_id'}, inplace=True)\ndf = meta.merge(df, on='paper_id', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n### Duplicate papers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(['abstract', 'body_text', 'ref_data'], inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Basic Stats"},{"metadata":{},"cell_type":"markdown","source":"### Paper text is missing ~28%\n### Abstract, Title, and Author mostly complete"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum(axis=0).sort_values(ascending=False) / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pubmed makes up more of the abstracts\n### But Elsevier makes up more of the text"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.source_x.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['paper_id'].notna()].source_x.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### License Distribution"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.license.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Journal Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.journal.value_counts(normalize=True).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Publish Time"},{"metadata":{},"cell_type":"markdown","source":"### Papers date back to 1950s"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.publish_time.value_counts(normalize=True).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pub_year = df['publish_time'].dropna().apply(lambda x: x[:4]).value_counts().sort_index()\nplt.bar(pub_year.index, np.log10(pub_year.values))\nplt.xticks([i for i in range(pub_year.shape[0]) if i%8==0]);\nplt.title('Log Plot of All Publications Per Year');\nplt.ylabel('Log10');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CZI and Biorxiv papers are only available for recent publications"},{"metadata":{"trusted":true},"cell_type":"code","source":"pub_year = df[df['source_x'] == 'biorxiv']['publish_time'].dropna().apply(lambda x: x[:4]).value_counts().sort_index()\nplt.bar(pub_year.index, np.log10(pub_year.values))\n\nplt.xticks([i for i in range(pub_year.shape[0]) if i%1==0]);\nplt.title('BIORXIV Log Plot of Publications Per Year');\nplt.ylabel('Log10');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pub_year = df[df['source_x'] == 'CZI']['publish_time'].dropna().apply(lambda x: x[:4]).value_counts().sort_index()\nplt.bar(pub_year.index, np.log10(pub_year.values))\n\nplt.xticks([i for i in range(pub_year.shape[0]) if i%1==0]);\nplt.title('BIORXIV Log Plot of Publications Per Year');\nplt.ylabel('Log10');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Medrxiv papers don't have publish times"},{"metadata":{"trusted":true},"cell_type":"code","source":"#All MEDRXIV PAPERS ARE MISSING MOST PUBLISH TIMES\ndf[df['source_x'] == 'medrxiv']['publish_time'].notna().sum() / df[df['source_x'] =='medrxiv'].shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Covid References"},{"metadata":{},"cell_type":"markdown","source":"### Only ~20% of papers are about Covid-19!"},{"metadata":{"trusted":true},"cell_type":"code","source":"((df['abstract'].dropna().str.contains('corona', case=False)) | (df['abstract'].dropna().str.contains('COVID', case=False))).sum() / df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### References to Promising Drugs"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['abstract'].fillna('').str.contains('chloroquine', case=False)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['abstract'].fillna('').str.contains('favipiravir', case=False)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['abstract'].fillna('').str.contains('lopinavir', case=False)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['abstract'].fillna('').str.contains('ritonavir', case=False)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['abstract'].fillna('').str.contains('convalescent plasma', case=False)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['abstract'].fillna('').str.contains('passive antibody', case=False)].shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word counts"},{"metadata":{},"cell_type":"markdown","source":"### Some abstracts have more than 10k words!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['abstract'].dropna().apply(lambda x: len(x.split(' '))).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some body text is less than 1000 words"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['body_text'].dropna().apply(lambda x: len(x.split(' '))).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Long Abstract Example"},{"metadata":{"trusted":true},"cell_type":"code","source":"long_idx = df[df['abstract'].apply(lambda x: len(x.split(' ')) if isinstance(x,str) else 0) > 10000]['paper_id'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['paper_id'] == long_idx][['paper_id', 'source_x','title', 'license','abstract','publish_time', 'authors','journal','has_full_text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"' '.join(df[df['paper_id'] == long_idx]['abstract'].values[0].split(' ')[:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"' '.join(df[df['paper_id'] == long_idx]['abstract'].values[0].split(' ')[-100:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic Text Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=['abstract'], inplace=True)\ndf.drop(columns='body_text', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the scispacy model relevant to diseases\nnlp = spacy.load('en_ner_bc5cdr_md')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp.vocab.length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#each word comes with an embedding\nnlp(df.iloc[0]['abstract'])[0].vector[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_doc_vec(tokens):\n    #combine word embeddings from a document into a single document vector\n    #filter out any stop words like 'the', and remove any punction/numbers\n    w_all = np.zeros(tokens[0].vector.shape)\n    n=0\n    for w in tokens:\n        if (not w.is_stop) and (len(w)>1) and (not w.is_punct) and (not w.is_digit):\n            w_all += w.vector\n            n+=1\n    return (w_all / n) if n>0 else np.zeros(tokens[0].vector.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#takes a long time, load from file\nvector_dict={}\nfor n,row in df.iterrows():\n    if n%500==0:\n        print(n)\n    if len(row['abstract']) > 0:\n        vector_dict[row['paper_id']] = get_doc_vec(nlp(row['abstract']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_vals = list(vector_dict.values())\nvec_vals = [v for v in vec_vals if all(v==0)==False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.to_pickle(vec_vals, 'vec_vals.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(vec_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q_vec = [get_doc_vec(nlp('What do we know about COVID-19 risk factors?'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_sims = cosine_similarity(vec_vals, q_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_sims.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q_series = pd.Series(dict(zip(vector_dict.keys(), target_sims)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"closet_papers = q_series.sort_values(ascending=False).head(10).index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth',200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['paper_id'].isin(closet_papers)][['title','abstract']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not bad!\n\nSome article titles like '**Super-spreaders and the rate of transmission of the SARS virus**', '**Bioethical Implications of Globalization: An International Consortium Project of the European Commission**', and '**Infectious Disease Prevalence and Factors Associated with Upper Respiratory Infection in Cats Following Relocation**' all sound promising. \n\nThough I guess it's debatable how relevant the cat article really is."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":4}