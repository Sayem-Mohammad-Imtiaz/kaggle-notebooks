{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n#Importing Datasets\nds = pd.read_csv(\"../input/bottle.csv\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Both the temparature and salinity varies with depth so using only the first 500 samples reduces the significance of the depth, as it does not vary much(relative to the entire set), and also allows our regression models to peform much faster"},{"metadata":{"trusted":true,"_uuid":"de6f3a9223416935678a8e21a0c314574024ffb8"},"cell_type":"code","source":"ds = ds[:][:500]\nds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eff1db257faabde7fd60dd6652d1f7f547e52a08"},"cell_type":"code","source":"#Getting rid of Nan data\ntemp = ds[ds['Salnty'].isnull()].index\nds = ds.drop(temp)\n\ntemp = ds[ds['T_degC'].isnull()].index\nds = ds.drop(temp)\n\n#Usable Variable Data\nx = ds['Salnty']\n\nx = np.array(x)\nx = np.reshape(x,(len(x),1))\n\ny = ds['T_degC']\n\nx\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ded96afb25a89a7a09d077df4dcf6a675f141317"},"cell_type":"code","source":"#Splitting Data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,\n                                                 random_state = 20)\n#Initial Visualisation\nplt.scatter(x,y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a40a2edf6ca60871c8bb8c73172eb6661b361d6"},"cell_type":"markdown","source":"We can now fit the data to a few regrssion models to see which performs best."},{"metadata":{"trusted":true,"_uuid":"c811c92ff3cfd2ed584c4666ae39299052c68884"},"cell_type":"code","source":"#Linear Regression\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(x_train,y_train)\n\n#Visaulising Linear regression Results\nplt.scatter(x_test,y_test,color = 'red')\nplt.plot(x_test,lin_reg.predict(x_test),color = 'blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3119b37a33c00248c79ace4ec75b6ce408b51eb6"},"cell_type":"code","source":"#Polynomial Regression\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_feat = PolynomialFeatures(degree = 2)\nx_poly = poly_feat.fit_transform(x_train)\npoly_reg = LinearRegression()\npoly_reg.fit(x_poly,y_train)\n\n#Ensure smooth curve\nx_grid = np.arange(min(x_train),max(x_train),0.01)\nx_grid = x_grid.reshape(len(x_grid),1)\n\n#Visualising Polynominal Results\nplt.scatter(x_test,y_test,color = 'red')\nplt.plot(x_grid,poly_reg.predict(poly_feat.fit_transform(x_grid)),color = 'blue')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e1aa9810bfbc91429c380b6f48104059dffff25"},"cell_type":"code","source":"#Decision Tree Regression\nfrom sklearn.tree import DecisionTreeRegressor\ndt_reg = DecisionTreeRegressor(min_samples_split =50, random_state = 0)\ndt_reg.fit(x_train,y_train)\n\n#Visualising Decision Tree Regression\nplt.scatter(x_test, y_test, color = 'red')\nplt.plot(x_grid, dt_reg.predict(x_grid), color = 'blue')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e8d626a4320b56b8ce8100f79246a7abac67956"},"cell_type":"code","source":"\n#Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor(n_estimators = 1,min_samples_split=20, random_state = 0)\nrf_reg.fit(x_train,y_train)\n\n#Visualising Random Forest Regression\nplt.scatter(x_test, y_test, color = 'red')\nplt.plot(x_grid, rf_reg.predict(x_grid), color = 'blue')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}