{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Customer Churn Modeling\n<img src=\"https://miro.medium.com/max/1024/1*YRq10sAcj2ScV2TirdSKBg.png\" height =500 width=500></imag>\n\n##### Can you predict if bank customers will turnover next cycle?\n\nChurn prevention allows companies to develop loyalty programs and retention campaigns to keep as many customers as possible."},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Process Step by Step\n<img src=\"https://miro.medium.com/max/1399/0*C_ibLD-RscbJzjMq.png\" height =500 width=500></imag>\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries\n- numpy\n- matplotlib\n- seaborn\n- scikit-learn\n- imblearn\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Librarys\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV # to split the data\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score, roc_curve #To evaluate our model\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.externals import joblib\nfrom scipy import stats\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom pylab import rcParams\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Dataset\n<a>https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling </a>\n\n__Given below are columns information__\n1. RowNumber\n2. CustomerId\n3. Surname\n4. CreditScore\n5. Geography\n6. Gender\n7. Age\n8. Tenure\n9. Balance\n10. NumOfProductsHow many accounts, bank account affiliated products the person has\n11. HasCrCard\n12. IsActiveMemberSubjective, but for the concept\n13. EstimatedSalary\n14. Exited Did they leave the bank after all?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using pandas \n# Data downloaded from above link and stored in local folder\ndataframe = pd.read_csv(\"../input/bank-customer-churn-modeling/Churn_Modelling.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis\n- __Summarizing, Describing and Data Distributions__\n- __Univariate and bivariate Analysis__\n- __Outliers and their influence__\n- __Metadata errors__\n- __Missing Data__\n- __Correlation analysis between variables__\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find out the total number of rows and columns\ndataframe.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns and their corresponding data types,along with finding whether they contain null values or not\ndataframe.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The describe() function in pandas is very handy in getting various summary statistics.\n# This function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data\ndataframe.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking data sampling\ndataframe.Exited.unique()\ndataframe.Exited.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization\nimport seaborn as sns\nsns.countplot(dataframe['Exited'],label=\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data to plot\nmale_dataframe = dataframe[dataframe.Gender==\"Male\"]\nsizes = male_dataframe['Exited'].value_counts(sort = True)\ncolors = [\"Green\",\"Red\"] \nrcParams['figure.figsize'] = 5,5\n# Plot\nplt.pie(sizes,  colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=270,)\nplt.title('Percentage of Churn in Dataset for Male')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data to plot\nfemale_dataframe = dataframe[dataframe.Gender==\"Female\"]\nsizes = female_dataframe['Exited'].value_counts(sort = True)\ncolors = [\"Green\",\"Red\"] \nrcParams['figure.figsize'] = 5,5\n# Plot\nplt.pie(sizes,  colors=colors,\n        autopct='%1.1f%%', shadow=True, startangle=270,)\nplt.title('Percentage of Churn in Dataset for Female')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = dataframe.corr()\n# plot correlation matrix\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(correlations, vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,9,1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(dataframe.columns)\nax.set_yticklabels(dataframe.columns)\nrcParams['figure.figsize'] = 40,15\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 10,10\nboxplot = dataframe.boxplot(column=['EstimatedSalary', 'Balance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 10,8\nsns.boxplot(x=\"Geography\",y=\"Exited\",data=dataframe,palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing\n- __Imputing Missing Data__\n- __Handling Unbalanced Data(Under Sampling and OverSampling)__\n- __Handling Outliers__\n- __Transforming, Encoding, Scaling, and Shuffling__"},{"metadata":{},"cell_type":"markdown","source":"### Imputing Missing Data "},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing null values to avoid errors  \ndataframe.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering\n- __Adding or dropping features__\n- __Combining multiple features into one feature__\n- __Binning__\n- __One Hot Encoding__"},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove the fields from the data set that we don't\n# want to include in our model\ndel dataframe['RowNumber']\ndel dataframe['CustomerId']\ndel dataframe['Surname']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label1 = LabelEncoder()\ndataframe['Geography'] = label1.fit_transform(dataframe['Geography'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label2 = LabelEncoder()\ndataframe['Gender'] = label2.fit_transform(dataframe['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_dataframe = pd.get_dummies(dataframe, columns=['Geography'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove the Exited from the feature data\ndel features_dataframe['Exited']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = features_dataframe.values\ny = dataframe['Exited']\nfeatures_dataframe.columns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply near miss\nimport imblearn\nfrom imblearn.under_sampling import NearMiss \nnr = NearMiss() \nX, y = nr.fit_sample(X, y)\nX[100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data set in a traning set (80%) and a test set(20%)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Training and Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Algorithmns models to be compared\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# to feed the random state\nseed = 7\nresults = []\nnames = []\nscoring = 'recall'\n\n# Models = [RandomForestClassifier(), LogisticRegression(), DecisionTreeClassifier(), KNeighborsClassifier(), \n# LinearDiscriminantAnalysis(),GaussianNB(), SVC(), GradientBoostingClassifier(), XGBClassifier()]\n# prepare models\nmodels = []\nmodels.append(('LogisticRegression         :', LogisticRegression()))\nmodels.append(('LinearDiscriminantAnalysis :', LinearDiscriminantAnalysis()))\nmodels.append(('KNeighborsClassifier       :', KNeighborsClassifier()))\nmodels.append(('DecisionTreeClassifier     :', DecisionTreeClassifier()))\nmodels.append(('GaussianNB                 :', GaussianNB()))\nmodels.append(('RandomForestClassifier     :', RandomForestClassifier()))\nmodels.append(('SVC                        :', SVC(gamma='auto')))\nmodels.append(('GradientBoostingClassifier :', GradientBoostingClassifier()))\nmodels.append(('XGBClassifier              :', XGBClassifier()))\nprint('Accuracy_Score :')\nprint('----------------')\nfor name, model in models:\n    model.fit(X_train,y_train)\n    kfold = KFold(n_splits=10, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print(name,accuracy_score(y_test, model.predict(X_test))*100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Choosed GradientBoostingClassifier Algorithm and List Metrics "},{"metadata":{"trusted":true},"cell_type":"code","source":"# From above models we can see, \n# We are getting highest accuracy and better values of precision and recall for XGBClassifier\nmodel = GradientBoostingClassifier()\nmodel.fit(X_train, y_train)\nprint('Accuracy = ',accuracy_score(y_test, model.predict(X_test)))\nprint('classification_report = ',classification_report(y_test, model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyper Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparameters = {\n    \"learning_rate\": [0.01, 0.025, 0.05],\n    \"max_depth\":[1,3,5],\n    \"max_features\":[\"log2\",\"sqrt\"],\n    \"n_estimators\":[10,50,100,150]\n    }\n\ngrid_search = GridSearchCV(GradientBoostingClassifier(), parameters, cv=10, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\nprint(grid_search.score(X_train, y_train))\nprint(grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model based on best hyper parameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Seting the Hyper Parameters\nmodel = GradientBoostingClassifier(learning_rate= 0.05, \n                                   max_depth = 5, \n                                   max_features = 'sqrt', \n                                   n_estimators= 50)\nmodel.fit(X_train, y_train)\nprint('Accuracy = ',accuracy_score(y_test, model.predict(X_test)))\nprint('classification_report = ',classification_report(y_test, model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy and Classification_report"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy = ',accuracy_score(y_test, model.predict(X_test)))\nprint('classification_report = ',classification_report(y_test, model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(model, X_test, y_test,\n                                 display_labels=['Exited','Not Exited'],\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save Model for Production Deployment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the trained model to a file so we can use it in other programs\njoblib.dump(model,\"customer_churn_mlmodel.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### List Important Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# These are the features labels from out data set\nfeature_labels = np.array(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Geography_0','Geography_1', 'Geography_2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a numpy array based on the model's feature importances\nimportance = model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort the feature labels based on the feature importance rankings from the model\nfeature_indexes_by_importance = importance.argsort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print each feature label, from most important to least important (reverse order)\nfor index in feature_indexes_by_importance:\n    print(\"{} - {:.2f}%\".format(feature_labels[index], (importance[index] * 100.0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}