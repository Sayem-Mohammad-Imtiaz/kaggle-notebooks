{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries and Data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#Importing libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing data\ndata = pd.read_csv('../input/500-person-gender-height-weight-bodymassindex/500_Person_Gender_Height_Weight_Index.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reviewing Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We need to see if the data set is complete with valid entries. This means checking if there are:\n - any null value entries\n - an equal number of entries for all features (columns)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This means we have no null values in the data. Next we want to check:\n - what features we are working with\n - how much data there is","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seeing what columns we have, what the data types there are, \n#and what number of entries per column we have.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This tells us that there are 4 feature columns - `Gender`, `Height`, `Weight`, and `Index` (BMI Index). \n\nKnowing that BMI is a calculated value, we can say that the variables we will be working with are `Gender`,`Height`, and `Weight`.\n\nWe can verify this with the data description given to us:\n\n>Gender : Male / Female\n\n>Height : Number (cm)\n\n> Weight : Number (Kg)\n\n>Index :\n0 - Extremely Weak, 1 - Weak, 2 - Normal, 3 - Overweight, 4 - Obesity, 5 - Extreme Obesity","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization\n\nNow we can start looking for trends in the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can first check the distribution of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set default plot grid\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index Historgram: Frequency of values falling under each Index [0,1,2,3,4,5]\nplt.rcParams['figure.figsize'] = (6, 6)\nsns.countplot(data['Index'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Index\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Height Historgram: Frequency of values falling under certain height intervals\nplt.rcParams['figure.figsize'] = (30, 10)\nsns.countplot(data['Height'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Height\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Weight Historgram: Frequency of values falling under certain weight intervals\nplt.rcParams['figure.figsize'] = (30, 10)\nsns.countplot(data['Weight'], palette='YlGnBu')\nax = plt.gca()\nax.set_title(\"Histogram of Weight\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot relation between weight and height\nsns.jointplot(x='Weight', y='Height', data=data, kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trend in Gender based on relationship between Height and Weight\nsns.lmplot(x='Height', y='Weight', hue='Gender', data=data,\n           fit_reg=True, height=7, aspect=1.25, palette = \"Accent\")\nax = plt.gca()\nax.set_title(\"Height Vs Weight Data Grouped by Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of height vs weight does not follow any trends when categorized by gender.\n\nSo, we can hypothesize that gender does not affect the index/BMI value significantly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trend in Index based on relationship between Height and Weight \nsns.lmplot(x='Height', y='Weight', hue='Index', data=data,\n           fit_reg=True, height=7, aspect=1.25, palette='Accent')\nax = plt.gca()\nax.set_title(\"Height Vs Weight Data Grouped by Index\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can make out distinct bands in the data based on the index value.\n\nSo, there is a general positive correlation between height and weight when categorized by index value.\n\nNow, let us see if there are any discrepencies in the relation when looking at each gender separately.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Segregate data based on whether the gender is Male or Female\nmale_data = data[data['Gender']=='Male']\nfemale_data = data[data['Gender']=='Female']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trend in Index based on relationship between Height and Weight \nmale_data = data[data['Gender']=='Male']\nfemale_data = data[data['Gender']=='Female']\nsns.lmplot(x='Height', y='Weight', hue='Index', data=male_data,\n           fit_reg=True, height=7, aspect=1.25,palette='Accent')\nax = plt.gca()\nax.set_title(\"Male Height Vs Weight Data Grouped by Index\")\n\nsns.lmplot(x='Height', y='Weight', hue='Index', data=female_data,\n           fit_reg=True, height=7, aspect=1.25,palette='Accent')\nax = plt.gca()\nax.set_title(\"Female Height Vs Weight Data Grouped by Index\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also see if there are any correlation in the data by producing correlation matrices.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gives us basic correlation index for numerical variables\ndata.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Provides visual context for correlations via color scale\nplt.rcParams['figure.figsize'] = (8, 7)\nsns.heatmap(data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once again, let's see if this changes for people of different genders.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (8, 7)\nsns.heatmap(male_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (8, 7)\nsns.heatmap(female_data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Before moving on to creating the predictive model, we need to find a way to include our non-numeric variable which is the Gender.\nEven though we found that it does not \n\nKnowing gender is a categorical value (Male/Female based on the data description) we need to encode the data for Gender to make it useable.\n\nThere are 2 ways we can do this:\n - Ordinal Encoding:\n     - Assign arbitrary numbers such as 1 to `Female` and 0 to `Male` (similar to a Boolean/Truth value) to differentiate them\n     - End up with one new column with number values from 0 to n representing n unique values\n - One-Hot Encoding:\n     - Create dummy variables, where we produce new columns for `Female` and `Male` and have binary values (0 or 1) for each of them\n     - End up with n new columns representing n unique values, but we only use n-1 of these columns dropping the last one as it ends up being redundant in nature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ordinal Encoding\ndata[\"Gender\"] = data[\"Gender\"].astype('category')\ndata[\"Gender_Enc\"] = data[\"Gender\"].cat.codes\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding\ndummies = pd.get_dummies(data['Gender'])\ndata = data.join(dummies)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that the results from Ordinal Encoding and One-Hot Encoding are very similar.\n\nThe new column `Male` from One-Hot Encoding is the same as the column `Gender_Enc` from Ordinal Encoding.  <br />\nThis happens to be the case since we are working with the categorical variable `Gender` which only has two exclusive values in the data.\n\nSo, for this case it does not matter which encoded values for `Gender` we use.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping last two columns with dummy values from one-hot encoding as they are redundant\ndata = data.drop(columns=['Male', 'Female'], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For making our predictive model we will need to proceed with certain steps:\n - Assign our data instances and target value (X and y columns)\n - Split data into training and test sets\n - Train our model\n - Test and evaluate the model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Prepare Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Since we want to predict what Index a person would be assigned based on their height, weight, and gender we will be making `Index` our target value or y. <br>\nSo, this makes our features `Height`, `Weight`, and `Gender_Enc` or X. <br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select columns to add to X and y sets\nfeatures = list(data.columns.values)\nfeatures.remove('Gender')\nfeatures.remove('Index')\nX = data[features]\ny = data['Index']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we split the X and y data between the training set and testing set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import additional required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import confusion_matrix,classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import required class from sklearn library\nfrom sklearn.model_selection import train_test_split\n\n# Split X and y into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here we will introduce our model and train it to fit the data we give it. <br>\nWe will be using the k-nearest neighbours algorithm first.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import required class from sklearn library\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Fit k-nearest neighbors classifier with training sets for n = 3\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test and Evaluate Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To test our model, we will:\n - Run and compare the models predictions to the real values using `X_test` and `y_test`\n - Produce a confusion matrix and classification report\n - Get mean accuracy scores and error rate for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run a prediction\ny_pred = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import remaining required classes from sklearn\nfrom sklearn.metrics import confusion_matrix,classification_report, accuracy_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get confusion matrix\nprint(confusion_matrix(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get classification report\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get accuracy score\nscore = np.mean(y_pred == y_test)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get error rate\nerror = np.mean(y_pred != y_test)\nprint(error)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's compare the results of the predictor to the actual values using a plot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x=y_test, y=y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = sns.jointplot(x=y_test, y=y_pred, kind='hex')\nx0, x1 = fig.ax_joint.get_xlim()\ny0, y1 = fig.ax_joint.get_ylim()\nlims = [max(x0, y0), min(x1, y1)]\nfig.ax_joint.plot(lims, lims, ':k')    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({ 'ytest':y_test,'ypred':y_pred})\nsns.residplot('ytest','ypred',data=df) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From these figures we see that not all points lie on the line of equality (where `y_test` equals `y_pred` indicating a correct prediction. <br>\nThis tells us the model is not as accurate as we may like it to be.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that we have seen how well our model predicts index values, let us see if the results can compare to the output from using a formula for calculating BMI. <br>\nWe can compare performance based on accuracy and time complexity.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"(IN PROGRESS)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}