{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing. \nFirstly, let's make all tables into one and process it."},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_data =[\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/audi.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/bmw.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/cclass.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/focus.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/ford.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/hyundi.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/merc.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/skoda.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/toyota.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/unclean cclass.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/unclean focus.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/vauxhall.csv\"),\n    pd.read_csv(\"../input/used-car-dataset-ford-and-mercedes/vw.csv\")\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is read. **Now let's modify read tables to make it all in one table**. Firstly, **we define needed functions**."},{"metadata":{"trusted":true},"cell_type":"code","source":"def select_common_columns(lst=[pd.DataFrame()], last=(cars_data[::-1])[0]):\n    if(len(lst)):\n        return set(lst[0].columns) & select_common_columns(lst[1:])\n    else:\n        return set(last)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modifyTables(lst=[pd.DataFrame()], cols=[]):\n    if(len(lst)):\n        lst[0] = lst[0][cols]\n        modifyTables(lst[1:], cols)\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def writeMark(lst=[pd.DataFrame()], car_marks=[]):\n    if( len(lst) and len(car_marks) ):\n        lst[0][\"mark\"] = car_marks[0]\n        writeMark(lst[1:], car_marks[1:])\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calcGeneralLength(lst=[pd.DataFrame()]):\n    if(len(lst)):\n        return len(lst[0]) + calcGeneralLength(lst[1:])\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resultColumn(lst=[pd.DataFrame()], col=\"\"):\n    if(len(lst)):\n        return lst[0][col].to_list() + resultColumn(lst[1:], col)\n    else:\n        return []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now we modify data tables.** Firstly, let's find common columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"commonColumns = select_common_columns(cars_data)\nprint(commonColumns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modifyTables(cars_data, commonColumns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will write a mark of cars for data tables."},{"metadata":{"trusted":true},"cell_type":"code","source":"marks = [\"audi\", \"bmw\", \"cclass\", \"focus\", \"ford\", \"hyundy\", \"merc\", \"skoda\", \"toyota\", \"unclean cclass\", \"unclean focus\", \n         \"vauxhall\", \"vw\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"writeMark(cars_data, marks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars_data[0].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we build general data package."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(columns=cars_data[0].columns, index=range(calcGeneralLength(cars_data)))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in data.columns:\n    data[column] = resultColumn(cars_data, column)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna()\ndata.head()\nprint(len(data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building a prediction model. \nData package is ready. Now let's do final manipulations with data and try to build prediction model."},{"metadata":{"trusted":true},"cell_type":"code","source":"models        = list( data[\"model\"].unique() )        #to code models of cars\ntransmissions = list( data[\"transmission\"].unique() ) #in code transmission types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    data[\"model\"][ data[\"model\"]==model ] = models.index(model)\nfor transmission in transmissions:\n    data[\"transmission\"][ data[\"transmission\"]==transmission ] = transmissions.index(transmission)\nfor mark in marks:\n    data[\"mark\"][ data[\"mark\"]==mark ] = marks.index(mark)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes = []\nfor i in data.index:\n    if( type(data.loc[i][\"price\"]) not in [int, float] or type(data.loc[i][\"model\"]) not in [int, float] or\n        type(data.loc[i][\"mileage\"]) not in [int, float] or type(data.loc[i][\"transmission\"]) not in [int, float] or\n        type(data.loc[i][\"mark\"]) not in [int, float]\n      ):\n        indexes.append(i)\ndata = data.drop(indexes)\nprint(len(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.astype(\"float\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, all parameters have numerical variant. **Let's build prediction model**."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(\"price\", axis=1)\ny = data[\"price\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, we will build linear regression model and will test it."},{"metadata":{"trusted":true},"cell_type":"code","source":"predModelDeg1 = LinearRegression().fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSE: \"+str(metrics.mean_squared_error(y, predModelDeg1.predict(X))) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"R^2: \"+str(metrics.r2_score(y, predModelDeg1.predict(X))) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, linear model is not very good. So, let's build quadratic regression model and test it."},{"metadata":{"trusted":true},"cell_type":"code","source":"predModelDeg2 = LinearRegression().fit(PolynomialFeatures(degree=2).fit_transform(X), y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSE: \"+str(metrics.mean_squared_error(y, predModelDeg2.predict(PolynomialFeatures(degree=2).fit_transform(X)))) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"R^2: \"+str(metrics.r2_score(y, predModelDeg2.predict(PolynomialFeatures(degree=2).fit_transform(X)))) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, we see implovement of results. Will we see improvement if we will use cubic regression model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"predModelDeg3 = LinearRegression().fit(PolynomialFeatures(degree=3).fit_transform(X), y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSE: \"+str(metrics.mean_squared_error(y, predModelDeg3.predict(PolynomialFeatures(degree=3).fit_transform(X)))) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"R^2: \"+str(metrics.r2_score(y, predModelDeg3.predict(PolynomialFeatures(degree=3).fit_transform(X)))) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see improvement again. But is it enough? I think no. So let's try to experiment with neural networks."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predNNModel = MLPRegressor((25, 25), activation=\"tanh\", max_iter=500).fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSE: \"+str(metrics.mean_squared_error( y, predNNModel.predict(X) )) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"R^2: \"+str(metrics.r2_score( y, predNNModel.predict(X) )) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSLE: \"+str(metrics.mean_squared_log_error( y, predNNModel.predict(X) )) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, it's possible, that prediction model, based in neural network can be enough good to be used, if we use our data. So let's build more bulky newural network to see, is it true or no."},{"metadata":{"trusted":true},"cell_type":"code","source":"predNNModel = MLPRegressor((50, 50, 50), activation=\"tanh\", max_iter=1500).fit(PolynomialFeatures(degree=2).fit_transform(X), y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSE: \"+str(metrics.mean_squared_error( y, predNNModel.predict(PolynomialFeatures(degree=2).fit_transform(X)) )) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"R^2: \"+str(metrics.r2_score( y, predNNModel.predict(PolynomialFeatures(degree=2).fit_transform(X)) )) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( \"MSLE: \"+str(metrics.mean_squared_log_error( y, predNNModel.predict(PolynomialFeatures(degree=2).fit_transform(X)) )) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, we can try to build neural network as prediction model to predict price and this model can be not very worse then regression model."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}