{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NEWS HEADLINE COMPILER \n\n![NEWS](http://fivebars.co.uk/wp-content/uploads/2018/08/news-1.jpg)\n\n - [Overview](#OVERVIEW)\n - [Instructions](#INSTRUCTIONS)\n - [Pip Requirements](#PIP-REQUIREMENTS)\n - [Selected Sources](#SELECTED-NEWS-SOURCES)\n - [Available Sources](#AVAILABLE-NEWS-SOURCES)\n\n# OVERVIEW\n\nThis project utilises the awesome  [newsAPI](https://newsapi.org/s/uk-news-api) , to pull down the latest news articles, descriptions and other information from a select amount of news sources. This project then compiles those lists into a daily folder, as the API can only get a select slice of the news, it will run three times a day to build up news data which in the future could be used to drive text generation, news comparisons and so on.\n\nBecause the API returns json, it's easier to just save json files for each source, then collate those files into one CSV. This can then be appeneded throughout the day, week and year.  \n\n\nThis project is fully open source and mostly for fun, if any future work is aimed at generating revenue, you must comply with the newsAPI policy and upgrade from Developer. I may do this if I find a useful business case based upon my exploration here. \n\nThis code requries access to newsAPI, thus can't run in this kernel: please reference my git repo for my latest updates [News_Source_compiler](https://github.com/murchie85/News_Source_compiler) . I will however include the code here anyway for completeness.\n  \n\n## INSTRUCTIONS\n\n1. Sign up to [newsAPI](https://newsapi.org/s/uk-news-api), generate keys **(it will tell you how to)** and store in a parent directory of this one called `keys`, or simply change the key path in the python code. \n2. Create a folder called `data` at same level as the python code\n3. run `python process_news.py` from command line / terminal.\n4. Program will pull down news articles and store them in data folder, creating a new folder for each day you run it. \n\n  \n## PIP REQUIREMENTS\n\n```\npandas\njson\nos\ndatetime\nnewsapi\n```\n\n\n## SELECTED NEWS SOURCES \n\nI may change this depending on the circumstance.\n\n\n```\nnews_keyname_array = ['bbc-news', 'abc-news','cnn','fox-news','independent','mirror','metro','daily-mail', 'Theguardian.com' , 'Sky.com', 'the-new-york-times', 'al-jazeera-english', 'reuters', 'the-hill' , 'breitbart-news', 'the-verge', 'the-huffington-post']\n```\n\n## AVAILABLE NEWS SOURCES\n\nFrom calling `the get_sources.py` code i have written (because the website doesn't give a full list), the below list of available ones are there. May have different ones depending on time of day? \n\n```\nabc-news-au\naftenposten\nal-jazeera-english\nansa\nargaam\nars-technica\nary-news\nassociated-press\naustralian-financial-review\naxios\nbbc-news\nbbc-sport\nbild\nblasting-news-br\nbleacher-report\nbloomberg\nbreitbart-news\nbusiness-insider\nbusiness-insider-uk\nbuzzfeed\ncbc-news\ncbs-news\ncnbc\ncnn\ncnn-es\ncrypto-coins-news\nder-tagesspiegel\ndie-zeit\nel-mundo\nengadget\nentertainment-weekly\nespn\nespn-cric-info\nfinancial-post\nfocus\nfootball-italia\nfortune\nfour-four-two\nfox-news\nfox-sports\nglobo\ngoogle-news\ngoogle-news-ar\ngoogle-news-au\ngoogle-news-br\ngoogle-news-ca\ngoogle-news-fr\ngoogle-news-in\ngoogle-news-is\ngoogle-news-it\ngoogle-news-ru\ngoogle-news-sa\ngoogle-news-uk\ngoteborgs-posten\ngruenderszene\nhacker-news\nhandelsblatt\nign\nil-sole-24-ore\nindependent\ninfobae\ninfo-money\nla-gaceta\nla-nacion\nla-repubblica\nle-monde\nlenta\nlequipe\nles-echos\nliberation\nmarca\nmashable\nmedical-news-today\nmsnbc\nmtv-news\nmtv-news-uk\nnational-geographic\nnational-review\nnbc-news\nnews24\nnew-scientist\nnews-com-au\nnewsweek\nnew-york-magazine\nnext-big-future\nnfl-news\nnhl-news\nnrk\npolitico\npolygon\nrbc\nrecode\nreddit-r-all\nreuters\nrt\nrte\nrtl-nieuws\nsabq\nspiegel-online\nsvenska-dagbladet\nt3n\ntalksport\ntechcrunch\ntechcrunch-cn\ntechradar\nthe-american-conservative\nthe-globe-and-mail\nthe-hill\nthe-hindu\nthe-huffington-post\nthe-irish-times\nthe-jerusalem-post\nthe-lad-bible\nthe-new-york-times\nthe-next-web\nthe-sport-bible\nthe-times-of-india\nthe-verge\nthe-wall-street-journal\nthe-washington-post\nthe-washington-times\ntime\nusa-today\nvice-news\nwired\nwired-de\nwirtschafts-woche\nxinhua-net\nynet\n```\n\n**Powered by news API**\n[link](https://newsapi.org/s/uk-news-api)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#-----------------------------------------------------------------------------------------\n#\n# Program name : process_news.py\n# Program Created Date: 31 December 2019\n# Program Amanded Date: 02 Jan 2020\n# Program Author: Adam McMurchie\n#\n# Program Description:  This program iterrogates news.api, pulls data and consolodates in a re-occuring append fasion. The aim to \n#                       Overtime build a portfolio of news data from various sources. Various archival, and time delay considerations \n#                       have been baked into the code (explained in program flow).\n#\n# Input Files:     Data from news.api which is whatever was present 15 minutes ago. \n# Output Files:    Json files in data folder, output.csv full list in data folder\n#\n# Program Flow :  **to be updated** Run job three times per day (at least)\n#                  Gets current date\n#                  Checks current date data folder (create if not exist)\n#                  compares news array pulled from news.api to written files\n#                  If news array has items that are not in written files\n#                  Regenerate news array with missing items\n#                  call news api, get news for updated news array\n#                  Save to json\n#                  Also save all files to csv (can overwrite)\n#                  Saves crossing any wires or putting the wrong list in the wrong market\n#\n#-----------------------------------------------------------------------------------------\n\n\n# IMPORT STATEMENTS \nimport json\nimport os\nfrom datetime import date\nfrom newsapi import NewsApiClient\nimport pandas as pd\n\n# IMPORT API KEYS (YOU WILL NEED TO REGISTER AT NEWSAPI.ORG)\nf = open(\"../your/key/location/api.txt\", \"r\")\nkeys = f.read()\nf.close()\nACCESS_TOKEN = keys\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------------------------------------------------------------------------------------\n#   PARMS SECTION \n#-------------------------------------------------------------------------------------------\n\n# READING IN \nNewsFileNameArray = []                         # A LIST OF FILENAMES \ndata = []                                      # ALL NEWS DATA FROM LOCAL NEWS JSON FILES\n\n# REQUESTING NEW DATA\nnewsapi = NewsApiClient(api_key=ACCESS_TOKEN)  # INITIALISING newsapi object\nnews_keyname_array = ['bbc-news', 'abc-news','cnn','fox-news','independent','mirror','metro','daily-mail', 'Theguardian.com' , 'Sky.com', 'the-new-york-times', 'al-jazeera-english', 'reuters', 'the-hill' , 'breitbart-news', 'the-verge', 'the-huffington-post']\nnews_array = []\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#-------------------------------------------------------------------------------------------\n#   CREATE NEW FOLDER FOR TODAY IF NOT EXIST\n#-------------------------------------------------------------------------------------------\n# GET TODAYS DATE \ntoday = date.today()\nprint(\"Today's date:\", today)\n\n# CREATE A NEW DIRECTORY FOR TODAY IF NOT EXIST\nif os.path.isdir(\"data/\" + str(today)):\n    print('Dir Already exists')\nelse:\n    os.mkdir(\"data/\" + str(today))\n\nprint('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------------------------------------------------------------------------------------\n#   REQUESTING MORE NEWS \n#-------------------------------------------------------------------------------------------\n\n# Init API and save to news_array\n# WRITE TO JSON\nprint('PULLING NEWS HEADLINES - PLEASE WAIT .... ')\nprint('')\nfor item in news_keyname_array:\n    print('processing ' + str(item + ' headlines'))\n    news_key = item\n    json_item = newsapi.get_top_headlines(sources=news_key)\n    if json_item['totalResults'] == 0:\n        print(\"Request for the \" + str(item) + \" news source is empty, skipping\")\n        print('')\n        continue\n    news_array.append(json_item)\n    print('COMPLETE - appending to array .......')\n    print('')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------------------------------------------------------------------------------------------\n#   BUILDING REPORT \n#-------------------------------------------------------------------------------------------\n\n# BUILD A PANDAS DATA FRAME \ndf = pd.DataFrame(columns=['source','author','title','description','url', 'requested_date','publishedAt','content'])\n\n\n# Iterate through DATA array and write to csv\nprint('iterating through ')\nx = 0 \nfor news_outlet in range (0, len(news_array)):\n    for article_number in range (0, len(news_array[news_outlet]['articles'])):\n        source         = news_array[news_outlet]['articles'][article_number]['source']['name']\n        author         = news_array[news_outlet]['articles'][article_number]['author']\n        title          = news_array[news_outlet]['articles'][article_number]['title']\n        description    = news_array[news_outlet]['articles'][article_number]['description']\n        url            = news_array[news_outlet]['articles'][article_number]['url']\n        publishedAt    = news_array[news_outlet]['articles'][article_number]['publishedAt']\n        requested_date = today\n        content        = news_array[news_outlet]['articles'][article_number]['content']\n        df = df.append([{ 'source': source, 'author': author, 'title': title, 'description': description, 'url':url, 'publishedAt': publishedAt, 'requested_date': requested_date, 'content': content    }])\n        x = x + 1 \n\nprint('PROCESSING COMPLETE')\nprint('number of articles processed are : ' + str(x))\n\n# imported is old data\n# df is the new data\n# combined is merged \n\n\ntry:\n    f = open(\"data/\" + str(today) + \"/\" + 'output.csv')\n    print('File exists')\nexcept IOError:\n    print(\"File not accessible, saving current df to file\")\n    df.to_csv(\"data/\" + str(today) + \"/\" + 'output.csv')\n\nfinally:\n    f.close()\n\nprint('importing saved data')\nimported = pd.read_csv(\"data/\" + str(today) + \"/\" + 'output.csv', index_col=0)\nprint('Appending old and new feeds')\ncombined = imported.append(df)\nprint('')\nprint('dropping duplicates')\ncombined = combined.drop_duplicates(subset=\"title\", keep='first')\nprint('')\nprint('describing new data')\nprint(df.shape)\nprint('')\nprint('describing old data')\nprint(imported.shape)\nprint('describing merged data with dropped duplicates')\nprint(combined.shape)\n\n        \ncombined.to_csv(\"data/\" + str(today) + \"/\" + 'output.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}