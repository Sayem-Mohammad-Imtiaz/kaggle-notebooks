{"cells":[{"metadata":{"id":"nRU3T3zoALwN","colab_type":"text"},"cell_type":"markdown","source":"<center>\n<h2> Classificaion Pipeline </h2>\n\n</center>"},{"metadata":{"id":"ZM8x5SdYALwQ","colab_type":"text"},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"id":"hgzZOwTRam9d","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"try:\n    import mlens\nexcept ImportError:\n    !pip install mlens\n    import mlens","execution_count":null,"outputs":[]},{"metadata":{"id":"YweCc3saALwS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport pandas as pd\nimport pandas_profiling\nimport numpy as np\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 10.0)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"id":"YWlP8-ahB7BO","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# seeding\nSEED = 7\nnp.random.seed(SEED)\n\nstart = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def execution_time(start):\n    _ = time.time()\n    hours, _ = divmod(_-start, 3600)\n    minutes, seconds = divmod(_, 60)\n    print(\"Execution Time:  {:0>2} hours: {:0>2} minutes: {:05.2f} seconds\".format(int(hours),int(minutes),seconds))","execution_count":null,"outputs":[]},{"metadata":{"id":"13MVAunWALwW","colab_type":"text"},"cell_type":"markdown","source":"## Data Preprocessing and Visualization"},{"metadata":{"id":"w7rl8i3jALwX","colab_type":"code","outputId":"3aa76287-6dcf-40c2-f43a-e80f35ada8b8","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"# Reading the data\ndf = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndf_name = df.columns\n\nprint('Shape of the dataframe: ', df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"-hHeH_66DBUu","colab_type":"text"},"cell_type":"markdown","source":"### Discriptive Statistics"},{"metadata":{"id":"fj4RvKGADmTf","colab_type":"code","outputId":"e213dfc5-3f60-4531-a110-9497b596c12b","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"EXah3Xv8DYSk","colab_type":"code","outputId":"3c39c2ba-81f6-4c5d-d1e0-49b7c860a8c8","colab":{"base_uri":"https://localhost:8080/","height":255},"trusted":true},"cell_type":"code","source":"df.info();","execution_count":null,"outputs":[]},{"metadata":{"id":"uQp5aUKUDnkI","colab_type":"code","outputId":"a6c977f7-a19f-4d2e-ac1a-e2edf0bc7b50","colab":{"base_uri":"https://localhost:8080/","height":317},"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"MFUbqC7EDqZ2","colab_type":"code","outputId":"960d64be-5fa0-4631-809c-7930412f6dc3","colab":{"base_uri":"https://localhost:8080/","height":328},"trusted":true},"cell_type":"code","source":"# Basic stats\ndef basic_stats(df):\n    b = pd.DataFrame()\n    b['Missing value'] = df.isnull().sum()\n    b['N unique value'] = df.nunique()\n    b['dtype'] = df.dtypes\n    return b\n\nbasic_stats(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot missing values similar to missingno package\n\ndef plot_missing_values(df):\n    sns.heatmap(df.isnull().T, cbar=False)\n    \nplot_missing_values(df)","execution_count":null,"outputs":[]},{"metadata":{"id":"JpDNO0IeDy1P","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# missing data replace with mode\ndef replace_missing_value(df):\n    col = df.columns\n    for i in col:\n        if df[i].isnull().sum()>0:\n            df[i].fillna(df[i].mode()[0],inplace=True)\n\n# replace_missing_value(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# complete data profiling using pandas_profiling package\ndf.profile_report()","execution_count":null,"outputs":[]},{"metadata":{"id":"kN1blKxfEG3U","colab_type":"text"},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"id":"-4Twq-WsALwk","colab_type":"code","outputId":"6f991ded-2156-43cb-921e-d2314242cd78","colab":{"base_uri":"https://localhost:8080/","height":607},"trusted":true},"cell_type":"code","source":"# Univariate graphs to see the distribution\ndf.hist();","execution_count":null,"outputs":[]},{"metadata":{"id":"H55fqfLpALwp","colab_type":"code","outputId":"797b0829-3608-4f31-fd13-cd3f32b632c3","colab":{"base_uri":"https://localhost:8080/","height":737},"trusted":true},"cell_type":"code","source":"# Correlation Matrix\ndef correlation_matrix(df):\n    Corr = df.corr()\n\n    mask = np.zeros(Corr.shape, dtype=bool)\n    mask[np.triu_indices(len(mask))] = True\n\n    sns.heatmap(Corr, cmap = 'coolwarm', annot = True, mask = mask);\n\ncorrelation_matrix(df);","execution_count":null,"outputs":[]},{"metadata":{"id":"GccAUyhFEvAW","colab_type":"code","outputId":"489eb1e9-2fb6-4963-d614-54331b54a9f7","colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"# pairplot\nsns.pairplot(df, hue=\"Outcome\", palette=\"husl\", markers=[\"o\", \"s\"], diag_kind='hist');","execution_count":null,"outputs":[]},{"metadata":{"id":"rSGf1phhG2jV","colab_type":"code","outputId":"9e81a7df-5712-433a-ba7f-ca53cc6e006e","colab":{"base_uri":"https://localhost:8080/","height":642},"trusted":true},"cell_type":"code","source":"# Dependent Variable Distribution\ndef dv_distribution(df, dv):\n    print(df[dv].value_counts())\n    plt.pie(df[dv].value_counts().values, labels=df[dv].value_counts().keys(), startangle=90, autopct='%.1f%%')\n    plt.title('Dependent Variable Distribution');\n\ndv_distribution(df, 'Outcome')","execution_count":null,"outputs":[]},{"metadata":{"id":"HRhf1XVgLXCu","colab_type":"code","outputId":"74d36c2e-4673-4177-b386-d072ef262d65","colab":{"base_uri":"https://localhost:8080/","height":683},"trusted":true},"cell_type":"code","source":"# Outliers Visualization\ndef plot_outliers(df):\n    df_name = df.columns\n    fig, axs = plt.subplots(1, len(df_name), figsize=(20, 10))\n\n    for i, col in enumerate(df_name):\n        axs[i].set_title(col)\n        axs[i].boxplot(df[col])\n    fig.suptitle('Outliers');\n\nplot_outliers(df)","execution_count":null,"outputs":[]},{"metadata":{"id":"48WOwhQ8ZWUK","colab_type":"text"},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"id":"b56AiNN7ALws","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Creating Dependent and Independent variables\nX =  df[df_name[0:8]]\nY = df[df_name[8]]\n\n# Dummy Variables\n# X = pd.get_dummies(X, drop_first=True)\n# X_cv = pd.get_dummies(X_cv, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Kn6cF106ALwv","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Spliting data\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test =train_test_split(X, Y, test_size=0.25, random_state=0, stratify=df['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"id":"zYFq_1CDALw9","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# convert to category\ndef category_type(df):\n    col = df.columns\n    for i in col:\n        if df[i].nunique()<=104:\n            df[i] = df[i].astype('category')\n\n#category_type(train)\n#category_type(test)","execution_count":null,"outputs":[]},{"metadata":{"id":"pGkSKZilALxC","colab_type":"text"},"cell_type":"markdown","source":"## Baseline: Models Evaluation"},{"metadata":{"id":"EtAjvayrALxD","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, make_scorer\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n\n# Spot-Check Algorithms (Classification)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Spot-Check Ensemble Models (Classification)\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n\ndef getBaselineModels():\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('LDA', LinearDiscriminantAnalysis()))\n    models.append(('NB', GaussianNB()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('CART', DecisionTreeClassifier()))\n    models.append(('SVM', SVC(probability=True)))\n\n    models.append(('AB', AdaBoostClassifier()))\n    models.append(('GBM', GradientBoostingClassifier()))\n    models.append(('ET', ExtraTreesClassifier()))\n    models.append(('RF', RandomForestClassifier()))\n\n    return models\n\ndef baselineModelsEval(X_train, y_train, models):\n    # Test options and evaluation metric\n    num_folds = 10\n    scoring = make_scorer(accuracy_score)\n\n    # evaluate each model in turn\n    results = {}\n    for name, model in tqdm_notebook(models):\n        kfold = StratifiedKFold(n_splits=num_folds, random_state=SEED)\n        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n        results[name] = cv_results\n\n    return results","execution_count":null,"outputs":[]},{"metadata":{"id":"-f9-dQv4K3N9","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def scoreDataFrame(results):\n    scores = []\n    names = []\n    for k, r in results.items():\n        names.append(k)\n        scores.append(round(r.mean(),4))\n\n    scoreDataFrame = pd.DataFrame({'Model':names, 'Score': scores})\n\n    return scoreDataFrame\n\ndef plotScores(results):\n    # boxplot algorithm comparison\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison')\n    ax = fig.add_subplot(111)\n    plt.boxplot(list(results.values()))\n    ax.set_xticklabels(list(results.keys()));","execution_count":null,"outputs":[]},{"metadata":{"id":"wYqEypV1J-CP","colab_type":"code","outputId":"bebb2a73-745f-4672-cb88-6092046bdadd","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2b762f7460004a8db93f4597efac6d87","572f0afb4acc479dae993d960984311d","c3799519cb564613884260c8263a0d67","79f75538e3ed4137932ea7b3d27290bf","79bffa38d1da41b08cb0f0297c2fc768","88b3c1a8ae5a4968a8656d7568a5d012","668dfca0d30f4c4e978d2411aadfb9a0","433ba352552b4bc8a83dec38351d2d6a"]},"trusted":true},"cell_type":"code","source":"models = getBaselineModels()\nresults = baselineModelsEval(X_train, y_train, models)\nplotScores(results)\nbaselineScore = scoreDataFrame(results)\nbaselineScore","execution_count":null,"outputs":[]},{"metadata":{"id":"o4so5FuiN1Vh","colab_type":"text"},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"id":"ukIIA9kjPm7h","colab_type":"text"},"cell_type":"markdown","source":"### Scaling"},{"metadata":{"id":"vus4MWMTN09X","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\ndef getScaledModel(nameOfScaler):\n    \n    if nameOfScaler == 'standard':\n        scaler = StandardScaler()\n    elif nameOfScaler =='minmax':\n        scaler = MinMaxScaler()\n\n    pipelines = []\n    pipelines.append((nameOfScaler+'LR'  , Pipeline([('Scaler', scaler),('LR'  , LogisticRegression())])))\n    pipelines.append((nameOfScaler+'LDA' , Pipeline([('Scaler', scaler),('LDA' , LinearDiscriminantAnalysis())])))\n    pipelines.append((nameOfScaler+'KNN' , Pipeline([('Scaler', scaler),('KNN' , KNeighborsClassifier())])))\n    pipelines.append((nameOfScaler+'CART', Pipeline([('Scaler', scaler),('CART', DecisionTreeClassifier())])))\n    pipelines.append((nameOfScaler+'NB'  , Pipeline([('Scaler', scaler),('NB'  , GaussianNB())])))\n    pipelines.append((nameOfScaler+'SVM' , Pipeline([('Scaler', scaler),('SVM' , SVC())])))\n    pipelines.append((nameOfScaler+'AB'  , Pipeline([('Scaler', scaler),('AB'  , AdaBoostClassifier())])))\n    pipelines.append((nameOfScaler+'GBM' , Pipeline([('Scaler', scaler),('GMB' , GradientBoostingClassifier())])  ))\n    pipelines.append((nameOfScaler+'RF'  , Pipeline([('Scaler', scaler),('RF'  , RandomForestClassifier())])))\n    pipelines.append((nameOfScaler+'ET'  , Pipeline([('Scaler', scaler),('ET'  , ExtraTreesClassifier())])))\n    \n    return pipelines","execution_count":null,"outputs":[]},{"metadata":{"id":"0OXYkEQBOSLh","colab_type":"code","outputId":"7b8b684a-57f8-4913-acf2-a300d4a16a1c","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ca68adb188ec42ff8c893710286508a3","52e4244570134cbea02fc7ecebec3290","55ea2c37f95842d589cdde9ce2f44135","b85f9f8737f247428fac368a211d64a1","06a28f40cb084a168bea4747254b6bc0","cce5ba4f7c854a49a8e674a9840efac1","f28b35a09599404b9933951a5b60e590","40389c5c7a714db0afe9399200513803"]},"trusted":true},"cell_type":"code","source":"#standard scaler\nmodels = getScaledModel('standard')\nresults = baselineModelsEval(X_train, y_train, models)\nplotScores(results)\nscaledScoreStandard = scoreDataFrame(results)\ncompareModels = pd.concat([baselineScore, scaledScoreStandard], axis=1)\ncompareModels","execution_count":null,"outputs":[]},{"metadata":{"id":"-ZTJUjCeO-Bv","colab_type":"code","outputId":"136860ce-a997-4e38-b065-6947c325d856","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ef3162633f1e4be69b632a3bbe76ec33","0195afb9b17c4a1da6dbf20d1b44866c","85ff6a86015c4295a694e8c3377049f1","8ffb06f8123c4111b35051fb9131c47a","21021de7e2d74284ad785d3e4e8bffb9","b31dc45213324769ba9d8c38511a1d26","fcbdcb1692e24b60a70b3993e04c66d0","aaa1030f57944df7a3b6c533ff510d33"]},"trusted":true},"cell_type":"code","source":"#minmax scaler\nmodels = getScaledModel('minmax')\nresults = baselineModelsEval(X_train, y_train, models)\nplotScores(results)\nscaledScoreMinMax = scoreDataFrame(results)\ncompareModels = pd.concat([baselineScore, scaledScoreStandard, scaledScoreMinMax], axis=1)\ncompareModels","execution_count":null,"outputs":[]},{"metadata":{"id":"vBc6Xz9pPiJk","colab_type":"text"},"cell_type":"markdown","source":"### Removing Outlies"},{"metadata":{"id":"74Ex3pnGQz-d","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"df_t = df.copy()\ndf_t_name = df_t.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"SmkrEFEQPhn1","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def outliers(df_out, drop=False):\n    \n    #good_data = df_out.copy()\n    for nameOfFeature in df_out.columns:\n        valueOfFeature = df_out[nameOfFeature]\n        # Calculate Q1 (25th percentile of the data) for the given feature\n        Q1 = np.percentile(valueOfFeature, 25.)\n\n        # Calculate Q3 (75th percentile of the data) for the given feature\n        Q3 = np.percentile(valueOfFeature, 75.)\n\n        # Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n        step = (Q3-Q1)*1.5\n\n        outliers = valueOfFeature[~((valueOfFeature >= Q1 - step) & (valueOfFeature <= Q3 + step))].index.tolist()\n        feature_outliers = valueOfFeature[~((valueOfFeature >= Q1 - step) & (valueOfFeature <= Q3 + step))].values\n\n        # Remove the outliers, if any were specified\n        print(\"\\n\" + \"\\u0332\".join(nameOfFeature) + \": \\n\")\n        print (\"Number of outliers (inc duplicates): {} and outliers: {}\".format(len(outliers), feature_outliers))\n\n        if drop:\n            df_out = df_out.drop(df_out.index[outliers]).reset_index(drop = True)\n            print(\"New dataset with removed outliers has shape ({}, {})\".format(*df_out.shape))\n    \n    return df_out","execution_count":null,"outputs":[]},{"metadata":{"id":"yd6IvUV5RSeY","colab_type":"code","outputId":"22942f10-9205-4589-8a40-6b2fbf475d04","colab":{"base_uri":"https://localhost:8080/","height":751},"trusted":true},"cell_type":"code","source":"# without drop\n_ = outliers(df_t)","execution_count":null,"outputs":[]},{"metadata":{"id":"sS23oHHu5Uro","colab_type":"code","outputId":"4cd34073-935b-4721-9637-249938aca962","colab":{"base_uri":"https://localhost:8080/","height":887},"trusted":true},"cell_type":"code","source":"# with drop\ndf_clean = outliers(df_t, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"z_TG5h8U6wev","colab_type":"code","outputId":"63f46b45-c7cb-4b9f-b987-ead9aaa0f94e","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"print('df shape: {}, new df shape: {}, we lost {} rows, {}% of our data'.format(df.shape[0], df_clean.shape[0], df.shape[0]-df_clean.shape[0],\n                                                        (df.shape[0]-df_clean.shape[0])/df.shape[0]*100))","execution_count":null,"outputs":[]},{"metadata":{"id":"29IwZVmY7OUS","colab_type":"text"},"cell_type":"markdown","source":"#### Model evaluation on Cleaned Data"},{"metadata":{"id":"_XK-f5he68sP","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"df_clean_name = df_clean.columns\n\nX_c =  df_clean[df_clean_name[0:8]]\nY_c = df_clean[df_clean_name[8]]\n\nX_train_c, X_test_c, y_train_c, y_test_c =train_test_split(X_c, Y_c, test_size=0.25, random_state=0, stratify=df_clean['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"id":"jXmLikwy7W-P","colab_type":"code","outputId":"1e884e19-1ecc-4c08-9828-062ff7456a82","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1cfc016d20894f919628bf7f324b5690","a5195656974c4bb7b613565d9e44a978","e27c1cab733742b2aa225141e386c2ab","bc87c1dd52004c9ebfca82df26e9dc71","8890b70b7b7b486fad27dc75f259f8f9","a80cc4a69631445792e7647440462ea2","be6036ff8b5047e89906e242040c2c0b","7200c2d8b8e24c6ca31b395e6294210a"]},"trusted":true},"cell_type":"code","source":"models = getScaledModel('minmax')\nresults = baselineModelsEval(X_train_c, y_train_c, models)\nplotScores(results)\nscaledScoreMinMax_c = scoreDataFrame(results)\ncompareModels = pd.concat([baselineScore, scaledScoreStandard, scaledScoreMinMax, scaledScoreMinMax_c], axis=1)\ncompareModels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Interpretability (for Feature Importance/Selection)"},{"metadata":{},"cell_type":"markdown","source":"### ExtraTreeClassifier's feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = ExtraTreesClassifier(n_estimators=250, random_state=SEED)\nclf.fit(X_train_c, y_train_c);","execution_count":null,"outputs":[]},{"metadata":{"id":"cAnRwWCI-oe2","colab_type":"code","outputId":"427ea352-e58f-473d-936e-d723c11a7c25","colab":{"base_uri":"https://localhost:8080/","height":350},"trusted":true},"cell_type":"code","source":" def featureImportance(X, y): \n    clf = ExtraTreesClassifier(n_estimators=250, random_state=SEED)\n    clf.fit(X, y)\n\n    # Plot feature importance\n    feature_importance = clf.feature_importances_\n    # make importances relative to max importance\n    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n    sorted_idx = np.argsort(feature_importance)\n    pos = np.arange(sorted_idx.shape[0]) + .5\n    plt.figure(figsize=(5,5))\n    plt.barh(pos, feature_importance[sorted_idx], align='center')\n    plt.yticks(pos, df.columns[sorted_idx])\n    plt.xlabel('Relative Importance')\n    plt.title('Variable Importance');\n\nfeatureImportance(X_train_c, y_train_c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LIME (Local Interpretable Model-Agnostic Explanation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lime\nfrom lime.lime_tabular import LimeTabularExplainer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialization of LIME explainer\nexplainer = LimeTabularExplainer(X_train_c.values, \n                                 mode='classification',\n                                 feature_names=X_train_c.columns,\n                                 class_names=['Diabetic', 'Not Diabetic'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Lime - ExtraTreeClassifer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"exp = explainer.explain_instance(X_test_c.values[0],\n                                 clf.predict_proba,\n                                 num_features=X_train_c.shape[1])\n\nexp.show_in_notebook(show_table = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ELI5 (Explain Like I'm 5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Global Model Interpretation"},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(clf, feature_names=list(X_train_c.columns), top=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Local Model Interpretation"},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_prediction(clf, X_test_c.values[0], feature_names=list(X_train_c.columns), top=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Permutation Inportance from Testing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"exp = PermutationImportance(clf, random_state=0).fit(X_test_c, y_test_c)\n\neli5.show_weights(exp, feature_names=list(X_train_c.columns), top=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SHAP (SHapley Additive exPlanations)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nfrom shap import TreeExplainer, KernelExplainer, LinearExplainer\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Local Model Interpretation"},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = TreeExplainer(clf, X_train_c, feature_dependence='imdependent')\nshap_values = explainer.shap_values(X_test_c.values)\nshap.force_plot(explainer.expected_value[1],\n                shap_values[1],\n                X_test_c.values,\n                feature_names=X_train_c.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Global Model Interpretation"},{"metadata":{"trusted":true},"cell_type":"code","source":"ssplot = shap.summary_plot(shap_values, X_test_c.values, feature_names=X_train_c.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Partial Dependency Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check plot for 'Glucose'\n\n#shap.dependence_plot('Glucose', shap_values, X_test_c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***`'Glucose','BMI','Age','DiabetesPedigreeFunction' columns have most effect on the data.`***"},{"metadata":{"id":"080YFUc-W5bw","colab_type":"text"},"cell_type":"markdown","source":"#### Model evaluation on Feature Selection"},{"metadata":{"id":"OzFpzk8x_wNe","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"df_feature_imp = df_clean[['Glucose','BMI','Age','DiabetesPedigreeFunction','Outcome']]\ndf_feature_imp_name = df_feature_imp.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"VZ8o1Imq_wK7","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"X =  df_feature_imp[df_feature_imp_name[0:df_feature_imp.shape[1]-1]]\nY = df_feature_imp[df_feature_imp_name[df_feature_imp.shape[1]-1]]\n\nX_train_im, X_test_im, y_train_im, y_test_im =train_test_split(X, Y, test_size=0.1, random_state=0,\n                                                   stratify=df_feature_imp['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"id":"rpszWuF7__SG","colab_type":"code","outputId":"beb9e7cf-f012-4a93-a4ad-3e565b677ea9","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f05533631b754ca3a0701c24d2682c44","0f6bd65ca0034372936fa9a5d13e183d","829bf274891f4bef8b9636c889c7e3d0","7ef52968f10345ec8bc15994da6bfdd4","d5fdd0a408d846aca71b783c3b7b8321","cd6fafb6d52c42118aa52536e2c1b10a","69ee3d040b364961876e528902892c70","7943c6188ea74e35a42fd700e58a520e"]},"trusted":true},"cell_type":"code","source":"models = getScaledModel('minmax')\nresults = baselineModelsEval(X_train_im, y_train_im,models)\nplotScores(results)\nscaledScoreMinMax_im = scoreDataFrame(results)\ncompareModels = pd.concat([baselineScore,\n                           scaledScoreStandard,\n                           scaledScoreMinMax,\n                           scaledScoreMinMax_c,\n                           scaledScoreMinMax_im], axis=1)\ncompareModels","execution_count":null,"outputs":[]},{"metadata":{"id":"nDWhDJAXALxG","colab_type":"text"},"cell_type":"markdown","source":"## Parameter Tuning"},{"metadata":{"id":"5-R6MlT1A-SS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom scipy.stats import uniform, randint","execution_count":null,"outputs":[]},{"metadata":{"id":"SHkFf65PArPK","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"df_imp_scaled = MinMaxScaler().fit_transform(df_clean[['Glucose','BMI','Age','DiabetesPedigreeFunction','Outcome']])\ndf_imp_scaled_name = df_clean.columns\n\nX =  df_imp_scaled[:,0:4]\nY =  df_imp_scaled[:,4]\nX_train_sc, X_test_sc, y_train_sc, y_test_sc =train_test_split(X, Y, test_size=0.1, random_state=0,\n                                                   stratify=df_imp_scaled[:,4])","execution_count":null,"outputs":[]},{"metadata":{"id":"Cpg95ANTL54S","colab_type":"text"},"cell_type":"markdown","source":"### Grid Seach/ Random Search"},{"metadata":{"id":"hFLKfArFBQcV","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class RandomSearch(object):\n    \n    def __init__(self,X_train,y_train,model,hyperparameters):\n        \n        self.X_train = X_train\n        self.y_train = y_train\n        self.model = model\n        self.hyperparameters = hyperparameters\n        \n    def RandomSearch(self):\n        # Create randomized search 10-fold cross validation and 100 iterations\n        cv = 10\n        clf = RandomizedSearchCV(self.model,\n                                 self.hyperparameters,\n                                 random_state=1,\n                                 n_iter=100,\n                                 cv=cv,\n                                 iid = True,\n                                 verbose=0,\n                                 n_jobs=-1,\n                                 )\n        # Fit randomized search\n        best_model = clf.fit(self.X_train, self.y_train)\n        message = (best_model.best_score_, best_model.best_params_)\n        print(\"Best: %f using %s\" % (message))\n\n        return best_model,best_model.best_params_\n    \n    def BestModelPridict(self,X_test):\n        \n        best_model,_ = self.RandomSearch()\n        pred = best_model.predict(X_test)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"id":"fAt_IXaQBZWH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"class GridSearch(object):\n    \n    def __init__(self,X_train,y_train,model,hyperparameters):\n        \n        self.X_train = X_train\n        self.y_train = y_train\n        self.model = model\n        self.hyperparameters = hyperparameters\n        \n    def GridSearch(self):\n        # Create randomized search 10-fold cross validation and 100 iterations\n        cv = 10\n        clf = GridSearchCV(self.model,\n                                 self.hyperparameters,\n                                 cv=cv,\n                                 verbose=0,\n                                 n_jobs=-1,\n                                 )\n        # Fit randomized search\n        best_model = clf.fit(self.X_train, self.y_train)\n        message = (best_model.best_score_, best_model.best_params_)\n        print(\"Best: %f using %s\" % (message))\n\n        return best_model,best_model.best_params_\n    \n    def BestModelPridict(self,X_test):\n        \n        best_model,_ = self.GridSearch()\n        pred = best_model.predict(X_test)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"id":"FBf5qxfaErKQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"models = {LogisticRegression(): dict(C=uniform(loc=0, scale=4), penalty = ['l1', 'l2']),\n          KNeighborsClassifier(): dict(n_neighbors=[i for i in range(1, 21)]),\n          SVC(): dict(C=[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0], kernel=['linear', 'poly', 'rbf', 'sigmoid']),\n          DecisionTreeClassifier(): dict(max_depth=[3,None], max_features=randint(1, 4), min_samples_leaf=randint(1, 4), criterion=[\"gini\", \"entropy\"]),\n          AdaBoostClassifier(): dict(learning_rate=[.01,.05,.1,.5,1], n_estimators=[50,100,150,200,250,300]),\n          GradientBoostingClassifier(): dict(learning_rate=[.01,.05,.1,.5,1], n_estimators=[50,100,150,200,250,300]),\n          RandomForestClassifier(): dict(n_estimators=[50,100,150,200,250,300], max_depth=[5,8,15,25,30], min_samples_split=[2,5,10,15,100], min_samples_leaf = [1,2,5,10]),\n          ExtraTreesClassifier(): dict(n_estimators=[50,100,150,200,250,300], min_samples_split=[2,5,10,15,100], min_samples_leaf = [1,2,5,10])}","execution_count":null,"outputs":[]},{"metadata":{"id":"r3TM-4XqJnwE","colab_type":"code","outputId":"ede7bfd4-3264-4b85-bff4-51ecb7c8d086","colab":{"base_uri":"https://localhost:8080/","height":593,"referenced_widgets":["b5deb82ef1c2421093f9443572ccddb1","3382de8078344b5ea7958ac6a0757998","7aa58ccf49874656823fc509ff262d01","0040ad3bcf6941dab29ead8d0b2f84a9","fb0962973a9645bab1ef9c5b56e2f8c4","200d7106b9004037bbb1ee0463f911e3","bdb182a347be4946b3a8752782a1c94a","c5c4f66e6c624823bfcebd3a7bd20ec9"]},"trusted":true},"cell_type":"code","source":"for model, hyperparameters in tqdm_notebook(models.items()):\n    print(\"\\u0332\".join(type(model).__name__))\n    _ = RandomSearch(X_train_sc, y_train_sc, model, hyperparameters)\n    _ = _.BestModelPridict(X_test_sc)\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"id":"2NcQCbj9MJg5","colab_type":"text"},"cell_type":"markdown","source":"## Ensemble Methods"},{"metadata":{"id":"XfjULxc9Mf65","colab_type":"text"},"cell_type":"markdown","source":"### VotingClassifier"},{"metadata":{"id":"J5rfHYQOMMh5","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\n# best params from parameter tuning step\nparam = {'C': 0.7678243129497218, 'penalty': 'l1'}\nmodel1 = LogisticRegression(**param)\n\nparam = {'n_neighbors': 15}\nmodel2 = KNeighborsClassifier(**param)\n\nparam = {'kernel': 'linear', 'C': 1.7}\nmodel3 = SVC(**param)\n\nparam = {'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 3}\nmodel4 = DecisionTreeClassifier(**param)\n\nparam = {'learning_rate': 0.05, 'n_estimators': 150}\nmodel5 = AdaBoostClassifier(**param)\n\nparam = {'learning_rate': 0.01, 'n_estimators': 100}\nmodel6 = GradientBoostingClassifier(**param)\n\nmodel7 = GaussianNB()\n\nparam = {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_depth': 25}\nmodel8 = RandomForestClassifier(**param)\n\nparam = {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 10}\nmodel9 = ExtraTreesClassifier(**param)\n\n\n# create the sub models\nestimators = [('LR',model1), ('KNN',model2), ('SVC',model3),\n              ('DT',model4), ('ADa',model5), ('GB',model6),\n              ('NB',model7), ('RF',model8),  ('ET',model9)]","execution_count":null,"outputs":[]},{"metadata":{"id":"w0KPvzDlNDpJ","colab_type":"code","outputId":"1a2dfc7e-2d3d-4024-c852-a14a1e6e4d60","colab":{"base_uri":"https://localhost:8080/","height":51},"trusted":true},"cell_type":"code","source":"# create the ensemble model\nkfold = StratifiedKFold(n_splits=10, random_state=SEED)\n\nensemble = VotingClassifier(estimators)\nresults = cross_val_score(ensemble, X_train_sc,y_train_sc, cv=kfold)\nvc_result = results.mean()\nprint('Accuracy on train: ',vc_result)\n\nensemble_model = ensemble.fit(X_train_sc,y_train_sc)\npred = ensemble_model.predict(X_test_sc)\nprint('Accuracy on test:' , (y_test_sc == pred).mean())","execution_count":null,"outputs":[]},{"metadata":{"id":"9Sb1G1GUO-xL","colab_type":"text"},"cell_type":"markdown","source":"### Predict and Error Corrolation"},{"metadata":{"id":"p8awi6ETNSiL","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def get_models():\n    param = {'C': 0.7678243129497218, 'penalty': 'l1'}\n    model1 = LogisticRegression(**param)\n\n    param = {'n_neighbors': 15}\n    model2 = KNeighborsClassifier(**param)\n\n    param = {'kernel': 'linear', 'C': 1.7, 'probability':True}\n    model3 = SVC(**param)\n\n    param = {'criterion': 'gini', 'max_depth': 3, 'max_features': 2, 'min_samples_leaf': 3}\n    model4 = DecisionTreeClassifier(**param)\n\n    param = {'learning_rate': 0.05, 'n_estimators': 150}\n    model5 = AdaBoostClassifier(**param)\n\n    param = {'learning_rate': 0.01, 'n_estimators': 100}\n    model6 = GradientBoostingClassifier(**param)\n\n    model7 = GaussianNB()\n\n    param = {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_depth': 25}\n    model8 = RandomForestClassifier(**param)\n\n    param = {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 10}\n    model9 = ExtraTreesClassifier(**param)\n\n    models = {'LR':model1, 'KNN':model2, 'SVC':model3,\n              'DT':model4, 'ADa':model5, 'GB':model6,\n              'NB':model7, 'RF':model8,  'ET':model9\n              }\n\n    return models","execution_count":null,"outputs":[]},{"metadata":{"id":"JMYcVFx-O48C","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def train_predict(model_list,xtrain, xtest, ytrain, ytest):\n    \"\"\"Fit models in list on training set and return preds\"\"\"\n    P = np.zeros((ytest.shape[0], len(model_list)))\n    P = pd.DataFrame(P)\n\n    print(\"Fitting models.\")\n    cols = list()\n    for i, (name, m) in enumerate(tqdm_notebook(models.items())):\n        m.fit(xtrain, ytrain)\n        P.iloc[:, i] = m.predict_proba(xtest)[:, 1]\n        cols.append(name)\n\n    P.columns = cols\n    return P","execution_count":null,"outputs":[]},{"metadata":{"id":"RBs1U2CBPkL1","colab_type":"code","outputId":"b803a99f-84bc-42b2-c306-d46c1bcfac31","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["787ef630e5a642b4a743b26230709693","da5d31001ac24952a007321146bb74e6","040d4bb2905f45128d879c07ddd74463","2a12d79f326d4cdea282d867f776c1aa","60441f9b557041be84605050e100bf25","729eb7e686eb4bf9add522ab53153bff","c752085dd1824550a54f3b254096b94a","24c257e0932a4da88a89c78d659e58ee"]},"trusted":true},"cell_type":"code","source":"models = get_models()\nP = train_predict(models, X_train_sc, X_test_sc, y_train_sc, y_test_sc)","execution_count":null,"outputs":[]},{"metadata":{"id":"CMPAP4F0Qf-r","colab_type":"code","outputId":"ecc427c7-24ec-4934-f69a-3a210cea1d9e","colab":{"base_uri":"https://localhost:8080/","height":595},"trusted":true},"cell_type":"code","source":"correlation_matrix(P)","execution_count":null,"outputs":[]},{"metadata":{"id":"aw46tTSKRMjE","colab_type":"text"},"cell_type":"markdown","source":"error correlations on a class prediction basis things look a bit more promising:"},{"metadata":{"id":"Qp0M0h0mREMe","colab_type":"code","outputId":"3c70083f-5838-4e87-cf58-ca9a7a94575a","colab":{"base_uri":"https://localhost:8080/","height":595},"trusted":true},"cell_type":"code","source":"correlation_matrix(P.apply(lambda predic: 1*(predic >= 0.5) - y_test_sc))","execution_count":null,"outputs":[]},{"metadata":{"id":"U-wD37hjALxW","colab_type":"text"},"cell_type":"markdown","source":"### Stacking"},{"metadata":{"id":"vGJZUMvUTPc_","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"base_learners = get_models()\n\nmeta_learner = GradientBoostingClassifier(\n    n_estimators=1000,\n    loss=\"exponential\",\n    max_features=6,\n    max_depth=3,\n    subsample=0.5,\n    learning_rate=0.001, \n    random_state=SEED\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"9OEOg5ErSYR9","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from mlens.ensemble import SuperLearner\n\n# create the super learner\ndef get_super_learner():\n    ensemble = SuperLearner(scorer=accuracy_score, folds=10, random_state=SEED, verbose=True)\n    # add base models\n    ensemble.add(list(base_learners.values()), proba=True)\n    # add the meta model\n    ensemble.add_meta(meta_learner, proba=True)\n \n    return ensemble","execution_count":null,"outputs":[]},{"metadata":{"id":"g59H6Y_iTdQ4","colab_type":"code","outputId":"27cbe9a3-7b87-44d3-a58e-dfb3de9e05ea","colab":{"base_uri":"https://localhost:8080/","height":119},"trusted":true},"cell_type":"code","source":"ensemble = get_super_learner()\n\n# Train the ensemble\nensemble.fit(X_train_sc, y_train_sc)\n\n# Predict the test set\np_ensemble = ensemble.predict_proba(X_test_sc)","execution_count":null,"outputs":[]},{"metadata":{"id":"c6LYvxVjUGe-","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"pp = []\nfor p in p_ensemble[:, 1]:\n    if p>0.5:\n        pp.append(1.)\n    else:\n        pp.append(0.)","execution_count":null,"outputs":[]},{"metadata":{"id":"jGcD5nYWT2Gf","colab_type":"code","outputId":"9a9bd982-069a-41d4-f708-7bf974eab83a","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"SL_result = (y_test_sc == pp).mean()\nprint(\"Super Learner Accuracy score: %.8f\" % SL_result)","execution_count":null,"outputs":[]},{"metadata":{"id":"oiNUC3cnYq51","colab_type":"text"},"cell_type":"markdown","source":"## Save Models"},{"metadata":{"id":"FUxZZeduYslq","colab_type":"code","outputId":"d22bf834-a108-46cf-d86f-0c97746ea1d5","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":false},"cell_type":"code","source":"import joblib\n\n# Output a pickle file for the model\njoblib.dump(ensemble, 'super_learner.pkl') \n \n# Load the pickle file\nclf_load = joblib.load('super_learner.pkl')\n\n# Check that the loaded model is the same as the original\nclf_load.scorer(y_test_sc, pp) == ensemble.scorer(y_test_sc, pp)","execution_count":0,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = df_clean[:500]\ntest_df = df_clean[500:]\n\ny_test = test_df['Outcome']\ntest_df.drop(columns=['Outcome'], inplace=True)\n\nfeatures = test_df.columns\ncategoricals = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Base_Model(object):\n    \n    def __init__(self, train_df, test_df, target, features, categoricals=[], n_splits=10, verbose=True):\n        self.train_df = train_df\n        self.test_df = test_df\n        self.target = target\n        self.features = features\n        self.categoricals = categoricals\n        self.n_splits = n_splits\n        self.verbose = verbose\n        self.cv = self.get_cv()\n        self.params = self.get_params()\n        self.y_pred, self.score, self.model = self.fit()\n        \n    def train_model(self, train_set, val_set):\n        raise NotImplementedError\n        \n    def get_cv(self):\n        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        return cv.split(self.train_df, self.train_df[self.target])\n    \n    def get_params(self):\n        raise NotImplementedError\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        raise NotImplementedError\n        \n    def convert_x(self, x):\n        return x\n        \n    def fit(self):\n        oof_pred = np.zeros((len(train_df), ))\n        y_pred = np.zeros((len(test_df), ))\n        for fold, (train_idx, val_idx) in enumerate(self.cv):\n            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n            model = self.train_model(train_set, val_set)\n            conv_x_val = self.convert_x(x_val)\n            _ = np.where(model.predict(conv_x_val) > 0.5, 1, 0)\n            oof_pred[val_idx] = _.reshape(oof_pred[val_idx].shape)\n            x_test = self.convert_x(self.test_df[self.features])\n            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n            print('Partial score of fold {} is: {}'.format(fold, accuracy_score(y_val, oof_pred[val_idx])))\n        loss_score = accuracy_score(self.train_df[self.target], oof_pred)\n        if self.verbose:\n            print('Our oof Accuracy is: ', loss_score)\n        return y_pred, loss_score, model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nclass Lgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'n_estimators':10,\n                    'boosting_type': 'gbdt',\n                    'objective': 'binary',\n                    'metric': 'auc',\n                    }\n        return params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = Lgb_Model(train_df, test_df, 'Outcome', features, categoricals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\nclass Xgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 0 if self.verbose else 0\n        return xgb.train(self.params, train_set, \n                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n                         verbose_eval=verbosity, early_stopping_rounds=100)\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = xgb.DMatrix(x_train, y_train)\n        val_set = xgb.DMatrix(x_val, y_val)\n        return train_set, val_set\n    \n    def convert_x(self, x):\n        return xgb.DMatrix(x)\n        \n    def get_params(self):\n        params = {'colsample_bytree': 0.8,                 \n                    'learning_rate': 0.01,\n                    'max_depth': 10,\n                    'subsample': 1,\n                    'objective':'binary:hinge',\n                    'eval_metric':'auc',\n                    'min_child_weight':3,\n                    'gamma':0.25,\n                    'n_estimators':10}\n\n        return params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = Xgb_Model(train_df, test_df, 'Outcome', features, categoricals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\nclass Catb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 0 if self.verbose else 0\n        clf = CatBoostClassifier(**self.params)\n        clf.fit(train_set['X'], train_set['y'], \n                eval_set=(val_set['X'], val_set['y']),\n                verbose=verbosity, \n                cat_features=self.categoricals)\n        return clf\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = {'X': x_train, 'y': y_train}\n        val_set = {'X': x_val, 'y': y_val}\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'loss_function': 'Logloss',\n                   'task_type': \"CPU\",\n                   'iterations': 10,\n                   'od_type': \"Iter\",\n                    'depth': 10,\n                    'colsample_bylevel': 0.5, \n                    'early_stopping_rounds': 300,\n                    'random_seed': 42,\n                    'use_best_model': True\n                    }\n        return params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catb_model = Catb_Model(train_df, test_df, 'Outcome', features, categoricals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FeedForward Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nclass Nn_Model(Base_Model):\n    \n    def __init__(self, train_df, test_df, target, features, categoricals=[], n_splits=10, verbose=True):\n        super().__init__(train_df, test_df, target, features, categoricals, n_splits, verbose)\n        \n    def train_model(self, train_set, val_set):\n        verbosity = 0 if self.verbose else 0\n        model = tf.keras.models.Sequential([\n            tf.keras.layers.Input(shape=(train_set['X'].shape[1],)),\n            tf.keras.layers.Dense(200, activation='relu'),\n            tf.keras.layers.LayerNormalization(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Dense(100, activation='relu'),\n            tf.keras.layers.LayerNormalization(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Dense(50, activation='relu'),\n            tf.keras.layers.LayerNormalization(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Dense(25, activation='relu'),\n            tf.keras.layers.LayerNormalization(),\n            tf.keras.layers.Dropout(0.3),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss='binary_crossentropy', metrics=['accuracy'])\n        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=0)\n        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n        model.fit(train_set['X'], \n                train_set['y'], \n                validation_data=(val_set['X'], val_set['y']),\n                epochs=100,\n                verbose=0,\n                callbacks=[save_best, early_stop])\n        model.load_weights('nn_model.w8')\n        return model\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = {'X': x_train, 'y': y_train}\n        val_set = {'X': x_val, 'y': y_val}\n        return train_set, val_set\n        \n    def get_params(self):\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_model = Nn_Model(train_df, test_df, 'Outcome', features, categoricals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from random import choice\n\nclass Cnn_Model(Base_Model):\n    \n    def __init__(self, train_df, test_df, target, features, categoricals=[], n_splits=5, verbose=True):\n        self.create_feat_2d(features)\n        super().__init__(train_df, test_df, target, features, categoricals, n_splits, verbose)\n        \n    def create_feat_2d(self, features, n_feats_repeat=50):\n        self.n_feats = len(features)\n        self.n_feats_repeat = n_feats_repeat\n        self.mask = np.zeros((self.n_feats_repeat, self.n_feats), dtype=np.int32)\n        for i in range(self.n_feats_repeat):\n            l = list(range(self.n_feats))\n            for j in range(self.n_feats):\n                c = l.pop(choice(range(len(l))))\n                self.mask[i, j] = c\n        self.mask = tf.convert_to_tensor(self.mask)\n        print(self.mask.shape)\n       \n        \n    \n    def train_model(self, train_set, val_set):\n        verbosity = 0 if self.verbose else 0\n\n        inp = tf.keras.layers.Input(shape=(self.n_feats))\n        x = tf.keras.layers.Lambda(lambda x: tf.gather(x, self.mask, axis=1))(inp)\n        x = tf.keras.layers.Reshape((self.n_feats_repeat, self.n_feats, 1))(x)\n        x = tf.keras.layers.Conv2D(18, (50, 50), strides=50, activation='relu')(x)\n        x = tf.keras.layers.Flatten()(x)\n        x = tf.keras.layers.Dense(100, activation='relu')(x)\n        x = tf.keras.layers.LayerNormalization()(x)\n        x = tf.keras.layers.Dropout(0.3)(x)\n        x = tf.keras.layers.Dense(50, activation='relu')(x)\n        x = tf.keras.layers.LayerNormalization()(x)\n        x = tf.keras.layers.Dropout(0.3)(x)\n        out = tf.keras.layers.Dense(1)(x)\n        \n        model = tf.keras.Model(inp, out)\n    \n        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics='accuracy')\n        print(model.summary())\n        save_best = tf.keras.callbacks.ModelCheckpoint('cnn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n        model.fit(train_set['X'], \n                train_set['y'], \n                validation_data=(val_set['X'], val_set['y']),\n                epochs=100,\n                 callbacks=[save_best, early_stop])\n        model.load_weights('cnn_model.w8')\n        return model\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = {'X': x_train, 'y': y_train}\n        val_set = {'X': x_val, 'y': y_val}\n        return train_set, val_set\n        \n    def get_params(self):\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost Score: \", xgb_model.score)\nprint(\"LightGBM Score: \", lgb_model.score)\nprint(\"CatBoost Score: \", catb_model.score)\nprint(\"Neural Network Score: \", nn_model.score)\nprint(\"Voting Classifier Score: \", vc_result)\nprint(\"Super Learner Score: \", SL_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compareModels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#joblib.dump(xgb_model, 'xgb.pkl')\n#joblib.dump(lgb_model, 'lgb.pkl')\n#joblib.dump(catb_model, 'catb.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"execution_time(start)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Classification_Template.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b762f7460004a8db93f4597efac6d87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_572f0afb4acc479dae993d960984311d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c3799519cb564613884260c8263a0d67","IPY_MODEL_79f75538e3ed4137932ea7b3d27290bf"]}},"572f0afb4acc479dae993d960984311d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3799519cb564613884260c8263a0d67":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_79bffa38d1da41b08cb0f0297c2fc768","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88b3c1a8ae5a4968a8656d7568a5d012"}},"79f75538e3ed4137932ea7b3d27290bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_668dfca0d30f4c4e978d2411aadfb9a0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 10/10 [00:06&lt;00:00,  1.28s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_433ba352552b4bc8a83dec38351d2d6a"}},"79bffa38d1da41b08cb0f0297c2fc768":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88b3c1a8ae5a4968a8656d7568a5d012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"668dfca0d30f4c4e978d2411aadfb9a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"433ba352552b4bc8a83dec38351d2d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca68adb188ec42ff8c893710286508a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_52e4244570134cbea02fc7ecebec3290","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_55ea2c37f95842d589cdde9ce2f44135","IPY_MODEL_b85f9f8737f247428fac368a211d64a1"]}},"52e4244570134cbea02fc7ecebec3290":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55ea2c37f95842d589cdde9ce2f44135":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06a28f40cb084a168bea4747254b6bc0","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cce5ba4f7c854a49a8e674a9840efac1"}},"b85f9f8737f247428fac368a211d64a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f28b35a09599404b9933951a5b60e590","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 10/10 [00:06&lt;00:00,  1.23s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40389c5c7a714db0afe9399200513803"}},"06a28f40cb084a168bea4747254b6bc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cce5ba4f7c854a49a8e674a9840efac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f28b35a09599404b9933951a5b60e590":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"40389c5c7a714db0afe9399200513803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef3162633f1e4be69b632a3bbe76ec33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0195afb9b17c4a1da6dbf20d1b44866c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85ff6a86015c4295a694e8c3377049f1","IPY_MODEL_8ffb06f8123c4111b35051fb9131c47a"]}},"0195afb9b17c4a1da6dbf20d1b44866c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85ff6a86015c4295a694e8c3377049f1":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_21021de7e2d74284ad785d3e4e8bffb9","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b31dc45213324769ba9d8c38511a1d26"}},"8ffb06f8123c4111b35051fb9131c47a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fcbdcb1692e24b60a70b3993e04c66d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 10/10 [00:06&lt;00:00,  1.28s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aaa1030f57944df7a3b6c533ff510d33"}},"21021de7e2d74284ad785d3e4e8bffb9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b31dc45213324769ba9d8c38511a1d26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fcbdcb1692e24b60a70b3993e04c66d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aaa1030f57944df7a3b6c533ff510d33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cfc016d20894f919628bf7f324b5690":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a5195656974c4bb7b613565d9e44a978","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e27c1cab733742b2aa225141e386c2ab","IPY_MODEL_bc87c1dd52004c9ebfca82df26e9dc71"]}},"a5195656974c4bb7b613565d9e44a978":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e27c1cab733742b2aa225141e386c2ab":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8890b70b7b7b486fad27dc75f259f8f9","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a80cc4a69631445792e7647440462ea2"}},"bc87c1dd52004c9ebfca82df26e9dc71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be6036ff8b5047e89906e242040c2c0b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 10/10 [00:06&lt;00:00,  1.15s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7200c2d8b8e24c6ca31b395e6294210a"}},"8890b70b7b7b486fad27dc75f259f8f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a80cc4a69631445792e7647440462ea2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be6036ff8b5047e89906e242040c2c0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7200c2d8b8e24c6ca31b395e6294210a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f05533631b754ca3a0701c24d2682c44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0f6bd65ca0034372936fa9a5d13e183d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_829bf274891f4bef8b9636c889c7e3d0","IPY_MODEL_7ef52968f10345ec8bc15994da6bfdd4"]}},"0f6bd65ca0034372936fa9a5d13e183d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"829bf274891f4bef8b9636c889c7e3d0":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d5fdd0a408d846aca71b783c3b7b8321","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd6fafb6d52c42118aa52536e2c1b10a"}},"7ef52968f10345ec8bc15994da6bfdd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69ee3d040b364961876e528902892c70","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 10/10 [00:06&lt;00:00,  1.16s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7943c6188ea74e35a42fd700e58a520e"}},"d5fdd0a408d846aca71b783c3b7b8321":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cd6fafb6d52c42118aa52536e2c1b10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69ee3d040b364961876e528902892c70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7943c6188ea74e35a42fd700e58a520e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5deb82ef1c2421093f9443572ccddb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3382de8078344b5ea7958ac6a0757998","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7aa58ccf49874656823fc509ff262d01","IPY_MODEL_0040ad3bcf6941dab29ead8d0b2f84a9"]}},"3382de8078344b5ea7958ac6a0757998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7aa58ccf49874656823fc509ff262d01":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fb0962973a9645bab1ef9c5b56e2f8c4","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":8,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":8,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_200d7106b9004037bbb1ee0463f911e3"}},"0040ad3bcf6941dab29ead8d0b2f84a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bdb182a347be4946b3a8752782a1c94a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 8/8 [09:57&lt;00:00, 129.02s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c5c4f66e6c624823bfcebd3a7bd20ec9"}},"fb0962973a9645bab1ef9c5b56e2f8c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"200d7106b9004037bbb1ee0463f911e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdb182a347be4946b3a8752782a1c94a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c5c4f66e6c624823bfcebd3a7bd20ec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"787ef630e5a642b4a743b26230709693":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_da5d31001ac24952a007321146bb74e6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_040d4bb2905f45128d879c07ddd74463","IPY_MODEL_2a12d79f326d4cdea282d867f776c1aa"]}},"da5d31001ac24952a007321146bb74e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"040d4bb2905f45128d879c07ddd74463":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_60441f9b557041be84605050e100bf25","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":9,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_729eb7e686eb4bf9add522ab53153bff"}},"2a12d79f326d4cdea282d867f776c1aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c752085dd1824550a54f3b254096b94a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 9/9 [00:01&lt;00:00,  5.60it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24c257e0932a4da88a89c78d659e58ee"}},"60441f9b557041be84605050e100bf25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"729eb7e686eb4bf9add522ab53153bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c752085dd1824550a54f3b254096b94a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24c257e0932a4da88a89c78d659e58ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":1}