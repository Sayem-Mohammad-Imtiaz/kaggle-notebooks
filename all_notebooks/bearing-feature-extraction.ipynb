{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport plotly.express as px # library for plotting\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-13T12:17:07.645019Z","iopub.execute_input":"2021-07-13T12:17:07.645597Z","iopub.status.idle":"2021-07-13T12:17:09.189532Z","shell.execute_reply.started":"2021-07-13T12:17:07.645485Z","shell.execute_reply":"2021-07-13T12:17:09.188575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset for processing","metadata":{}},{"cell_type":"code","source":"signals = pd.read_csv('/kaggle/input/bearing-classification/bearing_signals.csv', low_memory=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:10.774023Z","iopub.execute_input":"2021-07-13T12:17:10.77445Z","iopub.status.idle":"2021-07-13T12:17:55.460468Z","shell.execute_reply.started":"2021-07-13T12:17:10.774413Z","shell.execute_reply":"2021-07-13T12:17:55.45935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/bearing-classification/bearing_classes.csv',sep=\";\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:55.462435Z","iopub.execute_input":"2021-07-13T12:17:55.462847Z","iopub.status.idle":"2021-07-13T12:17:55.477322Z","shell.execute_reply.started":"2021-07-13T12:17:55.462802Z","shell.execute_reply":"2021-07-13T12:17:55.476146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is the example how to get the experiment by id","metadata":{}},{"cell_type":"code","source":"id_experiment = 95\nexperiment = signals[signals['experiment_id']==id_experiment]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:58:12.924817Z","iopub.execute_input":"2021-07-13T08:58:12.925304Z","iopub.status.idle":"2021-07-13T08:58:12.990343Z","shell.execute_reply.started":"2021-07-13T08:58:12.925252Z","shell.execute_reply":"2021-07-13T08:58:12.98943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get main information about experiment","metadata":{}},{"cell_type":"code","source":"experiment.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:03:28.273268Z","iopub.execute_input":"2021-07-06T11:03:28.273736Z","iopub.status.idle":"2021-07-06T11:03:28.296312Z","shell.execute_reply.started":"2021-07-06T11:03:28.273703Z","shell.execute_reply":"2021-07-06T11:03:28.295494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiment.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:03:31.200791Z","iopub.execute_input":"2021-07-06T11:03:31.201147Z","iopub.status.idle":"2021-07-06T11:03:31.296757Z","shell.execute_reply.started":"2021-07-06T11:03:31.201103Z","shell.execute_reply":"2021-07-06T11:03:31.29589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some visualisation of experiment","metadata":{}},{"cell_type":"code","source":"fig = px.line(experiment, x=\"timestamp\", y=[\"a2_y\",\"a1_y\"], title='The vibration both accelerometers by axis y')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-01T10:31:50.289786Z","iopub.execute_input":"2021-07-01T10:31:50.290157Z","iopub.status.idle":"2021-07-01T10:31:53.213947Z","shell.execute_reply.started":"2021-07-01T10:31:50.290128Z","shell.execute_reply":"2021-07-01T10:31:53.212767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(experiment, x=\"timestamp\", y=[\"a2_z\",\"a1_z\"], title='The vibration both accelerometers by axis z')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(experiment, x=\"timestamp\", y=[\"hz\"], title='The speed motor ')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get part of experiment where the speed motor was more stable","metadata":{}},{"cell_type":"code","source":"# get steady speed \nsteady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 27)\nexperiment_steady_speed = experiment[steady_filter]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:58:12.991774Z","iopub.execute_input":"2021-07-13T08:58:12.99227Z","iopub.status.idle":"2021-07-13T08:58:13.007853Z","shell.execute_reply.started":"2021-07-13T08:58:12.992216Z","shell.execute_reply":"2021-07-13T08:58:13.006313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(experiment_steady_speed, x=\"timestamp\", y=[\"hz\"], title='The speed motor ')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:03:37.5483Z","iopub.execute_input":"2021-07-06T11:03:37.548635Z","iopub.status.idle":"2021-07-06T11:03:38.840014Z","shell.execute_reply.started":"2021-07-06T11:03:37.548602Z","shell.execute_reply":"2021-07-06T11:03:38.838899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiment_steady_speed['a2_y'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T11:03:46.771215Z","iopub.execute_input":"2021-07-06T11:03:46.771661Z","iopub.status.idle":"2021-07-06T11:03:46.782642Z","shell.execute_reply.started":"2021-07-06T11:03:46.771632Z","shell.execute_reply":"2021-07-06T11:03:46.78171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_signal_a1_y = experiment_steady_speed['a1_y']\nraw_signal_a2_y = experiment_steady_speed['a2_y']","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:58:13.010164Z","iopub.execute_input":"2021-07-13T08:58:13.01106Z","iopub.status.idle":"2021-07-13T08:58:13.016366Z","shell.execute_reply.started":"2021-07-13T08:58:13.01099Z","shell.execute_reply":"2021-07-13T08:58:13.015149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some additional functions for working with data","metadata":{}},{"cell_type":"code","source":"def get_current_rate(df, step):\n    time_step = df['timestamp'].iloc[step+1] - df['timestamp'].iloc[step]\n    sample_rate = 1.0 / time_step\n    cur_freq = df['hz'].iloc[step]\n    return cur_freq, sample_rate\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:55.479976Z","iopub.execute_input":"2021-07-13T12:17:55.480446Z","iopub.status.idle":"2021-07-13T12:17:55.485877Z","shell.execute_reply.started":"2021-07-13T12:17:55.480403Z","shell.execute_reply":"2021-07-13T12:17:55.485021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.fft import fft, fftfreq\n\ndef get_fft(df,fs):\n    N=len(df)\n    fs = fs\n    x_plot= fftfreq(N, 1/fs)[:N//2]\n    \n    df_fft = pd.DataFrame()\n    df_phase = pd.DataFrame()\n    for name in df.columns:\n        yf = fft(df[name].values) \n        y_plot= 2.0/N * np.abs(yf[0:N//2])\n        df_fft = pd.concat([df_fft,\n                            pd.DataFrame({'Frequency (Hz)':x_plot[1:],\n                                          name:y_plot[1:]}).set_index('Frequency (Hz)')],axis=1)\n    \n    return df_fft","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:55.487869Z","iopub.execute_input":"2021-07-13T12:17:55.488259Z","iopub.status.idle":"2021-07-13T12:17:55.500465Z","shell.execute_reply.started":"2021-07-13T12:17:55.488224Z","shell.execute_reply":"2021-07-13T12:17:55.499691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.signal as signal\n\ndef get_psd(df,bin_width,fs):\n    fs = fs   \n    f, psd = signal.welch(df.to_numpy(), \n                          fs=fs, \n                          nperseg=fs/bin_width,\n                          window='hanning',\n                          axis=0\n                         )\n\n    df_psd = pd.DataFrame(psd,columns=df.columns)\n    df_psd.columns\n    df_psd['Frequency (Hz)'] = f\n    df_psd = df_psd.set_index('Frequency (Hz)')\n    return df_psd[1:] #drop the first value because it makes the plots look bad and is effectively 0","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:55.501759Z","iopub.execute_input":"2021-07-13T12:17:55.502211Z","iopub.status.idle":"2021-07-13T12:17:56.350439Z","shell.execute_reply.started":"2021-07-13T12:17:55.502176Z","shell.execute_reply":"2021-07-13T12:17:56.349246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# There are the functions for feature extraction from vibration data","metadata":{}},{"cell_type":"markdown","source":"Peak acceleration may be easy, but it is often very misleading. \nAnd you can see in the table above that although there is some correlation between \nthe significance of the fault and the peak acceleration, it isn't a perfect correlation. \nPeak acceleration values can be too dependent on a bit of chance with how the sampling lines up with the data. \nMeaning when you are comparing multiple signals to each other, any difference in sample rate or low-pass filters \nwill make the comparison between the peak accelerations inappropriate and even more misleading than normal.","metadata":{}},{"cell_type":"code","source":"def get_peak_acceleration(signal):\n    return pd.DataFrame.max(signal.abs())","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.351795Z","iopub.execute_input":"2021-07-13T12:17:56.3521Z","iopub.status.idle":"2021-07-13T12:17:56.35661Z","shell.execute_reply.started":"2021-07-13T12:17:56.352045Z","shell.execute_reply":"2021-07-13T12:17:56.355405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RMS is by far my preference over peak because it is independent of the sample rate \nand it will more accurately let you compare the vibration levels of two signals. \nThe RMS value increase gradually as fault developed. However, RMS is unable to provide \nthe information of incipient fault stage while it increases with the fault development.\n","metadata":{}},{"cell_type":"code","source":"def get_rms_acceleration(signal):\n    N = len(signal)\n    return np.sqrt(1/N * (signal**2).sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.35827Z","iopub.execute_input":"2021-07-13T12:17:56.358681Z","iopub.status.idle":"2021-07-13T12:17:56.371812Z","shell.execute_reply.started":"2021-07-13T12:17:56.358636Z","shell.execute_reply":"2021-07-13T12:17:56.370695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Crest factor (CF) calculates how much impact occur during the rolling element and raceway contact. \nCF is appropriate for “spiky signals”. Crest factor is simply the ratio of the peak acceleration \nto the RMS acceleration, so it is unitless which is always nice. It defines how \"peaky\" a signal is. \nA square wave could have a crest factor of 1 whereas a signal with occasional shock events may have \na very high crest factor. As crest factor increases, it tends to be an indicator of bearing failure.\n","metadata":{}},{"cell_type":"code","source":"def get_crest_factor(signal):\n    return get_peak_acceleration(signal)/get_rms_acceleration(signal)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.374828Z","iopub.execute_input":"2021-07-13T12:17:56.375509Z","iopub.status.idle":"2021-07-13T12:17:56.387489Z","shell.execute_reply.started":"2021-07-13T12:17:56.375466Z","shell.execute_reply":"2021-07-13T12:17:56.385949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Standard deviation is a statistical metric defining the amount of variation in the signal\n","metadata":{}},{"cell_type":"code","source":"def get_std(signal):\n    return signal.std()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.389637Z","iopub.execute_input":"2021-07-13T12:17:56.389999Z","iopub.status.idle":"2021-07-13T12:17:56.399486Z","shell.execute_reply.started":"2021-07-13T12:17:56.389965Z","shell.execute_reply":"2021-07-13T12:17:56.398031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variance measures the dispersion of a signal around their reference mean value.","metadata":{}},{"cell_type":"code","source":"def get_variance(signal):\n    return signal.var()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.401008Z","iopub.execute_input":"2021-07-13T12:17:56.401484Z","iopub.status.idle":"2021-07-13T12:17:56.41382Z","shell.execute_reply.started":"2021-07-13T12:17:56.40145Z","shell.execute_reply":"2021-07-13T12:17:56.412776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Skewness quantifies the asymmetry behavior of vibration signal through its probability density function (PDF).","metadata":{}},{"cell_type":"code","source":"def get_skewness(signal):\n    return signal.skew()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.414993Z","iopub.execute_input":"2021-07-13T12:17:56.41552Z","iopub.status.idle":"2021-07-13T12:17:56.427739Z","shell.execute_reply.started":"2021-07-13T12:17:56.415409Z","shell.execute_reply":"2021-07-13T12:17:56.426139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kurtosis quantifies the peak value of the PDF. \nThe kurtosis value for normal rolling element bearing is well-recognized as 3.","metadata":{}},{"cell_type":"code","source":"def get_kurtosis(signal):\n    return signal.kurtosis()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.429413Z","iopub.execute_input":"2021-07-13T12:17:56.429735Z","iopub.status.idle":"2021-07-13T12:17:56.441318Z","shell.execute_reply.started":"2021-07-13T12:17:56.429706Z","shell.execute_reply":"2021-07-13T12:17:56.439633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Shape factor is a value that is affected by an object’s shape but is independent of its dimensions.","metadata":{}},{"cell_type":"code","source":"def get_shape_factor(signal):\n    N = len(signal)\n    return np.sqrt(((signal**2).sum()/N) / ((signal.abs()).sum()/N))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.442708Z","iopub.execute_input":"2021-07-13T12:17:56.44325Z","iopub.status.idle":"2021-07-13T12:17:56.455837Z","shell.execute_reply.started":"2021-07-13T12:17:56.443213Z","shell.execute_reply":"2021-07-13T12:17:56.454373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Entropy is a calculation of the uncertainty and randomness of a sampled vibration data.","metadata":{}},{"cell_type":"code","source":"from math import log, e\n\ndef get_entropy(signal, base=None):\n  vc = signal.value_counts(normalize=True, sort=False)\n  base = e if base is None else base\n  return -(vc * np.log(vc)/np.log(base)).sum()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.457654Z","iopub.execute_input":"2021-07-13T12:17:56.458125Z","iopub.status.idle":"2021-07-13T12:17:56.468736Z","shell.execute_reply.started":"2021-07-13T12:17:56.45809Z","shell.execute_reply":"2021-07-13T12:17:56.46737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Impulse Factor is used to measure how much impact is generated from the bearing defect.\nIF divides the maximum absolute value by the mean of absolute value.","metadata":{}},{"cell_type":"code","source":"def get_impulse_factor(signal):\n    return signal.abs().max() / (signal.abs().sum() / len(signal))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.470134Z","iopub.execute_input":"2021-07-13T12:17:56.470592Z","iopub.status.idle":"2021-07-13T12:17:56.483643Z","shell.execute_reply.started":"2021-07-13T12:17:56.470559Z","shell.execute_reply":"2021-07-13T12:17:56.482474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Margin factor (MF) measures the level of impact between rolling element and raceway. The MF is\ncalculated by dividing the maximum absolute value of vibration signal to the RMS of absolute value\nof vibration signal","metadata":{}},{"cell_type":"code","source":"def get_margin_factor(signal):\n    signal = signal.to_numpy()\n    return np.max(np.abs(signal)) / ((np.sum(np.sqrt(np.abs(signal)))/ len(signal))**2)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.485298Z","iopub.execute_input":"2021-07-13T12:17:56.485665Z","iopub.status.idle":"2021-07-13T12:17:56.495959Z","shell.execute_reply.started":"2021-07-13T12:17:56.485629Z","shell.execute_reply":"2021-07-13T12:17:56.49508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hjorts’ parameters are calculated based on the first and the second derivatives of the vibration signal. \nIn the time series context, the numerical values for the derivatives are obtained as the differences \nbetween the current value and the prior value. There are three parameters: activity, mobility, complexity. \nThese parameters have been used in electroencephalography (EEG) signals to detect the epileptic seizures. \nThey have never been used in vibration bearing signal except for activity feature, which is similar to the \nvariance feature in the statistical time-domain features extraction.","metadata":{}},{"cell_type":"code","source":"def get_hjorts_parameters(signal):\n    first_diff = signal.diff()\n    first_diff_std = first_diff.std()\n    second_diff = signal.diff().diff()\n    std = signal.std()\n    \n    activity_hjorts_parameters = std**2\n    mobility_hjorts_parameters = first_diff.std()/std\n    complexity_hjorts_parameters = (second_diff.std()/first_diff_std )/ (first_diff_std / std)\n    return [activity_hjorts_parameters, mobility_hjorts_parameters, complexity_hjorts_parameters]\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.497133Z","iopub.execute_input":"2021-07-13T12:17:56.497546Z","iopub.status.idle":"2021-07-13T12:17:56.511711Z","shell.execute_reply.started":"2021-07-13T12:17:56.497513Z","shell.execute_reply":"2021-07-13T12:17:56.510392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Other frequency-domain features such as frequency centre (FC), root mean square frequency (RMSF) \nand root variance frequency (RVF) are using in vibration feature extraction. When fault exists, the frequency \nelement changes, and the values of the FC, RMSF and RVF also change. The FC and RMSF indicate \nthe position changes of main frequencies, while the RVF shows the convergence of the power spectrum.","metadata":{}},{"cell_type":"code","source":"def get_frequency_centre(signal):\n    return ((signal.diff()*signal).sum()) / (2 * np.pi * np.sum(signal**2))\ndef get_mean_square_frequency(signal):\n    return  np.sum(signal.diff()**2) / (4 * np.pi**2 * np.sum(signal**2))\ndef get_root_mean_square_frequency(signal):\n    return  np.sqrt(get_mean_square_frequency(signal))\ndef get_root_variance_frequency(signal):\n    return  np.sqrt(get_mean_square_frequency(signal) - get_frequency_centre(signal)**2)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.513357Z","iopub.execute_input":"2021-07-13T12:17:56.51367Z","iopub.status.idle":"2021-07-13T12:17:56.529475Z","shell.execute_reply.started":"2021-07-13T12:17:56.513641Z","shell.execute_reply":"2021-07-13T12:17:56.528262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\n \nfrom scipy.stats import entropy\n  \ndef get_shannon_entropy(signal):\n    bases = collections.Counter([tmp_base for tmp_base in signal])\n    # define distribution\n    dist = [x/sum(bases.values()) for x in bases.values()]\n \n    # use scipy to calculate entropy\n    entropy_value = entropy(dist, base=2)\n \n    return entropy_value\n\n# print(get_shannon_entropy(raw_signal_a2_y))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.531417Z","iopub.execute_input":"2021-07-13T12:17:56.531862Z","iopub.status.idle":"2021-07-13T12:17:56.542076Z","shell.execute_reply.started":"2021-07-13T12:17:56.531815Z","shell.execute_reply":"2021-07-13T12:17:56.540773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_features_function = [get_peak_acceleration, get_rms_acceleration, get_crest_factor,get_std, get_variance,\n                          get_skewness, get_kurtosis, get_shape_factor, get_entropy, get_impulse_factor, get_margin_factor,\n                          get_hjorts_parameters, get_frequency_centre, get_mean_square_frequency, get_root_mean_square_frequency,\n                          get_root_variance_frequency]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:17:56.797959Z","iopub.execute_input":"2021-07-13T12:17:56.79849Z","iopub.status.idle":"2021-07-13T12:17:56.802925Z","shell.execute_reply.started":"2021-07-13T12:17:56.798457Z","shell.execute_reply":"2021-07-13T12:17:56.802095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's process all experiments and get features for each of them using the functions above","metadata":{}},{"cell_type":"code","source":"experiments = signals['experiment_id'].unique()\ndata_stationary_feaures = []\nfor exp in experiments:\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 27)\n    experiment_steady = experiment[steady_filter]\n    feature_a1_y = []\n    feature_a2_y = []\n    for func in list_features_function:\n        a1 = func(experiment_steady['a1_y'])\n        a2 = func(experiment_steady['a2_y'])\n        if type(a1) == list:\n            feature_a1_y+=a1\n            feature_a2_y+=a2\n            \n        else:\n            feature_a1_y.append(a1)\n            feature_a2_y.append(a2)\n    data_stationary_feaures.append((feature_a1_y,feature_a2_y))\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:22:43.707361Z","iopub.execute_input":"2021-07-13T08:22:43.707908Z","iopub.status.idle":"2021-07-13T08:22:51.201227Z","shell.execute_reply.started":"2021-07-13T08:22:43.707873Z","shell.execute_reply":"2021-07-13T08:22:51.199997Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_stationary_feaures = np.array(data_stationary_feaures,ndmin=3)\ndf_first = pd.DataFrame(data_stationary_feaures[:,0,:]) # df_first is dataframe of the features first bearing in each experiment\ndf_second = pd.DataFrame(data_stationary_feaures[:,1,:])# df_second is dataframe of the features second bearing in each experiment","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:22:51.203186Z","iopub.execute_input":"2021-07-13T08:22:51.203632Z","iopub.status.idle":"2021-07-13T08:22:51.212209Z","shell.execute_reply.started":"2021-07-13T08:22:51.203585Z","shell.execute_reply":"2021-07-13T08:22:51.21098Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig =px.bar(df_first)\nfig.update_yaxes(range=[0,150])\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:22:51.216198Z","iopub.execute_input":"2021-07-13T08:22:51.216656Z","iopub.status.idle":"2021-07-13T08:22:52.475154Z","shell.execute_reply.started":"2021-07-13T08:22:51.216611Z","shell.execute_reply":"2021-07-13T08:22:52.474409Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig =px.bar(df_second)\nfig.update_yaxes(range=[0,150])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:22:52.476355Z","iopub.execute_input":"2021-07-13T08:22:52.476775Z","iopub.status.idle":"2021-07-13T08:22:52.633211Z","shell.execute_reply.started":"2021-07-13T08:22:52.476743Z","shell.execute_reply":"2021-07-13T08:22:52.632468Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obviously, there are differences in bearing features.","metadata":{}},{"cell_type":"markdown","source":"# Let's use dimensionality reduction techniques to visualize the resulting features on a plane.","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans, Birch, DBSCAN,MeanShift, OPTICS, SpectralBiclustering\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.manifold import Isomap\nfrom sklearn.preprocessing import StandardScaler\n\n# scaler = StandardScaler()\n# df_second = scaler.fit_transform(df_second)\nX_train = X_chunks.copy() # check only the second bearing\nN_classes = 3\n\nkmeans = KMeans(N_classes).fit(X_train)\nbirch = Birch(N_classes).fit(X_train)\ndbscan = DBSCAN(eps=3, min_samples=10).fit(X_train)\nmean_shift = MeanShift(bandwidth=5).fit(X_train)\noptics = OPTICS(min_samples=10).fit(X_train)\n\nclusters_algorithms = [kmeans, birch, dbscan, mean_shift, optics]\ndecomposition_algorithms = [TruncatedSVD, TSNE, PCA, Isomap]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:27:35.413827Z","iopub.execute_input":"2021-07-13T12:27:35.414251Z","iopub.status.idle":"2021-07-13T12:29:43.413063Z","shell.execute_reply.started":"2021-07-13T12:27:35.414213Z","shell.execute_reply":"2021-07-13T12:29:43.411571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef SetColor(x):\n    colors = [\"red\",\"blue\",\"green\",\"magenta\",\"yellow\",\"orange\", \n              \"pink\", \"cyan\", \"black\",\"#eee32ff\", \"#1eebff\", \"#fe2212\",\"#eee3211\", \"#1efbff\", \n              \"#fe2512\", \"#aae32a\", \"#22ebff\", \"#ef2212\"]\n    try:\n        return colors[int(x)]\n    except:\n        return \"red\"","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:37:25.513529Z","iopub.execute_input":"2021-07-13T12:37:25.513932Z","iopub.status.idle":"2021-07-13T12:37:25.520833Z","shell.execute_reply.started":"2021-07-13T12:37:25.513896Z","shell.execute_reply":"2021-07-13T12:37:25.519291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\n\n\n\n\n\nfor cluster_alg in clusters_algorithms:\n    for dec_alg in decomposition_algorithms:\n        decomposition = dec_alg(n_components=2)\n        X_transformed = decomposition.fit_transform(X_train)\n        \n        x = X_transformed[:,0]\n        y = X_transformed[:,1]\n        \n        markers = dict(color=list(map(SetColor, cluster_alg.labels_)))\n        text_id = Y# id_bearing with 0 isn't participate on bearing second place \n        \n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(mode='markers',x=x,y=y, marker = markers , text=text_id))\n        \n        fig.update_layout(\n            title=str(cluster_alg) + \" \" + str(decomposition),\n            xaxis_title=\"X Axis Title\",\n            yaxis_title=\"Y Axis Title\",\n            legend_title=\"Legend Title\",\n            font=dict(\n                family=\"Courier New, monospace\",\n                size=18,\n                color=\"RebeccaPurple\"\n            )\n        )\n        \n        SMALL = 6\n        BIG = 22\n        \n        marker_size=[SMALL if status == 0 else BIG for status in Y ]\n        \n        fig.data[0].update(marker_size=marker_size)\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:36:10.666073Z","iopub.execute_input":"2021-07-13T12:36:10.666502Z","iopub.status.idle":"2021-07-13T12:36:45.403231Z","shell.execute_reply.started":"2021-07-13T12:36:10.666463Z","shell.execute_reply":"2021-07-13T12:36:45.400364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import interpolate\n\nexperiments = signals['experiment_id'].unique()\n\ndata_fft_features = []\nfor exp in experiments:\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 26)\n    \n    experiment_steady_speed = experiment[steady_filter]\n    \n    signal = experiment_steady_speed['a2_y']\n    fft_ = get_fft(pd.DataFrame(signal), 3000)\n\n    freq = fft_['a2_y'].index.to_numpy()\n    val = fft_['a2_y'].to_numpy()\n    \n    mean_speed = experiment_steady_speed['hz'].mean()\n    val = val/mean_speed\n\n    interpolate_function_fft = interpolate.interp1d(freq, val, kind = 'linear')\n\n    start_hz = 1\n    end_hz = 200\n    step = 1\n\n    freq_new = np.arange(start_hz,end_hz + 1,step)\n    val_new = interpolate_function_fft(freq_new)\n    data_fft_features.append(val_new[:end_hz])\n    \n\n#     fig = go.Figure()\n#     cutted_hz = end_hz\n#     fig.add_trace(go.Scatter(x=freq[freq<cutted_hz], y=val[freq<cutted_hz],mode='lines',name='Fft'))\n#     fig.add_trace(go.Scatter(x=freq_new[:cutted_hz], y=val_new[:cutted_hz],mode='lines',name='Fft after interpolation and get values with an interval of 1 hz'))\n#     fig.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:23:16.854828Z","iopub.execute_input":"2021-07-13T08:23:16.855214Z","iopub.status.idle":"2021-07-13T08:23:20.367228Z","shell.execute_reply.started":"2021-07-13T08:23:16.855182Z","shell.execute_reply":"2021-07-13T08:23:20.365873Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_fft_features = np.array(data_fft_features)\ndata_fft_features.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T08:23:20.369371Z","iopub.execute_input":"2021-07-13T08:23:20.36985Z","iopub.status.idle":"2021-07-13T08:23:20.381459Z","shell.execute_reply.started":"2021-07-13T08:23:20.3698Z","shell.execute_reply":"2021-07-13T08:23:20.38027Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans, Birch, DBSCAN,MeanShift, OPTICS, SpectralBiclustering\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.manifold import Isomap\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.graph_objects as go\nN_classes = 3\n\nX_train = np.array(X_fft).copy()\n\nkmeans = KMeans(N_classes).fit(X_train)\ndbscan = DBSCAN(eps=2, min_samples=20).fit(X_train)\nmean_shift = MeanShift(bandwidth=2).fit(X_train)\noptics = OPTICS(min_samples=3).fit(X_train)\n\nclusters_algorithms = [kmeans, dbscan, mean_shift, optics]\ndecomposition_algorithms = [TruncatedSVD, TSNE, PCA, Isomap]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T11:53:04.325796Z","iopub.execute_input":"2021-07-13T11:53:04.326225Z","iopub.status.idle":"2021-07-13T11:53:45.405181Z","shell.execute_reply.started":"2021-07-13T11:53:04.326184Z","shell.execute_reply":"2021-07-13T11:53:45.403426Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for cluster_alg in clusters_algorithms:\n    for dec_alg in decomposition_algorithms:\n        decomposition = dec_alg(n_components=2)\n        X_transformed = decomposition.fit_transform(X_train)\n        \n        x = X_transformed[:,0]\n        y = X_transformed[:,1]\n\n        markers = dict(color=list(map(SetColor, cluster_alg.labels_)))\n        text_id = Y\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(mode='markers',x=x,y=y, marker = markers , text=text_id))\n        fig.update_layout(\n            title=str(cluster_alg) + \" \" + str(decomposition),\n            xaxis_title=\"X Axis Title\",\n            yaxis_title=\"Y Axis Title\",\n            legend_title=\"Legend Title\",\n            font=dict(\n                family=\"Courier New, monospace\",\n                size=18,\n                color=\"RebeccaPurple\"\n            )\n        )\n        \n        small = 6\n        big = 22\n        \n        marker_size=[small if status == 0 else big for status in Y ]\n        \n        fig.data[0].update(marker_size=marker_size)\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T11:57:33.250198Z","iopub.execute_input":"2021-07-13T11:57:33.250636Z","iopub.status.idle":"2021-07-13T11:57:58.44629Z","shell.execute_reply.started":"2021-07-13T11:57:33.2506Z","shell.execute_reply":"2021-07-13T11:57:58.441644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualisation the same things but for one turn","metadata":{}},{"cell_type":"code","source":"def get_one_turn_signal(signals):\n    time_step = b_data['Time'].iloc[1] - b_data['Time'].iloc[0]\n    sample_rate = 1.0 / time_step\n    cur_freq = b_data['Hz'].iloc[0]\n\n    n_rot = 3\n    num_pints = n_rot * int(sample_rate / cur_freq)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:18:54.835744Z","iopub.execute_input":"2021-07-13T12:18:54.836306Z","iopub.status.idle":"2021-07-13T12:18:54.842006Z","shell.execute_reply.started":"2021-07-13T12:18:54.836269Z","shell.execute_reply":"2021-07-13T12:18:54.841064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import interpolate\nexperiments = signals['experiment_id'].unique()\nexperiments = experiments[experiments != 101]\nexperiments = experiments[experiments != 102]\nprint(experiments)\nX = []\nY = []\nX_fft = []\nX_chunks = []\nid_experience_test = np.random.choice(experiments[:100],size=20, replace=False)\nid_experience_test = np.append(id_experience_test,np.random.choice(experiments[100:],size=5, replace=False))\nprint(id_experience_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:16:34.445211Z","iopub.execute_input":"2021-07-13T13:16:34.445579Z","iopub.status.idle":"2021-07-13T13:16:34.520468Z","shell.execute_reply.started":"2021-07-13T13:16:34.445548Z","shell.execute_reply":"2021-07-13T13:16:34.519319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_fft_validation = []\nx_chunks_validation = []\nx_validation = []\ny_validation = []\nfor exp in experiments:\n    # print(exp)\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 24) & (experiment['hz'] < 27)\n    experiment_steady = experiment[steady_filter]\n    sig = experiment_steady['a2_y']\n    y = int(labels[(labels['bearing_id'] == exp)]['status'])\n    \n    chunks = [sig[i:i + N] for i in range(0, len(sig), N)]\n    chunks.pop(-1)\n    \n    for chunk in chunks:\n        \n        features = []\n        for func in list_features_function:\n            a1 = func(chunk)\n            if type(a1) == list:\n                features+=a1\n            else:\n                features.append(a1)\n        \n        fft_ = get_fft(pd.DataFrame(chunk), 3000)\n\n        freq = fft_['a2_y'].index.to_numpy()\n        val = fft_['a2_y'].to_numpy()\n        mean_speed = experiment_steady['hz'].mean()\n        val_normalized = val/mean_speed\n        \n        interpolate_function_fft = interpolate.interp1d(freq, val_normalized, kind = 'linear')\n\n        start_hz = 1\n        end_hz = 200\n        step = 1\n\n        freq_new = np.arange(start_hz,end_hz + 1,step)\n        val_new = interpolate_function_fft(freq_new)\n        \n        if exp not in id_experience_test:\n            X_fft.append(val_new[:end_hz])\n            X_chunks.append(chunk)\n            X.append(features)\n            Y.append(y)\n        else:\n            x_fft_validation.append(val_new[:end_hz])\n            x_chunks_validation.append(chunk)\n            x_validation.append(features)\n            y_validation.append(y)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:19:34.777017Z","iopub.execute_input":"2021-07-13T13:19:34.777502Z","iopub.status.idle":"2021-07-13T13:19:53.506415Z","shell.execute_reply.started":"2021-07-13T13:19:34.777456Z","shell.execute_reply":"2021-07-13T13:19:53.505236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(X).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:20:02.412096Z","iopub.execute_input":"2021-07-13T13:20:02.412496Z","iopub.status.idle":"2021-07-13T13:20:02.425008Z","shell.execute_reply.started":"2021-07-13T13:20:02.412463Z","shell.execute_reply":"2021-07-13T13:20:02.424323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(Y).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:20:11.494936Z","iopub.execute_input":"2021-07-13T12:20:11.495362Z","iopub.status.idle":"2021-07-13T12:20:11.501457Z","shell.execute_reply.started":"2021-07-13T12:20:11.495327Z","shell.execute_reply":"2021-07-13T12:20:11.500683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(X_fft).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:20:12.607999Z","iopub.execute_input":"2021-07-13T12:20:12.610241Z","iopub.status.idle":"2021-07-13T12:20:12.618688Z","shell.execute_reply.started":"2021-07-13T12:20:12.610194Z","shell.execute_reply":"2021-07-13T12:20:12.61757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(X_chunks).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:20:24.799844Z","iopub.execute_input":"2021-07-13T12:20:24.800216Z","iopub.status.idle":"2021-07-13T12:20:24.873965Z","shell.execute_reply.started":"2021-07-13T12:20:24.800186Z","shell.execute_reply":"2021-07-13T12:20:24.872223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(x_validation).shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:20:11.282995Z","iopub.execute_input":"2021-07-13T13:20:11.283635Z","iopub.status.idle":"2021-07-13T13:20:11.293427Z","shell.execute_reply.started":"2021-07-13T13:20:11.283598Z","shell.execute_reply":"2021-07-13T13:20:11.292141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_det_curve\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nimport matplotlib.pyplot as plt\n\n# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=15, shuffle=True)\nX_train, y_train = X_chunks, Y\n# X_train, X_test, y_train, y_test = train_test_split(X_fft, Y, test_size=0.33, random_state=15, shuffle=True)\nclassifiers = {\n    \"Linear SVM\": make_pipeline(StandardScaler(), SVC(gamma='auto', kernel=\"rbf\")),\n    \"Random Forest\": RandomForestClassifier(\n        max_depth=5, n_estimators=10, max_features=1, class_weight='balanced'\n    ),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n    \"AdaBoostClassifier\": AdaBoostClassifier(n_estimators=100, random_state=0),\n    \"KNeighbor\": KNeighborsClassifier(n_neighbors=6),\n    \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0),\n    \"GaussianProcessClassifier\": GaussianProcessClassifier(kernel=1.0 * RBF(1.0),random_state=0),\n    \"LogisticRegression\": LogisticRegression(random_state=0, solver='lbfgs'),\n    'MLPCLassifier': MLPClassifier(random_state=1),\n    \"GaussianNB\":GaussianNB()\n    \n}\n\n\nfig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(22, 7))\nfor name, clf in classifiers.items():\n    clf.fit(X_train, y_train)\n    y_predict = clf.predict(x_chunks_validation)\n    \n    print(\"\\n\\n\" + name + \"\\n\\n\")\n    print(\"\\n\" + \"Metrics:\" + \"\\n\")\n    print(classification_report(y_validation, y_predict))\n    print(\"\\n\")\n    print(\"\\n\" + \"Confusion Matrix:\" + \"\\n\")\n    print(confusion_matrix(y_validation, y_predict))\n    print(\"\\n____________________________________________\\n\")\n\n    plot_roc_curve(clf, x_chunks_validation, y_validation, ax=ax_roc, name=name)\n    plot_det_curve(clf, x_chunks_validation, y_validation, ax=ax_det, name=name)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:46:42.298264Z","iopub.execute_input":"2021-07-13T13:46:42.298643Z","iopub.status.idle":"2021-07-13T13:47:43.790612Z","shell.execute_reply.started":"2021-07-13T13:46:42.298611Z","shell.execute_reply":"2021-07-13T13:47:43.789295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique, counts = np.unique(Y, return_counts=True)\ndict(zip(unique, counts))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T12:49:39.704883Z","iopub.execute_input":"2021-07-13T12:49:39.705318Z","iopub.status.idle":"2021-07-13T12:49:39.712989Z","shell.execute_reply.started":"2021-07-13T12:49:39.705283Z","shell.execute_reply":"2021-07-13T12:49:39.711952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-13T11:07:11.365043Z","iopub.execute_input":"2021-07-13T11:07:11.365742Z","iopub.status.idle":"2021-07-13T11:07:11.890331Z","shell.execute_reply.started":"2021-07-13T11:07:11.365702Z","shell.execute_reply":"2021-07-13T11:07:11.889078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplot_det_curve(clf, X_test, y_test)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:57:34.672103Z","iopub.execute_input":"2021-07-13T09:57:34.672765Z","iopub.status.idle":"2021-07-13T09:57:34.849026Z","shell.execute_reply.started":"2021-07-13T09:57:34.672725Z","shell.execute_reply":"2021-07-13T09:57:34.847606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in y_predict:\n    print(i, end=\" \")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:57:13.618856Z","iopub.execute_input":"2021-07-13T09:57:13.619308Z","iopub.status.idle":"2021-07-13T09:57:13.711079Z","shell.execute_reply.started":"2021-07-13T09:57:13.619266Z","shell.execute_reply":"2021-07-13T09:57:13.709552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in y_test:\n    print(i, end=\" \")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:57:14.781702Z","iopub.execute_input":"2021-07-13T09:57:14.78216Z","iopub.status.idle":"2021-07-13T09:57:14.890362Z","shell.execute_reply.started":"2021-07-13T09:57:14.782121Z","shell.execute_reply":"2021-07-13T09:57:14.879957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's see the spectral characteristics of the signal (doing at the moment)","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nid_experiment = 54\npowerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(signals[signals['experiment_id']==id_experiment]['a2_y'], Fs=3000)\n\nplt.xlabel('Time')\nplt.title('SpecGram Bearing #2 in experiment {}'.format(id_experiment))\nplt.ylabel('Frequency')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:59:40.511468Z","iopub.execute_input":"2021-07-02T11:59:40.511872Z","iopub.status.idle":"2021-07-02T11:59:40.763868Z","shell.execute_reply.started":"2021-07-02T11:59:40.511841Z","shell.execute_reply":"2021-07-02T11:59:40.762754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"powerSpectrum, freqenciesFound, time, imageAxis = plt.specgram(raw_signal_a1_y, Fs=3000)\n\nplt.xlabel('Time')\nplt.title('SpecGram Bearing #1 in experiment {}'.format(id_experiment))\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Estimate power spectral density using Welch’s method.\n\nWelch’s method computes an estimate of the power \nspectral density by dividing the data into overlapping segments, \ncomputing a modified periodogram for each segment and averaging the periodograms.","metadata":{}},{"cell_type":"code","source":"import scipy.signal as signal\nimport plotly.graph_objects as go\nid_experiment=92\nfreqs_first, psd_first = signal.welch(signals[signals['experiment_id']==id_experiment]['a2_y'],fs=3000)\nfreqs_second, psd_second = signal.welch(signals[signals['experiment_id']==id_experiment]['a1_y'],fs=3000)\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=freqs_first, y=psd_first,\n                    mode='lines',\n                    name='First bearing'))\nfig.add_trace(go.Scatter(x=freqs_second, y=psd_second,\n                    mode='lines',\n                    name='second_bearing'))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:01:32.773371Z","iopub.execute_input":"2021-07-02T12:01:32.773934Z","iopub.status.idle":"2021-07-02T12:01:32.83168Z","shell.execute_reply.started":"2021-07-02T12:01:32.773879Z","shell.execute_reply":"2021-07-02T12:01:32.830331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A vibration FFT (Fast Fourier Transform) spectrum is an incredibly useful tool for machinery vibration analysis. \nFFT spectra allow us to analyze\nvibration amplitudes at various component frequencies on the FFT spectrum. \nIn this way, we can identify and track vibration occurring at specific frequencies.","metadata":{}},{"cell_type":"code","source":"fft_second = get_fft(pd.DataFrame(raw_signal_a2_y), 3000)\nfft_first = get_fft(pd.DataFrame(raw_signal_a1_y), 3000)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=fft_second.index, y=fft_second.iloc[:,0],\n                    mode='lines',\n                    name='Second bearing'))\nfig.add_trace(go.Scatter(x=fft_first.index, y=fft_first.iloc[:,0],\n                    mode='lines',\n                    name='First bearing'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A Power Spectral Density (PSD) is the measure of signal's power content versus frequency. \nA PSD is typically used to characterize broadband random signals. \nThe amplitude of the PSD is normalized by the spectral resolution employed to digitize the signal.\n","metadata":{}},{"cell_type":"code","source":"df_psd_first = get_psd(pd.DataFrame(raw_signal_a1_y), 1, 3000)\ndf_psd_second = get_psd(pd.DataFrame(raw_signal_a2_y), 1, 3000)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=df_psd_second.index, y=df_psd_second.iloc[:,0],\n                    mode='lines',\n                    name='Second bearing'))\nfig.add_trace(go.Scatter(x=df_psd_first.index, y=df_psd_first.iloc[:,0],\n                    mode='lines',\n                    name='First bearing'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tftb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tftb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Wigner distribution (WD) is derived from the relationship between the power spectrum and the autocorrelation function for \ntime-variant and non-stationary processes. The WVD has been used for gear fault detection and it is recently used for rolling \nelement bearing to represent the time-frequency features of vibration signals.","metadata":{}},{"cell_type":"code","source":"sig = raw_signal_a2_y[0:300].to_numpy()\ntimestamps = experiment_steady_speed['timestamp'][0:300].to_numpy()\nwvd = tftb.processing.WignerVilleDistribution(sig, timestamps=timestamps)\ntfr_wvd, t_wvd, f_wvd = wvd.run()\n\n\ndt = 1 /3000\nts = timestamps\nf_wvd = np.fft.fftshift(np.fft.fftfreq(tfr_wvd.shape[0], d=2 * dt))\ndf_wvd = f_wvd[1]-f_wvd[0]  # the frequency step in the WVT\nim = plt.imshow(np.fft.fftshift(tfr_wvd, axes=0), aspect='auto', origin='lower',\n       extent=(ts[0] - dt/2, ts[-1] + dt/2,\n               f_wvd[0]-df_wvd/2, f_wvd[-1]+df_wvd/2))\nplt.xlabel('time [s]')\nplt.ylabel('frequency [Hz]')\nplt.colorbar(im)\nplt.title('Wigner-Ville Transform')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Get some distribution of signals","metadata":{}},{"cell_type":"code","source":"experiment[['a1_y','a2_y']].plot.hist(alpha=0.5, log=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiment[['a1_y','a2_y']].plot.kde()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install AntroPy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import antropy as ent\n# ent.spectral_entropy(raw_signal_a2_y, sf=3000, method='fft',normalize=True)\nent.spectral_entropy(raw_signal_a2_y, sf=3000, nperseg=10000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rolling_window(a, window):\n    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n    strides = a.strides + (a.strides[-1],)\n    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\nrolling_window_a2_y = rolling_window(raw_signal_a2_y.to_numpy(), 10000)\nrolling_window_a2_y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spectral_entropy_list = []\nfor window in rolling_window_a2_y:\n    spectral_entropy_list.append(ent.spectral_entropy(window, sf=3000, method='welch'))\n\npx.line(spectral_entropy_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import signal\nimport matplotlib.pyplot as plt\nf, t, Sxx = signal.spectrogram(raw_signal_a2_y, 3000)\nplt.pcolormesh(t, f[:15], Sxx[:15,:], shading='gouraud')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, t, Sxx = signal.spectrogram(raw_signal_a1_y, 3000)\nplt.pcolormesh(t, f[:15], Sxx[:15,:], shading='gouraud')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom scipy import signal\nanalytic_signal = signal.hilbert(raw_signal_a2_y)\namplitude_envelope = np.abs(analytic_signal)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=experiment_steady_speed['timestamp'], y=raw_signal_a2_y,\n                    mode='lines',\n                    name='lines'))\nfig.add_trace(go.Scatter(x=experiment_steady_speed['timestamp'], y=amplitude_envelope,\n                    mode='lines',\n                    name='lines'))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:44:18.935656Z","iopub.execute_input":"2021-06-30T14:44:18.936151Z","iopub.status.idle":"2021-06-30T14:44:19.193476Z","shell.execute_reply.started":"2021-06-30T14:44:18.93612Z","shell.execute_reply":"2021-06-30T14:44:19.190088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.line(get_fft(pd.DataFrame(amplitude_envelope), 3000)[:500])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.line(get_psd(pd.DataFrame(amplitude_envelope), 1,3000)[:500])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:44:25.355049Z","iopub.execute_input":"2021-06-30T14:44:25.355453Z","iopub.status.idle":"2021-06-30T14:44:25.430713Z","shell.execute_reply.started":"2021-06-30T14:44:25.355408Z","shell.execute_reply":"2021-06-30T14:44:25.429764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:13:08.092463Z","iopub.execute_input":"2021-06-30T13:13:08.092844Z","iopub.status.idle":"2021-06-30T13:13:08.125925Z","shell.execute_reply.started":"2021-06-30T13:13:08.092811Z","shell.execute_reply":"2021-06-30T13:13:08.124975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:14:49.66001Z","iopub.execute_input":"2021-06-30T13:14:49.660367Z","iopub.status.idle":"2021-06-30T13:14:49.665147Z","shell.execute_reply.started":"2021-06-30T13:14:49.660337Z","shell.execute_reply":"2021-06-30T13:14:49.664291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:30:35.801213Z","iopub.execute_input":"2021-06-30T13:30:35.801556Z","iopub.status.idle":"2021-06-30T13:30:35.807771Z","shell.execute_reply.started":"2021-06-30T13:30:35.801527Z","shell.execute_reply":"2021-06-30T13:30:35.806835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:30:46.981262Z","iopub.execute_input":"2021-06-30T13:30:46.981598Z","iopub.status.idle":"2021-06-30T13:30:46.986382Z","shell.execute_reply.started":"2021-06-30T13:30:46.981568Z","shell.execute_reply":"2021-06-30T13:30:46.985047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:30:47.340557Z","iopub.execute_input":"2021-06-30T13:30:47.341212Z","iopub.status.idle":"2021-06-30T13:30:47.365033Z","shell.execute_reply.started":"2021-06-30T13:30:47.341161Z","shell.execute_reply":"2021-06-30T13:30:47.363957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiments = signals['experiment_id'].unique()\ndata = []\nfor exp in experiments:\n    experiment = signals[(signals['experiment_id']==exp)]\n    steady_filter = (experiment['hz'] > 22) & (experiment['hz'] < 27)\n    experiment_steady_speed = experiment[steady_filter]\n    feature_a1_y = []\n    feature_a2_y = []\n    for func in list_features_function:\n        a1 = func(experiment['a1_y'])\n        a2 = func(experiment['a2_y'])\n        if type(a1) == list:\n            feature_a1_y+=a1\n            feature_a2_y+=a2\n            \n        else:\n            feature_a1_y.append(a1)\n            feature_a2_y.append(a2)\n    data.append((feature_a1_y,feature_a2_y))\n\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tftb","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:44:13.358881Z","iopub.execute_input":"2021-06-30T13:44:13.359297Z","iopub.status.idle":"2021-06-30T13:44:23.509583Z","shell.execute_reply.started":"2021-06-30T13:44:13.359259Z","shell.execute_reply":"2021-06-30T13:44:23.508757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install EMD-signal","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:17:05.692299Z","iopub.execute_input":"2021-06-30T14:17:05.692648Z","iopub.status.idle":"2021-06-30T14:17:19.810269Z","shell.execute_reply.started":"2021-06-30T14:17:05.692617Z","shell.execute_reply":"2021-06-30T14:17:19.808991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PyEMD import EEMD\nimport numpy as np\nimport pylab as plt\n\n# Define signal\nt = np.linspace(0, 1, 200)\n\nsin = lambda x,p: np.sin(2*np.pi*x*t+p)\nS = 3*sin(18,0.2)*(t-0.2)**2\nS += 5*sin(11,2.7)\nS += 3*sin(14,1.6)\nS += 1*np.sin(4*2*np.pi*(t-0.8)**2)\nS += t**2.1 -t\n\n# Assign EEMD to `eemd` variable\neemd = EEMD()\n\n# Say we want detect extrema using parabolic method\nemd = eemd.EMD\nemd.extrema_detection=\"parabol\"\n# Execute EEMD on S\nS = experiment_steady_speed['a2_y'].to_numpy()[:3000]\nt = experiment_steady_speed['timestamp'].to_numpy()[:3000]\neIMFs = eemd.eemd(S, t)\nnIMFs = eIMFs.shape[0]\n\n# Plot results\nplt.figure(figsize=(20,15))\nplt.subplot(nIMFs+1, 1, 1)\nplt.plot(t, S, 'r')\n\nfor n in range(nIMFs):\n    plt.subplot(nIMFs+1, 1, n+2)\n    plt.plot(t, eIMFs[n], 'g')\n    plt.ylabel(\"eIMF %i\" %(n+1))\n    plt.locator_params(axis='y', nbins=5)\n\nplt.xlabel(\"Time [s]\")\nplt.tight_layout()\nplt.savefig('eemd_example', dpi=120)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:44:38.700268Z","iopub.execute_input":"2021-06-30T14:44:38.700621Z","iopub.status.idle":"2021-06-30T14:45:01.693854Z","shell.execute_reply.started":"2021-06-30T14:44:38.700587Z","shell.execute_reply":"2021-06-30T14:45:01.692809Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.line(get_fft(pd.DataFrame(eIMFs[2]), 3000))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:46:01.452526Z","iopub.execute_input":"2021-06-30T14:46:01.452932Z","iopub.status.idle":"2021-06-30T14:46:01.537448Z","shell.execute_reply.started":"2021-06-30T14:46:01.452894Z","shell.execute_reply":"2021-06-30T14:46:01.536371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = signal.correlate(S, np.ones(128), mode='same') / 128\npx.line(y=[corr])","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:54:34.207561Z","iopub.execute_input":"2021-06-30T14:54:34.207967Z","iopub.status.idle":"2021-06-30T14:54:34.296375Z","shell.execute_reply.started":"2021-06-30T14:54:34.207929Z","shell.execute_reply":"2021-06-30T14:54:34.295354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, Cxy = signal.coherence(t, S, 300, nperseg=1024)\nplt.semilogy(f, Cxy)\nplt.xlabel('frequency [Hz]')\nplt.ylabel('Coherence')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:57:51.930106Z","iopub.execute_input":"2021-06-30T14:57:51.930462Z","iopub.status.idle":"2021-06-30T14:57:52.5209Z","shell.execute_reply.started":"2021-06-30T14:57:51.930434Z","shell.execute_reply":"2021-06-30T14:57:52.519833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import signal\nfrom scipy.fft import fftshift\nf, t, Sxx = signal.spectrogram(raw_signal_a2_y, 3000, return_onesided=False)\nplt.pcolormesh(t, fftshift(f), fftshift(Sxx, axes=0), shading='gouraud')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T14:59:35.820179Z","iopub.execute_input":"2021-06-30T14:59:35.820542Z","iopub.status.idle":"2021-06-30T14:59:36.212453Z","shell.execute_reply.started":"2021-06-30T14:59:35.820508Z","shell.execute_reply":"2021-06-30T14:59:36.211623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}