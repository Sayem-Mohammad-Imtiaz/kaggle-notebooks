{"cells":[{"metadata":{"_cell_guid":"4ed69942-eef4-4f07-9bb6-a6a08603523b","_uuid":"e0b49d511f59f5bc07294c5a57c99884d1fd2bd8","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import LambdaCallback, ModelCheckpoint\nimport random\nimport sys\nimport io\n\n\nprint(tf.test.gpu_device_name())\n# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# Read in only the two columns we need \nemoji = pd.read_csv('../input/twitter_emoji.csv')\n\n# remove rows with an emoji sequence of len 1\nemoji = emoji[emoji.length > 1]\n\n# check out the dataframe\nemoji.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"08da8f76-f9f5-4fd1-a161-7546500aa23c","_uuid":"7bbee9dce830eeeb8ea83fd793ade259b21c31fd","trusted":true},"cell_type":"code","source":"# get the relevent column & summary info\nemojis = emoji.emoji_no_mods\n\nn_messages = len(emojis) # number of lines\nn_chars = len(' '.join(map(str, emojis))) \n\nprint(\"Number of messages %d\" % n_messages)\nprint(\"Their messages add up to %d characters\" % n_chars)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94ee4c53-ca78-4a30-ab07-6ad957c12c04","_uuid":"be3cd8c084c617523bf100650ec9fd67beb72fdb","trusted":true},"cell_type":"code","source":"# conjoin all emoji into one huge string\nemojis = '\\n'.join(map(str, emojis)).lower()\n\nemojis[:100] # Show first 100 characters","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6fbf7e2e-c7b6-4f12-9648-471dea09b90f","_uuid":"8c3ac7ede01c9884c4e245d649dd383e3e1486ba","scrolled":true,"trusted":true},"cell_type":"code","source":"# get the indices & counts of each character\nchars = sorted(list(set(emojis)))\nprint('Count of unique characters (i.e., features):', len(chars))\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"44b8a3df-25fe-40d4-81c0-5ca0c7438337","_uuid":"74921d3196fef3d16cc264b4a9508bcf091d5c17","trusted":true},"cell_type":"code","source":"# set span to length of the shortest emoji sequence plus 1\n# get all spans of that length, with a step width of 1\nmaxlen = emoji.emoji.str.len().min() + 1\nstep = 1\nsentences = []\nnext_chars = []\nfor i in range(0, len(emojis) - maxlen, step):\n    sentences.append(emojis[i: i + maxlen])\n    next_chars.append(emojis[i + maxlen])\nprint('Number of sequences:', len(sentences), \"\\n\")\n\nprint(sentences[:10], \"\\n\")\nprint(next_chars[:10])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0061dbc-193a-4355-91e7-ff8d8f04f98e","_uuid":"820d224ac0842acf51240008f118ca75582dd817","trusted":true},"cell_type":"code","source":"# splitting spans into character to predict & \n# preceding characters\nx = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\ny = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        x[i, t, char_indices[char]] = 1\n    y[i, char_indices[next_chars[i]]] = 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc5f72f0-89f9-4caa-8208-5968f2701a36","_uuid":"fd7a33b3ce13e07f27cf67c7d0608a63f2128fcd","collapsed":true,"trusted":true},"cell_type":"code","source":"# define our model\nmodel = Sequential()\nmodel.add(LSTM(1, input_shape=(maxlen, len(chars))))\nmodel.add(Dense(len(chars)))\nmodel.add(Activation('softmax'))\n\n# compile model\noptimizer = RMSprop(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa111cc9-4a2b-4781-9d32-2b2a07c782d0","_uuid":"85aaec3c1cf76eb94af499685bec3ae961f6f8bb","collapsed":true,"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef on_epoch_end(epoch, logs):\n    # Function invoked for specified epochs. Prints generated text.\n    # Using epoch+1 to be consistent with the training epochs printed by Keras\n    if epoch+1 == 1 or epoch+1 == 15:\n        print()\n        print('----- Generating text after Epoch: %d' % epoch)\n\n        start_index = random.randint(0, len(emojis) - maxlen - 1)\n        for diversity in [0.2, 0.5, 1.0, 1.2]:\n            print('----- diversity:', diversity)\n\n            generated = ''\n            sentence = emojis[start_index: start_index + maxlen]\n            generated += sentence\n            print('----- Generating with seed: \"' + sentence + '\"')\n            sys.stdout.write(generated)\n\n            next_char = \"\"\n            while next_char != \"\\n\":\n                x_pred = np.zeros((1, maxlen, len(chars)))\n                for t, char in enumerate(sentence):\n                    x_pred[0, t, char_indices[char]] = 1.\n\n                preds = model.predict(x_pred, verbose=0)[0]\n                next_index = sample(preds, diversity)\n                next_char = indices_char[next_index]\n\n                generated += next_char\n                sentence = sentence[1:] + next_char\n\n                sys.stdout.write(next_char)\n                sys.stdout.flush()\n            print()\n    else:\n        print()\n        print('----- Not generating text after Epoch: %d' % epoch)\n\ngenerate_text = LambdaCallback(on_epoch_end=on_epoch_end)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"45a7b04311b4fb5720827a574a193c1dfd5f7252"},"cell_type":"code","source":"?ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ef29cdd-e300-4860-b32f-df782e414c40","_uuid":"8fc88c921433d17a5d80a9be1916bd491ac74b75","scrolled":true,"trusted":true},"cell_type":"code","source":"# define the checkpoint\nfilepath = \"weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, \n                             monitor='loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min')\n\n# fit model using our gpu\nwith tf.device('/gpu:0'):\n    model.fit(x, y,\n              batch_size=128,\n              epochs=15,\n              verbose=2,\n              callbacks=[generate_text, checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcd4bd7fd45e3d68d890ad898b00e7156576b6a1"},"cell_type":"code","source":"print(np.fromstring(\"ðŸ’©ðŸ˜‚\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57c24bbc82690191a6dea629bee81bbe153b8a95"},"cell_type":"markdown","source":"To generate new sequences, use the generate_emoji_seq() function with at least one seed emoji. If the ouput is empty, it's generated the end of the sequence after your last emoji."},{"metadata":{"trusted":true,"_uuid":"24c7e5c3f9081c5a07bfe93ec978f44a1c67dbe3"},"cell_type":"code","source":"def generate_emoji_seq(input_chars, # seed characters for prediction\n                       maxlen=maxlen, # max input length\n                       chars=chars, # number of unique emoji\n                       char_indices=char_indices # indices from one-hot encoding\n                      ):\n    generated = ''\n    sentence = input_chars\n    generated += sentence\n\n    next_char = ''\n    while next_char != '\\n':\n        x_pred = np.zeros((1, maxlen, len(chars)))\n        for t, char in enumerate(sentence):\n            x_pred[0, t, char_indices[char]] = 1.\n\n        preds = model.predict(x_pred, verbose=0)[0]\n        next_index = sample(preds, 1)\n        next_char = indices_char[next_index]\n\n        generated += next_char\n        sentence = sentence[1:] + next_char\n\n        sys.stdout.write(next_char)\n        \nprint (generate_emoji_seq(\"ðŸ’©\"))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}