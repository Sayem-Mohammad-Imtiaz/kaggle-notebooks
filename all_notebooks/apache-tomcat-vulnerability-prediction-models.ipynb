{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n# linear algebra\nimport pandas as pd\n# data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n# Select features => Fit features to model => Model prediction => Model validation\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nvulnerability_data = pd.read_csv(\"/kaggle/input/apachevulnerabilities/finalDataset.csv\")\nnp.set_printoptions(threshold=np.inf)\n\n\nfrom sklearn.model_selection import train_test_split\n\n# Creating the training and test data\ndf = pd.DataFrame(vulnerability_data)\ndf.dropna()\ndf.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\ntrain, test = train_test_split(df, test_size=0.3)\n#print(train)\n\nfrom sklearn.model_selection import KFold\n# prepare cross validation\nkfold = KFold(10, shuffle=True, random_state=1)\n# enumerate splits\n\n#vulnerability_data.head()\n#df.pop('synchronizedFieldsQty')\nfeature_columns =df.iloc[:,4:52] \n#feature_columns.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n#print(feature_columns.vulnerable)\nfeature_columns.pop('severity')\nfeature_columns.pop('title')\nfeature_columns.pop('version')\nfeature_columns.pop('vulnerable')\n\nX =train[feature_columns.columns]\ntest_X = test[feature_columns.columns]\ny = train.vulnerable\nseverity_y = train.severity\ntitle_y = train.title\ntest_Y = test.vulnerable\nseverity_test_Y = test.severity\ntitle_test_Y= test.title","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-07T11:09:20.947004Z","iopub.execute_input":"2021-07-07T11:09:20.947373Z","iopub.status.idle":"2021-07-07T11:09:21.105687Z","shell.execute_reply.started":"2021-07-07T11:09:20.947343Z","shell.execute_reply":"2021-07-07T11:09:21.104847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_feature_set(feature_set):\n    X =train[feature_set_1]\n    test_X = test[feature_set_1]\n    y = train.vulnerable\n    severity_y = train.severity\n    title_y = train.title\n    test_Y = test.vulnerable\n    severity_test_Y = test.severity\n    title_test_Y= test.title","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:09:28.79695Z","iopub.execute_input":"2021-07-07T11:09:28.797495Z","iopub.status.idle":"2021-07-07T11:09:28.803116Z","shell.execute_reply.started":"2021-07-07T11:09:28.79745Z","shell.execute_reply":"2021-07-07T11:09:28.801992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FIRST FEATURE SET SELECTION\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.linear_model import LinearRegression\n# Sequential Forward Selection(sfs)\nsfs = SFS(LinearRegression(), \n           k_features='best', \n           forward=True, # if forward = True then SFS otherwise SBS\n           floating=False, \n           scoring='r2')\nsfs.fit(X,y)\nfeature_set_1 = np.array(sfs.k_feature_names_)\nprint(\"Feature set 1 ready...\")","metadata":{"execution":{"iopub.status.busy":"2021-07-07T10:28:07.229986Z","iopub.execute_input":"2021-07-07T10:28:07.230353Z","iopub.status.idle":"2021-07-07T10:29:04.320534Z","shell.execute_reply.started":"2021-07-07T10:28:07.230324Z","shell.execute_reply":"2021-07-07T10:29:04.319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FOR SECOND FEATURE SET\nfrom sklearn.feature_selection import RFE\nrfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=None)\n# fit the model\nrfe.fit(X, y)\n# transform the data\nfeature_set_2= rfe.fit_transform(X,y)\nfor i in range(X.shape[1]):\n    if(rfe.support_[i] == 1):\n        #print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n        final_features = np.array(X.columns[i])\n        print(final_features)\n        #np.array(X.columns[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modern Feature selection techniques\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n#print(X)\nX = X.astype(int)\nchi2_features = SelectKBest(f_classif, k=3)\nbest_features = chi2_features.fit_transform(X, y)\nprint(best_features.scores)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-07-05T09:09:04.568075Z","iopub.execute_input":"2021-07-05T09:09:04.56993Z","iopub.status.idle":"2021-07-05T09:09:04.783511Z","shell.execute_reply.started":"2021-07-05T09:09:04.569881Z","shell.execute_reply":"2021-07-05T09:09:04.780776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_feature_set(feature_set_1)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:09:40.529728Z","iopub.execute_input":"2021-07-07T11:09:40.530717Z","iopub.status.idle":"2021-07-07T11:09:40.53832Z","shell.execute_reply.started":"2021-07-07T11:09:40.53063Z","shell.execute_reply":"2021-07-07T11:09:40.537369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_feature_set(feature_set_2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FOR HANDLING THE IMBALANCED VULNERABILITY STATUS\nfrom imblearn.over_sampling  import RandomOverSampler\n\nros = RandomOverSampler()\nX_ros, y_ros = ros.fit_resample(X, y)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:06:36.175955Z","iopub.execute_input":"2021-07-07T11:06:36.176524Z","iopub.status.idle":"2021-07-07T11:06:36.212811Z","shell.execute_reply.started":"2021-07-07T11:06:36.176479Z","shell.execute_reply":"2021-07-07T11:06:36.211744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FOR HANDLING THE IMBALANCED VULNERABILITY SEVERITY\nfrom imblearn.over_sampling  import RandomOverSampler\n\nros = RandomOverSampler()\nX_ros, y_ros = ros.fit_resample(X, severity_y)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:09:43.720392Z","iopub.execute_input":"2021-07-07T11:09:43.721051Z","iopub.status.idle":"2021-07-07T11:09:43.788862Z","shell.execute_reply.started":"2021-07-07T11:09:43.720973Z","shell.execute_reply":"2021-07-07T11:09:43.787878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FOR HANDLING THE IMBALANCED VULNERABILITY TITLE\nfrom imblearn.over_sampling  import RandomOverSampler\n\nros = RandomOverSampler()\nX_ros, y_ros = ros.fit_resample(X, title_y)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:12:38.782643Z","iopub.execute_input":"2021-07-07T11:12:38.78299Z","iopub.status.idle":"2021-07-07T11:12:39.288496Z","shell.execute_reply.started":"2021-07-07T11:12:38.78296Z","shell.execute_reply":"2021-07-07T11:12:39.287463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ndef plot_confusionmatrix(y_train_pred,y_train,dom):\n    print(f'{dom} Confusion matrix')\n    cf = confusion_matrix(y_train_pred,y_train)\n    sns.heatmap(cf,annot=True,cmap='Blues', fmt='g')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:10:45.968415Z","iopub.execute_input":"2021-07-07T11:10:45.968764Z","iopub.status.idle":"2021-07-07T11:10:45.973744Z","shell.execute_reply.started":"2021-07-07T11:10:45.968731Z","shell.execute_reply":"2021-07-07T11:10:45.97296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree Classifier (No PRUNING done)\ndt_model = DecisionTreeClassifier(random_state=0)\ndt_model.fit(X_ros, y_ros)\nfrom sklearn.metrics import accuracy_score\ny_train_pred = dt_model.predict(X)\ny_test_pred = dt_model.predict(test_X)\n\nprint(f'Train score {accuracy_score(y_train_pred,y)}')\nprint(f'Test score {accuracy_score(y_test_pred,test_Y)}')\nfrom sklearn import tree\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(dt_model, X_ros, y_ros, scoring='accuracy', cv=kfold, n_jobs=-1)\n# report performance\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n\npath = dt_model.cost_complexity_pruning_path(X, y)\nccp_alphas, impurities = path.ccp_alphas, path.impurities\nprint(mean(ccp_alphas))\n\nclfs = []\nfor ccp_alpha in ccp_alphas:\n    clf = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    clf.fit(X_ros, y_ros)\n    clfs.append(clf)\n    \nclfs = clfs[:-1]\nccp_alphas = ccp_alphas[:-1]\nnode_counts = [clf.tree_.node_count for clf in clfs]\ndepth = [clf.tree_.max_depth for clf in clfs]\nplt.scatter(ccp_alphas,node_counts)\nplt.scatter(ccp_alphas,depth)\nplt.plot(ccp_alphas,node_counts,label='no of nodes',drawstyle=\"steps-post\")\nplt.plot(ccp_alphas,depth,label='depth',drawstyle=\"steps-post\")\nplt.legend()\nplt.show()\n\ntrain_acc = []\ntest_acc = []\nfor c in clfs:\n    y_train_pred = c.predict(X)\n    y_test_pred = c.predict(test_X)\n    train_acc.append(accuracy_score(y_train_pred,y))\n    test_acc.append(accuracy_score(y_test_pred,test_Y))\n\nplt.scatter(ccp_alphas,train_acc)\nplt.scatter(ccp_alphas,test_acc)\nplt.plot(ccp_alphas,train_acc,label='train_accuracy',drawstyle=\"steps-post\")\nplt.plot(ccp_alphas,test_acc,label='test_accuracy',drawstyle=\"steps-post\")\nplt.legend()\nplt.title('Accuracy vs alpha')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-07T10:32:49.690503Z","iopub.execute_input":"2021-07-07T10:32:49.691176Z","iopub.status.idle":"2021-07-07T10:33:28.940677Z","shell.execute_reply.started":"2021-07-07T10:32:49.691133Z","shell.execute_reply":"2021-07-07T10:33:28.939388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decision_tree_results(X_ros, y_ros, test_Y):\n    model = DecisionTreeClassifier(random_state=0,ccp_alpha=0.060)\n    model.fit(X_ros, y_ros)\n\n    from sklearn import tree\n    from numpy import mean\n    from numpy import std\n    from sklearn.model_selection import cross_val_score\n    scores = cross_val_score(model, X_ros, y_ros, scoring='accuracy', cv=kfold, n_jobs=-1)\n    print('Precision: %.3f' % mean(cross_val_score(model, X_ros, y_ros, scoring='precision', cv=kfold, n_jobs=-1)))\n    print('Recall: %.3f' % mean(cross_val_score(model, X_ros, y_ros, scoring='recall', cv=kfold, n_jobs=-1)))\n    # report performance\n    print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n    y_train_pred = model.predict(X_ros)\n    y_test_pred = model.predict(test_X)\n\n    print(f'Train score {accuracy_score(y_train_pred,y_ros)}')\n    print(f'Test score {accuracy_score(y_test_pred,test_Y)}')\n    plot_confusionmatrix(y_train_pred,y_ros,dom='Train')\n    from sklearn.metrics import plot_precision_recall_curve\n    plot_confusionmatrix(y_test_pred,test_Y,dom='Test')\n    plot_precision_recall_curve(model, X_ros, y_ros)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:05:02.542659Z","iopub.execute_input":"2021-07-07T11:05:02.543101Z","iopub.status.idle":"2021-07-07T11:05:02.552687Z","shell.execute_reply.started":"2021-07-07T11:05:02.543049Z","shell.execute_reply":"2021-07-07T11:05:02.550844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decision_tree_results(X_ros, y_ros, test_Y)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-07T11:10:50.431427Z","iopub.execute_input":"2021-07-07T11:10:50.43194Z","iopub.status.idle":"2021-07-07T11:10:54.444843Z","shell.execute_reply.started":"2021-07-07T11:10:50.431894Z","shell.execute_reply":"2021-07-07T11:10:54.442491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decision_tree_results(X_ros, y_ros, severity_test_Y)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:11:29.715605Z","iopub.execute_input":"2021-07-07T11:11:29.716015Z","iopub.status.idle":"2021-07-07T11:11:34.410309Z","shell.execute_reply.started":"2021-07-07T11:11:29.715983Z","shell.execute_reply":"2021-07-07T11:11:34.408781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decision_tree_results(X_ros, y_ros, title_test_Y)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T11:12:45.31189Z","iopub.execute_input":"2021-07-07T11:12:45.312388Z","iopub.status.idle":"2021-07-07T11:13:54.201237Z","shell.execute_reply.started":"2021-07-07T11:12:45.312355Z","shell.execute_reply":"2021-07-07T11:13:54.199671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nmodel = KNN()\nmodel.fit(X_ros, y_ros)\n\nfrom sklearn import tree\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(model, X_ros, y_ros, scoring='accuracy', cv=kfold, n_jobs=-1)\nprint('Precision: %.3f' % mean(cross_val_score(model, X_ros, y_ros, scoring='precision', cv=kfold, n_jobs=-1)))\nprint('Recall: %.3f' % mean(cross_val_score(model, X_ros, y_ros, scoring='recall', cv=kfold, n_jobs=-1)))\n# report performance\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\ny_train_pred = model.predict(X_ros)\ny_test_pred = model.predict(test_X)\n\nprint(f'Train score {accuracy_score(y_train_pred,y_ros)}')\nprint(f'Test score {accuracy_score(y_test_pred,severity_test_Y)}')\nfrom sklearn.metrics import confusion_matrix\ndef plot_confusionmatrix(y_train_pred,y_train,dom):\n    print(f'{dom} Confusion matrix')\n    cf = confusion_matrix(y_train_pred,y_train)\n    sns.heatmap(cf,annot=True,cmap='Blues', fmt='g')\n    plt.tight_layout()\n    plt.show()\n    \n\nplot_confusionmatrix(y_train_pred,y_ros,dom='Train')    \nplot_confusionmatrix(y_test_pred,title_test_Y,dom='Test')\n\n#from sklearn.metrics import plot_precision_recall_curve\n#plot_precision_recall_curve(model, X_ros, y_ros)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:27:06.212442Z","iopub.execute_input":"2021-07-06T08:27:06.212844Z","iopub.status.idle":"2021-07-06T08:28:43.282403Z","shell.execute_reply.started":"2021-07-06T08:27:06.212812Z","shell.execute_reply":"2021-07-06T08:28:43.280235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression (For explainable)\nlr_model = LogisticRegression(max_iter=np.inf,solver='sag', class_weight='Balanced')\nlr_model.fit(X_ros, y_ros)\npredictions2 = lr_model.predict(test_X)\nfrom sklearn import tree\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(lr_model, X_ros, y_ros, scoring='accuracy', cv=kfold, n_jobs=-1)\nprint('Precision: %.3f' % mean(cross_val_score(lr_model, X_ros, y_ros, scoring='precision', cv=kfold, n_jobs=-1)))\nprint('Recall: %.3f' % mean(cross_val_score(lr_model, X_ros, y_ros, scoring='recall', cv=kfold, n_jobs=-1)))\n# report performance\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#from sklearn.metrics import confusion_matrix\n#cm = confusion_matrix(test_Y, predictions2)\n#print(cm)\n#from sklearn.metrics import r2_score\n#print(r2_score(test_Y, predictions2)\n\nfrom sklearn.metrics import plot_precision_recall_curve\nplot_precision_recall_curve(lr_model, X_ros, y_ros)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T09:09:04.801021Z","iopub.status.idle":"2021-07-05T09:09:04.801603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model, decomposition, datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nstd_slc = StandardScaler()\npca = decomposition.PCA()\nlogistic_Reg = linear_model.LogisticRegression(max_iter=np.inf)\n\npipe = Pipeline(steps=[('std_slc', std_slc),\n                           ('pca', pca),\n                           ('logistic_Reg', logistic_Reg)])\nn_components = list(range(1,X.shape[1]+1,1))\n\nC = np.logspace(-4, 4, 50)\npenalty = ['l2']\n\nparameters = dict(pca__n_components=n_components,\n                      logistic_Reg__C=C,\n                      logistic_Reg__penalty=penalty)\nclf_GS = GridSearchCV(pipe, parameters)\nclf_GS.fit(X, y)\n\nprint('Best Penalty:', clf_GS.best_estimator_.get_params()['logistic_Reg__penalty'])\nprint('Best C:', clf_GS.best_estimator_.get_params()['logistic_Reg__C'])\nprint('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\nprint(clf_GS.best_estimator_.get_params()['logistic_Reg'])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T09:33:56.885531Z","iopub.execute_input":"2021-07-05T09:33:56.885897Z","iopub.status.idle":"2021-07-05T09:34:44.591708Z","shell.execute_reply.started":"2021-07-05T09:33:56.885862Z","shell.execute_reply":"2021-07-05T09:34:44.588817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression (For explainable)\nlr_model = LogisticRegression(solver='sag', class_weight='balanced')\nlr_model.fit(X_ros, y_ros)\npredictions2 = lr_model.predict(test_X)\nfrom sklearn import tree\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(lr_model, X_ros, y_ros, scoring='accuracy', cv=kfold, n_jobs=-1)\nprint('Precision: %.3f' % mean(cross_val_score(lr_model, X_ros, y_ros, scoring='precision', cv=kfold, n_jobs=-1)))\nprint('Recall: %.3f' % mean(cross_val_score(lr_model, X_ros, y_ros, scoring='recall', cv=kfold, n_jobs=-1)))\n# report performance\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#from sklearn.metrics import confusion_matrix\n#cm = confusion_matrix(test_Y, predictions2)\n#print(cm)\n#from sklearn.metrics import r2_score\n#print(r2_score(test_Y, predictions2))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T09:36:30.120906Z","iopub.execute_input":"2021-07-05T09:36:30.121276Z","iopub.status.idle":"2021-07-05T10:15:38.233342Z","shell.execute_reply.started":"2021-07-05T09:36:30.12123Z","shell.execute_reply":"2021-07-05T10:15:38.231291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes Algorithm (Since the dataset is a bit too large too)\nnb_model = GaussianNB()\nnb_model.fit(X_ros,y_ros)\nfrom sklearn import tree\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(nb_model, X_ros, y_ros, scoring='accuracy', cv=kfold, n_jobs=-1)\nprint('Precision: %.3f' % mean(cross_val_score(nb_model, X_ros, y_ros, scoring='precision', cv=kfold, n_jobs=-1)))\nprint('Recall: %.3f' % mean(cross_val_score(nb_model, X_ros, y_ros, scoring='recall', cv=kfold, n_jobs=-1)))\n# report performance\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n\npredictions3 = nb_model.predict(test_X)\n#print(accuracy_score(predictions3,test_Y))\n#print(precision_score(predictions3,test_Y))\n#print(recall_score(predictions3,test_Y))\n#from sklearn.metrics import confusion_matrix\n#cm = confusion_matrix(test_Y, predictions3)\n#print(cm)\n#from sklearn.metrics import r2_score\n#print(r2_score(test_Y, predictions3))\nfrom sklearn.metrics import plot_precision_recall_curve\nplot_precision_recall_curve(nb_model, X_ros, y_ros)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T08:17:32.3578Z","iopub.execute_input":"2021-07-06T08:17:32.358548Z","iopub.status.idle":"2021-07-06T08:17:33.976674Z","shell.execute_reply.started":"2021-07-06T08:17:32.358507Z","shell.execute_reply":"2021-07-06T08:17:33.974651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\n# roc curve for models\nfpr1, tpr1, thresh1 = roc_curve(test_Y, y_test_pred, pos_label=1)\nfpr2, tpr2, thresh2 = roc_curve(test_Y, predictions2, pos_label=1)\nfpr3, tpr3, thresh3 = roc_curve(test_Y, predictions3, pos_label=1)\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(test_Y))]\np_fpr, p_tpr, _ = roc_curve(test_Y, random_probs, pos_label=1)\n\nfrom sklearn.metrics import roc_auc_score\n\n# auc scores\nauc_score1 = roc_auc_score(test_Y, y_test_pred)\nauc_score2 = roc_auc_score(test_Y, predictions2)\nauc_score3 = roc_auc_score(test_Y, predictions3)\n\nplt.style.use('seaborn')\n\n# plot roc curves\nplt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Decision Tree')\nplt.plot(fpr2, tpr2, linestyle='--',color='green', label='Logistic Regression')\nplt.plot(fpr3, tpr3, linestyle='--',color='yellow', label='Naive Bayes')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC.pdf',dpi=300)\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-07-05T09:09:04.806456Z","iopub.status.idle":"2021-07-05T09:09:04.806781Z"},"trusted":true},"execution_count":null,"outputs":[]}]}