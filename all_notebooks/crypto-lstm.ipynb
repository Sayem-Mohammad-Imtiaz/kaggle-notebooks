{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Bitcoin minute-by-minute predictions**","metadata":{}},{"cell_type":"markdown","source":"# This is a work in progress. I am updating this code, and it  will be featured in a Medium article. ","metadata":{}},{"cell_type":"markdown","source":"## If this notebook gets 10 upvotes I will release the Inference code notebook for real time deployment.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets, linear_model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport requests\nimport joblib\n\n\n# fix random seed for reproducibility\nnp.random.seed(7)\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-21T12:40:51.972262Z","iopub.execute_input":"2021-05-21T12:40:51.972568Z","iopub.status.idle":"2021-05-21T12:40:57.589905Z","shell.execute_reply.started":"2021-05-21T12:40:51.972494Z","shell.execute_reply":"2021-05-21T12:40:57.589182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load in Data","metadata":{}},{"cell_type":"code","source":"path_name = \"../input/392-crypto-currency-pairs-at-minute-resolution/btcusd.csv\" \ndf = pd.read_csv(path_name, index_col='time')\ndf.index = pd.to_datetime(df.index, unit='ms')\ndf = df[~df.index.duplicated(keep='first')]\ndf = df.resample('1T').pad()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:40:57.59331Z","iopub.execute_input":"2021-05-21T12:40:57.593578Z","iopub.status.idle":"2021-05-21T12:41:01.995334Z","shell.execute_reply.started":"2021-05-21T12:40:57.593551Z","shell.execute_reply":"2021-05-21T12:41:01.994372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get scaled differences between open and close\ndf['delta'] = (df.close - df.open) / df.open\n# Adding a previous close column\ndf['prev_close'] = df['close'].shift(1)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:01.996663Z","iopub.execute_input":"2021-05-21T12:41:01.997124Z","iopub.status.idle":"2021-05-21T12:41:02.116337Z","shell.execute_reply.started":"2021-05-21T12:41:01.997085Z","shell.execute_reply":"2021-05-21T12:41:02.115535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.117432Z","iopub.execute_input":"2021-05-21T12:41:02.117759Z","iopub.status.idle":"2021-05-21T12:41:02.401768Z","shell.execute_reply.started":"2021-05-21T12:41:02.117724Z","shell.execute_reply":"2021-05-21T12:41:02.40091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.405063Z","iopub.execute_input":"2021-05-21T12:41:02.405422Z","iopub.status.idle":"2021-05-21T12:41:02.4198Z","shell.execute_reply.started":"2021-05-21T12:41:02.405384Z","shell.execute_reply":"2021-05-21T12:41:02.418851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.plot(df.index[-100000:], df.close[-100000:])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.421685Z","iopub.execute_input":"2021-05-21T12:41:02.422129Z","iopub.status.idle":"2021-05-21T12:41:02.636534Z","shell.execute_reply.started":"2021-05-21T12:41:02.422078Z","shell.execute_reply":"2021-05-21T12:41:02.635703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Univariate LSTM","metadata":{}},{"cell_type":"markdown","source":"## Prepare Dataset","metadata":{}},{"cell_type":"code","source":"def create_dataset(dataset, look_back=5):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.637746Z","iopub.execute_input":"2021-05-21T12:41:02.638243Z","iopub.status.idle":"2021-05-21T12:41:02.644371Z","shell.execute_reply.started":"2021-05-21T12:41:02.638204Z","shell.execute_reply":"2021-05-21T12:41:02.643642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = df['close'][-100000:].values\ndataset = dataset.astype('float32')\ndataset = dataset.reshape(-1, 1)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.645507Z","iopub.execute_input":"2021-05-21T12:41:02.645917Z","iopub.status.idle":"2021-05-21T12:41:02.656196Z","shell.execute_reply.started":"2021-05-21T12:41:02.645877Z","shell.execute_reply":"2021-05-21T12:41:02.655026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n# split into train and test sets\ntrain_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.65795Z","iopub.execute_input":"2021-05-21T12:41:02.658354Z","iopub.status.idle":"2021-05-21T12:41:02.667703Z","shell.execute_reply.started":"2021-05-21T12:41:02.658316Z","shell.execute_reply":"2021-05-21T12:41:02.666771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reshape into X=t and Y=t+1\nlook_back = 6\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n# reshape input to be [samples, time steps, features]\ntrainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\ntestX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:41:02.669351Z","iopub.execute_input":"2021-05-21T12:41:02.670008Z","iopub.status.idle":"2021-05-21T12:41:02.841789Z","shell.execute_reply.started":"2021-05-21T12:41:02.669956Z","shell.execute_reply":"2021-05-21T12:41:02.840907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(4, input_shape=(look_back, 1)))\nmodel.add(Dense(8))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:42:59.81689Z","iopub.execute_input":"2021-05-21T12:42:59.817258Z","iopub.status.idle":"2021-05-21T12:47:04.742757Z","shell.execute_reply.started":"2021-05-21T12:42:59.817226Z","shell.execute_reply":"2021-05-21T12:47:04.742048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:47:52.186727Z","iopub.execute_input":"2021-05-21T12:47:52.187065Z","iopub.status.idle":"2021-05-21T12:49:28.853656Z","shell.execute_reply.started":"2021-05-21T12:47:52.187036Z","shell.execute_reply":"2021-05-21T12:49:28.852929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shift train predictions for plotting\ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nplt.figure(figsize=(15,10))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:49:28.856705Z","iopub.execute_input":"2021-05-21T12:49:28.856973Z","iopub.status.idle":"2021-05-21T12:49:29.059488Z","shell.execute_reply.started":"2021-05-21T12:49:28.856936Z","shell.execute_reply":"2021-05-21T12:49:29.058618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save Model","metadata":{}},{"cell_type":"code","source":"# Scaler\nscaler_filename = \"scaler.save\"\njoblib.dump(scaler, scaler_filename) \n# Model\nmodel.save('keras_lstm_uni.h5')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T12:42:45.099496Z","iopub.status.idle":"2021-05-21T12:42:45.100214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thanks for making it to the end! I'm only two bronze medals away from Kaggle Expert (searching for jobs so maybe it would look cool on my LinkedIn?) so please leave a upvote if you enjoyed this notebook and/or know the struggle of job searching!","metadata":{}}]}