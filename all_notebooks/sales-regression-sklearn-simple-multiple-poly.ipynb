{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n\nThe objective is to create a **linear regression model** for a given dataset( House Sales in King County, USA). The overall idea of regression is to examine two things: (1) does a set of predictor variables do a good job in predicting an outcome (dependent) variable?  (2) Which variables in particular are significant predictors of the outcome variable, and in what way do they–indicated by the magnitude and sign of the beta estimates–impact the outcome variable?  These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.\n\n**Linear Regression Analysis** consists of more than just fitting a linear line through a cloud of data points.  It consists of 3 stages – (1) analyzing the correlation and directionality of the data, (2) estimating the model, i.e., fitting the line, and (3) evaluating the validity and usefulness of the model.\n\n## Regressions Performed\n\n\n**Simple Linear Regression:** <br>\n<br>\n1) 'bedrooms' vs 'price'<br>\n2) 'grade' vs 'price'<br>\n                         \n**Multiple Regression:** <br><br>\n1) 'bedrooms','grade', 'sqft_living', 'sqft_above'<br>\n2) 'bedrooms','bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'grade',                                     'sqft_above', 'sqft_basement', 'lat', 'sqft_living15'\n\n**Polynomial Regression:**<br>\n<br> 1) degree=2<br>\n2) degree=3\n"},{"metadata":{},"cell_type":"markdown","source":"# Data\n\n## Description\n\nIn this dataset we have to predict the **sales price of houses in King County, Seattle**. It includes homes sold between May 2014 and May 2015. Before doing anything we should first know about the dataset what it contains what are its features and what is the structure of data.\n\nThe dataset cantains 20 house features plus the price, along with 21613 observations.\n\nThe description for the 20 features is given below:\n\n1. id :- It is the unique numeric number assigned to each house being sold.\n2. date :- It is the date on which the house was sold out.\n3. price:- It is the price of house which we have to predict so this is our target variable and aprat from it are our features.\n4. bedrooms :- It determines number of bedrooms in a house.\n5. bathrooms :- It determines number of bathrooms in a bedroom of a house.\n6. sqft_living :- It is the measurement variable which determines the measurement of house in square foot.\n7. sqft_lot : It is also the measurement variable which determines square foot of the lot.\n8. floors: It determines total floors means levels of house.\n9. waterfront : This feature determines whether a house has a view to waterfront 0 means no 1 means yes.\n10. view : This feature determines whether a house has been viewed or not 0 means no 1 means yes.\n11. condition : It determines the overall condition of a house on a scale of 1 to 5.\n12. grade : It determines the overall grade given to the housing unit, based on King County grading system on a scale of 1 to 11\n13. sqft_above : It determines square footage of house apart from basement.\n14. sqft_basement : It determines square footage of the basement of the house.\n15. yr_built : It detrmines the date of building of the house.\n16. yr_renovated : It detrmines year of renovation of house.\n17. zipcode : It determines the zipcode of the location of the house.\n18. lat : It determines the latitude of the location of the house.\n19. long : It determines the longitude of the location of the house.\n20. sqft_living15 : Living room area in 2015(implies-- some renovations)\n21. sqft_lot15 : lotSize area in 2015(implies-- some renovations)\n\nBy observing the data, we can know that the **price is dependent on various features** like bedrooms(which is most dependent feature), bathrooms, sqft_living(second most important feature), sqft_lot, floors etc. The price is also dependent on the location of the house where it is present. The other features like waterfront, view are less dependent on the price. Of all the records, there are **no missing values, which helps us creating better model.** \n\nFirst, we **import** the required libraries like pandas, numpy, seaborn, matplotlib. Now import the **csv file.** Now we should get to know how the data is, what datatype using info function. We observe that date is in 'object' format. To know the no of rows and columns we use shape function. Describe the dataframe to know the mean, minumum, ,maximum, standard deviation, percentiles. \n\nThen plot graphs for visualization and then we do simple regression using 'bedrooms', multiple regression and polynomial regression. \n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing numpy and pandas, seaborn\n\nimport numpy as np #linear algebra\nimport pandas as pd #datapreprocessing, CSV file I/O\nimport seaborn as sns #for plotting graphs\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/housesalesprediction/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding no of rows and columns\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bedrooms'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['waterfront'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['grade'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['condition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.bedrooms,order=df['bedrooms'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))\nplt.title('house prices by sqft_living')\nplt.xlabel('sqft_living')\nplt.ylabel('house prices')\nplt.legend()\nsns.barplot(x='sqft_living',y='price',data=df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))\nplt.title(\"house prices by sqft_above\")\nplt.xlabel('sqft_above')\nplt.ylabel('house prices')\nplt.legend()\nsns.barplot(x='sqft_above',y='price',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist('sqft_living',data=df,bins=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))\nsns.distplot(df['sqft_living'],hist=True,kde=True,rug=False,label='sqft_living',norm_hist=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(nrows=1,ncols=1,figsize=(15,10))\nsns.distplot(df['sqft_above'],hist=True,kde=True,rug=False,label='sqft_above',norm_hist=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean',round(df['sqft_living'].mean(),2))\nprint('Median',df['sqft_living'].median())\nprint('Mode',df['sqft_living'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[df['sqft_living']==1300])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation_heatmap(df1):\n    _,ax=plt.subplots(figsize=(15,10))\n    colormap=sns.diverging_palette(220,10,as_cmap=True)\n    sns.heatmap(df.corr(),annot=True,cmap=colormap)\n    \ncorrelation_heatmap(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,test_data=train_test_split(df,train_size=0.8,random_state=3)\nreg=linear_model.LinearRegression()\nx_train=np.array(train_data['sqft_living']).reshape(-1,1)\ny_train=np.array(train_data['price']).reshape(-1,1)\nreg.fit(x_train,y_train)\n\nx_test=np.array(test_data['sqft_living']).reshape(-1,1)\ny_test=np.array(test_data['price']).reshape(-1,1)\npred=reg.predict(x_test)\nprint('linear model')\nmean_squared_error=metrics.mean_squared_error(y_test,pred)\nprint('Sqaured mean error', round(np.sqrt(mean_squared_error),2))\nprint('R squared training',round(reg.score(x_train,y_train),3))\nprint('R sqaured testing',round(reg.score(x_test,y_test),3) )\nprint('intercept',reg.intercept_)\nprint('coefficient',reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(figsize= (12, 10))\nplt.scatter(x_test, y_test, color= 'darkgreen', label = 'data')\nplt.plot(x_test, reg.predict(x_test), color='red', label= ' Predicted Regression line')\nplt.xlabel('Living Space (sqft)')\nplt.ylabel('price')\nplt.legend()\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['right'].set_visible(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data,test_data=train_test_split(df,train_size=0.8,random_state=3)\nreg=linear_model.LinearRegression()\nx_train=np.array(train_data['grade']).reshape(-1,1)\ny_train=np.array(train_data['price']).reshape(-1,1)\nreg.fit(x_train,y_train)\n\nx_test=np.array(test_data['grade']).reshape(-1,1)\ny_test=np.array(test_data['price']).reshape(-1,1)\npred=reg.predict(x_test)\nprint('linear model')\nmean_squared_error=metrics.mean_squared_error(y_test,pred)\nprint('squared mean error',round(np.sqrt(mean_squared_error),2))\nprint('R squared training',round(reg.score(x_train,y_train),3))\nprint('R squared testing',round(reg.score(x_test,y_test),3))\nprint('intercept',reg.intercept_)\nprint('coeeficient',reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multiple Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(2,1,figsize=(15,10))\nsns.boxplot(x=train_data['grade'],y=train_data['price'],ax=ax[0])\nsns.boxplot(x=train_data['bedrooms'],y=train_data['price'],ax=ax[1])\n_ , axes = plt.subplots(1, 1, figsize=(15,10))\nsns.boxplot(x=train_data['bathrooms'],y=train_data['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features1=['bedrooms','grade','sqft_living','sqft_above']\nreg=linear_model.LinearRegression()\nreg.fit(train_data[features1],train_data['price'])\npred=reg.predict(test_data[features1])\nprint('complex_model 1')\nmean_squared_error=metrics.mean_squared_error(y_test,pred)\nprint('mean squared error(MSE)', round(np.sqrt(mean_squared_error),2))\nprint('R squared training',round(reg.score(train_data[features1],train_data['price']),3))\nprint('R squared training', round(reg.score(test_data[features1],test_data['price']),3))\nprint('Intercept: ', reg.intercept_)\nprint('Coefficient:', reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features1 = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','grade','sqft_above','sqft_basement','lat','sqft_living15']\nreg= linear_model.LinearRegression()\nreg.fit(train_data[features1],train_data['price'])\npred = reg.predict(test_data[features1])\nprint('Complex Model_2')\nmean_squared_error = metrics.mean_squared_error(y_test, pred)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(reg.score(train_data[features1], train_data['price']), 3))\nprint('R-squared (testing) ', round(reg.score(test_data[features1], test_data['price']), 3))\nprint('Intercept: ', reg.intercept_)\nprint('Coefficient:', reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Polynomial Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"polyfeat=PolynomialFeatures(degree=2)\nxtrain_poly=polyfeat.fit_transform(train_data[features1])\nxtest_poly=polyfeat.fit_transform(test_data[features1])\n\npoly=linear_model.LinearRegression()\npoly.fit(xtrain_poly,train_data['price'])\npolypred=poly.predict(xtest_poly)\n\nprint('Complex Model_3')\nmean_squared_error = metrics.mean_squared_error(test_data['price'], polypred)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))\nprint('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"polyfeat=PolynomialFeatures(degree=3)\nxtrain_poly=polyfeat.fit_transform(train_data[features1])\nxtest_poly=polyfeat.fit_transform(test_data[features1])\n\npoly=linear_model.LinearRegression()\npoly.fit(xtrain_poly,train_data['price'])\npolypred=poly.predict(xtest_poly)\n\nprint('complex model_4')\nmean_squared_error=metrics.mean_squared_error(test_data['price'],polypred)\nprint('Mean Squared Error (MSE) ', round(np.sqrt(mean_squared_error), 2))\nprint('R-squared (training) ', round(poly.score(xtrain_poly, train_data['price']), 3))\nprint('R-squared (testing) ', round(poly.score(xtest_poly, test_data['price']), 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observation/Result"},{"metadata":{},"cell_type":"markdown","source":"Complex Model_3 gives us R-squared (testing) score of 0.759. From above reports, we can conclude that Polynomial regression is best solution."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}