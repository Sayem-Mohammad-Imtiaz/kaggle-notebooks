{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting Mines or Rocks with Keras and TensorFlow\n\nUsing Keras library with TensorFlow backend, three Multilayer perceptron models were built and evaluated using KFold cross validation.\n```\n1. Model 1 - Input (60) - Hidden (60) - Output (1)\n2. Model 2 - Input (60) - Hidden (30) - Output (1)\n3. Model 3 - Input (60) - Hidden (60) - Hidden (60) - Output (1)\n```\n\nWhile training and evaluating models, standardization is being learned on each fold and applied to the validation fold. This is achieved using `StandardScaler()` function of `sklearn.preprocessing` and passing it to the sklearn's `make_pipeline` method","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.pipeline import make_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nfrom tensorflow.random import set_seed\nfrom numpy.random import seed\nseed(SEED)\nset_seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"### Loading the dataset ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mines-vs-rocks/sonar.all-data.csv', header = None)\ndf = df.values\nX = df[:,0:60].astype(float)\nY = df[:,60]\nprint ('X Shape :', X.shape)\nprint ('Y Shape :', Y.shape)\nprint ('Number of Unique Values in Y:', set(Y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepping Y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nY_encoded = encoder.fit_transform(Y).astype(int)\nprint ('Shape of Y_encoded :', len(Y_encoded))\nprint ('Unique values in Y_encoded :', list(set(Y_encoded)))\nprint ('Inverse transforming : ', encoder.inverse_transform(list(set(Y_encoded))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepping X","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_transformed = ss.fit_transform(X)\nX_transformed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline_model():\n    \n    model = Sequential()\n    model.add(Dense(60, input_dim=(60), activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    \n    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building a single model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"single_model = baseline_model()\n%time history = single_model.fit(X_transformed, Y_encoded, epochs = 200, batch_size = 8, verbose = 0, validation_split = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating Model using K-Fold Crossvalidation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS     = 50\nBATCH_SIZE = 8\nVERBOSE    = 0\nFOLDS      = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nestimators = make_pipeline(StandardScaler(), KerasClassifier(build_fn = baseline_model, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = VERBOSE))\nresults = cross_val_score(estimators, X, Y_encoded, cv = kfold)\nprint (f'Mean Accuracy : {round(results.mean()*100,2)} %, Std. dev : {round(results.std()*100,2)}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Trying out a small network\nReducing the number of hidden layer dimensions after the input dimension to 30 from 60 will put pressure on the network get the most important structure of the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ndef small_model():\n    model = Sequential()\n    model.add(Dense(30, input_dim=(60), activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n    return model\n\nkfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nestimators = make_pipeline(StandardScaler(), KerasClassifier(build_fn = small_model, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = VERBOSE))\nresults = cross_val_score(estimators, X, Y_encoded, cv = kfold)\nprint (f'Mean Accuracy : {round(results.mean()*100,2)} %, Std. dev : {round(results.std()*100,2)}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got an equally good model with a smaller network","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Evaluating a larger network\n\nEvaluating a larger Network - A neural network topology with more layers offers more opportunity for the network to extract key features and combined them in useful non-linear ways","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ndef large_model():\n    model = Sequential()\n    model.add(Dense(60, input_dim=(60), activation = 'relu'))\n    model.add(Dense(60, activation = 'relu'))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n    return model\n\nkfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\nestimators = make_pipeline(StandardScaler(), KerasClassifier(build_fn = large_model, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = VERBOSE))\nresults = cross_val_score(estimators, X, Y_encoded, cv = kfold)\nprint (f'Mean Accuracy : {round(results.mean()*100,2)} %, Std. dev : {round(results.std()*100,2)}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy improved with increased hidden layer ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}