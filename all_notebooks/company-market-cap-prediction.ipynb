{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Company Market Cap Prediction  \n  \nGiven *data about big companies*, let's try to predict the **market capitalization** of a given company.  \n  \nWe will use a variety of regression models to make our predictions.","metadata":{}},{"cell_type":"markdown","source":"# Getting Started","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/fortune-500-data-2021/Fortune_1000.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unused columns\n    df = df.drop(['rank', 'rank_change', 'company', 'newcomer', 'prev_rank', 'CEO', 'Website', 'Ticker'], axis=1)\n    \n    # Encode missing values\n    df['Market Cap'] = df['Market Cap'].replace('-', np.NaN).astype(np.float)\n    \n    # Drop missing target rows\n    missing_target_rows = df[df['Market Cap'].isna()].index\n    df = df.drop(missing_target_rows, axis=0).reset_index(drop=True)\n    \n    # Fill remaining missing values\n    df['profit'] = df['profit'].fillna(df['profit'].mean())\n    \n    # Binary encoding\n    for column in ['ceo_founder', 'ceo_woman', 'profitable']:\n        df[column] = df[column].replace({'no': 0, 'yes': 1})\n    \n    # One-hot encoding\n    for column in ['sector', 'city', 'state']:\n        dummies = pd.get_dummies(df[column], prefix=column)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    # Split df into X and y\n    y = df['Market Cap']\n    X = df.drop('Market Cap', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"models = {\n    \"     Linear Regression\": LinearRegression(),\n    \"Linear Regression (L2)\": Ridge(),\n    \"Linear Regression (L1)\": Lasso(),\n    \"         Decision Tree\": DecisionTreeRegressor(),\n    \"        Neural Network\": MLPRegressor(),\n    \"         Random Forest\": RandomForestRegressor(),\n    \"     Gradient Boosting\": GradientBoostingRegressor()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"for name, model in models.items():\n    y_pred = model.predict(X_test)\n    rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n    print(name + \" RMSE: {:.2f}\".format(rmse))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, model in models.items():\n    r2 = model.score(X_test, y_test)\n    print(name + \" R^2 Score: {:.5f}\".format(r2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/fiwSBIS6N9c","metadata":{}}]}