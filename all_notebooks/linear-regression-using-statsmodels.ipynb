{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I am still a very beginner of Data Science field (just started few months ago)\n# So, I will try my best to tackle this dataset.\n# Feel free to comment anything if I have done anything wrong or any improvement needed.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nweather_data = pd.read_csv(\"/kaggle/input/mount-rainier-weather-and-climbing-data/Rainier_Weather.csv\")\nclimb_data = pd.read_csv(\"/kaggle/input/mount-rainier-weather-and-climbing-data/climbing_statistics.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.isnull().sum()\n# no missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"climb_data.isnull().sum()\n# no missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"climb_data.describe()\n# seems like there is an abnormal value (14.2) on column \"Success Percentage\"\n# \"Success Percentage\" shouldn't have value more than 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can combine those two datasets \ndf = weather_data.merge(climb_data, on=\"Date\")\n\ndf.info()\n# we can change that \"Date\" from object format into datetime format\n\ndf.drop([\"Attempted\",\"Succeeded\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n\ndf.info()\n# \"Date\" has changed from object format into datetime format\n\n# we can crete column \"Month\" from \"Date\"\ndf[\"Month\"] = df[\"Date\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################### Exploratory Data Analysis (EDA) #################################\nplt.figure(figsize=(16,8))\nsns.countplot(x=df[\"Route\"])\nplt.xticks(rotation=90)\nplt.show()\n# \"Disapointment Cleaver\" is the highest route taken","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.lineplot(x=df[\"Date\"], y=df[\"Success Percentage\"])\nplt.show()\n# the graph shows that there are high number of \"Success Percentage\" around June to August 2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.lineplot(x=df[\"Month\"], y=df[\"Success Percentage\"])\nplt.show()\n# the graph show that month for the highest number of \"Success Percentage\" is June","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.lineplot(x=df[\"Month\"], y=df[\"Temperature AVG\"], label=\"Temperature\")\nsns.lineplot(x=df[\"Month\"], y=df[\"Relative Humidity AVG\"], label=\"Relative Humidity\")\nsns.lineplot(x=df[\"Month\"], y=df[\"Wind Speed Daily AVG\"], label=\"Wind Speed\")\nplt.show()\n# Judging from the graph, \"Relative Humidity AVG\" and \"Wind Speed Daily AVG\" starts to decrease while \n# \"Temperature AVG\" starts to increase when near month of \"June\".\n# Perhaps, lower \"Relative Humidity AVG\" and \"Wind Speed Daily AVG\", and higher \"Temperature AVG\" will increase the chance of success.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#################################### Feature Engineer our data #############################\n# check for outliers\n\nsns.boxplot(df[\"Success Percentage\"])\n# there is an extreme outlier at around 14","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Battery Voltage AVG\"])\n# there are outliers at lower and upper ends.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Temperature AVG\"])\n# there are outliers at lower end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Relative Humidity AVG\"])\n# no outlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Wind Speed Daily AVG\"])\n# there are outliers at upper end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Wind Direction AVG\"])\n# no outlier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"Solare Radiation AVG\"])\n# there are outliers at lower end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can drop the rows containing \"Success Percentage\" higher than 1\nindex = df[df[\"Success Percentage\"] > 1].index\ndf.drop(index, inplace=True)\n\n# we can change the value of \"Wind Speed Daily AVG\" being 0 into 0.753458 (the second lowest value after 0).\n# it is hard to imagine where there will be totally no wind.\ndf[\"Wind Speed Daily AVG\"] = np.where(df[\"Wind Speed Daily AVG\"] == 0, 0.753458, df[\"Wind Speed Daily AVG\"])\ndf[\"Wind Speed Daily AVG\"] = np.where(df[\"Wind Speed Daily AVG\"] >= 30.02925, 30.02925, df[\"Wind Speed Daily AVG\"])\n\n# we can change the value of \"Solare Radiation AVG\" being 0 into 0.0330833 (the second lowest value after 0).\n# it is hard to imagine where there will be totally no radiation.\ndf[\"Solare Radiation AVG\"] = np.where(df[\"Solare Radiation AVG\"] == 0, 0.0330833, df[\"Solare Radiation AVG\"])\ndf[\"Solare Radiation AVG\"] = np.where(df[\"Solare Radiation AVG\"] <= 22.502249, 22.502249, df[\"Solare Radiation AVG\"])\n\n# we can apply \"top-coding\" and \"bottom-coding\" on those outliers.\n# we can limit cap those outliers with interquantile proximity rule. \ndf[\"Battery Voltage AVG\"] = np.where(df[\"Battery Voltage AVG\"] >= 13.685626, 13.685626, df[\"Battery Voltage AVG\"])\ndf[\"Battery Voltage AVG\"] = np.where(df[\"Battery Voltage AVG\"] <= 13.313955, 13.313955, df[\"Battery Voltage AVG\"])\n\n# we can limit cap those outliers as well.\ndf[\"Temperature AVG\"] = np.where(df[\"Temperature AVG\"] <= 10.4985425, 10.4985425, df[\"Temperature AVG\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Route\"].nunique()\n# it has 22 unique values which are quite a lot.\n# it is a high cardinality variable.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Route\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I decided to keep only top 9 highest counts of unique values.\n# As for the rest, I will group all of them under a new value \"Others\".\n\nRoute = pd.Series(df[\"Route\"].value_counts())\nRoute_to_keep = Route.index[0:9]\nRoute_to_remove = [i for i in df[\"Route\"].unique() if i not in Route_to_keep]\n\nfor i in Route_to_remove:\n    df[\"Route\"] = np.where(df[\"Route\"] == i, \"Others\", df[\"Route\"])\n\ndf[\"Route\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply one hot encoding on \"Route\" variable\ndummies = pd.get_dummies(df[\"Route\"], drop_first=True)\ndf = pd.concat([dummies, df], axis=1)\ndf.drop(\"Route\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"Date\", \"Month\"], axis=1, inplace=True)\n# I am not going to put these two variables into my model building\n\n# check for correlation\ncorrmat = df.corr()\nplt.figure(figsize=(16,8))\nsns.heatmap(df.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I am going to check what is the correlation between \"Success Percentage\" and other variables\ncorrmat = df.corr()\ncorrmat[\"Success Percentage\"].abs().sort_values(ascending=False)\n\n# from the result, we can observe that \"Success Percentage\" does not have strong correlation with any other variables.\n# I do not think our linear regression model is going to work very well on this data.\n# Anyway, we still go ahead and try it out.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the data\n\ndef norm_func(i):\n    return ((i-i.min()) / (i.max()-i.min()))\n\ndf = df.apply(norm_func)\n\ndf.describe()\n# all variables are being kept in range between 0 and 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data into predictors and output\nX = df.drop(\"Success Percentage\", axis=1)\nY = df[\"Success Percentage\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data into train and test datasets.\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####################################### Model Building #####################################\nfrom statsmodels.regression.linear_model import OLS\n\nmodel = OLS(Y_train, X_train).fit()\nmodel.summary()\n# seems like there are many variables with p_value more than 0.05\n# we can drop those variables with p-value more than 0.05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop([\"Emmons-Winthrop\", \"Gibralter Ledges\", \"Ingraham Direct\", \"Kautz Glacier\", \"Liberty RIngraham Directge\", \"Little Tahoma\", \"Others\", \"Wind Direction AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\"], axis=1)\nX_test = X_test.drop([\"Emmons-Winthrop\", \"Gibralter Ledges\", \"Ingraham Direct\", \"Kautz Glacier\", \"Liberty RIngraham Directge\", \"Little Tahoma\", \"Others\", \"Wind Direction AVG\", \"Relative Humidity AVG\", \"Wind Speed Daily AVG\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rebuild the same model with new training data\n\nmodel = OLS(Y_train, X_train).fit()\nmodel.summary()\n# seems like \"Temperature AVG\" now has p-value more than 0.05\n# so we can drop that variable as well.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.drop(\"Temperature AVG\", axis=1)\nX_test = X_test.drop(\"Temperature AVG\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = OLS(Y_train, X_train).fit()\nmodel.summary()\n\n# we can observe that adjusted R-squared is only 0.527.\n# perhaps due to our dependent variable (\"Success Percentage\") does not has any strong correlation with any predictors.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the model with mean-squared-error\nfrom sklearn.metrics import mean_squared_error\n\npred = model.predict(X_test)\nmean_squared_error(Y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As a conclusion, I am not going to say that this model is very good since mean_squared error is quite large.\n# Maybe we still lack of other significant information such as how many mountains have those climbers climbed before (veteran or rookie), years of experience being climbers, etc","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}