{"cells":[{"metadata":{},"cell_type":"markdown","source":"Semantic segmentation refers to the process of linking each pixel in an image to a class label. These labels could include a person, car, flower, piece of furniture, etc., just to mention a few. We can think of semantic segmentation as image classification at a pixel level. https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSlxW_H3CMwIcKZb48Hu8c9w3uG5VNx5cOhG3WZBzjtX1xN2rfq',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image qiita.com - Pascal VOCをTFRecord形式へ変換する(Python) - @Jixjia - https://qiita.com/Jixjia/items/a465e9cdd94b8b8f555e"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRRffmJENxcC0fHkOcQwpSDHbJzRummirTVpbp3s3eu5cdsyu4C',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image towardsdatascience.com"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/the-2019-ai-index-report/AI INDEX 2019 PUBLIC DATA/3. Technical Performance/Vision/Semantic Segmentation/Pascal VOC 2012.xlsx')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ4o6X4ArRuD0xKvGv_BcH5f0JjUGCbKrki6RY8TI_rGXrJZrE2',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image liangchiehchen.com"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"Rank\"].apply(lambda x: x**4))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRL6MG_xa-oDBV0qkhvsiYObhATzVnWDAMYmLXzkJRepHbEHHB6',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image developpaper.com"},{"metadata":{"trusted":true},"cell_type":"code","source":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df.Method)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200, background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['Rank']).size().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Necessary Functions: \ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py\nvalue_counts = df['Rank'].value_counts()\nlabels = value_counts.index.tolist()\npy.iplot(pie_plot(labels, value_counts,['#1B9E77', '#7570B3'], \"Rank\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_excel('/kaggle/input/the-2019-ai-index-report/AI INDEX 2019 PUBLIC DATA/3. Technical Performance/Vision/Semantic Segmentation/PASCAL Context.xlsx')\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrs = df.corr()\ncorrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 8))\n\n# Heatmap of correlations\nsns.heatmap(corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('Rank');","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRyoIYh0Dppmng9zFdht3bSnbhqm_QhsIhfpwI_WuNcqMxxE2Y6',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image link.springer.com - Recent progress in semantic image segmentation - Liu, X., Deng, Z. & Yang, Y. Recent progress in semantic image segmentation. Artif Intell Rev 52, 1089–1106 (2019). https://doi.org/10.1007/s10462-018-9641-3"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(corrs, annot=True, cmap=\"Greens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTZ34lHxrxnwtUYrs0vahh557PGs0p1w29MQKShHWoaHG5Hlu4i',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image jifengdai.org - ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation - Di Lin1*     Jifeng Dai2     \n\nJiaya Jia1     Kaiming He2     Jian Sun2    \n* 1The Chinese University of Hong Kong    2Microsoft Research (*This work was done when Di Lin was an intern at Microsoft Research)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRp_dnEZMYDm9Cu1Hd_50XYu-U5krj3bIoOHm8md6kWSJekZUJH',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image cvlab.postech.ac.kr - Weakly Supervised Semantic Segmentation using Web-Crawled Videos - \n* Seunghoon Hong1,3\tDonghun Yeo1\tSuha Kwak2\tHonglak Lee3\tBohyung Han1\n* 1Dept. of Computer Science and Engineering, POSTECH, Korea\n* 2Dept. of Information and Communication Engineering, DGIST, Korea\n* 3Dept. of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA - http://cvlab.postech.ac.kr/research/weaksup_video/"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df1, markers=\"+\", diag_kind=\"kde\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQyGx5LP4021dw6yLDfSFavtrqxmMunb6rEzTVGdR0SUsALI7iY',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image link.springer.com - Deep-recursive residual network for image semantic segmentation - Zhang, Y., Li, X., Lin, M. et al. Deep-recursive residual network for image semantic segmentation. Neural Comput & Applic (2020). https://doi.org/10.1007/s00521-020-04738-5"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(corrs, annot=True, cmap=\"Reds\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSfdUmiIYut4f-zGLoo8fkxMZbp_7Z9u9nkT9V5YwIg70WKXGzl',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image arxiv-vanity.com - Recurrent Segmentation for Variable Computational."},{"metadata":{"trusted":true},"cell_type":"code","source":"segmentation = df1[\"Method\"]\nprint(segmentation)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQGsErxC94shrO-JYxcNvevFvg9vga1gVLP3nMcqiATY0kTu_5o',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image paperwithcode.com - Semantic Segmentation on PASCAL VOC 2012 val "},{"metadata":{"trusted":true},"cell_type":"code","source":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in df1.Method)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(width=480, height=480, margin=0, background_color=\"white\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcToSMV0NAjWMl6RtMlYEfXr7XYFo6b3JbKStTzsdE8EXTu7Tycg',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image paperswithcode.com - RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation - CVPR 2017 • Guosheng Lin • Anton Milan • Chunhua Shen • Ian Reid - https://paperswithcode.com/paper/refinenet-multi-path-refinement-networks-for"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='Rank',y='mean Iou',data=df)\nplt.xticks(rotation=90)\nplt.yticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Intersection-Over-Union (IoU), also known as the Jaccard Index, is one of the most commonly used metrics in semantic segmentation and for good reason. For binary (two classes) or multi-class segmentation, the mean IoU of the image is calculated by taking the IoU of each class and averaging them. https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRgjAwRIP-XEJj92m896UP9qemqzEvlltk9Ouwl4HwUz1KHmJck',width=400,height=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image d2I.ai - Semantic Segmentation and the Dataset - https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}