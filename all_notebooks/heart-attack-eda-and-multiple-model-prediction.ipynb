{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom sklearn.metrics import mean_absolute_error, accuracy_score, classification_report,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#load the heart attack dataset and view the features       \nfile_path_name = \"../input/heart-disease-uci/heart.csv\" \nheart_data = pd.read_csv(file_path_name)\nheart_data.head()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check for null values and proceed with next steps if there are no null values\nheart_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change the feature names to easily understable names\nheart_data.columns= ['Age','Sex','Chest Pain Type','Rest BP','Cholestrol','FBS','RestECG','Max Heart Rate','Exer Angina','Prev Peak','Slope','No of Major Vessels','Thal Rate','Target']\n\n#see the data type and value details of all variable\nheart_data.info()\nheart_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initial peek into the data shows that there aare no missing values or null values. It looks clean and we can proceed with the next steps.\n","metadata":{}},{"cell_type":"code","source":"#check the correlation\nplt.figure(figsize=(12,10))\nsns.heatmap(heart_data.corr(),annot=True,square=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the above correlation map, the below 3 features have some positive relation with heart attack (the target).\n1. Chest Pain Type, \n2. Maximum Heart rate\n3. Slope \n\nAnd the below features have negative relation with heart attack. (the target)\n 1. Excercize Angina\n 2. Previous Peak\n 3. No of Major vessels\n 4. Thal rate","metadata":{}},{"cell_type":"markdown","source":"Draw and Visualize the relation between features and the target","metadata":{}},{"cell_type":"code","source":"#draw box plot to get some insight on the relationship of features \nplt.figure(figsize=(12,8))\nsns.boxplot(x=heart_data['Target'],y=heart_data['Age'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize the relationship between Chest Pain type and chance of a heart attack\nplt.figure(figsize=(20,8))\nsns.boxplot(x=heart_data['Target'], y = heart_data['Chest Pain Type'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize the relationship between Maximum heart rate and chance of a heart attack\nplt.figure(figsize=(20,8))\nsns.boxplot(x=heart_data['Target'], y = heart_data['Max Heart Rate'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize the relationship between Slope and chance of a heart attack\nplt.figure(figsize=(20,8))\nsns.boxplot(x=heart_data['Target'], y=heart_data['Slope'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot histogram for each feature to get some insight \nheart_data.hist(figsize=(12,8))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above we can see some observations.\n1. People about the age of 60 have more risk of having a heart attack compare to other age group.\n2. People with sex = 1 have double the risk of having a heart attack when compare to people with sex = 0.\n3. People with Chest pain type 0 have higest risk of heart attack followed by type 2\n4. People with resting BP of between 130-140 have higher risk of having heart attack\n5.People with Cholesterol in the range 210-260 have higest risk of having a heart attack\n6. FBS seem not to effect heart attack\n7. People with maximum heart rate in the range 150-175 have higher risk of heart attack\n8.Exercise Angina has no effect on heart attack\n9.People with Thaal rate 2 and 3 have higher risk\n10. All other features donot have any direct impact with hear attack","metadata":{}},{"cell_type":"markdown","source":"Preparation work and build Models","metadata":{}},{"cell_type":"code","source":"#Prepare and split training and test data\nX = heart_data.drop('Target', axis=1)\ny = heart_data['Target']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Build and test the performance of different Regression Models.\n","metadata":{}},{"cell_type":"code","source":"#Try different Regression  models\nlr = LinearRegression().fit(X_train,y_train)\nlgr = LogisticRegression(solver='liblinear').fit(X_train,y_train)\nrfr = RandomForestRegressor(n_estimators = 100, random_state=0, verbose=False).fit(X_train,y_train)\ndtr = DecisionTreeRegressor(random_state=0).fit(X_train, y_train)\nxgbr = XGBRegressor().fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get MAE for these regression models that we have already fit \nmodels=[lr,lgr,rfr,dtr,xgbr]\nfor model in models:\n    scores = -1 * cross_val_score(model, X, y, cv = 10, scoring ='neg_mean_absolute_error')\n    print(\"MAE Score:\\n\", scores.mean())    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above MAE values, we can conclude that the LogisticRegression model performs better than the other regression models. ","metadata":{}},{"cell_type":"markdown","source":"Build and test performance of differenrt Classification Models","metadata":{}},{"cell_type":"code","source":"#Try different Classifier models\nknn = KNeighborsClassifier().fit(X_train,y_train)\ndtc = DecisionTreeClassifier(random_state=0).fit(X_train,y_train)\nrfc = RandomForestClassifier(random_state=0, verbose=False).fit(X_train, y_train)\nxgbc = XGBClassifier().fit(X_train,y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[knn,dtc,rfc,xgbc]\nfor model in models:\n    scores = -1 * cross_val_score(model,X,y,cv=10, scoring='neg_mean_absolute_error')\n    print(\"MAE Score is:\\n\", scores.mean())\n    \nprint(scores)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the above classifier and regressor models, **RandomForestClassifier**  and **LogisticRegression** models look to have lower MAE. Let us look at details of their other performence measure metrics like Precision, Recall and f1-Score","metadata":{}},{"cell_type":"code","source":"rfc_pred = rfc.predict(X_test)\nscores = -1*cross_val_score(rfc, X,y, cv = 10, scoring ='neg_mean_absolute_error')\nprint(\"MAE is:\", scores.mean())\nprint(\"Accuracy score is: \", accuracy_score(y_test,rfc_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test,rfc_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test,rfc_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RandomForestClassifier** model has low MAE and fairly good accuracy of 88%. It has good scores for Precision, Recall and F1 Score as well. The confusion matrix values shows good prediction results of the model too. ","metadata":{}},{"cell_type":"code","source":"#fit, train and prdict using logistic regression model and check accuracy\nlr = LogisticRegression().fit(X_train,y_train)\n\ny_pred = lr.predict(X_test)\n\n#calculate accuracy of the fitted model\nacc_score = accuracy_score(y_test,y_pred)\n\n#check the mean absolute error \nscore = -1* cross_val_score(lr,X,y,cv=8, scoring='neg_mean_absolute_error')\n\nprint(\"Mean Absolute error is:\", score.mean())\nprint(\"The accuracy score of Logistric Regression Classifier is:\", acc_score)\n\n#lets look at precision, recall, f1_score to check models performance\nprint(\"Classification Report:\\n\",classification_report(y_test,y_pred))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression** model has the accuracy of about 85%. Looking at precision, recall and F1 score will give more insight on how well the model is performing. Precision of 0.85/0.86 and recall of 0.81/0.88 and f1_score of 0.83/0.87 shows that the models performance is fairly good. Confusion matrix also shows results that supports the good performance of the above model.","metadata":{}},{"cell_type":"markdown","source":"From the above performance measures, we can see that **RandomForstClassifier** is better performed when compared to **LogisticRegression** model. We can conclude that the **RandomForestClassifier** model seems to be best model for our heart attack data prediction. ","metadata":{}},{"cell_type":"markdown","source":"My humble request to all the experts/participants  in this group- please give me your feedback and suggestions so that I can improve my work and learn from you all. \nPlease upvote my work if you like it. \nThank you!!!","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}