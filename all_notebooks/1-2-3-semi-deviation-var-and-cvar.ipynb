{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Semi Deviation, VAR and CVAR\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"What Is Downside? Downside is the negative movement in the price of a security, sector or market. ","metadata":{}},{"cell_type":"markdown","source":"# 0. Downside","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy.stats\n\ndef drawdown(return_series: pd.Series):\n    \"\"\"Takes a time series of asset returns.\n       returns a DataFrame with columns for\n       the wealth index, \n       the previous peaks, and \n       the percentage drawdown\n    \"\"\"\n    wealth_index = 1000*(1+return_series).cumprod()\n    previous_peaks = wealth_index.cummax()\n    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n    return pd.DataFrame({\"Wealth\": wealth_index, \n                         \"Previous Peak\": previous_peaks, \n                         \"Drawdown\": drawdowns})\n\n\ndef get_ffme_returns():\n    \"\"\"\n    Load the Fama-French Dataset for the returns of the Top and Bottom Deciles by MarketCap\n    \"\"\"\n    me_m = pd.read_csv(\"../input/edhec-data-for-portfolio-construction-with-python/Portfolios_Formed_on_ME_monthly_EW.csv\",\n                       header=0, index_col=0, na_values=-99.99)\n    rets = me_m[['Lo 10', 'Hi 10']]\n    rets.columns = ['SmallCap', 'LargeCap']\n    rets = rets/100\n    rets.index = pd.to_datetime(rets.index, format=\"%Y%m\").to_period('M')\n    return rets\n\n\ndef get_hfi_returns():\n    \"\"\"\n    Load and format the EDHEC Hedge Fund Index Returns\n    \"\"\"\n    hfi = pd.read_csv(\"../input/edhec-data-for-portfolio-construction-with-python/edhec-hedgefundindices.csv\",\n                      header=0, index_col=0, parse_dates=True)\n    hfi = hfi/100\n    hfi.index = hfi.index.to_period('M')\n    return hfi\n\ndef skewness(r):\n    \"\"\"\n    Alternative to scipy.stats.skew()\n    Computes the skewness of the supplied Series or DataFrame\n    Returns a float or a Series\n    \"\"\"\n    return scipy.stats.skew(r)\n\n\n\ndef kurtosis(r):\n    \"\"\"\n    Alternative to scipy.stats.kurtosis()\n    Computes the kurtosis of the supplied Series or DataFrame\n    Returns a float or a Series\n    \"\"\"\n    return scipy.stats.kurtosis(r)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hfi=get_hfi_returns()\nhfi.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Semideviation","metadata":{}},{"cell_type":"code","source":"# standard deviation\nhfi.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# however we only compute the deviation towards the downside\nhfi[hfi<0].std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make it a function\ndef semideviation(r):\n    '''\n    returns the semideviation aka negative semideviation of r\n    r must be a Series or a DataFrame\n    '''\n    return r[r<0].std(ddof=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"semideviation(hfi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. VaR\n\n* 2.1 historical VaR\n* 2.2 Gaussian Parametric VaR\n* 2.3 Modified Cornish-Fisher VaR","metadata":{}},{"cell_type":"markdown","source":"## 2.1 historical VaR","metadata":{}},{"cell_type":"markdown","source":"**Historical value at risk (VaR), also known as historical simulation or the historical method, refers to a particular way of calculating VaR. In this approach we calculate VaR directly from past returns. For example, suppose we want to calculate the 1-day 95% VaR for an equity using 100 days of data. The 95th percentile corresponds to the least worst of the worst 5% of returns. In this case, because we are using 100 days of data, the VaR simply corresponds to the 5th worst day.**\nhttps://corporatefinanceinstitute.com/resources/knowledge/trading-investing/value-at-risk-var/","metadata":{}},{"cell_type":"code","source":"print(np.percentile(hfi,5,axis=0))\nprint(hfi.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def var_historic(r, level=5):\n    '''\n    VaR Historic\n    '''\n    # if r is a DataFrame , it will return a True\n    # Aggregate using one or more operations over the specified axis.\n    if isinstance(r,pd.DataFrame):\n        return r.aggregate(var_historic,level=level) # call on each columns\n    elif isinstance (r,pd.Series):\n        return -np.percentile(r,level)\n    else:\n        raise TypeError ('Expected r to be series or dataframe')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_historic(hfi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Gaussian Pasrametric VaR (standard normal gaussian)","metadata":{}},{"cell_type":"markdown","source":"**VaR = - (mean + z * std)**","metadata":{}},{"cell_type":"code","source":"from scipy.stats import norm\n# get the Z-score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://www.investopedia.com/thmb/qnWc7_zqmjH4rB0ft3K_IRSIslE=/1787x0/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)/Variance-CovarianceMethod5-5bde86ce7819405ca63f26aa275a4bd2.png)\nhttps://www.investopedia.com/articles/04/092904.asp","metadata":{}},{"cell_type":"code","source":"# get the Z-score \nnorm.ppf(0.95)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate the Z-score for the 5%, and calculate the VaR using\n# VaR = - (mean + z * std)\nz=norm.ppf(0.05)\n-(hfi.mean()+z*hfi.std(ddof=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make it a function\ndef var_gaussian(r, level=5):\n    z=norm.ppf(level/100)\n    return -(r.mean()+z*r.std(ddof=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_gaussian(hfi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Cornish-Fisher VaR","metadata":{}},{"cell_type":"markdown","source":"![](https://image.slidesharecdn.com/infiniticapitalfourmomentriskdecomposition-111128005125-phpapp02/95/four-moment-risk-decomposition-presentation-6-728.jpg?cb=1322442187)","metadata":{}},{"cell_type":"code","source":"# key: modified z from the: gaussian z, skewness, kurtosis\n\n# make it a function\ndef var_gaussian(r, level=5,modified=False):\n    z=norm.ppf(level/100)\n    # the Cornish Fisher option\n    if modified:\n        # modified z from s, k and z\n        s=skewness(r)\n        k=kurtosis(r)\n        z=(z+\n           (z**2-1)*s/6+\n           (z**3-3*z)*(k-3)/24-\n           (2*z**3-5*z)*(s**2)/36\n        )\n    \n    return -(r.mean()+z*r.std(ddof=0))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_list=(var_gaussian(hfi),var_gaussian(hfi,modified=True),var_historic(hfi))\ncomparison=pd.concat(var_list,axis=1)\ncomparison.columns=['Gaussian','Cornish-Fisher','Historic']\ncomparison","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nfig = plt.figure(figsize = (10, 5))\ncomparison.plot.bar(title='Hedge Fund Indices: VaR')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"most cases the Cornish-Fisher produces higher VaR","metadata":{}},{"cell_type":"markdown","source":"# 3. CVaR (BeyondVaR)","metadata":{}},{"cell_type":"markdown","source":"**Definition**: CVaR is derived by taking a weighted average of the “extreme” losses in the tail of the distribution of possible returns, beyond the value at risk (VaR) cutoff point. \nURL: https://www.investopedia.com/terms/c/conditional_value_at_risk.asp\n![](https://www.researchgate.net/profile/Y-Vardanyan/publication/322917958/figure/fig6/AS:589989427560454@1517675849921/Demonstration-of-the-VaR-and-CVaR-concepts.png)","metadata":{}},{"cell_type":"code","source":"# CVaR: average of all the returns that worse(beyond) the VaR\ndef cvar_historic(r, level=5):\n    if isinstance(r,pd.Series):\n        below_var_True=r<=-var_historic(r,level=level) # find all the returns that less thant the VaR, which gives a mask\n        return -r[below_var_True].mean()\n    elif isinstance (r,pd.DataFrame):\n        return r.aggregate(cvar_historic,level=level)\n    else:\n        raise TypeError ('Expected r to be a Series or DataFrame')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if the worst sitiuation with 5% chance occured, the average loss (expected loss) would be in 1 month:\ncvar_historic(hfi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some other exploration","metadata":{}},{"cell_type":"code","source":"hfi=hfi['2000':'2018']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kurtosis(hfi)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hfi.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}