{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"img_dir = \"../input/flickr30k_images/flickr30k_images/flickr30k_images\"\nresults = \"../input/flickr30k_images/flickr30k_images/results.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(results, error_bad_lines=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = list(df[df.columns[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = {}\n\nkey = data[0].split('.jpg')[0]\nmapping[key] = []\n\ni = 0\n\nfor d in data:\n     \n    i += 1\n        \n    if d.split('.jpg')[0] != key:\n        key = d.split('.jpg')[0]\n        mapping[key] = []\n    if i == 18005:    \n        mapping[key].append(\" \".join(d.split()[2:]))\n        continue\n        \n    mapping[key].append(d.split('|')[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_mapping = {}\n\nfor key, desc in mapping.items():\n    if len(mapping[key]) == 3:\n        cleaned_mapping[key] = mapping[key]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\n\nmapping = {}\n\nre_punc = re.compile( '[%s]' % re.escape(string.punctuation))\nfor key, descs in cleaned_mapping.items():\n    mapping[key] = []\n    for desc in descs:\n        desc = desc.split()\n        desc = [word.lower() for word in desc]\n        desc = [re_punc.sub( '' , w) for w in desc]\n        desc = [word for word in desc if len(word)>1]\n        desc = ' '.join(desc)\n        mapping[key].append(desc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img, img_to_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\n\nmodel = VGG16()\nmodel.layers.pop()\nmodel = Model(inputs=model.inputs, outputs=model.layers[-1].output)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import preprocess_input\n\nfeatures = {}\n\nfor key in mapping.keys():\n    img = load_img(img_dir + '/' + key + '.jpg', target_size=(224, 224))\n    img = img_to_array(img)\n    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n    img = preprocess_input(img)\n    feature = model.predict(img, verbose=0)\n    features[key] = feature\n    print(key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc = []\n\nfor ds in list(mapping.values()):\n    for d in ds:\n        desc.append(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"descs = []\n\nfor d in desc:\n    d = d.split()\n    d.insert(0, 'START')\n    d.append('END')\n    descs.append(' '.join(d))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\n# prepare tokenizer\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(descs)\nvocab_size = len(tokenizer.word_index) + 1\nprint( ' Vocabulary Size: %d ' % vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded = tokenizer.texts_to_sequences(descs) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = list(features.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence = []\n\nlabels = []\ni = 0\n\nfor desc in encoded:\n    \n    l = label[int(i/3)]\n    i += 1\n    for j in range(1, len(desc)):\n        d = desc[0:j+1]\n        sequence.append(d)\n        labels.append(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = max([len(s) for s in sequence]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nsequence = pad_sequences(sequence, maxlen = max_length, padding = 'pre')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import array\nsequence = array(sequence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x , y = sequence[:,:-1], sequence[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\ny = to_categorical(y, num_classes = vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, LSTM, Dense,Embedding, Dropout\nfrom keras.layers.merge import add\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input1 = Input(shape = (4096, ))\nfe1 = Dropout(0.25)(input1)\nfe2 = Dense(256, activation='relu')(fe1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input2 = Input(shape = (max_length - 1,))\nse1 = Embedding(vocab_size, 256, mask_zero=True)(input2)\nse2 = Dropout(0.5)(se1)\nse3 = LSTM(256)(se2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder1 = add([fe2, se3])\ndecoder2 = Dense(256, activation= 'relu' )(decoder1)\noutputs = Dense(vocab_size, activation= 'softmax' )(decoder2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs=[input1, input2], outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint( 'model.h5' , monitor= 'loss' , verbose=1, save_best_only=True, mode= 'min' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"photos = []\n\nfor label in labels:\n    photos.append(features[label])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = []\nfor i in range(len(photos)):\n    features.append(photos[i][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import array\n\nfeatures = array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit([features, x], y, epochs = 20, verbose=1, callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}