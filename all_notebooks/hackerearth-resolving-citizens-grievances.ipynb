{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/resolving-citizens-grievances-v1/dataset/train.csv')\ntest = pd.read_csv('../input/resolving-citizens-grievances-v1/dataset/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combining test and train to do feature engineering.\ntest['importance']=-1\ntrain['label'] = 'train'\ntest['label'] = 'test'\ncombined = pd.concat([train,test],axis=0)\ncombined.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in combined.columns:\n    print(col,'unique values-> ',combined[col].nunique(), 'null values--> ', combined[col].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_issues(df):\n    issue_columns = [\n        'issue.0', 'issue.1', 'issue.2', 'issue.3', 'issue.4', 'issue.5', 'issue.6', 'issue.7', 'issue.8', \n        'issue.9', 'issue.10', 'issue.11', 'issue.12', 'issue.13', 'issue.14', 'issue.15', 'issue.16', \n        'issue.17', 'issue.18', 'issue.19', 'issue.20', 'issue.21', 'issue.22', 'issue.23']\n    issue_df = combined[issue_columns]\n    issue_df.fillna('',inplace=True)\n    issue_df['issues'] = issue_df[issue_columns].apply(lambda x: '. '.join([val for val in x if val != '']), axis=1)\n    df.drop(issue_columns, axis=1, inplace=True)\n    issue_df.drop(issue_columns, axis=1, inplace=True)\n    df = pd.concat([df, issue_df], axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lowercase_texts(df):\n    print('converting all text columns in lowercase.',)\n    for col in combined.columns:\n        if combined[col].dtype=='object':\n            combined[col] = combined[col].str.lower()\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def universalize_countries(df):\n# converting all the countries to single symbolic numerical value.(eg - Albania, albania, abl, ab -> 1)\n    country_dict_A = df[['respondentOrderEng','country.name']].set_index('country.name').T.to_dict('list')\n    country_dict_C = df[['respondentOrderEng','respondent.0']].set_index('respondent.0').T.to_dict('list')    \n    country_dict = {}\n    for d in (country_dict_A, country_dict_C):#, country_dict_C): #, country_dict_D, country_dict_E, country_dict_F): \n        country_dict.update(d)\n        \n    country_dict = {k: v for k, v in country_dict.items() if pd.notna(k)}\n    df['respondent.0'] = df['respondent.0'].apply(lambda x: country_dict[x][0])\n    df['respondent.1'] = df['respondent.1'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.2'] = df['respondent.2'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.3'] = df['respondent.3'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    df['respondent.4'] = df['respondent.4'].apply(lambda x: country_dict[x][0] if pd.notnull(x) else x)\n    del df['respondentOrderEng']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_constant_values(df):\n#     this function removes redundant constant features.\n    print('Removing constant columns -> ',)\n    for col in df.columns:\n        if df[col].nunique()==1:\n            print(col,end=', ' )\n            del df[col]\n    return df\n\ndef remove_unwanted_features(df):\n#     these features dont add any valueable signal to the data.\n    remove_cols =['parties.0', 'country.alpha2', 'parties.1', 'country.name', 'docname', 'appno', 'ecli', 'kpdate', 'originatingbody_name']\n    for col in remove_cols:\n        if col in df.columns:\n            df.drop(col, axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def featurize_columns(df):\n#     making new columns.\n    df['itemid'] = df['itemid'].apply(lambda x: x[4:7])\n    df['sharepointid'] = df['sharepointid'].apply(lambda x: str(x)[:3])\n    df['total_respondents'] = 5- df[['respondent.0','respondent.1','respondent.2','respondent.3','respondent.4']].isna().sum(axis=1)\n\n    return df\n\ndef featurize_date_columns(df):\n    #     making new columns based on dates.\n    df['daysbetween_intro_decision'] = (pd.to_datetime(df['decisiondate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_intro_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['introductiondate'])).dt.days\n    df['daysbetween_decision_judgement'] = (pd.to_datetime(df['judgementdate']) - pd.to_datetime(df['decisiondate'])).dt.days\n    df.drop(['decisiondate','introductiondate','judgementdate'], axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ndef encoding(df):\n    df['doctypebranch'] = le.fit_transform(df['doctypebranch'])\n    df['separateopinion'] = le.fit_transform(df['separateopinion'])\n    df['typedescription'] = le.fit_transform(df['typedescription'])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_missing(df):\n    for col in df.columns:\n        if col not in ['label', 'issues']:\n            df[col].fillna(0,inplace=True)\n            df[col] = df[col].astype('int')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = combine_issues(combined)\nprint('combined shape after combining issues ->', combined.shape)\ncombined = lowercase_texts(combined)\ncombined = universalize_countries(combined)\ncombined = featurize_columns(combined)\ncombined = featurize_date_columns(combined)\ncombined = encoding(combined)\ncombined = remove_constant_values(combined)\nprint('\\ncombined shape after removing constant features->', combined.shape)\ncombined = remove_unwanted_features(combined)\ncombined = fill_missing(combined)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.to_csv('combined_inbetween.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_col = 'importance'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_train = combined.query('label == \"train\"').drop(['issues', 'label'] , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(combined_train.drop([target_col], axis=1),combined_train[target_col],test_size=0.2,stratify=combined_train[target_col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"xgbm = LGBMClassifier(max_depth=6, learning_rate=0.1, n_estimators=500,\n                         min_child_weight=100, subsample=1.0, \n                         colsample_bytree=0.8, colsample_bylevel=0.8,\n                         random_state=42, n_jobs=-1)"},{"metadata":{},"cell_type":"markdown","source":"oof_preds = cross_val_predict(xgbm, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)"},{"metadata":{"trusted":true},"cell_type":"code","source":"XG = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = cross_val_predict(XG, X_train, Y_train, cv=5, \n                                  n_jobs=-1, method=\"predict\")\nprint(\"cv score: \", accuracy_score(oof_preds, Y_train) * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\nxgbm.fit(X_train,Y_train)\npreds = xgbm.predict(tst)\npreds "},{"metadata":{"trusted":true},"cell_type":"code","source":"tst = combined.query('label == \"test\"').drop(['issues', 'label', target_col] , axis=1)\nXG.fit(X_train,Y_train)\npreds = XG.predict(tst)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(columns=[\"appno\",\"importance\"])\nsub[\"appno\"] = test.appno\nsub[\"importance\"] = preds\nsub.to_csv(\"result2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}