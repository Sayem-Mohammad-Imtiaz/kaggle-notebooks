{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Model of Diabetic Patients\n\n### Problem Statement\n\n\nDiabetes is diagnosed with fasting sugar blood tests or with A1c blood tests, also known as glycated hemoglobin tests. \nA fasting blood sugar test is performed after you have had nothing to eat or drink for at least eight hours.\nIn most cases, if **glucose** (blood sugar) level is equal to or greater than 126 mg/dl (7 mmol/l), the patient can be diagnosed with the disease.\n\nIn this study case, patient data was used to predict the likelyhood of a patient being diagnosed with Diabetes Disease.\nThis model can serve as an indicator prior testing.\n"},{"metadata":{},"cell_type":"markdown","source":"### Understanding the Dataset: "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"data = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data comprises of 768 records.\nBesides including 8 patient metrics (such as blood pressure, BMI, age...), the dataset also contains a dummy variable - Outcome - indicating wether the patient was diagnosed with diabetes or not (1 - has the disease, 0 - doesn't have the disease)."},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning\n\nBefore begining analysis and modeling, we need to clean and prepare the dataset.\nLet's start by inspecting the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have values of 0 for Glucose levels, Blood Pressure and BMI, where they can be considered abnormal, we can remove them:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['Glucose'] != 0]\ndata = data[data['BloodPressure'] != 0]\ndata = data[data['BMI'] != 0]\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Patient Sample Caracterization"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of healthy and diabetic patients in the dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"diabetic_patients = data[data['Outcome'] == 1] # diabetic patients\nnum_diabetics = diabetic_patients.shape[0] # count of diabetic patients\n\nhealthy_patients = data[data['Outcome'] == 0] # healthy patients\nnum_healthy = healthy_patients.shape[0] # count of healthy patients\n\nprint('Number of diabetic patients: ' + str(num_diabetics))\nprint('Number of healthy patients: ' + str(num_healthy))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Patient age:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While there's a range of patients aged between 21 and 81 years, 75% of patients are below the age of 36."},{"metadata":{},"cell_type":"markdown","source":"## Classification Model\n\nFor this project, a simple K-Nearest Neighbors Classifier is used to predict wether a patient could have diabetes or not.\nAs mentioned before, the dataset provides the *labels* for the model with the variable **Outcome**.\nThe goal is to predict the possibility of having diabetes from a subset of features provided, such as blood pressure, insulin levels, glucose, skin thickness, and BMI."},{"metadata":{},"cell_type":"markdown","source":"### 1. Normalization\n\nBefore building the model, the feature data needs to be normalized. (More info:\n[Why normalize data in KNN?](https://medium.com/analytics-vidhya/why-is-scaling-required-in-knn-and-k-means-8129e4d88ed7))\nThis is done below with the help of sklearn:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nfeatures = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n'BMI', 'DiabetesPedigreeFunction', 'Age']\n\nfeatures =  data[features]\n\ntarget = data['Outcome'] ## labels\n\nX = preprocessing.normalize(features) ## normalized features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Choosing K\n\nThe algorithm clusters classes based on a number, *k*, of nearest neighbors.\nTo choose the value we will use for K in the KNN model, it's necessary to test the value that can get the best ***accuracy score*** for the model - the proportion of correct classifications over all predictions made.\n\nThis can be done by plotting different values of k-score pairs."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# splitting train and test data\nx_train, x_test, y_train, y_test = train_test_split(X, target, random_state=3)\n\n# we'll store each k value and score tested\nk_scores = {} # will map k and score\nk = list(range(1,25))\n\nscores = [] # stores model scores\n\n## looping to test different k values\nfor i in k:\n    # create and fit the model\n    classifier = KNeighborsClassifier(n_neighbors=i)\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test) # predicted values\n    \n    # store test results\n    k_scores[i] = accuracy_score(y_test, y_pred) # stores classification score for k\n    scores.append(k_scores[i]) # append result in list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can plot the scores:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(k, scores)\nplt.xlabel(\"K Value\")\nplt.ylabel(\"Score\")\nplt.title('Accuracy Score for Each Value of K')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"## prints out max score for the model\nmax_test = max(scores)\nfor val in k:\n    if k_scores[val] == max_test:\n        result = val\n\nprint('Max test score: ' + str(max_test) + ' with k: ' + str(result))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With k = 6, the model makes 68.5% of predictions correct."},{"metadata":{},"cell_type":"markdown","source":"### 3. Model Evaluation and Tuning\n\nWe have determined that 6 would be the number of neighbors necessary in order to maximize the model's accuracy score (=0.68).\nHowever, [other measures should be taken into account when building classification models](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9):\n* Precision score: measures the proportion of true positives over all positive values (in this case, the number of correctly \"diagnosed\" patients over all labeled diabetic patients).\n* F1 Score: takes into account accuracy and precision (using the harmonic mean)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# final model\nclassifier = KNeighborsClassifier(n_neighbors=6)\nclassifier.fit(x_train, y_train)\n\npredictions = classifier.predict(x_test) ## model predictions using test set\n\n## f1 score\nf1 = sklearn.metrics.f1_score(y_test, predictions)\n## metrics\naccuracy = sklearn.metrics.accuracy_score(y_test, predictions)\nprecision = sklearn.metrics.precision_score(y_test, predictions)\nrecall = sklearn.metrics.recall_score(y_test, predictions)\n\nprint(\"Accuracy: \" + str(accuracy))\nprint(\"F1 score: \" + str(f1))\nprint(\"Precision: \" + str(precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While the model has an accuracy score of 68.5%, it has a precision score of 62%, which means that of all patients who are diagnosed (as in, predicted by the model to have the disease) only 62% actually have it."},{"metadata":{},"cell_type":"markdown","source":"We can also display the results with the help of a confusion matrix:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(y_test, predictions, rownames=['Actual'], colnames=['Predicted'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}