{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/PN1019/MobileGameABTesting/blob/main/CookieCatsGameAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"**Cookie Cats** is a hugely popular mobile puzzle game developed by Tactile Entertainment. It's a classic \"connect three\"-style puzzle game where the player must connect tiles of the same color to clear the board and win the level. It also features singing cats. We're not kidding! Check out this short demo:","metadata":{"id":"RRQhIk9mmGYF"}},{"cell_type":"code","source":"from IPython.display import YouTubeVideo\nYouTubeVideo('LLVD72FuRlw')","metadata":{"id":"DqfCr9AdnthY","outputId":"3897845e-1b93-4f68-c817-582209fedb37","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As players progress through the levels of the game, they will occasionally encounter gates that force them to wait a non-trivial amount of time or make an in-app purchase to progress. In addition to driving in-app purchases, these gates serve the important purpose of giving players an enforced break from playing the game, hopefully resulting in that the player's enjoyment of the game being increased and prolonged.\n\n\nBut where should the gates be placed? Initially the first gate was placed at level 30, but in this notebook we're going to analyze an AB-test where we moved the first gate in Cookie Cats from level 30 to level 40. In particular, we will look at the impact on player retention. But before we get to that, a key step before undertaking any analysis is understanding the data. So let's load it in and take a look!\n\n","metadata":{"id":"sm4pnsnXouvy"}},{"cell_type":"code","source":"# Importing pandas\n#import pandas as pd\n#from google.colab import files\n#uploaded = files.upload()\n\n","metadata":{"id":"FuQ7hTO2kPcK","outputId":"44dc5baa-ddab-4f51-da07-c9f364ab0bfb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport io\nimport matplotlib.pyplot as plt\n\n\n#df2 = pd.read_csv(io.BytesIO(uploaded['cookie_cats_new.csv']))\ndf = pd.read_csv('../input/mobile-games-ab-testing/cookie_cats.csv')\n","metadata":{"id":"XRJQC3M2lLeI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check head\ndf.head()\n# Integrity Check\ndf.info()\n\n# Describe\ndf.describe()\n\n# Check levels\ndf.version.unique()\n","metadata":{"id":"QbEw9gR4lLbB","outputId":"4a9edf04-3199-4c3e-fc8a-4d0007774514","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **EDA OUTPUT**\n\nIt appears that we have **90,189** rows populated over 5 columns, and no missing data! Perfect.\n\nOur columns are userid, version, sum_gamerounds, retention_1, and retention_7.\n Only two columns contain numeric variables, userid and sum_gamerounds. Userid reflects unique user ID’s, and sum_gamerounds reflects the number of rounds played by each unique user. \n Version contains 2 groups, and will be the source of some of our AB groupings. \n As we see from our EDA output, there are two levels, gate_30 and gate_40. Finally, our last two columns, retention_1 and retention_7 are boolean values, True or False, indicating whether a player is still active after 1 or 7 days.\n\nLike most “free” mobile games, there is an economic element for the craftsmen of the product to generate revenue. \nIn this case, there is a forced cool-down period after so many levels, which the player can remove by paying a fee. \nThe version column in our dataframe reflects versions with different gates preventing the player’s progress, after 30 levels or after 40, these are recorded as gate_30 and gate_40.\n\nThese two versions allow us a fine entry point to AB testing.","metadata":{"id":"k-y2SpiJWBEm"}},{"cell_type":"markdown","source":"**Sanity Check**\n\nLet’s first define the population sizes we’re dealing with to make sure we can proceed with a statistically sound comparison.","metadata":{"id":"EjAjlMMDkZmC"}},{"cell_type":"code","source":"# Counting the number of players in each AB group.\nA = df.version.groupby(df.version == \"gate_30\").count()\nB = df.version.groupby(df.version == \"gate_40\").count()\nprint(A)\nprint(B)\n","metadata":{"id":"RzQ_y3S_VsI8","outputId":"01ebafd0-4943-46cc-f0d7-ff421e2222d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Of our 90,189 total records, approximately half are using version gate_30 (which we will call Group A) and the other half are using version gate_40 (which we will call version B).\n\nThis is great, we can proceed with the analysis.\n\n","metadata":{"id":"naUfxpnnlQJU"}},{"cell_type":"markdown","source":"**How Much Do They Play?**\n\nWe want to see how many how long players typically stay with a product. One way to measure the metric in this case, is to examine how many rounds each user plays.\n\nSince we’re using a Pandas DataFrame, we can take the following approach. We’ll use .groupby() to set each user’s experience to a bin, and return a total count. We’ll then plot how many players are active within a set range, showing us the counts of players within the 0-100 range of total rounds played.","metadata":{"id":"pG85EVrdlzeB"}},{"cell_type":"code","source":"# Counting the number of players for each number of gamerounds \nplot_df = df.groupby(\"sum_gamerounds\").count()\n\n# Plotting the distribution of players that played 0 to 100 game rounds\nax = plot_df[:100].plot()\nax.set_xlabel(\"Total Game Rounds\")\nax.set_ylabel(\"Number Of Players\")\nax.set_title(\"Number of Game Rounds Players on the First Week\")","metadata":{"id":"0XSf53SllUKl","outputId":"33948d1d-4b46-45dc-b8ec-097fc84e525b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Conclusion:**\n\nIt appears that the vast majority of users are playing less than 20 rounds in total, over the recording of this data.\n\nLet’s take the same approach to see if there is much of a difference in the number of games played in our AB versions allotted to each user.\n\n","metadata":{"id":"_tJgcBs3oBaX"}},{"cell_type":"markdown","source":"## **Group Distributions: A vs B Total Plays**\n\nThis time, we’ll need to explore the data a bit more. We’re also going to switch to an overlayed bar-plot of the distinct AB group distributions.\n\nSince we’ve already identified that the drop off in users occurs in less than 20 sessions, let’s also change our bin distribution to get a more nuanced view of the low end and high end of user activities.\n\n\n","metadata":{"id":"-wtbfRTsorIt"}},{"cell_type":"code","source":"plt.style.use('ggplot')\n\n# Counting the number of players for each number of gamerounds \nGroup_A = df[df.version == 'gate_30']\nprint(Group_A.head())\n\nGroup_B = df[df.version == 'gate_40']\nprint(Group_B.head())\nbins = [0,1,10,20,30,40,50,60,70,80,90,100,200,500]\nplot_GA = pd.DataFrame(Group_A.groupby(pd.cut(Group_A[\"sum_gamerounds\"], bins=bins)).count())\nplot_GB = pd.DataFrame(Group_B.groupby(pd.cut(Group_B[\"sum_gamerounds\"], bins=bins)).count())\n","metadata":{"id":"kIBsILLepQNg","outputId":"f0aea933-6d8f-45b8-8b52-ad65d70044ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remember, we’re going to overlay our graphs, so take particular notice of one approach that works for our example, where we assign the second graph the parameter ax=ax to allow the overlay of the second distribution.\n\n","metadata":{"id":"Sp0VbCNgqEiS"}},{"cell_type":"code","source":"# Plotting the distribution of players that played 0 to 100 game rounds\nax = plot_GA[:50].plot(kind = 'bar', y=\"userid\", color = \"blue\", alpha = 1, \n                       title = 'Total Usage By Groups')\nplot_GB[:50].plot(kind = 'bar', y=\"userid\", ax=ax, color = \"red\", alpha = 0.7 )\nax.set_xlabel(\"Total Game Rounds\")\nax.set_ylabel(\"Number of Players\")\nplt.legend([\"Group A\", \"Group B\"])\nplt.tight_layout()\nplt.grid(True)\n","metadata":{"id":"1L-g5XL9qEKv","outputId":"eca0552f-31ab-48eb-a095-6bd4f6add4b9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There doesn’t seem to be a large difference between the two versions overall. However, there does seem to be some slight disparities around the 30-40 marks that may be related to the AB test at hand.\n\n","metadata":{"id":"UG9FjmmNorGG"}},{"cell_type":"markdown","source":"\n**Overall 1-Day Retention**\n\n\nWhat we want is for players to like the game and to get hooked. A common metric in the video gaming industry for how fun and engaging a game is 1-day retention: The percentage of players that comes back and plays the game one day after they have installed it. The higher 1-day retention is, the easier it is to retain players and build a large player base.\n\nAs a step, let's look at what 1-day retention is overall.\n\n","metadata":{"id":"jHg4oQWltEf5"}},{"cell_type":"code","source":"# Calculate percent of returning users - next day\noneday = df.retention_1.sum()/df.retention_1.count()\nprint(str(oneday*100)+\"%\")\n","metadata":{"id":"hDLBSI0brpKr","outputId":"41f40e8d-7564-4d61-91cd-fde827170015","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n**44.52095044850259%**\nReturn the day following an installation of the product.\n\nSlightly less than half? Ok, just out of curiousity is there any fundamental difference in our two user populations from the start regardless of version impact? This time, let’s do as we did above, but this time group them by version group and see how the numbers pan out.\n\n","metadata":{"id":"rg5yBkI4sQF-"}},{"cell_type":"code","source":"# Calculating 1-day retention for each AB-group\noneday = df.retention_1.groupby(df.version).sum()/df.retention_1.groupby(df.version).count()\nprint(oneday)\n","metadata":{"id":"Dw60UMRXsp-k","outputId":"ef64aa7f-fb2b-43bc-b505-62066d3fb001","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like regardless of version, next day returns are essentially the same between our experimental groups.\n\nBut, there IS that 0.6% loss in return players randomized to the 40 round gate…could it be significant? Maybe this product will see millions of users and that extra 0.6% could translate into some paying customers and/or ad dollars.\n\nIt’s worth investigating.\n\nWe can use *Bootstrapping* to test our confidence. Bootstrapping is used in many disciplines, such as in molecular biology to help the analysis of phylogenetics, to re-sample and replace data to and test our statistical confidence in our results.\n\n","metadata":{"id":"lzmAfmZktEc2"}},{"cell_type":"markdown","source":"# **Bootstrapping Means Sampling**","metadata":{"id":"1CFF-xwfvBmp"}},{"cell_type":"code","source":"# Creating an list with bootstrapped means for each AB-group\nboot_1d = []\nfor i in range(500):\n    boot_mean = df.retention_1.sample(frac=1, replace=True).groupby(df.version).mean()\n    boot_1d.append(boot_mean)\n    \n# Transforming the list to a DataFrame\nboot_1d = pd.DataFrame(boot_1d)\nprint(boot_1d)\n    \n","metadata":{"id":"htc59blhvAiT","outputId":"485c9ec0-0e40-4e80-ad8c-bc4ea83af7e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A Kernel Density Estimate plot of the bootstrap distributions\nax= boot_1d.plot.kde()\nax.set_title(\"The Average of 1-Day Retention for each AB group\")\nax.set_xlabel(\"The Average of 1-Day Retention\")","metadata":{"id":"Ku1LM2_Ewqc8","outputId":"8f8cac46-d64b-4816-f141-b1c145bf63e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Zooming over % Difference**\n\nThese two distributions above represent the bootstrap uncertainty over what the underlying 1-day retention could be for the two AB-groups. Let’s zoom in on the difference in 1-day retention.\n","metadata":{"id":"A5f3h3LHvBjl"}},{"cell_type":"code","source":"# Populate a new % Difference Column\nboot_1d['difference'] = (boot_1d['gate_30'] - boot_1d['gate_40']) /  boot_1d['gate_40'] * 100\n\n# Plot the new Column\nax = boot_1d['difference'].plot.kde()\nax.set_xlabel(\"% Difference for 1-Day Retention by AB-group \")\nax.set_title(\"Zooming % Difference\")","metadata":{"id":"apPHSZVYwqaj","outputId":"38931619-50da-4730-d33b-9abd36ebc117","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this chart, we can see that the most likely % difference is around 1% — 2%, and that most of the distribution is above 0%, in favor of a gate at level 30. But what is the probability that the difference is above 0%?\n\n","metadata":{"id":"DRD-6oRi2KZn"}},{"cell_type":"code","source":"prob =(boot_1d['difference'] > 0).sum() / len(boot_1d['difference'])\nprint(str(prob*100)+\"%\")\n","metadata":{"id":"jQ09PA112MVJ","outputId":"c72d0b12-4f57-426d-b965-34e0ef72b041","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Overall 7 Day Retention**\n\nThe bootstrap analysis tells us that there is a high probability that 1-day retention is better when the gate is at level 30. However, since players have only been playing the game for one day, it is likely that most players haven't reached level 30 yet. That is, many players won't have been affected by the gate, even if it's as early as level 30.\n\nBut after having played for a week, more players should have reached level 40, and therefore it makes sense to also look at 7-day retention. That is: What percentage of the people that installed the game also showed up a week later to play the game again.\n\nLet's start by calculating 7-day retention for the two AB-groups.","metadata":{"id":"hrvtZpKG3xja"}},{"cell_type":"code","source":"# Calculating 7-day retention for both AB-groups\ndf.groupby('version')['retention_7'].sum() / df.groupby('version')['retention_7'].count()\n","metadata":{"id":"l5vDQ6qo5Ipb","outputId":"f4332aa7-69a5-443d-bf29-cfefa89bf59e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Like with 1-day retention, we see that 7-day retention is slightly lower (18.2%) when the gate is at level 40 than when the gate is at level 30 (19.0%). This difference is also larger than for 1-day retention, presumably because more players have had time to hit the first gate. But as before, let’s use bootstrap analysis to figure out how certain we should be of the difference between the AB-groups.\n\n","metadata":{"id":"ep-QYa0m5IJe"}},{"cell_type":"code","source":"boot_7d = []\nfor i in range(500):\n    boot_mean = df.retention_7.sample(frac=1, replace=True).groupby(df.version).mean()\n    boot_7d.append(boot_mean)\n    \n# Transforming the list to a DataFrame\nboot_7d = pd.DataFrame(boot_7d)\nprint(boot_7d.head())\n# Adding a column with the % difference between the two AB-groups\nboot_7d['diff'] = (boot_7d['gate_30'] - boot_7d['gate_40']) /  boot_7d['gate_40'] * 100\n\n","metadata":{"id":"SYSwMUn25_nZ","outputId":"f0673adb-4ef5-4327-ea2f-80a8ef218d59","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the bootstrap % difference\nax = boot_7d['diff'].plot.kde()\nax.set_xlabel(\"% difference in means\")\nax.set_title(\"% Difference Distribution For 7 Days\")\n# Calculating the probability that 7-day retention is greater when the gate is at level 30\nprob = (boot_7d['diff'] > 0).sum() / len(boot_7d['diff'])\n\n# Pretty printing the probability\nprint(prob)\n","metadata":{"id":"eiPt7o8c6mRy","outputId":"aa2588ae-9ac1-4ca7-cf29-e0191c0e2242","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **The Conclusion**\n\nThe bootstrap result tells us that there is strong evidence that 7-day retention is higher when the gate is at level 30 than when it is at level 40. The conclusion is: If we want to keep retention high — both 1-day and 7-day retention — we should not move the gate from level 30 to level 40. There are, of course, other metrics we could look at, like the number of game rounds played or how much in-game purchases are made by the two AB-groups. But retention is one of the most important metrics. If we don’t retain our player base, it doesn’t matter how much money they spend in-game.\n\nSo, why is retention higher when the gate is positioned earlier? One could expect the opposite: The later the obstacle, the longer people are going to engage with the game. But this is not what the data tells us. The theory of hedonic adaptation can give one explanation for this. In short, hedonic adaptation is the tendency for people to get less and less enjoyment out of a fun activity over time if that activity is undertaken continuously. By forcing players to take a break when they reach a gate, their enjoyment of the game is prolonged. But when the gate is moved to level 40, fewer players make it far enough, and they are more likely to quit the game because they simply got bored of it.\n\n***Therefore, it makes sense that we keep gate at Level 30***\n\n","metadata":{"id":"On1mk0y5ZB_Y"}}]}