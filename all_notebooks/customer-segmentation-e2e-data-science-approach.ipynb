{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Proposal: "},{"metadata":{},"cell_type":"markdown","source":"We strive to solve for the business problem to predict that a wine from Italy falls in which customer segment based on the wine data set available. \nBased on the dataset obtained, wines are grown in the same region in Italy but derived from three different cultivars. The chemical analysis on the data determined the quantities of 13 constituents found in each of the three types of wines.\n\nAs part of this project, we intend to perform exploratory analysis on the given historical data, get insights about the data and perform data pre-processing/data wrangling. This should be done for imputation and to get the correlation matrix for the 13 constituents. \nCorrelation matrix will help us in getting to know if any of the 13 constituents are correlated and may be grouped to reduce the number of columns or fields in data frame for prediction. \n\nWe should then perform feature engineering techniques like Scaling or Binning on the data based on the pre-processing findings. Based on that, we can determine the relevant feature for our problem.\nOnce we have our features and findings, we can perform classification using standard ML Algorithms. As any other standard ML Model implementation technique, we may divide the given wine dataset into 2 parts : 70% training, 30% test data. If we find any discrepancies we may update our data set distribution. \n\nBased on the predictions from the ML models created, we can get the accuracies for them to compare and conclude for the better ML model for our segmentation problem."},{"metadata":{},"cell_type":"markdown","source":"#### Importing Required Libraires and Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd #data pre-processing\nimport numpy as np  #linear algebra\n\nimport matplotlib.pyplot as plt #plotting\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nfrom sklearn.metrics import confusion_matrix #alogorithm purpose\nfrom sklearn import metrics\n\n#read csv file - wine.csv and create a dataframe \n\ndf = pd.read_csv('/kaggle/input/wine-customer-segmentation/Wine.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploratory Analysis and Data Pre-Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Looking at the percentage of missing values per column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data = pd.DataFrame({'total_missing': df.isnull().sum(), 'perc_missing': (df.isnull().sum()/178)*100})\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Statistical description of numerical variables"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's visualize the numerical quantities in our dataset as boxplots, to have a better sense of the outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols =['Alcohol','Malic_Acid','Ash','Ash_Alcanity','Magnesium','Total_Phenols','Flavanoids','Nonflavanoid_Phenols','Proanthocyanins','Color_Intensity','Hue','OD280','Proline','Customer_Segment']\nplt.figure(figsize=(30,12))\ndf[num_cols].boxplot()\nplt.title(\"Numerical variables in given Wine dataset\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(df.describe()[1:].transpose(),\n            annot=True,linecolor=\"w\",\n            linewidth=2,cmap=sns.color_palette(\"Set1\"))\nplt.title(\"Wine Data summary\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"cor_mat= df[:].corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(30,12)\nsns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### see the correlation for Customer Segment column in our dataset"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"corr=df.corr()\ncorr.sort_values(by=[\"Customer_Segment\"],ascending=False).iloc[0].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Goup 1:',len(df[df.Customer_Segment == 1]))\nprint('Group 2:',len(df[df.Customer_Segment == 2]))\nprint('Group 3:',len(df[df.Customer_Segment == 3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 10)\nsize = [59, 71, 48]\ncolors = ['mediumseagreen', 'c', 'gold']\nlabels = \"Group A\", \"Group B\", \"Group C\"\nexplode = [0, 0, 0.1]\nplt.subplot(1, 2, 1)\nplt.pie(size, colors = colors, labels = labels, explode = explode, shadow = True, autopct = '%.2f%%')\n#plt.title('Different Visitors', fontsize = 20)\nplt.axis('off')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,9))\nsns.scatterplot(x='Ash_Alcanity',y='Color_Intensity',data=df,palette='Set1', hue = 'Customer_Segment');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check Target variable imalance"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df['Customer_Segment'].value_counts(sort = False, normalize = True)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Customer Segment looks like balanced with 3 different types. No imabalance treatment required"},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the data into training set and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop('Customer_Segment',axis=1)\ny = df['Customer_Segment'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering -  Scalling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)  #standardize the independent features","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3,random_state=1)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL BUILDING"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nhistory = lr.fit(x_train,y_train)\ny_pred=lr.predict(x_test)\nprint(\"Logistic Regression Algorithm performance result: \",lr.score(x_test,y_test))\n#print(y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance"},{"metadata":{},"cell_type":"markdown","source":"# confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc(y_test,y_score):\n    from sklearn.preprocessing import label_binarize\n    from sklearn.metrics import roc_curve, auc\n    y_test = label_binarize(y_test, classes=[1,2,3])\n    y_score = label_binarize(y_score, classes=[1,2,3])\n    n_classes = 3\n    fpr = dict()\n    tpr = dict()\n    thr = dict()\n    roc_auc = dict()\n    for i in range(n_classes):\n        fpr[i], tpr[i], thr[i] = roc_curve(y_test[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n    return roc_auc[2],fpr[2],tpr[2],thr[2]\n\ndef precision_compute(class_id,TP, FP, TN, FN):\n    sonuc=0\n    \n    for i in range(0,len(class_id)):\n        if TP[i]==0 or FP[i]==0:\n            TP[i]=0.00000000001\n            FP[i]=0.00000000001\n        sonuc+=(TP[i]/(TP[i]+FP[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\n\ndef recall_compute(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=(TP[i]/(TP[i]+FN[i]))\n       \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef accuracy_compute(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=((TP[i]+TN[i])/(TP[i]+FP[i]+TN[i]+FN[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef specificity_compute(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=(TN[i]/(FP[i]+TN[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef NPV_compute(class_id,TP, FP, TN, FN):\n    sonuc=0\n    for i in range(0,len(class_id)):\n        sonuc+=(TN[i]/(TN[i]+FN[i]))\n        \n    sonuc=sonuc/len(class_id)\n    return sonuc\ndef perf_measure(y_actual, y_pred):\n    class_id = set(y_actual).union(set(y_pred))\n    TP = []\n    FP = []\n    TN = []\n    FN = []\n\n    for index ,_id in enumerate(class_id):\n        TP.append(0)\n        FP.append(0)\n        TN.append(0)\n        FN.append(0)\n        for i in range(len(y_pred)):\n            if y_actual[i] == y_pred[i] == _id:\n                TP[index] += 1\n            if y_pred[i] == _id and y_actual[i] != y_pred[i]:\n                FP[index] += 1\n            if y_actual[i] == y_pred[i] != _id:\n                TN[index] += 1\n            if y_pred[i] != _id and y_actual[i] != y_pred[i]:\n                FN[index] += 1\n\n\n    return class_id,TP, FP, TN, FN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_liste=[]\nauc_scor=[]\nprecision_scor=[]\nrecall_scor=[]\nf1_scor=[]\nLR_plus=[]\nLR_eksi=[]\nodd_scor=[]\nNPV_scor=[]\nyouden_scor=[]\nspecificity_scor=[]\nlrcauc,lrc_fpr,lrc_tpr,lrc_trr=roc(y_test,y_pred)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_pred)\nauc_scor.append(lrcauc)\n\nscore_liste.append(accuracy_compute(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_compute(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_compute(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_pred,average='macro'))\nNPV_scor.append(NPV_compute(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_compute(classid,tn,fp,fn,tp))\nTPR=recall_compute(classid,tn,fp,fn,tp)\nTNR=specificity_compute(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\nprint(\"Classification report for the Logistic Regression algorithm: \\n\",classification_report(y_test,y_pred))\n\ncmlr = confusion_matrix(y_test,y_pred)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmlr,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Estimated\")\nplt.ylabel(\"Actual Value\")\nplt.title(\"Logistic Regression Algorithm Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier()\ndtc.fit(x_train,y_train)\ny_pred_decisiontree=dtc.predict(x_test)\nprint(\"Performance result for Decision Trees Algorithm: \",dtc.score(x_test,y_test))\ndtcauc,dtc_fpr,dtc_tpr,dtc_trr=roc(y_test,y_pred_decisiontree)\nclassid,tn,fp,fn,tp=perf_measure(y_test,y_pred_decisiontree)\nauc_scor.append(dtcauc)\n\nscore_liste.append(accuracy_compute(classid,tn,fp,fn,tp))\nprecision_scor.append(precision_compute(classid,tn,fp,fn,tp))\nrecall_scor.append(recall_compute(classid,tn,fp,fn,tp))\nf1_scor.append(f1_score(y_test,y_pred,average='macro'))\nNPV_scor.append(NPV_compute(classid,tn,fp,fn,tp))\nspecificity_scor.append(specificity_compute(classid,tn,fp,fn,tp))\nTPR=recall_compute(classid,tn,fp,fn,tp)\nTNR=specificity_compute(classid,tn,fp,fn,tp)\nFPR=1-TNR\nif FPR==0:\n    FPR=0.00001\nFNR=1-TPR\nlreksi=FNR/TNR\nlrarti=TPR/FPR\nif lreksi==0:\n    lreksi=0.00000001\nLR_plus.append(TPR/FPR)\nLR_eksi.append(FNR/TNR)\nodd_scor.append(lrarti/lreksi)\nyouden_scor.append(TPR+TNR-1)\n\nprint(\"Classification report for Decision Tree algorithm: \\n\",classification_report(y_test,y_pred_decisiontree))\n\ncmdtc = confusion_matrix(y_test,y_pred_decisiontree)\nf, ax = plt.subplots(figsize =(5,5))\nsns.heatmap(cmdtc,annot = True,linewidths=0.5,linecolor=\"red\",fmt = \".0f\",ax=ax)\nplt.xlabel(\"Estimated\")\nplt.ylabel(\"Actual Value\")\nplt.title(\"Decision Trees Algorithm Confusion Matrix\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyper-parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n'criterion':['gini','entropy'],\n'max_depth':[4,6,8,12]\n}\ng_dt = GridSearchCV(dtc,param_grid=param_grid,n_jobs=-1,cv=5,scoring='accuracy')\ng_dt.fit(x_train,y_train)\ng_dt.best_params_\ng_dt.best_score_\nf_dt = DecisionTreeClassifier(criterion='gini',max_depth=12)\nf_dt.fit(x_train,y_train)\ny_pred1 = f_dt.predict(x_test)\nprint('Test Accuracy:',accuracy_score(y_test,y_pred1))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparision of Performance Classifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_list=[\"Logistic Regression\",\"Decision Tree\"]\nscore={\"algo_list\":algo_list,\"precision\":precision_scor,\"recall\":recall_scor,\"f1_score\":f1_scor,\"AUC\":auc_scor,\"Specificity\":specificity_scor}","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df2=pd.DataFrame(score)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\npred_prob1 = lr.predict_proba(x_test)\npred_prob2 = dtc.predict_proba(x_test)\n\n# roc curve for models\nfpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\nfpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n\n\n# plot roc curves\nplt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\nplt.plot(fpr2, tpr2, linestyle='--',color='green', label='Decision tree')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"1. Performed Exploratary Analysis to find the insights about the data\n2. Performed Data Pre- processing, but there is no empty or null values in the given data set, so that we considered the data as itis.\n3. We Applied Feature Scaling since all the features are independant and performed feature subselction for dropping of not useful features.\n4. Plotted top 10 features in a heat map\n5. We Build Models for Logistic regression and Decision Tree\n6. We Find the Confusion matrix for Performance matrics and we compared for classifiers Logistic regression and Decision tree.\n7. We plotted the ROC curve for validation of train and test results."},{"metadata":{},"cell_type":"markdown","source":"Based on the Test results, Logistic regression Classifier is having higher accuracy than Decision Tree, so that we can recommend Logistic Regression classifier approach to identify the customer segment."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}