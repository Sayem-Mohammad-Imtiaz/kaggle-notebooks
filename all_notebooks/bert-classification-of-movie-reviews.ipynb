{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        data = os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport re\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nMAX_LEN = 512\nEPOCHS = 10\n\nTOKENIZER = BertTokenizer.from_pretrained('bert-base-cased')\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning/ Preprocessing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(data)\nprint(df.info())\n\nsns.countplot(x=df.sentiment)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_html_tags(string):\n    result = re.sub('<.*?>','',string)\n    return result\n\ndf.sentiment = df.sentiment.apply(lambda x: 1 if x == \"positive\" else 0)\ndf.review = df.review.apply(lambda x : remove_html_tags(x))\n\ntrain, test = train_test_split(df, test_size=0.2)\ntrain, test = train.reset_index(drop=True), test.reset_index(drop=True) \n\nprint(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing dataset for Transformer","metadata":{}},{"cell_type":"code","source":"class BERTDataset:\n    def __init__(self, review, sentiment):\n        self.review = review\n        self.sentiment = sentiment\n        self.tokenizer = TOKENIZER\n        self.max_len = MAX_LEN\n\n    def __len__(self):\n        return len(self.review)\n\n    def __getitem__(self, item):\n        review = str(self.review[item])\n\n        encoding = self.tokenizer.encode_plus(review, None, add_special_tokens=True, \n            max_length=self.max_len, padding='max_length', truncation= True)\n        \n        return {   \n            \"ids\": torch.tensor(encoding[\"input_ids\"], dtype=torch.long),\n            \"mask\": torch.tensor(encoding[\"attention_mask\"], dtype=torch.long),\n            \"token_type_ids\": torch.tensor(encoding[\"token_type_ids\"], dtype=torch.long),\n            \"sentiments\": torch.tensor(self.sentiment[item], dtype=torch.float),\n        }\n\ndef create_data_loader(df):\n    ds = BERTDataset(review=df.review.values, sentiment=df.sentiment.values)\n    return DataLoader(ds, batch_size=BATCH_SIZE, num_workers=2)\n\ntrain_data_loader = create_data_loader(train)\ntest_data_loader = create_data_loader(test)\n\ndata = next(iter(train_data_loader))\nprint(data.keys())\nprint(data[\"ids\"].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class BERTSentiment(nn.Module):\n    def __init__(self):\n        super(BERTSentiment, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-cased', return_dict=False)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size,1) \n        \n    def forward(self, ids, mask, token_type_ids):\n        _, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids) \n        return self.out(self.drop(pooled_output))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BERTSentiment()\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Traning/ Testing","metadata":{}},{"cell_type":"code","source":"def train_model(data_loader, model, optimizer, scheduler, loss_fn):\n    model.train()\n    avg_losses = []\n    print_freq = 100\n    \n    for epoch in range(EPOCHS):\n        running_loss = 0.0\n        for i,d in enumerate(data_loader):\n            ids = d[\"ids\"].to(device, dtype=torch.long)\n            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n            mask = d[\"mask\"].to(device, dtype=torch.long)\n            sentiments = d[\"sentiments\"].to(device, dtype=torch.float)\n\n            optimizer.zero_grad()\n\n            output = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n            loss = loss_fn(output, sentiments.view(-1,1))\n\n            loss.backward()\n\n            optimizer.step()\n            scheduler.step()\n            \n            # Print statistics.\n            running_loss += loss.item()\n            if i % print_freq == print_freq - 1: # Print every several mini-batches.\n                avg_loss = running_loss / print_freq\n                print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(epoch+1, i+1, avg_loss))\n                avg_losses.append(avg_loss)\n                running_loss = 0.0\n    print('Finished Training.')\n    return avg_losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(data_loader, model):\n    model.train()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for d  in data_loader:\n            ids = d[\"ids\"].to(device, dtype=torch.long)\n            token_type_ids = d[\"token_type_ids\"].to(device, dtype=torch.long)\n            mask = d[\"mask\"].to(device, dtype=torch.long)\n            sentiments = d[\"sentiments\"].to(device, dtype=torch.float)\n\n            output = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n            \n            predicted = (torch.sigmoid(output)).cpu().numpy() >=0.5\n            predicted = np.concatenate(predicted).ravel()  #flaten a list of numpy array 1x16 to 16\n            sentiments = sentiments.cpu().numpy()\n            \n            total += len(sentiments)\n            correct += (predicted == sentiments).sum().item()\n            \n    print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_step = len(train_data_loader)*EPOCHS\noptimizer = AdamW(model.parameters(), lr = 2e-5, correct_bias= False)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_step)\nloss_fn = nn.BCEWithLogitsLoss().to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = train_model(train_data_loader, model, optimizer, scheduler,loss_fn)\n\nplt.plot(train_loss)\nplt.xlabel('mini-batch index / {}'.format(100))\nplt.ylabel('avg. mini-batch loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_model(test_data_loader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}