{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#supress warning\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save file path\nreal_estate_file_path = '/kaggle/input/real-estate-price-prediction/Real estate.csv'\n#read data and store data\nreal_estate = pd.read_csv(real_estate_file_path)\n#summary of real_estate data\nreal_estate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inspect various aspect of dataframe\n\nreal_estate.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_estate.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to check the null values\nreal_estate.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no null value present in dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"#describe the data\nreal_estate.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There is no need of 'No' column and 'Date' column, hence we can drop it without afftecting our predictions.\nreal_estate.drop(['No'], axis=1, inplace=True)\nreal_estate.drop(['X1 transaction date'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check dataset after dropping 'No' col\nreal_estate.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#Visualising all numeric variable\nplt.figure(figsize=(6,12))\nsns.pairplot(real_estate)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import style \nstyle.use(\"dark_background\")\nsns.heatmap(real_estate.corr(),annot=True,cmap=\"winter\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=\"X2 house age\",y=\"Y house price of unit area\",data=real_estate,kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"X5 latitude\",y=\"Y house price of unit area\",data=real_estate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(real_estate[\"Y house price of unit area\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pair plot in dark theme\nsns.pairplot(real_estate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the columns before moving to plit data into train and test\nreal_estate.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data splitting to Training and Testing model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing required libraries from scikit learn to spilt in train - test\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score\n\nnp.random.seed(0)\n\ndf_train,df_test = train_test_split(real_estate, train_size=0.70, test_size=0.30,random_state=100)\nprint(df_train.head())\nprint(df_test.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividing X and y sets for model building\ny_train = df_train.pop('Y house price of unit area')\nX_train = df_train\nprint(y_train.head())\nprint(X_train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Modelling and Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import Linear regression\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model\nlm = LinearRegression()\nlm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The coefficient of all independent variable are as follows\ncoeff = pd.DataFrame(lm.coef_, X_train.columns, columns=['coefficient'])\ncoeff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nX_train_new = sm.add_constant(X_train)\n\nlm_1 = sm.OLS(y_train, X_train).fit()\nprint(lm_1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\n#vif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All features p-value is significant and vif is less than 5. Hence no need to remove any feature."},{"metadata":{},"cell_type":"markdown","source":"# Residual Analysis of train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_price = lm_1.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y_true=y_train,y_pred=y_train_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot histogram of error terms\nfig = plt.figure()\nsns.distplot((y_train-y_train_price), bins=20)\nfig.suptitle('Error Terms',fontsize = 20)\nplt.xlabel('Error',fontsize=17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here error terms has come in normal error distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"#residual error scatter plot of error terms\n\nresidual = y_train-y_train_price\n\nfig, ax = plt.subplots(figsize=(6,2.5))\n_ = ax.scatter(residual, y_train_price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making Prediction on Final model"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop('Y house price of unit area')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = lm_1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating R2 Value now"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import library\nfrom sklearn.metrics import r2_score\n#Evaluate r2\nr2_score(y_true=y_test,y_pred=y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual':y_test,'Predictions':y_test_pred})\ndf['Predictions']= round(df['Predictions'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot('Actual','Predictions',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating Model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\n#Mean absolute error(MAE)\nprint('MAE',metrics.mean_absolute_error(y_test,y_test_pred))\n#Mean squared error(MSE)\nprint('MSE',metrics.mean_squared_error(y_test,y_test_pred))\n#Root mean squared error(RMSE)\nprint('RMSE',np.sqrt(metrics.mean_squared_error(y_test,y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using LightGBM for Predicting Prices"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\nmodel=LGBMRegressor(n_estimators=1000)\nmodel.fit(X_train,y_train)\nkfold=KFold(n_splits=10)\nprint(model)\nres=cross_val_score(model,X_train,y_train,cv=kfold)\nprint(res.mean()*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yp=model.predict(X_train)\n\nimport statsmodels.api as sm\nmodel1= sm.WLS(y_train,X_train).fit()\nmodel1.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yp1=model1.predict(X_test)\n\n#import library\nfrom sklearn.metrics import r2_score\n#Evaluate r2\nr2_score(y_true=y_test,y_pred=yp1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual':y_test,'Predictions':yp1})\ndf['Predictions']= round(df['Predictions'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n\nprint(mean_absolute_error(y_test,yp1))\nprint(mean_squared_error(y_test,yp1))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}