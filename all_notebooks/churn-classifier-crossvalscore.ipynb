{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Modelo de Classificação - Variável Target Binária"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problema de Gestão"},{"metadata":{},"cell_type":"markdown","source":"O dataset contém características dos clientes de um banco. O nosso objetivo é desenvolver um modelo para predição de quando o cliente deixará o banco. A variável target se chama \" Exited \", é binária : 0 quando o cliente ainda permanece no banco e 1 quando ele deixou de ser cliente."},{"metadata":{},"cell_type":"markdown","source":"# Base"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a base\n\ndf = pd.read_csv('../input/churn-modelling/Churn_Modelling.csv')\n                 \ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando os dados\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando tipos de dados\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variáveis Object"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Análise de valores únicos das variáveis object\n\nprint('Surname: ',df['Surname'].nunique(),'\\nGeography: ',df['Geography'].nunique(),'\\nGender: ',df['Gender'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop de variáveis com alta cardinalidade ou variáveis de contagem\ndf.drop(columns=['RowNumber', 'CustomerId', 'Surname'],inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualização das variaveis no dataset\nax = df.hist(bins=25, grid=False, figsize=(18,18), color='#1DB954', zorder=2, rwidth=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a feature Estimated Salary\ndf.EstimatedSalary.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot Estimated Salary\n\nplt.figure(figsize=(8,8))\nax = sns.boxplot(y=df[\"EstimatedSalary\"],color='#1DB954')\nplt.title(\"Estimated Salary\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criar variaveis Dummy para Gender e Geography\n\ndata = pd.concat([pd.get_dummies(df[['Gender', 'Geography']]), df[['CreditScore', 'Age', 'Tenure', 'Balance',\n       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary','Exited']]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando dados de forma transposta\ndata.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinamento do modelo\n\n# Separando o dataframe\n\n# Importando o train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# Separando treino e teste\ntrain, test = train_test_split(data, test_size=0.20, random_state=42)\n\n# Separando treino e validação\ntrain, valid = train_test_split(train, test_size=0.20, random_state=42)\n\ntrain.shape, valid.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# definindo colunas de entrada\nfeats = [c for c in data.columns if c not in ['Exited']]\n\nfeats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# treinar o modelo\n\n# Importando o modelo\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Instanciar o modelo\nrf = RandomForestClassifier(n_estimators=200, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# treinar o modelo RandomForestClassifier\nrf.fit(train[feats], train['Exited'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prevendo os dados de validação\npreds_val = rf.predict(valid[feats])\n\npreds_val","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Métricas do modelo Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Avaliando o desempenho do modelo\n\n# Importando a metrica\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nimport scikitplot as skplt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Medindo a acurácia nos dados de teste\npreds_test = rf.predict(test[feats])\n\nprint(\"Acurácia:\",accuracy_score(test['Exited'], preds_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de Confusão com os dados de teste\nprint(\"Matriz de Confusão:\",confusion_matrix(test['Exited'], preds_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de Confusão com os dados de teste de forma gráfica\nskplt.metrics.plot_confusion_matrix(test['Exited'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Olhando para variável target no dataset\ntest['Exited'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Exited'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dos 393 clientes que deixaram o banco, o nosso modelo conseguiu detectar 179 ( na partição teste )"},{"metadata":{},"cell_type":"markdown","source":"# Comparação de modelos de classificação - Cross Val Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando outros modelos\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_best(x,y,cv):\n    \n    ## instanciando modelos\n    log = LogisticRegression()\n    dt = DecisionTreeClassifier()\n    \n    ## gerando lista de modelos\n    list_of_models = [log,dt,rf]\n    \n    ## gerando lista de scores\n    dc_of_scores = {}\n    \n    ## iterando sobre modelos e executando a validação\n    for idx,model in enumerate(list_of_models):\n        dc_of_scores[idx] = cross_val_score(model,x,y,cv=cv,scoring='precision').mean()\n    \n    best_model = max(dc_of_scores,key=dc_of_scores.get)\n    \n    print('xxx Encontrando melhor modelo xxx\\n')\n    if best_model == 0:\n        print(f'Melhor modelo: LogisticRegression\\nPrecisão : {dc_of_scores[0]}')\n    \n    elif best_model == 1:\n        print(f'Melhor modelo: DecisionTreeClassifier\\nPrecisão : {dc_of_scores[1]}')\n        \n    elif best_model == 2:\n        print(f'Melhor modelo: RandomForestClassifier\\nPrecisão : {dc_of_scores[2]}')\n\n    print(f'\\nLogisticRegression\\nPrecisão : {dc_of_scores[0]}')\n    print(f'DecisionTreeClassifier\\nPrecisão : {dc_of_scores[1]}')\n    print(f'RandomForestClassifier\\nPrecisão : {dc_of_scores[2]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_best(data[feats],data['Exited'],10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No caso desse problema de gestão, a métrica usada para avialar qual melhor modelo foi PRECISÃO.\nPor quê? Porque essa métrica mostra quão bem o modelo consegue captar os verdadeiros positivos. \nO objetivo é encontrar quem está propenso a sair do banco (Exited == 1). \nA acurácia mede uma perfomance geral. Nesse caso, foi necessário analisar precisão também.\n\nPara seleção de melhor modelo foi usado o cross_val_score, que mostrou que o Random Forest Classifier é que possui a maior precisão entre Random Forest, Decision Tree e Logistic Regression."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}