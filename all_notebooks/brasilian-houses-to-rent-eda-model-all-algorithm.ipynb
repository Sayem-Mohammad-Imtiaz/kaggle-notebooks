{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Brazilian Houses To Rent","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Columns\n- id\n- city: City where the property is located\n- area:Area do imovel / Property area\n- rooms:Numero de quartos/ Quantity of rooms\n- bathroom:Numero de banheiros / Quantity of bathroom\n- parking spaces:Numero de vagas / Quantity of parking spaces\n- floor:Andar / Floor\n- animal:Aceita animais? / Acept animals?\n- furniture: Mobilhada? / Furniture?\n- hoa: Valor do condominio / Homeowners association tax\n- rent amount: Valor do Aluguel / Rent amount\n- property tax: IPTU / Property tax\n- fire insurance: Seguro Incendio / Fire Insurance\n- total: Valor total / Total","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Goal \n\nWe will examine the effects of the variables 'furniture', 'animal', 'floor', 'parking spaces', 'bathroom', 'rooms', 'area' and 'city' on our target variable 'total'. Our aim is to predict our target variable correctly by guessing if our dependent variables are not provided. In summary; To be able to estimate house prices in Brazil according to the criteria of dependent variables.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport statsmodels.api as sm \nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/brasilian-houses-to-rent/houses_to_rent_v2.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.floor.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"floor\"] = df[\"floor\"].apply(str.strip).replace(\"-\", np.nan)\ndf[\"floor\"] = pd.to_numeric(df[\"floor\"], downcast=\"float\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()*100/df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"floor\"].fillna(np.mean(df.floor), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()*100/df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outlier Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nplt.boxplot(df['total (R$)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Histogram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats.mstats import winsorize\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import normalize\n\ntitle_font = {'family': 'arial', 'color': 'darkred','weight': 'bold','size': 13 }\ncurve_font  = {'family': 'arial', 'color': 'darkblue','weight': 'bold','size': 10 }\n\nplt.figure(figsize=(38,28))\n\ncolumns=[ 'area', 'rooms', 'bathroom', 'parking spaces', 'floor',\n         'hoa (R$)', 'rent amount (R$)',\n       'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\n\nfor i in range(10):\n    plt.subplot(5, 10, i+1)\n    plt.hist(df[columns[i]])\n    plt.title(columns[i]+str(\"/Orjinal\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+11)\n    plt.hist(winsorize(df[columns[i]], (0, 0.10)))\n    plt.title(columns[i]+str(\"/Winsorize\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+21)\n    plt.hist(np.log(df[columns[i]]+1))\n    plt.title(columns[i]+str(\"/Log\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+31)\n    plt.hist(scale(df[columns[i]]))\n    plt.title(columns[i]+str(\"/Scale\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+41)\n    plt.hist(normalize(np.array(df[columns[i]]).reshape(1,-1).reshape(-1,1)))\n    plt.title(columns[i]+str(\"/Normalize\")  , fontdict=title_font)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BoxPlot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(38,28))\n\ncolumns=[ 'area', 'rooms', 'bathroom', 'parking spaces', 'floor',\n         'hoa (R$)', 'rent amount (R$)',\n       'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\n\nfor i in range(10):\n    plt.subplot(5, 10, i+1)\n    plt.boxplot(df[columns[i]])\n    plt.title(columns[i]+str(\"/Orjinal\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+11)\n    plt.boxplot(winsorize(df[columns[i]], (0, 0.03))) # %95\n    plt.title(columns[i]+str(\"/Winsorize\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+21)\n    plt.boxplot(np.log(df[columns[i]]+1))\n    plt.title(columns[i]+str(\"/Log\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+31)\n    plt.boxplot(scale(df[columns[i]]))\n    plt.title(columns[i]+str(\"/Scale\")  , fontdict=title_font)\nfor i in range(10):\n    plt.subplot(5, 10, i+41)\n    plt.boxplot(normalize(np.array(df[columns[i]]).reshape(1,-1).reshape(-1,1)))\n    plt.title(columns[i]+str(\"/Normalize\")  , fontdict=title_font)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we understand from Boxplot and Histogram graphics, the best ways to get rid of outliers are winsorized and transform logarithms. Now, if you transform or winsorize our data into a logarithm, how much will we be outliers? let's find it","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# IQR Method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"log_threshold_variables= pd.DataFrame()\nvariables = [ 'area', 'rooms', 'bathroom', 'parking spaces', 'floor',\n         'hoa (R$)', 'rent amount (R$)',\n       'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\nfor j in variables:\n    for threshold_worth in np.arange(1,5,1):\n        \n        #logarithm Transformed\n        q75_log, q25_log = np.percentile(np.log(df[j]), [75 ,25])\n        caa_log = q75_log - q25_log\n        \n        #Orjinal Data\n        q75, q25 = np.percentile(df[j], [75 ,25])\n        caa= q75 - q25\n        \n        # Winsorize Data\n        q75_win, q25_win = np.percentile(winsorize(df[j],(0, 0.03)), [75 ,25])\n        caa_win= q75 - q25\n        \n        #logarithm Transformed\n        min_worth_log = q25_log - (caa_log*threshold_worth)\n        max_worth_log = q75_log + (caa_log*threshold_worth)\n        \n        #Orjinal Data\n        min_worth= q25 - (caa*threshold_worth) \n        max_worth = q75 + (caa*threshold_worth) \n        \n        # Winsorize Data\n        min_worth_win= q25_win - (caa_win*threshold_worth) \n        max_worth_win = q75_win + (caa_win*threshold_worth)\n        \n        number_of_outliers_log = len((np.where((np.log(df[j]) > max_worth_log)| \n                                               (np.log(df[j]) < min_worth_log))[0]))\n        \n        number_of_outliers = len((np.where((df[j] > max_worth)| \n                                               (df[j] < min_worth))[0]))\n        \n        number_of_outliers_win = len((np.where((winsorize(df[j],(0, 0.03)) > max_worth_win)| \n                                               (winsorize(df[j],(0, 0.03)) < min_worth_win))[0]))\n        \n        log_threshold_variables = log_threshold_variables.append({'threshold_worth': threshold_worth,\n                                                            'number_of_outliers' : number_of_outliers, \n                                                            'number_of_outliers_log': number_of_outliers_log,\n                                                            \"number_of_outliers_win\":number_of_outliers_win\n                                                            }, ignore_index=True)\n    print(\"-\"*10,\"\",j,\"-\"*10)\n    display(log_threshold_variables)\n    log_threshold_variables = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we can focus on our target variable 'total'. the target variable has less contradictory value when converted to logarithm however, it should be noted that winsorize is clear of all outliers for us in the 3 * IQR.In these situations, we can make a wrong decision these between dataframe. Therefore, we have to study both.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(df['total (R$)'], whis=4) # Not log transformed whis = 4 \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(np.log(df['total (R$)']), whis=4) # log Transformed whis = 4 \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoder Transform","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"city\"]= df[\"city\"].replace({\"SÃ£o Paulo\":0, 'Porto Alegre':1, 'Rio de Janeiro':2, 'Campinas':3,'Belo Horizonte':4})\ndf['animal']= pd.get_dummies(df['animal'],drop_first=True)\ndf['furniture']= pd.get_dummies(df['furniture'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Log Transform Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log= df[['area','rooms',\"bathroom\",\"parking spaces\",\"floor\",\"hoa (R$)\",\"rent amount (R$)\",\"property tax (R$)\",\"fire insurance (R$)\",\"total (R$)\"]]\n\ndf_add=df[['city',\"animal\",\"furniture\"]] # Not Transform Log because we apply get_dummies() these columns\n\ndf_log = np.log(df_log+1) # We don't want taking -inf values in dataframe. \n\n\ndf_log=pd.concat([df_log,df_add],axis=1)\ndf_log.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IQR* 4 Log Transform\n\nq1 = df_log['total (R$)'].quantile(0.25)\nq3 = df_log['total (R$)'].quantile(0.75)\niqr = q3-q1 #Interquartile range\nlow  = q1-1.5*iqr #acceptable range\nhigh = q3+4*iqr #acceptable range\nlow,high","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IQR* 4 Log Transform Boxplot\n\ndf_log['total (R$)']=np.where(df_log['total (R$)'] > high,high,df_log['total (R$)']) # upper limit\n\nplt.boxplot(df_log['total (R$)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr=df_log.corr()\ndf_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,10))\nax=sns.heatmap(df_corr, square=True, annot=True, linewidths=.5, vmin=0, vmax=1, cmap='viridis')\nax.set_ylim(13,0)\nplt.title(\"Correlation Matrix\", fontdict=title_font)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Be Carefull\n\n- Before moving on to modeling, we need to leave hoa (R) + ðððð¡ðððð¢ðð¡ (ð) + real estate tax (R) + ððððððð ð¢ððððð (ð) columns in our data. Because when we add these variables, we reach our target variable. The variables I mentioned statistically are the variables that determine our target variable. If these variables were given to us, we would collect and reach our target variable directly. Therefore, if we are not guessing one of these variables, we must delete them and focus on other variables that affect our Target variable.\n\n- We drop these variables from our dataframe before the model because it can negatively affect the metrics of our model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log=df_log.drop([\"rent amount (R$)\",\"property tax (R$)\",\"fire insurance (R$)\",\"hoa (R$)\"], axis=1)\ndf_log.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Winsorize Data and threshold = 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win['total (R$)'] = winsorize(df['total (R$)'], (0, 0.03))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win=df_win.drop([\"rent amount (R$)\",\"property tax (R$)\",\"fire insurance (R$)\",\"hoa (R$)\"], axis=1)\ndf_win.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Winsorize Data and threshold = 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_1 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_1['total (R$)'] = winsorize(df['total (R$)'], (0, 0.03))\ndf_win_1=df_win_1.drop([\"rent amount (R$)\",\"property tax (R$)\",\"fire insurance (R$)\",\"hoa (R$)\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IQR* 1 Log Transform\nq1 = df_win_1['total (R$)'].quantile(0.25)\nq3 = df_win_1['total (R$)'].quantile(0.75)\niqr = q3-q1 #Interquartile range\nlow  = q1-1.5*iqr #acceptable range\nhigh = q3+1*iqr #acceptable range\nlow,high","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_1['total (R$)']=np.where(df_win_1['total (R$)'] > high,high,df_win_1['total (R$)']) # upper limit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Winsorize Data and threshold = 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_2 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_2['total (R$)'] = winsorize(df['total (R$)'], (0, 0.03))\ndf_win_2=df_win_2.drop([\"rent amount (R$)\",\"property tax (R$)\",\"fire insurance (R$)\",\"hoa (R$)\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IQR* 1 Log Transform\nq1 = df_win_2['total (R$)'].quantile(0.25)\nq3 = df_win_2['total (R$)'].quantile(0.75)\niqr = q3-q1 #Interquartile range\nlow  = q1-1.5*iqr #acceptable range\nhigh = q3+2*iqr #acceptable range\nlow,high","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_win_2['total (R$)']=np.where(df_win_2['total (R$)'] > high,high,df_win_2['total (R$)']) # upper limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_log.to_csv('Log_Brazil')\ndf_win.to_csv('Winsorize_Brazil')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error ,r2_score,explained_variance_score,max_error\nfrom sklearn.model_selection import train_test_split, cross_val_score ,cross_val_predict,GridSearchCV, cross_validate\nfrom statsmodels.tools.eval_measures import mse, rmse\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport statsmodels.api as sm ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(X,y,model,tip):\n    X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20, random_state=111)\n    model.fit(X_train, y_train)\n    \n    prediction_train=model.predict(X_train)\n    prediction_test=model.predict(X_test)\n    \n    cv = cross_validate(estimator=model,X=X,y=y,cv=10,return_train_score=True)\n    \n    d = pd.Series({'mean_squared_error_train':mean_squared_error(y_train,prediction_train),\n                   'mean_squared_error_test':mean_squared_error(y_test,prediction_test),\n                   'RMSE Train':np.sqrt(mean_squared_error(y_train,prediction_train)),\n                   'RMSE Test':np.sqrt(mean_squared_error(y_test,prediction_test)),\n                   'r2_score_train':r2_score(y_train,prediction_train),\n                   'r2_score_test':r2_score(y_test,prediction_test),\n                   'explained_variance_score_train':explained_variance_score(y_train,prediction_train),\n                   'explained_variance_score_test':explained_variance_score(y_test,prediction_test),\n                   'max_error_train':max_error(y_train,prediction_train),\n                   'max_error_test':max_error(y_test,prediction_test),\n                   \"Cross_val_train\":cv['train_score'].mean(),\n                   \"Cross_val_test\":cv['test_score'].mean()\n                  },name=tip)\n    return d","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Log Transform IQR * 4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test =  train_test_split(X_scl, y, test_size=0.20, random_state=111) \n      \nlm = LinearRegression()\nlm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics=pd.DataFrame()\nmetrics=metrics.append(create_model(X_scl,y,lm,tip='Log_IQR*4'))\nmetrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Winsorize And threshold = 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_win.drop([\"total (R$)\"], axis=1)\ny = df_win['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nlm = LinearRegression()\n\nmetrics=metrics.append(create_model(X_scl,y,lm,tip='Winsorize_IQR*0'))\nmetrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Winsorize And threshold = 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_win_1.drop([\"total (R$)\"], axis=1)\ny = df_win_1['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nlm = LinearRegression()\n\nmetrics=metrics.append(create_model(X_scl,y,lm,tip='Winsorize_IQR*1'))\nmetrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Winsorize And threshold = 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_win_2.drop([\"total (R$)\"], axis=1)\ny = df_win_2['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nlm = LinearRegression()\n\nmetrics=metrics.append(create_model(X_scl,y,lm,tip='Winsorize_IQR*2'))\nmetrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes. It seems that our best model is our logarithm transform and IQR * 4 dataset. Cross Validate and RMSE Test values are the best ones It seems,. Then we will do the modeling process with this dataframe.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Linear Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nlm = LinearRegression()\n\nmodels= pd.DataFrame()\nmodels=models.append(create_model(X_scl,y,lm,tip='Linear_Model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nKnn=KNeighborsRegressor(n_neighbors=5)\n\nmodels=models.append(create_model(X_scl,y,Knn,tip='Knn_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Knn=KNeighborsRegressor()\nk_range = list(range(1,25))\nparameter = dict(n_neighbors=k_range)\ngrid = GridSearchCV(Knn, parameter, cv=10, scoring='r2')\nGrds = grid.fit(X,y)\nprint('The best parameters:', Grds.best_estimator_)\nprint('The best score:', Grds.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Knn = KNeighborsRegressor(n_neighbors=23)\n\nmodels=models.append(create_model(X_scl,y,Knn,tip='Knn_model_Tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CART MODEL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\ncart_model = DecisionTreeRegressor()\n\nmodels=models.append(create_model(X_scl,y,cart_model,tip='cart_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cart_params= {'min_samples_split':range(2,20), \n             \"max_leaf_nodes\":range(2,10),\n             \"max_features\":range(0,5)}\n\ncart_cv_model = GridSearchCV(cart_model, cart_params, cv=10)\n\ncart_cv_model.fit(X_train,y_train)\nprint(\"The best Parameters\"+str(cart_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cart_model = DecisionTreeRegressor(max_features=4 , max_leaf_nodes=9 , min_samples_split=6 )\n\nmodels=models.append(create_model(X_scl,y,cart_model,tip='cart_model_tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nrandom_model = RandomForestRegressor(n_estimators=25, random_state=2)\n\nmodels=models.append(create_model(X_scl,y,random_model,tip='random_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {'max_depth': [2,3,5,8,10],\n            \"max_features\":[1,2,3,4],\n            \"min_samples_split\":[2,5,40]}\n\nrf_cv_model= GridSearchCV(random_model, rf_params , cv=10)\n\nrf_cv_model.fit(X_train,y_train)\nprint(\"The best paramters :\"+str(rf_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_model = RandomForestRegressor(n_estimators=25, random_state=2,max_depth=10, max_features=4 ,min_samples_split=2)\n\nmodels=models.append(create_model(X_scl,y,random_model,tip='random_model_tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nimportance_level = pd.Series(data=random_model.feature_importances_,\n                        index= X.columns)\n\nimportance_level_sorted = importance_level.sort_values()\n\nimportance_level_sorted.plot(kind='barh', color='darkblue')\nplt.title('Importance Level of the Features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\nX = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nsvm_model = SVR()\n\nmodels=models.append(create_model(X_scl,y,svm_model,tip='svm_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svr_params = {\"C\": np.arange(0.1, 2, 0.1)}\n\nsvr_cv_model = GridSearchCV(svm_model,svr_params, cv=10 ).fit(X_train,y_train)\n\nprint(\"The Best Parameters :\"+str(svr_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_model = SVR(C=1.9000000000000001)\n\nmodels=models.append(create_model(X_scl,y,svm_model,tip='svm_model_Tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bagging Trees","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingRegressor\n\nX = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler=StandardScaler()\nX_scl=scaler.fit_transform(X)\n\nbag_model = BaggingRegressor(bootstrap_features=True)\n\nmodels=models.append(create_model(X_scl,y,bag_model,tip='bag_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_params = {\"n_estimators\": range(2,20)}\n\nbag_cv_model = GridSearchCV(bag_model,bag_params, cv=10 ).fit(X_train,y_train)\n\nbag_cv_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_model = BaggingRegressor(n_estimators=19, random_state=45)\n\nmodels=models.append(create_model(X_scl,y,bag_model,tip='bag_model_tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nX = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler= StandardScaler()\nX_scl= scaler.fit_transform(X)\n\nxgb = XGBRegressor(base_score=0.5, verbose=False)\n\nmodels=models.append(create_model(X_scl,y,xgb,tip='xgb_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_params = {'colsample_bytree':[0.4,0.5,0.6, 0.9, 1],\n             \"n_estimators\":[100,200,500,1000],\n             \"max_depth\":[2,3,4,5,6],\n             \"learning_rate\":[0.1,0.01,0.5]}\n\nxgb_cv_model = GridSearchCV(xgb,xgb_params, cv=10, n_jobs= -1 , verbose=False )\n\nxgb_cv_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Best Parameters :\"+str(xgb_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor(base_score=0.5,colsample_bytree=0.5,learning_rate=0.01\n                   ,max_depth=6,n_estimators=1000,verbose=False )\n\nmodels=models.append(create_model(X_scl,y,xgb,tip='xgb_model_tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Light GBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\n\nX = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler= StandardScaler()\nX_scl= scaler.fit_transform(X)\n\nlgbm = LGBMRegressor()\n\nmodels=models.append(create_model(X_scl,y,lgbm,tip='lgbm_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_params = {'colsample_bytree':[0.4,0.5,0.6, 0.9, 1],\n             \"n_estimators\":[100,200,500,1000],\n             \"max_depth\":[2,3,4,5,6],\n             \"learning_rate\":[0.1,0.01,0.5]}\n\nlgbm_cv_model = GridSearchCV(lgbm,lgbm_params, cv=10, n_jobs= -1 , verbose=False )\n\nlgbm_cv_model.fit(X_train,y_train)\nprint(\"The Best Parameters :\"+str(lgbm_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMRegressor(colsample_bytree=0.6,learning_rate=0.01\n                   ,max_depth=6,n_estimators=1000 )\n\nmodels=models.append(create_model(X_scl,y,lgbm,tip='lgbm_model_tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CatBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\n\nX = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler= StandardScaler()\nX_scl= scaler.fit_transform(X)\n\ncatboost_model = CatBoostRegressor(verbose=False)\n\nmodels=models.append(create_model(X_scl,y,catboost_model,tip='catboost_model'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"catb_params = {\n    \"iterations\":[200,500,1000],\n    \"learning_rate\":[0.01,0.03,0.05,0.1],\n    \"depth\":[3,4,5,6,7,8]}\n\ncat_cv_model = GridSearchCV(catboost_model,catb_params, cv=10, n_jobs= -1 ,verbose=False )\n\ncat_cv_model.fit(X_train,y_train)\nprint(\"The Best Parameters :\"+str(cat_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost_model = CatBoostRegressor(depth=7 , iterations=500, learning_rate= 0.05,verbose=False)\n\nmodels=models.append(create_model(X_scl,y,catboost_model,tip='catboost_model_tuning'))\nmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As you can see, our model that best describes and predicts our data was the Cat Boost Algorithm.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Result CatBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_log.drop([\"total (R$)\"], axis=1)\ny = df_log['total (R$)']\n\nscaler= StandardScaler()\nX_scl= scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test =  train_test_split(X_scl, y, test_size=0.20, random_state=111)\n\ncatboost_model = CatBoostRegressor(depth=7 , iterations=500, learning_rate= 0.05,verbose=False).fit(X,y)\n\nprint(catboost_model.get_scale_and_bias())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost_model.get_feature_importance(data=None,prettified=False,thread_count=-1,verbose=False,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total = '8.243122100830078 + area * 26.03681985 + rooms * 5.60436687 + bathroom * 13.64171516 + parking spaces * 7.6913577 + floor * 18.73900675 +\" \n      ,\"city *17.16975768 + animal * 1.34374804 + furniture * 9.77322794  \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nimportance_level = pd.Series(data=catboost_model.feature_importances_,\n                        index= X.columns)\n\nimportance_level_sorted = importance_level.sort_values()\n\nimportance_level_sorted.plot(kind='barh', color='darkblue')\nplt.title('Importance Level of the Features')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}