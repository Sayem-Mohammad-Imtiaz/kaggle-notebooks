{"cells":[{"metadata":{"id":"5j9NMhYoZlpA","colab_type":"text"},"cell_type":"markdown","source":"Install Tensorflow datasets Tensorflow2.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow_datasets\n","execution_count":null,"outputs":[]},{"metadata":{"id":"M_Bxj4DaZi0E","colab_type":"code","outputId":"7a812ee0-bf8a-42d5-f23a-d450affa9b9e","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport os","execution_count":null,"outputs":[]},{"metadata":{"id":"giNnm2SqK5Lc","colab_type":"text"},"cell_type":"markdown","source":"Reference Code\nhttps://www.tensorflow.org/tutorials/load_data/text"},{"metadata":{},"cell_type":"markdown","source":"The dataset used for analysis is the clean version as preperared using the following kernel \nhttps://www.kaggle.com/brunnoricci/personalitytypeclassification with the numerical categories added for the MBTI \nType . Can be downloaded from www.kaggle.com/uplytics/mbti-clean-with-categories"},{"metadata":{"id":"kUTDwYSm_QTx","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"mbti_dataset_line = tf.data.TextLineDataset(\"../input/mbti-clean-with-categories/mbti_clean.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"83SkhV8H1wZT","colab_type":"code","outputId":"c84b312e-adda-4195-a5df-13a376e2c14c","colab":{"base_uri":"https://localhost:8080/","height":122},"trusted":true},"cell_type":"code","source":"for ex in mbti_dataset_line.take(5):\n  print(ex)","execution_count":null,"outputs":[]},{"metadata":{"id":"QY3QoTwzqjMD","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def label(line):\n  label =  tf.strings.substr([line],[-10],[1])\n  if label[0]==',':\n    label = tf.strings.substr([line],[-9],[1])\n  else:\n    label = tf.strings.substr([line],[-10],[2])\n  labelnum=tf.strings.to_number(label,tf.int64)\n  line= tf.strings.substr([line],[6],(tf.strings.length([line])-17))\n  return line[0], labelnum[0]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"0d9AlM9j2sTG","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"\nmbti_dataset_line = mbti_dataset_line.skip(1).map(lambda line: label(line))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Xq4LF_WmK-iR","colab_type":"text"},"cell_type":"markdown","source":""},{"metadata":{"colab_type":"code","outputId":"e6e5492a-2340-4728-d641-f8d7726735f1","id":"8wg6GDg2ypU8","colab":{"base_uri":"https://localhost:8080/","height":122},"trusted":true},"cell_type":"code","source":"for ex in mbti_dataset_line.take(5):\n  print(ex)","execution_count":null,"outputs":[]},{"metadata":{"id":"uGKRMFWzqd87","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 100000\nBATCH_SIZE = 64\nTAKE_SIZE = 5000","execution_count":null,"outputs":[]},{"metadata":{"id":"_YADuNtEqdu-","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"mbti_dataset_line = mbti_dataset_line.shuffle(\n    BUFFER_SIZE, reshuffle_each_iteration=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"qNPmRZ3WKvzj","colab_type":"text"},"cell_type":"markdown","source":"##Encode text lines as numbers\nFirst, build a vocabulary by tokenizing the text into a collection of individual unique words. \n1.Iterate over each example's numpy value.\n2. Use tfds.features.text.Tokenizer to split it into tokens.\n3.Collect these tokens into a Python set, to remove duplicates.\n4.Get the size of the vocabulary for later use."},{"metadata":{"id":"m0yWIbr2G_fs","colab_type":"code","outputId":"daa49757-748e-4172-883f-a9fd5c91a9ef","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"tokenizer = tfds.features.text.Tokenizer()\n\nvocabulary_set = set()\nfor text_tensor, _ in mbti_dataset_line:\n  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n  vocabulary_set.update(some_tokens)\n\nvocab_size = len(vocabulary_set)\nvocab_size","execution_count":null,"outputs":[]},{"metadata":{"id":"7LTWfd2PL0HS","colab_type":"text"},"cell_type":"markdown","source":"Create an encoder by passing the vocabulary_set to tfds.features.text.TokenTextEncoder. The encoder's encode method takes in a string of text and returns a list of integers."},{"metadata":{"id":"vIPpa3ueL4T8","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)","execution_count":null,"outputs":[]},{"metadata":{"id":"KXrIdaUFMCun","colab_type":"code","outputId":"bb005dc5-b868-4d06-fc2b-0153ad286af0","colab":{"base_uri":"https://localhost:8080/","height":54},"trusted":true},"cell_type":"code","source":"example_text = next(iter(mbti_dataset_line))[0].numpy()\nprint(example_text)","execution_count":null,"outputs":[]},{"metadata":{"id":"wXtIm_OBMMia","colab_type":"code","outputId":"d25e8848-6b3d-429d-a8e3-fbb6c83bdb10","colab":{"base_uri":"https://localhost:8080/","height":54},"trusted":true},"cell_type":"code","source":"encoded_example = encoder.encode(example_text)\nprint(encoded_example)","execution_count":null,"outputs":[]},{"metadata":{"id":"jhcUSxREMTw6","colab_type":"text"},"cell_type":"markdown","source":"Now run the encoder on the dataset by wrapping it in tf.py_function and passing that to the dataset's map method."},{"metadata":{"id":"O9vTBESiMSl0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def encode(text_tensor, label):\n  encoded_text = encoder.encode(text_tensor.numpy())\n  return encoded_text, label\n\ndef encode_map_fn(text, label):\n  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n\nall_encoded_data = mbti_dataset_line.map(encode_map_fn)","execution_count":null,"outputs":[]},{"metadata":{"id":"xhnjY5UuMmn6","colab_type":"text"},"cell_type":"markdown","source":"Split the dataset into test and train batches"},{"metadata":{"id":"w5Kb_Xr_MqkD","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\ntrain_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n\ntest_data = all_encoded_data.take(TAKE_SIZE)\ntest_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))","execution_count":null,"outputs":[]},{"metadata":{"id":"UC_AD3PTMmfE","colab_type":"text"},"cell_type":"markdown","source":""},{"metadata":{"id":"VpZ220tYMW_8","colab_type":"code","outputId":"e5ca99f6-4168-4ff2-ee62-b76478c2b082","colab":{"base_uri":"https://localhost:8080/","height":119},"trusted":true},"cell_type":"code","source":"sample_text, sample_labels = next(iter(test_data))\n\nsample_text[0], sample_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"MqWEkz8hQVBG","colab_type":"text"},"cell_type":"markdown","source":"Add the padding (0) token to vocabulary"},{"metadata":{"id":"C9wgtWwDQTx3","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"vocab_size += 1","execution_count":null,"outputs":[]},{"metadata":{"id":"DClqSCM1Qb-B","colab_type":"text"},"cell_type":"markdown","source":"Start Building the Tensorflow2.0 Model"},{"metadata":{"id":"gQRm7E5zQbHa","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"id":"P-0einoXQnIP","colab_type":"text"},"cell_type":"markdown","source":"The first layer converts integer representations to dense vector embeddings. "},{"metadata":{"id":"xG9s7Zy_Ql_r","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"model.add(tf.keras.layers.Embedding(vocab_size+1, 64))","execution_count":null,"outputs":[]},{"metadata":{"id":"O2MxlZ5YQzBh","colab_type":"text"},"cell_type":"markdown","source":"The next layer is a Long Short-Term Memory layer, which lets the model understand words in their context with other words. A bidirectional wrapper on the LSTM helps it to learn about the datapoints in relationship to the datapoints that came before it and after it."},{"metadata":{"id":"__BU9SgdQ0iO","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))","execution_count":null,"outputs":[]},{"metadata":{"id":"DTO100-cQ6hX","colab_type":"text"},"cell_type":"markdown","source":"Finally we'll have a series of one or more densely connected layers, with the last one being the output layer. The output layer produces a probability for all the labels. The one with the highest probability is the models prediction of an example's label."},{"metadata":{"id":"UjCj-HyKQ9m4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# One or more dense layers.\n# Edit the list in the `for` line to experiment with layer sizes.\nfor units in [64, 64]:\n  model.add(tf.keras.layers.Dense(units, activation='relu'))\n\n# Output layer. The first argument is the number of labels.\nmodel.add(tf.keras.layers.Dense(16, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"id":"Y7LtU_cPRB_X","colab_type":"text"},"cell_type":"markdown","source":"Finally, compile the model. For a softmax categorization model, use sparse_categorical_crossentropy as the loss function. You can try other optimizers, but adam is very common."},{"metadata":{"id":"_efDhoZvQyVw","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"iw9VlQalRIcn","colab_type":"code","outputId":"7f8f1869-b406-4738-a2e6-9aab6b1de33c","colab":{"base_uri":"https://localhost:8080/","height":156},"trusted":true},"cell_type":"code","source":"model.fit(train_data, epochs=1, validation_data=test_data)","execution_count":null,"outputs":[]},{"metadata":{"id":"b7FQCc38eOKw","colab_type":"code","outputId":"f17bfbe0-967e-4409-e26b-83f38be52606","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":true},"cell_type":"code","source":"eval_loss, eval_acc = model.evaluate(test_data)\n\nprint('\\nEval loss: {:.3f}, Eval accuracy: {:.3f}'.format(eval_loss, eval_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9887c367c4d22f30843844559c2b11f16a7e024","id":"YnGr89T7gCvG","colab_type":"code","colab":{}},"cell_type":"code","source":"exit()","execution_count":0,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"mbti_tensorflow2.0.ipynb","provenance":[],"collapsed_sections":["kY_s_xfTgCss","oBA6NTnhgCs3","qsW0NsQ0gCs9","qtnBo3rRgCtK","bs23Xj6UgCtQ","ffDQlSk6gCtc"],"toc_visible":true}},"nbformat":4,"nbformat_minor":1}