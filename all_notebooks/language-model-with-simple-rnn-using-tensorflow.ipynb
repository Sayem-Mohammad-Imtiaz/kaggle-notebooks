{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### A simple RNN language model implemented from scratch with TensorFlow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-24T16:22:38.2882Z","iopub.execute_input":"2021-06-24T16:22:38.288611Z","iopub.status.idle":"2021-06-24T16:22:39.871091Z","shell.execute_reply.started":"2021-06-24T16:22:38.288521Z","shell.execute_reply":"2021-06-24T16:22:39.870257Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random\nfrom typing import Union\nfrom math import ceil\nfrom os import mkdir","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNK = '<UNK>' # Unknown word\nEOS = '<EOS>' # End of sentence\n\ndef build_vocabulary(sentences: list, words_to_keep: int) -> list:\n    # builds a vocabulary using 'words_to_keep' most frequent words\n    # encountered in the list of sentences\n    vocabulary = {}\n    n = len(sentences)\n    for i, s in enumerate(sentences):\n        print('Creating vocabulary: %05.2f%%' % (100*(i+1)/n,), end='\\r')\n        for word in s.strip().split():\n            vocabulary[word] = vocabulary.get(word, 0) + 1\n    vocabulary = list(vocabulary.items())\n    vocabulary.sort(reverse=True, key=lambda e: e[1])\n    vocabulary = vocabulary[0:words_to_keep]\n    vocabulary = [e[0] for e in vocabulary]\n    vocabulary.sort()\n    vocabulary.append(UNK)\n    vocabulary.append(EOS)\n    print('Done'+(50*' '))\n    return vocabulary\n\ndef build_sentences(vocabulary: list, sentences: list) -> list:\n    # transforms the list of sentences into a list of lists of words\n    # replacing words that are not in the vocabulary with <UNK>\n    # and appending <EOS> at the end of each sentence\n    processed_sent = []\n    n = len(sentences)\n    for i, sent in enumerate(sentences):\n        print('Creating sentences list: %05.2f%%' % (100*(i+1)/n,), end='\\r')\n        s = []\n        for word in sent.strip().split():\n            if word not in vocabulary:\n                word = UNK\n            s.append(word)\n        s.append(EOS)\n        processed_sent.append(s)\n    print('Done'+(50*' '))\n    return processed_sent\n\ndef word2index(vocabulary: list, word: str) -> int:\n    # returns the index of 'word' in the vocabulary\n    return vocabulary.index(word)\n\ndef words2onehot(vocabulary: list, words: list) -> np.ndarray:\n    # transforms the list of words given as argument into\n    # a one-hot matrix representation using the index in the vocabulary\n    n_words = len(words)\n    n_voc = len(vocabulary)\n    indices = np.array([word2index(vocabulary, word) for word in words])\n    a = np.zeros((n_words, n_voc))\n    a[np.arange(n_words), indices] = 1\n    return a\n\ndef sample_word(vocabulary: list, prob: np.ndarray) -> str:\n    # sample a word from the vocabulary according to 'prob'\n    # probability distribution (the softmax output of our model)\n    # until it is != <UNK>\n    while True:\n        word = np.random.choice(vocabulary, p=prob)\n        if word != UNK:\n            return word","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:22:42.141656Z","iopub.execute_input":"2021-06-24T16:22:42.142001Z","iopub.status.idle":"2021-06-24T16:22:42.155494Z","shell.execute_reply.started":"2021-06-24T16:22:42.141971Z","shell.execute_reply":"2021-06-24T16:22:42.154519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model:\n    def __init__(self, vocabulary: list = [], a_size: int = 0):\n        self.vocab = vocabulary\n        self.vocab_size = len(vocabulary)\n        self.a_size = a_size\n        self.combined_size = self.vocab_size + self.a_size\n        \n        # weights and bias used to compute the new a\n        # (a = vector that is passes to the next time step)\n        self.wa = tf.Variable(tf.random.normal(\n            stddev=1.0/(self.combined_size+self.a_size),\n            shape=(self.combined_size, self.a_size),\n            dtype=tf.double))\n        self.ba = tf.Variable(tf.random.normal(\n            stddev=1.0/(1+self.a_size),\n            shape=(1, self.a_size),\n            dtype=tf.double))\n        \n        # weights and bias used to compute y (the softmax predictions)\n        self.wy = tf.Variable(tf.random.normal(\n            stddev=1.0/(self.a_size+self.vocab_size),\n            shape=(self.a_size, self.vocab_size),\n            dtype=tf.double))\n        self.by = tf.Variable(tf.random.normal(\n            stddev=1.0/(1+self.vocab_size),\n            shape=(1, self.vocab_size),\n            dtype=tf.double))\n        \n        self.weights = [self.wa, self.ba, self.wy, self.by]\n        self.optimizer = tf.keras.optimizers.Adam()\n    \n    def __call__(self,\n                 a: Union[np.ndarray, tf.Tensor],\n                 x: Union[np.ndarray, tf.Tensor],\n                 y: Union[np.ndarray, tf.Tensor, None] = None) -> tuple:\n        \n        a_new = tf.math.tanh(tf.linalg.matmul(tf.concat([a, x], axis=1), self.wa)+self.ba)\n        y_logits = tf.linalg.matmul(a_new, self.wy)+self.by\n        if y is None:\n            # during prediction return softmax probabilities\n            return (a_new, tf.nn.softmax(y_logits))\n        else:\n            # during training return loss\n            return (a_new, tf.math.reduce_mean(\n                        tf.nn.softmax_cross_entropy_with_logits(y, y_logits)))\n    \n    def fit(self,\n            sentences: list,\n            batch_size: int = 128,\n            epochs: int = 10) -> None:\n        \n        n_sent = len(sentences)\n        num_batches = ceil(n_sent / batch_size)\n        \n        for epoch in range(epochs):\n            \n            random.shuffle(sentences)\n            start = 0\n            batch_idx = 0\n            \n            while start < n_sent:\n                \n                print('Training model: %05.2f%%' %\n                      (100*(epoch*num_batches+batch_idx+1)/(epochs*num_batches),),\n                      end='\\r')\n                \n                batch_idx += 1\n                end = min(start+batch_size, n_sent)\n                batch_sent = sentences[start:end]\n                start = end\n                batch_sent.sort(reverse=True, key=lambda s: len(s))\n                \n                init_num_words = len(batch_sent)\n                a = np.zeros((init_num_words, self.a_size))\n                x = np.zeros((init_num_words, self.vocab_size))\n                \n                time_steps = len(batch_sent[0])\n                \n                with tf.GradientTape() as tape:\n                \n                    losses = []\n                    for t in range(time_steps):\n                        words = []\n                        for i in range(init_num_words):\n                            if t >= len(batch_sent[i]):\n                                break\n                            words.append(batch_sent[i][t])\n\n                        y = words2onehot(self.vocab, words)\n                        n = y.shape[0]\n                        a, loss = self(a[0:n], x[0:n], y)\n                        losses.append(loss)\n                        x = y\n                    \n                    loss_value = tf.math.reduce_mean(losses)\n                \n                grads = tape.gradient(loss_value, self.weights)\n                self.optimizer.apply_gradients(zip(grads, self.weights))\n\n    def sample(self) -> str:\n        # sample a new sentence from the learned model\n        sentence = ''\n        a = np.zeros((1, self.a_size))\n        x = np.zeros((1, self.vocab_size))\n        while True:\n            a, y_hat = self(a, x)\n            word = sample_word(self.vocab, tf.reshape(y_hat, (-1,)))\n            if word == EOS:\n                break\n            sentence += ' '+word\n            x = words2onehot(self.vocab, [word])\n        return sentence[1:]\n    \n    def predict_next(self, sentence: str) -> str:\n        # predict the next part of the sentence given as parameter\n        a = np.zeros((1, self.a_size))\n        for word in sentence.strip().split():\n            if word not in vocabulary:\n                word = UNK\n            x = words2onehot(self.vocab, [word])\n            a, y_hat = self(a, x)\n        s = ''\n        while True:\n            word = sample_word(self.vocab, tf.reshape(y_hat, (-1,)))\n            if word == EOS:\n                break\n            s += ' '+word\n            x = words2onehot(self.vocab, [word])\n            a, y_hat = self(a, x)\n        return s\n    \n    def save(self, name: str) -> None:\n        mkdir(f'./{name}')\n        with open(f'./{name}/vocabulary.txt', 'w') as f:\n            f.write(','.join(self.vocab))\n        with open(f'./{name}/a_size.txt', 'w') as f:\n            f.write(str(self.a_size))\n        np.save(f'./{name}/wa.npy', self.wa.numpy())\n        np.save(f'./{name}/ba.npy', self.ba.numpy())\n        np.save(f'./{name}/wy.npy', self.wy.numpy())\n        np.save(f'./{name}/by.npy', self.by.numpy())\n    \n    def load(self, name: str) -> None:\n        with open(f'./{name}/vocabulary.txt', 'r') as f:\n            self.vocab = f.read().split(',')\n        with open(f'./{name}/a_size.txt', 'r') as f:\n            self.a_size = int(f.read())\n            \n        self.vocab_size = len(self.vocab)\n        self.combined_size = self.vocab_size + self.a_size\n        \n        self.wa = tf.Variable(np.load(f'./{name}/wa.npy'))\n        self.ba = tf.Variable(np.load(f'./{name}/ba.npy'))\n        self.wy = tf.Variable(np.load(f'./{name}/wy.npy'))\n        self.by = tf.Variable(np.load(f'./{name}/by.npy'))\n        self.weights = [self.wa, self.ba, self.wy, self.by]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:22:44.67998Z","iopub.execute_input":"2021-06-24T16:22:44.680307Z","iopub.status.idle":"2021-06-24T16:22:44.711695Z","shell.execute_reply.started":"2021-06-24T16:22:44.680281Z","shell.execute_reply":"2021-06-24T16:22:44.710447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/million-headlines/abcnews-date-text.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:22:46.867066Z","iopub.execute_input":"2021-06-24T16:22:46.867414Z","iopub.status.idle":"2021-06-24T16:22:47.812492Z","shell.execute_reply.started":"2021-06-24T16:22:46.867386Z","shell.execute_reply":"2021-06-24T16:22:47.811453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocabulary = build_vocabulary(df['headline_text'].values.tolist(), words_to_keep=10000)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:22:50.524347Z","iopub.execute_input":"2021-06-24T16:22:50.524675Z","iopub.status.idle":"2021-06-24T16:25:08.010866Z","shell.execute_reply.started":"2021-06-24T16:22:50.524647Z","shell.execute_reply":"2021-06-24T16:25:08.010047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(vocabulary)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:26:07.726078Z","iopub.execute_input":"2021-06-24T16:26:07.726428Z","iopub.status.idle":"2021-06-24T16:26:07.731872Z","shell.execute_reply.started":"2021-06-24T16:26:07.726398Z","shell.execute_reply":"2021-06-24T16:26:07.730974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = build_sentences(vocabulary, df['headline_text'].values.tolist())","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:26:09.580631Z","iopub.execute_input":"2021-06-24T16:26:09.580979Z","iopub.status.idle":"2021-06-24T16:39:26.288415Z","shell.execute_reply.started":"2021-06-24T16:26:09.580945Z","shell.execute_reply":"2021-06-24T16:39:26.287623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(vocabulary, 1024)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:42:46.111381Z","iopub.execute_input":"2021-06-24T16:42:46.111706Z","iopub.status.idle":"2021-06-24T16:42:46.119247Z","shell.execute_reply.started":"2021-06-24T16:42:46.111677Z","shell.execute_reply":"2021-06-24T16:42:46.118402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(sentences, batch_size=128, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T16:42:48.84581Z","iopub.execute_input":"2021-06-24T16:42:48.846139Z","iopub.status.idle":"2021-06-24T17:17:52.083501Z","shell.execute_reply.started":"2021-06-24T16:42:48.84611Z","shell.execute_reply":"2021-06-24T17:17:52.082649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('news_headlines_model')\n# model.load('news_headlines_model')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:22:14.5963Z","iopub.execute_input":"2021-06-24T17:22:14.596658Z","iopub.status.idle":"2021-06-24T17:22:14.905813Z","shell.execute_reply.started":"2021-06-24T17:22:14.596626Z","shell.execute_reply":"2021-06-24T17:22:14.90499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(20):\n    print(model.sample())","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:22:16.479718Z","iopub.execute_input":"2021-06-24T17:22:16.480065Z","iopub.status.idle":"2021-06-24T17:22:17.038231Z","shell.execute_reply.started":"2021-06-24T17:22:16.480033Z","shell.execute_reply":"2021-06-24T17:22:17.037339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = 'scientists just discovered'\ns += model.predict_next(s)\ns","metadata":{"execution":{"iopub.status.busy":"2021-06-24T17:24:05.235679Z","iopub.execute_input":"2021-06-24T17:24:05.236025Z","iopub.status.idle":"2021-06-24T17:24:05.260394Z","shell.execute_reply.started":"2021-06-24T17:24:05.235991Z","shell.execute_reply":"2021-06-24T17:24:05.259669Z"},"trusted":true},"execution_count":null,"outputs":[]}]}