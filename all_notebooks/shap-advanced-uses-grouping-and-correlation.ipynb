{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport shap\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import cross_validate, train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom itertools import repeat, chain\nrevert_dict = lambda d: dict(chain(*[zip(val, repeat(key)) for key, val in d.items()]))\n        \n%matplotlib inline\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grouped_shap(shap_vals, features, groups):\n    groupmap = revert_dict(groups)\n    shap_Tdf = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features')).T\n    shap_Tdf['group'] = shap_Tdf.reset_index().features.map(groupmap).values\n    shap_grouped = shap_Tdf.groupby('group').sum().T\n    return shap_grouped","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')\nplt.figure(figsize=(10,4))\ndata.Date.value_counts(True).sort_index().cumsum().plot();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = data.drop(['Date', 'RainTomorrow'], axis=1).columns.tolist()\ncat_features = data[features].select_dtypes('object').columns.tolist()\ndata['target'] = (data['RainTomorrow']=='Yes').astype(int)\n\ntrain = data.query(\"Date < '2015-01-01'\").dropna(subset=['RainTomorrow'])\ntest  = data.query(\"Date > '2015-01-01'\").dropna(subset=['RainTomorrow'])\n\nclf = CatBoostClassifier(iterations=30)\nclf.fit(train[features].fillna(-99), train['target'], cat_features=cat_features, verbose=False)\n\ntrain_auc = roc_auc_score(train['target'], clf.predict_proba(train[features].fillna(-99))[:,1])\ntest_auc  = roc_auc_score(test['target'],  clf.predict_proba(test[features].fillna(-99))[:,1] )\nprint(\"Train AUC: \", train_auc)\nprint(\"Out-of-time AUC: \", test_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shap import TreeExplainer\nexp = TreeExplainer(clf)\n\nshap_vals = exp.shap_values(test[features].fillna(-99))\nshap_df = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features'))\nshap.summary_plot(shap_vals, test[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_vals = exp.shap_values(train[features].fillna(-99))\nshap_df = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features'))\nshap.summary_plot(shap_vals, train[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ngroups_by_time = {\n    '3pm': [f for f in features if '3pm' in f],\n    '9am': [f for f in features if '9am' in f],\n    'not_time_based': [f for f in features if '9am' not in f and '3pm' not in f]\n}\n\ngroups_by_type = {\n    'humidity_and_rain': ['Rainfall',\n                          'Evaporation',\n                          'Humidity9am',\n                          'Humidity3pm',\n                          'RainToday'],\n    'temperature': ['MinTemp',\n                    'MaxTemp',\n                    'Temp9am',\n                    'Temp3pm'],\n    'sun_and_clouds': ['Cloud9am',\n                       'Cloud3pm',\n                       'Sunshine'],\n    'wind_and_pressure': ['WindGustDir',\n                          'WindGustSpeed',\n                          'WindDir9am',\n                          'WindDir3pm',\n                          'WindSpeed9am',\n                          'WindSpeed3pm',\n                          'Pressure9am',\n                          'Pressure3pm'],\n    'location': ['Location']\n}\n\n\nmaptime = revert_dict(groups_by_time)\nmaptype = revert_dict(groups_by_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_time = grouped_shap(shap_vals, features, groups_by_time)\nshap_type = grouped_shap(shap_vals, features, groups_by_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_time.values, features=shap_time.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_type.values, features=shap_type.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = pd.Series(clf.predict_proba(train[features].fillna(-99))[:,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quintiles = pd.qcut(preds, np.linspace(0,1,6), labels=np.arange(5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,5, figsize=(36, 7))\nfor q in range(5):\n    plt.sca(ax[q])\n    shap.summary_plot(shap_vals[(quintiles==q).values], \n                      train.loc[(quintiles==q).values, features], \n                      show=False, \n                      plot_size=None, \n                      color_bar=False,\n                      max_display=6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1,5, figsize=(36, 6))\nfor q in range(5):\n    plt.sca(ax[q])\n    shap.summary_plot(shap_vals[(quintiles==q).values], \n                      train.loc[(quintiles==q).values, features], \n                      show=False, \n                      plot_size=None, \n                      color_bar=False,\n                      max_display=6)\n    plt.title(f\"Quintile {q} of predictions\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"biens = np.arange(3)*2+2009\nyear = train.Date.apply(lambda s: s.split('-')[0]).astype(int)\nfig, ax = plt.subplots(1,3, figsize=(36, 10))\nfor i, b in enumerate(biens):\n    plt.sca(ax[i])\n    idx = (year==b).values\n    shap.summary_plot(shap_vals[idx], \n                      train.loc[idx, features], \n                      show=False, \n                      plot_size=None, \n                      color_bar=False)\n    plt.title(f\"Year {b}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.MaxTemp.plot.hist(bins=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.Humidity3pm.plot.hist(bins=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rained_flag = (train.MinTemp > 25).values\nrained_shap = shap_df[rained_flag]\nrained_feats = train.loc[rained_flag, features]\n\nshap.summary_plot(rained_shap.values, rained_feats, show=False)\nplt.title(\"Shap for hot days (minTemp > 25 Celsius) \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rained_flag = (train.MaxTemp < 10).values\nrained_shap = shap_df[rained_flag]\nrained_feats = train.loc[rained_flag, features]\n\nshap.summary_plot(rained_shap.values, rained_feats, show=False)\nplt.title(\"Shap for cold days (maxTemp < 10 Celsius)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,9))\nfeat_order = shap_df.abs().mean().sort_values().index.drop(\"WindGustDir\").tolist()[::-1]\nsns.heatmap(shap_df.corr().abs().loc[feat_order, feat_order], cbar=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.clustermap(shap_df.drop(\"WindGustDir\", axis=1).corr().abs())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing uk accidents data","metadata":{}},{"cell_type":"code","source":"import warnings\ncas = pd.read_csv(\"/kaggle/input/dft-accident-data/Casualties0515.csv\",  delimiter=',', error_bad_lines=False, warn_bad_lines=False)\nveh = pd.read_csv(\"/kaggle/input/dft-accident-data/Vehicles0515.csv\",  delimiter=',', error_bad_lines=False, warn_bad_lines=False)\nacc = pd.read_csv(\"/kaggle/input/dft-accident-data/Accidents0515.csv\", delimiter=',', error_bad_lines=False, warn_bad_lines=False)\ncas['Accident_Index'] = cas['Accident_Index'].astype(str)+'g'\nveh['Accident_Index'] = veh['Accident_Index'].astype(str)+'g'\nacc['Accident_Index'] = acc['Accident_Index'].astype(str)+'g'\ncas = cas.set_index('Accident_Index')\nveh = veh.set_index('Accident_Index')\nacc = acc.set_index('Accident_Index')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joined = (\nacc\n.join(cas, on=[\"Accident_Index\"], how='inner', rsuffix='cas')\n.join(veh, on=[\"Accident_Index\"], how='inner', rsuffix='veh'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj_cols = joined.select_dtypes('object').columns.tolist()\nfeatures = joined.columns.drop(['Vehicle_Referenceveh', 'Casualty_Severity', 'Accident_Severity']+obj_cols).tolist()\nfeatures =[f for f in features if f!= 'target']\njoined['target'] = (joined.Casualty_Severity<3).astype(int)\njoined['Date'] = pd.to_datetime(joined.Date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = {\n    'geografical': [ \n        'Location_Easting_OSGR',\n        'Location_Northing_OSGR',\n        'Longitude',\n        'Latitude',\n        'Junction_Location',\n        'Urban_or_Rural_Area'],\n    \n    'road_specs': [\n        '1st_Road_Class',\n        '1st_Road_Number',\n        'Junction_Detail',\n        'Junction_Control',\n        '2nd_Road_Class',\n        '2nd_Road_Number',\n        'Road_Type',\n        'Speed_limit',\n        'Police_Force',\n        'Local_Authority_(District)'],\n    \n    'accident': [   \n        'Number_of_Vehicles',\n        'Number_of_Casualties',\n        'Pedestrian_Crossing-Human_Control',\n        'Pedestrian_Crossing-Physical_Facilities',\n        'Towing_and_Articulation',\n        'Vehicle_Manoeuvre',\n        'Vehicle_Location-Restricted_Lane',\n        'Skidding_and_Overturning',\n        'Hit_Object_in_Carriageway',\n        'Vehicle_Leaving_Carriageway',\n        'Hit_Object_off_Carriageway',\n        '1st_Point_of_Impact',\n        'Carriageway_Hazards',\n        'Casualty_Reference',\n        'Casualty_Type',\n        'Did_Police_Officer_Attend_Scene_of_Accident'],\n    \n    'conditions': [\n         'Light_Conditions',\n         'Weather_Conditions',\n         'Road_Surface_Conditions',\n         'Special_Conditions_at_Site',\n         'Day_of_Week'],\n    \n    'victim_specs': [\n         'Casualty_Class',\n         'Sex_of_Casualty',\n         'Age_of_Casualty',\n         'Age_Band_of_Casualty',\n         'Pedestrian_Location',\n         'Pedestrian_Movement',\n         'Car_Passenger',\n         'Bus_or_Coach_Passenger',\n         'Pedestrian_Road_Maintenance_Worker',\n         'Casualty_Home_Area_Type'],\n    \n    'driver_specs': [\n        'Journey_Purpose_of_Driver',\n        'Sex_of_Driver',\n        'Age_of_Driver',\n        'Age_Band_of_Driver',\n        'Driver_IMD_Decile',\n        'Driver_Home_Area_Type'],\n    \n    'vehicle_specs': [ \n        'Vehicle_Type',\n        'Was_Vehicle_Left_Hand_Drive?',\n        'Engine_Capacity_(CC)',\n        'Propulsion_Code',\n        'Age_of_Vehicle',\n        'Vehicle_Reference'],\n\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joined.Date.dt.year.value_counts().sort_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = joined.query(\"Date < '2012-01-01'\").dropna(subset=['target'])\ntest  = joined.query(\"Date > '2012-01-01'\").dropna(subset=['target'])\n\nclf = CatBoostClassifier(iterations=30)\nclf.fit(train[features].fillna(-99), train['target'], verbose=False)\n\ntrain_auc = roc_auc_score(train['target'], clf.predict_proba(train[features].fillna(-99))[:,1])\ntest_auc  = roc_auc_score(test['target'],  clf.predict_proba(test[features].fillna(-99))[:,1] )\nprint(\"Train AUC: \", train_auc)\nprint(\"Out-of-time AUC: \", test_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shap import TreeExplainer\nexp = TreeExplainer(clf)\ntest_shap = test.sample(10000)\n\nshap_vals = exp.shap_values(test_shap[features].fillna(-99))\nshap_df = pd.DataFrame(shap_vals, columns=pd.Index(features, name='features'))\nshap.summary_plot(shap_vals, test_shap[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_grouped = grouped_shap(shap_vals, features, groups)\nshap.summary_plot(shap_grouped.values, feature_names = shap_grouped.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = {\n    'geografical': [ \n        'Location_Easting_OSGR',\n        'Location_Northing_OSGR',\n        'Longitude',\n        'Latitude',\n        'Junction_Location',\n        'Urban_or_Rural_Area'],\n    \n    'road_specs': [\n        '1st_Road_Class',\n        '1st_Road_Number',\n        'Junction_Detail',\n        'Junction_Control',\n        '2nd_Road_Class',\n        '2nd_Road_Number',\n        'Road_Type',\n        'Speed_limit',\n        'Police_Force',\n        'Local_Authority_(District)'],\n    \n    'accident_before': [   \n        'Pedestrian_Crossing-Human_Control',\n        'Pedestrian_Crossing-Physical_Facilities',\n        'Towing_and_Articulation',\n        'Vehicle_Manoeuvre',\n        'Vehicle_Location-Restricted_Lane',\n        'Vehicle_Leaving_Carriageway'],\n    \n    'accident_during': [\n        'Number_of_Vehicles',\n        'Number_of_Casualties',\n        'Hit_Object_in_Carriageway',\n        'Hit_Object_off_Carriageway',\n        'Skidding_and_Overturning',\n        '1st_Point_of_Impact'],\n    \n    'accident_after': [\n        'Carriageway_Hazards',\n        'Casualty_Reference',\n        'Casualty_Type',\n        'Did_Police_Officer_Attend_Scene_of_Accident'],\n    \n    'conditions': [\n         'Light_Conditions',\n         'Weather_Conditions',\n         'Road_Surface_Conditions',\n         'Special_Conditions_at_Site',\n         'Day_of_Week'],\n    \n    'victim_specs': [\n         'Casualty_Class',\n         'Sex_of_Casualty',\n         'Age_of_Casualty',\n         'Age_Band_of_Casualty',\n         'Pedestrian_Location',\n         'Pedestrian_Movement',\n         'Car_Passenger',\n         'Bus_or_Coach_Passenger',\n         'Pedestrian_Road_Maintenance_Worker',\n         'Casualty_Home_Area_Type'],\n    \n    'driver_specs': [\n        'Journey_Purpose_of_Driver',\n        'Sex_of_Driver',\n        'Age_of_Driver',\n        'Age_Band_of_Driver',\n        'Driver_IMD_Decile',\n        'Driver_Home_Area_Type'],\n    \n    'vehicle_specs': [ \n        'Vehicle_Type',\n        'Was_Vehicle_Left_Hand_Drive?',\n        'Engine_Capacity_(CC)',\n        'Propulsion_Code',\n        'Age_of_Vehicle',\n        'Vehicle_Reference']\n}\nshap_grouped = grouped_shap(shap_vals, features, groups)\nshap.summary_plot(shap_grouped.values, feature_names = shap_grouped.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unimportant = shap_df.abs().mean()< 1e-3\nunimportant_feats = unimportant[unimportant.values].index.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(9,7), dpi=200)\nsns.heatmap(shap_df.drop(unimportant_feats, axis=1).corr(method='spearman').abs())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abcorr = shap_df.drop(unimportant_feats, axis=1).corr(method='spearman').abs()\nsns.clustermap(abcorr, figsize=(13,13))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"highestcorrs = (abcorr**2).sum().sort_values()[-20:].index.tolist()\nsns.clustermap(abcorr.loc[highestcorrs, highestcorrs], figsize=(8,8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"highestcorrs = (abcorr.replace(1, 0)).max().sort_values()[-20:].index.tolist()\nsns.clustermap(abcorr.loc[highestcorrs, highestcorrs], figsize=(8,8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"important = shap_df.abs().mean().sort_values()[-20:].index.tolist()\nsns.clustermap(abcorr.loc[important, important], figsize=(10,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}