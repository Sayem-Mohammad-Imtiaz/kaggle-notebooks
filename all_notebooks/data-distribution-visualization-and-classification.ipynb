{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing and Looking at The Last 5 Rows of The Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf=pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n\nBefore we could see that the column \"id\" will not be of much help to us, so we can eliminate it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"id\", axis=1, inplace=True)\nprint(df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nWe can also see that we only have missing data in the body mass index column, being a small amount we can get rid of those rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=[\"bmi\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\nsns.pairplot(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing The Distribution of The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax=plt.subplots(nrows=6, ncols=2, figsize=(20, 30))\nfig.tight_layout(h_pad=9, w_pad=7)\n\nsns.countplot(x=df.gender, ax=ax[0][0])\ninfo_text=\"Female: \"+str(df.gender.value_counts().Female)+\"\\nMale: \"+str(df.gender.value_counts().Male)+\"\\nOther: \"+str(df.gender.value_counts().Other)\nax[0][0].legend(title=info_text, labels=[])\nax[0][0].set_xlabel(\"Gender\")\nax[0][0].set_ylabel(\"Count\")\nax[0, 0].set_title(\"Gender\", fontsize=20)\n\nsns.histplot(df.age, ax=ax[0, 1], kde=True)\nax[0, 1].set_xlabel(\"Age\")\nax[0, 1].set_ylabel(\"Count\")\nax[0, 1].set_title(\"Age\", fontsize=20)\nplt.sca(ax[0, 1])\nplt.legend(labels=[], title=\"Line: Kernel Density Estimation\")\n\nsns.countplot(x=df.hypertension, ax=ax[1, 0])\nplt.sca(ax[1, 0])\nplt.xticks([0, 1], [\"No\", \"Yes\"])\ninfo_text=\"No: \"+str(df.hypertension.value_counts()[0])+\"\\nYes: \"+str(df.hypertension.value_counts()[1])\nplt.legend(labels=[], title=info_text)\nax[1, 0].set_xlabel(\"Answer\")\nax[1, 0].set_ylabel(\"Count\")\nax[1, 0].set_title(\"Hypertension\", fontsize=20)\n\nsns.countplot(x=df.heart_disease, ax=ax[1, 1])\nplt.sca(ax[1, 1])\nplt.xticks([0, 1], [\"No\", \"Yes\"])\ninfo_text=\"No: \"+str(df.heart_disease.value_counts()[0])+\"\\nYes: \"+str(df.heart_disease.value_counts()[1])\nplt.legend(labels=[], title=info_text)\nax[1, 1].set_xlabel(\"Answer\")\nax[1, 1].set_ylabel(\"Count\")\nax[1, 1].set_title(\"Heart Disease\", fontsize=20)\n\nsns.countplot(x=df.ever_married, ax=ax[2, 0], order=[\"No\", \"Yes\"])\nax[2, 0].set_xlabel(\"Answer\")\nax[2, 0].set_ylabel(\"Count\")\nax[2, 0].set_title(\"Ever Married?\", fontsize=20)\n\nplt.sca(ax[2, 1])\nax[2, 1].set_title(\"Work Type\", fontsize=20)\ndf.work_type.value_counts().index\nrenamed_labels=['Private', 'Self Employed', 'Children', 'Government Jobs', 'Never Worked']\nplt.pie(x=df.work_type.value_counts(), labels=renamed_labels, autopct=\"%1.1f%%\", \n        explode=df.work_type.nunique()*[.03])\n\nplt.sca(ax[3, 0])\nax[3, 0].set_title(\"Residence Type\", fontsize=20)\ndf.Residence_type.value_counts().index\nplt.pie(x=df.Residence_type.value_counts(), labels=df.Residence_type.value_counts().index, autopct=\"%1.1f%%\", \n        explode=df.Residence_type.nunique()*[.03])\n\nsns.histplot(x=df.avg_glucose_level, ax=ax[3, 1], kde=True)\nax[3, 1].set_title(\"Average Glucose Level In Blood\", fontsize=20)\nax[3, 1].set_xlabel(\"Level\")\nax[3, 1].set_ylabel(\"Count\")\n\nsns.histplot(x=df.bmi, kde=True, ax=ax[4, 0])\nax[4, 0].set_title(\"Body Mass Index\", fontsize=20)\nax[4, 0].set_xlabel(\"\")\nax[4, 0].set_ylabel(\"Count\")\n\nsns.countplot(x=df.smoking_status, ax=ax[4, 1])\nplt.sca(ax[4, 1])\nax[4, 1].set_title(\"Smoking Status\", fontsize=20)\nax[4, 1].set_xlabel(\"\")\nax[4, 1].set_ylabel(\"Count\")\n\nplt.sca(ax[5, 0])\nax[5, 0].set_title(\"Stroke\", fontsize=20)\nplt.pie(x=df.stroke.value_counts(), labels=[\"No\", \"Yes\"], autopct=\"%1.1f%%\")\n\nax[5, 1].set_visible(False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding Process"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_df=df.copy()\ndictionary_of_encodes={}\n\nfor column in categorical_df.select_dtypes(\"object\").columns:\n    categorical_df[column]=categorical_df[column].astype(\"category\") #Changing dtype.\n    dictionary_of_encodes[column]=dict( enumerate(categorical_df[column].cat.categories ) ) #Saving the encoding dictionary.\n    categorical_df[column]=categorical_df[column].cat.codes #Encoding the dataframe.\n    \ncategorical_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_df[[\"age\", \"avg_glucose_level\", \"bmi\"]].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating Certain Ranges For Numeric Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_df.age=pd.cut(x=categorical_df.age, bins=[x for x in range(0, 101, 10)])\ncategorical_df.avg_glucose_level=pd.cut(x=categorical_df.avg_glucose_level, bins=[x for x in range(55, 301, 20)])\ncategorical_df.bmi=pd.cut(x=categorical_df.bmi, bins=[x for x in range(10, 101, 10)])\n\nfor column in [\"age\", \"avg_glucose_level\", \"bmi\"]:\n    dictionary_of_encodes[column]=dict( enumerate(categorical_df[column].cat.categories ) ) #Saving the encoding dictionary.\n    categorical_df[column]=categorical_df[column].cat.codes\n\ncategorical_df[[\"age\", \"avg_glucose_level\", \"bmi\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adjusting Training Data\n\nAfter having seen the distribution of the data we know that we have little data on people who had strokes.\n \nInstead of doing an oversampling we will collect the same amount of data from people who had and did not have strokes in a totally random way, then a test will be done with the remaining data (despite having a large majority of test data from people that they did not have strokes, this process is being done with the intention of being able to see the precision of some classification algorithms)."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_df.stroke.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adjusting Train Data\n\ntype1indices=[]\ntype0indices=[]\n\nfor x in range(categorical_df.shape[0]):\n    if categorical_df.stroke.iloc[x]==1:\n        type1indices.append(x)\n    else:\n        type0indices.append(x)\n        \nimport numpy as np\n\nnp.random.shuffle(type0indices)\nnp.random.shuffle(type1indices)\n\ntrain_x=categorical_df.iloc[type0indices[0:101]+type1indices[0:101], 0:-1]\ntrain_y=categorical_df.iloc[type0indices[0:101]+type1indices[0:101], -1]\nval_x=categorical_df.iloc[type0indices[101:]+type1indices[101:], 0:-1]\nval_y=categorical_df.iloc[type0indices[101:]+type1indices[101:], -1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification By Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel=RandomForestRegressor(random_state=1)\nmodel.fit(train_x, train_y)\npred_y=model.predict(val_x)\n\npred_y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creation of a New Data Frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"comparing_results_df=pd.DataFrame(val_y) #Creating new DF.\ncomparing_results_df.columns=[\"actual\"] \ncomparing_results_df[\"pred\"]=pred_y #Adding new column for predicted values.\ncomparing_results_df['pred'] = np.where(comparing_results_df['pred']<=np.mean(pred_y), 0, 1) #adjusting values by the obtained probability.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decoding Values From Encoded Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df=pd.concat([val_x, comparing_results_df], axis=1).reset_index(drop=True)\n\nfor row_n in range(results_df.shape[0]):\n    for column in dictionary_of_encodes.keys():\n        results_df.loc[row_n, column]=dictionary_of_encodes[column][results_df.loc[row_n, column]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Precision Display"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\ndef plotAndSaveConfusionMatrix(name_of_model, name_of_pic, actual_arr, pred_arr):\n    confmat = confusion_matrix(actual_arr, pred_arr)\n    fig, ax=plt.subplots(ncols=2, nrows=1, figsize=(20, 7))\n\n    sns.heatmap(confmat, cbar=False, annot=True, fmt=\"g\", ax=ax[0])\n    plt.suptitle(\"Confusion Matrix of \"+name_of_model+\" Model\", fontsize=23)\n    plt.sca(ax[0])\n    plt.ylabel(\"True Values\")\n    plt.xlabel(\"Predicted Values\")\n\n    ax[1].set_axis_off()\n    ax[1].text(0, 0, classification_report(actual_arr, pred_arr), fontsize=20)\n    plt.savefig(name_of_pic+'.png')\n    plt.show()\n    \nplotAndSaveConfusionMatrix(\"Random Forest\", \"cm_rf\", comparing_results_df['actual'], comparing_results_df['pred'])\nresults_df[results_df.actual==1].tail(n=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification By Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression \n\nmodel=LogisticRegression(max_iter=440)\nmodel.fit(train_x, train_y)\npred_y=model.predict(val_x)\nresults_df.pred=pred_y\n\npred_y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Precision Display"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotAndSaveConfusionMatrix(\"Logistic Regression\", \"cm_lr\", results_df['actual'], pred_y)\nresults_df[results_df.actual==1].tail(n=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification By Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nmodel=MultinomialNB(alpha=1)\nmodel.fit(train_x, train_y)\npred_y=model.predict(val_x)\nresults_df.pred=pred_y\n\npred_y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Precision Display"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotAndSaveConfusionMatrix(\"Naive Bayes\", \"cm_nb\", results_df['actual'], pred_y)\nresults_df[results_df.actual==1].tail(n=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification By K-Nearest Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom scipy import stats\n\nbest_score=-1\nbest_n=-1\n\nfor x in range(1, 101):\n    model=KNeighborsClassifier(n_neighbors=x)\n    model.fit(train_x, train_y)\n    pred_y=model.predict(val_x)\n    \n    score=np.sum(pred_y==val_y)/len(val_y)\n    if score>best_score:\n        best_score=score\n        best_n=x\n        \nmodel=KNeighborsClassifier(n_neighbors=best_n)\nmodel.fit(train_x, train_y)\npred_y=model.predict(val_x)\nresults_df.pred=pred_y\n\nprint(stats.describe(pred_y), \"\\nBest N: \",best_n, sep=\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Precision Display"},{"metadata":{"trusted":true},"cell_type":"code","source":"plotAndSaveConfusionMatrix(\"K-Nearest Neighbors\", \"cm_knb\", results_df['actual'], pred_y)\nresults_df[results_df.actual==1].tail(n=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of The Precision of All The Algorithms Used"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\n\nfig, ax=plt.subplots(nrows=4, ncols=1, figsize=(20, 40))\nfig.tight_layout(h_pad=-80)\n\nax[0].imshow(mpimg.imread('cm_rf.png'))\nax[0].set_axis_off()\n\nax[1].imshow(mpimg.imread('cm_lr.png'))\nax[1].set_axis_off()\n\nax[2].imshow(mpimg.imread('cm_nb.png'))\nax[2].set_axis_off()\n\nax[3].imshow(mpimg.imread('cm_knb.png'))\nax[3].set_axis_off()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}