{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/autism-screening-for-toddlers/Toddler Autism dataset July 2018.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Case_No','Who completed the test'], axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(df['Class/ASD Traits '])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is a little bias? Majority are classfied as having ASD"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(10,10))\nax = sns.heatmap(df.corr(),annot=True,cmap='coolwarm',vmin=0, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A10 and Age_Mons are not really correlated with the score"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Age_Mons',y='Qchat-10-Score',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"okay, it looks like it doesn't matter what your age is, the chance of the getting high/low score won't be affected."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='A10',y='Qchat-10-Score',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A10 doesn't seem like a good indicator as well. "},{"metadata":{},"cell_type":"markdown","source":"I want to see what are the ethicity distribution among the survey responders. How common is that among the gender and ethicity? "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Ethnicity'])\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.columns\n# df_new = df[df['Class/ASD Traits ']=='Yes']\nsns.countplot(x='Ethnicity',hue='Sex',data=df)\nplt.xticks(rotation=90)\n\n#we can see that more survey respondants are males than females for each ethnicity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plot = df.groupby(['Sex', 'Ethnicity']).size().reset_index().pivot(columns='Sex', index='Ethnicity', values=0)\n# df_plot\ndf_plot.plot(kind='bar', stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y, hue = 'Ethnicity', 'prop', 'Sex'\nprop_df = (df[x]\n            .groupby(df[hue])\n            .value_counts(normalize=True)\n            .rename(y)\n            .reset_index())\nsns.barplot(x=x,y=y,hue=hue,data=prop_df)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.countplot(df['Sex'])\ndf = df[df['Class/ASD Traits ']=='Yes']\nsns.countplot(df['Sex'])\n#we can see more males are are categorized as ASD thru the app","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Q: how many of the males/males are ASD? What is the proportion? "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_yes = df[df['Class/ASD Traits ']=='Yes']\n\nm_prop = df_yes.Sex.value_counts()['m']/df.Sex.value_counts()['m']\nf_prop = df_yes.Sex.value_counts()['f']/df.Sex.value_counts()['f']\nm_prop\nf_prop","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataset is extremely bias? on the classification. It might causes problems with unmet data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\ncat_features = df.select_dtypes(include='object')\nnum_features = df.select_dtypes(exclude='object')\ndf = pd.get_dummies(df, drop_first=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df.drop(['Class/ASD Traits _Yes'], axis=1)\ny = df['Class/ASD Traits _Yes']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#logistic method\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\npreds = logreg.predict(X_test)\nlogreg.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\n#confusion matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nclassification_report(y_test, preds)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, it is suprising that logistic regression works perfectly fine? There's something wrong with this model or dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's try another model\n#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nclassification_report(y_test, pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#to get the optimum n_neighbors\n#this code is taken from a Udemy course \"Python for Data Science and Machine Learning\" taught by Jose Portilla\nimport matplotlib.pyplot as plt\nerror_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred = knn.predict(X_test)\n    error_rate.append(np.mean(y_test != pred))\nplt.figure(figsize=(10,10))\nplt.plot(range(1,40), error_rate, color='blue',linestyle='dashed',marker='o',markerfacecolor='red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the error rate dropped when it is around 27. We will set the n_neighbors to 27, and let's see what will happen. "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=27)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nclassification_report(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ok. much better result! Next step is Decision Tree and random forest. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#decision tree\nfrom sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train, y_train)\npred = dtree.predict(X_test)\nclassification_report(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Did I do something wrong? Why is the score so good?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's try random forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\npred = rf.predict(X_test)\nclassification_report(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one last model, which I will use SVM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nclassification_report(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion: Logistic, tree, random forest, KNN, and SVM predicted well. "},{"metadata":{},"cell_type":"markdown","source":"I will end this notebook here. This is my first notebook, so please let me know if there's anything I can improve. I look forward to any feedback. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}