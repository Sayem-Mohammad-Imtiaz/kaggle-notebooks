{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank.csv\")\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"pdays\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the percentiles are -1 and mean also seems to be less compare to max values "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df[\"pdays\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-1 is the missing values, so we can consider removing it when describing. As many value are missing we cannot remove it "},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"pdays\"][df[\"pdays\"]>0].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see that the mean, median are acceptable value and also as mean is greater than median we can say that it is right skewed and therefore we should standardardize it"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"education\",y=\"balance\", data=df[df[\"education\"]!=\"unknown\"],estimator=np.median);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can say that tertiary has the highest median compare to others"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nsns.boxplot(\"pdays\", data= df[df[\"pdays\"]>0]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df[df[\"pdays\"]>600].index,inplace=True) # remove putliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['deposit'].replace('no',0, inplace=True)\ndf['deposit'].replace('yes',1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"pdays\"]<0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will keep it as it is because if i change that to median and mean it will create a biasing like -1 as almost 90% data is missing "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"deposit\", y=\"age\", data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is not much change w.r.t age"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"deposit\", y=\"balance\", data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that response are more if the average balance of a person is more"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"deposit\", y=\"duration\", data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"if a person talk more to a sales person at an average there is a high chance of him being converted"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"deposit\", y=\"pdays\", data=df[df['pdays']>0]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that there is high chance of a person to not response if a person is not frequently contacted"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=\"deposit\", y=\"previous\", data=df[df['previous']>0]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is not much difference w.r.t response"},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features_names = ['age','balance', 'day', 'duration','campaign', 'pdays', 'previous']\ncategorical_features_name = ['job','marital','education','default','housing','loan','contact','month', 'poutcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss= StandardScaler()\nss.fit(df[numeric_features_names])\ndf[numeric_features_names] = ss.transform(df[numeric_features_names])\n#print(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, columns=categorical_features_name,drop_first=True) #drop first = true to take care of dummy\n#variable trap\n\n#print(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous',\n        'job_blue-collar', 'job_housemaid',\n       'job_management', 'job_retired', 'job_services',\n       'job_student', 'job_technician', 'job_unemployed',\n       'marital_married', 'marital_single', 'education_secondary',\n       'education_tertiary', 'education_unknown', 'housing_yes',\n       'loan_yes', 'contact_telephone', 'contact_unknown',\n       'month_dec', 'month_feb', 'month_jan', 'month_jun',\n       'month_mar', 'month_may', 'month_oct', 'month_sep',\n       'poutcome_other', 'poutcome_success', 'poutcome_unknown'] ]\ny = df[\"deposit\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 'default_yes' , 'job_unknown', 'month_nov', 'month_aug', , 'job_entrepreneur' , 'job_self-employed',  'month_jul' , 'day' as been removed as the p-value of the variables are greater than 0.05 which means they are not significant"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nOLS= sm.OLS(y,X).fit()\nOLS.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nmodel = lr.fit(X_train,np.array(y_train))\n\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(model, X_train, y_train, cv=5)\nnp.mean(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"mean of kfold accuracy is 81% let's check f1 score, precission and recall of dependent variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators=45,random_state=0,max_depth=30)\nclassifier=classifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(classifier, X_train, y_train, cv=5)\nnp.mean(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"mean of kfold accuracy is 83% let's check f1 score, precission and recall of dependent variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(\"Classification Report:\\n \", classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"f1 score of 1 has also been increased from 81% to 82% so as the accuracy from 81% to 83%"},{"metadata":{},"cell_type":"markdown","source":"### So we will prefer Random Forest rather than Logistics regression"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}