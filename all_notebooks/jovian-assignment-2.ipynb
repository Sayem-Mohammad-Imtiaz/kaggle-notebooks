{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Assignment 2\n# CalCOFI: predict the water temperature based on salinity\n\nCalCOFI: Over 60 years of oceanographic data: Is there a relationship between water salinity & water temperature? Can you predict the water temperature based on salinity?\n\nI took the data from the Kaggle website: [https://www.kaggle.com/sohier/calcofi/kernels](https://www.kaggle.com/sohier/calcofi/kernels) and ran the notebook on Kaggle with the CalCOFI data files provided.\n\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the workspace","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# check tha the last version of Jovian is installed\n!pip install jovian --upgrade --quiet\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Imports\n\nimport torch\nimport jovian\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Other constants\nDATASET_URL = \"../input/calcofi/bottle.csv\"\nDATA_FILENAME = \"bottle.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download and explore my dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The data will first be loaded as a Pandas dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = pd.read_csv(DATASET_URL)\n# I take the first 700 data points to examine more in detail\ndf = dataframe[:][:700]\n#df.iloc[0:3,8:25]\ndf.head()\n\n# I get a warning because of the different datatypes on import. I will clean up my dataset in the next steps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I can see that I have some columns which are not numeric which are ID's and some which have many missing values in it shown as 'NaN' in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Salnty'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I first take the rows where temperature and the salinity is not NaN:\n\ndf = df[df['Salnty'].notna()]\nprint(\"rows are now \", len(df))\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = df[df['T_degC'].notna()]\nprint(\"rows are now \", len(df))\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I had a few rows with NaNs in the temperature and salinity columns which I now have taken out, I get now 675 rows","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next I remove the columns containing NaN values. I think for this dataset it will not impact the results. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# will drop any columns (axis= 1) with a NaN value. I can do that, since we already made sure that the temperature and salinity columns have no NaNs values.\ndf = df.dropna(axis = 1, how = 'any') \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Also, I want to have only the columns with numerical data. I am not interested in Strings and ID's for this dataset.\ndf = df._get_numeric_data()\n\ndf.head()\n# The three variables that interest me the most are 'Depthm, T_degC, Salnty', for water depth of the sample, the salinity and the temperature. \n# the temperature is my output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I define my output column\noutput_cols = ['T_degC']\n\n# The inputs will be all my columns except the temperature column:\ninput_cols = df.columns[df.columns!='T_degC']\n# so finally I have my pandas inputs and outputs\ninput_cols,output_cols\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# these are my input columns\nlen(input_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['T_degC']].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inspect relationships between the data \n\nI am interested in the relationship of the data I extracted from the dataset. The inputs are the saltiness of the water and the depth. I want to create a model able to predict the temperature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# I make a scatter plot to see any visual relationship between the data \nsns.lmplot(x=\"Salnty\", y=\"T_degC\", data=df,\n           order=2, ci=None);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x=\"Depthm\", y=\"T_degC\", data=df,\n           order=2, ci=None);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs_array = df[input_cols].to_numpy()\ntargets_array = df[output_cols].to_numpy()\ninputs_array, targets_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I convert the numpy arrays inputs_array and targets_array into PyTorch tensors. I make sure that the data type is torch.float32.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = torch.float32\ninputs = torch.from_numpy(inputs_array).type(dtype)\ntargets = torch.from_numpy(targets_array).type(dtype)\ninputs.shape, targets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.dtype, targets.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project='jovian-Assignment-2', environment=None)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a TensorDataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = TensorDataset(inputs, targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pick a number between 0.1 and 0.2 to determine the fraction of data that will be used for creating the validation set. Then use random_split to create training & validation datasets.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_percent = 0.1 # between 0.1 and 0.2\nnum_rows = len(df)\nnum_cols = len(df.columns)\nval_size = int(num_rows * val_percent)\n\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(df,(train_size, val_size)) # Use the random_split function to split dataset into 2 parts of the desired length","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pick a batch size for the data loader.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at a batch of data to verify everything is working fine so far.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's save our work by committing to Jovian.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project='jovian-Assignment-2', environment=None) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a Linear Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(input_cols)\nprint(input_size)\noutput_size = len(output_cols)\nprint(output_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TempModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb)                          # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out,targets)                         # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out,targets)                     # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us create a model using the TempModel class. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = TempModel()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check out the weights and biases of the model using model.parameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.linear.weight.dtype,model.linear.bias.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project='jovian-Assignment-2', environment=None) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model to fit the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = evaluate (model,val_loader)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are now ready to train the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nlr = 1e-6\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nlr = 1e-6\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 500\nlr = 1e-6\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 500\nlr = 1e-8\nhistory4 = fit(epochs, lr, model, train_loader, val_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is the final validation loss of your model?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = 1.0058\njovian.log_metrics(val_loss=val_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = []\nfor value in history1+history2+history3+history4:\n    loss.append(value['val_loss'])\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('loss vs. No. of epochs');\nplt.plot(loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make predictions using the trained model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)                # fill this\n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[0]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[10]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[23]\npredict_single(input, target, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project='jovian-Assignment-2', environment=None) \njovian.commit(project='jovian-Assignment-2', environment=None) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}