{"cells":[{"metadata":{"id":"HrdZsbhSrXfq"},"cell_type":"markdown","source":"# Importing the libraries and data"},{"metadata":{"id":"k7ZWlAgrrXf7","trusted":true},"cell_type":"code","source":"# Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom sklearn.model_selection import train_test_split\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{"id":"gpZyL6TnrXf9","trusted":true},"cell_type":"code","source":"# Importing Datasets\nall_dataset = pd.read_csv('../input/spotify-dataset-19212020-160k-tracks/data.csv')\n# artist_dataset = pd.read_csv('data_by_artist.csv')\n# genres_dataset = pd.read_csv('data_by_genres.csv')\n# year_dataset = pd.read_csv('data_by_year.csv')\n# w_genres_dataset = pd.read_csv('data_w_genres.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"WFHMKl0orXf-"},"cell_type":"markdown","source":"# Exploration"},{"metadata":{"id":"ZAIQH0eOrXf_","outputId":"9c4dbbad-b9db-4577-ec52-cdf58eb60672","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"all_dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"AZqNQ2TQrXgA","outputId":"f6e24f15-92c9-457b-a545-92ea3d5dca25","trusted":true},"cell_type":"code","source":"all_dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"0sijjT9JrXgA"},"cell_type":"markdown","source":"## EDA Plan of attack and some expectations\n\n#### Univariate Analysis\nOverall Valence on songs? Tendency of songs? <br>\nSong distribution by years <br>\nAcousticness distribution (Most songs acoustic or not?) <br>\nDanceabilitty distribution (Most songs danceable or not?) <br>\nSong duration distribution <br>\nExplicit songs count? <br>\nInstrumentalness distribution? <br>\nkey count? <br>\nliveness distribution? <br>\nloudness distribution? <br>\nmode count? <br>\npopularity distribution? <br>\nspeechiness distribution? <br>\ntempo distribution? <br>\n\n\n#### Bivariate Analysis\n##### Popularity\nyear vs popularity <br>\nvalence vs popularity (valence=sentiment [depression 0 or happy 1]) <br>\nmode vs popularity <br>\nenergy vs popularity <br>\nkey vs popularity <br>\nexplicit vs popularity <br> \n\n###### Valence\ntempo vs valence (expect low tempo low valence -- high tempo high valence) <br>\nacousticness(not electronicaly amplified) vs valence <br>\nenergy vs valence (expect high energy high valence) <br>\nkey vs valence <br>\nvalence vs year? (song valence differences in the last century) <br>\nvalence vs loudness (expect low loudness low valence) <br>\n\n###### Others\ninstrumentalness(instruments) vs year <br>\ntempo vs danceavility (expect high tempo high danceability) <br>\ndanceability vs explicit <br>\nloudness vs explicit <br>\n\n\n#### More info for the audio features you can find them in the spotify API docs here: [Audio Features](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/)"},{"metadata":{"id":"c4Do4F5XrXgB","outputId":"e7b131d3-40f7-4879-fb9a-a0c9a58fddfa","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all_dataset.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"4_FvLJdxrXgC","outputId":"35402f49-70a7-44c1-d57b-4d30b013ea06","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"all_dataset.isnull().sum() / all_dataset.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"CDvPcpNhrXgC"},"cell_type":"markdown","source":"## Univariate Analysis"},{"metadata":{"id":"r2N1m4ImrXgD","outputId":"3a7435c9-aefa-46e7-94d5-39088677b043","trusted":true},"cell_type":"code","source":"# Valence Histogram\nfig = px.histogram(all_dataset, x=\"valence\", nbins=1000, title=\"Valence Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"yL6mNmkqrXgD"},"cell_type":"markdown","source":"If we look at the whole dataset, most songs are above 0.5 valence so we can say the <b>tendency of creating a positive song is a little bit higher </b>. But there is not a category of the two (sad-0, happy-1) that stands out. <br><br> Also <b>highest count of sad songs is between 0.03-0.04</b> and <b>highest count of happy songs is between 0.96-0.972</b>. These are the spikes you can see in the histogram."},{"metadata":{"id":"ViCHHarrrXgE","outputId":"4a3405a6-9da7-4e1a-9435-9fa98a4ebb26","trusted":true},"cell_type":"code","source":"# Year Histogram\nfig = px.histogram(all_dataset, x=\"year\", nbins=100, title = \"Year Song Count Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"FexgY6SNrXgE"},"cell_type":"markdown","source":"##### After 1945 songs in the dataset are almost the same count each year until 2020."},{"metadata":{"id":"D1N2KmEjrXgF","outputId":"dd4fe61f-e0b5-47f3-c062-5f4cf4866f06","trusted":true},"cell_type":"code","source":"# Acousticness Histogram\nfig = px.histogram(all_dataset, x=\"acousticness\", nbins=1000, title = \"Acousticness Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_ZDG3juirXgF"},"cell_type":"markdown","source":"Most songs tend to have <b>extreme values of acousticness</b> (either 0 or 1) and we can see that in the above histogram."},{"metadata":{"id":"_H1w25EhrXgG","outputId":"4fffe7f7-6202-40d5-8521-477b871068db","trusted":true},"cell_type":"code","source":"# Acousticness Histogram\nfig = px.histogram(all_dataset, x=\"danceability\", title = \"Danceability Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"jXwiVuDGrXgG"},"cell_type":"markdown","source":"We can see that the <b>danceability histogram</b> follows a <b>normal distribution</b>. <br>\nMost songs around 0.5 - 0.7 danceability."},{"metadata":{"id":"gJ6XBQECrXgH","outputId":"20f7c1b9-7ca3-4956-fc5f-891e679dc7ce","trusted":true},"cell_type":"code","source":"# Song Duration Histogram (We transform ms to minutes)\nfig = px.histogram(all_dataset, x=all_dataset.duration_ms/ (1000 * 60),range_x = [0,15],\n                   title = \"Song Duration Histogram\",\n                   color_discrete_sequence=['indianred'],\n                   labels={\n                \"x\": \"Song Duration(minutes)\",\n            })\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"wSpu8hbxrXgI"},"cell_type":"markdown","source":"Again we see that the <b>duration of the songs</b> in the dataset follow a <b>normal distribution</b> and most values are around 2:90 and 3:35 minutes."},{"metadata":{"id":"A4ldEUStrXgI","outputId":"936ec066-fafc-418e-b3f8-7a3abb0b154a","scrolled":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Explicit Songs Count/Percentage\ndf_explicit_labels = all_dataset.copy()\nfor i in range(len(all_dataset)):\n    if all_dataset[\"explicit\"][i] == 0:\n        df_explicit_labels[\"explicit\"][i] = \"non-explicit\"\n    elif all_dataset[\"explicit\"][i] == 1:\n        df_explicit_labels[\"explicit\"][i] = \"explicit\"\n\n\nfig = px.histogram(df_explicit_labels,\n                   x=df_explicit_labels.explicit,\n                   histnorm=\"percent\",\n                   color_discrete_sequence=['indianred'],\n                   title = \"Explicit Song Percentage\")\nfig.show()\nprint(\"Explicit Songs Count\\n\", df_explicit_labels[\"explicit\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"hr5VzhN5rXgJ"},"cell_type":"markdown","source":"#### Most songs in the dataset are non-explicit. (91.54 % non explicit and 8.46% explicit)"},{"metadata":{"id":"NDSryUYOrXgJ","outputId":"d55a7b41-f5a1-4c45-d244-28f48dcd7ca5","trusted":true},"cell_type":"code","source":"# Instrumentalness Histogram (Metric for how much instrumental is the song)\nfig = px.histogram(all_dataset, x=all_dataset.instrumentalness, nbins = 100, title = \"Instrumentalness Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"G4yh17l3rXgJ"},"cell_type":"markdown","source":"We can see from the above histogram that the songs in the dataset are <b>mostly non-instrumental</b>."},{"metadata":{"id":"hxoipLB_rXgJ","outputId":"edffa00a-6e80-46b2-8e90-dd164ffe8358","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Key Count of Songs\ndf_keys_labels = all_dataset.copy()\nkeys = [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]\nfor index in range(len(all_dataset)):\n    for key_index in range(len(keys)):\n        if all_dataset[\"key\"][index] == key_index:\n            df_keys_labels[\"key\"][index] = keys[key_index]\n            \nfig = px.histogram(df_keys_labels,\n                   x=df_keys_labels.key,\n                   title = \"Key of Songs Count\",\n                   color_discrete_sequence=['indianred'],\n                   category_orders={\n                \"key\": [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]\n            })\nfig.show()\nprint(\"Key of Songs Count\\n\", df_keys_labels[\"key\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"T2kGgZeQrXgK"},"cell_type":"markdown","source":"From the above plot we can see that the <b>most used key notes are C and G</b> and that all key notes with <b>#</b> (sharp notes) are mainly <b>used less by artists</b>."},{"metadata":{"id":"cKUlFIFjrXgK","outputId":"e20780bd-b032-4278-dcfb-e8b07082ad22","scrolled":false,"trusted":true},"cell_type":"code","source":"# Liveness Histogram\n# (Higher liveness values represent an increased probability that the track was performed live)(From Spotify docs)\nfig = px.histogram(all_dataset, x=all_dataset.liveness, nbins = 1000, title = \"Liveness Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"zx-DB9lSrXgL"},"cell_type":"markdown","source":"In most songs there is probably <b>not a live audience</b>. For Example : live concert song recording etc."},{"metadata":{"id":"2Bge0QIkrXgL","outputId":"f295760e-08aa-4dbb-aeca-a2f91d170bfd","trusted":true},"cell_type":"code","source":"# Loudness Histogram\nfig = px.histogram(all_dataset, x=all_dataset.loudness, nbins = 1000, title = \"Loudness Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"H0nyfc_orXgL"},"cell_type":"markdown","source":"Most values lie in bettween -20 and -5db."},{"metadata":{"id":"jx67NhnwrXgM","outputId":"d921166c-2983-4b9c-d4fc-a7a1d57a718c","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Modality of Songs Count/Percentage\ndf_mode_labels = all_dataset.copy()\nfor i in range(len(all_dataset)):\n    if all_dataset[\"mode\"][i] == 0:\n        df_mode_labels[\"mode\"][i] = \"Minor\"\n    elif all_dataset[\"mode\"][i] == 1:\n        df_mode_labels[\"mode\"][i] = \"Major\"\n\n\nfig = px.histogram(df_mode_labels, x=\"mode\", histnorm = \"percent\", title = \"Modality of Songs Percentage\",color_discrete_sequence=['indianred'])\nfig.show()\nprint(\"Modality of Songs Count\\n\", df_mode_labels[\"mode\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"TQ4vFnz8rXgM"},"cell_type":"markdown","source":"Songs in the dataset are <b>mostly Major</b> (approximately 70% of the whole dataset)."},{"metadata":{"id":"McuM8jWYrXgM","outputId":"a8d0f456-6d45-405b-8f3c-9172dbff0c8d","trusted":true},"cell_type":"code","source":"# Speechiness Histogram\n# 1.0 - 0.66 probably songs made entirely of words, 0.66-0.33 speech and music (rap songs), 0.33-0 other melodic songs\n# (from Spotify docs)\nfig = px.histogram(all_dataset, x=all_dataset.speechiness, nbins = 1000, title = \"Speechiness Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"zRlw_Z_7rXgM"},"cell_type":"markdown","source":"We can see that most of the songs do not have <b>non melodic speechiness</b>."},{"metadata":{"id":"8qbtxmVtrXgN","outputId":"c82cdfe2-07fd-4aea-8aa2-1b11118892ec","scrolled":false,"trusted":true},"cell_type":"code","source":"# Tempo Distribution (Beats Per Minute BPM)\nfig = px.histogram(all_dataset, x=all_dataset.tempo, nbins = 1000, title = \"Tempo Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_SZiqfZLlf3x","outputId":"6110708b-a3c6-4aff-9c67-3338b919e323","trusted":true},"cell_type":"code","source":"# Popularity Distribution\nfig = px.histogram(all_dataset, x=all_dataset.popularity, nbins = 100, title = \"Popularity Histogram\",color_discrete_sequence=['indianred'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"5KiDDzcQrXgN"},"cell_type":"markdown","source":"## Bivariate Analysis"},{"metadata":{"id":"r0anP5_CrXgN","trusted":true},"cell_type":"code","source":"# First I will add all the String label made columns into one dataframe\nlabeled_df = all_dataset.copy()\nlabeled_df[\"explicit\"] = df_explicit_labels[\"explicit\"]\nlabeled_df[\"key\"] = df_keys_labels[\"key\"]\nlabeled_df[\"mode\"] = df_mode_labels[\"mode\"]\n\n# Creating random subset due to the computational time and lagging of runtime\nsub_labeled_df = labeled_df.sample(frac=0.5,random_state=42,axis=0)\nsub_labeled_df[\"duration_ms\"] = sub_labeled_df[\"duration_ms\"]/ (1000*60)\nsub_labeled_df.rename(columns={\"duration_ms\" : \"duration\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"YPkrQ4uCrXgO","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Splitting to categorical and continous dataframes\nlabeled_cat_df = sub_labeled_df[[\"explicit\", \"key\", \"mode\"]].copy()\nlabeled_con_df = sub_labeled_df.drop(columns=[\"explicit\", \"key\", \"mode\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"nVs5-JGXrXgO","outputId":"9f6801c9-7ec7-4976-9ebc-c568a8f8078c","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Creating the indexes for the columns of sub_labeled_df\ntarget_columns = sub_labeled_df.select_dtypes(include=[\"float64\",\"int64\"]).columns\ntarget_columns = np.delete(target_columns, target_columns.get_loc(\"popularity\"))\ntarget_columns","execution_count":null,"outputs":[]},{"metadata":{"id":"-9EqIQTmPZ9v","outputId":"be04db01-dcd7-48cc-e1db-24a54fbc01cc","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Creating the indexes for the categorical columns\ncat_target_columns = labeled_cat_df.columns\ncat_target_columns","execution_count":null,"outputs":[]},{"metadata":{"id":"w9Q6esF9YJu4","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# # Defining function to plot boxplots or Scatterplots dropdown menus\n# \"\"\"\n# df = data, \n# target_columns are the different columns that we apply the plots against popularity\n# \"\"\"\n# def plot_graph(df,target_columns,boxplot=False):\n#     fig = go.Figure()\n#     #buttons are the things you see in the dropdown \n#     buttons = []\n    \n#     if (boxplot == True):\n#         fig.add_trace(go.Box(x= df[target_columns[0]],\n#                          y= df[\"popularity\"],\n#                          marker_color = 'indianred',\n#                          boxmean=True))\n#     else:\n#         fig.add_trace(go.Scattergl(x= df[target_columns[0]], y=df[\"popularity\"], mode=\"markers\",\n#                                marker = go.Marker(size=5,\n#                                color =df[\"popularity\"],\n#                                colorscale= 'YlOrRd',\n#                                symbol = 'circle',\n#                                showscale=True,\n#                                cmax=100,\n#                                cmin=0)))\n\n    \n\n#     for index in range(len(target_columns)):\n#           buttons.append(dict(method='restyle',\n#                       label=f\"{target_columns[index]} vs Popularity\".title(),\n#                       visible=True,\n#                       args=[{'y':[df[\"popularity\"].values],\n#                              'x':[df[target_columns[index]]]},[0]]\n#                       )\n#                 )\n\n#   #to get a menu to show, you need to create an updatemenu.\n\n#     updatemenu = []\n#     your_menu = {}\n#     updatemenu.append(your_menu)\n\n#     updatemenu[0]['buttons'] = buttons\n#     updatemenu[0]['direction'] = 'down'\n#     updatemenu[0]['showactive'] = True\n#     updatemenu[0]['yanchor'] = \"top\"\n\n#     # add dropdown menus to the figure\n#     fig.update_layout(showlegend=False, updatemenus=updatemenu)\n#     fig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_Lzctr78lf32","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Defining function to plot boxplots or Scatterplots dropdown menus\n\"\"\"\ndf = data, \ntarget_columns are the different columns that we apply the plots against popularity\nplot_against : string of vs variable\nboxplot : if Boxplot True, plot Boxplot\ncmax : max value of y value for marker colorscale\ncmin : min value of y value for marker colorscale\n\"\"\"\ndef plot_graph(df,target_columns,plot_against,cmax=100,cmin=0,boxplot=False):\n    fig = go.Figure()\n    #buttons are the things you see in the dropdown \n    buttons = []\n    \n    if (boxplot == True):\n        fig.add_trace(go.Box(x= df[target_columns[0]],\n                         y= df[plot_against],\n                         marker_color = 'indianred',\n                         boxmean=True))\n    else:\n        fig.add_trace(go.Scattergl(x= df[target_columns[0]], y=df[plot_against], mode=\"markers\",\n                               marker = go.Marker(size=5,\n                               color =df[plot_against],\n                               colorscale= 'YlOrRd',\n                               symbol = 'circle',\n                               showscale=True,\n                               cmax=cmax,\n                               cmin=cmin)))\n\n    \n\n    for index in range(len(target_columns)):\n          buttons.append(dict(method='restyle',\n                      label=f\"{target_columns[index]} vs {plot_against}\".title(),\n                      visible=True,\n                      args=[{'y':[df[plot_against].values],\n                             'x':[df[target_columns[index]]]},[0]]\n                      )\n                )\n\n  #to get a menu to show, you need to create an updatemenu.\n\n    updatemenu = []\n    your_menu = {}\n    updatemenu.append(your_menu)\n\n    updatemenu[0]['buttons'] = buttons\n    updatemenu[0]['direction'] = 'down'\n    updatemenu[0]['showactive'] = True\n    updatemenu[0]['yanchor'] = \"top\"\n\n    # add dropdown menus to the figure\n    fig.update_layout(showlegend=False, updatemenus=updatemenu)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"nI38BYBClf32","outputId":"f255369a-41c9-4cd0-c180-e43c9049bb23","trusted":true},"cell_type":"code","source":"plot_graph(sub_labeled_df,target_columns,\"popularity\")","execution_count":null,"outputs":[]},{"metadata":{"id":"5bt8uU5O1gpB"},"cell_type":"markdown","source":"## Insights from the above Dropdown menu Graphs"},{"metadata":{"id":"3nRIs3Is2G5i"},"cell_type":"markdown","source":"**Acousticness vs Popularity** : More songs with popularity 60 or above tend to have low values of acousticness, 0 - 0.4 .\n<br>\n**Danceability vs Popularity** : Popular songs (>60) tend to have values of danceability between 0.4 - 0.8 .\n<br>\n**Duration vs Popularity** : Most Popular songs have duration of 2-5 minutes.\n<br>\n**Energy vs Popularity** : Popularity values are a little bit higher in the second half of the plot (0.5 - 1).\n<br>\n**Instrumentalness vs Popularity** : Most Popular songs have low values of instrumentalness (0 - 0.1).\n<br>\n**Liveness vs Popularity** : Most Popular songs have values between 0 and 0.4.\n<br>\n**Loudness vs Popularity** : Most Popular songs have values between -20 and 0 db.\n<br>\n**Speechiness vs Popularity** : Tracks with low speechiness tend to be more popular.\n<br>\n**Tempo vs Popularity** : Tracks with tempo between 60 and 200 are more popular.\n<br>\n**Valence vs Popularity** : Can't distinguish any correlation with the popularity. \n<br>\n**Year vs Popularity** : Songs popularity is correlated with the year of the song. Newer songs have more popularity which is normal.\n<br>"},{"metadata":{"id":"GaymRYB5aR_E","outputId":"c5eebf1f-927c-4b11-bb6b-2b4526b4400a","trusted":true},"cell_type":"code","source":"# Plotting boxplots dropdown menu\nplot_graph(sub_labeled_df,cat_target_columns,\"popularity\",boxplot=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"RmUbKTPDlf34"},"cell_type":"markdown","source":"## Insights from above Boxplots Dropdown menu"},{"metadata":{"id":"-jybqe1Qlf34"},"cell_type":"markdown","source":"**Explicit vs Popularity** : Explicit songs, tend to be more popular that the non-explicit ones. Worthy to note here that we have very little number of explicit songs, in contrast with non-explicit.\n<br>\n**Key vs Popularity** : More popular songs tend to have key values of C# and F# but in general the popularity amongst keys is the same (with the exception of D#)\n<br>\n**Mode vs Popularity** : Not any significant differences in mode and popularity boxplot."},{"metadata":{"id":"__B849g1lf34","outputId":"84bcf980-7be8-458a-bb13-73112ed8baab","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Creating the indexes for the columns of sub_labeled_df except valence and popularity\ntarget_columns_val = sub_labeled_df.select_dtypes(include=[\"float64\",\"int64\"]).columns\ntarget_columns_val = np.delete(target_columns_val, target_columns_val.get_loc(\"popularity\"))\ntarget_columns_val = np.delete(target_columns_val, target_columns_val.get_loc(\"valence\"))\ntarget_columns_val","execution_count":null,"outputs":[]},{"metadata":{"id":"CkxbEyXhlf35","outputId":"4ec25bfb-af21-4fc1-b5c8-52b46a0109e4","trusted":true},"cell_type":"code","source":"plot_graph(sub_labeled_df,target_columns_val,\"valence\", cmax=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"hNprokSulf35"},"cell_type":"markdown","source":"## Insights from above Scatterplot (Valence)"},{"metadata":{"id":"vnnbwFIGlf35"},"cell_type":"markdown","source":"**Acousticness vs Valence** : We can't distinguish any correlation or pattern on the data.\n<br>\n**Danceability vs Valence** : We can see that in general, as the danceability goes high, the valence also goes high, as expected and noted in the Plan of Attack.\n<br>\n**Duration vs Valence** : If we consider that there aren't many tracks that last more than 10 minutes then we can't make any conclusions.\n<br>\n**Energy vs Valence** : We can see that songs with energy less 0.1 have also less valence than the songs with higher energy.\n<br>\n**Instrumentalness vs Valence** : Can't see any correlation between the two variables.\n<br>\n**Liveness vs Valence** : Even though there are less tracks with high liveness and high valence, we can't see any correlation.\n<br>\n**Loudness vs Valence** : More loud songs tend to have higher values of valence.\n<br>\n**Speechiness vs Valence** : We can see that most tracks gather in high or low speechiness values(near 1 or near 0). Additionally, tracks with higher speechiness tend to have lower valence than the tracks near 0.\n<br>\n**Tempo vs Valence** : The only thing we can notice is that tracks near 200BPM don't have valence values of 0.2 and below.\n<br>\n**Year vs Valence** : We can't distinguish any correlation or pattern on the data.\n<br>"},{"metadata":{"id":"Xwd4UvNhlf36","outputId":"5b60f4f8-a69a-442f-952a-2a337d3b0db9","trusted":true},"cell_type":"code","source":"plot_graph(sub_labeled_df,cat_target_columns,\"valence\", boxplot=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"YjhLS4Qnlf36"},"cell_type":"markdown","source":"## Insights from above Boxplots Dropdown menu (Valence)"},{"metadata":{"id":"euTPfNmrlf36"},"cell_type":"markdown","source":"**Explicit vs Valence** : Valence boxplots of explicit and non-explicit tracks are almost identical with the exception of the values in 75th percentile (explicit songs lower 75th percentile valence values).\n<br>\n**Key vs Valence** : Can't distinguish any correlation between keys and valence values.\n<br>\n**Mode vs Valence** : Boxplots of Major and Minor Modes almost identical."},{"metadata":{"id":"AQfCkC6xlf37","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_single_scatter(x,y,cmax=100,cmin=0,title=\"\"):\n    fig = go.Figure()\n    fig.add_trace(go.Scattergl(x= x, y=y, mode=\"markers\",\n                               marker = go.Marker(size=5,\n                               color =y,\n                               colorscale= 'YlOrRd',\n                               symbol = 'circle',\n                               showscale=True,\n                               cmax=cmax,\n                               cmin=cmin)))\n    fig.update_layout(title=title,\n                  yaxis_zeroline=False, xaxis_zeroline=False)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"A99XIGWhlf37","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_single_box(x,y,title=\"\"):\n    fig = go.Figure()\n    fig.add_trace(go.Box(x= x,\n                         y= y,\n                         marker_color = 'indianred',\n                         boxmean=True))\n    fig.update_layout(title=title,\n                  yaxis_zeroline=False, xaxis_zeroline=False)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"3CUzTtbTlf37","outputId":"1c4d6bec-dce6-4033-b9d4-d7f8938a273f","trusted":true},"cell_type":"code","source":"plot_single_scatter(x=sub_labeled_df.year,y=sub_labeled_df.instrumentalness, cmax=1,title=\"Year Vs Instrumentalness Scatterplot\")","execution_count":null,"outputs":[]},{"metadata":{"id":"DuxJ_bdklf38","outputId":"0c62e6f4-13d1-4504-e8cb-0ebbee6057f0","trusted":true},"cell_type":"code","source":"plot_single_scatter(sub_labeled_df.tempo, sub_labeled_df.danceability,cmax=1,title=\"Tempo Vs Danceability Scatterplot\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ZvOxdI7Jp7eX"},"cell_type":"markdown","source":"We can see that until 110 BPM the danceability grows and after 110, declines. So the peak is at around 110 BPM."},{"metadata":{"id":"xwePuBKQlf38","outputId":"00f270e7-4428-4f01-9c7b-629eeb89e7f9","trusted":true},"cell_type":"code","source":"plot_single_box(sub_labeled_df.explicit, sub_labeled_df.danceability,title=\"Explicit Vs Danceability Boxplot\")","execution_count":null,"outputs":[]},{"metadata":{"id":"pfLbnH00q4xF"},"cell_type":"markdown","source":"According to the boxplots above, we can deduct that explicit songs tend to be more danceable than non-explicit ones."},{"metadata":{"id":"1F3wwcFdlf38","outputId":"83390d9f-8d0a-4aed-f92a-22e3fa5d49b3","trusted":true},"cell_type":"code","source":"plot_single_box(sub_labeled_df.explicit, sub_labeled_df.loudness,title=\"Explicit Vs Loudness Boxplot\")","execution_count":null,"outputs":[]},{"metadata":{"id":"c3jwDA1frIQm"},"cell_type":"markdown","source":"Additionally, we can see that explicit songs tend to have values closer to 0 than the non-explicit tracks."},{"metadata":{"id":"LrU5WnqJW9Ht"},"cell_type":"markdown","source":"## Plotting the Correlation Matrix"},{"metadata":{"id":"PDWb1vBeXCvK","outputId":"39741841-13e8-43d2-8e8d-b424e5ffa9b0","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=(15,7))\nheatmap = sns.heatmap(all_dataset.corr(),vmin=-1, vmax=1, annot=True)\nheatmap.set_title(\"Correlation Heatmap\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"MdB5vzCGlf39"},"cell_type":"markdown","source":"# Data Preprocessing Feature Engineering and cleanup"},{"metadata":{"id":"cLAbVkwHum5h","outputId":"1478f01a-e308-4ea5-b13e-91404e10cf82","trusted":true},"cell_type":"code","source":"all_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"4BmtReKPuuJE","outputId":"7d608d13-e5b3-45b9-aaf4-b30ae97e8386","trusted":true},"cell_type":"code","source":"# Get value counts of top 10 artists features\nall_dataset[\"artists\"].value_counts().nlargest(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"hx2jnRRAzzDZ","outputId":"e0bca9f3-6eff-4a95-fca1-cce78fa7271d","trusted":true},"cell_type":"code","source":"# Get average popularity of an artist eg. Eminem\nall_dataset.loc[all_dataset['artists']==\"['Eminem']\",\"popularity\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"bmME39vM3qg5"},"cell_type":"markdown","source":"We will create 2 features for artists based on the number of tracks they released and on the mean value of their popularity amongst all their songs.<br>\nThese two variables I think can describe accurately each artist as to how much **famous** he/she is and how many **tracks** he/she has released."},{"metadata":{"id":"-1DClYUG6MW7","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Create a copy of the existing dataset to manipulate\ntransf_dataset = all_dataset.copy()\ntransf_dataset_sub = transf_dataset.sample(frac=0.4,random_state=42,axis=0)\ntransf_dataset_sub.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Gsy9XM5L7zOk","trusted":true},"cell_type":"code","source":"# Assign series object of artists and song counts\nall_artist_counts = transf_dataset_sub[\"artists\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"JbYpGqns804k","outputId":"13f8983c-5da2-4ab4-eef7-0073228c022b","trusted":true},"cell_type":"code","source":"# Total songs of eminem in the dataset\nall_artist_counts[[\"['Eminem']\"]][0]","execution_count":null,"outputs":[]},{"metadata":{"id":"pX6fwXKb82HM","trusted":true},"cell_type":"code","source":"# Creating two new feature zero columns\ntransf_dataset_sub[\"tracks_number\"] = 0\ntransf_dataset_sub[\"artist_popularity\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"XXklYf8vAYHf","outputId":"02aefcce-0a23-4e0e-85ce-8b56180bdff1","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Artist of first song in the dataframe\ntransf_dataset_sub[\"artists\"][0]","execution_count":null,"outputs":[]},{"metadata":{"id":"snGpY5_f-8iE","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for index in range(len(transf_dataset_sub)):\n    transf_dataset_sub[\"tracks_number\"][index] = all_artist_counts[[transf_dataset_sub[\"artists\"][index]]][0]\n    transf_dataset_sub[\"artist_popularity\"][index] = transf_dataset_sub.loc[transf_dataset_sub['artists']==transf_dataset_sub[\"artists\"][index],\"popularity\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"SOaJ-W84BnNy","outputId":"20326009-2458-4dec-a39a-812aa5062fa1","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"transf_dataset_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"BNp7U7z9KEc9","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# If artist popularity = popularity of song, means that the proposed artist has 1 only song. \n# So we will assign those values of artist_popularity to 0\nfor index in range(len(transf_dataset_sub)):\n    if transf_dataset_sub[\"tracks_number\"][index]==1:\n        transf_dataset_sub[\"artist_popularity\"][index] = 0\n        transf_dataset_sub[\"tracks_number\"][index] = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"GCp2kcw3LBOe","outputId":"87c6e64b-7b44-43ed-bccf-2ff56306ebe1","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"transf_dataset_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"M3vZzEVtX8S9"},"cell_type":"markdown","source":"For the name of the song, i'll use the length of the name of each song as one feature. For example the first track has name \"Il barbiere di Siviglia: Overture (Sinfonia)\" and characters size of 44. So the new feature here will be 44."},{"metadata":{"id":"4m9uhOSbX8ft","outputId":"30b3a662-e54f-448d-fd71-8e157a558f68","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Character Length for first song\nlen(transf_dataset_sub[\"name\"][0])","execution_count":null,"outputs":[]},{"metadata":{"id":"-hgZ21B8czOD","trusted":true},"cell_type":"code","source":"# Creating new column for new feature\ntransf_dataset_sub[\"song_length\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"4erHuxPNdWG9","outputId":"9b822237-a58f-4bd8-898f-ca4f4d4e904b","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"transf_dataset_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"YMeUc7jmX8_m","trusted":true},"cell_type":"code","source":"# Assigning values to the song_length feature\nfor index in range(len(transf_dataset_sub)):\n    transf_dataset_sub[\"song_length\"][index] = len(transf_dataset_sub[\"name\"][index])","execution_count":null,"outputs":[]},{"metadata":{"id":"quWeiyLXjZXn","outputId":"eb07e3b1-1f32-42de-d34e-ec328e6f2eab","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"transf_dataset_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"8W0Qcizxj3dA"},"cell_type":"markdown","source":"Now we will drop the columns : Artists, Id, name and release_date.\n\nThe column Id doesn't have anything usefull and the release date is described also in the year of the song (Year column)."},{"metadata":{"id":"LZSKpsrnks9d","trusted":true},"cell_type":"code","source":"# Dropping columns we won't use\ntransf_dataset_sub.drop(columns=[\"artists\", \"id\", \"name\", \"release_date\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"JlD9NVy1lPV_","outputId":"eff184ec-695d-4245-f89f-c3ea54753f62","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"transf_dataset_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"tU-R5UMjJDRG","trusted":true},"cell_type":"code","source":"# One hot encoding the key column\nfinal_dataset = pd.concat([transf_dataset_sub,pd.get_dummies(transf_dataset_sub[\"key\"], prefix=\"key\")],axis=1)\nfinal_dataset.drop(columns=[\"key\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Fq6ukUmtKYKJ","outputId":"72fc5b63-2181-427e-d544-1cdd0f44ff73","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"final_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"8nJJggAvN1oT","trusted":true},"cell_type":"code","source":"# Normalizing the ms duration by converting it to minutes and renaming the column\nfinal_dataset[\"duration_ms\"] = final_dataset[\"duration_ms\"]/(1000 * 60)\nfinal_dataset.rename(columns={\"duration_ms\" : \"duration\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"_RRwtQKCN95-","outputId":"24d4efbf-10e2-436f-b772-8890b46686ac","trusted":true},"cell_type":"code","source":"final_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Yij367FMKaT5"},"cell_type":"markdown","source":"# Training and Testing various models"},{"metadata":{"id":"hNXvmrBCSF_9"},"cell_type":"markdown","source":"### Splitting into Train and Test data"},{"metadata":{"id":"gf_Ce-WGLSj9","trusted":true},"cell_type":"code","source":"# Splitting to inputs and labels\nX = final_dataset.drop(columns=[\"popularity\"])\ny = final_dataset[\"popularity\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"OmpsliT3Lh0u","outputId":"f49add51-caa0-4f28-b950-4ecba442e215","trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"QUUoY5I9L4Sd","trusted":true},"cell_type":"code","source":"# Splitting into Train and Test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"id":"34CAuxmGSRhM"},"cell_type":"markdown","source":"### Benchmarking with Simple Regression Models"},{"metadata":{"id":"3wYgk8gTS-RD"},"cell_type":"markdown","source":"#### Ridge Regression"},{"metadata":{"id":"9QjlDfcsO1Q9","trusted":true},"cell_type":"code","source":"# Ridge Regression (l2 norm)\nfrom sklearn.linear_model import Ridge\nridge_reg = Ridge(alpha=400,solver='cholesky')\nridge_reg.fit(X_train,y_train)\ny_pred = ridge_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"AHfb5rYMPoDa","outputId":"f6bb189f-7c5a-487c-b2c4-65371c94dcde","trusted":true},"cell_type":"code","source":"# Applying the RMSE Metric\nfrom sklearn.metrics import mean_squared_error\nimport math\n\ndef rmse(y_test,y_pred):\n    return math.sqrt(mean_squared_error(y_test, y_pred))\n\nprint(rmse(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"gcPJia-hQaYH"},"cell_type":"markdown","source":"#### Lasso Regression"},{"metadata":{"id":"wnAbp__tTDOA","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlasso_reg = Lasso(alpha = 0.05)\nlasso_reg.fit(X_train,y_train)\ny_pred = lasso_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"tnr0iAtPTm87","outputId":"217a7196-d705-443a-cfa9-fe2432f67d93","trusted":true},"cell_type":"code","source":"print(rmse(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"_Tz8wZOHT0Ul"},"cell_type":"markdown","source":"#### ElasticNet"},{"metadata":{"id":"5O--5V1JHOyD","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nelastic_reg = ElasticNet(l1_ratio=0.8,alpha=0.05)\nelastic_reg.fit(X_train, y_train)\ny_pred = elastic_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"tmcnHyuPICpJ","outputId":"21fc7196-f41c-411e-84cf-f1fc09c9c35f","trusted":true},"cell_type":"code","source":"print(rmse(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"GacX-gNkIEFb"},"cell_type":"markdown","source":"### Gradient Boosting Regressors"},{"metadata":{"id":"sxUDwxVxMjGI"},"cell_type":"markdown","source":"#### Sci-kit Gradient Boosting Regressor"},{"metadata":{"id":"1R75fKEJMYjs","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor(n_estimators=200,learning_rate=0.2,validation_fraction=0.1,n_iter_no_change=15)\ngbr.fit(X_train,y_train)\ny_pred = gbr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Bv2p_PCOPyY5","outputId":"b8e6ad5f-64b8-489b-99c9-3db67551b760","trusted":true},"cell_type":"code","source":"# Evaluation on train set\nprint(rmse(y_train, gbr.predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"id":"8o-iWVx4NeUK","outputId":"f15816c5-213a-44f6-d714-ee5c43c3be21","trusted":true},"cell_type":"code","source":"# Evaluation on test set\nprint(rmse(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"jypXvFuZOKV_","outputId":"a82364e6-ee01-4098-cde8-d9a959490a15","trusted":true},"cell_type":"code","source":"gbr.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"id":"J4ozAfLPOOgl"},"cell_type":"markdown","source":"We can actually see that with the gradient boosting regressor we are not overfitting in the training set, which is a good thing."},{"metadata":{"id":"33lGCEXQRb-n"},"cell_type":"markdown","source":"Let's see the importance of each feature in our model."},{"metadata":{"id":"k6ENPxGsb9ky","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Defining function for plotting feature importances\ndef plot_feature_importances(feat_imp_array, dataframe,title):\n    # Sorted importance array\n    col_sorted_by_importance=(-feat_imp_array).argsort()\n    #Creating dataframe with importances\n    feat_imp=pd.DataFrame({\n      'cols':dataframe.columns[col_sorted_by_importance],\n      'imps':feat_imp_array[col_sorted_by_importance]\n  })\n    #Plotting the importances of our model\n    fig = px.bar(feat_imp, x='cols', y='imps', title=title)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"y2uqDSdhcijP","outputId":"7f7ff7fc-91c7-4d25-af7f-e472de27a2a0","trusted":true},"cell_type":"code","source":"plot_feature_importances(gbr.feature_importances_,X_train,\"GBR Feature Importances\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CXrA4DjjTySR"},"cell_type":"markdown","source":"We have some interesting insights here. We can see that our engineered features \"artist_popularity\" and \"tracks_number\", highly describe our depedent variable. It seems normal if we think that a well known artist is more likely to release a popular track, since he's already famous. "},{"metadata":{"id":"iurF4O2jUklX"},"cell_type":"markdown","source":"#### CatBoost Regressor"},{"metadata":{"id":"lxRJb5k9fPyF","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install catboost","execution_count":null,"outputs":[]},{"metadata":{"id":"s6tm8buqekiR","outputId":"cdc35760-114e-407e-bbbd-cd00d51a3f99","trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"2sk8ytbsbR86","trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor, Pool, cv\n\ncat_features = X_train[[\"explicit\", \"mode\", \"key_0\", \"key_1\", \"key_2\", \"key_3\", \"key_4\", \"key_5\", \"key_6\", \"key_7\", \"key_8\", \"key_9\", \"key_10\", \"key_11\"]].columns\n\ntrain_pool = Pool(X_train, \n                  y_train,\n                  cat_features)","execution_count":null,"outputs":[]},{"metadata":{"id":"Y34iH7n0ftrz","trusted":true,"collapsed":true},"cell_type":"code","source":"catboost_reg = CatBoostRegressor(iterations=1000,\n                                #task_type='GPU',\n                                #devices='0:1',\n                                loss_function='RMSE',\n                                eval_metric='RMSE',\n                                random_seed=42)\n\ncatboost_reg.fit(train_pool,plot=True)\ny_pred = catboost_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"s2ARBRZBhRfA","outputId":"fc34a056-edcc-4a60-df6f-36a8d8656e86","trusted":true},"cell_type":"code","source":"print(rmse(y_train,catboost_reg.predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"id":"n0TW9JK6hDbc","outputId":"d39306ce-e187-47c2-d8b5-d0ced695c05c","trusted":true},"cell_type":"code","source":"print(rmse(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"4gpJLMZgnfCj"},"cell_type":"markdown","source":"With RMSE of 8.66 on the training set and 9.76 on the test set, we don't have overfitting and this is actually our best perfomance yet on the test data (9.76)."},{"metadata":{"id":"KYo9Wqtxjr0R","outputId":"b756b942-e465-4966-eb63-d2c26ef192c4","trusted":true},"cell_type":"code","source":"plot_feature_importances(catboost_reg.feature_importances_,X_train,\"CatBost Regressor Feature Importances\")","execution_count":null,"outputs":[]},{"metadata":{"id":"M-6JXHcflbFn"},"cell_type":"markdown","source":"With the CatBoost Regressor the predictions are not so artist depedent (artist popularity and artist songs) but more features play a role for the final prediction. We can also see that the year is the most important feature here."},{"metadata":{"id":"syYwmwnJmmtq"},"cell_type":"markdown","source":"### Tensorflow DNN Regression Model"},{"metadata":{"id":"HfFAmr5io90v","outputId":"c91b67d5-7a06-4fe7-cd1e-26d8b884efe3","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"WsWYm1Zco9_w","trusted":true},"cell_type":"code","source":"# Normalizing our Train and Test data to feed them in our DNN\nmm_scaler = MinMaxScaler()\nX_train_sc = mm_scaler.fit_transform(X_train)\nX_test_sc = mm_scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"HyJ6LrcXqasD","outputId":"c4b9e281-59f7-4c65-e757-c236bc3c17bd","trusted":true},"cell_type":"code","source":"# The shape of our train set\nX_train_sc.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"qvN5-xi9qllT","trusted":true},"cell_type":"code","source":"# Defining our DNN Model\nmodel = tf.keras.Sequential([\n                             tf.keras.layers.Dense(128,activation=\"relu\"),\n                             tf.keras.layers.Dropout(0.2),\n                             tf.keras.layers.Dense(64,activation=\"relu\"),\n                             tf.keras.layers.Dense(1)\n])\n\n# Defining RMSE Metric\nrmse = tf.keras.metrics.RootMeanSquaredError()\n\n# Compiling our Model\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[rmse])","execution_count":null,"outputs":[]},{"metadata":{"id":"wbUWc0jPtmrj","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Training the model\nhistory = model.fit(x=X_train_sc,y=y_train,epochs=40, validation_data=(X_test_sc,y_test))","execution_count":null,"outputs":[]},{"metadata":{"id":"c_389GtT7MXF","outputId":"a1d50981-6cf1-4ab0-d321-42a0d72a765f","trusted":true},"cell_type":"code","source":"# Print RMSE Accuracy with DNN Regression Model\ny_pred = model.predict(X_test_sc)\nprint(float(rmse(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"id":"1uFTbg3k2GGU","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Plot function for training and testing\ndef plot_loss(history):\n    plt.figure(figsize=(13,7))\n    plt.plot(history.history['root_mean_squared_error'], label='root_mean_squared_error')\n    plt.plot(history.history['val_root_mean_squared_error'], label='val_root_mean_squared_error')\n    plt.xlabel('Epoch')\n    plt.ylabel('Error')\n    plt.legend()\n    plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"id":"yy3QPNLf66N8","outputId":"475eb2d8-fc91-41ee-bc27-02443f09ee6b","trusted":true},"cell_type":"code","source":"plot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"3mxJLIR968v8"},"cell_type":"markdown","source":"We can see that the training line and the validation line fit perfectly with each other. So there's no overfitting here. "},{"metadata":{"id":"ykCwtLkf_OQ7"},"cell_type":"markdown","source":"# Conclusions"},{"metadata":{"id":"m6wG75gdAcXB"},"cell_type":"markdown","source":"To sum up, firstly we performed an Exploratory Data Analysis on the Spotify 1921-2020 Dataset, created some new features and then tested various regression models to predict the popularity of each one. Best performance achieved by CatBoostRegressor with 9.76 RMSE on the test set. Note that due to computational resources we used a subset of almost half the original dataset (fraction of 0.4) to plot the EDA graphs and to train our models."},{"metadata":{"id":"iGXE4Mr3A-Vt"},"cell_type":"markdown","source":"#### Models and Results\n\nRidge Regression : 14.23<br>\nLasso Regression : 14.24<br>\nElasticNet : 14.25<br>\nGradient Boosting Regressor : 10.29<br>\nCatBoost Regressor : 9.76<br>\nDeep Neural Network Regression : 10.29<br>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}