{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom datetime import date\nimport statsmodels.api as sm\nfrom scipy import stats\nfrom scipy.special import inv_boxcox\nfrom math import fabs\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv('../input/bitcoin-prices-in-usd-from-20120201to20210411/Bitcoin_USD_2012-02-01_2021-04-11.csv')\ndf = df.drop(\"Unnamed: 0\", axis = 1)\n\n\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf.index = df[\"Date\"]\ndf = df.drop(\"Date\", axis = 1)\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Plots, and data interpretation","metadata":{}},{"cell_type":"markdown","source":"There was three halvings in the history of bitcoin. Let's show it on the plot.","metadata":{}},{"cell_type":"code","source":"df['Price USD'].plot()\n\nhalving_dates = [date(2012, 11, 28), date(2016,7,9), date(2020, 6, 11)]\na = plt.plot(halving_dates, df[\"Price USD\"].loc[halving_dates], marker = \"o\", linewidth = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One year after each halvig, there is a price spike that creates a local high for the coming years. Ð¡onsider the post-halving periods in more detail.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=[10, 24])\n\nplt.subplot(311)\ntemp_df = df.loc[df.index > \"2012-11-28\"]\ntemp_df[\"Price USD\"].loc[temp_df.index < \"2014-11-28\"].plot()\nplt.title(\"after first halving\")\n\nplt.subplot(312)\ntemp_df = df.loc[df.index > \"2016-07-09\"]\ntemp_df[\"Price USD\"].loc[temp_df.index < \"2018-07-09\"].plot()\nplt.title(\"after second halving\")\n\nplt.subplot(313)\ndf[\"Price USD\"].loc[df.index > \"2020-06-11\"].plot()\na = plt.title(\"after third halving\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Statistics tests and data transformations","metadata":{}},{"cell_type":"markdown","source":"index transformation, and adf test","metadata":{}},{"cell_type":"code","source":"month_df = df.resample('M').mean()\nprint(month_df.shape)\nprint(\"ADF test: p=%f\" % sm.tsa.stattools.adfuller(month_df[\"Price USD\"])[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The time series is not stationary, due to the presence of a trend and a non-variable variance. To verify the variability of the variance, we use the Bartlett test.","metadata":{}},{"cell_type":"code","source":"# take the data between the halvings as comparable samples\nfirst_arr = month_df.loc[month_df.index > \"2012-11-28\"]; first_arr = first_arr.loc[first_arr.index < \"2016-07-09\"][\"Price USD\"].to_numpy()\nsecond_arr = month_df.loc[month_df.index > \"2016-07-09\"]; second_arr = second_arr.loc[second_arr.index < \"2020-06-11\"][\"Price USD\"].to_numpy()\nthird_arr = month_df.loc[month_df.index > \"2020-06-11\"][\"Price USD\"].to_numpy()\n\n\n# Bartlett test\nstat, p = stats.bartlett(first_arr, second_arr, third_arr)\nprint(\"Bartlett P-value: \" + str(p))\n\n# calculate the variance of the different sections\nprint('Variances:')\nprint([np.var(x, ddof=1) for x in [first_arr, second_arr, third_arr]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, the variance is statistically non-integral and it can be assumed from the variance estimates that the variance increases monotonically. In order to correct for this, we can use the Box-Cox transform.","metadata":{}},{"cell_type":"code","source":"month_df['Box-Cox transformed'], lmbda = stats.boxcox(month_df['Price USD'])\n\nfig = plt.figure(figsize = [15, 10])\n\nplt.subplot(211)\nmonth_df['Price USD'].plot()\nplt.subplot(212)\nmonth_df['Box-Cox transformed'].plot()\n\nfirst_arr = month_df.loc[month_df.index > \"2012-11-28\"]; first_arr = first_arr.loc[first_arr.index < \"2016-07-09\"][\"Box-Cox transformed\"].to_numpy()\nsecond_arr = month_df.loc[month_df.index > \"2016-07-09\"]; second_arr = second_arr.loc[second_arr.index < \"2020-06-11\"][\"Box-Cox transformed\"].to_numpy()\nthird_arr = month_df.loc[month_df.index > \"2020-06-11\"][\"Box-Cox transformed\"].to_numpy()\n\nstat, p = stats.bartlett(first_arr, second_arr, third_arr)\nprint(\"Bartlett P-value: \" + str(p))\n\nprint('Variances:')\nprint([np.var(x, ddof=1) for x in [first_arr, second_arr, third_arr]])\n\nprint(\"ADF test: p=%f\" % sm.tsa.stattools.adfuller(month_df[\"Box-Cox transformed\"])[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now much better. But there is still a variable mathematical expectation. Let's fix this with finite differences.","metadata":{}},{"cell_type":"code","source":"month_df['diffs1'] = month_df['Box-Cox transformed'] - month_df['Box-Cox transformed'].shift(1)\nprint(\"ADF test: p=%f\" % sm.tsa.stattools.adfuller(month_df[\"diffs1\"][1:])[1])\n\nfig = plt.figure(figsize = [15, 5])\na = month_df['diffs1'].plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can now be assumed that the data is stationary.","metadata":{}},{"cell_type":"markdown","source":"# Model identification","metadata":{}},{"cell_type":"markdown","source":"Lets chek acf and pacf plots","metadata":{}},{"cell_type":"code","source":"\nfig = plt.figure(figsize = [15, 10])\nax = plt.subplot('211')\na = sm.graphics.tsa.plot_acf(month_df['diffs1'][1:], lags=48, ax = ax)\n\nax = plt.subplot('212')\na = sm.graphics.tsa.plot_pacf(month_df['diffs1'][1:], lags=48, ax = ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice PACF at lag 47, but it not enought data to build model with 4 year seasonality. I have no ideas about orders, but lets check aic value for defferent models. ","metadata":{}},{"cell_type":"code","source":"# this line will spend some time, the best order is (4,8) = 141.21\n#test = sm.tsa.arma_order_select_ic(month_df['diffs1'][1:],max_ar=10, max_ma=10, ic='aic')\n#test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I see no reason to suspect seasonality in the data, so let's leave the simple ARIMA model","metadata":{}},{"cell_type":"markdown","source":"# Model building and quality check","metadata":{}},{"cell_type":"markdown","source":"function for calculating the approximation error, MLEResult.mae does not work for me.","metadata":{}},{"cell_type":"code","source":"def mae_recompute(y, y_est):\n    A = 0\n    \n    for i in y.index:\n        A += fabs((y.loc[i] - y_est.loc[i])/y.loc[i])\n\n    return A/len(y.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have consistently excluded weakly significant coefficients from the model until only significant ones remain.","metadata":{}},{"cell_type":"code","source":"model=sm.tsa.statespace.SARIMAX(month_df['Box-Cox transformed'], order=(0, 1, [1,7])).fit(disp=-1)\n\nresult_box_cox = model.predict(start=0, end=110)\nprint('mean absolute error by myself: ' + str(mae_recompute(month_df['Box-Cox transformed'] ,result_box_cox)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the residuals parallelogram as it may suggest which coefficients it makes sense to include as well","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = [15, 10])\nax = plt.subplot('211')\na = sm.graphics.tsa.plot_acf(model.resid, lags=48, ax = ax)\n\nax = plt.subplot('212')\na = sm.graphics.tsa.plot_pacf(model.resid, lags=48, ax = ax)\n\n#q_test = sm.tsa.stattools.acf(model.resid, qstat=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"you can see quite a few odds that stand out.  PACF will help you select additional AR coefficients. ACF will help select new MA coefficients. I tried to add AR 21, 26, 28, 40 but none of them turned out to be significant, while 47 turned out to be significant and improved the performance of the model. In addition, I tried a number of MA coefficients, only 47 turned out to be significant.","metadata":{}},{"cell_type":"code","source":"model=sm.tsa.statespace.SARIMAX(month_df['Box-Cox transformed'], order=([47], 1, [1,7,47])).fit(disp=-1)\n\nprint(model.summary())\n\nresult_box_cox = model.predict(start=0, end=110)\nresult = inv_boxcox(model.predict(start=0, end=110), lmbda)\n\nprint('mean absolute error box-cox: ' + str(mae_recompute(month_df['Box-Cox transformed'] ,result_box_cox)))\nprint('mean absolute error: ' + str(mae_recompute(month_df['Price USD'] ,result)))\n\nfigure = plt.figure(figsize = [20,20])\n\nplt.subplot('211')\n\nmonth_df['Box-Cox transformed'].plot()\nresult_box_cox.plot(color = 'r' , ls = '--')\nplt.title(\"box-cox data\")\n\nplt.subplot('212')\nmonth_df['Price USD'].plot()\nresult.plot(color = 'r' , ls = '--')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generally speaking, this result confirms some seasonality of 4 years (48 months). Just halving passed with a period not exactly 4 years - a little less, because the dependence with an interval of 47 months.\n\nLet's check the residuals of the resulting model","metadata":{}},{"cell_type":"code","source":"q_test = sm.tsa.stattools.acf(model.resid, qstat=True)\nprint(pd.DataFrame({'ACF':q_test[0][1:],'Q-stat':q_test[1], 'p-value':q_test[2]}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice result - observations are likely to be white noise. We got the final model.","metadata":{}},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"markdown","source":"Once again confirm seasonality at four years with a spot long-term forecast.","metadata":{}},{"cell_type":"code","source":"pred_end = 250\n\npred_box_cox = model.get_prediction(start = 110, end = pred_end)\npoind_pred = inv_boxcox(pred_box_cox.predicted_mean, lmbda)\n\nfigure = plt.figure(figsize = [15,15])\n\nplt.subplot('212')\nmonth_df['Price USD'].plot()\npoind_pred.plot(color = 'r' , ls = '--')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can say from the spot forecast that the next price boom is expected to start in 2024, which is why we will make more detailed forecasts before then.","metadata":{}},{"cell_type":"code","source":"pred_end = 143\n\npred_box_cox = model.get_prediction(start = 110, end = pred_end)\npoind_pred = inv_boxcox(pred_box_cox.predicted_mean, lmbda)\n\nupper_pred = inv_boxcox(pred_box_cox.conf_int(alpha=0.05)['upper Box-Cox transformed'], lmbda)\nlower_pred = inv_boxcox(pred_box_cox.conf_int(alpha=0.05)['lower Box-Cox transformed'], lmbda)\n\nfigure = plt.figure(figsize = [15,10])\n\nax = plt.subplot('111')\n\n#month_df.loc[month_df.index > \"2020-06-11\"][\"Price USD\"].plot(ax = ax)\n#poind_pred.plot(ls = '--', color = 'red', ax = ax)\n\nplt.plot(month_df.loc[month_df.index > \"2020-06-11\"][\"Price USD\"])\nplt.plot(poind_pred, ls = '--', color = 'red')\n\nplt.fill_between(upper_pred.index, upper_pred, lower_pred, alpha = 0.5)\nplt.show()\n\nprint(pd.concat([poind_pred, upper_pred, lower_pred], axis = 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get that, judging by the model, the current iteration will peak in December 2021 at an average of 171.08 thousand, with a 95 percent probability of being between 66.16 thousand and 405.4 thousand. Obviously, it is around this point that cryptocurrency will be most profitable to sell.\nAnd the next bottom should be expected in December 2022. On average, the price should be around 144.63 thousand per cryptocurrency unit, and with a 95 probability it will lie between 16.06 and 581.89 thousand. This downturn is the best time to invest in bitcoin.","metadata":{}}]}