{"cells":[{"metadata":{},"cell_type":"markdown","source":"The data contains the credit details about credit borrowers. Data Description:\n- age - Age of Customer\n- ed - Eductation level of customer\n- employ: Tenure with current employer (in years)\n- address: Number of years in same address\n- income: Customer Income\n- debtinc: Debt to income ratio\n- creddebt: Credit to Debt ratio\n- othdebt: Other debts\n- default: Customer defaulted in the past (1= defaulted, 0=Never defaulted)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, f1_score\n\n# Resampling\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bankloan = pd.read_csv('../input/bankloans/bankloans.csv')\nbankloan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bankloan.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"*Check Missing Value and Fill*"},{"metadata":{"trusted":true},"cell_type":"code","source":"bankloan.isna().sum()/len(bankloan.index)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_default = SimpleImputer(strategy = 'median')\nbankloan[['default']] = imp_default.fit_transform(bankloan[['default']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Check the Imbalance*"},{"metadata":{"trusted":true},"cell_type":"code","source":"bankloan['default'].value_counts()/len(bankloan['default'].index)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This percentage indicates that the data is **imbalanced**."},{"metadata":{},"cell_type":"markdown","source":"*Splitting Data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = bankloan[['employ', 'debtinc', 'creddebt', 'othdebt']]\ny = bankloan['default']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val, X_test, y_train_val, y_test = train_test_split(\n                                            X, y, \n                                            stratify = y, \n                                            test_size = 0.2, \n                                            random_state = 44)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I use 0.2 as test_size score and X.shape for random_state so the data will be devided equally."},{"metadata":{},"cell_type":"markdown","source":"# Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\ntree = DecisionTreeClassifier(random_state = 44)\nknn = KNeighborsClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_scale = Pipeline([\n    ('scale', StandardScaler()),\n    ('logreg', logreg)\n])\n\ntree_pipe_scale = Pipeline([\n    ('tree', tree)\n])\n\nknn_pipe_scale = Pipeline([\n    ('scale', StandardScaler()),\n    ('knn', knn)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"*Model Evaluation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_cv = cross_val_score(model, X_train_val, y_train_val, cv = skfold, scoring = metric)\n    return model_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_scale_cv = model_evaluation(logreg_pipe_scale, 'f1')\ntree_pipe_scale_cv = model_evaluation(tree_pipe_scale, 'f1')\nknn_pipe_scale_cv = model_evaluation(knn_pipe_scale, 'f1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_cv = logreg_pipe_scale_cv.mean()\ntree_cv = tree_pipe_scale_cv.mean()\nknn_cv = knn_pipe_scale_cv.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [logreg_cv, tree_cv, knn_cv]\nmethod_name = ['Logistic Regression CV Score', 'Decision Tree Classifier CV Score',\n              'KNN Classifier CV Score']\ncv_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\ncv_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Fitting Data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for model, model_name in zip([logreg_pipe_scale, tree_pipe_scale, knn_pipe_scale], \n                             ['Logistic Regression', 'Decision Tree Classifier', 'KNN Classifier']):\n    model.fit(X_train_val, y_train_val)\n    y_pred = model.predict(X_test)\n    print(model_name+ ':')\n    print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I use 3 resampling methods to handle it, Under Sampling, Over Sampling and SMOTE."},{"metadata":{},"cell_type":"markdown","source":"# Resampling: *UnderSampling*"},{"metadata":{"trusted":true},"cell_type":"code","source":"rus = RandomUnderSampler(random_state = 44)\nX_under, y_under = rus.fit_resample(X_train_val, y_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_scale_rus = Pipeline([\n    ('scale', StandardScaler()),\n    ('rus', rus),\n    ('logreg', logreg)\n])\n\ntree_pipe_scale_rus = Pipeline([\n    ('rus', rus),\n    ('tree', tree)\n])\n\nknn_pipe_scale_rus = Pipeline([\n    ('scale', StandardScaler()),\n    ('rus', rus),\n    ('knn', knn)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Model Evaluation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation_rus(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_rus = cross_val_score(model, X_under, y_under, cv = skfold, scoring = metric)\n    return model_rus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_rus = model_evaluation_rus(logreg_pipe_scale_rus, 'f1')\ntree_pipe_rus = model_evaluation_rus(tree_pipe_scale_rus, 'f1')\nknn_pipe_rus = model_evaluation_rus(knn_pipe_scale_rus, 'f1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_rus = logreg_pipe_rus.mean()\ntree_rus = tree_pipe_rus.mean()\nknn_rus = knn_pipe_rus.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [logreg_rus, tree_rus, knn_rus]\nmethod_name = ['Logistic Regression UnderSampling Score', 'Decision Tree Classifier UnderSampling Score',\n              'KNN Classifier UnderSampling Score']\nrus_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nrus_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Fitting Data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for model, model_name in zip([logreg_pipe_scale_rus, tree_pipe_scale_rus, knn_pipe_scale_rus], \n                             ['Logistic Regression UnderSampling', 'Decision Tree Classifier UnderSampling', 'KNN Classifier UnderSampling']):\n    model.fit(X_under, y_under)\n    y_pred = model.predict(X_test)\n    print(model_name+ ':')\n    print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resampling: *OverSampling*"},{"metadata":{"trusted":true},"cell_type":"code","source":"ros = RandomOverSampler(random_state = 44)\nX_over, y_over = ros.fit_resample(X_train_val, y_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_scale_ros = Pipeline([\n    ('scale', StandardScaler()),\n    ('ros', ros),\n    ('logreg', logreg)\n])\n\ntree_pipe_scale_ros = Pipeline([\n    ('ros', ros),\n    ('tree', tree)\n])\n\nknn_pipe_scale_ros = Pipeline([\n    ('scale', StandardScaler()),\n    ('ros', ros),\n    ('knn', knn)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Model Evaluation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation_ros(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_ros = cross_val_score(model, X_over, y_over, cv = skfold, scoring = metric)\n    return model_ros","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_ros = model_evaluation_ros(logreg_pipe_scale_ros, 'f1')\ntree_pipe_ros = model_evaluation_ros(tree_pipe_scale_ros, 'f1')\nknn_pipe_ros = model_evaluation_ros(knn_pipe_scale_ros, 'f1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_ros = logreg_pipe_ros.mean()\ntree_ros = tree_pipe_ros.mean()\nknn_ros = knn_pipe_ros.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [logreg_ros, tree_ros, knn_ros]\nmethod_name = ['Logistic Regression OverSampling Score', 'Decision Tree Classifier OverSampling Score',\n              'KNN Classifier OverSampling Score']\nros_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nros_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Fitting Data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for model, model_name in zip([logreg_pipe_scale_ros, tree_pipe_scale_ros, knn_pipe_scale_ros], \n                             ['Logistic Regression OverSampling', 'Decision Tree Classifier OverSampling', 'KNN Classifier OverSampling']):\n    model.fit(X_over, y_over)\n    y_pred = model.predict(X_test)\n    print(model_name+ ':')\n    print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resampling: *SMOTE*"},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE(random_state = 44)\nX_smote, y_smote = smote.fit_resample(X_train_val, y_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_scale_smote = Pipeline([\n    ('scale', StandardScaler()),\n    ('smote', smote),\n    ('logreg', logreg)\n])\n\ntree_pipe_scale_smote = Pipeline([\n    ('smote', smote),\n    ('tree', tree)\n])\n\nknn_pipe_scale_smote = Pipeline([\n    ('scale', StandardScaler()),\n    ('smote', smote),\n    ('knn', knn)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Model Evaluation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluation_smote(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_smote = cross_val_score(model, X_smote, y_smote, cv = skfold, scoring = metric)\n    return model_smote","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_pipe_smote = model_evaluation_smote(logreg_pipe_scale_smote, 'f1')\ntree_pipe_smote = model_evaluation_smote(tree_pipe_scale_smote, 'f1')\nknn_pipe_smote = model_evaluation_smote(knn_pipe_scale_smote, 'f1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_smote = logreg_pipe_smote.mean()\ntree_smote = tree_pipe_smote.mean()\nknn_smote = knn_pipe_smote.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [logreg_smote, tree_smote, knn_smote]\nmethod_name = ['Logistic Regression SMOTE Score', 'Decision Tree Classifier SMOTE Score',\n              'KNN Classifier SMOTE Score']\nsmote_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nsmote_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*fitting data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for model, model_name in zip([logreg_pipe_scale_smote, tree_pipe_scale_smote, knn_pipe_scale_smote], \n                             ['Logistic Regression SMOTE', 'Decision Tree Classifier SMOTE', 'KNN Classifier SMOTE']):\n    model.fit(X_smote, y_smote)\n    y_pred = model.predict(X_test)\n    print(model_name+ ':')\n    print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HyperParam Tuning"},{"metadata":{},"cell_type":"markdown","source":"Finally, I choose **Logistic Regression using UnderSampling** model because it has the highest of accuracy score. Let's do hyperparameter tuning to see if I can improve the score again after the imbalance data has been handled. Can it improve?"},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\n\nrus = RandomUnderSampler(random_state = 44)\nX_under, y_under = rus.fit_resample(X_train_val, y_train_val)\n\nestimator = Pipeline([\n    ('scale', StandardScaler()),\n    ('rus', rus),\n    ('logreg', logreg)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperparam_space = {\n    'logreg__C': [100, 10, 1, 0.1, 0.01, 0.001],\n    'logreg__solver': ['liblinear', 'newton-cg', 'saga', 'lbfgs'],\n    'logreg__max_iter': [100, 200, 300, 400]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search = GridSearchCV(\n                estimator,\n                param_grid = hyperparam_space,\n                cv = StratifiedKFold(n_splits = 5),\n                scoring = 'f1',\n                n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.fit(X_train_val, y_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('best score', grid_search.best_score_)\nprint('best param', grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Before VS After Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator.fit(X_under, y_under)\ny_pred_estimator = estimator.predict(X_test)\nprint(classification_report(y_test, y_pred_estimator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_.fit(X_train_val, y_train_val)\ny_pred_grid = grid_search.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_pred_grid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_estimator = f1_score(y_test, y_pred_estimator)\nf1_best_estimator = f1_score(y_test, y_pred_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [f1_estimator, f1_best_estimator]\nmethod_name = ['Logistic Regression UnderSampling Before Tuning', 'Logistic Regression UnderSampling After Tuning']\nbest_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nbest_summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usually, Hyperparameter tuning can improve the result, but in this case, **it can't**. So i have to change with another model for tuning until get the improvement."},{"metadata":{},"cell_type":"markdown","source":"* Best Model: Logistic Regression using UnderSampling\n* Best Estimator Score: 0.52376\n* Best C: 0.1\n* Best max_iter: 100\n* Best solver: newton-cg"},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading this notebook."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}