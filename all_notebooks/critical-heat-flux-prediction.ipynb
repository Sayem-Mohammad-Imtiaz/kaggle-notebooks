{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Critical Heat Flux Prediction  \n  \nGiven *data about various experimental conditions*, let's try to predict the **critical heat flux** for a given experiment.  \n  \nWe will use a random forest regression model to make our predictions.","metadata":{}},{"cell_type":"markdown","source":"# Getting Started","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/predicting-heat-flux/Data_CHF_Zhao_2020_ATE.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop id and author columns\n    df = df.drop(['id', 'author'], axis=1)\n    \n    # Shuffle the dataset\n    df = df.sample(frac=1.0, random_state=1)\n    \n    # Split df into X and y\n    y = df['chf_exp [MW/m2]']\n    X = df.drop('chf_exp [MW/m2]', axis=1)\n    \n    return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = preprocess_inputs(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Pipeline","metadata":{}},{"cell_type":"code","source":"def build_model():\n    \n    nominal_transformer = Pipeline(steps=[\n        ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n    ])\n    \n    preprocessor = ColumnTransformer(transformers=[\n        ('nominal', nominal_transformer, ['geometry'])\n    ], remainder='passthrough')\n    \n    model = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('regressor', RandomForestRegressor(random_state=1))\n    ])\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=5)\n\nrmses = []\n\nfor train_idx, test_idx in kf.split(X):\n    \n    X_train = X.iloc[train_idx, :]\n    X_test = X.iloc[test_idx, :]\n    y_train = y.iloc[train_idx]\n    y_test = y.iloc[test_idx]\n    \n    model = build_model()\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    \n    rmse = np.sqrt(np.mean((y_test - y_pred)**2))\n    \n    rmses.append(rmse)\n\nfinal_rmse = np.mean(rmses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"RMSE: {:.2f}\".format(final_rmse))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/rK_Y9DjQ8js","metadata":{}}]}