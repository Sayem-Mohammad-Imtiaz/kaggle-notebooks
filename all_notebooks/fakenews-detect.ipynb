{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\n\nimport pandas, xgboost, numpy, textblob, string\nfrom keras.preprocessing import text, sequence\nfrom keras import layers, models, optimizers\n\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv(\"../input/fake-news-detection/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Label\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking missing values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.fillna(' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()\ndf[\"text\"] = data[\"Body\"]\ndf[\"label\"] = data[\"Label\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for outliers\n\ndf[\"length\"] = df[\"text\"].str.len()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for minumum,maximum and average length\n#looks like there are outliers\n\nmin(df['length']), max(df['length']), round(sum(df['length'])/len(df['length']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the outliers which are less than 50 word\n\ndf = df.drop(df['text'][df['length'] < 50].index, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min(df['length']), max(df['length']), round(sum(df['length'])/len(df['length']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#upper-lower transform\ndf['text'] = df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n#punctuations\ndf['text'] = df['text'].str.replace('[^\\w\\s]','')\n#numbers\ndf['text'] = df['text'].str.replace('\\d','')\n#stopwords\nimport nltk\n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nsw = stopwords.words('english')\ndf['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n#deleting sparse words\nsil = pd.Series(' '.join(df['text']).split()).value_counts()[-1000:]\ndf['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n#lemmi\nfrom textblob import Word\n#nltk.download('wordnet')\ndf['text'] = df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Word Cloud Visualization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(i for i in df.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(max_font_size = 50, \n                     background_color = \"white\").generate(text)\nplt.figure(figsize = [10,10])\nplt.imshow(wordcloud, interpolation = \"bilinear\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"text\"],\n                                                                   df[\"label\"], \n                                                                    random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = encoder.fit_transform(train_y)\ntest_y = encoder.fit_transform(test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ngram level tf-idf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range = (2,3))\ntf_idf_ngram_vectorizer.fit(train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(train_x)\nx_test_tf_idf_ngram = tf_idf_ngram_vectorizer.transform(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loj = linear_model.LogisticRegression()\nloj_model = loj.fit(x_train_tf_idf_ngram,train_y)\naccuracy = model_selection.cross_val_score(loj_model, \n                                           x_test_tf_idf_ngram, \n                                           test_y, \n                                           cv = 10).mean()\n\nprint(\"N-GRAM TF-IDF Accuracy Rate:\", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}