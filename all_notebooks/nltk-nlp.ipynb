{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from urllib import request\nurl = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\nresponse = request.urlopen(url)\nraw = response.read().decode('utf8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk import sent_tokenize \nfrom nltk import word_tokenize\nf = open('../input/hate-speech-and-offensive-language-dataset/labeled_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw = f.read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=sent_tokenize(raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_sentence1=[sent for sent in sentence if \"Bad\" in word_tokenize(sent)] #this gave you the all sentences that your special word is in it ! \nmy_sentence2=[sent for sent in sentence if \"hoe\" in word_tokenize(sent)] #this gave you the all sentences that your special word is in it ! \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_1 = set(my_sentence1)\n\nset_2 = set(my_sentence2)\n\nlist_2_items_not_in_list_1 = list(set_2 - set_1)\ncombined_list = my_sentence1 + my_sentence2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(combined_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open('../input/data60/labeled_data60.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw2 = f.read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=sent_tokenize(raw2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_sentence1=[sent for sent in sentence if \"all\" in word_tokenize(sent)] #this gave you the all sentences that your special word is in it ! \nmy_sentence2=[sent for sent in sentence if \"are\" in word_tokenize(sent)] #this gave you the all sentences that your special word is in it ! \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_1 = set(my_sentence1)\n\nset_2 = set(my_sentence2)\n\nlist_2_items_not_in_list_1 = list(set_2 - set_1)\ncombined_list = my_sentence1 + my_sentence2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(combined_list)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}