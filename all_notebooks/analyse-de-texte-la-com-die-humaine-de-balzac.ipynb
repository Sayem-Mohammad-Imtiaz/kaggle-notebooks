{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"L'objet de ce notebook est de fournir un exemple d'étude de texte en français par traitement du langage naturel.\nLe texte choisi est l'intégralité de la Comédie humaine de Balzac.","metadata":{}},{"cell_type":"markdown","source":"# 1. Librairies","metadata":{}},{"cell_type":"code","source":"!python -m spacy download fr_core_news_md;\n!python -m spacy download fr_core_news_sm;","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv;\ndef SaveData (Filename=\"\",DataList=[]):\n    with open (Filename,\"w\",encoding='utf-8',newline='\\n') as csvfile:\n        DataWriter=csv.writer(csvfile,delimiter='\\n',quotechar=\" \",quoting=csv.QUOTE_NONNUMERIC)\n        DataWriter.writerow(DataList)\n        csvfile.close()\n        print (\"Données enregistrées!\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pprint import pprint;\nimport numpy as np;\nimport pandas as pd;\nimport seaborn as sns;\nimport matplotlib.pyplot as plt;\nimport nltk;\nfrom sklearn.feature_extraction.text import CountVectorizer;\nfrom sklearn.feature_extraction.text import TfidfVectorizer;\nfrom sklearn.preprocessing import LabelBinarizer;\nfrom nltk.corpus import stopwords;\nfrom nltk.stem.porter import PorterStemmer;\nfrom wordcloud import WordCloud,STOPWORDS;\nfrom nltk.stem import WordNetLemmatizer;\nfrom nltk.tokenize import word_tokenize,sent_tokenize;\nimport os;\nimport spacy;\nimport re,string,unicodedata;\nfrom nltk.tokenize.toktok import ToktokTokenizer;\nfrom nltk.stem import LancasterStemmer,WordNetLemmatizer;\nfrom nltk.tag import pos_tag;\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier;\nfrom sklearn.naive_bayes import MultinomialNB;\nfrom sklearn.svm import SVC;\nfrom textblob import TextBlob;\nfrom textblob import Word;\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score;\nimport fr_core_news_md;\nnlp_fr = fr_core_news_md.load();\nimport spacy.lang.fr;\nfrom stop_words import get_stop_words;\nimport plotly.graph_objects as go;\nimport networkx as nx;\nfrom networkx.algorithms import bipartite;\nimport igraph as ig;\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Import du texte","metadata":{}},{"cell_type":"code","source":"def getFilenames(root, extension='.txt', separator=' '): #fonction pour récupérer les noms de fichiers\n    result = []\n    for _, _, files in os.walk(root):\n        for file in files:\n            if file.endswith(extension):\n                result.append(file.split(separator)[0])\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_files = getFilenames(\"../input/la-comedie-humaine-de-balzac/\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def nett_nom(texte):  #fonction de nettoyage du nom des fichiers pour obtenir le nom du roman\n    cleantext=re.sub(r'[0-9]', '', str(texte))\n    cleantext=re.sub(r'\\A_', '', cleantext)\n    cleantext=re.sub(r'.txt', '', cleantext)\n    cleantext=re.sub(r'_',' ', cleantext)\n    return cleantext","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'Noms_fichier': list_files}) #définition du data frame contenant les noms de fichier, les noms de roman et le texte.\ndf['Noms_romans'] = df.Noms_fichier.apply(lambda x: nett_nom(x));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Texte']=0 #initialisation de la colonne 'Texte'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_text(fileName):  #fonction de récupération du texte de chaque roman\n    fileName=str(\"../input/la-comedie-humaine-de-balzac/\" )+ str(fileName)\n    f = open(fileName, \"r\", encoding='latin-1')\n    cleantext = f.read()\n    return cleantext","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(df)):  # import du texte dans la colonne 'Texte'\n    tmp = str(get_text(str(df.Noms_fichier.iloc[i])))\n    df.Texte.iloc[i]=tmp\n    #print (i)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Etude du nom des personnages","metadata":{}},{"cell_type":"markdown","source":"On commence par extraire les noms propres du premier roman. On procède par NER grâce à spaCy.","metadata":{}},{"cell_type":"code","source":"doc = nlp_fr(re.sub(r'\\x97','',re.sub(r'\\x92',' ',df.Texte.iloc[0]))) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Noms_propres=pd.DataFrame(columns = ['Word' , 'Label'])\ni=0\nfor word in doc.ents:\n    Noms_propres.loc[i]=[word.text,word.label_]\n    i=i+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On ne conserve que les noms propres de personnes (étiquetés 'PER').","metadata":{}},{"cell_type":"code","source":"tmp=Noms_propres.loc[Noms_propres['Label'] == 'PER']\ntmp['Label']=1\ntmp['Word']=tmp.Word.apply(lambda x: str.lower(x))\ntmp=tmp.groupby(by=[\"Word\"],as_index=False).sum()\n#tmp=tmp.loc[tmp['Label'] >2]\ntmp['Roman']=str(df.Noms_romans.iloc[0])\ntmp","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Noms=tmp\nNoms","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range (1,len(list_files)):\n    doc = nlp_fr(re.sub(r'\\x97','',re.sub(r'\\x92',' ',df.Texte.iloc[i])))\n    nom_roman=str(df.Noms_romans.iloc[i])\n    Noms_propres=pd.DataFrame(columns = ['Word' , 'Label'])\n    j=0\n    for word in doc.ents:\n        Noms_propres.loc[j]=[word.text,word.label_]\n        j=j+1\n    tmp=Noms_propres.loc[Noms_propres['Label'] == 'PER']\n    tmp['Label']=1\n    tmp['Word']=tmp.Word.apply(lambda x: str.lower(x))\n    tmp=tmp.groupby(by=[\"Word\"],as_index=False).sum()\n    #tmp=tmp.loc[tmp['Label'] >2]\n    tmp['Roman']=str(nom_roman)\n    tmp\n    Noms=pd.concat([Noms,tmp], ignore_index=False)\n    del tmp\n    del nom_roman\n    del Noms_propres\n    #print(i)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aperçu du data frame obtenu:","metadata":{}},{"cell_type":"code","source":"display(Noms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"romans=df['Noms_romans']\nnoms_pers = set(Noms['Word'])\nliens = pd.DataFrame(Noms)\nliens.set_axis(['personnages', 'weigth','livres'], \n                    axis='columns', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G = nx.Graph()\nG.add_nodes_from(romans,bipartite='livres')\nG.add_nodes_from(noms_pers,bipartite='personnages')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G.add_weighted_edges_from([(row['personnages'], row['livres'],1) for idx, row in liens.iterrows()],weight='weigth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(G.edges(data=True))\npos = {node:[0, i] for i,node in enumerate(liens['livres'])}\npos.update({node:[1, i] for i,node in enumerate(liens['personnages'])})\nnx.draw(G, pos, with_labels=False)\nfor p in pos:  # raise text positions\n    pos[p][1] += 0.25\nnx.draw_networkx_labels(G, pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Noms = Noms.groupby(by=[\"personnages\"],as_index=False).sum()\nNoms = Noms.sort_values(by=['weigth'],ascending=False)\nNoms = Noms.loc[Noms['weigth'] >300]\nNoms\nfig = go.Figure(\n    data=[go.Bar(y=Noms['weigth'],x=Noms['personnages'])],\n    layout_title_text=\"Noms propres de personnages les plus représentés dans la Comédie humaine\" )\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bonus: reseau des personnages récurrents dans la Comédie humaine.","metadata":{}},{"cell_type":"code","source":"Nodes=pd.read_csv('../input/la-comedie-humaine-de-balzac/nodes.csv',sep=\";\",encoding='utf-8')\nLinks=pd.read_csv('../input/la-comedie-humaine-de-balzac/links.csv',sep=\";\",encoding='utf-8')\nLinks.set_axis(['from', 'to'], \n                    axis='columns', inplace=True)\nL=len(Links)\nN=len(Nodes)\nEdges=[(Links['from'][k], Links['to'][k]) for k in range(L)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=[]\ngroup=[]\nfor node in range(0,N):\n    labels.append(Nodes['nom'].iloc[node])\n    group.append(Nodes['groupe'].iloc[node])\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G=ig.Graph(Edges, directed=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layt=G.layout('kk', dim=3)\n\nXn=[layt[k][0] for k in range(N)]# x-coordinates of nodes\nYn=[layt[k][1] for k in range(N)]# y-coordinates\nZn=[layt[k][2] for k in range(N)]# z-coordinates\nXe=[]\nYe=[]\nZe=[]\n\nfor e in Edges:\n    Xe+=[layt[e[0]][0],layt[e[1]][0], None]# x-coordinates of edge ends\n    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n    Ze+=[layt[e[0]][2],layt[e[1]][2], None]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install chart_studio\nimport chart_studio.plotly as py\ntrace1=go.Scatter3d(x=Xe,\n               y=Ye,\n               z=Ze,\n               mode='lines',\n               line=dict(color='rgb(125,125,125)', width=1),\n               hoverinfo='none'\n               )\n\ntrace2=go.Scatter3d(x=Xn,\n               y=Yn,\n               z=Zn,\n               mode='markers',\n               name='actors',\n               marker=dict(symbol='circle',\n                             size=6,\n                             color=group,\n                             colorscale='Viridis',\n                             line=dict(color='rgb(50,50,50)', width=0.5)\n                             ),\n               text=labels,\n               hoverinfo='text'\n               )\n\naxis=dict(showbackground=False,\n          showline=False,\n          zeroline=False,\n          showgrid=False,\n          showticklabels=False,\n          title=''\n          )\n\nlayout = go.Layout(\n         title=\"Réseau des personnages récurrents de la Comédie humaine et des romans dans lesquels ils apparaissent\",\n         width=1000,\n         height=1000,\n         showlegend=False,\n         scene=dict(\n             xaxis=dict(axis),\n             yaxis=dict(axis),\n             zaxis=dict(axis),\n        ),\n     margin=dict(\n        t=100\n    ),\n    hovermode='closest',\n    annotations=[\n           dict(\n           showarrow=False,\n            xref='paper',\n            yref='paper',\n            x=0,\n            y=0.1,\n            xanchor='left',\n            yanchor='bottom',\n            font=dict(\n            size=14\n            )\n            )\n        ],    )\ndata=[trace1, trace2]\nfig=go.Figure(data=data, layout=layout)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.io as pio\npio.show(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Etude des lieux","metadata":{}},{"cell_type":"code","source":"doc = nlp_fr(re.sub(r'\\x97','',re.sub(r'\\x92',' ',df.Texte.iloc[0]))) \nNoms_propres=pd.DataFrame(columns = ['Word' , 'Label'])\ni=0\nfor word in doc.ents:\n    Noms_propres.loc[i]=[word.text,word.label_]\n    i=i+1\ntmp=Noms_propres.loc[Noms_propres['Label'] == 'LOC']\ntmp['Label']=1\ntmp['Word']=tmp.Word.apply(lambda x: str.lower(x))\ntmp=tmp.groupby(by=[\"Word\"],as_index=False).sum()\n#tmp=tmp.loc[tmp['Label'] >2]\ntmp['Roman']=str(df.Noms_romans.iloc[0])\nLieux=tmp\nfor i in range (1,len(list_files)):\n    doc = nlp_fr(re.sub(r'\\x97','',re.sub(r'\\x92',' ',df.Texte.iloc[i])))\n    nom_roman=str(df.Noms_romans.iloc[i])\n    Noms_propres=pd.DataFrame(columns = ['Word' , 'Label'])\n    j=0\n    for word in doc.ents:\n        Noms_propres.loc[j]=[word.text,word.label_]\n        j=j+1\n    tmp=Noms_propres.loc[Noms_propres['Label'] == 'LOC']\n    tmp['Label']=1\n    tmp['Word']=tmp.Word.apply(lambda x: str.lower(x))\n    tmp=tmp.groupby(by=[\"Word\"],as_index=False).sum()\n    #tmp=tmp.loc[tmp['Label'] >2]\n    tmp['Roman']=str(nom_roman)\n    tmp\n    Lieux=pd.concat([Lieux,tmp], ignore_index=False)\n    del tmp\n    del nom_roman\n    del Noms_propres\n    \nLieux","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Lieux = Lieux.groupby(by=[\"Word\"],as_index=False).sum()\nLieux = Lieux.sort_values(by=['Label'],ascending=False)\nLieux = Lieux.loc[Lieux['Label'] >200]\nLieux\nfig = go.Figure(\n    data=[go.Bar(y=Lieux['Label'],x=Lieux['Word'])],\n    layout_title_text=\"Noms propres de lieux les plus représentés dans la Comédie humaine\"\n    \n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Etude du texte","metadata":{}},{"cell_type":"code","source":"#from spacy.tokens import Token\n#stop_words_getter = lambda token: token.is_stop or token.lower_ in stopwords or token.lemma_ in stopwords\n#Token.set_extension('is_stop', getter=stop_words_getter, force=True)\n#docs = list(nlp_fr.pipe(df.Texte))\n#tokens = [[w.lemma_ for w in tokens if w.is_alpha and (len(w.lemma_))>2 and not w.is_stop] for tokens in docs]\n#Lemmas = pd.Series(tokens)\n#df.loc[:,'lemmas'] =Lemmas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def suppSW(liste):\n#    lem_sw = []\n#    for mot in liste:\n#        if mot not in stopwords:\n#            lem_sw.append(mot)\n#    return lem_sw","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lemmy = df_reviews_clean.lemmas.apply(suppSW)\n#lem_sery = pd.Series(lemmy)\n#df['lemmas_c'] = lem_sery","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}