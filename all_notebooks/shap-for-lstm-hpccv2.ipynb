{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/hpcc-new-datasets/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==1.14.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"variables_name = pd.read_csv(\"../input/hpcc20steps/variables_name.csv\", header=None)  # use variable names from hpcc_data_v1\nfeatures = variables_name.values[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variables_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport numpy as np\n# with open(\"../input/hpcc-new-datasets/X_train_HPCC_ts20_set_1.json\") as of:\n#     X_train_1 = np.array(json.load(of))\n# with open(\"../input/hpcc-new-datasets/y_train_HPCC_ts20_set_1.json\") as of:\n#     y_train_1 = np.array(json.load(of))\n# with open(\"../input/hpcc-new-datasets/X_train_HPCC_ts20_set_2.json\") as of:\n#     X_train_2 = np.array(json.load(of))\n# with open(\"../input/hpcc-new-datasets/y_train_HPCC_ts20_set_2.json\") as of:\n#     y_train_2 = np.array(json.load(of))\nwith open(\"../input/hpcc-new-datasets/X_train_HPCC_ts20_set_3.json\") as of:\n    X_train_3 = np.array(json.load(of))\nwith open(\"../input/hpcc-new-datasets/y_train_HPCC_ts20_set_3.json\") as of:\n    y_train_3 = np.array(json.load(of))\n    \n# with open(\"../input/hpcc-new-datasets/X_test_HPCC_ts20_set_1.json\") as of:\n#     X_test_1 = np.array(json.load(of))\n# with open(\"../input/hpcc-new-datasets/y_test_HPCC_ts20_set_1.json\") as of:\n#     y_test_1 = np.array(json.load(of))    \nwith open(\"../input/hpcc-new-datasets/X_test_HPCC_ts20_set_3.json\") as of:\n    X_test_3 = np.array(json.load(of))\nwith open(\"../input/hpcc-new-datasets/y_test_HPCC_ts20_set_3.json\") as of:\n    y_test_3 = np.array(json.load(of)) \n    \n# X_train = np.concatenate((X_train_1, X_train_2, X_train_3))\n# X_test = np.concatenate((X_test_1, X_test_2))\n\nX_train =  X_train_3\nX_test = X_test_3\n\n# y_train = np.concatenate((y_train_1, y_train_2, y_train_3))\n# y_test = np.concatenate((y_test_1, y_test_2))\n\ny_train = y_train_3\ny_test = y_test_3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.optimizers import Adam\n\n\ndef createModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, inputShape):\n    # input layer\n    lstm1 = LSTM(l1Nodes, input_shape=inputShape, return_sequences=True)\n    lstm2 = LSTM(l2Nodes, return_sequences=True)\n    flatten = Flatten()\n    dense1 = Dense(d1Nodes)\n    dense2 = Dense(d2Nodes)\n\n    # output layer\n#     outL = Dense(1, activation='relu')\n    outL = Dense(1)\n    # combine the layers\n    layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n    # create the model\n    model = Sequential(layers)\n    opt = Adam(learning_rate=0.005)\n    model.compile(optimizer=opt, loss='mse')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = createModel(8, 8, 8, 4, (X_train.shape[1], X_train.shape[2]))\nmodel.fit(X_train, y_train, batch_size=8, epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the entire model to a HDF5 file.\n# The '.h5' extension indicates that the model shuold be saved to HDF5.\nmodel.save('my_model.h5') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train = model.predict(X_train)\nmse(y_train, y_pred_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\nmse(y_test, y_pred)\n\n### ?? Why is the error so big","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SHAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DeepSHAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the training data for deep explainer => can use fewer instances\nexplainer = shap.DeepExplainer(model, X_train)\n# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_test)\n# init the JS visualization code\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer.expected_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(shap_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shap.force_plot(explainer.expected_value[0], shap_values[0][0][0,:], features)\nprint(features)\nprint(len(features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nj=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values[0][i][j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[i][j].shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shap.force_plot(explainer.expected_value[0], shap_values[0][0], features)\ni = 0\nj = 0\nx_test_df = pd.DataFrame(data=X_test[i][j].reshape(1,10), columns = features)\nshap.force_plot(explainer.expected_value[0], shap_values[0][i][j], x_test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check sum of shap values vs prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 11\npred_i = model.predict(X_test[i:i+1])\nsum_shap_i = shap_values[0][i].sum() + explainer.expected_value[0]\n\npred_i, sum_shap_i","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They are the same. It looks ok"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot SHAP for ONLY one observation i\ni = 0\nshap.initjs()\n\nx_test_df = pd.DataFrame(data=X_test[i], columns = features)\nshap.force_plot(explainer.expected_value[0], shap_values[0][i], x_test_df)\n## Problem:  Can not take into account many observations at the same time.\n### The pic below explain for only 1 observation of 20 time steps, each time step has 10 features.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average SHAP for ALL observations"},{"metadata":{"trusted":true},"cell_type":"code","source":"################# Plot AVERAGE shap values for ALL observations  #####################\n## Consider ABSOLUTE of SHAP values ##\nshap_average_abs_value = np.abs(shap_values[0]).mean(axis=0)\n\nx_average_value = pd.DataFrame(data=X_test.mean(axis=0), columns = features)\nshap.force_plot(0, shap_average_abs_value, x_average_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot time step 10th for average shap\ni = 0\nshap.force_plot(0, shap_average_abs_value[i], x_average_value.iloc[i,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################# Plot AVERAGE shap values for ALL observations  #####################\n## Consider average (+ is different from -)\nshap_average_value = shap_values[0].mean(axis=0)\n\nx_average_value = pd.DataFrame(data=X_test.mean(axis=0), columns = features)\nshap.force_plot(explainer.expected_value[0], shap_average_value, x_average_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot time step 10th for average shap\ni = 0\nshap.force_plot(explainer.expected_value[0], shap_average_value[i], x_average_value.iloc[i,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values_2D = shap_values[0].reshape(-1,10)\nX_test_2D = X_test.reshape(-1,10)\n\n\nshap_values_2D.shape, X_test_2D.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_2d.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values_2D, x_test_2d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values_2D, x_test_2d, plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_test_set = X_test_2D.shape[0]\nlen_test_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## SHAP for each time step\nNUM_STEPS = 20\nNUM_FEATURES = 10\n\n\n# step = 0\nfor step in range(NUM_STEPS):\n    indice = [i for i in list(range(len_test_set)) if i%NUM_STEPS == step]\n    shap_values_2D_step = shap_values_2D[indice]\n    x_test_2d_step = x_test_2d.iloc[indice]\n    print(\"_______ time step {} ___________\".format(step))\n    shap.summary_plot(shap_values_2D_step, x_test_2d_step, plot_type=\"bar\")\n    shap.summary_plot(shap_values_2D_step, x_test_2d_step)\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## GradientExplainer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the training data for deep explainer => can use fewer instances\nexplainer = shap.GradientExplainer(model, X_train)\n# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_test)\n# init the JS visualization code\nshap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}