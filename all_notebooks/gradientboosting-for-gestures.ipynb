{"cells":[{"metadata":{"_uuid":"cbe11c03-01f5-4af2-8d45-190f4864646a","_cell_guid":"89c49461-893b-4034-b077-a95aa282e6f3","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ndata1= pd.read_csv('/kaggle/input/emg-4/0.csv',header=None)\ndata2= pd.read_csv('/kaggle/input/emg-4/1.csv',header=None)\ndata3= pd.read_csv('/kaggle/input/emg-4/2.csv',header=None)\ndata4= pd.read_csv('/kaggle/input/emg-4/3.csv',header=None)\ndfs=[data1,data2,data3,data4]\ndata = pd.concat(dfs)\n\ny = data[64]\nx = data.drop(64,axis=1)\n\ndef Grad_boost(x,y):\n  from sklearn.ensemble import GradientBoostingClassifier\n  import numpy as np\n  from sklearn.model_selection import GridSearchCV\n  param_grid2 = [\n    {'min_samples_split': np.array([7]),\n    'max_depth': np.array([4]),\n    'min_samples_leaf':np.array([5]),\n    'learning_rate': np.array([0.41]),\n    'criterion':['friedman_mse']\n    }\n  ]\n  modelo = GradientBoostingClassifier(n_estimators=50)\n  gridGradientBoostingClassifier= GridSearchCV(estimator=modelo,param_grid=param_grid2,cv=3,n_jobs=-1)\n  gridGradientBoostingClassifier.fit(x,y)\n  print('Mínimo split:', gridGradientBoostingClassifier.best_estimator_.min_samples_split)\n  print('Máxima profundidade:', gridGradientBoostingClassifier.best_estimator_.max_depth)\n  print('Mínimo leaf:', gridGradientBoostingClassifier.best_estimator_.min_samples_leaf)\n  print('Mínimo learning rate:', gridGradientBoostingClassifier.best_estimator_.learning_rate)\n  print('Mínimo criterion:', gridGradientBoostingClassifier.best_estimator_.criterion)    \n  print('R2:',gridGradientBoostingClassifier.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grad_boost(x,y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}