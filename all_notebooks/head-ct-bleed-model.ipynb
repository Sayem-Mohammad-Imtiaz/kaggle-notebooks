{"cells":[{"metadata":{"_uuid":"dd44b63d190c758656ffc470c4db9741cbee049f","_cell_guid":"bd74543b-a38a-4c67-8ff5-eac089052e29"},"cell_type":"markdown","source":"# Overview\nIn this notebook we try and automatically detect bleeds in Head CT scans. We have readings from 3 independent physicians for the entire scan and we associate the readings with each slice"},{"metadata":{"trusted":true,"_uuid":"3f650920fb1b31605b40371701c6605db2123c26"},"cell_type":"code","source":"# params\nNR_EPOCHS = 10\nMODEL_ARCH = 'NAS'\nBATCH_SIZE = 48\nDENSE_SIZE = 128\nIMG_X = 384\nIMG_Y = 384","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom pydicom import read_file as read_dicom\nimport SimpleITK as sitk\nbase_dir = os.path.join('..', 'input', 'qureai-headct')\nreads_dir = os.path.join('..', 'input', 'headctreads')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"all_dicom_paths = glob(os.path.join(base_dir, '*', '*', '*', '*', '*'))\nprint(len(all_dicom_paths), 'dicom files')\ndicom_df = pd.DataFrame(dict(path = all_dicom_paths))\ndicom_df['SliceNumber'] = dicom_df['path'].map(lambda x: int(os.path.splitext(x.split('/')[-1])[0][2:]))\ndicom_df['SeriesName'] = dicom_df['path'].map(lambda x: x.split('/')[-2])\ndicom_df['StudyID'] = dicom_df['path'].map(lambda x: x.split('/')[-3])\ndicom_df['PatientID'] = dicom_df['path'].map(lambda x: x.split('/')[-4].split(' ')[0])\ndicom_df['PatSeries'] = dicom_df.apply(lambda x: '{PatientID}-{SeriesName}'.format(**x), 1)\ndicom_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f4c7676c980fe08441074ef577663a332c0969c","_cell_guid":"b144a5f5-cb59-4685-a4e3-81e24cf1b323","trusted":true},"cell_type":"code","source":"small_scans = dicom_df.groupby('PatSeries').count().reset_index().query('SliceNumber<240')\ndicom_df = dicom_df[dicom_df['PatSeries'].isin(small_scans['PatSeries'])]\nprint('Removed big scans', dicom_df.shape[0], 'remaining images')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ff117050589356170973c7e835330a2cda4c15a","_cell_guid":"81ace960-20c7-46a3-ba38-7f96887409ed","trusted":true},"cell_type":"code","source":"dicom_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d765dd7fd9630c2667135da7661c7c4f2e1ab02","_cell_guid":"2d9042aa-7d07-4c82-b3f9-ad998422d818"},"cell_type":"markdown","source":"# Read Physician Reads\nHere we load the physician reads and preprocess them so we can associate them with each scan. We average them here to make it easier."},{"metadata":{"_uuid":"99ef343cf64350ce722249bda2200e535c8e26e3","_cell_guid":"01132a7a-525d-403d-b15d-03027b32cb12","trusted":true},"cell_type":"code","source":"read_overview_df = pd.read_csv(os.path.join(reads_dir, 'reads.csv'))\nread_overview_df['PatientID'] = read_overview_df['name'].map(lambda x: x.replace('-', '')) \nread_overview_df.sample(2).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4f7ea8d6fc4663211a62833e4cfe0578a57a16a","_cell_guid":"4ac083b0-9f20-4586-9f60-b43e071423cb","trusted":true},"cell_type":"code","source":"from collections import OrderedDict\nnew_reads = []\nfor _, c_row in read_overview_df.iterrows():\n    base_dict = OrderedDict(PatientID = c_row['PatientID'], Category = c_row['Category'])\n    for reader in ['R1', 'R2', 'R3']:\n        c_dict = base_dict.copy()\n        c_dict['Reader'] = reader\n        for k,v in c_row.items():\n            if (reader+':') in k:\n                c_dict[k.split(':')[-1]] = v\n        new_reads += [c_dict]\nnew_reads_df = pd.DataFrame(new_reads)\nnew_reads_df.to_csv('formatted_reads.csv')\nnew_reads_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8abb793b847755d522c644efb119e472681f1949","_cell_guid":"0fd497ef-3a82-4ef0-a845-1f4e48e64ace","trusted":true},"cell_type":"code","source":"avg_reads_df = new_reads_df.groupby(['PatientID', 'Category']).agg('mean').reset_index()\nread_dicom_df = pd.merge(avg_reads_df, dicom_df, on = 'PatientID')\nread_dicom_df['Bleed'] = read_dicom_df.apply(lambda x: np.clip(x['BleedLocation-Left']+x['BleedLocation-Right']+x['ChronicBleed'], 0, 1), 1)\nprint(read_dicom_df.shape[0], 'total weakly-labeled slices')\nread_dicom_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad3a2c8a33fa23fbd64a85507e2ce0743d38e57c","_cell_guid":"a9ac6c61-641d-4c35-be8b-8fc790ff63a7"},"cell_type":"markdown","source":"# Using SimpleITK\nUsing SimpleITK instead of pydicom lets us load the images correctly now"},{"metadata":{"_uuid":"3421e85a831427d3688e31b6a48c9bd78952b328","_cell_guid":"a3065dca-f10c-425b-a570-2a0a86877004","trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, 3, figsize = (20, 20))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), read_dicom_df.sample(9).iterrows()):\n    try:\n        c_img = sitk.ReadImage(c_row['path'])\n        c_slice = sitk.GetArrayFromImage(c_img)[0]\n        c_ax.imshow(c_slice, cmap = 'bone')\n        c_ax.set_title('Bleed: {Bleed:2.2f}, Fracture: {Fracture:2.2f}\\n{SeriesName}'.format(**c_row))\n    except Exception as e:\n        c_ax.set_title('{}'.format(str(e)[:40]))\n        print(e)\n    #c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fc33fa62086453ce818c33d1637e11a4cc35382","_cell_guid":"31316cb6-550a-49c4-902a-d5151ca4a3ac"},"cell_type":"markdown","source":"# Classify series name from image\nWe can make a simple model here to identify which series type an image came from"},{"metadata":{"_uuid":"34b96889ae36d915175c3945bc9ab6ac5c4f18ca","_cell_guid":"4274801b-e65a-4320-86fa-73ed283dfa16","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nvalid_df = read_dicom_df[['PatientID', 'Bleed']].drop_duplicates()\nprint('Patients', valid_df.shape[0])\ntrain_ids, test_ids = train_test_split(valid_df[['PatientID']], \n                                       test_size = 0.25, \n                                       stratify = valid_df['Bleed'].map(lambda x: x>0))\n\ntrain_unbalanced_df = read_dicom_df[read_dicom_df['PatientID'].isin(train_ids['PatientID'])]\ntest_df = read_dicom_df[read_dicom_df['PatientID'].isin(test_ids['PatientID'])]\nprint(train_unbalanced_df.shape[0], 'training images', test_df.shape[0], 'testing images')\ntrain_unbalanced_df['Bleed'].hist(figsize = (10, 5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f52e0afdf01103244085668d9c1751779be95f1","_cell_guid":"e17b2aee-685b-4d30-93ef-308eabe47f7d","trusted":true},"cell_type":"code","source":"train_df = train_unbalanced_df.groupby(['Bleed', 'SeriesName']).apply(lambda x: x.sample(200, replace = True)\n                                                      ).reset_index(drop = True)\nprint('New Data Size:', train_df.shape[0], 'Old Size:', train_unbalanced_df.shape[0])\ntrain_df['Bleed'].hist(figsize = (20, 5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c251f08afd6004ae37894565180545226d175056","_cell_guid":"1ffbdabd-1acd-4117-b97d-8d8846ba4f22","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (IMG_X, IMG_Y) # many of the ojbects are small so 512x512 lets us see them\nimg_gen_args = dict(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range = 0.05, \n                              width_shift_range = 0.02, \n                              rotation_range = 3, \n                              shear_range = 0.01,\n                              fill_mode = 'nearest',\n                              zoom_range = 0.05)\nimg_gen = ImageDataGenerator(**img_gen_args)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85be6dbc598f46579c61317291fc36fb614be6b0","_cell_guid":"4e17cb14-66f0-4aea-951c-9df1fe2269fd","trusted":true},"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                              seed = seed,\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values,0)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a771c6664f6de7bbb205787f7814b5810b045cd4","_cell_guid":"462a8d5d-6172-433d-9e18-c37e27ef2123"},"cell_type":"markdown","source":"# Replace PIL with SimpleITK\nSince we want to open images that are DICOMs we use SimpleITK to open them"},{"metadata":{"_uuid":"c8e2a983fcf3e247c3907188d1af21d4ec4ab8c8","_cell_guid":"1fe476c0-22aa-47c9-b465-042695057b00","trusted":true},"cell_type":"code","source":"import keras_preprocessing.image.utils as KPImage\nfrom PIL import Image\ndef apply_window(data, center, width):\n    low = center - width/2.\n    high = center + width/2\n    data = np.clip(data, low, high)\n    data += -1 * low\n    data /= width\n    return data\ndef read_dicom_image(in_path):\n    c_img = sitk.ReadImage(in_path)\n    c_slice = sitk.GetArrayFromImage(c_img)[0]\n    return c_slice\n    \nclass medical_pil():\n    @staticmethod\n    def open(in_path):\n        if '.dcm' in in_path:\n            # we only want to keep the positive labels not the background\n            c_slice = read_dicom_image(in_path)\n            wind_slice = apply_window(c_slice, 40, 80)\n            int_slice =  (255*wind_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n            return Image.fromarray(int_slice)\n        else:\n            return Image.open(in_path)\n    fromarray = Image.fromarray\nKPImage.pil_image = medical_pil","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"882508db9e54304b0f33868fae54adae3cbeed3a","_cell_guid":"9865a24f-ecd0-478a-b002-2c42871eb996","trusted":true},"cell_type":"code","source":"batch_size = BATCH_SIZE\ntrain_gen = flow_from_dataframe(img_gen, train_df, \n                             path_col = 'path',\n                            y_col = 'Bleed', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = batch_size)\ntest_gen = flow_from_dataframe(img_gen, test_df, \n                             path_col = 'path',\n                            y_col = 'Bleed', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"176d48f680ce43f525f1243e7d6332727dcfd726","_cell_guid":"96bc0510-a13a-4298-9adf-e90893a0dd78","trusted":true},"cell_type":"code","source":"t_x, t_y = next(train_gen)\nprint(t_x.shape, '->', t_y.shape)\nfig, m_axs = plt.subplots(2, 4, figsize = (16, 8))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('Bleed: {:2.2f}'.format(c_y))\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f065238c0d53a40ce1fca57bed3adb1488c69b1b","_cell_guid":"c84cd0dc-e00f-4128-b248-0e4dc0665a11","trusted":true},"cell_type":"code","source":"if MODEL_ARCH=='NAS':\n    from keras.applications.nasnet import NASNetMobile as BaseModel\nelif MODEL_ARCH=='MOBILE':\n    from keras.applications.mobilenet import MobileNet as BaseModel\nelse:\n    raise ValueError('Model {} not supported'.format(MODEL_ARCH))\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\nct_model = Sequential()\nct_model.add(BatchNormalization(input_shape = t_x.shape[1:]))\nct_model.add(BaseModel(input_shape = t_x.shape[1:], include_top = False, weights = None))\nct_model.add(GlobalAveragePooling2D())\nct_model.add(Dropout(0.5))\nct_model.add(Dense(DENSE_SIZE))\nct_model.add(Dropout(0.25))\nct_model.add(Dense(1, activation = 'sigmoid'))\n\nct_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['mae', 'binary_accuracy'])\nct_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b448e63763fb9f218e0a5f39345e01d62c5c6e78","_cell_guid":"25a6f937-632f-406a-8de8-a626460c72f2","trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('cthead')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=6) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6910f279957dd0a0aeb4d7d338e72dfa79ef6b96","_cell_guid":"e3697411-2ba7-4e2e-94fa-5d03f577723a","scrolled":true,"trusted":true},"cell_type":"code","source":"ct_model.fit_generator(train_gen, \n                       steps_per_epoch = 8000//BATCH_SIZE,\n                        validation_data = test_gen, \n                       validation_steps = 4000//BATCH_SIZE,\n                              epochs = NR_EPOCHS, \n                              callbacks = callbacks_list,\n                             workers = 4,\n                             use_multiprocessing=False, \n                             max_queue_size = 10\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86f11f7c10abfbb95ed2012585599942ea1af54d"},"cell_type":"code","source":"%%time\nout_vals = ct_model.evaluate_generator(test_gen, steps = 4000//BATCH_SIZE, workers=4)\nprint('Mean Absolute Error: %2.1f%%\\nAccuracy %2.1f%%' % (out_vals[1]*100, out_vals[2]*100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e18e3170d7456486a9bbb2b3cf13e5f4f2537c85","_cell_guid":"463c6cac-9113-4993-9d10-b866face1d76","trusted":true},"cell_type":"code","source":"eval_df = pd.DataFrame([dict(zip(ct_model.metrics_names, out_vals))])\neval_df.to_csv('test_score.csv', index = False)\neval_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d2fd621e57c4788f0c22882001dd9fad9d20da1","_cell_guid":"583130cb-e35a-4bcb-b9e9-432d8026fcf3","trusted":true},"cell_type":"code","source":"test_gen.batch_size = 128\nt_x, t_y = next(test_gen)\npred_y = ct_model.predict(t_x)\nprint(t_x.shape, '->', t_y.shape)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, p_y, c_ax) in zip(t_x, t_y, pred_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('Bleed: {:2.2f}%\\nPrediction: {:2.2f}%'.format(100*c_y, 100*p_y[0]))\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"194806c036e95a5f5c942818fab83db76513d56c","_cell_guid":"63efcd98-7bc8-4099-83b1-22695cc31557"},"cell_type":"markdown","source":"# Regression Prediction\nIn a perfect world this would be a line, but as we see it is quite far from that"},{"metadata":{"_uuid":"b988ceccc77a5868159ccbf56a0be880ded2a526","_cell_guid":"14271aef-e91c-4c8d-a518-31fef21aa935","trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig,ax1 = plt.subplots(1,1)\nsns.swarmplot(x = (100*t_y).astype(int), y = pred_y[:,0], ax = ax1)\nax1.set_xlabel('Bleed')\nax1.set_ylabel('Prediction')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa0462b4caf4bacb2e1f09eca888d40b68b60511","_cell_guid":"d6ebb8d7-a3a1-4901-ac8b-9ec1ded4a29c","trusted":true},"cell_type":"code","source":"sns.lmplot(x = 'x', y = 'y', data = pd.DataFrame(dict(x = (100*t_y).astype(int), y = pred_y[:,0])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f56c08115aa337d32f76257cf12dd03b9ea32090","_cell_guid":"dd8d6850-fbb5-4b9f-85b0-43aaeb135c1a"},"cell_type":"markdown","source":"# Run a whole scan\nHere we take a random scan and run every slice"},{"metadata":{"_uuid":"b798618646d0c244718842e7b997451c3a6b9dfd","_cell_guid":"723383ea-f97c-4c23-a40b-e76033a247ea","trusted":true},"cell_type":"code","source":"bleed_patient_id = test_df.query('Bleed==1.0').query('SliceNumber>100 and SliceNumber<300').sample(1, random_state = 2018)[['PatientID', 'SeriesName']]\nscan_df = pd.merge(test_df,bleed_patient_id).sort_values('SliceNumber')\nprint('Slices', scan_df.shape[0])\nscan_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f487e7e03dd56a0b39fd32528df27702f311f9fc"},"cell_type":"markdown","source":"#### fix slice order (names arent always right)"},{"metadata":{"_uuid":"2913af3ad74d6351aa92def04f3ccbf16b6aa947","trusted":true},"cell_type":"code","source":"series_reader = sitk.ImageSeriesReader()\nscan_df['path'] = series_reader.GetGDCMSeriesFileNames(os.path.dirname(scan_df['path'].values[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e758f242968f7f25c2119dd38144e5a49332c0b5","_cell_guid":"b2024535-57bc-455b-9c8a-e887fd1bf2d1","trusted":true},"cell_type":"code","source":"scan_gen = flow_from_dataframe(img_gen, scan_df, \n                             path_col = 'path',\n                            y_col = 'Bleed', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = scan_df.shape[0], \n                              shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0055c534792f77a404b1b0a76fd658edb5f44c32","_cell_guid":"b4db83f0-1ba6-4707-b1d2-ed870821e975","trusted":true},"cell_type":"code","source":"t_x, t_y = next(scan_gen)\npred_y = ct_model.predict(t_x, batch_size = batch_size)\nprint(t_x.shape, '->', t_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76e8d0aa60a0d4c29b58871269094d2873ecae52","_cell_guid":"bdc379ab-8c37-423b-ba74-133c58a17801","trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(8, 8, figsize = (16, 16))\nfor (c_x, c_y, p_y, c_ax) in zip(t_x, t_y, pred_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('{:2.1f}%'.format(100*p_y[0]))\n    c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bd99335c82ca1fa580e3fb0e4d6e0b0e7937ba5","_cell_guid":"50e730f6-a3ce-44bb-99f4-7ddfce046c65","trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(1,1, figsize = (10, 10))\nax1.plot(scan_df['SliceNumber'], pred_y[:,0], 'r.-')\nax1.set_xlabel('Slice Number')\nax1.set_ylabel('Bleed Prediction')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6447ba0bb6392524dce21d2d88b4493e77231389","_cell_guid":"187a76a1-2a1f-4b83-b4b2-da8a125988d2"},"cell_type":"markdown","source":"# Show the Most Suspicious Slices"},{"metadata":{"_uuid":"65d7d10fd52366061c3b71a8967dcec0ea4a0924","_cell_guid":"7006b599-b438-4194-9c48-133b2e6ec99f","trusted":true},"cell_type":"code","source":"new_idx = np.argsort(-pred_y[:,0])\nfig, m_axs = plt.subplots(5, 5, figsize = (16, 16))\nfor (c_x, c_y, p_y, c_ax) in zip(t_x[new_idx], t_y[new_idx], pred_y[new_idx], m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n    c_ax.set_title('{:2.1f}%'.format(100*p_y[0]))\n    c_ax.axis('off')\nfig.savefig('suspicious_slices.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c79f46373a385fb65c790a63d71a30c63f7eb8af","_cell_guid":"a7633db9-beb4-4ce6-a502-c127724cedff","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}