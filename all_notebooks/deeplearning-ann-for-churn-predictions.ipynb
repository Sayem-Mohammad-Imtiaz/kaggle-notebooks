{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading Required Data\n\ndata_train = pd.read_csv(\"/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv\",encoding=\"utf-8\", delimiter=',')\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bank Turnover Dataset\n#### Can you predict if bank customers will turnover next cycle ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the libraries\nimport numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\", 100)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Removing customerID and Row Number\n\ndata_train2 = data_train.drop(['RowNumber','CustomerId','Surname'],axis=1)\ndata_train2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train2.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets findout the distribution of Churn: Yes and Nos First\n\n# Good Practice: Always check if data set is balance or imbalance.\nsns.set_style('whitegrid')\nsns.countplot(x='Exited',data=data_train2,palette='RdBu_r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observations: \n\n- This is imbalanced dataset, There are different ways to cater it, But for the sake of learning deep learning, We can ignore it for now. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## There are some outliers in Balance and Estimated Salry. 1. Balance (min to 25%) is 0; while Estimated salary is \n## 11.58 rupees as minimum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets see this through dist plot\n\nplt.hist(data_train2.EstimatedSalary, bins=5\n         , rwidth=0.8)\nplt.xlabel('EstimatedSalary')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(data_train2.EstimatedSalary, bins=7\n         , rwidth=0.8)\nplt.xlabel('EstimatedSalary')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use percentiles technique to detect and remove outliers\n\n\nMaxThershold = data_train2['EstimatedSalary'].quantile(0.999)\nMaxThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MinThershold = data_train2['EstimatedSalary'].quantile(0.015)\nMinThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train3 = data_train2[(data_train2.EstimatedSalary < MaxThershold) & (data_train2.EstimatedSalary > MinThershold)]\ndata_train3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"10000-9540","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Detecting outlier in Balance\n\n## Lets see this through dist plot\n\nplt.hist(data_train3.Balance, bins=5\n         , rwidth=0.8)\nplt.xlabel('Balance')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(data_train3.Balance, bins=7\n         , rwidth=0.8)\nplt.xlabel('Balance')\nplt.ylabel('Count')\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use percentiles technique to detect and remove outliers\n\n\nMaxThershold = data_train3.Balance.quantile(0.999)\nMaxThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MinThershold = data_train3.Balance.quantile(0.370)\nMinThershold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4 = data_train3[(data_train3.Balance < MaxThershold) & (data_train3.Balance > MinThershold)]\ndata_train4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets seperate all as numerical/Categorical\n# Findout Missing Value %age\n\nstatistics_of_data = []\nfor col in data_train4.columns:\n  statistics_of_data.append((col,\n                             data_train4[col].isnull().sum()*100/data_train4.shape[0],\n                             data_train4[col].dtype\n                             ))\nstats_df = pd.DataFrame(statistics_of_data, columns=['Feature', 'missing_val', 'type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats_df.sort_values('missing_val', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##No missing Values Found","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Seperate out Numerical/Int Variables.\nnumerical_features = [feature for feature in data_train4.columns if data_train4[feature].dtypes != 'O' ]\nprint(len(numerical_features))\ndata_train4[numerical_features].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature = [feature for feature in numerical_features if len(data_train4[feature].unique())<25]\nprint(len(discrete_feature))\ndiscrete_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Continous Features\n\n\ncontinous_feature = [feature for feature in numerical_features if feature not in discrete_feature]\nprint(\"Continuous feature Count {}\".format(len(continous_feature)))\ndata_train4[continous_feature].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_unique_col_values(df):\n    i=1\n    for column in df:\n        str = \"{i}. {a} column have {b} unique values\"\n        print(str.format(i=i,a=column,b=df[column].unique()))\n        i=i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_unique_col_values(data_train4[discrete_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets create visuals for comparison of continous/discrete and target vairable\n##Exited: 0 -> No,1 ->Yes\ntenure_churn_no = data_train4[data_train4.Exited==0].Tenure\ntenure_churn_yes = data_train4[data_train4.Exited==1].Tenure\n\nplt.xlabel(\"tenure\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets create visuals for comparison of continous/discrete and target vairable\n##Exited: 0 -> No,1 ->Yes\nAge_churn_no = data_train4[data_train4.Exited==0].Age\nAge_churn_yes = data_train4[data_train4.Exited==1].Age\n\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([Age_churn_yes, Age_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Exited: 0 -> No,1 ->Yes\nBalance_churn_no = data_train4[data_train4.Exited==0].Balance\nBalance_churn_yes = data_train4[data_train4.Exited==1].Balance\n\nplt.xlabel(\"Balance\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([Balance_churn_yes, Balance_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EstimatedSalary\n##Exited: 0 -> No,1 ->Yes\nEstimatedSalary_churn_no = data_train4[data_train4.Exited==0].EstimatedSalary\nEstimatedSalary_churn_yes = data_train4[data_train4.Exited==1].EstimatedSalary\n\nplt.xlabel(\"EstimatedSalary\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nplt.hist([EstimatedSalary_churn_yes, EstimatedSalary_churn_no], rwidth=0.95, color=['red','green'],label=['Churn=1','Churn=0'])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets seperate our categorical features so that we can add other transformation uopn them\ncategoricalVariable = [feature for feature in data_train4.columns if data_train3[feature].dtype == 'O' ]\nlen(categoricalVariable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train4[categoricalVariable].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Male->1, Female 0\ndata_train4['Gender'].replace({'Female':1,'Male':0},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets apply One hot encoding for categorical column Geography\n\ndata_train5 = pd.get_dummies(data=data_train4, columns=['Geography'])\ndata_train5.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train5.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train5.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Scaling of continous data\n\ncontinous_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Data Scaling -->>Continous data only\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_train5[continous_feature] = scaler.fit_transform(data_train5[continous_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ij=1\nfor col in data_train5:\n    str = \"{ij}. {a} column have {b} unique values\"\n    print(str.format(ij = ij,a=col,b=data_train5[col].unique()))\n    ij=ij+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Train Test Split:::\n\nX = data_train5.drop('Exited',axis='columns')\ny = data_train5['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we are Builiding a Deep Learning Model (ANN) On keras/Tensorflow"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ChurnPred = keras.Sequential([\n    keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n    keras.layers.Dense(15, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ChurnPred.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ChurnPred.fit(X_train, y_train, epochs=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## So we got 85% Accuracy, Now Save this model\n\n# save model and architecture to single file\nmodel_ChurnPred.save(\"model_ChurnPred.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Now Loading a Model\nfrom keras.models import load_model\n \n# load model\nModel_Reloaded = load_model('model_ChurnPred.h5',compile=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yp = Model_Reloaded.predict(X_test)\nyp[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor element in yp:\n    if element > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , classification_report\n\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####################### ********** THE END ********************** ############################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}