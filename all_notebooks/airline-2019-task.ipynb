{"cells":[{"metadata":{},"cell_type":"markdown","source":"****Task Details****\n1. Combine different csv files into a single dataframe\n2. Clean the city_name columns, which also contain the abreviated state names.\n3. Check which of the columns are redundant information (i.e. they can easily be computed from the other columns)\n4. Find out the airports and the flight operators which correspond to maximum delay in general.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Imports","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gather Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_files = []\nfor (dirpath, dirnames, filenames) in os.walk('../input/airline-2019'):\n    for f in filenames:\n        full_path = os.path.abspath(os.path.join(dirpath, f))\n        list_of_files.append(full_path)\n        \nnum_files = len(list_of_files)\n\n#print the number of files gathered\nprint(f'{num_files} files in airline-2019 directory')\n\n#print out the absolute path to every file gathered\nfor file in list_of_files:\n    print(file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 1: Combine different csv files into a single dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# read one dataframe\ndf1 = pd.read_csv(list_of_files[0])\ndf1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#create an empty list, which we will fill up with dataframes\ndf_list = []\n\nfor file in list_of_files:\n    df = pd.read_csv(file)\n    df_list.append(df)\n\n    \n#concatenate all dfs in the list into one dataframe\nairline_2019_df = pd.concat(df_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sort airline dataframe by data\nairline_2019_df = airline_2019_df.sort_values(by=['FL_DATE'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 2: Clean the city_name columns, which also contain the abreviated state names.\n\nCurrently the ORIGIN_CITY_NAME and DEST_CITY_NAME columns shows the city and state abbreviation. The state abbreviation is redundant becuase there is a column named ORIGIN_STATE_NM and DEST_CITY_NAME","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#update the ORIGIN_CITY_NAME column\norigin_cities = airline_2019_df['ORIGIN_CITY_NAME'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_cities = []\nfor city in origin_cities:\n    city = city.split(',')[0]\n    true_cities.append(city)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df['ORIGIN_CITY_NAME'] = true_cities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#update destination cities\ndest_cities = airline_2019_df['DEST_CITY_NAME'].tolist()\n\ntrue_dest = []\nfor city in dest_cities:\n    city = city.split(',')[0]\n    true_dest.append(city)\n\nairline_2019_df['DEST_CITY_NAME'] = true_dest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 3: Check which of the columns are redundant information (i.e. they can easily be computed from the other columns)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#what is unamed.. are they all NaN..\nprint(airline_2019_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(airline_2019_df)) #Unamed 25 is full of NaN","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Investigate cancelled and cancellation code","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df.loc[airline_2019_df['CANCELLED'] != 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It seems as if canceled is redundant... if cancelled, then the cancellation code will have some value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#it seems as if canceled is redundant\ncanceled = airline_2019_df.loc[airline_2019_df['CANCELLED'] != 0]['CANCELLED'].tolist()\ncancel_code = airline_2019_df.loc[airline_2019_df['CANCELLED'] != 0]['CANCELLATION_CODE'].tolist()\nprint('length of canceled list: ', len(canceled))\nprint('length of canceled list: ', len(cancel_code))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"canceled_set = set()\ncancel_codes = set()\nfor i, j in zip(canceled, cancel_code):\n    if i not in canceled_set:\n        canceled_set.add(i)\n    if j not in cancel_codes:\n        cancel_codes.add(j)\n        \nprint('types of cancellations: ', canceled_set)\nprint('types of cancellation codes: ', cancel_codes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The canceled column is redundant, if a flight is cancelled it will be given a code of A, B, C, or D\n\n## We also already cleaned the city columns to take out the states, so states column is no longer redundant","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete cancelled column\nairline_2019_df = airline_2019_df.drop(columns=['CANCELLED', 'Unnamed: 25'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Task 4: Find out the airports and the flight operators which correspond to maximum delay in general.\n\nWhich origin airports correspond to greater delays.. and which destination airports correspond to greater delays?\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The following is the number of missing values in all of the delay columns\n* CARRIER_DELAY            6044570\n* WEATHER_DELAY            6044570\n* NAS_DELAY                6044570\n* SECURITY_DELAY           6044570\n* LATE_AIRCRAFT_DELAY      6044570\n\nBecause they all have the same amount of missing values, I'm going to assume that if one delay column has NaN, \nthey all have NaN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our goal is to find: \n\n* Which origin airports correspond with the greatest number of delays\n* Which origin airports correspond with the greatest average delay times\n* Which airlines correspond with the greatest number of delays\n* Which airlines correspond with the greatest average delay times\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#only work with flights that have values in the delay columns\ndelayed_flights = airline_2019_df.dropna(subset=['NAS_DELAY'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delayed_flights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#was getting SettingWithCopyWarning\ndelayed_flights = delayed_flights.copy()\ndelayed_flights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delayed_flights['total_delay'] = delayed_flights['CARRIER_DELAY'] + delayed_flights['WEATHER_DELAY'] +\\\ndelayed_flights['NAS_DELAY'] + delayed_flights['SECURITY_DELAY'] + delayed_flights['LATE_AIRCRAFT_DELAY']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total delay per airport')\ntotal_delay_org = delayed_flights.groupby('ORIGIN').total_delay.sum().reset_index()\ntotal_delay_org.sort_values('total_delay', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num delayed.. can someone help me find the probability of delay\nprint('number of delayed flights per airport')\nnumber_of_delays_org = delayed_flights.groupby('ORIGIN').total_delay.count().reset_index()\nnumber_of_delays_org.sort_values('total_delay', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#average delay... \n\n#fillnas with 0s...\nairline_2019_df = airline_2019_df.fillna(0)\n\n#calculate total\nairline_2019_df['total_delay'] = airline_2019_df['CARRIER_DELAY'] + airline_2019_df['WEATHER_DELAY'] +\\\nairline_2019_df['NAS_DELAY'] + airline_2019_df['SECURITY_DELAY'] + airline_2019_df['LATE_AIRCRAFT_DELAY']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"airline_2019_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Average delay by airport')\navg_delay = airline_2019_df.groupby('ORIGIN').total_delay.mean().reset_index()\navg_delay = avg_delay.rename(columns={\"total_delay\": \"avg_delay\"})\navg_delay.sort_values('avg_delay', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of delays per airline\nprint('total delay time by airline')\nairline_delay = airline_2019_df.groupby('OP_CARRIER_AIRLINE_ID').total_delay.count().reset_index()\nairline_delay.sort_values('total_delay', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#average delay time per airline\nprint('average delay time by airline')\nairline_avg_delay = airline_2019_df.groupby('OP_CARRIER_AIRLINE_ID').total_delay.mean().reset_index()\nairline_avg_delay = airline_avg_delay.rename(columns={'total_delay':'avg_delay'})\nairline_avg_delay.sort_values('avg_delay', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#probability of delay..\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So I have found the number of delays per airport, but can someone help me find the probability of delay.. \nP = (number of delays per airport)/(number of flights from airport) ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Questions, Comments, Suggestions?","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}