{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Notebook forked from [Abhishek Thakur](https://www.kaggle.com/abhishek/blending-blending-blending)","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y lightgbm\n!apt-get install -y libboost-all-dev\n!git clone --recursive https://github.com/Microsoft/LightGBM\n\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\nmake -j$(nproc)","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n!cd LightGBM/python-package/;python setup.py install --precompile\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:17:18.051833Z","iopub.execute_input":"2021-08-25T15:17:18.05219Z","iopub.status.idle":"2021-08-25T15:17:19.45059Z","shell.execute_reply.started":"2021-08-25T15:17:18.052149Z","shell.execute_reply":"2021-08-25T15:17:19.449712Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n!rm -r LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:17:19.452731Z","iopub.execute_input":"2021-08-25T15:17:19.453111Z","iopub.status.idle":"2021-08-25T15:17:20.899294Z","shell.execute_reply.started":"2021-08-25T15:17:19.453071Z","shell.execute_reply":"2021-08-25T15:17:20.898208Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-25T15:17:20.900873Z","iopub.execute_input":"2021-08-25T15:17:20.901216Z","iopub.status.idle":"2021-08-25T15:17:20.905825Z","shell.execute_reply.started":"2021-08-25T15:17:20.901186Z","shell.execute_reply":"2021-08-25T15:17:20.904994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {\n        'random_state': 1, \n        'booster': 'gbtree',\n        'n_estimators': 10000,\n        'learning_rate': 0.03628302216953097,\n        'reg_lambda': 0.0008746338866473539,\n        'reg_alpha': 23.13181079976304,\n        'subsample': 0.7875490025178415,\n        'colsample_bytree': 0.11807135201147481,\n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        n_jobs=4,tree_method='gpu_hist',\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_1\"]\nsample_submission.to_csv(\"test_pred_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:12:16.538832Z","iopub.status.idle":"2021-08-25T15:12:16.53921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    lgb_params = {'reg_alpha': 0.00016893787477692912,\n                 'reg_lambda': 7380.524142310997,\n                 'learning_rate': 0.05382799531839089,\n                 'max_depth': 4,\n                 'n_estimators': 9900,\n                 'min_child_weight': 10.617199131630898,\n                 'subsample': 0.2,\n                 'colsample_bytree': 0.2,'n_jobs':4}\n    \n    model = LGBMRegressor(\n        random_state=fold,\n        **lgb_params,device_type= 'gpu',metric = 'RMSE'\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_2\"]\nsample_submission.to_csv(\"test_pred_2.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:12:16.542491Z","iopub.status.idle":"2021-08-25T15:12:16.542888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    lgbm_parameters = {\n        'metric': 'RMSE',\n        'feature_pre_filter': False,\n        'lambda_l1': 0.45,\n        'lambda_l2': 4.8,\n        'learning_rate': 0.005,\n        'num_trees': 80000,\n        'num_leaves': 10, \n        'feature_fraction': 0.4, \n        'bagging_fraction': 1.0, \n        'bagging_freq': 0, \n        'min_child_samples': 100,\n        'num_threads': 4\n    }\n    \n    model = LGBMRegressor(\n        random_state=fold,\n        **lgbm_parameters,device= \"gpu\",\n        gpu_platform_id= 0,\n        gpu_device_id= 0\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_3\"]\nsample_submission.to_csv(\"test_pred_3.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:12:16.760806Z","iopub.execute_input":"2021-08-25T15:12:16.761141Z","iopub.status.idle":"2021-08-25T15:13:06.593217Z","shell.execute_reply.started":"2021-08-25T15:12:16.761105Z","shell.execute_reply":"2021-08-25T15:13:06.590923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {\n        'learning_rate': 0.07853392035787837,\n        'reg_lambda': 1.7549293092194938e-05,\n        'reg_alpha': 14.68267919457715, \n        'subsample': 0.8031450486786944, \n        'colsample_bytree': 0.170759104940733, \n        'max_depth': 3\n    }\n    \n    model = XGBRegressor(\n        random_state=fold,\n        n_jobs=4,\n        n_estimators=5000,tree_method='gpu_hist',\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_4\"]\nfinal_valid_predictions.to_csv(\"train_pred_4.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_4\"]\nsample_submission.to_csv(\"test_pred_4.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.594132Z","iopub.status.idle":"2021-08-25T15:13:06.594496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    lgbm_parameters_1 = {\n    'metric': 'RMSE',\n    'feature_pre_filter': False,\n    'reg_alpha': 0.4972562469417825, \n    'reg_lambda': 0.3273637203281044, \n    'num_leaves': 50, \n    'learning_rate': 0.032108486615557354,                      \n    'max_depth': 40,                     \n    'n_estimators': 4060, \n    'min_child_weight': 0.0173353329222102,\n    'subsample': 0.9493343850444064, \n    'colsample_bytree': 0.5328221263825876, \n    'min_child_samples': 80\n}\n    \n    model = LGBMRegressor(\n        random_state=fold,\n        n_jobs=4,\n        **lgbm_parameters_1,device= \"gpu\",\n        gpu_platform_id= 0,\n        gpu_device_id= 0\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_5\"]\nfinal_valid_predictions.to_csv(\"train_pred_5.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_5\"]\nsample_submission.to_csv(\"test_pred_5.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.595553Z","iopub.status.idle":"2021-08-25T15:13:06.59603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    xgb_params = {'objective': 'reg:squarederror',\n              'n_estimators': 10000,\n              'learning_rate': 0.25,\n              'subsample': 0.926,\n              'colsample_bytree': 0.84,\n              'grow_policy':'lossguide',\n              'max_depth': 2,\n              'booster': 'gbtree', \n              'reg_lambda': 45.1,\n              'reg_alpha': 34.9,\n              'random_state': 42,\n              'n_jobs': 4}\n\n    \n    model = XGBRegressor(\n        **xgb_params,tree_method='gpu_hist'\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_6\"]\nfinal_valid_predictions.to_csv(\"train_pred_6.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_6\"]\nsample_submission.to_csv(\"test_pred_6.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.596964Z","iopub.status.idle":"2021-08-25T15:13:06.597479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    xgb_params = {'max_depth': 1,\n                 'learning_rate': 0.8616220572782383,\n                 'n_estimators': 12900,\n                 'eta': 0.011828729736491916,\n                 'subsample': 0.9,\n                 'colsample_bytree': 0.7,\n                 'colsample_bylevel': 0.30000000000000004,\n                 'min_child_weight': 1.5207698213399512,\n                 'reg_lambda': 0.0005791179588496165,\n                 'reg_alpha': 0.17560065566511068,\n                 'gamma': 0.1553307899331432,'n_jobs':4}\n\n    \n    model = XGBRegressor(\n        random_state=fold,tree_method='gpu_hist',\n        **xgb_params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_7\"]\nfinal_valid_predictions.to_csv(\"train_pred_7.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_7\"]\nsample_submission.to_csv(\"test_pred_7.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.598493Z","iopub.status.idle":"2021-08-25T15:13:06.599068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    param = {\n        \"objective\": \"regression\",\n        \"metric\": \"rmse\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"n_estimators\": 10000,\n        \"early_stopping_round\": 300,\n        \"device\": \"gpu\",\n        \"gpu_platform_id\": 0,\n        \"gpu_device_id\": 0,\n    }\n    \n    param2 = {\n        'lambda_l1': 0.00472279780583036, \n        'lambda_l2': 2.9095205689488508e-05, \n        'num_leaves': 158, \n        'feature_fraction': 0.7386878356648194, \n        'bagging_fraction': 0.8459744550725283, \n        'bagging_freq': 2, \n        'max_depth': 2, \n        'max_bin': 249, \n        'learning_rate': 0.044738463593017294,\n        'min_child_samples': 13\n    }\n    param.update(param2)\n    \n    model = LGBMRegressor(\n        random_state=fold,\n        **param\n    )\n    model.fit(xtrain, ytrain, eval_set=[(xvalid, yvalid)])\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_8\"]\nfinal_valid_predictions.to_csv(\"train_pred_8.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_8\"]\nsample_submission.to_csv(\"test_pred_8.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.60033Z","iopub.status.idle":"2021-08-25T15:13:06.600899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\ndf1 = pd.read_csv(\"train_pred_1.csv\")\ndf2 = pd.read_csv(\"train_pred_2.csv\")\ndf3 = pd.read_csv(\"train_pred_3.csv\")\ndf4 = pd.read_csv(\"train_pred_4.csv\")\ndf5 = pd.read_csv(\"train_pred_5.csv\")\ndf6 = pd.read_csv(\"train_pred_6.csv\")\ndf7 = pd.read_csv(\"train_pred_7.csv\")\ndf8 = pd.read_csv(\"train_pred_8.csv\")\n\ndf_test1 = pd.read_csv(\"test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"test_pred_3.csv\")\ndf_test4 = pd.read_csv(\"test_pred_4.csv\")\ndf_test5 = pd.read_csv(\"test_pred_5.csv\")\ndf_test6 = pd.read_csv(\"test_pred_6.csv\")\ndf_test7 = pd.read_csv(\"test_pred_7.csv\")\ndf_test8 = pd.read_csv(\"test_pred_8.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\ndf = df.merge(df4, on=\"id\", how=\"left\")\ndf = df.merge(df5, on=\"id\", how=\"left\")\ndf = df.merge(df6, on=\"id\", how=\"left\")\ndf = df.merge(df7, on=\"id\", how=\"left\")\ndf = df.merge(df8, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test5, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test6, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test7, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test8, on=\"id\", how=\"left\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.602064Z","iopub.status.idle":"2021-08-25T15:13:06.602605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [\"pred_1\", \"pred_2\",'pred_3','pred_4','pred_5','pred_6','pred_7','pred_8']\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = LinearRegression()\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.603751Z","iopub.status.idle":"2021-08-25T15:13:06.604302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T15:13:06.605443Z","iopub.status.idle":"2021-08-25T15:13:06.606028Z"},"trusted":true},"execution_count":null,"outputs":[]}]}