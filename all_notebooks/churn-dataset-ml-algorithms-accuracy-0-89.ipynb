{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CHURN VERİ SETİ MAKİNE ÖĞRENMESİ ALGORİTMALARI UYGULAMALARI","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gerekli kütüphaneleri import ettim.\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\n\n\nfrom collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# veriyi import ettim\nchurn = pd.read_csv(\"../input/churn-predictions-personal/Churn_Predictions.csv\")\ndf=churn.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA UNDERSTANDING\n\n#### Churn veri seti için ayrıntılı \"data understanding\" bölümü için şu notebook'a bakabilirsiniz:\n#### https://www.kaggle.com/nguncedasci/churn-data-understanding\n#### Data Preprocessing bölümünde oluşturulan değişkenlerin çoğu, yukarıda belirtilen notebooktaki incelemelere göre yapılmıştır.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Row number değişkenini attım, indexi yeniden düzenledim.\ndf=df.drop(\"RowNumber\", axis=1)\ndf=df.reset_index(drop=True)\n\n# Gender ve Geography kategorik değişkenlerine one hot encoding uyguladım.\ndf=pd.get_dummies(df,columns=[\"Geography\",\"Gender\"], drop_first=True)\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPROCESSING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.copy()\n\n# Age değişkeninde 18-30=1 , 30-40=2 ,40-50=3, 50-60=4, 60-92=5 olarak atadım\ndf1.loc[(df1[\"Age\"]>=18) & (df1[\"Age\"]<=30), \"Age\"]=1\ndf1.loc[(df1[\"Age\"]>30) & (df1[\"Age\"]<=40), \"Age\"]=2\ndf1.loc[(df1[\"Age\"]>40) & (df1[\"Age\"]<=50), \"Age\"]=3\ndf1.loc[(df1[\"Age\"]>50) & (df1[\"Age\"]<=60), \"Age\"]=4\ndf1.loc[(df1[\"Age\"]>60) & (df1[\"Age\"]<=92), \"Age\"]=5\n\n\n\n#kredi_skor_tablosu\ndef kredi_skor_tablosu(row):\n    \n    kredi_skoru = row.CreditScore\n    if kredi_skoru >= 300 and kredi_skoru < 500:\n        return (2)\n    elif kredi_skoru >= 500 and kredi_skoru < 601:\n        return (3)\n    elif kredi_skoru >= 601 and kredi_skoru < 661:\n        return (4)\n    elif kredi_skoru >= 661 and kredi_skoru < 781:\n        return (5)\n    elif kredi_skoru >= 851:\n        return (7)\n    elif kredi_skoru >= 781 and kredi_skoru < 851:\n        return (6)\n    elif kredi_skoru < 300:\n        return (1)\n    \ndf1 = df1.assign(credit_score_table=df1.apply(lambda x: kredi_skor_tablosu(x), axis=1))\n\n\n\n# emeklilik ile ilgili yeni bir değişken oluşturdum.( Alm, İsp =65 , İtalya=66)\n# retired\ndf1[\"retired\"]=df[\"Age\"]\n\ndf1.loc[(df1[\"retired\"]>=65) & (df1[\"Geography_Germany\"]==1), \"retired\"]=1\ndf1.loc[(df1[\"retired\"]>=65) & (df1[\"Geography_Spain\"]==1), \"retired\"]=1\ndf1.loc[(df1[\"retired\"]>=66) & (df[\"Geography_Spain\"]==0) & (df[\"Geography_Germany\"]==0), \"retired\"]=1\n\n\ndf1.loc[(df1[\"retired\"]<65) & (df1[\"Geography_Germany\"]==1), \"retired\"]=0\ndf1.loc[(df1[\"retired\"]<65) & (df1[\"Geography_Spain\"]==1), \"retired\"]=0\ndf1.loc[(df1[\"retired\"]<66) & (df[\"Geography_Spain\"]==0) & (df[\"Geography_Germany\"]==0), \"retired\"]=0\n\n\n# Tenure/NumOfProducts\ndf1[\"Tenure/NumOfProducts\"]=df1[\"Tenure\"]/df1[\"NumOfProducts\"]\n\n\n# 405 değerinin altındakilerin hepsi churn olmuş(20 değer), outlier gibi kenarda kalmışlar atmadım yeni değişken oluşturdum\n#smallerthan405\ndf1[\"smallerthan405\"]=df[\"CreditScore\"]\n\ndf1.loc[(df1[\"smallerthan405\"]<405), \"smallerthan405\"]=1\ndf1.loc[(df1[\"smallerthan405\"]>405), \"smallerthan405\"]=0\n\n\n# NOP* isminde değişken oluşturdum. Bu değişkeni, number of products'ın her bir ürün bazındaki exit durumuna göre sıraladım.\n# Mevcut number of products'ı incelediğimde: NOP=1,mean=0.27    NOP=2,mean=0.07    NOP=3,mean=0.82    NOP=4,mean=1\ndf1[\"NOP*\"]=df[\"NumOfProducts\"]\ndf1.loc[(df1[\"NOP*\"]==2), \"NOP*\"]=1\ndf1.loc[(df1[\"NOP*\"]==1), \"NOP*\"]=2\ndf1.loc[(df1[\"NOP*\"]>2), \"NOP*\"]=3\n\n#Balance'ı 0 olanların hiç exit olmadığını gözlemledim. Bu nedenle yeni değişken ile Balance'ı 0 ve 0 olmayanlar şeklinde ayırdım.\n#Balance0\ndf1[\"Balance0\"]=df1[\"Balance\"]\ndf1.loc[(df1[\"Balance0\"]==0), \"Balance0\"]=0\ndf1.loc[(df1[\"Balance0\"]!=0), \"Balance0\"]=1\n\n\n# Tahmin edilen maaşın yaşla oranı olabilir diye düşündüm.18 yaşına kadar para kazanmamışlardır dedim.\n# Fakat veri setinde en küçük yaş 18 olduğu için Age-17'ye böldüm.\n# Estimated Salary/Age\ndf1[\"ES/Age\"]=df1[\"EstimatedSalary\"]/(df[\"Age\"]-17)\n\n\n# Tenure/Age\ndf1[\"Tenure/Age\"]=df1[\"Tenure\"] / (df[\"Age\"]-17)\n\n# Balance/ ES\ndf1[\"Balance/ES\"]=df1[\"Balance\"] / df1[\"EstimatedSalary\"]\n\n#Tahmin edilen maaşı aylığa dönüştürdüm. Amacım vergileri de çıkarıp aylık yalın maaş bulmaktı ancak maaş vergileri için \n#net rakamlar yerine aralıklar bulduğum için uygulamaya geçiremedim.\n#Estimated Salary (monthly)\ndf1[\"EstimatedSalary\"]=df1[\"EstimatedSalary\"]/12\n\n# Tenure'de 0 olan değerler vardı, bu nedenle inf gelmemesi için 1 eklenmiş haline böldüm.\n# ES/Tenure \ndf1[\"ES/Tenure\"]=df1[\"EstimatedSalary\"]/(df1[\"Tenure\"]+1)\n\n# ES/Score\ndf1[\"ES/Score\"]=df1[\"EstimatedSalary\"]/df1[\"credit_score_table\"]     \n\n# DROP FEATURE \n#Kredi skor sıralamasını anlatan bir değişken oluşturduğum için asıl değişkeni veri setinden çıkardım.\ndf1=df1.drop([\"CreditScore\"], axis=1)\ndf1=df1.drop([\"Tenure\"], axis=1)\ndf1=df1.drop([\"Balance\"], axis=1)\ndf1.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Robust Scaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Robust Scaler uygulayacağım değişkenleri seçtim.\ndf1_num=df1[[\"Age\",\"NumOfProducts\",\"EstimatedSalary\", \n             \"credit_score_table\",\"Tenure/NumOfProducts\",\"NOP*\",\"ES/Age\",\n             \"Tenure/Age\",\"Balance/ES\",\"ES/Tenure\",\"ES/Score\"]]\n\n# Scaling işlemini uyguladığım veri setine x_transformed adını verdim.\ncol=df1_num.columns\nx_transformed=pd.DataFrame(RobustScaler().fit(df1_num).transform(df1_num), columns=col)\nx_transformed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale işlemini yaptığım ve yapmadığım değişkenlerle -churn veri setindeki değişken sırasını da dikkate alarak-\n# yeni bir dataframe oluşturdum. Exited isimli y değişkenini ise koymadım. Böylelikle bağımsız değişkenleri bir\n# dataframede toplamış oldum. X ismini koydum.\nX=pd.concat([x_transformed.loc[:,\"Age\":\"NumOfProducts\"],df1.loc[:,\"HasCrCard\":\"IsActiveMember\"],\n             x_transformed.loc[:,\"EstimatedSalary\"], df1.loc[:,\"Geography_Germany\":\"Gender_Male\"],\n             x_transformed.loc[:, \"credit_score_table\"], df1.loc[:,\"retired\"],\n             x_transformed.loc[:,\"Tenure/NumOfProducts\"],df1.loc[:,\"smallerthan405\"],\n             x_transformed.loc[:,\"NOP*\"],df1.loc[:,\"Balance0\"],\n             x_transformed.loc[:, \"ES/Age\":\"ES/Score\"]], axis=1)\nX.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# X' daha önceden tanımlamıştım, şimdi ise y'yi tanımladım. \ny=df1[\"Exited\"]\n\n#split işlemi\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=12345)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf model kurulumu\nrf_model = RandomForestClassifier().fit(X_train,y_train)\ny_pred = rf_model.predict(X_test)\n\n# validasyon hatası, accuracy skoru, confusion matrix\ncv_results = cross_val_score(rf_model, X_train, y_train, cv = 10, scoring= \"accuracy\")\n\nprint(cv_results.mean())\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance'a baktım. Retired önemsiz görünüyor, çıkararak tekrar hataları ölçtüm, \n#değişen bir şey olmadı. Diğer modellerde önemli olabilir diye bıraktım.\n\nimportance=rf_model.feature_importances_\nplt.figure(figsize=(8,8))\nplt.barh(X.columns,importance)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# gbm model kurulumu\ngbm_model=GradientBoostingClassifier().fit(X_train,y_train)\ny_pred = gbm_model.predict(X_test)\n\n# validasyon hatası, accuracy skoru, confusion matrix\ncv_results = cross_val_score(gbm_model, X_train, y_train, cv = 10, scoring= \"accuracy\")\n\nprint(cv_results.mean())\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbm model kurulumu\nlgbm_model=LGBMClassifier().fit(X_train,y_train)\ny_pred = lgbm_model.predict(X_test)\n\n# validasyon hatası, accuracy skoru, confusion matrix\ncv_results = cross_val_score(lgbm_model, X_train, y_train, cv = 10, scoring= \"accuracy\")\n\nprint(cv_results.mean())\nprint(accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# MODEL TUNING\n#### Denemeler yaptım. Yukarıda en iyi sonuç aldığım LGBM modeli için hiperparametrelerle oynadım ancak default değerlerinden daha iyi bir model oluşturamadım.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# DENGESİZ VERİ SETİ: SMOTE\n#### %20-80'lik veri seti için varolan dengesizliği oversamling yöntemi ile giderdim.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"smt = SMOTE(random_state=12345)\nX_res, y_res = smt.fit_sample(X, y)\n\nprint('Resampled dataset shape {}'.format(Counter(y_res)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#split işlemi\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, \n                                                    test_size=0.20, \n                                                    random_state=12345)\n\n# lgbm model kurulumu\nlgbm_model=LGBMClassifier(random_state=12345).fit(X_train,y_train)\ny_pred = lgbm_model.predict(X_test)\n\n# validasyon hatası, accuracy skoru, confusion matrix\ncv_results = cross_val_score(lgbm_model, X_train,y_train, cv = 10, scoring= \"accuracy\")\n\nprint(\"cross_val_score(train):\", cv_results.mean())\n\ncv_results = cross_val_score(lgbm_model, X_test,y_test, cv = 10, scoring= \"accuracy\")\nprint(\"cross_val_score(test):\", cv_results.mean())\n\n\ny_train_pred = lgbm_model.predict(X_train)\nprint(\"accuracy_score(train):\",accuracy_score(y_train, y_train_pred))\nprint(\"accuracy_score(test):\",accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, y_pred)\nprint(cf_matrix)\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n            fmt='.2%', cmap='Blues');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REPORT","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Doğru tahmin edilenler --> %89.42 (3186 tahminden 2849 tanesi doğru)\n* #### True Negative --> %44.54 --> Churn olmayacağı tahmin edilmiş ve churn olmamış.\n* #### True Positive --> %44.88 --> Churn olacağı tahmin edilmiş ve churn olmuş.\n\n### Yanlış tahmin edilenler -->  %10.58 (3186 tahminden 337 tanesi yanlış)\n* #### False Positive --> %4.02 --> Churn olacağı tahmin edilmemiş ama churn olmamış.\n* #### False Negative --> %6.56 --> Churn olmayacağı tahmin edilmiş ama churn olmuş.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Churn olmayanlar:\n* 1547--> 0 (Gerçekte test veri setinde),\n* 1628-->0 (Test veri seti için tahmin edilen)\n\n\n#### Churn olanlar:\n* 1639--> 1 (Gerçekte test veri setinde),\n* 1558-->1 (Test veri seti için tahmin edilen)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}