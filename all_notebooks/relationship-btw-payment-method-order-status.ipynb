{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the csv file\ndata = pd.read_csv('/kaggle/input/pakistans-largest-ecommerce-dataset/Pakistan Largest Ecommerce Dataset.csv')\ndf = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Data Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing / NaN values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Doing a visual inspection of all columns\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- Out of 26 columns, last 5 columns in the dataset contain NaN values for all records\n- Records at 464051 indices (from the bottom) contain NaN values for all columns\n- ' MV ' is an ambiguous column name with extra spaces\n- Some of the columns have incorrect data types\n\n##### Actions\n- Last 5 columns need to be dropped from the dataset\n- 464051 rows, containing NaN values need to be dropped from the dataset\n- Renamed the columns ' MV ' and 'category_name_1' to 'MV' and 'category_name'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"Unnamed: 21\", \"Unnamed: 22\", \"Unnamed: 23\", \"Unnamed: 24\", \"Unnamed: 25\"], axis = 1, inplace=True)\ndf.dropna(subset=[\"item_id\"], axis=0, inplace=True)\ndf.rename(columns={\" MV \": \"MV\", \"category_name_1\": \"category_name\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Dropping duplicate entries, if any, from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Basic data quality and integrity checks"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of rows with negative or zero Quantity:\",sum(n <= 0 for n in df.qty_ordered))\nprint(\"The number of rows with negative Price:\",sum(n < 0 for n in df.price))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Convert all values in 'sku' column to upper case for uniformity"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sku']=df['sku'].str.upper()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exploring all columns, finding and Imputing Null Values\n#### Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- There are a lot of labels for 'status' column.\n- Need to check if any relationship exists between 'status' and 'BI Status' columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('BI Status')['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- All transactions marked as either **'complete' or 'closed'**, fall in the **'Net' category** for 'BI Status'\n- All transactions marked as **'received','paid','cod','exchanged' or something related to refund** are marked in **'Valid' category**\n- All transactions marked as **either 'canceled' or something to do with incomplete transation** are marked in **'Gross' category**\n- '#REF!' looks an erroneus label.\n\n##### Actions\n**Replace values inside the 'status' column by creating new labels**\n\n- **'complete','closed','received','paid','cod'** will belong to category **'Completed'**\n- **'order_refunded','refund', 'exchange'** will belong to category **'Refund'**\n- **'pending','payment_review','processing','holded','pending_paypal','\\N'** will beling to **'Pending'**\n- **'canceled'** will belong to **'Cancelled'**\n- **'fraud'** will belong to **'Fraud'**\n**Also replace the '#REF!'' entry to 'Net' in 'BI status'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'] = df['status'].replace('complete', 'Completed')\ndf['status'] = df['status'].replace('closed', 'Completed')\ndf['status'] = df['status'].replace('received', 'Completed')\ndf['status'] = df['status'].replace('paid', 'Completed')\ndf['status'] = df['status'].replace('cod', 'Completed')\ndf['status'] = df['status'].replace('order_refunded', 'Refund')\ndf['status'] = df['status'].replace('refund', 'Refund')\ndf['status'] = df['status'].replace('exchange', 'Refund')\ndf['status'] = df['status'].replace('pending', 'Pending')\ndf['status'] = df['status'].replace('payment_review', 'Pending')\ndf['status'] = df['status'].replace('processing', 'Pending')\ndf['status'] = df['status'].replace('holded', 'Pending')\ndf['status'] = df['status'].replace('pending_paypal', 'Pending')\ndf['status'] = df['status'].replace(r'\\\\N', 'Pending', regex=True)\ndf['status'] = df['status'].replace('fraud', 'Fraud')\ndf['status'] = df['status'].replace('canceled', 'Cancelled')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BI Status'] = df['BI Status'].replace('#REF!', 'Net')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BI Status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Handling Null values in 'status' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['status'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observation\n- 15 NaN values in 'status' column have 'Gross' in the BI column meaning all these transactions are not valid\n\n##### Actions\n- Replacing NaN values with label **'Cancelled'** in line with our understanding of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['status'].fillna(\"Cancelled\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling NaN values in 'category_name' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- There are 164 NaN values in the **'category_name'** column that can be filled using some information from **'sku'** column. Not doing it right now\n- 7850 transactions have a unicode label associated with them.\n- 164 transactions have NaN values.\n\n##### Actions\n- Replacing the unicode label and NaN values with label 'Unknown'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['category_name'] = df['category_name'].replace(r'\\\\N', 'Unknown', regex=True)\ndf['category_name'].fillna(\"Unknown\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling NaN values in 'sku' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['sku'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Obsevations\n- 20 NaN values for **'sku'** exist in the dataset and these values can be replaced.\n\n##### Action\n- Replace NaN values with a new sku code **'Missing'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sku'].fillna(\"Missing\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling missing values in 'Sales_commission_code' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sales_commission_code'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['sales_commission_code'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- The column has a large number of NaN values and there are more than 7000 types of values in this column\n- The column does not seem to add any value for further analysis and can be dropped at a later stage\n- At this stage, NaN values as well as unicode labels can be replaced with 'Missing'\n\n##### Actions\n- Replacing NaN and unicode values with **'Missing'**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sales_commission_code'].fillna(\"Missing\",inplace=True)\ndf['sales_commission_code'] = df['sales_commission_code'].replace(r'\\\\N', 'Missing', regex=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling missing values in 'Customer ID' and 'Customer Since' columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Customer ID'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- There are a total of 11 rows where the 'Customer ID' column is NaN and exactly the same rows in 'Customer since' are also NaN, which makes sense and shows that these columns have a relationship.\n- All 11 records are from FY18, with the first record from 01-2018.\n- For keeping the records in dataset for analysis, a fake 'Customer ID' value of '0' can be assigned with '01-2018' assigned to all records in 'Customer Since' column\n\n##### Actions\n- Replaced 'Customer ID' with value **'0'** and 'Customer Since' with value **'01-2018'** for all NaN values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Customer ID'].fillna(\"0\",inplace=True)\ndf['Customer Since'].fillna(\"1-2018\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking for Null values again and setting appropriate datatypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Convert the datatypes of columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[\"item_id\"]] = df[[\"item_id\"]].astype(\"str\")\ndf[[\"Month\"]] = df[[\"Month\"]].astype(\"int\")\ndf[[\"Year\"]] = df[[\"Year\"]].astype(\"int\")\ndf[[\"qty_ordered\"]] = df[[\"qty_ordered\"]].astype(\"int\")\ndf[[\"Customer ID\"]] = df[[\"Customer ID\"]].astype(\"str\")\ndf[[\"increment_id\"]] = df[[\"increment_id\"]].astype(\"str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Is there a relationship between Payment method and Order Status?"},{"metadata":{},"cell_type":"markdown","source":"##### We can explore the relationship between payment method and order status through the fol. steps\n\n1. Examining both column labels\n2. See yearly trends in Transactions and Sales by Payment Method\n3. See yearly trends in Transactions and Sales by Order Status\n4. Examined the combined effect of both on Transactions and Sales with and without the time dimension\n5. Make a conclusion based on our observations from the trends"},{"metadata":{},"cell_type":"markdown","source":"##### Examine both column labels\nWe have already explored and modified the column labels for 'order_status' during pre-processing. Let's examine the **'payment_method'** column labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['payment_method'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- **'Easypay'** and **'Easypay_MA'** can be combined under the label **'Easypay'**\n- **'cod'** and **'cashatdoorstep'** can be combined under 'cod'\n- **'marketingexpense'** and **'financesettlement'** having very low transactions can be combined under **'Others'**\n\n##### Actions\n- Combine 'Easypay' and 'Easypay_MA'\n- Combine 'cod' and 'cashatdoorstep'\n- Combine 'marketingexpense' and 'financesettlement' under 'Others'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['payment_method'] = df['payment_method'].replace('Easypay_MA', 'Easypay')\ndf['payment_method'] = df['payment_method'].replace('cashatdoorstep', 'cod')\ndf['payment_method'] = df['payment_method'].replace('marketingexpense', 'Others')\ndf['payment_method'] = df['payment_method'].replace('financesettlement', 'Others')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['payment_method'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Examine yearly trends in Transactions and Sales by Payment Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\ndf1 = df.groupby(['FY','payment_method']).size().reset_index(name='count')\ndf2 = df.groupby(['FY','payment_method'])['grand_total'].sum().reset_index(name='sum')\ntemp = pd.concat([df1, df2['sum']], axis=1)\nfig = px.bar(temp, x=\"FY\", y=\"count\", color=\"payment_method\", title=\"Yearly Transactions by Payment method\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"FY\", y=\"sum\", color=\"payment_method\", title=\"Yearly Potential Revenue by Payment method\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n\n**Transactions**\n- **'cod' is the dominant method** for order placement over both FY17 and FY18\n- **Payaxis** had a higher share for FY17 which has decreased in FY18\n- **New digital or e-payment** methods like **Easypay, Easypay_voucher and bank alfalah** have started getting traction in FY18\n\n**Total Sales**\n- **Potential Revenue** has almost **doubled in FY18 as compared to FY17** due to new digital / e-payment methods.\n\n##### Actions\n- See the combined effect of Payment method with Order Status"},{"metadata":{},"cell_type":"markdown","source":"#### Examine yearly trends in Transactions and Sales by Order Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.groupby(['FY','status']).size().reset_index(name='count')\ndf2 = df.groupby(['FY','status'])['grand_total'].sum().reset_index(name='sum')\ntemp = pd.concat([df1, df2['sum']], axis=1)\ntemp['Sales per Transaction'] = temp['sum'] / temp['count']\nfig = px.bar(temp, x=\"FY\", y=\"count\", color=\"status\", title=\"Yearly Transactions by Order Status\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"FY\", y=\"sum\", color=\"status\", title=\"Yearly Potential Revenue by Order Status\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"FY\", y=\"Sales per Transaction\", color=\"status\", title=\"Yearly Sale per Transactions by Order Status\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- Trend for transactions and revenue is the same for both FY17 and FY18, but increase in revenue through **completed orders has almost doubled**, as seen from **Sales per transaction metric.**\n- However, **revenue lost has also increased** from FY17 to FY18 (12k to 14.6K) per transaction, which is a worrying metric for the business.\n- Trend for **Refund** is almost the same over both years.\n\n##### Actions\n- Examine the combined affect of order status and payment method on transaction/ order qty and Sales\n- Examine 'Completed','Cancelled' and 'Refund' transactions for payment method over time to get any insights"},{"metadata":{},"cell_type":"markdown","source":"#### Relationship between Payment method and Order Status Frequency"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf1 = df.groupby(['payment_method','status'])['qty_ordered'].sum().reset_index(name='count')\nfig = px.bar(df1, x=\"payment_method\", y=\"count\", color=\"status\", title=\"Qty Ordered by Payment method\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- **Highest ordered qty** happened through **cod** \n- **Majority of Completed transactions** are also happening through **cod**\n- Overall most ordered qty **(more than 50%)** through **Payaxis, jazzwallet, Easypay, Easypay_MA and bankalfalah** are getting cancelled\n- Most 'Refund' ordered qty taking place for 'cod'\n\n##### Actions\n- Is there a similar trend for Revenue as well because businesses are more interested in revenue than both number of transactions and ordered qty?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.groupby(['payment_method','status'])['grand_total'].sum().reset_index(name='sum')\nfig = px.bar(df1, x=\"payment_method\", y=\"sum\", color=\"status\", title=\"Total Sales by Payment method\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### Observations\n- Unlike, the qty ordered, **cod is not the highest contributor** towards potential revenue, it is **payaxis**\n- For **completed** orders, overall **cod** still has a major share, with **easypay_voucher** the 2nd biggest contrbutor.  \n- For **cancelled** orders, **Payaxis, Easypay and bankalfalah** have a much higher contribution than the rest which clearly shows that these technologies have **technology integration issues** on the E-commerce store website.\n- Bulk of the **Refunds** are happening through **cod** payment method\n- **Cash payments (cod) and voucher based payment methods (easypay_voucher and jazzvoucher)** make up majority of the revenue generated through **Completed transactions** and the rest of the technologies have a major share towards **revenue loss via Cancelled transactions**\n\n#### Actions\n- Check the yearly trend for payment methods vs order status and compare it with the overall trend. It is better to split the dataset for Completed, Cancelled and Refunds and see if there is any trend"},{"metadata":{},"cell_type":"markdown","source":"#### Yearly Sales for Completed Orders by Payment method"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.loc[df['status']=='Completed',['FY','payment_method','grand_total']]\ndf2 = df1.groupby(['FY','payment_method'])['grand_total'].sum().reset_index(name='sum')\ndf2['%'] = 100 * df2['sum'] / df2.groupby('FY')['sum'].transform('sum')\nfig = px.bar(df2, x=\"FY\", y=\"sum\", color=\"payment_method\", text=df2['%'].apply(lambda x: '{0:1.2f}%'.format(x)), title=\"Yearly Sales for Completed Orders\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- In FY17, **cod, payaxis and jazzvoucher** were responsible for almost **87% of generated revenue**. This combined contribution has **reduced to half (almost 42%)** in FY2018\n- **cod** share has almost reduced to half from FY17 to FY18. A 4% decrease also seen for payaxis\n- In FY18, almost **55% of Sales contribution** was coming from **Easypay, Easypay_voucher and Bank AlFalah combined**, which has significantly increased from FY17"},{"metadata":{},"cell_type":"markdown","source":"#### Yearly Revenue Lost through Cancelled Orders by Payment method"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.loc[df['status']=='Cancelled',['FY','payment_method','grand_total']]\ndf2 = df1.groupby(['FY','payment_method'])['grand_total'].sum().reset_index(name='sum')\ndf2['%'] = 100 * df2['sum'] / df2.groupby('FY')['sum'].transform('sum')\nfig = px.bar(df2, x=\"FY\", y=\"sum\", color=\"payment_method\", text=df2['%'].apply(lambda x: '{0:1.2f}%'.format(x)), title=\"Yearly Revenue Lost through Cancelled Orders\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- For both years, **cod share is less than 10% towards revenue losses**.\n- In both years, various **digital / e-payment methods** are contributing around **90% towards revenue losses from cancellations**\n- Revenue losses due to payaxis have **decrased from 49% to 20%** over FY17 to FY18.\n\n##### Actions\n- Examine the monthly trend of cancelled transactions and revenue loss for FY18"},{"metadata":{},"cell_type":"markdown","source":"#### Yearly Revenue Lost through Refund Orders by Payment method"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.loc[df['status']=='Refund',['FY','payment_method','grand_total']]\ndf2 = df1.groupby(['FY','payment_method'])['grand_total'].sum().reset_index(name='sum')\ndf2['%'] = 100 * df2['sum'] / df2.groupby('FY')['sum'].transform('sum')\nfig = px.bar(df2, x=\"FY\", y=\"sum\", color=\"payment_method\", text=df2['%'].apply(lambda x: '{0:1.2f}%'.format(x)), title=\"Yearly Revenue Lost through Refunded Orders\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observations\n- For both FY17 and FY18, Refunds are dominated by cod, however, there has been a decrease in the % age value but the amount is almost the same"},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n- E-commerce store users used **Cash and voucher based transactions** as the preferred method for FY17 and FY18 in terms of revenue generation through **Completed** transactions, but the **cod** payments %age saw a downward trend in FY18\n- **Digital or E-payment methods were mainly responsible for making the revenue earned in FY18 double than it was in FY17**. However, due to a large number of **cancelled** transactions associated with these methods, there is a **strong possibility that the web portal faced integration challenges and resulted in many cancelled transactions**\n- **Digital / E-payment have been a driver in revenue growth** but at the same time resulted in **more cancellations and potential revenue lost**."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}