{"metadata":{"language_info":{"version":"3.6.3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"_uuid":"5089dd8ce2ea3dfbec45f4cdf3a756b25833bd65","_cell_guid":"1cc78732-b0d5-4c62-b1c4-09e642a6506b"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport nltk\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nimport sklearn\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\n\n    "},{"metadata":{},"cell_type":"markdown","source":"**Reading the CSV into pythons arrays , articles and categories**"},{"metadata":{},"cell_type":"code","execution_count":null,"outputs":[],"source":"dosya= open(\"../input/7all.csv\")\nprint(\"Reading from file ...\")\ni=0\ncats=[]\narticles=[]\nvocab=[]\nfor line in dosya:\n i=i+1\n print (\"\\rComplete: \", i, \"%\", end=\"\")\n lines=line.split(\",\")\n cat=lines[0]\n cats.append(cat)\n article=lines[1].split()\n articles.append(article)\n vocab= vocab+ article\n"},{"metadata":{},"cell_type":"markdown","source":"*Find the ferquency of the words, articles number, *"},{"metadata":{},"cell_type":"code","execution_count":null,"outputs":[],"source":"fd=nltk.FreqDist(vocab)\nprint(\"Article Size \",len(articles))\nprint(\"initial vocab size \", len(vocab))\nvocab2=[k for k in fd.keys() if fd[k]>3]\n"},{"metadata":{},"cell_type":"markdown","source":"*Find the most common 2000 words used in the corpus and use them as dimension*"},{"metadata":{"collapsed":true},"cell_type":"code","execution_count":null,"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\nK=2000\nmc=fd.most_common(K) \nfreqK=[e[0] for e in mc]\nart2=[\" \".join([k for k in a if k in freqK ]) for a in articles]"},{"metadata":{},"cell_type":"markdown","source":"**Create X vector from documents***"},{"metadata":{},"cell_type":"code","execution_count":null,"outputs":[],"source":"vectorizer = CountVectorizer()\nX = vectorizer.fit_transform(art2)"},{"metadata":{},"cell_type":"markdown","source":"**Apply Machine Learning Algorithms**"},{"metadata":{},"cell_type":"code","execution_count":null,"outputs":[],"source":"data_labels=cats\n#models_name = [\"k-NN1\", \"k-NN2\", \"NB1\", \"LR-1\", \"LinearSVM\",  \"SGD\", \"DecisionTree\", \"RandomForest\", \"NeuralNet\"]\nmodels_name = [\"Multi NB\", \"LR\", \"LinearSVM\" ]\n\nmodels = [ MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), LogisticRegression(), LinearSVC()]\nprint(\"The number of Selected Feature (Frequency Based):\", K)\nfor j in range(len(models)):\n print(models_name[j]+ \" \")\n predicted = sklearn.model_selection.cross_val_predict(models[j], X, data_labels, cv=4)\n acc=sklearn.metrics.accuracy_score(data_labels, predicted)    \n print (\"Accuracy \", acc)\n print(\"***\")\n\n"}],"nbformat_minor":1,"nbformat":4}