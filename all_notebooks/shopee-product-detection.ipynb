{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm \nimport random, time, os\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom kaggle_datasets import KaggleDatasets\n\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading image\ndef load_img(pth, lab):\n    img = tf.io.read_file(pth)\n    img = tf.image.decode_png(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img.set_shape((299, 299, 3))\n    # img = tf.expand_dims(img, axis=0)\n    # Convert lab to uint8\n    lab = tf.cast(lab, tf.uint8)\n    # lab.set_shape(1)\n    return img, lab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(X, y):\n    global NUM_CLASS\n    y = tf.one_hot(y, NUM_CLASS)\n\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CutMix Augmentation\ndef CutMix(X, y_):\n    global CUTMIX_RATE, BATCH_SIZE\n    \n    _, W, H, _ = X.shape.as_list()\n    imgs, labs = [], []\n\n    for i in range(BATCH_SIZE):\n        k = np.random.randint(0, BATCH_SIZE)\n        \n        # Contructing the cutmix image\n        # =============================\n        # Img ith and kth\n        img_i = X[i,:,:,:]\n        img_k = X[k,:,:,:]\n\n        # Constructing bounding box for the mixed patch\n        w, h = int((1-CUTMIX_RATE)**.5 * W), int((1-CUTMIX_RATE)**.5 * H)\n        x, y = np.random.randint(0, W - w), np.random.randint(0, H - h)\n\n        # Mask \n        M = np.ones(img_i.shape)\n        M[x:x+w, y:y+h,:] = 0    \n        M_neg = 1 - M\n\n        M = tf.constant(M, dtype=tf.float32)\n        M_neg = tf.constant(M_neg, dtype=tf.float32)\n\n        img = tf.math.add(tf.math.multiply(M, img_i), tf.math.multiply(M_neg, img_k))\n        imgs.append(img)\n        \n        # Contructing the label\n        # ============================================\n        y_i = y_[i,:]\n        y_k = y_[k,:]\n\n        lab = CUTMIX_RATE * y_i + (1 - CUTMIX_RATE) * y_k\n        labs.append(lab)\n\n    imgs = tf.reshape(tf.stack(imgs), (BATCH_SIZE, W, H, 3))\n    labs = tf.reshape(tf.stack(labs), (BATCH_SIZE, NUM_CLASS))\n    return imgs, labs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def other_aug(X, y):\n    global MAX_DELTA_BRIGHT, LOWER_CONTRAST, UPPER_CONTRAST\n    X = tf.image.random_flip_left_right(X)\n    X = tf.image.random_brightness(X, max_delta=MAX_DELTA_BRIGHT)\n    X = tf.image.random_contrast(X, lower=LOWER_CONTRAST, upper=UPPER_CONTRAST)\n\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Augment_data(X, y):\n    X, y = CutMix(X, y)\n    X, y = other_aug(X, y)\n\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(valid_size = .1):\n    pad = lambda x: f\"0{x}\" if x < 10 else f\"{x}\"\n    \n    train = pd.read_csv(f\"{PTH}/train.csv\")\n    train_pth = train.apply(lambda x: f\"{GCS_PTH}/resized/train/{pad(x['category'])}/{x['filename']}\", axis=1)\n    train_lab = train[\"category\"]\n\n    test = pd.read_csv(f\"{PTH}/test.csv\")\n    test_pth = test.apply(lambda x: f\"{GCS_PTH}/resized/test/{x['filename']}\", axis=1)\n    test_lab = test[\"category\"].values\n\n    # Validation split:\n    train_pth , valid_pth, train_lab, valid_lab = train_test_split(train_pth, train_lab, test_size = valid_size)  \n    \n    # Returning TF's Dataset API\n    train = tf.data.Dataset.from_tensor_slices((train_pth, train_lab))\n    valid = tf.data.Dataset.from_tensor_slices((valid_pth, valid_lab))\n    test = tf.data.Dataset.from_tensor_slices((test_pth, test_lab))\n    \n    train = train.map(load_img, num_parallel_calls=AUTO)\\\n        .map(one_hot, num_parallel_calls=AUTO)\\\n        .batch(BATCH_SIZE)\\\n        .map(Augment_data, num_parallel_calls=AUTO)\\\n        .cache()\n    \n    valid = valid.map(load_img, num_parallel_calls=AUTO)\\\n        .map(one_hot, num_parallel_calls=AUTO)\n        # .batch(BATCH_SIZE)\n    \n    test = test.map(load_img, num_parallel_calls=AUTO)\\\n        .map(one_hot, num_parallel_calls=AUTO)\\\n        .batch(BATCH_SIZE)\n    \n    return train, valid, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Config TPU\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Efficient net preprocess input\nclass Preprocess(tf.keras.layers.Layer):\n    def __init__(self):\n        super(Preprocess, self).__init__()\n    \n    def call(self, X):\n        X = tf.keras.applications.efficientnet.preprocess_input(X)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    with strategy.scope():\n        # Load efficient net\n        Preprocess(),\n\n        base = tf.keras.applications.efficientnet.EfficientNetB7(\n            include_top = False,\n            weights=\"imagenet\",\n            pooling = None\n        )\n        \n        base.trainable=False\n\n        net = tf.keras.models.Sequential([\n            base,\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(42, activation=\"softmax\")\n        ])\n\n        net.compile(\n            optimizer = tf.keras.optimizers.SGD(learning_rate=.1),\n            loss = \"categorical_crossentropy\",\n            metrics = \"accuracy\"\n        )\n\n        return net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Callbacks\n# Reduce learning rate on plateau\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=2, verbose=1,\n    mode='auto', min_delta=0.0001, cooldown=0, min_lr=1e-5\n)\n\n# save checkspoint\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=\"/gdrive/MyDrive/dataset/checkpoint_tpu/efficient_netB7\",\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# configs\nPTH = \"/kaggle/input/shopee-code-league-2020-product-detection\"\nNUM_CLASS = 42\nCUTMIX_RATE = 0.66\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE\nMAX_DELTA_BRIGHT = .2\nLOWER_CONTRAST = .8\nUPPER_CONTRAST = 1.2\nGCS_PTH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = get_model()\ntrain, valid, test = get_dataset()\n\nhistory = net.fit(\n    train, \n    validation_data = valid,\n    callbacks=[reduce_lr],\n    epochs=5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}