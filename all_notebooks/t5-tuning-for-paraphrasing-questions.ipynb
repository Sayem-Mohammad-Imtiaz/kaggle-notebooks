{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this version of notebook, I've used the previously trained t5 model on a mixture of dataset and trained it on Quora dataset to enable multitasking i.e. Question generation as well as paraphrasing. Prefix has been drastically changed here.\n\nLet the code speak!!","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the code for tuning is adapted from my friend and colleague Parth Chokhra's [T5 tutorial notebook](https://www.kaggle.com/parthplc/t5-fine-tuning-tutorial). I've used his work for training the T5 with Quora questions dataset for paraphrasing by doing some tweakes and modifications in the dataset.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import glob\nimport os\nimport json\nimport time\nimport logging\nimport random\nimport re\nfrom itertools import chain\nfrom string import punctuation\n\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorch_lightning==0.8.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pytorch_lightning as pl\npl.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import (\n    AdamW,\n    T5ForConditionalGeneration,\n    T5Tokenizer,\n    get_linear_schedule_with_warmup\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/first-quora-dataset/q_quora.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1= train.loc[train['is_duplicate']=='1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1=train1.drop(['id','qid1', 'qid2','is_duplicate',\n       'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10',\n       'Unnamed: 11', 'Unnamed: 12'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1=train1.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1.columns= ['question', 'target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1= train1.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2= train1[:90000]\nval= train1[90000:110000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class T5FineTuner(pl.LightningModule):\n    def __init__(self, hparams):\n        super(T5FineTuner, self).__init__()\n        self.hparams = hparams\n\n        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n\n    def is_logger(self):\n        return True\n\n    def forward(\n            self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n    ):\n        return self.model(\n            input_ids,\n            attention_mask=attention_mask,\n            decoder_input_ids=decoder_input_ids,\n            decoder_attention_mask=decoder_attention_mask,\n            lm_labels=lm_labels,\n        )\n\n    def _step(self, batch):\n        lm_labels = batch[\"target_ids\"]\n        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n\n        outputs = self(\n            input_ids=batch[\"source_ids\"],\n            attention_mask=batch[\"source_mask\"],\n            lm_labels=lm_labels,\n            decoder_attention_mask=batch['target_mask']\n        )\n\n        loss = outputs[0]\n\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        loss = self._step(batch)\n\n        tensorboard_logs = {\"train_loss\": loss}\n        return {\"loss\": loss, \"log\": tensorboard_logs}\n\n    def training_epoch_end(self, outputs):\n        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n\n    def validation_step(self, batch, batch_idx):\n        loss = self._step(batch)\n        return {\"val_loss\": loss}\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n        tensorboard_logs = {\"val_loss\": avg_loss}\n        return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n\n    def configure_optimizers(self):\n        \"Prepare optimizer and schedule (linear warmup and decay)\"\n\n        model = self.model\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n        optimizer_grouped_parameters = [\n            {\n                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n                \"weight_decay\": self.hparams.weight_decay,\n            },\n            {\n                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n        self.opt = optimizer\n        return [optimizer]\n\n    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n        if self.trainer.use_tpu:\n            xm.optimizer_step(optimizer)\n        else:\n            optimizer.step()\n        optimizer.zero_grad()\n        self.lr_scheduler.step()\n\n    def get_tqdm_dict(self):\n        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n\n        return tqdm_dict\n\n    def train_dataloader(self):\n        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,\n                                num_workers=4)\n        t_total = (\n                (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n                // self.hparams.gradient_accumulation_steps\n                * float(self.hparams.num_train_epochs)\n        )\n        scheduler = get_linear_schedule_with_warmup(\n            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n        )\n        self.lr_scheduler = scheduler\n        return dataloader\n\n    def val_dataloader(self):\n        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"valid\", args=self.hparams)\n        return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\nclass LoggingCallback(pl.Callback):\n        def on_validation_end(self, trainer, pl_module):\n            logger.info(\"***** Validation results *****\")\n            if pl_module.is_logger():\n                  metrics = trainer.callback_metrics\n                  # Log results\n                  for key in sorted(metrics):\n                    if key not in [\"log\", \"progress_bar\"]:\n                      logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n\n        def on_test_end(self, trainer, pl_module):\n            logger.info(\"***** Test results *****\")\n\n            if pl_module.is_logger():\n                metrics = trainer.callback_metrics\n\n                  # Log and save results to file\n                output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n                with open(output_test_results_file, \"w\") as writer:\n                    for key in sorted(metrics):\n                          if key not in [\"log\", \"progress_bar\"]:\n                            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n                            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args_dict = dict(\n    data_dir=\"\", # path for data files\n    output_dir=\"\", # path to save the checkpoints\n    model_name_or_path='ramsrigouthamg/t5_squad_v1',\n    tokenizer_name_or_path='t5-base',\n    max_seq_length=512,\n    learning_rate=3e-4,\n    weight_decay=0.0,\n    adam_epsilon=1e-8,\n    warmup_steps=0,\n    train_batch_size=32,\n    eval_batch_size=32,\n    num_train_epochs=2,\n    gradient_accumulation_steps=32,\n    n_gpu=1,\n    early_stop_callback=False,\n    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n    seed=42,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GrammerDataset(Dataset):\n    def __init__(self, tokenizer, data_dir, type_path, max_len=256):\n        self.path = os.path.join(data_dir, type_path + '.csv')\n\n        self.question = \"question\"\n#         self.true_false = \"answer\"\n        self.target_column = \"target\"\n#         self.incorrect_max = \"mix_in_correct\"\n        self.data = pd.read_csv(self.path)\n\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.inputs = []\n        self.targets = []\n\n        self._build()\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, index):\n        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n        target_ids = self.targets[index][\"input_ids\"].squeeze()\n\n        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n\n        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n\n    def _build(self):\n        for idx in range(len(self.data)):\n            target,question= self.data.loc[idx, self.target_column], self.data.loc[idx, self.question]\n            #, self.data.loc[idx, self.incorrect_max]\n#             true_false = str(true_false)\n#             if true_false.lower() ==\"true\":\n#                 true_false =\"yes\"\n#             else:\n#                 true_false = \"no\"\n#             input_ = \": \"+ input_ + ' </s>'\n            input_ = \"ParaphraseQuestion: %s </s>\" % (question)\n            target = \"ParaphrasedTarget: %s </s>\" %(target)\n\n            # tokenize inputs\n            tokenized_inputs = self.tokenizer.batch_encode_plus(\n                [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n            )\n            # tokenize targets\n            tokenized_targets = self.tokenizer.batch_encode_plus(\n                [target], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n            )\n\n            self.inputs.append(tokenized_inputs)\n            self.targets.append(tokenized_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2.to_csv('train.csv', index=False)\nval.to_csv('valid.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained('t5-base')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args_dict.update({'data_dir': '/kaggle/working', 'output_dir': '/kaggle/working/output/result', 'num_train_epochs':1,'max_seq_length':50})\nargs = argparse.Namespace(**args_dict)\nprint(args_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    \n    period =1,filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=1\n)\n\ntrain_params = dict(\n    accumulate_grad_batches=args.gradient_accumulation_steps,\n    gpus=args.n_gpu,\n    max_epochs=args.num_train_epochs,\n    early_stop_callback=False,\n    precision= 16 if args.fp_16 else 32,\n    amp_level=args.opt_level,\n    gradient_clip_val=args.max_grad_norm,\n    checkpoint_callback=checkpoint_callback,\n    callbacks=[LoggingCallback()],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(tokenizer, type_path, args):\n    return GrammerDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Initialize model\")\nmodel = T5FineTuner(args)\n\ntrainer = pl.Trainer(**train_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\" Training model\")\ntrainer.fit(model)\n\nprint (\"training finished\")\n\nprint (\"Saving model\")\nmodel.model.save_pretrained(\"/kaggle/working/result\")\n\nprint (\"Saved model\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}