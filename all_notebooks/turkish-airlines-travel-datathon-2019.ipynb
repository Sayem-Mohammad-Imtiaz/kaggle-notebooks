{"cells":[{"metadata":{"id":"d6umBn88WlMy"},"cell_type":"markdown","source":"#THY Travel Datathon Preselection Case Study\n\nby Duygu Can, Meriç Pakkan, Neslihan Oflaz, Ahad Khaleghi Ardabili, Akın Erdem\n\n\nFlying passengers can check-in through the web site, applications, kiosks and counters. In this case study content, the train data including the number of seven-month passenger check-in operations is provided. We want you to estimate the number of channels (column Operation_Count) in the csv file attached."},{"metadata":{"id":"0kLlbk20ZyIq"},"cell_type":"markdown","source":"## Dataset Expolaration"},{"metadata":{"id":"SCQudbprX5pl"},"cell_type":"markdown","source":"Upload the data by reading provided .csv files from Google Drive (change path if needed). There are 808696 samples in the training and 121921 instances in the test sets. Each has 23 features."},{"metadata":{"id":"WmZbEAnwYJj6","outputId":"bcf79cb7-2be1-4b15-9444-a9b340085968","trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"../input/datathon/assessment/Assessment Data/Assessment Train Data.csv\")\nresult_df = pd.read_csv(\"../input/datathon/assessment/Assessment Data/Assessment Result File.csv\")\nprint(train_df.shape)\nprint(result_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"4ZY-nm_npgp3"},"cell_type":"markdown","source":"Check what data types we have:"},{"metadata":{"id":"GLxegNa1pd8G","outputId":"78238dfc-294f-42db-ebb1-3cbd8c03678d","trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"l4_01rsyCmlL"},"cell_type":"markdown","source":"In the *Departure_YMD_LMT* and the *Operation_YMD_LMT* colums, date of departure and date of check is stored so it is convenient to convert them to date time objects."},{"metadata":{"id":"JU_XBMXRDqOZ","trusted":true},"cell_type":"code","source":"train_df['Departure_YMD_LMT'] = pd.to_datetime(train_df['Departure_YMD_LMT'], format='%Y%m%d')\ntrain_df['Operation_YMD_LMT'] = pd.to_datetime(train_df['Operation_YMD_LMT'], format='%Y%m%d')\nresult_df['Departure_YMD_LMT'] = pd.to_datetime(result_df['Departure_YMD_LMT'], format='%Y%m%d')\nresult_df['Operation_YMD_LMT'] = pd.to_datetime(result_df['Operation_YMD_LMT'], format='%Y%m%d')","execution_count":null,"outputs":[]},{"metadata":{"id":"Gul7qn8ZEW4Y","outputId":"18f6d9cb-7a65-476b-d61e-2390c8e479a8","trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"OdDOiwuGFerU","outputId":"9d02436d-2b60-4dc0-8497-23fee9f2880e","trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"3gnER73WQam2"},"cell_type":"markdown","source":"Convert *object* datatype to category when needed."},{"metadata":{"id":"5e52srsIdGMK","trusted":true},"cell_type":"code","source":"for col_name in train_df.columns:\n    if train_df[col_name].dtype.name == 'object':\n        train_df[col_name] = train_df[col_name].astype('category')\n        result_df[col_name] = result_df[col_name].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"id":"oPj0AJ3UdmfQ","outputId":"f9afb10f-5fdc-41be-b2eb-3b26f0c7128e","trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"O5J9up0-d8bR"},"cell_type":"markdown","source":"See the unique levels of the categorical columns. *Departure Airport* has only one value called \"KDT\". So, it is not informative and should be dropped."},{"metadata":{"id":"kEzqrNWEYlL-","outputId":"9f9ca635-8e11-4c6f-e9ab-6353c0c946ed","trusted":true},"cell_type":"code","source":"for col_name in train_df.columns:\n    if train_df[col_name].dtype.name == 'category':\n        print(col_name, \":\", train_df[col_name].unique())","execution_count":null,"outputs":[]},{"metadata":{"id":"RMErP_yZRG1y"},"cell_type":"markdown","source":"Generate *Operation_Channel_Group* as defined in the pdf file."},{"metadata":{"id":"M3l1GzRXF3tu","outputId":"5942c607-4dfb-4020-c3fd-5ae0a8777bd5","trusted":true},"cell_type":"code","source":"dict = {\"JW\": 'Online',\n        \"TW\": 'Online',\n        \"TS\": 'Mobile',\n        \"JM\": 'Mobile',\n        \"TY\":\"Counter\",\n        \"QC\":\"Counter\",\n        \"SC\":\"Kiosks\",\n        \"IR\":\"Other\",\n        \"?\":\"Other\",\n        \"IA\":\"Other\",\n        \"BD\":\"Other\",\n        \"CC\":\"Other\",\n        \"QR\":\"Other\",\n        \"QP\":\"Other\",\n        \"QA\":\"Other\"\n        }\ntrain_df['Operation_Channel_Group'] = train_df['Operation_Channel'].map(dict)\ntrain_df['Operation_Channel_Group'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"d-dpsfiZ0F0B"},"cell_type":"markdown","source":"Do the same for the test set."},{"metadata":{"id":"NM2QHVLm0Lh8","outputId":"fada196b-da52-41f6-b4b1-fb77a724c930","trusted":true},"cell_type":"code","source":"result_df['Operation_Channel_Group'] = result_df['Operation_Channel'].map(dict)\nresult_df['Operation_Channel_Group'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"hHcQ08xGLCUe"},"cell_type":"markdown","source":"Change data type to category"},{"metadata":{"id":"LgqgfLW2K7TD","trusted":true},"cell_type":"code","source":"train_df[\"Operation_Channel_Group\"] = train_df[\"Operation_Channel_Group\"].astype('category')\nresult_df[\"Operation_Channel_Group\"] = result_df[\"Operation_Channel_Group\"].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"id":"unO5SdRzycc_"},"cell_type":"markdown","source":"### Missing Value Handling\n\nColumn percentage of null values in the training and test sets are printed below. At first glance,there are only null values in the *Operation Initials* column, however some unknown values are encoded as \"?\" in the datasets."},{"metadata":{"id":"uAipyZEz4-sw","outputId":"bae3ee21-089b-4634-eddb-a8d73e449c7d","trusted":true},"cell_type":"code","source":"(train_df.isnull().mean()*100).round(4)","execution_count":null,"outputs":[]},{"metadata":{"id":"Z9h6GsY65I5L","outputId":"88946bbd-8d76-4ab3-8d5c-3180327dbdde","trusted":true},"cell_type":"code","source":"(result_df.isnull().mean()*100).round(4)","execution_count":null,"outputs":[]},{"metadata":{"id":"jLbD741tyefs"},"cell_type":"markdown","source":"Column based \"?\" occurance percentages in the training set:"},{"metadata":{"id":"7CHS7T5Q6k_a","outputId":"6172ca56-b94c-4eb9-adf5-ba816b857536","trusted":true},"cell_type":"code","source":"import numpy as np\ndef unknown_perc(df):\n  print(\"Column Name\\t Percentage\")\n  for col_name in df.columns:\n        if df[col_name].dtype.name == 'category' and (df[col_name] == \"?\").any():\n          count = df[col_name].value_counts(dropna=False)['?']\n          percentage = (count/len(df)*100).round(3)\n          print(col_name,\"\\t\", percentage)\n  return\n        \nunknown_perc(train_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"6AM6L2Bpyw-G"},"cell_type":"markdown","source":"Column based \"?\" occurance percentages in the test set:"},{"metadata":{"id":"2UDEAA0LxKfX","outputId":"611cd33b-e352-4af8-ed34-82201e0b9ca8","trusted":true},"cell_type":"code","source":"unknown_perc(result_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"fkRjgKgzCFbu"},"cell_type":"markdown","source":"#### Generating Flags\n\n\nLet's transform Operation_Sonic_Code to Operation_Sonic_Code_Flag  in order to see if these variables are null or not. We choose to do this since there are so many different classes for these variables.\n\n\n\n---\n\nDepreciated: Terminal_Name to Terminal_Name_Flag\n\n\n---\n\n"},{"metadata":{"id":"b4PaXdgyEfUX","trusted":true},"cell_type":"code","source":"train_df['Operation_Sonic_Code_Flag'] = np.where(train_df['Operation_Sonic_Code']=='?', '0', '1')\ntrain_df['Operation_Sonic_Code_Flag'] = train_df['Operation_Sonic_Code_Flag'].astype(int)\n#train_df['Terminal_Number_Flag'] = np.where(train_df['Terminal_Number']=='?', '0', '1')\n#train_df['Terminal_Number_Flag'] = train_df['Terminal_Number_Flag'].astype(int)\nresult_df['Operation_Sonic_Code_Flag'] = np.where(result_df['Operation_Sonic_Code']=='?', '0', '1')\nresult_df['Operation_Sonic_Code_Flag'] = result_df['Operation_Sonic_Code_Flag'].astype(int)\n#result_df['Terminal_Number_Flag'] = np.where(result_df['Terminal_Number']=='?', '0', '1')\n#result_df['Terminal_Number_Flag'] = result_df['Terminal_Number_Flag'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"id":"FFsQhdoCmip7"},"cell_type":"markdown","source":"Convert \"?\" to NA when needed. Apart from *Inbound_Departure_Airport* and *Outbound_Arrival_Airport*, \"?\" is printed for unknown values (missing). For those specific columns \"?\" means that there is no inbound or outbound flight (direct flight), so they are encoded as a seperate class called *Unknown*."},{"metadata":{"id":"_f4FdP8Ymaxw","trusted":true},"cell_type":"code","source":"import numpy as np\n#train_df['Terminal_Number'] = train_df['Terminal_Number'].replace('?', np.nan)\n#train_df['Operation_Channel'] = train_df['Operation_Channel'].replace('?', np.nan)\ntrain_df['Passenger_Title'] = train_df['Passenger_Title'].replace('?', np.nan)\ntrain_df['Passenger_Gender'] = train_df['Passenger_Gender'].replace('?', np.nan)\ntrain_df['Inbound_Departure_Airport'] = train_df['Inbound_Departure_Airport'].replace('?', \"Unknown\")\ntrain_df['Outbound_Arrival_Airport'] = train_df['Outbound_Arrival_Airport'].replace('?', \"Unknown\")\ntrain_df['Cabin_Class'] = train_df['Cabin_Class'].replace('?', np.nan)\ntrain_df[\"Operation_Initials\"] = train_df[\"Operation_Initials\"].replace(\"?\",np.nan)\ntrain_df[\"Operation_Sonic_Code\"] = train_df[\"Operation_Sonic_Code\"].replace(\"?\",np.nan)\n\n#result_df['Terminal_Number'] = result_df['Terminal_Number'].replace('?', np.nan)\n#result_df['Operation_Channel'] = result_df['Operation_Channel'].replace('?', np.nan)\nresult_df['Passenger_Title'] = result_df['Passenger_Title'].replace('?', np.nan)\nresult_df['Passenger_Gender'] = result_df['Passenger_Gender'].replace('?', np.nan)\nresult_df['Inbound_Departure_Airport'] = result_df['Inbound_Departure_Airport'].replace('?', \"Unknown\")\nresult_df['Outbound_Arrival_Airport'] = result_df['Outbound_Arrival_Airport'].replace('?', \"Unknown\")\nresult_df['Cabin_Class'] = result_df['Cabin_Class'].replace('?', np.nan)\nresult_df[\"Operation_Initials\"] = train_df[\"Operation_Initials\"].replace(\"?\",np.nan)\nresult_df[\"Operation_Sonic_Code\"] = result_df[\"Operation_Sonic_Code\"].replace(\"?\",np.nan)","execution_count":null,"outputs":[]},{"metadata":{"id":"nplxsMXMAnXY"},"cell_type":"markdown","source":"Now, the new missing value percentages for the training set becomes:"},{"metadata":{"id":"CwmBM3TkrjrK","outputId":"86853c51-16db-4d49-dd12-2e433249a0fd","trusted":true},"cell_type":"code","source":"(train_df.isnull().mean()*100).round(4)","execution_count":null,"outputs":[]},{"metadata":{"id":"aSMbF8qEA4M7"},"cell_type":"markdown","source":"and for the test set the result is:"},{"metadata":{"id":"CINMBpV7A8pG","outputId":"8eb07c60-1462-46fe-f6f2-b7f088fd941c","trusted":true},"cell_type":"code","source":"(result_df.isnull().mean()*100).round(4)","execution_count":null,"outputs":[]},{"metadata":{"id":"2rroaK2-3ruv"},"cell_type":"markdown","source":"### Dropping Uninformative Features"},{"metadata":{"id":"Pe1XXORnVqGy"},"cell_type":"markdown","source":"Notice that *Operation Sonic Code*  has a missing value ratio of 79% and for *Terminal Number* column this ratio is even higher (>90%). With a ratio this high, we cannot impute missing values correctly. These columns should be dropped, along with the *Departure_Airport* column. \n\n\n\n---\n\nLater we decided to keep *Terminal Number* since it shows high correlation whether the passenger flies or not (SWC_FLY). We thought that even this column composed of values mostly unknown, it can be stil informative.\n\n\n---\n\n\n"},{"metadata":{"id":"w843hKQbB9Bs","trusted":true},"cell_type":"code","source":"#train_df2 = train_df.copy()\n#result_df2 = result_df.copy()\ntrain_df = train_df.drop(columns = [ \"Departure_Airport\", \"Operation_Sonic_Code\"]) #\"Terminal_Number\", \nresult_df = result_df.drop(columns = [\"Departure_Airport\", \"Operation_Sonic_Code\"]) #\"Terminal_Number\", ","execution_count":null,"outputs":[]},{"metadata":{"id":"egMg7CVHWqy-"},"cell_type":"markdown","source":"#### Imputing Passenger Gender\n\nFirst, we used *Passenger Title* to impute missing values in the gender column. We replaced unknown genders whose titles are *MISTER*, *MISS* and *MISSES* with male and females, respectively. Later, we decided *Operation Channel Group* based imputation for the rest. So we grouped the dataframe by this column and found most frequent observations for the *Passenger Gender* column."},{"metadata":{"id":"2aqNrg2SCFM7","outputId":"141f8730-b02e-452e-9007-5d9917ae2032","trusted":true},"cell_type":"code","source":"# Replace missing values whose titles are MISTER with M\ntrain_df.loc[(train_df.Passenger_Gender.isna() ) & (train_df.Passenger_Title=='MISTER'),\"Passenger_Gender\"] = \"M\"\nresult_df.loc[(result_df.Passenger_Gender.isna() ) & (result_df.Passenger_Title=='MISTER'),\"Passenger_Gender\"] = \"M\"\n\n# Replace missing values whose titles are MISS or MISSES with F\ntrain_df.loc[(train_df.Passenger_Gender.isna() ) & ((train_df.Passenger_Title=='MISS') | (train_df.Passenger_Title=='MISSES')) ,\"Passenger_Gender\"] = \"F\"\nresult_df.loc[(result_df.Passenger_Gender.isna() ) & ((result_df.Passenger_Title=='MISS') | (result_df.Passenger_Title=='MISSES')) ,\"Passenger_Gender\"] = \"F\"\n\nsum(train_df[\"Passenger_Gender\"].isnull())","execution_count":null,"outputs":[]},{"metadata":{"id":"ycXeXhyjIUoL"},"cell_type":"markdown","source":"There are 981 missing values left in the gender column. We checked channel group based gender distribution and found that the most frequent gender is male for every channel"},{"metadata":{"id":"RO2DoYwAW564","outputId":"39b5c6e6-f483-45e9-dc21-1fdd6e6ccb40","trusted":true},"cell_type":"code","source":"train_df.groupby(\"Operation_Channel_Group\")['Passenger_Gender'].apply(lambda x: x.value_counts().index[0])#.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"id":"S038IZzsZeP_","outputId":"fe169d29-4ce0-4cd4-f286-df309be981ef","trusted":true},"cell_type":"code","source":"train_df.groupby(\"Operation_Channel_Group\")['Passenger_Gender'].apply(lambda x: x.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"NbFrmcungJex","outputId":"fbe6c311-f518-4e6b-9068-5f63bc1a17af","trusted":true},"cell_type":"code","source":"result_df.groupby(\"Operation_Channel_Group\")['Passenger_Gender'].apply(lambda x: x.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"4_NAbcajX7S_"},"cell_type":"markdown","source":"Since most common gender for all channel groups is male, we imputed missing gender values with \"M\"."},{"metadata":{"id":"mthkiXm6YOMQ","outputId":"4a119a0a-215f-4e73-e92f-9e5874e5bc0b","trusted":true},"cell_type":"code","source":"train_df['Passenger_Gender'] = train_df['Passenger_Gender'].replace(np.nan, \"M\")\ntrain_df['Passenger_Gender'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"UcXgdApsgRJn","outputId":"f46b9cc7-41fa-4a30-f723-cbce6dfaf1d2","trusted":true},"cell_type":"code","source":"result_df['Passenger_Gender'] = train_df['Passenger_Gender'].replace(np.nan, \"M\")\nresult_df['Passenger_Gender'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"GsGg4v3wbntJ"},"cell_type":"markdown","source":"#### Imputing Passenger Title\n\nAgain, Operation Channel Group based imputation is employed. \"MISTER\" is most common tittle so we employed all the missin values with that."},{"metadata":{"id":"KVG7j7b8eMzB","outputId":"b455efdd-8a45-4890-e1fc-dd60ec1124d1","trusted":true},"cell_type":"code","source":"train_df.groupby(\"Operation_Channel_Group\")['Passenger_Title'].apply(lambda x: x.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"aEL6pDtTghn-","outputId":"70fac330-6d8a-425f-f882-ddb3876180f2","trusted":true},"cell_type":"code","source":"result_df.groupby(\"Operation_Channel_Group\")['Passenger_Title'].apply(lambda x: x.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"ZN7ATCdElSgI","outputId":"9fea7182-7e03-4d02-f74f-5713a1be0436","trusted":true},"cell_type":"code","source":"train_df['Passenger_Title'] = train_df['Passenger_Title'].replace(np.nan, \"MISTER\")\ntrain_df['Passenger_Title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"ZbPfQGIulcFK","outputId":"cc300289-983c-4180-ec71-33be59f27903","trusted":true},"cell_type":"code","source":"result_df['Passenger_Title'] = result_df['Passenger_Title'].replace(np.nan, \"MISTER\")\nresult_df['Passenger_Title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"cwp0gNe6oc0D"},"cell_type":"markdown","source":"#### Imputing Cabin Class\nMost common class is economy class for all channel groups so we imputed missing values with it."},{"metadata":{"id":"IVFNYI92qPs9","outputId":"db780c7e-b3f3-4615-e838-a5563e2813bf","trusted":true},"cell_type":"code","source":"train_df.groupby(\"Operation_Channel_Group\")['Cabin_Class'].apply(lambda x: x.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"OsAmymphAuah","outputId":"7cdcbeff-7e3d-45aa-c34b-598aade174fb","trusted":true},"cell_type":"code","source":"train_df[\"Cabin_Class\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"UxmTIOb9pm_V","outputId":"6852b52b-5841-44ae-837b-e8e92bbdf105","trusted":true},"cell_type":"code","source":"result_df.groupby(\"Operation_Channel_Group\")['Cabin_Class'].apply(lambda x: x.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"-vksq8jTwPMG","outputId":"8e8838b6-f8e5-4d9b-e66a-f319f591f91c","trusted":true},"cell_type":"code","source":"train_df['Cabin_Class'] = train_df['Cabin_Class'].replace(np.nan, \"Y\")\ntrain_df['Cabin_Class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"4YTu787QwPBr","outputId":"99ea42d1-defa-4088-f6fd-7f7da8e85e34","trusted":true},"cell_type":"code","source":"result_df['Cabin_Class'] = result_df['Cabin_Class'].replace(np.nan, \"Y\")\nresult_df['Cabin_Class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"l5Ym3TE5xX2y"},"cell_type":"markdown","source":"#### Imputing Operation Initials\n\nThe most frequent *Operation Initials* observed in different channel groups for the training and the test set are given below."},{"metadata":{"id":"Pnvv-Qavxfje","outputId":"b9daf151-e731-43b5-ee44-12367c49c15b","trusted":true},"cell_type":"code","source":"train_df.groupby(\"Operation_Channel_Group\")['Operation_Initials'].apply(lambda x: x.value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"gzCXzTUvALKC","outputId":"adac9f8d-072d-42b2-8ef2-2b0c33559542","trusted":true},"cell_type":"code","source":"result_df.groupby(\"Operation_Channel_Group\")['Operation_Initials'].apply(lambda x: x.value_counts().index[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"ibhXNfsaAUFu"},"cell_type":"markdown","source":"The most frequent initials observed in each channel group is \"KS\" for test set so we replaced NA values with it."},{"metadata":{"id":"4NApKi8rAkix","outputId":"5b5d80d0-5caf-485d-b75f-946c3c018616","trusted":true},"cell_type":"code","source":"result_df['Operation_Initials'] = result_df['Operation_Initials'].replace(np.nan, \"KS\")\nresult_df['Operation_Initials'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"TPZqMS_BAx-Y"},"cell_type":"markdown","source":"However, we need to impute missing values differently for different channels for the training set."},{"metadata":{"id":"mCV4rYaB5DcD","trusted":true},"cell_type":"code","source":"train_df.loc[(train_df.Operation_Channel_Group == \"Counter\") & (train_df.Operation_Initials.isna()),\"Operation_Initials\"] = \"KS\"\ntrain_df.loc[(train_df.Operation_Channel_Group == \"Kiosks\") & (train_df.Operation_Initials.isna()),\"Operation_Initials\"] = \"SC\"\ntrain_df.loc[(train_df.Operation_Channel_Group != \"Kiosks\") & (train_df.Operation_Channel_Group != \"Counter\") & (train_df.Operation_Initials.isna()),\"Operation_Initials\"] = \"MK\"","execution_count":null,"outputs":[]},{"metadata":{"id":"vb0dM8WjcpJh"},"cell_type":"markdown","source":"## Feature Generation"},{"metadata":{"id":"PUD2-XzlMggF"},"cell_type":"markdown","source":"### Early Check-in & Early Check-in Status\n\nWe generate another variable to see if people checked in on-time or not. The date is given as days, so how many days there are between the flight and the check-in is added as a variable."},{"metadata":{"id":"oqeDf5HEMuP1","outputId":"e8b1a0c0-e52c-4651-854e-74c739e3095a","trusted":true},"cell_type":"code","source":"train_df['Early_Check_In'] = (train_df.Departure_YMD_LMT - train_df.Operation_YMD_LMT)\ntrain_df['Early_Check_In'] = (train_df['Early_Check_In']/86400000000000).astype(int)\ntrain_df['Early_Check_In'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"2dtlQ7QNNq3b"},"cell_type":"markdown","source":"There are some peculiar cases where check-in made 7000 days before in 1999!"},{"metadata":{"id":"sdapddLzOHO7","outputId":"cc1b0a64-7037-48df-c953-ef317788353f","trusted":true},"cell_type":"code","source":"train_df[train_df['Early_Check_In']>100].sort_values('Operation_YMD_LMT')","execution_count":null,"outputs":[]},{"metadata":{"id":"WorjhS29RZlo"},"cell_type":"markdown","source":"We replaced the check-in day as early, on-time and peculiar."},{"metadata":{"id":"v_zaLveCRqjl","trusted":true},"cell_type":"code","source":"train_df.loc[train_df.Early_Check_In > 100, 'Early_Check_In_Status'] = 'Peculiar'\ntrain_df.loc[(train_df.Early_Check_In == 0) | (train_df.Early_Check_In == -1), 'Early_Check_In_Status'] = 'On-time'\ntrain_df.loc[(train_df.Early_Check_In == 1) | (train_df.Early_Check_In == 2) | (train_df.Early_Check_In == 3), 'Early_Check_In_Status'] = 'Early'","execution_count":null,"outputs":[]},{"metadata":{"id":"1HYwYqwVSWbM"},"cell_type":"markdown","source":"Do the same for the result set."},{"metadata":{"id":"HtHSktQbScqJ","trusted":true},"cell_type":"code","source":"result_df['Early_Check_In'] = (result_df.Departure_YMD_LMT - result_df.Operation_YMD_LMT)\nresult_df['Early_Check_In'] = (result_df['Early_Check_In']/86400000000000).astype(int)\nresult_df.loc[result_df.Early_Check_In > 100, 'Early_Check_In_Status'] = 'Peculiar'\nresult_df.loc[(result_df.Early_Check_In == 0) | (result_df.Early_Check_In == -1), 'Early_Check_In_Status'] = 'On-time'\nresult_df.loc[(result_df.Early_Check_In == 1) | (result_df.Early_Check_In == 2) | (result_df.Early_Check_In == 3), 'Early_Check_In_Status'] = 'Early'","execution_count":null,"outputs":[]},{"metadata":{"id":"wtCU50W6Wf-F"},"cell_type":"markdown","source":"The flights with no inbound and no outbound terminal are direct flights so we generated a new colum to label those flights"},{"metadata":{"id":"TAxU-lnlVd3d","trusted":true},"cell_type":"code","source":"train_df['Direct_Flight'] = np.where((train_df.Inbound_Departure_Airport == 'Unknown') & (train_df.Outbound_Arrival_Airport == 'Unknown'), 1, 0)\nresult_df['Direct_Flight'] = np.where((result_df.Inbound_Departure_Airport == 'Unknown') & (result_df.Outbound_Arrival_Airport == 'Unknown'), 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"XysO0DT6NlHl"},"cell_type":"markdown","source":"### Check-in Inbound & Check-in Outbound\n\nThe number of different values in Operation_Airport is very high. We think that, whether the Operation_Airport is the same airport with the Inbound_Departure_Airport or the Outbound_Arrival_Airport, is an important feature. So Checkin_Outbound and Operation_Outbound variables indicate if the check-in operation is done at either the Inbound_Departure_Airport or the Outbound_Arrival_Airport. \n\n"},{"metadata":{"id":"J7oJsUC-NXWF","trusted":true},"cell_type":"code","source":"train_df.loc[(train_df.Operation_Airport == train_df.Inbound_Departure_Airport), 'Checkin_Inbound'] = 1\ntrain_df['Checkin_Inbound'] = train_df['Checkin_Inbound'].replace(np.nan, 0)\n\nresult_df.loc[(result_df.Operation_Airport == result_df.Inbound_Departure_Airport), 'Checkin_Inbound'] = 1\nresult_df['Checkin_Inbound'] = result_df['Checkin_Inbound'].replace(np.nan, 0)\n\n\n\ntrain_df.loc[(train_df.Operation_Airport == train_df.Outbound_Arrival_Airport), 'Checkin_Outbound'] = 1\ntrain_df['Checkin_Outbound'] = train_df['Checkin_Outbound'].replace(np.nan, 0)\n\nresult_df.loc[(result_df.Operation_Airport == result_df.Outbound_Arrival_Airport), 'Checkin_Outbound'] = 1\nresult_df['Checkin_Outbound'] = result_df['Checkin_Outbound'].replace(np.nan, 0)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"9Aa6_RLeWzGb"},"cell_type":"markdown","source":"### Operation Airport Reduced\nWe now reduce the number of different values in Operation_Airport variable for the most frequent ones since there is a huge drop after *EST* airport."},{"metadata":{"id":"284WPAQnW0dw","outputId":"9f84975b-79f5-477b-a9ad-6b2c8c356a63","trusted":true},"cell_type":"code","source":"train_df.groupby('Operation_Airport').count().sort_values('Operation_Initials', ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"fDjyJK3YXWPJ"},"cell_type":"markdown","source":"The same most frequent 4 airports (KDT, IST, SKW, EST) found in the test set."},{"metadata":{"id":"pjyeKekDXW2T","outputId":"33b358af-3e7d-473e-9f6f-145579547cb0","trusted":true},"cell_type":"code","source":"result_df.groupby('Operation_Airport').count().sort_values('Operation_Initials', ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"cMbnF6IaX3Uf"},"cell_type":"markdown","source":"The occurences of most frequent values are far different for the first 4 values. They are the same airport for both train and test data. So, any airport other than these 4 is replaced with \"OTHERS\"."},{"metadata":{"id":"EOtz21cwX5IR","trusted":true},"cell_type":"code","source":"train_df['Operation_Airport_Reduced'] = np.where((train_df.Operation_Airport == 'KDT') | (train_df.Operation_Airport == 'IST') | (train_df.Operation_Airport == 'SKW') | (train_df.Operation_Airport == 'EST'), train_df.Operation_Airport, 'OTHERS')\nresult_df['Operation_Airport_Reduced'] = np.where((result_df.Operation_Airport == 'KDT') | (result_df.Operation_Airport == 'IST') | (result_df.Operation_Airport == 'SKW') | (result_df.Operation_Airport == 'EST'), result_df.Operation_Airport, 'OTHERS')","execution_count":null,"outputs":[]},{"metadata":{"id":"LvlPttUSYTNY"},"cell_type":"markdown","source":"### Operation Initials Reduced\n\nWe followed the same grouping scheme for the Operation_Initials column. There is a huge drop after LK company in terms of count."},{"metadata":{"id":"x-53u2rlYnOD","outputId":"dbb34f39-93fe-49f7-cb1f-9832d3c0c81a","trusted":true},"cell_type":"code","source":"train_df.groupby('Operation_Initials').count().sort_values('Operation_Airport', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"tHhekB0ma5K5","outputId":"5340fb6e-c1ae-4c3f-9f02-c63948a500e5","trusted":true},"cell_type":"code","source":"result_df.groupby('Operation_Initials').count().sort_values('Operation_Airport', ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"uONxfEgsaxuN"},"cell_type":"markdown","source":"The 6 most frequent values differ significantly from the others. The same pattern in the training set is shared with the test set.  We replace the others with \"OTHERS\" and kept the most frequent ones."},{"metadata":{"id":"lXeLYNIubT05","trusted":true},"cell_type":"code","source":"train_df['Operation_Initials_Reduced'] = np.where((train_df.Operation_Initials == 'KS') | (train_df.Operation_Initials == 'MK') | (train_df.Operation_Initials == 'SC') | (train_df.Operation_Initials == 'Q7') | (train_df.Operation_Initials == 'EY') | (train_df.Operation_Initials == 'LK'), train_df.Operation_Initials, 'OTHERS')\nresult_df['Operation_Initials_Reduced'] = np.where((result_df.Operation_Initials == 'KS') | (result_df.Operation_Initials == 'MK') | (result_df.Operation_Initials == 'SC') | (result_df.Operation_Initials == 'Q7') | (result_df.Operation_Initials == 'EY') | (result_df.Operation_Initials == 'LK'), result_df.Operation_Initials, 'OTHERS')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"hpEvN1Z-bxHz","outputId":"11ded5c1-f490-4fcb-f2d9-fa5d21620fb8","trusted":true},"cell_type":"code","source":"train_df.groupby('Operation_Initials_Reduced').count().sort_values('Operation_Airport', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"k9ymmU2zl2DA"},"cell_type":"markdown","source":"### Inbound_Departure_Airport_Reduced\n\nThe most common *Inbound Departure Airports* are unknowns (those with no inbound flight), IST, SKW and EST for the test and the training set both. So we kept those and grouped the others as OTHERS. "},{"metadata":{"id":"-0Hy6fudl__8","outputId":"d9669be4-2abc-4ca4-e0f7-582e05b9460c","trusted":true},"cell_type":"code","source":"train_df.groupby('Inbound_Departure_Airport').count().sort_values('Operation_Airport', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"-77cur3DmZQV","outputId":"1e8e1fce-7168-4e5f-fb3f-7c972db769dc","trusted":true},"cell_type":"code","source":"result_df.groupby('Inbound_Departure_Airport').count().sort_values('Operation_Airport', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"5vhrnhgnmlSa","trusted":true},"cell_type":"code","source":"train_df['Inbound_Departure_Airport_Reduced'] = np.where((train_df.Inbound_Departure_Airport == 'Unknown') | (train_df.Inbound_Departure_Airport == 'IST') | (train_df.Inbound_Departure_Airport == 'SKW') | (train_df.Inbound_Departure_Airport == 'EST'), train_df.Inbound_Departure_Airport, 'OTHERS')\nresult_df['Inbound_Departure_Airport_Reduced'] = np.where((result_df.Inbound_Departure_Airport == 'Unknown') | (result_df.Inbound_Departure_Airport == 'IST') | (result_df.Inbound_Departure_Airport == 'SKW') | (result_df.Inbound_Departure_Airport == 'EST'), result_df.Inbound_Departure_Airport, 'OTHERS')","execution_count":null,"outputs":[]},{"metadata":{"id":"sCaCIlC8nFqg"},"cell_type":"markdown","source":"### Outbound Arrival Airport Reduced\n\nThe most common *Outbound Departure Airports* are unknowns (those with no outbound flight) and KDT for the test and the training set both. So we kept those and grouped the others as OTHERS."},{"metadata":{"id":"4HWcqsLJnRxi","outputId":"f0e4ba5c-7ae4-4c6b-d7fc-35502fe8ef0d","trusted":true},"cell_type":"code","source":"train_df.groupby('Outbound_Arrival_Airport').count().sort_values('Operation_Airport', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"HTq6wrcioGav","outputId":"88472756-22fd-455f-8336-04a6488c167d","trusted":true},"cell_type":"code","source":"result_df.groupby('Outbound_Arrival_Airport').count().sort_values('Operation_Airport', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"sthvdOsqnk2V","trusted":true},"cell_type":"code","source":"train_df['Outbound_Arrival_Airport_Reduced'] = np.where((train_df.Outbound_Arrival_Airport == 'Unknown') | (train_df.Outbound_Arrival_Airport == 'KDT'), train_df.Outbound_Arrival_Airport, 'OTHERS')\nresult_df['Outbound_Arrival_Airport_Reduced'] = np.where((result_df.Outbound_Arrival_Airport == 'Unknown') | (result_df.Outbound_Arrival_Airport == 'KDT'), result_df.Outbound_Arrival_Airport, 'OTHERS')","execution_count":null,"outputs":[]},{"metadata":{"id":"CywhuSD1Zxg-"},"cell_type":"markdown","source":"### Weekend\n\nWe thought that may be week of day, weekend/weekday information might be usefull. Weekend days are encoded as 1 in the *Weekend* column."},{"metadata":{"id":"akDymq3AeIfj","trusted":true},"cell_type":"code","source":"import datetime\ntrain_df['Weekend'] = [x in [5,6] for x in train_df.Departure_YMD_LMT.dt.weekday]\ntrain_df['Weekend'] = train_df['Weekend'].replace(True, int(1))\ntrain_df['Weekend'] = train_df['Weekend'].replace(False, int(0))\nresult_df['Weekend'] = [x in [5,6] for x in result_df.Departure_YMD_LMT.dt.weekday]\nresult_df['Weekend'] = result_df['Weekend'].replace(True, int(1))\nresult_df['Weekend'] = result_df['Weekend'].replace(False, int(0))","execution_count":null,"outputs":[]},{"metadata":{"id":"HKKUix3-EWJi","outputId":"03eed56f-4d17-48f1-efa5-e9ac1a2e5bc9","trusted":true},"cell_type":"code","source":"train_df.Weekend.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"LWXVCZVQB00s"},"cell_type":"markdown","source":"### Departure Day\n\nGenerate *Departure Day* column:"},{"metadata":{"id":"L4JvhincBJ5c","outputId":"27d87d2d-2108-439a-b1f0-f7b98d3ee0f9","trusted":true},"cell_type":"code","source":"train_df['Departure Day'] = train_df['Departure_YMD_LMT'].dt.weekday_name\n\nresult_df['Departure Day'] = result_df['Departure_YMD_LMT'].dt.weekday_name\n\ntrain_df['Departure Day'].head()","execution_count":null,"outputs":[]},{"metadata":{"id":"tLlVcAyPe2GB"},"cell_type":"markdown","source":"### Day of Month"},{"metadata":{"id":"RXH84nITHWub","outputId":"483fb4e8-6f89-44fe-dd8b-c088d0c77f0c","trusted":true},"cell_type":"code","source":"train_df.insert(1,'Day_of_Month','foo')\ntrain_df['Day_of_Month'] = train_df['Departure_YMD_LMT'].dt.day\n\nresult_df.insert(1,'Day_of_Month','foo')\nresult_df['Day_of_Month'] = result_df['Departure_YMD_LMT'].dt.day\n\ntrain_df['Day_of_Month'].head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ltshc6kDIQJy"},"cell_type":"markdown","source":"### Economy Class\n\nTransform categorical *Cabin Class* column to binary variable."},{"metadata":{"id":"MO6IJgPmIaD5","outputId":"b1b9a6cc-340c-49a3-cce4-86a3f5cfcd0c","trusted":true},"cell_type":"code","source":"dict = {\"Y\": 1,\n        \"C\": 0\n        }\ntrain_df['Economy_Class'] = train_df['Cabin_Class'].map(dict)\ntrain_df = train_df.drop(\"Cabin_Class\", axis = 1)\nresult_df['Economy_Class'] = result_df['Cabin_Class'].map(dict)\nresult_df = result_df.drop(\"Cabin_Class\", axis = 1)\ntrain_df['Economy_Class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"spdigLH_bTof"},"cell_type":"markdown","source":"#### Lightly Flying Passengers\n\nNew feature is generated for lightly flying passengers since this case seems like a predictor for the operation count."},{"metadata":{"id":"k2JgtOb0bZED","trusted":true},"cell_type":"code","source":"train_df['Fly_Light'] = np.where(train_df['Passenger_Baggage_Count']==0, 1, 0)\nresult_df['Fly_Light'] = np.where(result_df['Passenger_Baggage_Count']==0, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"xXQYc2l4kjxX"},"cell_type":"markdown","source":"### Drop Unnecessary Columns"},{"metadata":{"id":"rDInMBCqkqXa","trusted":true},"cell_type":"code","source":"train_df = train_df.drop(columns = [\"Departure_YMD_LMT\", \n                                    \"Operation_YMD_LMT\", \n                                    \"Operation_Initials\", \n                                    \"Operation_Airport\",\n                                    \"Inbound_Departure_Airport\",\n                                    \"Outbound_Arrival_Airport\",\n                                    \"Terminal_Name\",\n                                    \"Early_Check_In\"], axis =1) ","execution_count":null,"outputs":[]},{"metadata":{"id":"PRVOF_Xhunel"},"cell_type":"markdown","source":"## Encoding Categorical Features"},{"metadata":{"id":"9PJeh-H0oyMw"},"cell_type":"markdown","source":"Convert objects to category"},{"metadata":{"id":"ClYRXhuDhri_","trusted":true},"cell_type":"code","source":"for col_name in train_df.columns:\n    if train_df[col_name].dtype.name == 'object':\n        train_df[col_name] = train_df[col_name].astype('category')\n        result_df[col_name] = result_df[col_name].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"id":"lS4UMDYIumpJ","outputId":"2211b33f-36d4-4672-8021-debe48a9b415","trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"jTCZbJCUxdWX"},"cell_type":"markdown","source":"Encode categorical columns"},{"metadata":{"id":"Bn7AH7VXwQbm","outputId":"5c9e35c1-3023-470f-baa3-aad5e30554eb","trusted":true},"cell_type":"code","source":"train_onehot = train_df.copy()\n#train_onehot.drop(columns = [\"Operation_Initials\", \"Terminal_Name\"], axis =1)\nresult_onehot = result_df.copy()\nfor cols in train_df.columns: #leave as traidf!!!\n  if train_onehot[cols].dtype.name == 'category':\n    print(cols)\n    one_hot = pd.get_dummies(train_df[cols], prefix = cols)\n    train_onehot = train_onehot.drop(cols,axis = 1)\n    train_onehot = train_onehot.join(one_hot)\n  ","execution_count":null,"outputs":[]},{"metadata":{"id":"EZkxjtnb1vEm","outputId":"43b0f24f-a859-4e32-b6eb-abed79f5dc71","trusted":true},"cell_type":"code","source":"train_onehot.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"i_yP2l6mMJ08"},"cell_type":"markdown","source":"## Correlation Matrix"},{"metadata":{"id":"12hiawVHIPe6"},"cell_type":"markdown","source":"Upon observing correlation matrix, we first noticed that *Passenger Baggage Count* is highly correlated with *Passenger Baggage Weight*. These columns are multicollinear, so we are going to include our model only one of them. We decided to continue with *Passenger Baggage Count* since we later observed that this feature has a higher importance weight. Lightly flying passengers with no baggages negatively correlates with baggage count and weight related columns, as expected. CIP's with high commercial value tend to belong a loyalty program."},{"metadata":{"id":"35cGI-2CNamg","outputId":"70ba4537-dae6-4d34-8a38-9172f3594840","trusted":true},"cell_type":"code","source":"import seaborn as sns\ncorr = train_df.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"id":"jlb4JUGrW70Q"},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"id":"TMogDZ-haAyU"},"cell_type":"markdown","source":"Curious behavior of the operation count:\nBelow we see the *Operation Count* distribution. It is positive skewed. A high majority of the passengers does 1 operation, the population is localized under 20 operations. There is an outlier with 129 operations."},{"metadata":{"id":"tcA_A05Fh_MR","outputId":"db503d10-18e8-482e-c274-5182e1709bd7","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 1,figsize=(10, 8))\ntrain_df[\"Operation_Count\"].hist(bins=500, color=\"blue\", ax=ax)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"3Vr9h6rAZcnJ"},"cell_type":"markdown","source":"Operation count distributed uniformly over days of the week. Fridays are slightly a little busier than the others (?)."},{"metadata":{"id":"3LXVhjPTY10a","outputId":"41ebd2fc-0372-4b8a-e994-b58f5c908a32","trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.barplot(x='Departure Day',y='Operation_Count',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"MaDi7cGxaSQx"},"cell_type":"markdown","source":"Uniform distribution in the operation count among weekend flag. So, there is no difference in number of operations during weekdays and the weekends."},{"metadata":{"id":"hlYCsTtnaTHt","outputId":"dd4d88b0-761e-46c3-fa3f-cbf4a0e141cd","trusted":true},"cell_type":"code","source":"sns.barplot(x='Weekend',y='Operation_Count',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"TxVlEE5dbK-3"},"cell_type":"markdown","source":"Direct flight seems to be an importan predictor of the operation count."},{"metadata":{"id":"QPzr0Gu5bKWc","outputId":"603dba6f-a029-4023-a44a-82320015fbef","trusted":true},"cell_type":"code","source":"sns.barplot(x='Direct_Flight',y='Operation_Count',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"QKB8DDXAbks-"},"cell_type":"markdown","source":"Passenger_Baggage_Count"},{"metadata":{"id":"Lvz2rSdObn9j","outputId":"786f0d8e-93eb-4f55-a577-be1531a00b4e","trusted":true},"cell_type":"code","source":"sns.barplot(x='Passenger_Baggage_Count',y='Operation_Count',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"i2-fQZQSeH-w","outputId":"2ecf61de-ed19-43d0-bb26-b55c95b8656c","trusted":true},"cell_type":"code","source":"sns.barplot(x='Fly_Light',y='Operation_Count',data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"id":"HhFEa_YTctDg","outputId":"48529422-31b4-48b0-842c-5298375e1aae","trusted":true},"cell_type":"code","source":"sns.distplot(train_df['Passenger_Baggage_Weight'])","execution_count":null,"outputs":[]},{"metadata":{"id":"ljbwi0pUiLYp"},"cell_type":"markdown","source":"## Feature Importance\n\nSince no strong correlation with the target is found within the data, an automatic feature selection method is employed. Light GBM, is a greadient boosted tree based algorithm. Differing from other three based algorithms, it grows the trees vertically, i.e. it chooses the leaf with maximum loss and grows the tree from there. Details of this algorithm can be found in references.\n\n\n\nImportant Features:\n---\n\n+ Day_of_Month\n+\tSWC_FQTV_Member\n+\tPassenger_Baggage_Count\n+\tDirect_Flight\n+\tEarly_Check_In_Status_Early\n+\tEconomy_Class\n+\tSWC_CIP_Passenger\n+\tTerminal_Number_?\n+\tPassenger_Gender_M\n+\tOperation_Initials_Reduced_MK\n+\tOperation_Channel_TS"},{"metadata":{"id":"5C723jIGnITf","outputId":"5c1bb516-f1f3-4998-ca15-2668bf12ada8","trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\n#train_onehot = train_onehot.drop(columns = [\"Departure_YMD_LMT\", \"Operation_YMD_LMT\", \"Operation_Initials\", \"Operation_Airport\"], axis =1)\ntarget = train_onehot[\"Operation_Count\"]\ntrain = train_onehot.drop([\"Operation_Count\"], axis = 1)\n#lightGBM model fit\ngbm = lgb.LGBMRegressor()\ngbm.fit(train, target)\ngbm.booster_.feature_importance()\n\"\"\n# importance of each attribute\nfea_imp_ = pd.DataFrame({'cols':train.columns, 'fea_imp':gbm.feature_importances_})\nfea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"id":"_s5-SDtkXAx5"},"cell_type":"markdown","source":"## Train/Validation/Test Split"},{"metadata":{"id":"Mhpd6YAMXFT4","outputId":"c4deb785-60d3-4fdd-c801-90672bce1142","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# define target\ny = train_onehot.Operation_Count\n# define features\nX = train_onehot.drop(columns = [\"Operation_Count\"])\n# stratified sampling\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) # stratify=X_train.Operation_Channel_Group, \nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\nprint('Training Features Shape:', X_train.shape)\nprint('Training Labels Shape:', y_train.shape)\nprint('Validation Features Shape:', X_val.shape)\nprint('Validation Labels Shape:', y_val.shape)\nprint('Testing Features Shape:', X_test.shape)\nprint('Testing Labels Shape:', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"5SfWVU9Vm568"},"cell_type":"markdown","source":"## Feature Normalization\n\nNot needed for DT based algorithms"},{"metadata":{"id":"MxuVUweJoh8p"},"cell_type":"markdown","source":""},{"metadata":{"id":"Vj6z6YnlYktH"},"cell_type":"markdown","source":"## Model Building\n\n### Baseline Model: Random Forest\n\nWe first used all the features avaible."},{"metadata":{"id":"c37J6m7FvQFu"},"cell_type":"markdown","source":"### MP Model:"},{"metadata":{"id":"-NyjZ0ghpRsg"},"cell_type":"markdown","source":"We see that y values are dominated by '1's. Our first aim is to classify the y values as '1's and 'others'.  Then we will use linear regression to find a relation among 'others'.\n"},{"metadata":{"id":"Vy2iSKMT1oEG"},"cell_type":"markdown","source":"#### Training and Validation of the model"},{"metadata":{"id":"jQGzLN1CvF1H"},"cell_type":"markdown","source":"**PART 1: Classification**"},{"metadata":{"id":"UStuJnsmsoBf"},"cell_type":"markdown","source":"The values that are different than '1' are set to zero \n\n"},{"metadata":{"id":"h8GpObNO7XfM","trusted":true},"cell_type":"code","source":"y_train_log = np.where(y_train == 1, 1, 0)\ny_val_log = np.where(y_val == 1, 1, 0)\ny_test_log = np.where(y_test == 1, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"zhsLSg-wt4ED"},"cell_type":"markdown","source":"Logistic Regression is employed:"},{"metadata":{"id":"meXC-UVw7rAq","outputId":"5c0143da-a436-4863-fd22-6b3146ab76f9","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train_log)","execution_count":null,"outputs":[]},{"metadata":{"id":"r00CjMTdtl_H"},"cell_type":"markdown","source":"*Validation for Part 1:*"},{"metadata":{"id":"ziOUogVQulwq"},"cell_type":"markdown","source":"A new column is created to encode the first prediction for validation data. "},{"metadata":{"id":"tc2ZLUVtxiNP"},"cell_type":"markdown","source":""},{"metadata":{"id":"xqRY7E69-C6i","trusted":true},"cell_type":"code","source":"X_val['Prediction1'] = logreg.predict(X_val)\ny_val_log_pred=X_val['Prediction1']","execution_count":null,"outputs":[]},{"metadata":{"id":"x988FDbjvdET"},"cell_type":"markdown","source":" **PART 2 : LINEAR REGRESSION**"},{"metadata":{"id":"JmdXXfHXBqN6"},"cell_type":"markdown","source":"In this part, we will train the data set corresponding to y values different than 1.\n\n\n\n\n\n"},{"metadata":{"id":"4ahiXpyoBpo4","trusted":true},"cell_type":"code","source":"X_train_multi = X_train[y_train_log == 0]\ny_train_multi = y_train[y_train_log == 0]\n\nX_val_multi = X_val[y_val_log_pred == 0]\ny_val_multi = y_val[y_val_log_pred == 0]","execution_count":null,"outputs":[]},{"metadata":{"id":"NihMb3yTylMN"},"cell_type":"markdown","source":"Lasso regression is used"},{"metadata":{"id":"ToKFcseu-Yy9","outputId":"0b095883-e1a9-499b-bd53-03ee086429e5","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n\nreg = LassoCV()\nreg.fit(X_train_multi, y_train_multi)\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\ncoef = pd.Series(reg.coef_, index = X.columns)\n\n\n#regressor = LinearRegression()  \n#regressor.fit(X_train_multi, y_train_multi) #training the algorithm","execution_count":null,"outputs":[]},{"metadata":{"id":"fcFTlVlPXIE2","outputId":"cb687ccd-7a54-4ef9-987a-4eebf7223fe7","trusted":true},"cell_type":"code","source":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","execution_count":null,"outputs":[]},{"metadata":{"id":"hEpr2NZ6y4rB"},"cell_type":"markdown","source":"Feature importance:"},{"metadata":{"id":"YE7ceB4rXN5C","outputId":"25495ac3-c57c-4d4d-ae34-a63e7af9d712","trusted":true},"cell_type":"code","source":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","execution_count":null,"outputs":[]},{"metadata":{"id":"-KjBqpa3y9O3"},"cell_type":"markdown","source":"Columns are chosen according to above Lasso model"},{"metadata":{"id":"Jqw7NSrLXgWO","trusted":true},"cell_type":"code","source":"cols = ['Fly_Light', 'Operation_Initials_Reduced_SC', 'Direct_Flight', 'Operation_Initials_Reduced_EY', 'Economy_Class', 'Passenger_Gender_M', \n        'Inbound_Departure_Airport_Reduced_Unknown', 'Early_Check_In_Status_Early', 'Operation_Channel_TS', 'SWC_FLY']","execution_count":null,"outputs":[]},{"metadata":{"id":"b59e28maYf_f","trusted":true},"cell_type":"code","source":"X_train_multi = X_train_multi[cols]\nX_val_multi = X_val[cols]","execution_count":null,"outputs":[]},{"metadata":{"id":"vFHUiux3zSvo"},"cell_type":"markdown","source":"Chosen columns are used in linear regression:"},{"metadata":{"id":"10Mz6YYyYrSp","trusted":true},"cell_type":"code","source":"regressor = LinearRegression()  \nregressor.fit(X_train_multi, y_train_multi) #training the algorithm\n\nX_val['Prediction2'] = regressor.predict(X_val_multi)","execution_count":null,"outputs":[]},{"metadata":{"id":"MulCixNZjeVa","trusted":true},"cell_type":"code","source":"X_val['Prediction2'] = X_val['Prediction2'].round()\ny_val_multi_pred= X_val['Prediction2']","execution_count":null,"outputs":[]},{"metadata":{"id":"0DNoi_9Jzq-K"},"cell_type":"markdown","source":"Data type is changed to integer:"},{"metadata":{"id":"lenlZDGxmPHM","trusted":true},"cell_type":"code","source":"X_val['Prediction2'] = X_val['Prediction2'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"id":"qnjo-vWj0GXt"},"cell_type":"markdown","source":"Final prediction combining the previus results are encoded in a third column called Prediction_fin"},{"metadata":{"id":"KLzzUCRhkpxP","trusted":true},"cell_type":"code","source":"X_val['Prediction_fin'] = np.where((X_val.Prediction1 == 1), 1, X_val.Prediction2)","execution_count":null,"outputs":[]},{"metadata":{"id":"nniA3k7_lAdm","trusted":true},"cell_type":"code","source":"X_val['Prediction_fin'] = X_val['Prediction_fin'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"id":"vr_0gVKB03Sk"},"cell_type":"markdown","source":"Accuracy check:"},{"metadata":{"id":"aX9BZ7pDWOXL","outputId":"d2ed4f6b-e298-4b1f-a0f2-20f1bac5982c","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nscore = accuracy_score(X_val['Prediction_fin'], y_val)\nscore\n","execution_count":null,"outputs":[]},{"metadata":{"id":"eL4Der4r1TAt"},"cell_type":"markdown","source":"Error etc."},{"metadata":{"id":"481hCUOMMJxg","outputId":"ccde8867-0fae-421d-e507-c84268d7becd","trusted":true},"cell_type":"code","source":"# Calculate the absolute errors\nerrors = abs(X_val['Prediction_fin'] - y_val)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_val)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{"id":"7H05xAUwYusL"},"cell_type":"markdown","source":"## Test and Evaluation\n\n"},{"metadata":{"id":"5yb7Oe9l2PvZ"},"cell_type":"markdown","source":"Applying same staps on the test data"},{"metadata":{"id":"vtU1lhC12391"},"cell_type":"markdown","source":""},{"metadata":{"id":"s5gMeIc025TF","outputId":"6f7db1ed-1044-4b8b-e00c-3149b803fa67","trusted":true},"cell_type":"code","source":"X_test['Prediction1'] = logreg.predict(X_test)\ny_test_log_pred=X_test['Prediction1']","execution_count":null,"outputs":[]},{"metadata":{"id":"TTaSW4cN5XJU","trusted":true},"cell_type":"code","source":"X_test_multi = X_test[cols]","execution_count":null,"outputs":[]},{"metadata":{"id":"xqNIY_ni4Aoj","outputId":"7d678880-141f-4109-e808-36be99bb14fc","trusted":true},"cell_type":"code","source":"X_test['Prediction2'] = regressor.predict(X_test_multi)","execution_count":null,"outputs":[]},{"metadata":{"id":"lzfbHHiq7pdb","outputId":"be808a65-1886-4315-ace3-c95ddcd24c32","trusted":true},"cell_type":"code","source":"X_test['Prediction2'] = X_test['Prediction2'].round()\ny_test_multi_pred= X_test['Prediction2']","execution_count":null,"outputs":[]},{"metadata":{"id":"sZcXqW6w70iH","outputId":"affbff0e-1a63-4c7e-97cb-fd2591ed6527","trusted":true},"cell_type":"code","source":"X_test['Prediction2'] = X_test['Prediction2'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"id":"2OYdYEiX79VF","outputId":"cb98af71-4bcb-4b4e-c429-a1ccddd938c7","trusted":true},"cell_type":"code","source":"X_test['Prediction_finito'] = np.where((X_test.Prediction1 == 1), 1, X_test.Prediction2)","execution_count":null,"outputs":[]},{"metadata":{"id":"Y6U9kMzh8WW_","outputId":"abdaac81-8093-4e90-98ba-afa32c7ea2b7","trusted":true},"cell_type":"code","source":"X_test['Prediction_finito'] = X_test['Prediction_finito'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"id":"47CirK6c8eGd","outputId":"3486282e-4b1c-4ae5-8aed-736d4e99a47a","trusted":true},"cell_type":"code","source":"# Calculate the absolute errors\nerrors = abs(X_test['Prediction_finito'] - y_test)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n# Calculate mean absolute percentage error (MAPE)\nmape = 100 * (errors / y_test)\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","execution_count":null,"outputs":[]},{"metadata":{"id":"bfB_Ran6ZInu"},"cell_type":"markdown","source":"## Prediction\n\non result_df"},{"metadata":{"id":"_9xVp7mm_2u0","trusted":true},"cell_type":"code","source":"result_df = result_df.drop(columns = [\"Departure_YMD_LMT\", \n                                    \"Operation_YMD_LMT\", \n                                    \"Operation_Initials\", \n                                    \"Operation_Airport\",\n                                    \"Inbound_Departure_Airport\",\n                                    \"Outbound_Arrival_Airport\",\n                                    \"Terminal_Name\",\n                                    \"Early_Check_In\",\n                                       \"Operation_Count\"], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"id":"2825neU2AC7d","outputId":"859c4a9b-a300-4671-dade-3ed15d8de3af","trusted":true},"cell_type":"code","source":"result_onehot = result_df.copy()\nfor cols in result_df.columns: #leave as train_df!!!\n  if result_onehot[cols].dtype.name == 'category':\n    print(cols)\n    one_hot = pd.get_dummies(train_df[cols], prefix = cols)\n    result_onehot = result_onehot.drop(cols,axis = 1)\n    result_onehot = result_onehot.join(one_hot)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"0ckSHAWzATaw","trusted":true},"cell_type":"code","source":"result_onehot['Prediction1'] = logreg.predict(result_onehot)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"KVvWZFqqATVO","trusted":true},"cell_type":"code","source":"result_onehot_multi = result_onehot[cols]","execution_count":null,"outputs":[]},{"metadata":{"id":"-AUJ0wd6ATUU","outputId":"df168e43-cb50-480e-81d2-59e77f73b13d","trusted":true},"cell_type":"code","source":"result_onehot['Prediction2'] = regressor.predict(result_onehot_multi)","execution_count":null,"outputs":[]},{"metadata":{"id":"E2NSDVEbZNKJ"},"cell_type":"markdown","source":"## Submission"},{"metadata":{"id":"JO2xXD7aF3Rs"},"cell_type":"markdown","source":"## References\n\n\n1.   [Impute Missing Values](https://jamesrledoux.com/code/imputation)\n2.   [Is it better to drop or impute values from data sets when applying ML, or would it be better to label them as 'missing' for categorical variables?](https://www.quora.com/Is-it-better-to-drop-or-impute-values-from-data-sets-when-applying-ML-or-would-it-be-better-to-label-them-as-missing-for-categorical-variables)\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}