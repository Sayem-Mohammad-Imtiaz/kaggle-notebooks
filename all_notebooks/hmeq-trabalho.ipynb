{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Centro Universitário IESB\n\nPós Graduação em Ciência de Dados\n\nData Mining e Machine Learning II\n\nProfessor Marcos Vinicius Guimarães\n\nFernanda Fernandes Ministério**\n\nObjetivo deste trabalho\nIdentificar as pessoas que possam ter problemas de inadimplência junto aos bancos na modalidade de habitação (Home Equity).\n\nDefinir um modelo que faça predição dos maus pagadores por meio de uma base de dados do Home Equity com aproximadamente 6.000 empréstimos anteriormente concedidos. Podemos usar estas informações identificando clientes que tenham deixado de pagar alguma parcela de empréstimo no passado para treinar modelos de aprendizado de máquina para prever probabilidades de pessoas que poderiam deixar de pagar a modalidade habitação (Home Equity) no futuro baseado em situações anteriores.\n\nAssim vou propor um problema de classificação binária onde o modelo deverá prever se uma pessoa seria um pagador ruim.\n\n\nMetodologia\nA base de dados \"Home Equity\" possui  pessoas e dados de empréstimo de 5.960 empréstimos recentes. Para cada empréstimo existem 12 variáveis. A variável alvo (BAD) indica quando o cliente não pagou o empréstimo (1), e quando ele pagou (0).\n\nSerão utilizados os modelos Random Forest Classifier, XGBosst e XGBoost com auxílio do GridSearchCV para otimização do modelo\n\nDicionário de Dados (em ordem alfabética)\n\nBAD: 1 = client defaulted on loan 0 = loan repaid\n\nCLAGE: Age of oldest trade line in months\n\nCLNO: Number of credit lines\n\nDEBTINC: Debt-to-income ratio\n\nDELINQ: Number of delinquent credit lines\n\nDEROG: Number of major derogatory reports\n\nJOB: Six occupational categories\n\nLOAN: Amount of the loan request\n\nMORTDUE: Amount due on existing mortgage\n\nNINQ: Number of recent credit lines\n\nREASON: DebtCon = debt consolidation ; HomeImp = home improvement\n\nVALUE: Value of current property\n\nYOJ: Years at present job"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importando o dataset\ndf = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando as informações do dataset\ndf.shape, df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observa-se que a maior parte das colunas são valores numéricos"},{"metadata":{"trusted":true},"cell_type":"code","source":"# realizando análise exploratória\n\ndf.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando o percentual de empréstimos não pagos (BAD = 1)\n\nprint(df['BAD'].value_counts())\nprint(df['BAD'].value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando estatísticas básicas dos valores de empréstimos. A média está em 18.607.\n\ndf['LOAN'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazer tratamento dos Dados verificando a existência de missing values ou valores null\n\nMissingValues =df.isnull().sum().rename_axis('Colunas').reset_index(name='Missing Values')\nMissingValues","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# utilizando a biblioteca Pandas Profiling para gerar um report com análise de todas os campos e suas principais estatísticas.\n\nimport pandas_profiling as pp\n\npp.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# avaliação das variáveis numéricas por meio de histogramas\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndf.hist(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observa-se que a base está desbalanceada e que possuímos uma quantidade pequena de maus pagadores (1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um dataframe para empréstimos que não foram pagos\n\ndf_bad = df[df['BAD'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando o Total dos empréstimos não pagos (20.120.400). Este total é relevante para estudar os potenciais maus pagadores.\n\ndf_bad['LOAN'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explorando as informações\ndf['DELINQ'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['LOAN'].sum())\nprint(df[df['DELINQ'] != 0.0]['LOAN'].sum())\nprint(df[df['DELINQ'] == 0.0]['LOAN'].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribuição por profissão\n%matplotlib inline\n\ndf['JOB'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribuição por motivo do empréstimo\n%matplotlib inline\n\ndf['REASON'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observa-se que no gráfico de correlação abaixo as variáveis não apresentam correlação fortes entre si. A melhor correlação apresentada foi entre as variáveis MORTDUE e VALUE (valor da hipotéca devido e o valor da propriedade)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Plotando a correlação\n\n# Aumentando a area do grafico\nf, ax = plt.subplots(figsize=(15,6))\nsns.heatmap(df.corr(), annot=True, fmt='.2f', linecolor='red', ax=ax, lw=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identificando valores de hipoteta devido nulo.\n\ndf[df['MORTDUE'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Substituindo Nan por 0\n\ndf.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# criando uma nova base para proteger a base original\n\ndf_n = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando uma nova coluna onde 0 não é maior e 1 é maior que, para o campo da hipotéca ser maior que o valor da propriedade\n\ndf_n['HIP_M_PROP'] = df_n['VALUE'] - df_n['MORTDUE']\n\nHIP_M_PROP = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# determinar as categorias\nfor valor in df_n['HIP_M_PROP']:\n    if valor <  0.0:\n        HIP_M_PROP.append(1)\n    elif valor >= 0.0:\n        HIP_M_PROP.append(0)\n        \ndf_n['HIP_M_PROP'] = HIP_M_PROP","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando nova coluna com valores 1 (sim) e 0 (não) para definir se o valor do empréstimo é maior que o valor da hipoteca\n\ndf_n['LOAN_M_HIP'] = df_n['LOAN'] - df_n['MORTDUE']\n\nLOAN_M_HIP = []\n\n# determinar as categorias\nfor valor in df_n['LOAN_M_HIP']:\n    if valor <  0.0:\n        LOAN_M_HIP.append(1)\n    elif valor >= 0.0:\n        LOAN_M_HIP.append(0)\n        \ndf_n['LOAN_M_HIP'] = LOAN_M_HIP","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos agora que as correlações de variáveis com a variável resposta BAD não são significativas\nTemos então dois cenários possíveis para predição:\n> pegar todas as variáveis, exceto  'BAD','REASON', 'JOB' e preparar um treinamento para encontrar um padrão que melhor gere um modelo capaz de prever a saída para novos dados. Será adotado X para os valores das entradas (features) e y para os valores das saídas.\n> outra possibilidade é pegar DEBTINC, e analisar a apresentada correlação média com a variável resposta BAD."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df_n.columns.difference(['BAD','REASON','JOB'])\n\nX = df_n[features].values\ny = df_n['BAD'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dividir a base em treino e teste\n\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(df_n.drop('BAD',\n                                                    axis=1),\n                                                    df_n['BAD'],\n                                                    test_size=0.3,\n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# criação das bases e seus tamanhos\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# base de treino\nx_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando o método do scikitlearn para divisão do dataframe de treino em treino e validação\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo a base de treino para teste\n\ntrain, valid = train_test_split(x_train, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# base de validação\nvalid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# árvore de decisão\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifier_dt = DecisionTreeClassifier(random_state=1986,\n                           criterion='gini',\n                           max_depth=3)\nclassifier_dt.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validar modelo\nfrom sklearn.model_selection import cross_val_score\n\nscores_dt = cross_val_score(classifier_dt, X, y,\n                            scoring='accuracy', cv=6)\n\nprint(scores_dt.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observa-se neste caso que a acurácia é ruim"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predição com Ensemble\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier_rf = RandomForestClassifier(random_state=1986,\n                           criterion='gini',\n                           max_depth=10,\n                           n_estimators=30,\n                           n_jobs=-1)\nscores_rf = cross_val_score(classifier_rf, X, y,\n                            scoring='accuracy', cv=6)\n\nprint(scores_rf.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ficou parecido o resultado com a aplicação do método CrossValidation, o que significa que o modelo continua sem boa acurácia."},{"metadata":{"trusted":true},"cell_type":"code","source":"# tentando uma nova modelagem e medindo a importância da features\n\nclassifier_rf.fit(X, y) \n\nfeatures_importance = zip(classifier_rf.feature_importances_, features)\nfor importance, feature in sorted(features_importance, reverse=True):\n    print(\"%s: %f%%\" % (feature, importance*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como o resultado sobre DEBTINC ficou melhor, vamos focar nesta variável como explicativa"},{"metadata":{"trusted":true},"cell_type":"code","source":"# nova modelagem com Variável resposta: BAD e Variável explicativa: DEBTINC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identificando a frequência da variável DEBTINC\n\ndf['DEBTINC'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando os dataframes onde o count é nulo\n\nteste = df[df['DEBTINC'] == 0.0]\n\ntreino = df[df['DEBTINC'] != 0.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treino.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"teste.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modelo RandomForest\n\n# método do scikitlearn para divisão e instanciando o modelo\n\nfrom sklearn.model_selection import train_test_split\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removendo as colunas de resposta\n\nremoved_cols = ['BAD','DEBTINC','JOB','REASON']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criar a lista da colunas de entrada\n\nfeats = [c for c in train.columns if c not in removed_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinamento do modelo com as variáveis de entrada e as de resposta\nrf.fit(treino[feats], treino['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Previsão da variável de teste usando o modelo treinado\nteste['BAD'] = rf.predict(teste[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier_rf = RandomForestClassifier(random_state=1986,\n                           criterion='gini',\n                           max_depth=10,\n                           n_estimators=30,\n                           n_jobs=-1)\nscores_rf = cross_val_score(classifier_rf, X, y,\n                            scoring='accuracy', cv=6)\n\nprint(scores_rf.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Este modelo apresentou um desempenho melhor no percentual de predição.\n# Há uma margem de diferença entre a base primária e a base testada de 10%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificação das previsões\nteste['BAD'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['BAD'].value_counts(normalize=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}