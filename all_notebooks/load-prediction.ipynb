{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport lightgbm as lgb\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport time\n\nimport datetime as datetime\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_file = r'/kaggle/input/create-pickle-for-dataset/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data = pd.read_pickle(os.path.join(path_file, 'df_merged.pickle.gz'))\ndf_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather = pd.read_pickle(os.path.join(path_file, 'df_weather.pickle.gz'))\ndf_weather","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_encode = pd.read_pickle(os.path.join(path_file, 'df_holiday_encode.pickle.gz'))\ndf_holiday_encode","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process dataset (power meter data at 15-mins interval)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Leave columns with keyword of 'kW'\ndf_powerMeter = df_data.loc[:, df_data.columns.str.contains('kW')].copy()\ndf_powerMeter = df_powerMeter.sum(axis=1).rename('total_demand')\ndf_powerMeter = df_powerMeter.resample('H').mean()\ndf_powerMeter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_powerMeter.iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression & visualizations","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The first forecasting model with only time-series features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter.reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\ndf_temp['hour'] = df_temp['Date'].dt.hour\ndf_temp['date'] =pd.to_datetime(df_temp['Date'].dt.date)\n\ndf_temp = df_temp.set_index('Date').drop(['date'],axis=1)\n\ndf_temp = df_temp.rename(columns={'total_demand':'total_demand_meas'})\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Weekly profiles of building energy\ndf_plot = df_temp.copy()\ndf_plot['date'] = pd.to_datetime(df_plot.index.date)\ndf_plot.pivot_table(columns=['weekday','hour'], index='date', values='total_demand_meas').T.plot(figsize=(15,5),color='black',alpha=0.1,legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc['2018-7':'2019-6'].copy()\ntestdata = df_temp.loc['2019-7':].copy()\n\ntrain_labels = traindata['total_demand_meas']\ntest_labels = testdata['total_demand_meas']\n\ntrain_features = traindata.drop('total_demand_meas', axis=1)\ntest_features = testdata.drop('total_demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['total_demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc[testdata.index, 'total_demand_pred'] = testdata['total_demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['total_demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors / test_labels))\nNMBE = 100 * (sum(testdata.dropna()['total_demand_meas'] - testdata.dropna()['total_demand_pred']) / (testdata.dropna()['total_demand_meas'].count() * np.mean(testdata.dropna()['total_demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['total_demand_meas'] - testdata.dropna()['total_demand_pred'])**2) / (testdata.dropna()['total_demand_meas'].count()-1))**(0.5)) / np.mean(testdata.dropna()['total_demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['total_demand_meas'], testdata.dropna()['total_demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['total_demand_meas', 'total_demand_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The second forecasting model with time-series and weather features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter.reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\ndf_temp['hour'] = df_temp['Date'].dt.hour\ndf_temp['date'] =pd.to_datetime(df_temp['Date'].dt.date)\n\n# Add weather features\ndf_temp = df_temp.merge(df_weather.reset_index(), left_on='date', right_on='index')\n\ndf_temp = df_temp.set_index('Date').drop(['date', 'index'],axis=1)\n\ndf_temp = df_temp.rename(columns={'total_demand':'total_demand_meas'})\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot for energy consumptions and outdoor temperature\nplt.figure(figsize=(10,10))\ndf_plot = df_temp.copy()\ndf_plot = df_plot.resample('D').mean()\ndf_plot['weekday/weekend'] = 'weekday'\ndf_plot.loc[df_plot['weekday']>4, 'weekday/weekend'] ='weekend'\n\nax = sns.relplot(x=\"Avg Temp\", y=\"total_demand_meas\", col=\"weekday/weekend\",\n                 kind=\"scatter\", data=df_plot, alpha=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc['2018-7':'2019-6'].copy()\ntestdata = df_temp.loc['2019-7':].copy()\n\ntrain_labels = traindata['total_demand_meas']\ntest_labels = testdata['total_demand_meas']\n\ntrain_features = traindata.drop('total_demand_meas', axis=1)\ntest_features = testdata.drop('total_demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['total_demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc[testdata.index, 'total_demand_pred'] = testdata['total_demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['total_demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors / test_labels))\nNMBE = 100 * (sum(testdata.dropna()['total_demand_meas'] - testdata.dropna()['total_demand_pred']) / (testdata.dropna()['total_demand_meas'].count() * np.mean(testdata.dropna()['total_demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['total_demand_meas'] - testdata.dropna()['total_demand_pred'])**2) / (testdata.dropna()['total_demand_meas'].count()-1))**(0.5)) / np.mean(testdata.dropna()['total_demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['total_demand_meas'], testdata.dropna()['total_demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['total_demand_meas', 'total_demand_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The third forecasting model with time-series, weather, and holiday featuresÂ¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_2018 = pd.read_html('https://www.timeanddate.com/holidays/thailand/2018')[0]\ndf_holiday_2018.columns = df_holiday_2018.columns.get_level_values(0)\ndf_holiday_2018 = df_holiday_2018.dropna(how='all')\ndf_holiday_2018 = df_holiday_2018[['Date', 'Name', 'Type']]\ndf_holiday_2018['Date'] = '2018 ' + df_holiday_2018['Date']\ndf_holiday_2018['Date'] = pd.to_datetime(df_holiday_2018['Date'])\n\ndf_holiday_2019 = pd.read_html('https://www.timeanddate.com/holidays/thailand/2019')[0]\ndf_holiday_2019.columns = df_holiday_2019.columns.get_level_values(0)\ndf_holiday_2019 = df_holiday_2019.dropna(how='all')\ndf_holiday_2019 = df_holiday_2019[['Date', 'Name', 'Type']]\ndf_holiday_2019['Date'] = '2019 ' + df_holiday_2019['Date']\ndf_holiday_2019['Date'] = pd.to_datetime(df_holiday_2019['Date'])\n\ndf_holiday = pd.concat([df_holiday_2018, df_holiday_2019], axis=0, ignore_index=True)\ndf_holiday = df_holiday.drop_duplicates(subset=['Date'])\ndf_holiday = df_holiday.set_index('Date').asfreq('D')\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Name'] = 'weekend'\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Type'] = 'weekend'\ndf_holiday.columns = 'holiday_' + df_holiday.columns\n\ndf_holiday = df_holiday.reset_index()\ndf_holiday = df_holiday.rename(columns={'Date':'date'}) \n\ndf_holiday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_encode = df_holiday.copy()\ndf_holiday_encode[['holiday_Name', 'holiday_Type']] = df_holiday_encode[['holiday_Name', 'holiday_Type']].astype('str').apply(LabelEncoder().fit_transform)\ndf_holiday_encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter.reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\ndf_temp['hour'] = df_temp['Date'].dt.hour\ndf_temp['date'] =pd.to_datetime(df_temp['Date'].dt.date)\n\n# Add weather features\ndf_temp = df_temp.merge(df_weather.reset_index(), left_on='date', right_on='index')\n\n# Add holiday features\ndf_temp = df_temp.merge(df_holiday_encode, on='date')\n\ndf_temp = df_temp.set_index('Date').drop(['date', 'index'],axis=1)\n\ndf_temp = df_temp.rename(columns={'total_demand':'total_demand_meas'})\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc['2018-7':'2019-6'].copy()\ntestdata = df_temp.loc['2019-7':].copy()\n\ntrain_labels = traindata['total_demand_meas']\ntest_labels = testdata['total_demand_meas']\n\ntrain_features = traindata.drop('total_demand_meas', axis=1)\ntest_features = testdata.drop('total_demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['total_demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc[testdata.index, 'total_demand_pred'] = testdata['total_demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['total_demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors / test_labels))\nNMBE = 100 * (sum(testdata.dropna()['total_demand_meas'] - testdata.dropna()['total_demand_pred']) / (testdata.dropna()['total_demand_meas'].count() * np.mean(testdata.dropna()['total_demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['total_demand_meas'] - testdata.dropna()['total_demand_pred'])**2) / (testdata.dropna()['total_demand_meas'].count()-1))**(0.5)) / np.mean(testdata.dropna()['total_demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['total_demand_meas'], testdata.dropna()['total_demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['total_demand_meas', 'total_demand_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Aggregated by different levels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata[['total_demand_meas', 'total_demand_pred']].resample('D').mean().iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata[['total_demand_meas', 'total_demand_pred']].resample('M').mean().iplot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}