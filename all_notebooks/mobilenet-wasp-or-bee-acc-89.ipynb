{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tqdm import tqdm\nimport cv2 as cv\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"main_folder = '../input/bee-vs-wasp/kaggle_bee_vs_wasp/'\ndf = pd.read_csv('../input/bee-vs-wasp/kaggle_bee_vs_wasp/labels.csv')\ndf = df[df.photo_quality==1]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nFrom https://www.kaggle.com/koshirosato/bee-or-wasp-base-line-using-resnet50\n'''\nfor idx in tqdm(df.index):    \n    df.loc[idx,'path']=df.loc[idx,'path'].replace('\\\\', '/') \n    \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df[df.is_final_validation==1].reset_index()\ndf_train = df[df.is_final_validation!=1].reset_index()\ndf_train.shape,df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.label.value_counts().plot.pie(autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"if `df = df[df.photo_quality==1]` dataset doesn't need sampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nFrom https://www.kaggle.com/koshirosato/bee-or-wasp-base-line-using-resnet50\n'''\nimg_size = 225\ndef create_datasets(df, img_size):\n    imgs = []\n    for path in tqdm(df['path']):\n        img = cv.imread(main_folder + path)\n        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n        img = cv.resize(img, (img_size,img_size))\n        imgs.append(img)\n        \n    imgs = np.array(imgs, dtype='float32')\n    imgs = imgs / 255.0\n    df = pd.get_dummies(df['label'])\n    return imgs, df\n\n\ntrain, df_train = create_datasets(df_train, img_size)\ntest, df_test = create_datasets(df_test, img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(layers.Input(shape=(img_size,img_size,3)))\nmodel.add(tf.keras.applications.MobileNetV2(include_top=False,weights=\"imagenet\"))\nmodel.add(layers. GlobalAveragePooling2D())#BatchNormalization()\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dense(32,activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(3,activation='softmax'))\nfor layer in model.layers[:1]:\n    layer.trainable = False\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scheduler(epoch, lr):\n    print(model.optimizer.lr.numpy())\n    if epoch < 5:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\nlr_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('Best_model.h5', monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(train,df_train,batch_size=128,epochs=25,validation_split=0.1,callbacks=[checkpoint_cb,lr_cb],verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n\nfig, axes = plt.subplots(1, 2, figsize=(15,5))\n\naxes[0].plot(epochs, acc, 'r-', label='Training Accuracy')\naxes[0].plot(epochs, val_acc, 'b--', label='Validation Accuracy')\naxes[0].set_title('Training and Validation Accuracy')\naxes[0].legend(loc='best')\n\naxes[1].plot(epochs, loss, 'r-', label='Training Loss')\naxes[1].plot(epochs, val_loss, 'b--', label='Validation Loss')\naxes[1].set_title('Training and Validation Loss')\naxes[1].legend(loc='best')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test,df_test,verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del model\n# import gc\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}