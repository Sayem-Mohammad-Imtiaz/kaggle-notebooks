{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nimport cv2\nimport time\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.layers.normalization import BatchNormalization\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T19:19:18.74508Z","iopub.execute_input":"2021-06-25T19:19:18.74541Z","iopub.status.idle":"2021-06-25T19:19:37.538213Z","shell.execute_reply.started":"2021-06-25T19:19:18.74538Z","shell.execute_reply":"2021-06-25T19:19:37.537432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = pd.read_csv('../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/names.csv')\nnames = names.values\nnp.random.shuffle(names)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:37.541062Z","iopub.execute_input":"2021-06-25T19:19:37.541306Z","iopub.status.idle":"2021-06-25T19:19:37.554001Z","shell.execute_reply.started":"2021-06-25T19:19:37.54128Z","shell.execute_reply":"2021-06-25T19:19:37.553251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nr_cars = 15\nidx_to_name = {x : names[x][0] for x in np.arange(nr_cars)}\nname_to_idx = {x:i for i,x in enumerate(idx_to_name.values())}\nidx_to_name","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:37.555691Z","iopub.execute_input":"2021-06-25T19:19:37.556023Z","iopub.status.idle":"2021-06-25T19:19:37.567917Z","shell.execute_reply.started":"2021-06-25T19:19:37.555986Z","shell.execute_reply":"2021-06-25T19:19:37.566999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/train/'\ntest_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/test/'","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:37.569474Z","iopub.execute_input":"2021-06-25T19:19:37.569874Z","iopub.status.idle":"2021-06-25T19:19:37.575223Z","shell.execute_reply.started":"2021-06-25T19:19:37.569838Z","shell.execute_reply":"2021-06-25T19:19:37.574535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(path):\n    train = []\n    for i, name in enumerate(name_to_idx.keys()):\n        new_path = path + name + \"/\"\n        [train.append([i, cv2.resize(cv2.imread(img), (244,244), interpolation = cv2.INTER_AREA)]) for img in glob.glob(new_path + \"*.jpg\")]\n    return np.array(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:37.576551Z","iopub.execute_input":"2021-06-25T19:19:37.576923Z","iopub.status.idle":"2021-06-25T19:19:37.583665Z","shell.execute_reply.started":"2021-06-25T19:19:37.57689Z","shell.execute_reply":"2021-06-25T19:19:37.58283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = get_data(train_path)\ntest = get_data(test_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:37.584695Z","iopub.execute_input":"2021-06-25T19:19:37.585616Z","iopub.status.idle":"2021-06-25T19:19:51.07725Z","shell.execute_reply.started":"2021-06-25T19:19:37.58558Z","shell.execute_reply":"2021-06-25T19:19:51.07644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr = np.concatenate(train[:,1], axis=0).reshape(len(train), 244, 244, 3)\nX_tr = X_tr / 255.0\nX_tr = X_tr.astype('float32')\ny_tr = train[:,0]\ny_tr = np.eye(len(idx_to_name))[list(y_tr)]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:51.078558Z","iopub.execute_input":"2021-06-25T19:19:51.078902Z","iopub.status.idle":"2021-06-25T19:19:51.556096Z","shell.execute_reply.started":"2021-06-25T19:19:51.078865Z","shell.execute_reply":"2021-06-25T19:19:51.555268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size = 0.15, random_state = 42)\nprint(\"x_train shape = \",x_train.shape)\nprint(\"y_train shape = \",y_train.shape)\nprint(\"x_val shape = \",x_val.shape)\nprint(\"y_val shape = \",y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:51.558115Z","iopub.execute_input":"2021-06-25T19:19:51.558427Z","iopub.status.idle":"2021-06-25T19:19:51.693591Z","shell.execute_reply.started":"2021-06-25T19:19:51.558393Z","shell.execute_reply":"2021-06-25T19:19:51.692578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential(name=\"Alexnet\")\n#1 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\n#2 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\n#3 layer (conv + batchnorm)\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(BatchNormalization())\n#4 layer (conv + batchnorm)\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(BatchNormalization())\n#5 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\n#1 dense layer\nmodel.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#2 dense layer\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#3 dense layer\nmodel.add(Dense(1000,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#output layer\nmodel.add(Dense(15,activation=\"softmax\"))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:51.695231Z","iopub.execute_input":"2021-06-25T19:19:51.69559Z","iopub.status.idle":"2021-06-25T19:19:54.113944Z","shell.execute_reply.started":"2021-06-25T19:19:51.695554Z","shell.execute_reply":"2021-06-25T19:19:54.113154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate by 0.1 when the validation error plateaus\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n \n# set the SGD optimizer with lr of 0.01 and momentum of 0.9\noptimizer = SGD(lr = 0.01, momentum = 0.9)\n \n# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:19:54.116757Z","iopub.execute_input":"2021-06-25T19:19:54.117003Z","iopub.status.idle":"2021-06-25T19:19:54.132804Z","shell.execute_reply.started":"2021-06-25T19:19:54.116978Z","shell.execute_reply":"2021-06-25T19:19:54.131885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\n# call the reduce_lr value using callbacks in the training method\nhistory = model.fit(x_train, y_train, epochs=25, validation_data=(x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:23:42.443251Z","iopub.execute_input":"2021-06-25T19:23:42.443617Z","iopub.status.idle":"2021-06-25T19:23:53.070059Z","shell.execute_reply.started":"2021-06-25T19:23:42.443584Z","shell.execute_reply":"2021-06-25T19:23:53.069179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 100) # set the vertical range to [0-1]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:24:22.276876Z","iopub.execute_input":"2021-06-25T19:24:22.277197Z","iopub.status.idle":"2021-06-25T19:24:22.514762Z","shell.execute_reply.started":"2021-06-25T19:24:22.277167Z","shell.execute_reply":"2021-06-25T19:24:22.513781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nDefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n padding=\"SAME\", use_bias=False)\nclass ResidualUnit(keras.layers.Layer):\n def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n     super().__init__(**kwargs)\n     self.activation = keras.activations.get(activation)\n     self.main_layers = [\n         DefaultConv2D(filters, strides=strides),\n         keras.layers.BatchNormalization(),\n         self.activation,\n         DefaultConv2D(filters),\n         keras.layers.BatchNormalization()]\n     self.skip_layers = []\n     if strides > 1:\n         self.skip_layers = [\n             DefaultConv2D(filters, kernel_size=1, strides=strides),\n             keras.layers.BatchNormalization()]\n def call(self, inputs):\n     Z = inputs\n     for layer in self.main_layers:\n         Z = layer(Z)\n     skip_Z = inputs\n     for layer in self.skip_layers:\n        skip_Z = layer(skip_Z)\n     return self.activation(Z + skip_Z)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:27:15.507783Z","iopub.execute_input":"2021-06-25T19:27:15.508139Z","iopub.status.idle":"2021-06-25T19:27:15.516066Z","shell.execute_reply.started":"2021-06-25T19:27:15.508109Z","shell.execute_reply":"2021-06-25T19:27:15.51519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = keras.models.Sequential(name=\"Resnet34\")\nmodel2.add(DefaultConv2D(64, kernel_size=7, strides=2,\n input_shape=[224, 224, 3]))\nmodel2.add(keras.layers.BatchNormalization())\nmodel2.add(keras.layers.Activation(\"relu\"))\nmodel2.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\nprev_filters = 64\nfor filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n strides = 1 if filters == prev_filters else 2\n model2.add(ResidualUnit(filters, strides=strides))\n prev_filters = filters\nmodel2.add(keras.layers.GlobalAvgPool2D())\nmodel2.add(keras.layers.Flatten())\nmodel2.add(keras.layers.Dense(15, activation=\"softmax\"))\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:32:57.436767Z","iopub.execute_input":"2021-06-25T19:32:57.437079Z","iopub.status.idle":"2021-06-25T19:32:58.007089Z","shell.execute_reply.started":"2021-06-25T19:32:57.437048Z","shell.execute_reply":"2021-06-25T19:32:58.006275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate by 0.1 when the validation error plateaus\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n \n# set the SGD optimizer with lr of 0.01 and momentum of 0.9\noptimizer = SGD(lr = 0.001, momentum = 0.9)\n # compile the model\nmodel2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nhistory = model2.fit(x_train, y_train,\n validation_data=(x_val, y_val),\n epochs=25)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:35:21.54941Z","iopub.execute_input":"2021-06-25T19:35:21.549782Z","iopub.status.idle":"2021-06-25T19:35:34.621364Z","shell.execute_reply.started":"2021-06-25T19:35:21.549751Z","shell.execute_reply":"2021-06-25T19:35:34.620549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 10) # set the vertical range to [0-1]\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T19:36:10.050899Z","iopub.execute_input":"2021-06-25T19:36:10.051243Z","iopub.status.idle":"2021-06-25T19:36:10.223232Z","shell.execute_reply.started":"2021-06-25T19:36:10.05121Z","shell.execute_reply":"2021-06-25T19:36:10.222479Z"},"trusted":true},"execution_count":null,"outputs":[]}]}