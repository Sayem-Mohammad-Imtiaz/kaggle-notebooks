{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Understanding data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"spam = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\", encoding='ISO-8859-1')\n\nprint(spam.shape)\nspam.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop unusless columns & renaming the rest\nspam=spam.iloc[:,:2]\nprint(spam.shape)\nspam.columns=['label','sms']\nspam.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for null\nspam.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam.groupby('label').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam['len']=spam.sms.apply(len)\nspam.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(20,10))\n\n\nsns.distplot(spam[spam['label']=='ham']['len'], ax=ax[0]);\nax[0].set_title('Ham SMS')\n\nsns.distplot(spam[spam['label']=='spam']['len'], ax=ax[1],color='r');\nax[1].set_title('Spam SMS')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looks like lenght is a key feature for spam detection!\n\nspam.groupby('label')['len'].describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see if there is wording difference in a first view:\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef word_cloud(label):\n    words = ''\n    for msg in spam[spam['label'] == label]['sms']:\n        words += msg + ' '\n    wordcloud = WordCloud(width=600, height=400).generate(words)\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.title(label)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud('spam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud('ham')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"spam['binary_labels']=spam['label'].map({'ham':0,'spam':1})\nspam.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nnlp = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sms_process(sms_text,stem=False):\n    text=nlp(sms_text)\n    d=[]\n    for token in text:\n        if not token.is_stop and not token.pos_=='PUNCT':\n            if stem==True:\n                token=token.lemma_.lower()\n            else:\n                token=token.lower_\n            d.append(token)\n    return ' '.join(d)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_process('HELLO. i am running the fuck .',stem=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_process('HELLO. i am running the fuck .')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam['sms_feat']=spam['sms'].apply(sms_process)\nspam['sms_feat_lem']=spam['sms'].apply(lambda x: sms_process(x,stem=True))\n\nspam.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets try different data processing ways!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer\n\ntf_idf=TfidfVectorizer(decode_error='ignore')\n\ncount_vector=CountVectorizer(decode_error='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TF-IDF\nX_tfidf= tf_idf.fit_transform(spam['sms_feat'])\nX_tfidf_lem= tf_idf.fit_transform(spam['sms_feat_lem'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#COUNT VECT\nX_count=count_vector.fit_transform(spam['sms_feat'])\nX_count_lem=count_vector.fit_transform(spam['sms_feat_lem'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TRAIN TEST SPLIT:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=spam['binary_labels'].values\nY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_tf,X_test_tf,y_train_tf,y_test_tf = train_test_split(X_tfidf,Y,test_size=0.2,random_state=42)\n\nX_train_tf_lem,X_test_tf_lem,y_train_tf_lem,y_test_tf_lem = train_test_split(X_tfidf_lem,Y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_c,X_test_c,y_train_c,y_test_c = train_test_split(X_count,Y,test_size=0.2,random_state=42)\n\nX_train_c_lem,X_test_c_lem,y_train_c_lem,y_test_c_lem = train_test_split(X_count_lem,Y,test_size=0.2,random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets compare different algorithms"},{"metadata":{},"cell_type":"markdown","source":"Some algorithms for text classification handling not much data:\n\nhttps://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n#first trying with default settings and same random seed\n\nalg= [SVC(random_state=42,gamma='scale'),\n      LogisticRegression(random_state=42),\n      MultinomialNB(),\n      DecisionTreeClassifier(random_state=42),\n      KNeighborsClassifier(),\n      RandomForestClassifier(random_state=42)]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef train_alg(algorithm,X_train_df,X_test_df,Y_train_df,Y_test_df):\n    algorithm.fit(X_train_df,Y_train_df)\n    y_pred=algorithm.predict(X_test_df)\n    return accuracy_score(y_pred,Y_test_df)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alg_name=[]\nacc_scores=[]\n\nfor item in alg:\n    alg_name.append(item.__class__.__name__)\n    acc_scores.append(train_alg(item,X_train_tf,X_test_tf,y_train_tf,y_test_tf))\n    df_tfidf=pd.DataFrame(index=alg_name,data=acc_scores,columns=['acc_scores'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alg_name=[]\nacc_scores2=[]\n\nfor item in alg:\n    alg_name.append(item.__class__.__name__)\n    acc_scores2.append(train_alg(item,X_train_tf_lem,X_test_tf_lem,y_train_tf_lem,y_test_tf_lem))\n    df_tfidf_lem=pd.DataFrame(index=alg_name,data=acc_scores2,columns=['acc_scores2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alg_name=[]\nacc_scores3=[]\n\nfor item in alg:\n    alg_name.append(item.__class__.__name__)\n    acc_scores3.append(train_alg(item,X_train_c,X_test_c,y_train_c,y_test_c))\n    df_count=pd.DataFrame(index=alg_name,data=acc_scores3,columns=['acc_scores3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alg_name=[]\nacc_scores4=[]\n\nfor item in alg:\n    alg_name.append(item.__class__.__name__)\n    acc_scores4.append(train_alg(item,X_train_c_lem,X_test_c_lem,y_train_c_lem,y_test_c_lem))\n    df_count_lem=pd.DataFrame(index=alg_name,data=acc_scores4,columns=['acc_scores4'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores=pd.concat([df_tfidf,df_tfidf_lem,df_count,df_count_lem],axis=1)\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.max().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The better results were obtain with Count Vectorizer and lemmatization. And the better algorithm is Multinomial NB.\nThen SVC and Log Reg. "},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.acc_scores4.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets do Hyperparameter Tuning for our best algorithms:"},{"metadata":{},"cell_type":"markdown","source":"## 1-SVC:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparameters={'kernel':['linear','rbf','sigmoid'],\n           'C': [0.001,0.01,0.1,1,10,20,50,100]\n           }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\ngrid_search=GridSearchCV(SVC(random_state=42,gamma='scale'),parameters,cv=5,verbose=True)\n\nt0=datetime.now()\ngrid_search.fit(X_train_c_lem,y_train_c_lem)\nprint('duration:',datetime.now()-t0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nsvc_f=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='linear', max_iter=-1, probability=False, random_state=42,\n    shrinking=True, tol=0.001, verbose=False)\n\nsvc_f.fit(X_train_c_lem,y_train_c_lem)\ny_svc_pred=svc_f.predict(X_test_c_lem)\nprint('Accuracy:',accuracy_score(y_svc_pred,y_test_c_lem))\nprint(classification_report(y_svc_pred,y_test_c_lem))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_svc_pred,y_test_c_lem))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2-Multinomial Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_nb={'alpha':[0.001,0.01,0.1,0.2,1,2,3,4,5,6,7,10,100]}\n\ngrid_search_nb=GridSearchCV(MultinomialNB(),param_nb,cv=5,verbose=True)\n\nt0=datetime.now()\ngrid_search_nb.fit(X_train_c,y_train_c)\nprint('duration:',datetime.now()-t0)\n\nprint(grid_search_nb.best_params_)\n\ngrid_search_nb.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MNB=MultinomialNB(alpha=3, class_prior=None, fit_prior=True)\n\nMNB.fit(X_train_c,y_train_c)\ny_mnb_pred=MNB.predict(X_test_c)\n\nprint('Accuracy:',accuracy_score(y_mnb_pred,y_test_c))\nprint(classification_report(y_mnb_pred,y_test_c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_mnb_pred,y_test_c))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}