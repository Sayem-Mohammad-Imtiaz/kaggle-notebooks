{"cells":[{"metadata":{"_cell_guid":"c69add83-09b7-4f11-b264-4e4f67412a09","_uuid":"88d2fedfcbf27d1f653da55a3119b9e033068168"},"cell_type":"markdown","source":"# Neural nets as Sudoku solvers\n\nSince the dataset was initially created for neural-nets, I focus on this approach. Obviously, there are other ways to solve Sudoku puzzle, some of them are way more intuitive than neural-nets. However, it was an opportunity to get a first hands-on with Keras framework !\n\nI read the https://github.com/Kyubyong/sudoku to see if CNNs can crack Sudoku puzzles. \nI was wondering if we could achieve similar results with a simpler neural net architecture.\n\nI decided to dig more in the direction of the following tip Kyubyong mentionned about predicting :\n> I use a simple trick in inference. Instead of cracking the whole blanks all at once, I fill in a single blank where the prediction is the most probable among the all predictions.\n\nI used the same trick but in **both prediction phase AND training phase.**\nOne of my workmate came up with this idea. Thanks to him !\n\nIn a nutshell : \n* **step 1 - Calibration**: train network to reproduce a correct grid identically.\n* **step 2 - Pull off** : for each training quizz, pull off one digit, and train to recover it.\n* **step 3 - pull off one more**: pull off 2 digits (the first one may be different than *step 2*).\n* **...**\n* **penultimate step**: pull off a reasonible number off digits to build a realistic Sudoku grid (arround 50)\n* **final step**: Predict smartly. Take a quizz, get predictions, place the digit which the network is more confident with to complete one single blank. Then feed the new quizz (with one blank less) into the network again. And so on until there is no more blank.\n\nIt works pretty well, with a final **99.7 % accuracy**. Feel free to fine-tune the model and share your results :).\n\nMerry end of the year !\n\nDithyrambe\n\n*NOTE : Training the network is quite long, you'll have to run the notebook on your environment since Kaggle kills it after 3600 sec*"},{"metadata":{"_cell_guid":"929f77d4-34ab-4866-9791-2cb9463be069","_uuid":"5a67ab391ffaa9e6a5d0dddbe36293af7b7b695a","collapsed":true,"trusted":false},"cell_type":"code","source":"# imports\nimport numpy as np\nimport pandas as pd\n\nfrom keras import Model, Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Dropout, Flatten, Input\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e1280c7e-859c-4167-9911-96d9a6f37eb4","_uuid":"6e2c44b7dd8880110a9673d866f07a7f1bf2b59c"},"cell_type":"markdown","source":"Define some useful functions. Docstrings should be enough for explanations. The whole trick is in the `batch_smart_solve` function."},{"metadata":{"_cell_guid":"3fe08b59-de4f-40ff-8144-a8cab73533a4","_uuid":"58458c047d5a801973815efe3abd0dc2bbb99b98","collapsed":true,"trusted":false},"cell_type":"code","source":"def load_data(nb_train=40000, nb_test=10000, full=False):\n    \"\"\"\n    Function to load data in the keras way.\n    \n    Parameters\n    ----------\n    nb_train (int): Number of training examples\n    nb_test (int): Number of testing examples\n    full (bool): If True, whole csv will be loaded, nb_test will be ignored\n    \n    Returns\n    -------\n    Xtrain, ytrain (np.array, np.array),\n        shapes (nb_train, 9, 9), (nb_train, 9, 9): Training samples\n    Xtest, ytest (np.array, np.array), \n        shapes (nb_test, 9, 9), (nb_test, 9, 9): Testing samples\n    \"\"\"\n    # if full is true, load the whole dataset\n    if full:\n        sudokus = pd.read_csv('../input/sudoku.csv').values\n    else:\n        sudokus = next(\n            pd.read_csv('../input/sudoku.csv', chunksize=(nb_train + nb_test))\n        ).values\n        \n    quizzes, solutions = sudokus.T\n    flatX = np.array([np.reshape([int(d) for d in flatten_grid], (9, 9))\n                      for flatten_grid in quizzes])\n    flaty = np.array([np.reshape([int(d) for d in flatten_grid], (9, 9))\n                      for flatten_grid in solutions])\n    \n    return (flatX[:nb_train], flaty[:nb_train]), (flatX[nb_train:], flaty[nb_train:])\n\n\ndef diff(grids_true, grids_pred):\n    \"\"\"\n    This function shows how well predicted quizzes fit to actual solutions.\n    It will store sum of differences for each pair (solution, guess)\n    \n    Parameters\n    ----------\n    grids_true (np.array), shape (?, 9, 9): Real solutions to guess in the digit repesentation\n    grids_pred (np.array), shape (?, 9, 9): Guesses\n    \n    Returns\n    -------\n    diff (np.array), shape (?,): Number of differences for each pair (solution, guess)\n    \"\"\"\n    return (grids_true != grids_pred).sum((1, 2))\n\n\ndef delete_digits(X, n_delet=1):\n    \"\"\"\n    This function is used to create sudoku quizzes from solutions\n    \n    Parameters\n    ----------\n    X (np.array), shape (?, 9, 9, 9|10): input solutions grids.\n    n_delet (integer): max number of digit to suppress from original solutions\n    \n    Returns\n    -------\n    grids: np.array of grids to guess in one-hot way. Shape: (?, 9, 9, 10)\n    \"\"\"\n    grids = X.argmax(3)  # get the grid in a (9, 9) integer shape\n    for grid in grids:\n        grid.flat[np.random.randint(0, 81, n_delet)] = 0  # generate blanks (replace = True)\n        \n    return to_categorical(grids)\n\n\ndef batch_smart_solve(grids, solver):\n    \"\"\"\n    NOTE : This function is ugly, feel free to optimize the code ...\n    \n    This function solves quizzes in the \"smart\" way. \n    It will fill blanks one after the other. Each time a digit is filled, \n    the new grid will be fed again to the solver to predict the next digit. \n    Again and again, until there is no more blank\n    \n    Parameters\n    ----------\n    grids (np.array), shape (?, 9, 9): Batch of quizzes to solve (smartly ;))\n    solver (keras.model): The neural net solver\n    \n    Returns\n    -------\n    grids (np.array), shape (?, 9, 9): Smartly solved quizzes.\n    \"\"\"\n    grids = grids.copy()\n    for _ in range((grids == 0).sum((1, 2)).max()):\n        preds = np.array(solver.predict(to_categorical(grids)))  # get predictions\n        probs = preds.max(2).T  # get highest probability for each 81 digit to predict\n        values = preds.argmax(2).T + 1  # get corresponding values\n        zeros = (grids == 0).reshape((grids.shape[0], 81))  # get blank positions\n\n        for grid, prob, value, zero in zip(grids, probs, values, zeros):\n            if any(zero):  # don't try to fill already completed grid\n                where = np.where(zero)[0]  # focus on blanks only\n                confidence_position = where[prob[zero].argmax()]  # best score FOR A ZERO VALUE (confident blank)\n                confidence_value = value[confidence_position]  # get corresponding value\n                grid.flat[confidence_position] = confidence_value  # fill digit inplace\n    return grids","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6721589d-7646-40bc-be27-c03b43f656ff","_uuid":"8ad6b3d894a4924d6fb456f116bb02b3a6688f94"},"cell_type":"markdown","source":"### Prepare data for the training phase.\n\nSince we built a `delete_digits` function, we will create our own training set from `ytrain` directly.\nAlso note that we don't want targets to be (9, 9, 10) shaped. Since predicting zeros is useless ... we want to FILL zeros"},{"metadata":{"_cell_guid":"dec29252-c08b-4df6-bee9-ca7f3d9a74b4","_uuid":"f66ac6c0b5776900166ee365803a5d29aa2b7de8","collapsed":true,"trusted":false},"cell_type":"code","source":"input_shape = (9, 9, 10)\n(_, ytrain), (Xtest, ytest) = load_data()  # We won't use _. We will work directly with ytrain\n\n# one-hot-encoding --> shapes become :\n# (?, 9, 9, 10) for Xs\n# (?, 9, 9, 9) for ys\nXtrain = to_categorical(ytrain).astype('float32')  # from ytrain cause we will creates quizzes from solusions\nXtest = to_categorical(Xtest).astype('float32')\n\nytrain = to_categorical(ytrain-1).astype('float32') # (y - 1) because we \nytest = to_categorical(ytest-1).astype('float32')   # don't want to predict zeros","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fff74434-5360-4ac7-ae4d-2cffd2b4730b","_uuid":"72a8851979580b3eb1db0df95640aaebb463aa8b"},"cell_type":"markdown","source":"### Lets now define the keras model\nIt consists in a simple 2 `Dense` layers and 81 `Dense` output layer (one for each digits to predict)."},{"metadata":{"_cell_guid":"249609bb-9340-4b7c-840c-6f14940296f2","_uuid":"3ac959c35620ad3de9a69ea25769916b0339388f","collapsed":true,"trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=input_shape))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\n\ngrid = Input(shape=input_shape)  # inputs\nfeatures = model(grid)  # commons features\n\n# define one Dense layer for each of the digit we want to predict\ndigit_placeholders = [\n    Dense(9, activation='softmax')(features)\n    for i in range(81)\n]\n\nsolver = Model(grid, digit_placeholders)  # build the whole model\nsolver.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d2a8e6b1-b66a-4e3d-be63-911b0187fced","_uuid":"6c57e818173fbb207d03f60ba7dd0d2f14c70fab"},"cell_type":"markdown","source":"### Train model to output solution from a solution.\nThis is part of the trick. The idea comes from a workmate. Thanks to him.\nThe idea is to make the network outputs the solution for the easiest quizz. That is to say ... the solution itself\n\n***solver(solution) &rarr; solution***\n\nThis will calibrate weights to reproduce the grid (as auto-encoders do ?)."},{"metadata":{"_cell_guid":"777277c5-c04f-4ff0-be57-bb03e6d73543","_uuid":"c6ac71ad587e5e69915e21a4b4438156493b53bb","collapsed":true,"trusted":false},"cell_type":"code","source":"solver.fit(\n    delete_digits(Xtrain, 0),  # we don't delete any digit for now\n    [ytrain[:, i, j, :] for i in range(9) for j in range(9)],  # each digit of solution\n    batch_size=128,\n    epochs=1,  # 1 epoch should be enough for the task\n    verbose=1,\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c64585a0-6544-49bf-8ad5-dfbd8b7f2a1d","_uuid":"5d3795f334aed71459fd34ee499a3c17071057c7"},"cell_type":"markdown","source":"### Train model to guess something harder ... and harder ... and harder. One drop at a time.\nHere we will track validation loss to avoid over fitting\n\nFirst, we will pull off *a single* digit from the solution. This is quite a simple quizz to guess.\nWe will train the network until it overfits\n\nNext, lets pull off 2 of them, ... then 3, ... then 4, and so on since we reach hard enough grid with around 55 missing digits."},{"metadata":{"_cell_guid":"19566367-f572-4806-888f-fa7f57630ce0","_uuid":"10663bb7dec58680bc21973820b318828671b1b8","collapsed":true,"trusted":false},"cell_type":"code","source":"early_stop = EarlyStopping(patience=2, verbose=1)\n\ni = 1\nfor nb_epochs, nb_delete in zip(\n        [1, 2, 3, 4, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],  # epochs for each round\n        [1, 2, 3, 4, 6, 8, 10, 12, 15, 20, 25, 30, 35, 40, 45, 50, 55]  # digit to pull off\n):\n    print('Pass n° {} ...'.format(i))\n    i += 1\n    \n    solver.fit(\n        delete_digits(Xtrain, nb_delete),  # delete digits from training sample\n        [ytrain[:, i, j, :] for i in range(9) for j in range(9)],\n        validation_data=(\n            delete_digits(Xtrain, nb_delete), # delete same amount of digit from validation sample\n            [ytrain[:, i, j, :] for i in range(9) for j in range(9)]),\n        batch_size=128,\n        epochs=nb_epochs,\n        verbose=1,\n        callbacks=[early_stop]\n    )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27aa4dd7-922c-4054-becc-121e67f4d043","_uuid":"39f84ab35f64c89007bd7016e8d6627ff757dba3"},"cell_type":"markdown","source":"### Evaluate solver"},{"metadata":{"_cell_guid":"3a8190a4-c8f2-429a-9654-b6d31670ca82","_uuid":"a78823090db3e7c44340204f260c0cc4aeb49094","collapsed":true,"trusted":false},"cell_type":"code","source":"quizzes = Xtest.argmax(3)  # quizzes in the (?, 9, 9) shape. From the test set\ntrue_grids = ytest.argmax(3) + 1  # true solutions dont forget to add 1 \nsmart_guesses = batch_smart_solve(quizzes, solver)  # make smart guesses !\n\ndeltas = diff(true_grids, smart_guesses)  # get number of errors on each quizz\naccuracy = (deltas == 0).mean()  # portion of correct solved quizzes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3cb047af-66ca-43c0-a764-c368facbe6f4","_uuid":"90760b6bd536f12cca24fe0cc1f48551b092b9e6","collapsed":true,"trusted":false},"cell_type":"code","source":"print(\n\"\"\"\nGrid solved:\\t {}\nCorrect ones:\\t {}\nAccuracy:\\t {}\n\"\"\".format(\ndeltas.shape[0], (deltas==0).sum(), accuracy\n)\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"710318bc-0130-4367-ab61-8fd97cb0546b","_uuid":"c8b8bf03f03d82dc83a479edf600d05642301100"},"cell_type":"markdown","source":"Thanks for reading me :)"}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}