{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SQL and Python practice\n\n## First off: Congrats on the job interview! ðŸŽ‰ðŸŽŠ\n\n![](https://i.gifer.com/7WZ0.gif)\n\nIn this tutorial, we will put our practice on all the basics SQL questions before diving into data manipulation using pandas in python. It's alright if you can't answer any of the questions (including questions in the upcoming interview). What's important is the ability to convey your thoughts and ideas to the interviewer and let them understand your thought process. Company will hire someone who can convey their ideas across complex topics so don't worry about not understanding some questions! ","metadata":{}},{"cell_type":"markdown","source":"### Step 1: Run the code below to import the required packages and functions to run SQL queries.","metadata":{}},{"cell_type":"code","source":"# Import the required packages\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Connecting to database.sqlite file\nconn = sqlite3.connect(\"../input/sf-salaries/database.sqlite\")\n#Function to display the query result as a dataframe\ndef query_result(query):\n    cursor = conn.cursor()#creating a cursor object to run the query\n    cursor.execute(query) #execute the query pass as an argument to this function\n    df = pd.DataFrame(cursor.fetchall())#fetching the results (raw result is a list) and converting it to dataframe\n    #SQLite query result doesn't return column names of table. So we get the column names from the description of cursor \n    df.columns = [col_name[0] for col_name in cursor.description]\n    cursor.close()\n    return df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Now let's run some SQL query!\nAs you can see below we select all the columns from the Salaries table. Usually what happen is you will import the required data from the database into your IDE (Rstudio, Pycharm, Jupyter notebook, etc) and use Python or R to make some data manipulation. Some may ask if we can just directly import **ALL** the data from SQL database and do the required cleaning using Python or R. Yes you can do that if **your data size is small** and even so it's a bad practice. Ideally, you want to only import the required data you need in SQL and **if possible, do the required filtering and cleaning on SQL** before importing them to your IDE.  ","metadata":{}},{"cell_type":"code","source":"all_data = query_result(\"SELECT * FROM Salaries;\")\nall_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Select the columns you think are important to your analysis.\nI will answer this one for you this time. The remaining question you will need to work out on your own.\nHere, I choose all the columns except id.","metadata":{}},{"cell_type":"code","source":"df = query_result(\"SELECT EmployeeName, JobTitle, BasePay, OvertimePay, OtherPay, Benefits, TotalPay, TotalPayBenefits, Year, Notes, Agency, Status FROM Salaries;\")\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Get rid of those rows with \"Not provided\" and 0.00 data using SQL\nHere, use a where clause.","metadata":{}},{"cell_type":"code","source":"# Remove Not provided and 0.00 from the data\ndf <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 5: Identify how many unique job titles are there\nHint: Use distinct","metadata":{}},{"cell_type":"code","source":"# Identify how many unique job titles\ndf <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 6: Identify how many jobs appear each year from 2011 to 2014. Generate a line plot using Matplotlib to show the trend. Explain what kind of trend are we observing.\nHint: Use group by and count","metadata":{}},{"cell_type":"code","source":"df <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 7: Identify how many times the word \"MACHINE\" appears in the JobTitle column.\nHint: Use Like","metadata":{}},{"cell_type":"code","source":"df <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 8: Calculate the average total pay for each year and evaluate the trend using a line plot.","metadata":{}},{"cell_type":"code","source":"df <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 9: Identify the top 10 jobs with the highest base pay. Plot them using a barplot.","metadata":{}},{"cell_type":"code","source":"df <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 10: Identify the top 10 jobs with the lowest base pay. Plot them using a barplot.","metadata":{}},{"cell_type":"code","source":"df <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 11: Identify the rows with the terms \"junior\", \"senior\" and \"chief\" and compare their average salary using a boxplot.","metadata":{}},{"cell_type":"code","source":"df <- query_result(\"\")\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pandas data manipulation\nHere, for convinient sake, we will import all the column except for ID in the SQL database and assign it to a variable call, all_data.","metadata":{}},{"cell_type":"code","source":"# Run this and don't change anything.\nall_data = query_result(\"SELECT EmployeeName, JobTitle, BasePay, OvertimePay, OtherPay, Benefits, TotalPay, TotalPayBenefits, Year, Notes, Agency, Status FROM Salaries;\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 1: Lets get started with some data manipulation using pandas. Use it on the all_data variable as assigned above.\nRemove rows with \"Not provided\" and 0.00 using pandas solution","metadata":{}},{"cell_type":"code","source":"# Enter code here\nclean_data = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Identify EmployeeName that hold multiple positions over the 4 years. Use it on the clean_data variable assigned in Step 1, where you cleaned off all the redundant data.","metadata":{}},{"cell_type":"code","source":"# Enter code here","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Identify EmployeeName that only hold a single position over the 4 years","metadata":{}},{"cell_type":"code","source":"# Enter code here.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 4: Identify all unique job titles","metadata":{}},{"cell_type":"code","source":"# Enter code here","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 5: Identify the top 10 common jobs ","metadata":{}},{"cell_type":"code","source":"# Enter code here","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 6: Identify the top 10 best paying jobs (based on base pay only)","metadata":{}},{"cell_type":"code","source":"# Enter code here.","metadata":{},"execution_count":null,"outputs":[]}]}