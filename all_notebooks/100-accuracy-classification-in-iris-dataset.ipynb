{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IRIS DATASET \nExploring Iris dataset through different methods. \n\n1. Plotting various features against their categories\n3. Linear Regression \n4. Correlation \n4. Decision Tree Classification \n5. Accuracy Measurement"},{"metadata":{},"cell_type":"markdown","source":"Importing necessary libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nCreating a Pandas DataFrame from a CSV file<br></p>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/Iris.csv\")\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning \nLet's look for any null values to find out whether there needs to be null values. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the ID column\ndata.drop('Id',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns\ncols = list(data.columns)\ncols\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, there are no null values in this data. Hence, we do not need to perform data cleaning. "},{"metadata":{},"cell_type":"markdown","source":"## Scaling the values ( Data Normalisation) "},{"metadata":{},"cell_type":"markdown","source":"We will use the min - max method to scale the values down "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"range = data[\"SepalLengthCm\"].max() - data[\"SepalLengthCm\"].min()\nrange","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"SepalLengthCm\"] = (data[\"SepalLengthCm\"] - data[\"SepalLengthCm\"].min())/range\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"SepalLengthCm\"] = data[\"SepalLengthCm\"] / data[\"SepalLengthCm\"].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reverting \nI reverted back to the same values to avoid major scale down and maintain some variance to allow for distinguishable features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/Iris.csv\")\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting \n\nLet's plot scatter plots to see the differences in the different features across different Species "},{"metadata":{"trusted":true},"cell_type":"code","source":"group_names = data['Species'].unique().tolist()\ngroup_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scatterplots"},{"metadata":{},"cell_type":"markdown","source":"#### SepalLength vs SepalWidth "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'SepalLengthCm', y = 'SepalWidthCm', data = data, hue = 'Species')\nplt.title('Sepal Length vs Sepal Width')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['SepalLengthCm'].corr(data['SepalWidthCm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Analysis**: We can see that there is a lot of correlation in Iris-Setosa category when it comes to Sepal Length and SepalWidth but not a similar distinction for the other two categories. The correlation does not seem very strong either. "},{"metadata":{},"cell_type":"markdown","source":"#### PetalLength vs PetalWidth"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'PetalLengthCm', y = 'PetalWidthCm', data = data ,hue ='Species')\nplt.title('Petal Length vs Petal Width')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['PetalLengthCm'].corr(data['PetalWidthCm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Analysis**: This is a very insightful graph. It tells us that we can use PetalLength to predict PetalWidth and it's category because of the proper clustrering of data points. The correlation is also very high. We can use these features for regression analysis later. **"},{"metadata":{},"cell_type":"markdown","source":"#### PetalLength vs SepalLength"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'PetalLengthCm', y = 'SepalLengthCm', data = data ,hue ='Species')\nplt.title('Petal Length vs Sepal Length')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['PetalLengthCm'].corr(data['SepalLengthCm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Analysis**: There is high correlation but we still do not get a very linear graph which is important. There is good  clustering but let's see if we can get something better "},{"metadata":{},"cell_type":"markdown","source":"#### PetalWidth vs SepalWidth"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'PetalWidthCm', y = 'SepalWidthCm', data = data ,hue ='Species')\nplt.title('Petal Length vs Sepal Length')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['PetalWidthCm'].corr(data['SepalWidthCm'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Analysis**: There isn't a lot of correlation. There is good clustering but let's see if we can get something better "},{"metadata":{},"cell_type":"markdown","source":"### Boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = \"Species\", y = \"PetalLengthCm\", data = data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Correlation Heat Map\nLet's make a correlation heatmap to understand the correlation between different species."},{"metadata":{"trusted":true},"cell_type":"code","source":"no_id_data = data.copy()\nno_id_data.drop(\"Id\", axis = 1, inplace = True)\nsns.heatmap(data = no_id_data.corr(), annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there is a very high correlation between Petal Length and Petal Width. "},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression ( Extra Work : Skip ahead to the 100% accuracy classification ) \nLet's try and predict the Petal Width from the Petal Length"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_values = data['PetalLengthCm'].copy()\ny_values = data['PetalWidthCm'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train1, y_test1 = train_test_split(x_values, y_values, test_size = 0.33, random_state = 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regression Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\">\nConvert to a Classification Task <br></p>\n"},{"metadata":{},"cell_type":"markdown","source":"### Adding Dummy Variables \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"species_dummy = pd.get_dummies(data[\"Species\"])\nspecies_dummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assigned_data = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assigned_data = pd.concat([data, species_dummy], axis = 1)\nassigned_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Classification "},{"metadata":{"trusted":true},"cell_type":"code","source":"assigned_data.drop([\"Id\"], inplace = True, axis = 1)\nassigned_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\nfeatures = cols[0:4]\nprint(target)\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = assigned_data[target].copy()\nX = assigned_data[features].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's divide the data into training and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.describe())\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see now that we have quite a randomized group of values for y_train and X_train. Let's build our classifier model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_classifier = DecisionTreeClassifier(max_leaf_nodes = 4, random_state = 0)\niris_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.75em; color:blue; font-style:bold\"><br>\n\nPredict on Test Set \n\n<br><br></p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction = iris_classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prediction[0 : 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nMeasure Accuracy of the Classifier\n<br><br></p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_true = y_test, y_pred = y_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion \n<br> \nI want to know  the reason for this 100% accuracy. Is it because these are highly correlated variables? \n\nThings to note:- \n1. If I decrease the size of the training set, I can reduce the accuracy which is obvious but still mentioning. **Is it a bad practice to take 0.1 as the test size? **\n2. Even if I do not scale the values, I can get a 100% result. The scaling was for my own knowledge. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}