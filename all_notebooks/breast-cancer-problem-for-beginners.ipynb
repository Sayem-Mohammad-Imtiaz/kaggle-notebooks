{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dtr = pd.read_csv('../input/breast-cancer-dataset-for-beginners/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dtr.iloc[:,1:10].values  # 0 indexed column 'Id' is not important and we chose all rows and 1 to 9 indexed columns\nY = dtr.iloc[:,10].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)   # Splitting using train_test_split\n\nX_train = X      # Using whole dataset for my model training\nY_train = Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler        # Used for feature scaling ie. reducing my range to [-1,1]\nFS = StandardScaler()                             \nX_train = FS.fit_transform(X_train)        # We only feature scale X not Y\nX_test = FS.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For finding the best classifier, every classifier is tested and their **training accuracy** was checked","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Performing CROSS-VALIDATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Created a function with many Machine Learning Models\n# def models(X_train,Y_train):\n  \n#   #Using Logistic Regression Algorithm to the Training Set\n#   from sklearn.linear_model import LogisticRegression\n#   log = LogisticRegression(random_state = 0)\n#   log.fit(X_train, Y_train)\n  \n#   #Using KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n#   from sklearn.neighbors import KNeighborsClassifier\n#   knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n#   knn.fit(X_train, Y_train)\n\n#   #Using SVC method of svm class to use Support Vector Machine Algorithm\n#   from sklearn.svm import SVC\n#   svc_lin = SVC(kernel = 'linear', random_state = 0)\n#   svc_lin.fit(X_train, Y_train)\n\n#   #Using SVC method of svm class to use Kernel SVM Algorithm\n#   from sklearn.svm import SVC\n#   svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n#   svc_rbf.fit(X_train, Y_train)\n\n#   #Using GaussianNB method of naïve_bayes class to use Naïve Bayes Algorithm\n#   from sklearn.naive_bayes import GaussianNB\n#   gauss = GaussianNB()\n#   gauss.fit(X_train, Y_train)\n\n#   #Using DecisionTreeClassifier of tree class to use Decision Tree Algorithm\n#   from sklearn.tree import DecisionTreeClassifier\n#   tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n#   tree.fit(X_train, Y_train)\n\n#   #Using RandomForestClassifier method of ensemble class to use Random Forest Classification algorithm\n#   from sklearn.ensemble import RandomForestClassifier\n#   forest = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n#   forest.fit(X_train, Y_train)\n  \n#   #printing model accuracy on the training data.\n#   print('Logistic Regression Training Accuracy: ', log.score(X_train, Y_train))\n#   print('K Nearest Neighbor Training Accuracy: ', knn.score(X_train, Y_train))\n#   print('Support Vector Machine (Linear Classifier) Training Accuracy: ', svc_lin.score(X_train, Y_train))\n#   print('Support Vector Machine (RBF Classifier) Training Accuracy: ', svc_rbf.score(X_train, Y_train))\n#   print('Gaussian Naive Bayes Training Accuracy: ', gauss.score(X_train, Y_train))\n#   print('Decision Tree Classifier Training Accuracy: ', tree.score(X_train, Y_train))\n#   print('Random Forest Classifier Training Accuracy: ', forest.score(X_train, Y_train))\n  \n#   return log, knn, svc_lin, svc_rbf, gauss, tree, forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Executing the above function\n# model = models(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Confusion matrix, every classifier is tested and their **testing accuracy** was checked","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix \n# for i in range(len(model)):\n#   cm = confusion_matrix(Y_test, model[i].predict(X_test))   #extracting TN, FP, FN, TP\n#   TN, FP, FN, TP = confusion_matrix(Y_test, model[i].predict(X_test)).ravel()\n#   print(cm)\n#   print('Model[{}] Testing Accuracy = \"{} !\"'.format(i,  (TP + TN) / (TP + TN + FN + FP)))  # Calculating testing accuracy\n#   print()  # Print a new line since its a by default feature of print function","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"THE BEST WAS CHOSEN, which is RANDOM FOREST CLASSIFIER","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = classifier.predict(X_test)   # Prediction was made from test data which we got due to splitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dte = pd.read_csv(\"../input/breast-cancer-dataset-for-beginners/test.csv\")   # Read the test dataset provided to us\ndte","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_TEST = dte.iloc[:,1:].values           # Same procedure is to be followed as it was followed in case of training dataset\nFST = StandardScaler()\nX_TEST = FST.fit_transform(X_TEST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_PRED = classifier.predict(X_TEST)   # Final Data was predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predicted = pd.DataFrame(Y_PRED)   # New Dataframe was created","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv(\"../input/breast-cancer-dataset-for-beginners/sample-submission.csv\")\ndataset = pd.concat([ss['Id'], Predicted], axis=1)     # Concatenation (Merging) with sample-submission dataset and creating a new dataset\ndataset.columns = ['Id', 'class']      # Column names were assigned for new dataset formed\ndataset.to_csv('sample_submission-rf.csv', index = False)   # Exported the new dataset with name","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}