{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Spam Classifier - Model comparison (accuracy > 97%)\n\n![emails](https://i.imgur.com/5mT9Beb.png)\n\n ","metadata":{}},{"cell_type":"markdown","source":"# Table of contents\n\n[<h3>1. Loading, data explorating and preprocessing</h3>](#1)\n\n[<h3>2. Model comparison</h3>](#2)\n\n[<h3>3. Hyperparameter selection for MultinomialNB</h3>](#3)\n\n[<h3>4. The MultinomialNB Model</h3>](#4)\n\n[<h3>5. Example of predictions</h3>](#5)","metadata":{}},{"cell_type":"markdown","source":"# 1. Loading, data explorating and preprocessing<a class=\"anchor\" id=\"1\"></a>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom time import perf_counter\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nfrom IPython.display import Markdown, display\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n    \ndf = pd.read_csv('../input/spam-mails-dataset/spam_ham_dataset.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first rows\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The dataset as a total of {df.shape[0]} E-Mails, which are categorized is ham and spam')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'].value_counts().plot.bar(color = [\"g\",\"r\"])\nplt.title('Total number of ham and spam in the dataset')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The raw E-Mails have a lot of characters beside of the ones of the alphabet, which might provoke issues later. Therefore, the E-Mails will be cleaned. Remember that it is a basic model, which won't take count of punctuation.","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\n\ndef clean_str(string, reg = RegexpTokenizer(r'[a-z]+')):\n    # Clean a string with RegexpTokenizer\n    string = string.lower()\n    tokens = reg.tokenize(string)\n    return \" \".join(tokens)\n\nprint('Before cleaning:')\ndf['text'][0]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('After cleaning:')\nclean_str(df['text'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new column with the cleaned messages\ndf['text_clean'] = df['text'].apply(lambda string: clean_str(string))\n\n# Display the result\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert a collection of text documents to a matrix of token counts\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(df.text_clean)\n\n# Get the categories\ny = df.label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split arrays or matrices into random train and test subsets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model comparison<a class=\"anchor\" id=\"2\"></a>","metadata":{}},{"cell_type":"code","source":"models = {\n    \"Random Forest\": {\"model\":RandomForestClassifier(), \"perf\":0},\n    \"Gradient Boosting\": {\"model\":GradientBoostingClassifier(), \"perf\":0},\n    \"XGBoost\": {\"model\":XGBClassifier(eval_metric='mlogloss'), \"perf\":0},\n    \"MultinomialNB\": {\"model\":MultinomialNB(), \"perf\":0},\n    \"Logistic Regr.\": {\"model\":LogisticRegression(), \"perf\":0},\n    \"KNN\": {\"model\":KNeighborsClassifier(), \"perf\":0},\n    \"Decision Tree\": {\"model\":DecisionTreeClassifier(), \"perf\":0},\n    \"SVM (Linear)\": {\"model\":LinearSVC(), \"perf\":0},\n    \"SVM (RBF)\": {\"model\":SVC(), \"perf\":0}\n}\n\nfor name, model in models.items():\n    start = perf_counter()\n    model['model'].fit(X_train, y_train)\n    duration = perf_counter() - start\n    duration = round(duration,2)\n    model[\"perf\"] = duration\n    print(f\"{name:20} trained in {duration} sec\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_acc = []\nfor name, model in models.items():\n    models_acc.append([name, model[\"model\"].score(X_test, y_test),model[\"perf\"]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_acc = pd.DataFrame(models_acc)\ndf_acc.columns = ['Model', 'Accuracy w/o scaling', 'Training time (sec)']\ndf_acc.sort_values(by = 'Accuracy w/o scaling', ascending = False, inplace=True)\ndf_acc.reset_index(drop = True, inplace=True)\ndf_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'Model', y = 'Accuracy w/o scaling', data = df_acc)\nplt.title('Accuracy on the test set\\n(the Y-Axis is between 0.8 and 1.0)', fontsize = 15)\nplt.ylim(0.8,1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'Model', y = 'Training time (sec)', data = df_acc)\nplt.title('Training time for each model in sec', fontsize = 15)\nplt.ylim(0,20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"XGBoosting gives the best result on the test set. Nevertheless, MultinomialNB is nearly as good, but is very fast (0.2 sec vs 5.1 sec). In the following part, we'll choose the MultinomialNB and try various hyperparameters to optimize it.","metadata":{}},{"cell_type":"markdown","source":"# 3. Hyperparameter selection for MultinomialNB<a class=\"anchor\" id=\"3\"></a>","metadata":{}},{"cell_type":"code","source":"# Find the best hyperparameter with GridSearchCV\n# Exhaustive search over specified parameter values for an estimator.\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import GridSearchCV\nparameters = {\"alpha\": [0.2,1,2,5,10], \"fit_prior\": [True, False]}\n\ngrid = GridSearchCV(MultinomialNB(), param_grid=parameters)\ngrid.fit(X_train,y_train)\n\n# Create a DataFrame with the best Hyperparameters\npd.DataFrame(grid.cv_results_)[['params','mean_test_score']]\\\n                               .sort_values(by=\"mean_test_score\", ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the best hyperparameters\ngrid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. The MultinomialNB Model<a class=\"anchor\" id=\"4\"></a>","metadata":{}},{"cell_type":"code","source":"# Create the model with the best hyperparameters\nfrom sklearn.naive_bayes import MultinomialNB\nalpha, fit_prior = grid.best_params_['alpha'], grid.best_params_['fit_prior']\nmodel = MultinomialNB(alpha = alpha)\n\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\n\nfrom sklearn.metrics import classification_report, accuracy_score\nprintmd(f'## Accuracy: {round(accuracy_score(y_test,y_pred),3)*100}%\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Example of predictions<a class=\"anchor\" id=\"5\"></a>","metadata":{}},{"cell_type":"code","source":"def display_result(df, number=2):\n    for i in range(number):\n        msg = df['text_clean'].iloc[i]\n        label = df[\"label\"].iloc[i]\n        msg_vec = cv.transform([msg])\n        pred_label = model.predict(msg_vec)\n        printmd(f\"**Real: {label}, Predicted: {pred_label[0]}**\")\n        printmd(f\"**E-Mail:** {msg}\")\n        printmd(\"_______________________________________________________________\")\n    \ndf_spam = df[df['label'] == 'spam']\ndf_ham = df[df['label'] == 'ham']\ndisplay_result(df_spam)\ndisplay_result(df_ham)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MultinomialNB: Lightweight, fast and powerfull!\n\n![simple-powerfull](https://i.imgur.com/bLOdU7Q.png)","metadata":{}}]}