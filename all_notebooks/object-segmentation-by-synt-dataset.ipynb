{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q git+https://github.com/tensorflow/examples.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T16:39:58.599849Z","iopub.execute_input":"2021-07-04T16:39:58.600246Z","iopub.status.idle":"2021-07-04T16:40:11.110412Z","shell.execute_reply.started":"2021-07-04T16:39:58.600151Z","shell.execute_reply":"2021-07-04T16:40:11.109453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport skimage\nimport skimage.io\n\nfrom IPython.display import clear_output\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\n\nimport tensorflow as tf\nfrom tensorflow_examples.models.pix2pix import pix2pix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:40:11.113983Z","iopub.execute_input":"2021-07-04T16:40:11.114306Z","iopub.status.idle":"2021-07-04T16:40:16.3603Z","shell.execute_reply.started":"2021-07-04T16:40:11.114273Z","shell.execute_reply":"2021-07-04T16:40:16.359356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(input_image):\n    input_image = tf.cast(input_image, tf.float32) / 255.0\n    return input_image\n\ndef normalize_mask(input_image):\n    input_image[input_image > 0] = 255\n    input_image = tf.cast(input_image, tf.float32) / 255.0\n    return input_image","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:40:16.362087Z","iopub.execute_input":"2021-07-04T16:40:16.362467Z","iopub.status.idle":"2021-07-04T16:40:16.371473Z","shell.execute_reply.started":"2021-07-04T16:40:16.362438Z","shell.execute_reply":"2021-07-04T16:40:16.370594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_HEIGHT = 128\nIMG_WIDTH = 128\nBATCH_SIZE = 48\nobj_path = '/kaggle/input/synthetic-dataset-for-object-detection/sofa_5/sofa_5/'\n# dataset_path = '/kaggle/input/synthetic-dataset-for-object-detection/synthetic_dataset/sofa/sofa_v4/'","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:40:16.375169Z","iopub.execute_input":"2021-07-04T16:40:16.375662Z","iopub.status.idle":"2021-07-04T16:40:16.381381Z","shell.execute_reply.started":"2021-07-04T16:40:16.375631Z","shell.execute_reply":"2021-07-04T16:40:16.38052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dataset = np.array([\n    cv2.resize(cv2.imread(f'{obj_path}features/images/' + file), dsize=(IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_CUBIC)\n    for file in tqdm(os.listdir(f'{obj_path}features/images/'))])\n\nmask_dataset = np.array([\n    np.expand_dims(\n        cv2.resize(\n            cv2.imread(f'{obj_path}labels/images/' + file, cv2.IMREAD_GRAYSCALE),\n            dsize=(IMG_HEIGHT, IMG_WIDTH),\n            interpolation=cv2.INTER_CUBIC\n        ),\n        axis=2\n    ) for file in tqdm(os.listdir(f'{obj_path}labels/images/'))])\n\nimage_for_test = np.array([\n    cv2.resize(cv2.imread(f'{obj_path}/image_for_test/' + file), dsize=(IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_CUBIC)\n    for file in tqdm(os.listdir(f'{obj_path}/image_for_test/'))])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:40:16.383763Z","iopub.execute_input":"2021-07-04T16:40:16.384069Z","iopub.status.idle":"2021-07-04T16:43:28.023901Z","shell.execute_reply.started":"2021-07-04T16:40:16.384043Z","shell.execute_reply":"2021-07-04T16:43:28.023022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ImgDir = f'{obj_path}/image_for_test/'\nimage_for_test = os.listdir(f\"{ImgDir}\")\nimgs = []\nfor i in image_for_test:\n    o = cv2.resize(cv2.imread(f'{ImgDir}' + i),\n               dsize=(IMG_HEIGHT, IMG_WIDTH),\n               interpolation=cv2.INTER_CUBIC)\n    o = cv2.cvtColor(o, cv2.COLOR_BGR2RGB)\n    imgs.append(o)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:28.025378Z","iopub.execute_input":"2021-07-04T16:43:28.025922Z","iopub.status.idle":"2021-07-04T16:43:28.493219Z","shell.execute_reply.started":"2021-07-04T16:43:28.025882Z","shell.execute_reply":"2021-07-04T16:43:28.492344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen_args = dict(\n    horizontal_flip=True,\n#     vertical_flip=True,\n# #     channel_shift_range=100,\n#     rotation_range=90,\n#     width_shift_range=0.1,\n#     height_shift_range=0.1,\n#     zoom_range=0.2,\n)\n\nimage_datagen = ImageDataGenerator(**data_gen_args, preprocessing_function=normalize, validation_split=0.3)\nmask_datagen = ImageDataGenerator(**data_gen_args, preprocessing_function=normalize_mask, validation_split=0.3)\nimage_for_test_datagen = ImageDataGenerator(preprocessing_function=normalize)\n\nseed = 1046527\n\nimage_datagen.fit(image_dataset[:2000], augment=True, seed=seed)\nmask_datagen.fit(mask_dataset[:2000], augment=True, seed=seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:28.494652Z","iopub.execute_input":"2021-07-04T16:43:28.495055Z","iopub.status.idle":"2021-07-04T16:43:29.201384Z","shell.execute_reply.started":"2021-07-04T16:43:28.494991Z","shell.execute_reply":"2021-07-04T16:43:29.200444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_generator = image_datagen.flow_from_directory(\n    f'{obj_path}features',\n    class_mode=None,\n    seed=seed,\n    batch_size=BATCH_SIZE,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    subset='training'\n)\n\ntrain_mask_generator = mask_datagen.flow_from_directory(\n    f'{obj_path}labels',\n    class_mode=None,\n    seed=seed,\n    batch_size=BATCH_SIZE,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    color_mode='grayscale',\n    subset='training'\n)\n\ntrain_generator = zip(train_image_generator, train_mask_generator)\n\nvalid_image_generator = image_datagen.flow_from_directory(\n    f'{obj_path}features',\n    class_mode=None,\n    seed=seed,\n    batch_size=BATCH_SIZE,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    subset='validation'\n)\n\nvalid_mask_generator = mask_datagen.flow_from_directory(\n    f'{obj_path}labels',\n    class_mode=None,\n    seed=seed,\n    batch_size=BATCH_SIZE,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    color_mode='grayscale',\n    subset='validation'\n)\n\nvalid_generator = zip(valid_image_generator, valid_mask_generator)\n\nimage_for_test_generator = image_for_test_datagen.flow_from_directory(\n    f'{obj_path}image_for_test_dg/',\n    class_mode=None,\n    seed=seed,\n    batch_size=1,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    subset='training'\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:29.204212Z","iopub.execute_input":"2021-07-04T16:43:29.204579Z","iopub.status.idle":"2021-07-04T16:43:51.881549Z","shell.execute_reply.started":"2021-07-04T16:43:29.204542Z","shell.execute_reply":"2021-07-04T16:43:51.879602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:51.883689Z","iopub.execute_input":"2021-07-04T16:43:51.884051Z","iopub.status.idle":"2021-07-04T16:43:51.891714Z","shell.execute_reply.started":"2021-07-04T16:43:51.88401Z","shell.execute_reply":"2021-07-04T16:43:51.890574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, mask in train_generator:\n    sample_image, sample_mask = image[0], mask[0]\n    break\ndisplay([sample_image, sample_mask])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:51.893372Z","iopub.execute_input":"2021-07-04T16:43:51.89378Z","iopub.status.idle":"2021-07-04T16:43:54.1427Z","shell.execute_reply.started":"2021-07-04T16:43:51.893739Z","shell.execute_reply":"2021-07-04T16:43:54.141865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.MobileNetV2(input_shape=[IMG_HEIGHT, IMG_WIDTH, 3], include_top=False, classes=2)\n\n# Use the activations of these layers\nlayer_names = [\n    'block_1_expand_relu',   # 64x64\n    'block_3_expand_relu',   # 32x32\n    'block_6_expand_relu',   # 16x16\n    'block_13_expand_relu',  # 8x8\n    'block_16_project',      # 4x4\n]\nbase_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n\n# Create the feature extraction model\ndown_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n\ndown_stack.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:54.143863Z","iopub.execute_input":"2021-07-04T16:43:54.144188Z","iopub.status.idle":"2021-07-04T16:43:55.576569Z","shell.execute_reply.started":"2021-07-04T16:43:54.144155Z","shell.execute_reply":"2021-07-04T16:43:55.575703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up_stack = [\n    pix2pix.upsample(1536, 3),  # 4x4 -> 8x8\n    pix2pix.upsample(1024, 3),  # 8x8 -> 16x16\n    pix2pix.upsample(512, 3),  # 16x16 -> 32x32\n    pix2pix.upsample(256, 3),   # 32x32 -> 64x64\n]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:55.577784Z","iopub.execute_input":"2021-07-04T16:43:55.578119Z","iopub.status.idle":"2021-07-04T16:43:55.608953Z","shell.execute_reply.started":"2021-07-04T16:43:55.578084Z","shell.execute_reply":"2021-07-04T16:43:55.608176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet_model(output_channels):\n    inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3])\n\n    # Downsampling through the model\n    skips = down_stack(inputs)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        concat = tf.keras.layers.Concatenate()\n        x = concat([x, skip])\n\n    # This is the last layer of the model\n    last = tf.keras.layers.Conv2DTranspose(\n        output_channels,\n        3,\n        strides=2,\n        activation='sigmoid',\n        padding='same')  # 64x64 -> 128x128\n\n    x = last(x)\n\n    return tf.keras.Model(inputs=inputs, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:55.610187Z","iopub.execute_input":"2021-07-04T16:43:55.610551Z","iopub.status.idle":"2021-07-04T16:43:55.617802Z","shell.execute_reply.started":"2021-07-04T16:43:55.610513Z","shell.execute_reply":"2021-07-04T16:43:55.616585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\n\ndef jaccard_distance(y_true, y_pred, smooth=100):\n\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n    return dice","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:55.619403Z","iopub.execute_input":"2021-07-04T16:43:55.619814Z","iopub.status.idle":"2021-07-04T16:43:55.629159Z","shell.execute_reply.started":"2021-07-04T16:43:55.619776Z","shell.execute_reply":"2021-07-04T16:43:55.628047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet_model(1)\nmodel.compile(optimizer='adam',\n              \n#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              \n              loss=jaccard_distance,\n              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2), dice_coef])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:55.630563Z","iopub.execute_input":"2021-07-04T16:43:55.63093Z","iopub.status.idle":"2021-07-04T16:43:56.100352Z","shell.execute_reply.started":"2021-07-04T16:43:55.630894Z","shell.execute_reply":"2021-07-04T16:43:56.099513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:56.10154Z","iopub.execute_input":"2021-07-04T16:43:56.101875Z","iopub.status.idle":"2021-07-04T16:43:56.122594Z","shell.execute_reply.started":"2021-07-04T16:43:56.101842Z","shell.execute_reply":"2021-07-04T16:43:56.121468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mask(pred_mask):\n    pred_mask = pred_mask[:,:,:,0]\n    pred_mask = tf.round(pred_mask)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:56.124033Z","iopub.execute_input":"2021-07-04T16:43:56.124629Z","iopub.status.idle":"2021-07-04T16:43:56.13058Z","shell.execute_reply.started":"2021-07-04T16:43:56.124589Z","shell.execute_reply":"2021-07-04T16:43:56.129427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predictions(dataset=None, num=1):\n    if dataset:\n        i = 0\n        for image, mask in dataset:\n            pred_mask = model.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n            i += 1\n            if i == num:\n                break\n    else:\n        display([sample_image, sample_mask,\n                 create_mask(model.predict(sample_image[tf.newaxis, ...]))])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:56.132138Z","iopub.execute_input":"2021-07-04T16:43:56.132497Z","iopub.status.idle":"2021-07-04T16:43:56.142429Z","shell.execute_reply.started":"2021-07-04T16:43:56.132462Z","shell.execute_reply":"2021-07-04T16:43:56.141524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(img,mode, cont=False):\n    color = (256, 0, 256)\n    pred = create_mask(mode.predict(img[tf.newaxis, ...]))\n    pred = pred[:, :,0].numpy()\n    pred[pred>0] = 255\n    pred = np.stack((pred,) * 3, axis=-1)\n    pred = np.uint8(pred*255)\n    pred = cv2.cvtColor(pred, cv2.COLOR_BGR2GRAY)\n    \n    contours, hierarchy = cv2.findContours(pred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    if cont:\n        try:\n            cv2.drawContours(pred, [max(contours, key = cv2.contourArea)], -1, cv2.FILLED, 8)\n            cv2.fillPoly(pred, pts=[max(contours, key = cv2.contourArea)], color=color)\n        except:\n            print('Contours not found!')\n            cv2.drawContours(pred, contours, -1, cv2.FILLED, 8)\n            cv2.fillPoly(pred, pts=contours, color=color)\n    else:\n        cv2.drawContours(pred, contours, -1, cv2.FILLED, 8)\n        cv2.fillPoly(pred, pts=contours, color=color)\n    \n    return pred\n\ndef show_fm():\n    img = next(image_for_test_generator)\n    img = img[0]\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'Model Mask', 'Contour Mask']\n    s_pred = pred(img, model, False)\n    c_pred = pred(img, model, True)\n    sh = (img, s_pred,c_pred)\n    \n    for i in range(len(sh)):\n        plt.subplot(1, len(sh), i+1)\n        plt.title(title[i])\n#         plt.imshow(sh[i],cmap='gray')\n        plt.imshow(sh[i])\n        plt.axis('off')\n    plt.show()\n ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:56.14351Z","iopub.execute_input":"2021-07-04T16:43:56.143825Z","iopub.status.idle":"2021-07-04T16:43:56.15897Z","shell.execute_reply.started":"2021-07-04T16:43:56.143799Z","shell.execute_reply":"2021-07-04T16:43:56.158131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_predictions()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:43:56.161325Z","iopub.execute_input":"2021-07-04T16:43:56.161965Z","iopub.status.idle":"2021-07-04T16:44:00.794908Z","shell.execute_reply.started":"2021-07-04T16:43:56.161921Z","shell.execute_reply":"2021-07-04T16:44:00.793959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DisplayCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        clear_output(wait=True)\n        show_fm()\n        show_fm() \n        show_fm() \n        show_predictions()\n        print('\\nSample Prediction after epoch {}\\n'.format(epoch+1))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:44:00.796582Z","iopub.execute_input":"2021-07-04T16:44:00.796974Z","iopub.status.idle":"2021-07-04T16:44:00.803413Z","shell.execute_reply.started":"2021-07-04T16:44:00.796932Z","shell.execute_reply":"2021-07-04T16:44:00.802166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\nVALIDATION_STEPS = 30\nSTEPS_PER_EPOCH = 300\n\nmodel_history = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_steps=VALIDATION_STEPS,\n    validation_data=valid_generator,\n    callbacks=[DisplayCallback()],\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:44:00.804846Z","iopub.execute_input":"2021-07-04T16:44:00.805338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_HEIGHT, IMG_WIDTH = model.get_config()['layers'][0]['config']['batch_input_shape'][1:3]\n\nImgDir = f'{obj_path}/image_for_test/'\nimage_for_test = os.listdir(f\"{ImgDir}\")\nimgs = []\nfor i in image_for_test:\n    o = cv2.resize(cv2.imread(f'{ImgDir}' + i),\n               dsize=(IMG_HEIGHT, IMG_WIDTH),\n               interpolation=cv2.INTER_CUBIC)\n    o = cv2.cvtColor(o, cv2.COLOR_BGR2RGB)\n    imgs.append(o)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_masked(img):\n    color = (256, 0, 256)\n    a = img.copy()\n    pred = a/255.\n    pred = create_mask(model.predict(pred[tf.newaxis, ...]))\n    pred = pred[:, :,0].numpy()\n    pred = np.stack((pred,) * 3, axis=-1)\n    pred = np.uint8(pred*255)\n    pred = cv2.cvtColor(pred, cv2.COLOR_BGR2GRAY)\n\n    contours, hierarchy = cv2.findContours(pred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n#     cv2.drawContours(a, [max(contours, key = cv2.contourArea)], -1, cv2.FILLED, 8)\n#     cv2.fillPoly(a, pts=[max(contours, key = cv2.contourArea)], color=color)\n    cv2.fillPoly(a, pts=contours, color=color)\n    return a\n\n\nfor i in range(len(imgs)):\n    plt.figure(figsize=(8, 8))\n    a = (show_masked(imgs[i]))\n    plt.imshow(a)\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}