{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# Librerias de Python \nimport tensorflow as tf\n\n#Librerias SKLearn \nfrom sklearn import decomposition, preprocessing, svm \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\n\n#Librerias Keras \nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Dropout\nfrom keras import regularizers\nfrom keras.callbacks import History \nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\n\n#otras librerias\nimport numpy as np\nfrom __future__ import print_function\nimport pandas as pd\nfrom pandas import read_excel\nfrom itertools import cycle\nfrom scipy import interp\nfrom matplotlib import pyplot as plt\nfrom scipy import stats\n\nhistory = History()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Usar la libreria de Pandas para insertar la data \npD = pd.read_csv(\"../input/data.csv\",header = None, low_memory = False)\n\n# Convierte los valores a una matriz N-Dimensional donde la N es el numero de rango de la matriz\npData = pD.as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e2c9775f19b0890c3427b9df57efd1a296036d","collapsed":true},"cell_type":"code","source":"#convierte cada '?' de la data a un 'nan (not a number)' y luego convierte el array de strings a floats \nlab = pData[0,:];\npData = np.delete(pData, (0), axis=0)\npData[pData == '?'] = np.nan;\n#transformacion a floats\npData = pData.astype('float32')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6228402872080b43603daedd97357d3e3d7a58e","collapsed":true},"cell_type":"code","source":"# Limpieza de datos\n# Toma todas las columnas que no estén completamente vacías, concatena los datos de destino y elimina cualquier fila con los datos faltantes restantes.\nd = pData[:,0:pData.shape[1]-4];\nd = np.hstack((d,pData[:,pData.shape[1]-1].reshape(len(pData[:,0]),1)));\nd = d[~np.isnan(d).any(axis=1)]\ntargets = d[:,d.shape[1]-1];\nd = np.delete(d, (d.shape[1]-1), axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40bd121d9d523adf408126ba2411269904f77233","collapsed":true},"cell_type":"code","source":"# uso de LDA (Linear Discriminant Analysis) and normalizacion min-max\ndN = preprocessing.minmax_scale(d, feature_range=(-1, 1), axis=0, copy=True)\nlda = LinearDiscriminantAnalysis(n_components=3)\nX = lda.fit(dN, targets).transform(dN)  \ntargets = np.reshape(targets.astype(int),(len(targets),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e438501482320cfd51eda3e9660484efb968218","collapsed":true},"cell_type":"code","source":"#np.hstack combina las matrices NumPy juntas en la dirección \"horizontal\".\nx = np.hstack((X,targets))\n# sort para un ploteo mas sencillo\nx = x[x[:,1].argsort()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba107e113adb37e6ed608c01faf8aa9dd7b10533"},"cell_type":"code","source":"# Cuántos pacientes pertenecen a cada grupo para plotear de acuerdo.\ntype0 = sum(np.isin(x[:,1], 0));\ntype1 = sum(np.isin(x[:,1], 1));\nq=0;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.bar(np.linspace(1,type0,type0), x[0:type0,q], align='center', label='Ninguno')\nax1.bar(np.linspace(type0+1,type0+type1,type1), x[type0:type0+type1,q], color='red', align='center', label='Afligidos')\nplt.xlabel('Paciente',fontsize=18)\nplt.ylabel('LDA Loading',fontsize=18)\nplt.title('1D LDA Ploteo en Barra',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 18});\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0a76554a974d1571c398b8c1525bc138d68ebd8"},"cell_type":"code","source":"# arbol de decision y cross validation\nclf = DecisionTreeClassifier(random_state=0)\nfiveF = cross_val_score(clf, x[:,0].reshape(len(x[:,0]),1), x[:,1], cv=5)\nprint(\"Todos: \", fiveF, \". \\nPromedio: \", np.mean(fiveF) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072482d33b0006d96ac9a5bc07f3f406fee44bb3"},"cell_type":"code","source":"X = x[:,0].reshape(x[:,0].shape[0],1);\n# X = x[:,0];\ny = x[:,1];\nn_samples, n_features = X.shape\ncv = StratifiedKFold(n_splits=5)\nclassifier = svm.SVC(kernel='linear', probability=True,\n                     random_state=0)\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nplt.figure(figsize=(10,10))\ni = 0\nfor train, test in cv.split(X, y):\n    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n    # Computar curvatura ROC curve ay area de la curva\n    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    i += 1\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n         label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('Tasa de falso positivo',fontsize=18)\nplt.ylabel('Tasa de positivos verdaderos',fontsize=18)\nplt.title('Cross-Validation ROC de LDA',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01c9d3965c39411ff1ffc1dc05f3eab95c86117d"},"cell_type":"code","source":"# min-max normalization\ny = np_utils.to_categorical(targets,num_classes=2)\ndN = preprocessing.minmax_scale(d, feature_range=(0, 1), axis=0, copy=True)\n# 50/50 entrenamiento/prueba\ntrain_X, test_X, train_y, test_y = train_test_split(dN, y, train_size=0.5, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3a01373f2920df9f14b79b9e7c2f26fcb1fad8e5"},"cell_type":"code","source":"# Definicion del modelo\n\ndef create_baseline():\n    model = Sequential()\n    model.add(Dense(15, activation='relu',input_shape=(10,)))\n    model.add(Dense(10, activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n    model.add(Dense(2, activation='sigmoid',kernel_regularizer=regularizers.l2(0.0001)))\n    keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-7, decay=0.0, amsgrad=False)\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy',auc_roc])\n    return model\n\n\ndef auc_roc(y_true, y_pred):\n    # metrica de Tensorflow\n    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n\n    # buscar todas las variables creadas para esta métrica\n    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n\n    # Agregar variables métricas a GLOBAL_VARIABLES.\n    # Se inicializarán para una nueva sesión.\n    for v in metric_vars:\n        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n\n    # forzar a actualizar valores de métrica\n    with tf.control_dependencies([update_op]):\n        value = tf.identity(value)\n        return value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"22aecfce5adf130c2ebf27a8eabe9c8392a9b341"},"cell_type":"code","source":"# Entrenamiento\nmodel = create_baseline();\nhistory = model.fit(train_X, train_y,\n          validation_data=(test_X, test_y),\n          batch_size=32, epochs=700, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"431b309dd1f0b7ff766a69d6e7f4cabe200f4d18"},"cell_type":"code","source":"# Curva AUROC y precisión de prueba para métrica de rendimiento\ny_pred = model.predict_proba(test_X);\nfpr_keras, tpr_keras, thresholds_keras = roc_curve(test_y[:,0], y_pred[:,0]);\nauc_keras = auc(fpr_keras, tpr_keras);\naccuracy = np.mean(np.equal(test_y, np.round(y_pred)));\nplt.figure(figsize=(10,10))\nplt.plot(fpr_keras, tpr_keras, color='black', label='AUC = {:.3f}'.format(auc_keras));\nplt.xlabel('Tasa de falso positivo',fontsize=18);\nplt.ylabel('Tasa de positivos verdaderos',fontsize=18);\nplt.title('ROC curve: Max-Min Normalizado - Prueba de precisión = %0.2f' % (accuracy),fontsize=18);\nplt.legend(loc='lower right',fontsize=18);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e521286180b82e5f8b7395c68fb94ddcba014e96"},"cell_type":"code","source":"# entrenar y probar la perdida (Loss)\ntrain_loss = history.history['loss']\nval_loss   = history.history['val_loss']\nxc         = range(700)\n_=plt.figure(figsize=(10,10))\nplt.plot(xc, train_loss,label='Entrenamiento')\nplt.plot(xc, val_loss, label='Validacion')\nplt.xlabel('Epochs',fontsize=18)\nplt.ylabel('Perdida(Loss)',fontsize=18)\nplt.title('Cost Curves',fontsize=18)\nplt.legend(loc=\"upper right\", prop={'size': 15})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fdfead4e75bd07514fd644fb681f458833febbc"},"cell_type":"code","source":"#resultados\nmodel = ExtraTreesClassifier();\nmodel.fit(dN, y);\nimportance = pd.DataFrame({ '1. Parametros' : lab[0:-4], '2. Importancia' : model.feature_importances_});\nimportance","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}