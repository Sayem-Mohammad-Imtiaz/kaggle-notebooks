{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The Techniques of Scaling training data in Linear Regression\n>     In this notebook, I apply different scaling techniques to the training data for King's County House Prices dataset such as StandardScaler, MinMaxScaler, MaxAbsScaler and Normalizer. I compare these LR models with a training data which didn't under go any scaling.\n    As a beginner to Machine Learning, I would appreciate constructive criticism about what things went wrong and how I could have tackled them better. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv',na_values='?')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Histogram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(bins=25,figsize=(16,16),xlabelsize='10',ylabelsize='10',xrot=-15)\nplt.title('Histogram for every feature')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping features that aren't used in this regression model\nn_df = df.drop(['id','date','lat','long'], axis=1)\nn_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = n_df.corr()\nmask = np.zeros_like(corr, dtype=np.bool) \nmask[np.triu_indices_from(mask)] = True \nplt.figure(figsize=(15,15))\nplt.title('Correlation Matrix')\nsns.set(font_scale=0.9)\nsns.heatmap(\n    corr\n    , annot=True\n    , fmt='.2f'\n    , cmap = 'inferno'\n    , vmax = 1\n    , square = True\n    , mask=mask\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing input data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding for yr_built\nyear_built_df = pd.get_dummies(n_df['yr_built'])\nyear_built_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding for zipcode column\nzipcodes_df = pd.get_dummies(n_df['zipcode'])\nzipcodes_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide into categorical and continous dfs\ncontinuos_df = n_df.drop([\n    'waterfront'\n    , 'view'\n    , 'yr_built'\n    , 'yr_renovated'\n    , 'sqft_above'\n    , 'zipcode'\n    , 'price'\n    , 'sqft_lot15'\n    , 'sqft_living15'\n    , 'sqft_above'\n],axis=1)\ncontinuos_df.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_df = n_df[['waterfront','view']]\ncategorical_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling Techniques","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# standard scaler\nss = preprocessing.StandardScaler()\nss_array = ss.fit_transform(continuos_df)\nss_array[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MinMaxScaler\nmms = preprocessing.MinMaxScaler()\nmms_array = mms.fit_transform(continuos_df)\nmms_array[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizer\nnorm = preprocessing.Normalizer()\nnorm_array = norm.fit_transform(continuos_df)\nnorm_array[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MaxAbsScaler\nmas = preprocessing.MaxAbsScaler()\nmas_array = mas.fit_transform(continuos_df)\nmas_array[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[['price']]\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training data with no scaling\nX = pd.concat(\n    [\n        continuos_df\n        , categorical_df\n        , zipcodes_df\n        , year_built_df\n    ]\n    , axis = 1 \n)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training data scaled with standard scaler\nX_ss = pd.concat(\n    [\n        pd.DataFrame(ss_array,columns=continuos_df.columns)\n        , categorical_df\n        , zipcodes_df\n        , year_built_df\n    ]\n    , axis = 1 \n)\nX_ss.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training data scaled with MinMaxScaler\nX_mms = pd.concat(\n    [\n        pd.DataFrame(mms_array,columns=continuos_df.columns)\n        , categorical_df\n        , zipcodes_df\n        , year_built_df\n    ]\n    , axis = 1 \n)\nX_mms.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training data scaled with a Normalizer\nX_norm = pd.concat(\n    [\n        pd.DataFrame(norm_array,columns=continuos_df.columns)\n        , categorical_df\n        , zipcodes_df\n        , year_built_df\n    ]\n    , axis = 1 \n)\nX_norm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Traning data scaled with a MinAbsScaler\nX_mas = pd.concat(\n    [\n        pd.DataFrame(mas_array,columns=continuos_df.columns)\n        , categorical_df\n        , zipcodes_df\n        , year_built_df\n    ]\n    , axis = 1 \n)\nX_mas.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split with 80:20 ratio for ss training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=69)\nprint('ss train X and y ->\\n','-'*69)\nprint(X_train[:5])\nprint(y_train[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split with 80:20 ratio for ss training data\nX_ss_train, X_ss_test, y_ss_train, y_ss_test = train_test_split(X_ss, y, test_size = 0.2, random_state=69)\nprint('ss train X and y ->\\n','-'*69)\nprint(X_ss_train[:5])\nprint(y_ss_train[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split with 80:20 ratio for mms training data\nX_mms_train, X_mms_test, y_mms_train, y_mms_test = train_test_split(X_mms, y, test_size = 0.2, random_state=69)\nprint('mms train X and y ->\\n','-'*69)\nprint(X_mms_train[:5])\nprint(y_mms_train[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split with 80:20 ratio for norm training data\nX_norm_train, X_norm_test, y_norm_train, y_norm_test = train_test_split(X_norm, y, test_size = 0.2, random_state=69)\nprint('norm train X and y ->\\n','-'*69)\nprint(X_norm_train[:5])\nprint(y_norm_train[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split with 80:20 ratio for mas training data\nX_mas_train, X_mas_test, y_mas_train, y_mas_test = train_test_split(X_mas, y, test_size = 0.2, random_state=69)\nprint('mas train X and y ->\\n','-'*69)\nprint(X_mas_train[:5])\nprint(y_mas_train[:5])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"regression_types = []\ntrain_r2_scores = []\ntest_r2_scores = []\ntrain_mses = []\ntrain_rmss = []\ntest_mses = []\ntest_rmss = []\ndef add_model_metrics(lr_model,x_tr,y_tr,x_te,y_te,lr_type):\n    print('Linear regression type -> ',lr_type)\n    r2_train = lr_model.score(x_tr,y_tr)\n    r2_test = lr_model.score(x_te,y_te)\n    print('R2 score for training set -> ',r2_train)\n    print('R2 score for testing set -> ',r2_test)\n    pred_train = lr_model.predict(x_tr)\n    train_mse = mean_squared_error(y_tr,pred_train)\n    train_rms = math.sqrt(mean_squared_error(y_tr,pred_train))\n    print('MSE for training set -> ',train_mse)\n    print('RMS for training set -> ',train_rms)\n    pred_test = lr_model.predict(x_te)\n    test_mse = mean_squared_error(y_te,pred_test)\n    test_rms = math.sqrt(mean_squared_error(y_te,pred_test))\n    print('MSE for training set -> ',test_mse)\n    print('RMS for training set -> ',test_rms)\n    regression_types.append(lr_type)\n    train_r2_scores.append(r2_train)\n    test_r2_scores.append(r2_test)\n    train_mses.append(train_mse)\n    train_rmss.append(train_rms)\n    test_mses.append(test_mse)\n    test_rmss.append(test_rms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training and Evaluation\n>     for different scaling methods applied for training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear regression using no scaling\nimport math\nlr = LinearRegression(fit_intercept=False)\nlr.fit(X_train,y_train)\nadd_model_metrics(lr,X_train,y_train,X_test,y_test,'No Scaling')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Sink regression using ss scaling\nlr_ss = LinearRegression(fit_intercept=False)\nlr_ss.fit(X_ss_train,y_ss_train)\nadd_model_metrics(lr_ss,X_ss_train,y_ss_train,X_ss_test,y_ss_test,'Standard Scaling')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Sink regression using mms scaling\nlr_mms = LinearRegression(fit_intercept=False)\nlr_mms.fit(X_mms_train,y_mms_train)\nadd_model_metrics(lr_mms,X_mms_train,y_mms_train,X_mms_test,y_mms_test,'MinMax Scaling')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Sink regression using norm scaling\nlr_norm = LinearRegression(fit_intercept=False)\nlr_norm.fit(X_norm_train,y_norm_train)\nadd_model_metrics(lr_norm,X_norm_train,y_norm_train,X_norm_test,y_norm_test,'Normalizer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Sink regression using mas scaling\nlr_mas = LinearRegression(fit_intercept=False)\nlr_mas.fit(X_mas_train,y_mas_train)\nadd_model_metrics(lr_mas,X_mas_train,y_mas_train,X_mas_test,y_mas_test,'MaxAbsScaler')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results Summarized in a table","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = pd.DataFrame({\n    'Type':regression_types\n    , 'Train R2 Scores' : train_r2_scores\n    , 'Test R2 Scores' : test_r2_scores\n    , 'Train MSE' : train_mses\n    , 'Train RMS' : train_rmss\n    , 'Test MSE' : test_mses\n    , 'Test RMS' : test_rmss\n}\n)\nresults_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Predictions\n    for training and testing data after scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,60))\nplt.title('Linear Regression with different types of scaling')\nplt.subplot(5,2,1)\nplt.title(' No Scaling training data')\nplt.scatter(y_train,lr.predict(X_train),label='train labels',color='green')\nplt.subplot(5,2,2)\nplt.scatter(y_test,lr.predict(X_test),label='test labels',color='blue')\nplt.title(' No Scaling testing data')\nplt.subplot(5,2,3)\nplt.title(' StandardScaler training data')\nplt.scatter(y_ss_train,lr.predict(X_ss_train),label='train labels',color='green')\nplt.subplot(5,2,4)\nplt.title(' StandardScaler testing data')\nplt.scatter(y_ss_test,lr_ss.predict(X_ss_test),label='test labels',color='blue')\nplt.legend()\nplt.subplot(5,2,5)\nplt.title(' MinMaxScaler training data')\nplt.scatter(y_mms_train,lr_mms.predict(X_mms_train),label='train labels',color='green')\nplt.subplot(5,2,6)\nplt.title(' MinMaxScaler testing data')\nplt.scatter(y_mms_test,lr_mms.predict(X_mms_test),label='test labels',color='blue')\nplt.legend()\nplt.subplot(5,2,7)\nplt.title(' Normalizer training data')\nplt.scatter(y_norm_train,lr_norm.predict(X_norm_train),label='train labels',color='green')\nplt.subplot(5,2,8)\nplt.title(' Normalizer testing data')\nplt.scatter(y_norm_test,lr_norm.predict(X_norm_test),label='test labels',color='blue')\nplt.legend()\nplt.subplot(5,2,9)\nplt.title(' MaxAbsScaler training data')\nplt.scatter(y_mas_train,lr_mas.predict(X_mas_train),label='train labels',color='green')\nplt.subplot(5,2,10)\nplt.title(' MaxAbsScaler testing data')\nplt.scatter(y_mas_test,lr_mas.predict(X_mas_test),label='test labels',color='blue')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inspecting regression coefficients","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# standard scaled linear regression training coefficients\ncoef_df_ss = pd.Series(lr_ss.coef_[0],X_ss.columns).sort_values()\nfor i,val in zip(list(coef_df_ss.index),coef_df_ss):\n    print(i,'=',val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# no scaling linear regression training coefficients\ncoef_df = pd.Series(lr.coef_[0],X.columns).sort_values()\nfor i,val in zip(list(coef_df.index),coef_df):\n    print(i,'=',val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MinMax scaled linear regression training coefficients\ncoef_df_mms = pd.Series(lr_mms.coef_[0],X_mms.columns).sort_values()\nfor i,val in zip(list(coef_df_mms.index),coef_df_mms):\n    print(i,'=',val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalized linear regression training coefficients\ncoef_df_norm = pd.Series(lr_norm.coef_[0],X_norm.columns).sort_values()\nfor i,val in zip(list(coef_df_norm.index),coef_df_norm):\n    print(i,'=',val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MaxAbs scaled linear regression training coefficients\ncoef_df_mas = pd.Series(lr_mas.coef_[0],X_mas.columns).sort_values()\nfor i,val in zip(list(coef_df_mas.index),coef_df_mas):\n    print(i,'=',val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n> No Scaling and Scaling using StandardScaler, MinMaxScaler and MaxAbsScaler doesn't show significant difference when comparing metrics. Using Normalizer showed significant difference, and the reason why is that Normalizer Scales using Cross-Sectional basis instead of longitudinal unlike the other scaling techniques i.e. row-based instead of column based","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Future Work\n* Add different pre-processing techniques and compare the results such as binning, feature creation, etc\n* Add regularization post training a model\n* Try on different regression techniques such as polynomial, neural network, etc","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}