{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"Author: Diana Rozenshteyn\n\nhttps://towardsdatascience.com/daily-to-weekly-pandas-c0557b12f052","metadata":{}},{"cell_type":"markdown","source":"# Converting Daily Data to Weekly in Pandas. #\n\nHands-on tutorial for converting daily data to weekly\n\nIn this article  I will show 4 different methods for converting daily data to weekly in Pandas and compare their performance.\n\n## The Challenge ##\n\nRecently, in one of my graduate classes I was asked to evaluate Covid-19 daily cases in various counties in the United States over the last year using Pandas. The challenge was to present findings as a weekly, rather than daily data. As a beginner in using Pandas this simple task was daunting to me at first, but in the process of completing this assignment I have developed 4 different methods to convert daily data to weekly. \n \nThe csv file used in this article is publicly available on [usafacts.org](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/) webpage.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport time\n\ncases = pd.read_csv('../input/covid-confirmed-usafacts/covid_confirmed_usafacts.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:07.357243Z","iopub.execute_input":"2021-06-07T21:27:07.357676Z","iopub.status.idle":"2021-06-07T21:27:07.613917Z","shell.execute_reply.started":"2021-06-07T21:27:07.357638Z","shell.execute_reply":"2021-06-07T21:27:07.612746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, letâ€™s get the cvs file ready to work on:\n\n+ For simplicity of the output, we will only concentrate on total number of cases in four states: CA, OR, WA and NV. Therefore, not needed county and state identification columns can be dropped.\n\n+ Week in our evaluation will start on Monday and end on Sunday. Thus, columns for dates corresponding to incomplete weeks in the beginning/end of the date range, can be dropped as well. For this publication the datafile used contains data from 01/22/2020 to 02/07/2021.\n\n+ The data in the original csv file is a running total of Covid-19 cases and needs to be transformed to new cases. This is done by using sum() followed by diff() functions applied to dataframe grouped by State.\n\n+ Finally, 01/26/2020 is a Sunday just before the first Monday in the dataframe and a part of the incomplete week. It must be dropped only after the new cases numbers calculated so new cases data is not lost for the first Monday.","metadata":{}},{"cell_type":"code","source":"cases_states = cases.query(\"State == 'CA' | State == 'OR' | State == 'WA' | State == 'NV'\")\ncases_states_filtered = cases_states.drop(columns = ['countyFIPS', 'StateFIPS','County Name', '2020-01-22', \n                                                     '2020-01-23', '2020-01-24', '2020-01-25'])\ncases_states_daily_total = cases_states_filtered.groupby('State').sum()\nnew_cases_daily_total = cases_states_daily_total.diff(axis = 1)\nnew_cases_daily_total = new_cases_daily_total.drop(columns = ['2020-01-26'])\ndisplay(new_cases_daily_total)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:13.285108Z","iopub.execute_input":"2021-06-07T21:27:13.285588Z","iopub.status.idle":"2021-06-07T21:27:13.426566Z","shell.execute_reply.started":"2021-06-07T21:27:13.285552Z","shell.execute_reply":"2021-06-07T21:27:13.42531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Method 1: using Python for-loops.\n\nAs I have now learned, using Python for-loops to iterate over data in Pandas is not the most efficient way to go about converting daily data to weekly. Just looping with Python for-loops does not take any advantage of build-in functions Pandas has to offer and it is the slowest way to accomplish the task at hand. However, in the beginning of this journey for-loops seemed as the easiest way to convert daily data columns to weekly, so I started with implementing a function that does that.\n\nFunction new_case_count() takes in DataFrame object, iterates over it and converts indexes, which are dates in string format, to Pandas Datetime format. Based on the date's day of the week, each week's new cases count is calculated and stored in a list. The function returns a list of weekly new cases counts for each state.\n\nFor simplicity, output for this and other methods only shows last 5 weeks of data.","metadata":{}},{"cell_type":"code","source":"def new_case_count(state_new_cases):\n    first_Monday_found = False\n    week_case_count = 0\n    week_case_counts = []\n    for index, value in state_new_cases.items():\n        index_date = pd.to_datetime(index, format='%Y/%m/%d', exact = False)\n        index_day_of_week = index_date.day_name()\n        if not first_Monday_found and index_day_of_week != 'Monday':\n            continue\n        first_Monday_found = True\n        week_case_count += value\n        if index_day_of_week == 'Sunday':\n            week_case_counts.append(week_case_count)\n            week_case_count = 0\n    return week_case_counts\n\n# converting list to DataFrame object\nnew_cases_weekly_total_method_1 = pd.DataFrame(new_case_count(new_cases_daily_total))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:21.098862Z","iopub.execute_input":"2021-06-07T21:27:21.099401Z","iopub.status.idle":"2021-06-07T21:27:21.299859Z","shell.execute_reply.started":"2021-06-07T21:27:21.099351Z","shell.execute_reply":"2021-06-07T21:27:21.298141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(new_cases_weekly_total_method_1.tail(5))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:24.934855Z","iopub.execute_input":"2021-06-07T21:27:24.938206Z","iopub.status.idle":"2021-06-07T21:27:24.954509Z","shell.execute_reply.started":"2021-06-07T21:27:24.938137Z","shell.execute_reply":"2021-06-07T21:27:24.9532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Method 2: relabeling and groupby().\n\nMy next attempt at converting daily data to weekly does not involve any for-loops. However, it is still the second slowest method of the four. \n\nFunction rename_columns_dates() takes in Series object and converts indexes, which are dates in string format, to Pandas Datetime format. The dates are relabeled with a date for current week's Monday in the '%Y/%m/%d' format followed by delimiter (% sign) and a number of days that the current date is offset from the current week's Monday. The function returns a string representing the new dates labelling. \nFor example, for Monday 2021/01/25 the return string will be '2021/01/25%0', for Tuesday 2021/01/26 the return string will be '2021/01/25%1', and so on.\n\nNext, new cases grouped weekly by splitting data labels at delimiter (%) and summing the values for the group that have the same Monday as their date.","metadata":{}},{"cell_type":"code","source":"def rename_columns_dates(new_cases_index):\n    index_date = pd.to_datetime(new_cases_index, format='%Y/%m/%d', exact = False)\n    index_day_of_week = index_date.day_name()\n    offset_from_monday = 0\n    if index_day_of_week == 'Tuesday':\n        offset_from_monday = 1\n    elif index_day_of_week == 'Wednesday':\n        offset_from_monday = 2\n    elif index_day_of_week == 'Thursday':\n        offset_from_monday = 3\n    elif index_day_of_week =='Friday':\n        offset_from_monday = 4\n    elif index_day_of_week == 'Saturday':\n        offset_from_monday = 5\n    elif index_day_of_week == 'Sunday':\n        offset_from_monday = 6\n        \n    # new_date is a class of Pandas.Timeframe   \n    new_date = index_date - pd.Timedelta(days = offset_from_monday)\n    return (new_date.strftime('%Y/%m/%d') + '%' + str(offset_from_monday))\n\n\nnew_cases_weekly_total = new_cases_daily_total.rename(rename_columns_dates, axis = 'columns')\n\n# grouping new cases weekly by splitting data labells at delimiter (%) and summing the values for the same Monday\nnew_cases_weekly_total_method_2 = new_cases_weekly_total.groupby(new_cases_weekly_total.columns.str.split('%').str[0], \n                                                        axis=1).sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:27.089716Z","iopub.execute_input":"2021-06-07T21:27:27.090102Z","iopub.status.idle":"2021-06-07T21:27:27.184932Z","shell.execute_reply.started":"2021-06-07T21:27:27.090061Z","shell.execute_reply":"2021-06-07T21:27:27.183972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(new_cases_weekly_total_method_2.T.tail(5))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:31.850519Z","iopub.execute_input":"2021-06-07T21:27:31.851192Z","iopub.status.idle":"2021-06-07T21:27:31.862667Z","shell.execute_reply.started":"2021-06-07T21:27:31.85115Z","shell.execute_reply":"2021-06-07T21:27:31.861713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Method 3: resample().\n\nThis method uses a resample() function. I came across couple of articles on Medium [here](https://raj26kumar.medium.com/convert-daily-data-to-weekly-data-without-losing-names-of-other-column-using-python-pandas-e2aa001a3691) and [here](https://medium.com/@sharath.ravi/convert-daily-data-to-weekly-data-using-python-pandas-6c73abcfb5f7) on how to convert daily data to weekly with resample(). After making some changes to the dataframe I had this method up and running. \n\nIt is the second fastest of the four as demonstrated at the end of this article. ","metadata":{}},{"cell_type":"code","source":"new_cases_daily_total_modified = new_cases_daily_total.T.reset_index()\n\nnew_cases_daily_total_modified = new_cases_daily_total_modified.assign(Weeks = \n                                                new_cases_daily_total_modified['index']).drop(columns = 'index')\n\nnew_cases_daily_total_modified['Weeks'] = new_cases_daily_total_modified['Weeks'].astype('datetime64[ns]')\n\nnew_cases_weekly_total_method_3 = new_cases_daily_total_modified.resample('W-Mon', label='left', \n                                                                          closed = 'left', on='Weeks').sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:33.828445Z","iopub.execute_input":"2021-06-07T21:27:33.828845Z","iopub.status.idle":"2021-06-07T21:27:33.858629Z","shell.execute_reply.started":"2021-06-07T21:27:33.82878Z","shell.execute_reply":"2021-06-07T21:27:33.857788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(new_cases_weekly_total_method_3.tail(5))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:36.197834Z","iopub.execute_input":"2021-06-07T21:27:36.19818Z","iopub.status.idle":"2021-06-07T21:27:36.209559Z","shell.execute_reply.started":"2021-06-07T21:27:36.198151Z","shell.execute_reply":"2021-06-07T21:27:36.208877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Method 4: groupby().\n\nThe idea for this method came to me after reading a suggestion on [stackoverflow](https://stackoverflow.com/questions/46607027/pandas-sum-of-every-n-columns). I was excited that you can group columns by 7 at a time in just one line. However, this simplicity comes at a price of losing your date labels and instead having numbers as indexes, 0-53 in this case. \n\nTo fix this I came up with an idea of creating a date range that is needed by using pd.period_range() function, converting the date range to Series and adding it to the DataFrame that now has weekly data. The period_range() function returns a fixed frequency PeriodIndex. The date period in this format looks like this: 'Monday date/Sunday date'. You can keep that as is or split the string on delimiter ('/') to just have Monday date marking the start of the week. \n\nThis method turned out to be the fastest method among the four tested.","metadata":{}},{"cell_type":"code","source":"new_cases_groupby_total_method_4 = new_cases_daily_total.groupby([[i//7 for i in range(0,378)]], axis = 1).sum().T\n\ndate_range = pd.period_range(start = '2020-01-27', end = '2021-02-07', freq = 'W-SUN')\ndate_range = date_range.map(str)\ndate_range = date_range.str.split('/').str[0]\n\ndate_range = pd.Series(date_range)\n\nnew_cases_weekly_total_method_4 = new_cases_groupby_total_method_4.assign(Weeks = date_range)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:40.071653Z","iopub.execute_input":"2021-06-07T21:27:40.072173Z","iopub.status.idle":"2021-06-07T21:27:40.094216Z","shell.execute_reply.started":"2021-06-07T21:27:40.072141Z","shell.execute_reply":"2021-06-07T21:27:40.092992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('DataFrame after groupby():')\ndisplay(new_cases_groupby_total_method_4.tail(5))\nprint('\\n')\n\nprint('date_range Series:')\ndisplay(date_range.tail(5))\nprint('\\n')\n\nprint('Final Dataframe:')\ndisplay(new_cases_weekly_total_method_4.set_index(['Weeks']).tail(5))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:46.161529Z","iopub.execute_input":"2021-06-07T21:27:46.162073Z","iopub.status.idle":"2021-06-07T21:27:46.192101Z","shell.execute_reply.started":"2021-06-07T21:27:46.162026Z","shell.execute_reply":"2021-06-07T21:27:46.19118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance evaluation:\n\nEach method's execution time was measured. I used %%timeit to measure execution time on Jupyter Notebooks by placing %%timeit at the top of each method's cell. To compare the performance of these four methods I have run them on Jupyter Notebook 10 consecutive times. \n\nIt is mportant to remember that the sample size of 10 runs is extreamly small and this is just a quick look at the methods performance.\n\nThe resulting data has been converted to a DataFrame. Mean and standard deviation were calculated.","metadata":{}},{"cell_type":"code","source":"data_milliseconds = {'Method 1: for-loops':[87.00, 88.3, 88.2, 87.3, 86.8, 87.1, 86.8, 87.2, 89.1, 87.5], \n                    'Method 2: relabeling/groupby()':[56.8, 57.2, 57.2, 56.8, 56.7, 56.9, 56.9, 56.7, 57.0, 57.1],\n                    'Method 3: resample()':[4.6, 4.61, 4.56, 4.53, 4.5, 4.52, 4.54, 4.49, 4.55, 4.51],\n                    'Method 4: groupby()':[3.52, 3.51, 3.51, 3.47, 3.6, 3.47, 3.53, 3.5, 3.45, 3.46]} \n\nmethods_performance = pd.DataFrame(data_milliseconds).T\nmethods_performance['Mean'] = methods_performance.loc[:, '0':].mean(axis = 1)\nmethods_performance['Std'] = methods_performance[0:].std(axis = 1)\n\ndisplay(methods_performance)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:50.752932Z","iopub.execute_input":"2021-06-07T21:27:50.753441Z","iopub.status.idle":"2021-06-07T21:27:50.785501Z","shell.execute_reply.started":"2021-06-07T21:27:50.753391Z","shell.execute_reply":"2021-06-07T21:27:50.784376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusions:\n\n+ Important to remember that the sample size is just 10 runs of the Jupyter Notebook file.\n+ Method 4 (gtoupby() method) is the fastest of the four. \n+ Method 4 runs ~25x as fast as Method 1 (for-loop method) and ~16x as fast as Method 2(relabelling/groupby() method).\n+ Method 3(resample() method) runs almost as fast as Method 4(groupby() method) with Method 4 runnning 1.3x faster. \n+ While I expected Methods 1 and 2 to be slower than Methods 3 and 4, I was surprised to find that Method 4 was the fastest of all. ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \n\nplt.figure(figsize=(13,6))\nmethods_performance['Mean'].plot(kind = 'bar', yerr=methods_performance['Std'], align='center',\n                                alpha=0.5, color=['red', 'blue', 'purple', 'green'], ecolor='black', capsize=10)\nplt.xticks(rotation = 0)\nplt.ylabel('Execution time in milliseconds', fontsize=14);\nplt.title('Performance Comparison of four different methods\\n for daily to weekly data conversion in Pandas\\n', \n          fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T21:27:54.179955Z","iopub.execute_input":"2021-06-07T21:27:54.180525Z","iopub.status.idle":"2021-06-07T21:27:54.414861Z","shell.execute_reply.started":"2021-06-07T21:27:54.180486Z","shell.execute_reply":"2021-06-07T21:27:54.413427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thank you for reading, \n\nDiana","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}