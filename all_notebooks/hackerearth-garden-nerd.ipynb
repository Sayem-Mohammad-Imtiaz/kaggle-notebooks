{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nimport math\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=np.load(\"../input/he-challenge-data-32x32/X_train_64.npy\")\nX_test=np.load(\"../input/he-challenge-data-32x32/X_test_64.npy\")\nY_train=np.load(\"../input/he-challenge-data-32x32/Y_train_np.npy\")\nplt.imshow(X_test[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=cv2.imread('../input/flower-recognition-he/he_challenge_data/data/test/18540.jpg')\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_csv=pd.read_csv(\"../input/flower-recognition-he/he_challenge_data/data/train.csv\")\nX_test_csv=pd.read_csv(\"../input/flower-recognition-he/he_challenge_data/data/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_csv[\"category\"].value_counts().plot(kind=\"bar\",figsize=(25,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers,layers,models,regularizers\nfrom keras.layers import GlobalMaxPool1D,GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping\nfrom keras.applications import DenseNet121,DenseNet169\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten,Activation,Conv2D,MaxPooling2D,Dense,Dropout,BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learning rate schedule\ndef step_decay(epoch):\n    initial_lrate = 0.0001\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n    return lrate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.preprocessing import image\n# from keras.applications.vgg16 import VGG16\n# from keras.applications.vgg16 import preprocess_input\n# import numpy as np\n\n# model_vgg = VGG16(weights='imagenet', include_top=False,input_shape=(64,64,3))\n# model = models.Sequential()\n# model.add(model_vgg)\n# model.add(layers.BatchNormalization())\n# # model.add(layers.GlobalMaxPool1D())\n# model.add(layers.Flatten())\n# model.add(layers.Dropout(rate=0.2))\n# model.add(layers.Dense(units=256,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n# model.add(layers.Dense(units=102,activation='softmax',kernel_regularizer=regularizers.l2(0.01)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.applications.inception_v3 import InceptionV3\n# base_model = InceptionV3(weights='imagenet', include_top=False,input_shape=(64,64,3))\n# model.add(base_model.output)\n# model.add(GlobalAveragePooling2D())\n# # model.add(layers.BatchNormalization())\n# # model.add(layers.GlobalMaxPool1D())\n# # model.add(layers.Flatten())\n# # model.add(layers.Dropout(rate=0.5))\n# model.add(layers.Dense(units=256,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n# model.add(layers.Dropout(rate=0.5))\n# model.add(layers.Dense(units=102,activation='softmax',kernel_regularizer=regularizers.l2(0.01)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nresnet_weights_path = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel_resnet=ResNet50(include_top=False, weights=resnet_weights_path,input_shape=(64,64,3))\nmodel = models.Sequential()\nmodel.add(model_resnet)\nmodel.add(layers.BatchNormalization())\n# model.add(layers.GlobalMaxPool1D())\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(rate=0.2))\nmodel.add(layers.Dense(units=256,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(layers.Dense(units=102,activation='softmax',kernel_regularizer=regularizers.l2(0.01)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam=optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-8)\n# sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=adam,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import clip\nX_train=X_train/255\nfor img in range(0,len(X_train)):\n    mean,std=X_train[img].mean(),X_train[img].std()\n    X_train[img] = (X_train[img] - mean) / std\n    X_train[img] = clip(X_train[img], -1.0, 1.0)\n    X_train[img] = (X_train[img] + 1.0) / 2.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set,val_set,y_set,y_val=train_test_split(X_train,Y_train,test_size=0.2,random_state=42)\ntrain_gen = ImageDataGenerator(\n                                zoom_range=[0.8,1.0],\n                                width_shift_range=0.2, \n                                height_shift_range=0.2,\n                                rotation_range=15,\n#                                 brightness_range=[0.8,1.0],\n                                fill_mode='nearest',\n                                horizontal_flip=True,\n#                                 vertical_flip=True\n#                                 ,shear_range=1.\n#                                zca_whitening=True,\n#                                featurewise_std_normalization=True,\n#                                samplewise_std_normalization=False\n                              )\ntrain_gen.fit(train_set)\ntrain_gen_flow  =  train_gen.flow(train_set,y_set,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_gen = ImageDataGenerator(rescale=1./1)\nval_gen.fit(val_set)\nval_gen_flow = val_gen.flow(val_set,y_val,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x_batch, y_batch in train_gen.flow(train_set, y_set, batch_size=1):\n    for i in range(0, 1):\n        fig = plt.figure()\n        ax = fig.add_subplot(110 + 1 + i)\n        ax.imshow(x_batch[i], interpolation='nearest')\n        ax.set_aspect(0.5)\n    plt.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrate = LearningRateScheduler(step_decay)\ncallbacks_list = [lrate]\n\nmodel.fit_generator(\n    train_gen_flow,\n    steps_per_epoch=len(train_set)/32, \n    epochs=20,\n    validation_data = val_gen_flow,\n    validation_steps = 32\n    ,callbacks=callbacks_list\n                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %reset_selective -f X_train     \n# import gc\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# del X_test ,train_gen_flow ,val_gen_flow,train_set,val_set,y_set,y_val,Y_train,train_gen,val_gen,x_batch,y_batch,X_test_csv\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import clip\nX_train2=np.load(\"../input/he-challenge-data-32x32/X_train_64.npy\")\nX_train2=X_train2/255\nfor img in range(0,18540):\n    mean,std=X_train2[img].mean(),X_train2[img].std()\n    X_train2[img] = (X_train2[img] - mean) / std\n    X_train2[img] = clip(X_train2[img], -1.0, 1.0)\n    X_train2[img] = (X_train2[img] + 1.0) / 2.0\nY_pred_train=model.predict(X_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=0\nsets=[]\nfor i in range(0,18540):\n    k=0\n    for j in range(0,102):\n        if(Y_pred_train[i][j]>=0.55 and Y_pred_train[i][j]<0.999) :\n            count=count+1\n            k=1\n            break\n    if(k):continue\n    else: sets.append(i)\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.delete(X_train, sets, 0)\nY_train = np.delete(Y_train, sets, 0)\nprint(len(X_train),len(Y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_train=(Y_pred_train>0.5)*1\nY_pred_train=Y_pred_train.argmax(axis=1)\nY_pred_train=Y_pred_train+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_train=pd.DataFrame(data=Y_pred_train,copy=True)\nY_pred_train[0].value_counts().plot(kind='bar',figsize=(25,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New Model\n\nfrom keras.applications.resnet50 import ResNet50\nresnet_weights_path = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel_resnet=ResNet50(include_top=False, weights=resnet_weights_path,input_shape=(64,64,3))\nmodel = models.Sequential()\nmodel.add(model_resnet)\nmodel.add(layers.BatchNormalization())\n# model.add(layers.GlobalMaxPool1D())\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(rate=0.2))\nmodel.add(layers.Dense(units=256,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(layers.Dense(units=102,activation='softmax',kernel_regularizer=regularizers.l2(0.01)))\n\n# Learning rate Scheduler\n\ndef step_decay(epoch):\n    initial_lrate = 0.0001\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n    return lrate\n\n# Optimizers\n\nadam=optimizers.Adam(lr=0.0001,beta_1=0.9,beta_2=0.999,epsilon=1e-8)\n# sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=adam,loss=\"categorical_crossentropy\",metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set,val_set,y_set,y_val=train_test_split(X_train,Y_train,test_size=0.2,random_state=42)\ntrain_gen = ImageDataGenerator(\n                                zoom_range=[0.8,1.0],\n                                width_shift_range=0.2, \n                                height_shift_range=0.2,\n                                rotation_range=15,\n#                                 brightness_range=[0.8,1.0],\n                                fill_mode='nearest',\n                                horizontal_flip=True,\n#                                 vertical_flip=True\n#                                 ,shear_range=1.\n#                                zca_whitening=True,\n#                                featurewise_std_normalization=True,\n#                                samplewise_std_normalization=False\n                              )\ntrain_gen.fit(train_set)\ntrain_gen_flow  =  train_gen.flow(train_set,y_set,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_gen = ImageDataGenerator(rescale=1./1)\nval_gen.fit(val_set)\nval_gen_flow = val_gen.flow(val_set,y_val,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(\n    train_gen_flow,\n    steps_per_epoch=len(train_set)/32, \n    epochs=20,\n    validation_data = val_gen_flow,\n    validation_steps = 32\n    ,callbacks=callbacks_list\n                       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel X_train2,Y_pred_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import clip\nX_test2=np.load(\"../input/he-challenge-data-32x32/X_test_64.npy\")\nX_test2=X_test2/255\nfor img in range(0,2009):\n    mean,std=X_test2[img].mean(),X_test2[img].std()\n    X_test2[img] = (X_test2[img] - mean) / std\n    X_test2[img] = clip(X_test2[img], -1.0, 1.0)\n    X_test2[img] = (X_test2[img] + 1.0) / 2.0\nY_pred=model.predict(X_test2)\nY_pred=(Y_pred>0.5)*1\nY_pred=Y_pred.argmax(axis=1)+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv(\"../input/flower-recognition-he/he_challenge_data/data/sample_submission.csv\")\nsub[\"category\"]=Y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n# N = 18540\n# NN=102\n# b = np.zeros((N,NN+1))\n# b[:,1:] = Y_train\n# count=0\n# for i in range(0,18540):\n#     if(b[i][0]==0):count=count+1\n# count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.argmax(axis=1)+1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}