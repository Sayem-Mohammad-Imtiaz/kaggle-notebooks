{"cells":[{"metadata":{},"cell_type":"markdown","source":"fork元のサンプルコード https://www.kaggle.com/ruruamour/simple-sample-code では良い精度が出ませんでした。 \n  \n精度が出なかった要因の１つに、学習データのバリエーションが不足していたことが考えられます。\n\n  \nこのNotebookでは、画像のaugmentation（水増し）を行い、学習データのバリエーションを増やす方法を書きます。\n"},{"metadata":{},"cell_type":"markdown","source":"## 1. 準備"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nroot_dir = \"/kaggle/input/mj1-anomaly-images-detection-challenge/\"\ntrain_csv_filepath = root_dir + \"train.csv\"\n\n# ファイルの読み込み\ntrain_df = pd.read_csv(train_csv_filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resize_w = 256\nresize_h = 256\nchannel = 3\n\nimport cv2\n# 画像が大きいと計算が遅いため、リサイズ縮小\ndef resize(tmp_image):\n    return cv2.resize(tmp_image , (resize_h, resize_w))\n\n# 4次元配列化()　\ndef to_4d(tmp_image):\n    return tmp_image.reshape(1, resize_h, resize_w, channel)\n    \n\n# 256段階の色調を0.0~1.0にする\ndef normalize(tmp_image):\n    return tmp_image / 255.0\n\n# 画像の前処理付きロード\ndef load_preprocessed_image(image_filepath):\n    tmp_image = cv2.imread(image_filepath)\n    tmp_image = resize(tmp_image)\n    tmp_image = normalize(tmp_image)\n    tmp_image = to_4d(tmp_image)\n\n    return tmp_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.utils import np_utils\n\nimages = None\nfor fn in train_df['filename']:\n    image_filepath = root_dir + 'train/' + fn\n    tmp_image = load_preprocessed_image(image_filepath)\n    if (images is None):\n        images = tmp_image\n    else:\n        images = np.vstack((images, tmp_image))\n\nanomaly_flags = np.array([flag for flag in train_df['anomaly']])\nanomaly_flags = np_utils.to_categorical(anomaly_flags, 2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.333, random_state=0)\n\nfor train_index, test_index in sss.split(images, anomaly_flags):\n    X_train = images[train_index]\n    y_train = anomaly_flags[train_index]\n    X_test = images[test_index]\n    y_test = anomaly_flags[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# over-samplingを試します。\n\ntmp = pd.DataFrame(y_train[:, 1]).value_counts().values\nprint(tmp)\nlabel_ok_num = tmp[0]\nlabel_ng_num = tmp[1]\n\nwhile(label_ok_num != label_ng_num):\n    rand_index = np.random.randint(0, len(y_train))\n\n    label_is_ng = (y_train[rand_index, 1] == 1.0)\n    if label_is_ng:\n        X_train = np.vstack((X_train, [X_train[rand_index]]))\n        y_train = np.vstack((y_train, [y_train[rand_index]]))\n        label_ng_num += 1\n    print(label_ng_num, end='\\r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. 画像を表示してみる"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\nfor i, f in enumerate(train_df['filename'][:5]):\n    plt.subplot(1,5,i+1)\n    image_filepath = root_dir + 'train/' + f\n    tmp_image = cv2.imread(image_filepath)\n    plt.imshow(cv2.cvtColor(tmp_image, cv2.COLOR_BGR2RGB)) # OpenCV は色がGBR順なのでRGB順に並べ替える","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"いくつか試しに表示してみましたが、  \n釘の向きがバラバラでした。"},{"metadata":{},"cell_type":"markdown","source":"# 3. ImageDataGeneratorで画像の水増しを行う"},{"metadata":{},"cell_type":"markdown","source":"kerasのImageDataGeneratorを使って、学習のたびにランダムな画像処理を行って学習させるようにします。  \n今回は釘の向きがバラバラであったので、画像の回転を行うことにします。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=360)\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, f in enumerate(datagen.flow(X_train, y_train, batch_size=1)):\n    tmp_image = f[0][0]*256\n    tmp_image = tmp_image.astype(np.uint8)\n    print(tmp_image.shape)\n    plt.imshow(tmp_image) # OpenCV は色がGBR順なのでRGB順に並べ替える\n    if (i>=4):\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.学習モデルの作成"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\n#データの読み込みと前処理\n\nfrom keras.datasets import mnist\n#kerasでCNN構築\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.optimizers import Adam\n\n \n'''\nCNNの構築\n'''\ndef cnn_model():\n    model = Sequential()\n\n    model.add(Conv2D(filters=10, kernel_size=(4,4), padding='same', input_shape=(256, 256, 3), activation='relu'))\n    model.add(Conv2D(filters=10, kernel_size=(3,3), padding='same', input_shape=(64, 64, 8), activation='relu'))\n    model.add(Conv2D(filters=10, kernel_size=(2,2), padding='same', input_shape=(16, 16, 16), activation='relu'))\n    model.add(Conv2D(filters=10, kernel_size=(2,2), padding='same', input_shape=(8, 8, 16), activation='relu'))\n\n    model.add(Flatten())\n    model.add(Dense(2, activation='softmax'))\n    adam = Adam(lr=1e-4, decay=1e-6)\n    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 500\nn_batch = 8\n\nmodel = cnn_model()\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=n_batch),\n                    steps_per_epoch=len(X_train) / n_batch,\n                    epochs=epochs,\n                    validation_data=(X_test, y_test))\n\ntrain_score = model.evaluate(X_train, y_train, verbose=0)\ntest_score = model.evaluate(X_test, y_test, verbose=0)\nprint('Train Loss:{0:.3f}'.format(train_score[0]))\nprint('Train accuracy:{0:.3}'.format(train_score[1]))\nprint('Test Loss:{0:.3f}'.format(test_score[0]))\nprint('Test accuracy:{0:.3}'.format(test_score[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ランダムな画像処理を行っているため、結果は毎回変わりますが、この文書を書いている実行の回では\n> Train Loss:0.575\n> Train accuracy:0.746\n> Test Loss:0.605\n> Test accuracy:0.68\n\nという結果になりました。\nLoss/accuracyともに、前回よりも悪い値になっているのですが、  \nTrainとTestの値が近く、バランスよく学習できていることが伺えます。  \n  \nTrainの値がよく、Testの値が悪い状況は一般的に「過学習」や「汎化性能が低い」と呼ばれており  \n本番データで良い結果が出せない傾向が強く、よくありません。"},{"metadata":{},"cell_type":"markdown","source":"# 6. 学習済みモデルで判定　〜　7.提出用ファイルの作成"},{"metadata":{},"cell_type":"markdown","source":"## 判定用ファイルの読み込み"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nfrom pathlib import Path\n\ntest_images = None\ntest_filenames = None\nfor test_filepath in glob.glob('/kaggle/input/mj1-anomaly-images-detection-challenge/test/*.png'):\n    tmp_image = load_preprocessed_image(test_filepath)\n    if (test_images is None):\n        test_images = tmp_image\n        test_filenames = [Path(test_filepath).name]\n    else:\n        test_images = np.vstack((test_images, tmp_image))\n        test_filenames.append(Path(test_filepath).name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_predict = model.predict(test_images)\nresult_predict = np.argmax(result_predict, axis=1)\nresult_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_filepath = \"/kaggle/input/mj1-anomaly-images-detection-challenge/sample_submit.csv\"\nsubmit_df = pd.read_csv(submit_filepath, index_col=0)\n\nfor i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\nsubmit_df[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.to_csv('result_submit.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}