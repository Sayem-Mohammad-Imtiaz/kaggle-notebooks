{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-02T21:19:46.20399Z","iopub.execute_input":"2021-07-02T21:19:46.204394Z","iopub.status.idle":"2021-07-02T21:19:46.225262Z","shell.execute_reply.started":"2021-07-02T21:19:46.20431Z","shell.execute_reply":"2021-07-02T21:19:46.224419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install twython","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:19:46.226962Z","iopub.execute_input":"2021-07-02T21:19:46.227511Z","iopub.status.idle":"2021-07-02T21:19:55.377205Z","shell.execute_reply.started":"2021-07-02T21:19:46.227477Z","shell.execute_reply":"2021-07-02T21:19:55.375795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:19:55.379965Z","iopub.execute_input":"2021-07-02T21:19:55.380288Z","iopub.status.idle":"2021-07-02T21:19:57.386896Z","shell.execute_reply.started":"2021-07-02T21:19:55.380253Z","shell.execute_reply":"2021-07-02T21:19:57.38553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/all-covid19-vaccines-tweets/vaccination_all_tweets.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:19:57.3884Z","iopub.execute_input":"2021-07-02T21:19:57.38875Z","iopub.status.idle":"2021-07-02T21:19:59.362817Z","shell.execute_reply.started":"2021-07-02T21:19:57.388698Z","shell.execute_reply":"2021-07-02T21:19:59.361645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef clean(text):\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:19:59.364175Z","iopub.execute_input":"2021-07-02T21:19:59.364506Z","iopub.status.idle":"2021-07-02T21:19:59.370799Z","shell.execute_reply.started":"2021-07-02T21:19:59.364447Z","shell.execute_reply":"2021-07-02T21:19:59.369849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['text'] = data['text'].apply(lambda x:clean(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:19:59.371865Z","iopub.execute_input":"2021-07-02T21:19:59.372262Z","iopub.status.idle":"2021-07-02T21:20:06.039356Z","shell.execute_reply.started":"2021-07-02T21:19:59.372232Z","shell.execute_reply":"2021-07-02T21:20:06.038229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sia=SIA()\nscores=[]\nfor i in range(len(data['text'])):\n    \n    score = sia.polarity_scores(data['text'][i])\n    score=score['compound']\n    scores.append(score)\nsentiment=[]\nfor i in scores:\n    if i>=0.05:\n        sentiment.append('Positive')\n    elif i<=(-0.05):\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndata['sentiment']=pd.Series(np.array(sentiment))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:20:06.041675Z","iopub.execute_input":"2021-07-02T21:20:06.042001Z","iopub.status.idle":"2021-07-02T21:20:36.914463Z","shell.execute_reply.started":"2021-07-02T21:20:06.04197Z","shell.execute_reply":"2021-07-02T21:20:36.913364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\n\ndef clean_text(text):\n    \n    text = str(text).lower()\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    \n    return text\ndata['text'] = data['text'].apply(lambda x:clean_text(x))\n\ndata['text']","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:20:36.916127Z","iopub.execute_input":"2021-07-02T21:20:36.916427Z","iopub.status.idle":"2021-07-02T21:20:38.233625Z","shell.execute_reply.started":"2021-07-02T21:20:36.916398Z","shell.execute_reply":"2021-07-02T21:20:38.232583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame()\ndf['text']=data['text']\ndef tokenization(text):\n    text = re.split('\\W+', text)\n    return text\n\ndf['tokenized'] = df['text'].apply(lambda x: tokenization(x.lower()))\nstopword = nltk.corpus.stopwords.words('english')\ndef remove_stopwords(text):\n    text = [word for word in text if word not in stopword]\n    return text\n    \ndf['No_stopwords'] = df['tokenized'].apply(lambda x: remove_stopwords(x))\n\nps = nltk.PorterStemmer()\n\ndef stemming1(text):\n    text = [ps.stem(word) for word in text]\n    return text\n\ndf['stemmed_porter'] = df['No_stopwords'].apply(lambda x: stemming1(x))\n\nfrom nltk.stem.snowball import SnowballStemmer\ns_stemmer = SnowballStemmer(language='english')\ndef stemming2(text):\n    text = [s_stemmer.stem(word) for word in text]\n    return text\ndf['stemmed_snowball'] = df['No_stopwords'].apply(lambda x: stemming2(x))\n\nwn = nltk.WordNetLemmatizer()\n\ndef lemmatizer(text):\n    text = [wn.lemmatize(word) for word in text]\n    return text\n\ndf['lemmatized'] = df['No_stopwords'].apply(lambda x: lemmatizer(x))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:20:38.235024Z","iopub.execute_input":"2021-07-02T21:20:38.235401Z","iopub.status.idle":"2021-07-02T21:21:51.675622Z","shell.execute_reply.started":"2021-07-02T21:20:38.235369Z","shell.execute_reply":"2021-07-02T21:21:51.674622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:51.677014Z","iopub.execute_input":"2021-07-02T21:21:51.677306Z","iopub.status.idle":"2021-07-02T21:21:51.71627Z","shell.execute_reply.started":"2021-07-02T21:21:51.677279Z","shell.execute_reply":"2021-07-02T21:21:51.715168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = data.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='coolwarm_r')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:51.717836Z","iopub.execute_input":"2021-07-02T21:21:51.718229Z","iopub.status.idle":"2021-07-02T21:21:51.967544Z","shell.execute_reply.started":"2021-07-02T21:21:51.718193Z","shell.execute_reply":"2021-07-02T21:21:51.966792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nn = nltk.WordNetLemmatizer()\n\nfrom nltk.tokenize import RegexpTokenizer\ntoken = RegexpTokenizer(r'[a-zA-Z0-9]+')\ncv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\ntext_counts = cv.fit_transform(df['text'])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:51.968617Z","iopub.execute_input":"2021-07-02T21:21:51.969071Z","iopub.status.idle":"2021-07-02T21:21:54.692476Z","shell.execute_reply.started":"2021-07-02T21:21:51.969022Z","shell.execute_reply":"2021-07-02T21:21:54.691728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (text_counts)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:54.693575Z","iopub.execute_input":"2021-07-02T21:21:54.69402Z","iopub.status.idle":"2021-07-02T21:21:54.715001Z","shell.execute_reply.started":"2021-07-02T21:21:54.693976Z","shell.execute_reply":"2021-07-02T21:21:54.713891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['sentiment'], test_size=0.25, random_state=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:54.716228Z","iopub.execute_input":"2021-07-02T21:21:54.716532Z","iopub.status.idle":"2021-07-02T21:21:54.748338Z","shell.execute_reply.started":"2021-07-02T21:21:54.716502Z","shell.execute_reply":"2021-07-02T21:21:54.747234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (X_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:54.749602Z","iopub.execute_input":"2021-07-02T21:21:54.749898Z","iopub.status.idle":"2021-07-02T21:21:54.763373Z","shell.execute_reply.started":"2021-07-02T21:21:54.74987Z","shell.execute_reply":"2021-07-02T21:21:54.762286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:54.7647Z","iopub.execute_input":"2021-07-02T21:21:54.765013Z","iopub.status.idle":"2021-07-02T21:21:54.771952Z","shell.execute_reply.started":"2021-07-02T21:21:54.764983Z","shell.execute_reply":"2021-07-02T21:21:54.770893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MNB = MultinomialNB()\nMNB.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:54.773542Z","iopub.execute_input":"2021-07-02T21:21:54.774221Z","iopub.status.idle":"2021-07-02T21:21:55.782071Z","shell.execute_reply.started":"2021-07-02T21:21:54.774165Z","shell.execute_reply":"2021-07-02T21:21:55.781032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\npredicted = MNB.predict(X_test)\naccuracy_score = metrics.accuracy_score(predicted, Y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:55.783542Z","iopub.execute_input":"2021-07-02T21:21:55.783861Z","iopub.status.idle":"2021-07-02T21:21:55.85989Z","shell.execute_reply.started":"2021-07-02T21:21:55.783827Z","shell.execute_reply":"2021-07-02T21:21:55.858665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(str('{:04.2f}'.format(accuracy_score*100))+'%')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:55.863684Z","iopub.execute_input":"2021-07-02T21:21:55.863988Z","iopub.status.idle":"2021-07-02T21:21:55.869056Z","shell.execute_reply.started":"2021-07-02T21:21:55.863959Z","shell.execute_reply":"2021-07-02T21:21:55.868044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import ComplementNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nCNB = ComplementNB()\nGNB = GaussianNB()\nBNB = BernoulliNB()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:55.871628Z","iopub.execute_input":"2021-07-02T21:21:55.871987Z","iopub.status.idle":"2021-07-02T21:21:55.880806Z","shell.execute_reply.started":"2021-07-02T21:21:55.871954Z","shell.execute_reply":"2021-07-02T21:21:55.879998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer()\ntext_count_2 = tfidf.fit_transform(df['text'])\n\n#splitting the data in test and training\n#from sklearn.model_selection() import train_test_split()\nx_train, x_test, y_train, y_test = train_test_split(text_count_2, data['sentiment'],test_size=0.25,random_state=5)\n\n#defining the model\n#compilimg the model -> we are going to use already used models  MNB, CNB, BNB\n#fitting the model\nMNB.fit(x_train, y_train)\naccuracy_score_mnb = metrics.accuracy_score(MNB.predict(x_test), y_test)\nprint('accuracy_score_mnb = '+str('{:4.2f}'.format(accuracy_score_mnb*100))+'%')\n\nBNB.fit(x_train, y_train)\naccuracy_score_bnb = metrics.accuracy_score(BNB.predict(x_test), y_test)\nprint('accuracy_score_bnb = '+str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')\n\nCNB.fit(x_train, y_train)\naccuracy_score_cnb = metrics.accuracy_score(CNB.predict(x_test), y_test)\nprint('accuracy_score_cnb = '+str('{:4.2f}'.format(accuracy_score_cnb*100))+'%')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:21:55.88206Z","iopub.execute_input":"2021-07-02T21:21:55.882708Z","iopub.status.idle":"2021-07-02T21:22:02.363355Z","shell.execute_reply.started":"2021-07-02T21:21:55.882663Z","shell.execute_reply":"2021-07-02T21:22:02.36242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(text_count_2)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:02.364683Z","iopub.execute_input":"2021-07-02T21:22:02.364967Z","iopub.status.idle":"2021-07-02T21:22:02.392485Z","shell.execute_reply.started":"2021-07-02T21:22:02.364938Z","shell.execute_reply":"2021-07-02T21:22:02.391331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:02.393769Z","iopub.execute_input":"2021-07-02T21:22:02.394109Z","iopub.status.idle":"2021-07-02T21:22:05.280526Z","shell.execute_reply.started":"2021-07-02T21:22:02.394067Z","shell.execute_reply":"2021-07-02T21:22:05.279152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ngram_df(corpus,nrange,n=None):\n    vec = CountVectorizer(stop_words = 'english',ngram_range=nrange).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    total_list=words_freq[:n]\n    df=pd.DataFrame(total_list,columns=['text','count'])\n    return df\nunigram_df=ngram_df(df['text'],(1,1),20)\nbigram_df=ngram_df(df['text'],(2,2),20)\ntrigram_df=ngram_df(df['text'],(3,3),20)\nfig = make_subplots(\n    rows=3, cols=1,subplot_titles=(\"Unigram\",\"Bigram\",'Trigram'),\n    specs=[[{\"type\": \"scatter\"}],\n           [{\"type\": \"scatter\"}],\n           [{\"type\": \"scatter\"}]\n          ])\n\nfig.add_trace(go.Bar(\n    y=unigram_df['text'][::-1],\n    x=unigram_df['count'][::-1],\n    marker={'color': \"blue\"},  \n    text=unigram_df['count'],\n    textposition = \"outside\",\n    orientation=\"h\",\n    name=\"Months\",\n),row=1,col=1)\n\nfig.add_trace(go.Bar(\n    y=bigram_df['text'][::-1],\n    x=bigram_df['count'][::-1],\n    marker={'color': \"blue\"},  \n    text=bigram_df['count'],\n     name=\"Days\",\n    textposition = \"outside\",\n    orientation=\"h\",\n),row=2,col=1)\n\nfig.add_trace(go.Bar(\n    y=trigram_df['text'][::-1],\n    x=trigram_df['count'][::-1],\n    marker={'color': \"blue\"},  \n    text=trigram_df['count'],\n     name=\"Days\",\n    orientation=\"h\",\n    textposition = \"outside\",\n),row=3,col=1)\n\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.update_layout(title_text='Top N Grams',xaxis_title=\" \",yaxis_title=\" \",\n                  showlegend=False,title_x=0.5,height=1200,template=\"plotly_dark\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:05.282286Z","iopub.execute_input":"2021-07-02T21:22:05.282624Z","iopub.status.idle":"2021-07-02T21:22:32.495465Z","shell.execute_reply.started":"2021-07-02T21:22:05.282593Z","shell.execute_reply":"2021-07-02T21:22:32.494383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Positive_tweet = data[data['sentiment']=='Positive'].reset_index()\nNegative_tweet = data[data['sentiment']=='Negative'].reset_index()\nNeutral_tweet = data[data['sentiment']=='Neutral'].reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:32.496741Z","iopub.execute_input":"2021-07-02T21:22:32.497058Z","iopub.status.idle":"2021-07-02T21:22:32.638951Z","shell.execute_reply.started":"2021-07-02T21:22:32.497027Z","shell.execute_reply":"2021-07-02T21:22:32.63787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Positive_tweet.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:32.640408Z","iopub.execute_input":"2021-07-02T21:22:32.640748Z","iopub.status.idle":"2021-07-02T21:22:32.663731Z","shell.execute_reply.started":"2021-07-02T21:22:32.640715Z","shell.execute_reply":"2021-07-02T21:22:32.662537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import unicodedata","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:32.665043Z","iopub.execute_input":"2021-07-02T21:22:32.665335Z","iopub.status.idle":"2021-07-02T21:22:32.675404Z","shell.execute_reply.started":"2021-07-02T21:22:32.665307Z","shell.execute_reply":"2021-07-02T21:22:32.674591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def basic_clean(text):\n  wnl = nltk.stem.WordNetLemmatizer()\n  stopwords = nltk.corpus.stopwords.words('english') \n  text = (unicodedata.normalize('NFKD', text)\n    .encode('ascii', 'ignore')\n    .decode('utf-8', 'ignore')\n    .lower())\n  words = re.sub(r'[^\\w\\s]', '', text).split()\n  return [wnl.lemmatize(word) for word in words if word not in stopwords]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:32.676772Z","iopub.execute_input":"2021-07-02T21:22:32.6771Z","iopub.status.idle":"2021-07-02T21:22:32.693365Z","shell.execute_reply.started":"2021-07-02T21:22:32.677069Z","shell.execute_reply":"2021-07-02T21:22:32.692239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = basic_clean(''.join(str(Positive_tweet['text'].tolist())))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:32.694508Z","iopub.execute_input":"2021-07-02T21:22:32.694823Z","iopub.status.idle":"2021-07-02T21:22:36.849176Z","shell.execute_reply.started":"2021-07-02T21:22:32.694794Z","shell.execute_reply":"2021-07-02T21:22:36.848063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (Positive_tweet['text'].count())","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:36.850638Z","iopub.execute_input":"2021-07-02T21:22:36.851062Z","iopub.status.idle":"2021-07-02T21:22:36.873276Z","shell.execute_reply.started":"2021-07-02T21:22:36.851019Z","shell.execute_reply":"2021-07-02T21:22:36.872211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unigrams_series =(pd.Series(nltk.ngrams(words, 1)).value_counts())[:30]\nunigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring unigrams')\nplt.ylabel('Unigram')\nplt.xlabel('# of Occurances')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:36.875008Z","iopub.execute_input":"2021-07-02T21:22:36.875441Z","iopub.status.idle":"2021-07-02T21:22:37.900506Z","shell.execute_reply.started":"2021-07-02T21:22:36.875395Z","shell.execute_reply":"2021-07-02T21:22:37.899536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (unigrams_series)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:37.901721Z","iopub.execute_input":"2021-07-02T21:22:37.902012Z","iopub.status.idle":"2021-07-02T21:22:37.913243Z","shell.execute_reply.started":"2021-07-02T21:22:37.901983Z","shell.execute_reply":"2021-07-02T21:22:37.911182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unigrams_series.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:37.91417Z","iopub.execute_input":"2021-07-02T21:22:37.914419Z","iopub.status.idle":"2021-07-02T21:22:38.091365Z","shell.execute_reply.started":"2021-07-02T21:22:37.914394Z","shell.execute_reply":"2021-07-02T21:22:38.090461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bigrams_series =(pd.Series(nltk.ngrams(words, 2)).value_counts())[:30]\nbigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring Bigrams')\nplt.ylabel('Bigram')\nplt.xlabel('# of Occurances')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:38.092581Z","iopub.execute_input":"2021-07-02T21:22:38.092889Z","iopub.status.idle":"2021-07-02T21:22:39.475348Z","shell.execute_reply.started":"2021-07-02T21:22:38.09286Z","shell.execute_reply":"2021-07-02T21:22:39.474474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trigrams_series =(pd.Series(nltk.ngrams(words, 3)).value_counts())[:30]\ntrigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring Trigrams')\nplt.ylabel('trigram')\nplt.xlabel('# of Occurances')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:39.476905Z","iopub.execute_input":"2021-07-02T21:22:39.47732Z","iopub.status.idle":"2021-07-02T21:22:40.947973Z","shell.execute_reply.started":"2021-07-02T21:22:39.477279Z","shell.execute_reply":"2021-07-02T21:22:40.946922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nwords = basic_clean(''.join(str(Negative_tweet['text'].tolist())))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:40.949757Z","iopub.execute_input":"2021-07-02T21:22:40.950163Z","iopub.status.idle":"2021-07-02T21:22:43.146958Z","shell.execute_reply.started":"2021-07-02T21:22:40.950121Z","shell.execute_reply":"2021-07-02T21:22:43.146126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unigrams_nseries =(pd.Series(nltk.ngrams(nwords, 1)).value_counts())[:30]\nunigrams_nseries.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring unigrams')\nplt.ylabel('unigram')\nplt.xlabel('# of Occurances')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:43.148228Z","iopub.execute_input":"2021-07-02T21:22:43.148682Z","iopub.status.idle":"2021-07-02T21:22:43.855651Z","shell.execute_reply.started":"2021-07-02T21:22:43.148649Z","shell.execute_reply":"2021-07-02T21:22:43.854905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bigrams_nseries =(pd.Series(nltk.ngrams(nwords, 2)).value_counts())[:30]\nbigrams_nseries.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring Bigrams')\nplt.ylabel('Bigram')\nplt.xlabel('# of Occurances')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:43.856627Z","iopub.execute_input":"2021-07-02T21:22:43.857027Z","iopub.status.idle":"2021-07-02T21:22:44.727676Z","shell.execute_reply.started":"2021-07-02T21:22:43.856998Z","shell.execute_reply":"2021-07-02T21:22:44.726961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trigrams_nseries =(pd.Series(nltk.ngrams(nwords, 3)).value_counts())[:20]\ntrigrams_nseries.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('20 Most Frequently Occuring trigrams')\nplt.ylabel('trigram')\nplt.xlabel('# of Occurances')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:44.728645Z","iopub.execute_input":"2021-07-02T21:22:44.729015Z","iopub.status.idle":"2021-07-02T21:22:45.58356Z","shell.execute_reply.started":"2021-07-02T21:22:44.728987Z","shell.execute_reply":"2021-07-02T21:22:45.582711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neuwords = basic_clean(''.join(str(Neutral_tweet['text'].tolist())))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:45.584618Z","iopub.execute_input":"2021-07-02T21:22:45.585019Z","iopub.status.idle":"2021-07-02T21:22:50.987711Z","shell.execute_reply.started":"2021-07-02T21:22:45.584989Z","shell.execute_reply":"2021-07-02T21:22:50.986879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unigrams_neuseries =(pd.Series(nltk.ngrams(neuwords, 1)).value_counts())[:30]\nunigrams_neuseries.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring unigrams')\nplt.ylabel('unigram')\nplt.xlabel('# of Occurances')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:50.988805Z","iopub.execute_input":"2021-07-02T21:22:50.989232Z","iopub.status.idle":"2021-07-02T21:22:52.148019Z","shell.execute_reply.started":"2021-07-02T21:22:50.989203Z","shell.execute_reply":"2021-07-02T21:22:52.146951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bigrams_neuseries =(pd.Series(nltk.ngrams(neuwords, 2)).value_counts())[:30]\nbigrams_neuseries.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring Bigrams')\nplt.ylabel('Bigram')\nplt.xlabel('# of Occurances')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:52.149513Z","iopub.execute_input":"2021-07-02T21:22:52.149965Z","iopub.status.idle":"2021-07-02T21:22:53.752716Z","shell.execute_reply.started":"2021-07-02T21:22:52.149919Z","shell.execute_reply":"2021-07-02T21:22:53.751674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trigrams_neuseries =(pd.Series(nltk.ngrams(neuwords, 3)).value_counts())[:30]\ntrigrams_neuseries.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))\nplt.title('30 Most Frequently Occuring trigrams')\nplt.ylabel('trigram')\nplt.xlabel('# of Occurances')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:53.754007Z","iopub.execute_input":"2021-07-02T21:22:53.754305Z","iopub.status.idle":"2021-07-02T21:22:55.452207Z","shell.execute_reply.started":"2021-07-02T21:22:53.754277Z","shell.execute_reply":"2021-07-02T21:22:55.451414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scattertext as st","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:55.453267Z","iopub.execute_input":"2021-07-02T21:22:55.453591Z","iopub.status.idle":"2021-07-02T21:22:55.745988Z","shell.execute_reply.started":"2021-07-02T21:22:55.453559Z","shell.execute_reply":"2021-07-02T21:22:55.744756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:55.747375Z","iopub.execute_input":"2021-07-02T21:22:55.747815Z","iopub.status.idle":"2021-07-02T21:22:55.76917Z","shell.execute_reply.started":"2021-07-02T21:22:55.747769Z","shell.execute_reply":"2021-07-02T21:22:55.767908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1=pd.DataFrame()\nfrom IPython.display import IFrame\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:55.770722Z","iopub.execute_input":"2021-07-02T21:22:55.771157Z","iopub.status.idle":"2021-07-02T21:22:55.780806Z","shell.execute_reply.started":"2021-07-02T21:22:55.771098Z","shell.execute_reply":"2021-07-02T21:22:55.779504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1=data.copy()\n\ndata1['binary_sentiment'] = data1['sentiment'].apply(lambda x: x if x ==\"Negative\" else \"non-negative\")\ndata1['date'] = data1['date'].apply(str)\n\ndata = data1.assign(\n    parse=lambda data: data.text.apply(st.whitespace_nlp_with_sentences)\n)\n\ncorpus = st.CorpusFromParsedDocuments(\n    data, category_col='binary_sentiment', parsed_col='parse'\n).build().get_unigram_corpus().compact(st.AssociationCompactor(2000))\n\nhtml = st.produce_scattertext_explorer(\n    corpus,\n    category='Negative', category_name='Negative', not_category_name='Neutral/Positive',\n    minimum_term_frequency=0, pmi_threshold_coefficient=0,\n    width_in_pixels=1000, metadata=corpus.get_df()['date'],\n    transform=st.Scalers.dense_rank\n    \n)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:22:55.782404Z","iopub.execute_input":"2021-07-02T21:22:55.782747Z","iopub.status.idle":"2021-07-02T21:24:26.534538Z","shell.execute_reply.started":"2021-07-02T21:22:55.782716Z","shell.execute_reply":"2021-07-02T21:24:26.533674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"open('./demo_compact.html', 'w').write(html)\nIFrame(src='./demo_compact.html', width=1200, height=700)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:24:26.535823Z","iopub.execute_input":"2021-07-02T21:24:26.536406Z","iopub.status.idle":"2021-07-02T21:24:26.58101Z","shell.execute_reply.started":"2021-07-02T21:24:26.536364Z","shell.execute_reply":"2021-07-02T21:24:26.579973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docs=Positive_tweet['text'].tolist()\ncv=CountVectorizer(max_df=0.85,stop_words='english',max_features=20000)\nword_count_vector=cv.fit_transform(docs)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:25:33.413106Z","iopub.execute_input":"2021-07-02T21:25:33.4135Z","iopub.status.idle":"2021-07-02T21:25:34.466071Z","shell.execute_reply.started":"2021-07-02T21:25:33.413466Z","shell.execute_reply":"2021-07-02T21:25:34.464953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count_vector","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:25:43.90586Z","iopub.execute_input":"2021-07-02T21:25:43.906216Z","iopub.status.idle":"2021-07-02T21:25:43.912661Z","shell.execute_reply.started":"2021-07-02T21:25:43.906186Z","shell.execute_reply":"2021-07-02T21:25:43.911323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(cv.vocabulary_.keys())[:10]","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:25:43.920188Z","iopub.execute_input":"2021-07-02T21:25:43.920555Z","iopub.status.idle":"2021-07-02T21:25:43.929471Z","shell.execute_reply.started":"2021-07-02T21:25:43.920524Z","shell.execute_reply":"2021-07-02T21:25:43.928205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\ntfidf_transformer.fit(word_count_vector)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:25:43.93675Z","iopub.execute_input":"2021-07-02T21:25:43.937554Z","iopub.status.idle":"2021-07-02T21:25:43.948385Z","shell.execute_reply.started":"2021-07-02T21:25:43.937502Z","shell.execute_reply":"2021-07-02T21:25:43.947345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Features of positive tweets using tf-idf:","metadata":{}},{"cell_type":"code","source":"\n\ndef sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n\ndef extract_topn_from_vector(feature_names, sorted_items, topn=32):\n    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n    \n    #use only topn items from vector\n    sorted_items = sorted_items[:topn]\n\n    score_vals = []\n    feature_vals = []\n    \n    # word index and corresponding tf-idf score\n    for idx, score in sorted_items:\n        \n        #keep track of feature name and its corresponding score\n        score_vals.append(round(score, 3))\n        feature_vals.append(feature_names[idx])\n\n    #create a tuples of feature,score\n    #results = zip(feature_vals,score_vals)\n    results= {}\n    for idx in range(len(feature_vals)):\n        results[feature_vals[idx]]=score_vals[idx]\n    \n    return results\n\n\nfeature_names=cv.get_feature_names()\n\n\n#generate tf-idf for the given document\ntf_idf_vector=tfidf_transformer.transform(cv.transform(docs))\n\n#sort the tf-idf vectors by descending order of scores\nsorted_items=sort_coo(tf_idf_vector.tocoo())\n\n#extract only the top n; n here is 32\nkeywords=extract_topn_from_vector(feature_names,sorted_items,32)\n\n\nprint(\"\\n===Keywords===\")\nfor k in keywords:\n    print(k,keywords[k])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:27:02.519383Z","iopub.execute_input":"2021-07-02T21:27:02.519772Z","iopub.status.idle":"2021-07-02T21:27:05.249154Z","shell.execute_reply.started":"2021-07-02T21:27:02.519741Z","shell.execute_reply":"2021-07-02T21:27:05.247981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ndocs=Negative_tweet['text'].tolist()\nneudocs=Neutral_tweet['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:27:07.362697Z","iopub.execute_input":"2021-07-02T21:27:07.363062Z","iopub.status.idle":"2021-07-02T21:27:07.371809Z","shell.execute_reply.started":"2021-07-02T21:27:07.363031Z","shell.execute_reply":"2021-07-02T21:27:07.370503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count_vector_neu=cv.fit_transform(neudocs)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T21:27:07.40687Z","iopub.execute_input":"2021-07-02T21:27:07.407216Z","iopub.status.idle":"2021-07-02T21:27:08.759444Z","shell.execute_reply.started":"2021-07-02T21:27:07.407186Z","shell.execute_reply":"2021-07-02T21:27:08.758423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nword_count_vector_neu","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:22.725342Z","iopub.execute_input":"2021-07-02T21:27:22.725733Z","iopub.status.idle":"2021-07-02T21:27:22.73416Z","shell.execute_reply.started":"2021-07-02T21:27:22.725702Z","shell.execute_reply":"2021-07-02T21:27:22.732929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(cv.vocabulary_.keys())[:10]","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:22.741698Z","iopub.execute_input":"2021-07-02T21:27:22.742546Z","iopub.status.idle":"2021-07-02T21:27:22.74934Z","shell.execute_reply.started":"2021-07-02T21:27:22.742507Z","shell.execute_reply":"2021-07-02T21:27:22.748189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_transformer.fit(word_count_vector_neu)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:22.761583Z","iopub.execute_input":"2021-07-02T21:27:22.761962Z","iopub.status.idle":"2021-07-02T21:27:22.773212Z","shell.execute_reply.started":"2021-07-02T21:27:22.76193Z","shell.execute_reply":"2021-07-02T21:27:22.771874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Features of neutral tweets using tf-idf:","metadata":{}},{"cell_type":"code","source":"feature_names=cv.get_feature_names()\n\n\n\n\n#generate tf-idf for the given document\ntf_idf_vector=tfidf_transformer.transform(cv.transform(neudocs))\n\n#sort the tf-idf vectors by descending order of scores\nsorted_items=sort_coo(tf_idf_vector.tocoo())\n\n#extract only the top n; n here is 32\nkeywords=extract_topn_from_vector(feature_names,sorted_items,32)\n\n\nprint(\"\\n===Keywords===\")\nfor k in keywords:\n    print(k,keywords[k])\n\n\ndef sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n\ndef extract_topn_from_vector(feature_names, sorted_items, topn=32):\n    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n    \n    #use only topn items from vector\n    sorted_items = sorted_items[:topn]\n\n    score_vals = []\n    feature_vals = []\n    \n    # word index and corresponding tf-idf score\n    for idx, score in sorted_items:\n        \n        #keep track of feature name and its corresponding score\n        score_vals.append(round(score, 3))\n        feature_vals.append(feature_names[idx])\n\n    #create a tuples of feature,score\n    #results = zip(feature_vals,score_vals)\n    results= {}\n    for idx in range(len(feature_vals)):\n        results[feature_vals[idx]]=score_vals[idx]\n    \n    return results","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:22.779293Z","iopub.execute_input":"2021-07-02T21:27:22.779694Z","iopub.status.idle":"2021-07-02T21:27:26.268369Z","shell.execute_reply.started":"2021-07-02T21:27:22.779662Z","shell.execute_reply":"2021-07-02T21:27:26.267296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_count_vector_n=cv.fit_transform(ndocs)\nlist(cv.vocabulary_.keys())[:10]","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:26.269885Z","iopub.execute_input":"2021-07-02T21:27:26.270189Z","iopub.status.idle":"2021-07-02T21:27:26.842204Z","shell.execute_reply.started":"2021-07-02T21:27:26.270161Z","shell.execute_reply":"2021-07-02T21:27:26.840971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_transformer.fit(word_count_vector_n)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:26.844163Z","iopub.execute_input":"2021-07-02T21:27:26.844522Z","iopub.status.idle":"2021-07-02T21:27:26.854031Z","shell.execute_reply.started":"2021-07-02T21:27:26.844486Z","shell.execute_reply":"2021-07-02T21:27:26.852769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Features of negative tweets using tf-idf:","metadata":{}},{"cell_type":"code","source":"feature_names=cv.get_feature_names()\n\n\n\n\n#generate tf-idf for the given document\ntf_idf_vector=tfidf_transformer.transform(cv.transform(ndocs))\n\n#sort the tf-idf vectors by descending order of scores\nsorted_items=sort_coo(tf_idf_vector.tocoo())\n\n#extract only the top n; n here is 32\nkeywords=extract_topn_from_vector(feature_names,sorted_items,100)\n\n\nprint(\"\\n===Keywords===\")\nfor k in keywords:\n    print(k,keywords[k])\n\n\ndef sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n\ndef extract_topn_from_vector(feature_names, sorted_items, topn=32):\n    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n    \n    #use only topn items from vector\n    sorted_items = sorted_items[:topn]\n\n    score_vals = []\n    feature_vals = []\n    \n    # word index and corresponding tf-idf score\n    for idx, score in sorted_items:\n        \n        #keep track of feature name and its corresponding score\n        score_vals.append(round(score, 3))\n        feature_vals.append(feature_names[idx])\n\n    #create a tuples of feature,score\n    #results = zip(feature_vals,score_vals)\n    results= {}\n    for idx in range(len(feature_vals)):\n        results[feature_vals[idx]]=score_vals[idx]\n    \n    return results","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-07-02T21:27:26.855639Z","iopub.execute_input":"2021-07-02T21:27:26.855969Z","iopub.status.idle":"2021-07-02T21:27:28.448709Z","shell.execute_reply.started":"2021-07-02T21:27:26.855938Z","shell.execute_reply":"2021-07-02T21:27:28.447661Z"},"trusted":true},"execution_count":null,"outputs":[]}]}