{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Botezlive chat classification model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport sklearn.feature_extraction.text as ft\nimport sklearn.feature_selection as fs\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nimport sklearn.svm as svm\nimport sklearn.calibration as cal\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix,plot_roc_curve,brier_score_loss\nfrom sklearn.metrics import plot_precision_recall_curve,classification_report\nfrom sklearn.metrics import precision_score,roc_auc_score,log_loss\nfrom sklearn.metrics import confusion_matrix,jaccard_score,f1_score,recall_score\nfrom sklearn.preprocessing import FunctionTransformer\nimport seaborn as sns\nimport numpy as np\nimport time\nimport datetime\nimport sklearn.pipeline as pipe\nfrom lime import lime_text\nfrom nltk.corpus import stopwords\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n#from emotes import emotes\nfrom sklearn.decomposition import TruncatedSVD\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalMaxPooling1D, Conv1D, Embedding, LSTM\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom wordcloud import WordCloud, STOPWORDS\nstop_words=set(stopwords.words('english'))\nstopwords = set(STOPWORDS)\nimport warnings\nwarnings.filterwarnings(\"ignore\", 'This pattern has match groups')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:23:01.922275Z","iopub.execute_input":"2021-08-25T20:23:01.922552Z","iopub.status.idle":"2021-08-25T20:23:09.574339Z","shell.execute_reply.started":"2021-08-25T20:23:01.922526Z","shell.execute_reply":"2021-08-25T20:23:09.573278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip3 install tensorflow","metadata":{"execution":{"iopub.status.busy":"2021-08-15T16:59:21.545212Z","iopub.execute_input":"2021-08-15T16:59:21.545546Z","iopub.status.idle":"2021-08-15T16:59:21.549136Z","shell.execute_reply.started":"2021-08-15T16:59:21.545517Z","shell.execute_reply":"2021-08-15T16:59:21.548433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/d/brandonbenton/botezlive-chat-classification/botezlive_data.csv\")\n#tmp = pd.read_csv('./data/botezlive_dataframe.csv',low_memory=False,keep_default_na=False)\n\n#df = tmp[['message','moderated']].copy()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:23:09.57682Z","iopub.execute_input":"2021-08-25T20:23:09.577152Z","iopub.status.idle":"2021-08-25T20:23:19.173115Z","shell.execute_reply.started":"2021-08-25T20:23:09.577121Z","shell.execute_reply":"2021-08-25T20:23:19.172045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.rename(columns={'message':'text','moderated':'is_offensive'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T16:59:29.425689Z","iopub.execute_input":"2021-08-15T16:59:29.426022Z","iopub.status.idle":"2021-08-15T16:59:29.429633Z","shell.execute_reply.started":"2021-08-15T16:59:29.42599Z","shell.execute_reply":"2021-08-15T16:59:29.428683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Funcs for wordclouds**","metadata":{}},{"cell_type":"code","source":"def clean_text(row):\n    words = []\n    for w in row.split():\n        word = re.sub('[^A-Za-z0-9]+', '', str(w))\n        words.append(word.lower())\n    return words\n\ndef get_words(df,text_label='text',target_label='is_offensive',value=0):\n    words = []\n    for row in df[df[target_label]==value].iloc[:][text_label]:\n        words += clean_text(row)\n    return ' '.join(words)    \n\ndef get_wordcloud(df,text_label='text',target_label='is_offensive',value=0):\n    words = get_words(df,text_label=text_label,target_label=target_label,value=value)\n    wc = WordCloud(background_color='white',\n                   max_words=500,\n                   stopwords=stopwords)\n    wc.generate(words)\n    return wc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Trim features based on chi2 score**","metadata":{}},{"cell_type":"code","source":"def split_data(df,params):\n#trim number of zeros from dataset\n    df_ones = df.loc[df[\"is_offensive\"]==1]\n    df_tmp = df.loc[df[\"is_offensive\"]==0]\n        \n    ratio = len(df_ones)/len(df_tmp)\n\n    msk = np.random.rand(len(df_tmp)) < params['multiplier']*ratio\n    df_zeros = df_tmp.loc[msk]\n    \n    df = pd.concat([df_ones,df_zeros]).reset_index(drop=True)\n    df_train,df_test = train_test_split(df,test_size=0.2,random_state=0)\n    \n    return df_train,df_test","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-25T20:23:19.174861Z","iopub.execute_input":"2021-08-25T20:23:19.175159Z","iopub.status.idle":"2021-08-25T20:23:19.182056Z","shell.execute_reply.started":"2021-08-25T20:23:19.17513Z","shell.execute_reply":"2021-08-25T20:23:19.181032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get tfidf vectorizer**","metadata":{}},{"cell_type":"code","source":"def get_vectorizer(df_train,params):\n    vparams = dict({'stop_words':stop_words,#None,#stop_words,\n                    'min_df':params['min_df'],\n                    'max_df':params['max_df'],\n                    'smooth_idf':params['smooth_idf'],\n                    'analyzer':params['analyzer'],\n                    'ngram_range':params['ngram_range'],\n                    'sublinear_tf':params['sublinear_tf'],\n                    'max_features':params['max_features'],\n                    })\n    \n    vectorizer = ft.TfidfVectorizer(**vparams)\n    x_train = vectorizer.fit_transform(df_train['text'])\n    \n    if params[\"trim features\"]:\n    \n        y = df_train['is_offensive']#y_train\n        x_names = vectorizer.get_feature_names()\n        p_value_limit = params['pvalue limit']\n    \n        dtf_features = pd.DataFrame()\n        for cat in np.unique(y):\n            chi2, p_value = fs.chi2(x_train, y==cat)\n            entry = pd.DataFrame({\"feature\":x_names, \"score\":1-p_value, \"y\":cat})\n            dtf_features = dtf_features.append(entry)\n            dtf_features = dtf_features.sort_values([\"y\",\"score\"], \n                    ascending=[True,False])\n            dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n        x_names = dtf_features[\"feature\"].unique().tolist()   \n    \n        vparams['vocabulary'] = x_names\n        vectorizer = ft.TfidfVectorizer(**vparams)\n    \n    return vectorizer","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-25T20:23:19.183203Z","iopub.execute_input":"2021-08-25T20:23:19.183557Z","iopub.status.idle":"2021-08-25T20:23:19.201909Z","shell.execute_reply.started":"2021-08-25T20:23:19.183527Z","shell.execute_reply":"2021-08-25T20:23:19.20079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dual_vectorizer(df_train,p1,p2):\n\n    vec1 = get_vectorizer(df_train,p1)\n    vec2 = get_vectorizer(df_train,p2)\n    \n    features = set(vec1.get_feature_names()) | set(vec2.get_feature_names())\n    features = list(features)\n    \n    vectorizer = ft.TfidfVectorizer(vocabulary=features,max_features=p1['max_features'])\n    \n    return vectorizer\n    ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-25T20:23:19.205719Z","iopub.execute_input":"2021-08-25T20:23:19.206064Z","iopub.status.idle":"2021-08-25T20:23:19.21319Z","shell.execute_reply.started":"2021-08-25T20:23:19.206032Z","shell.execute_reply":"2021-08-25T20:23:19.212545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pca(params):\n    pca = TruncatedSVD(n_components=params['n_components'])\n    #pca.fit(X)\n    #principalDf = pd.DataFrame(data = principalComponents,\n    #                           columns = ['%s' %(i) for i in range(n_components)])\n    return pca\n    ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-25T20:23:19.214506Z","iopub.execute_input":"2021-08-25T20:23:19.215201Z","iopub.status.idle":"2021-08-25T20:23:19.228876Z","shell.execute_reply.started":"2021-08-25T20:23:19.215159Z","shell.execute_reply":"2021-08-25T20:23:19.227974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Builds dictionary of scores based on parameter set","metadata":{}},{"cell_type":"code","source":"#def param_score(df,params):\ndef transformer(x):\n    return np.array(x.toarray())\n\ndef param_score(df,params):\n    \n    df_train,df_test = split_data(df,params)\n    vectorizer = get_vectorizer(df_train,params)\n    model = get_model(params)\n    \n    y_train = df_train['is_offensive']\n    y_test = df_test['is_offensive']\n    \n    num_splits = 1\n    \n    if params['classifier_type']=='NN': \n        \n        nn = KerasClassifier(build_fn=lambda:model)\n        nn._estimator_type = \"classifier\"\n        vectorizer.fit(df_train['text'])\n        num_rows = df_train.shape[0]\n        num_splits = 1#num_rows//5000 + 1\n        \n        print(\"Number of samples: %s\" %num_rows)\n        print(\"Number of splits: %s\" %num_splits)\n        \n        if params['pca']:\n            pca = get_pca(params)\n            pca.fit(vectorizer.transform(df_train['text']))            \n\n        if num_splits == 1 and params['pca']:\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('pca',pca),\n                                         ('classifier',nn)])\n            my_pipeline.fit(df_train['text'],df_train['is_offensive'],\n                            classifier__verbose=1,\n                            classifier__epochs=params['epochs'],\n                            classifier__batch_size=4)\n        \n        elif num_splits == 1 and not params['pca']:\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('transformer',FunctionTransformer(transformer)),\n                                         ('classifier',nn)])\n            my_pipeline.fit(df_train['text'],df_train['is_offensive'],\n                            classifier__verbose=1,\n                            classifier__epochs=params['epochs'],\n                            classifier__batch_size=4)\n            \n        elif num_splits > 1 and params['pca']:\n            pca.fit(vectorizer.transform(df_train['text'])) \n            df_array = np.array_split(df_train,num_splits)\n            for i in range(num_splits):\n                print(\"Split number: %s\" %i)\n                df_tmp = df_array[i]\n                nn.fit(pca.transform(vectorizer.transform(df_tmp['text'])),\n                       df_tmp['is_offensive'],verbose=1,\n                       epochs=params['epochs'],batch_size=4)\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('pca',pca),\n                                         ('classifier',nn)])    \n                \n        elif num_splits > 1 and not params['pca']:\n            df_array = np.array_split(df_train,num_splits)\n            for i in range(num_splits):\n                print(\"Split number: %s\" %i)\n                df_tmp = df_array[i]\n                nn.fit(transformer(vectorizer.transform(df_tmp['text'])),\n                       df_tmp['is_offensive'],verbose=1,\n                       epochs=params['epochs'],batch_size=4)\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('transformer',FunctionTransformer(transformer)),\n                                         ('classifier',nn)])         \n        \n    else:# params['classifier_type']=='SVM': \n        clf = cal.CalibratedClassifierCV(model,cv=p1['cv'],method='sigmoid')\n        if params['pca']:\n            pca = get_pca(params)\n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('pca',pca),\n                                         ('classifier',clf)])\n    \n        else:       \n            my_pipeline = pipe.Pipeline([('vectorizer',vectorizer),\n                                         ('classifier',clf)])\n    \n        my_pipeline.fit(df_train['text'],df_train['is_offensive'])\n    \n    score = my_pipeline.score(df_test['text'],df_test['is_offensive'])\n    print('test accuracy: %s' %score)\n\n    discrete_preds = my_pipeline.predict(df_test['text'])\n    confusion = confusion_matrix(y_test,discrete_preds)\n    \n    test_ones = sum(confusion[1][:])\n    test_zeros = sum(confusion[0][:])\n    \n    scores = dict({'classifier_type':params['classifier_type'],\n                   'splits':num_splits,\n                   'n_samples':df_train.shape[0],\n                   'ngram_range':params['ngram_range'],\n                   'pca':params['pca'],\n                   'n_components':params['n_components'],\n                   'max_features':params['max_features'],\n                   'trim features':params['trim features'],\n                   'pvalue limit':params['pvalue limit'],\n                   'multiplier':params['multiplier'],\n                   'precision':precision_score(y_test,discrete_preds),\n                   'jaccard':jaccard_score(y_test,discrete_preds),\n                   'recall':recall_score(y_test,discrete_preds),\n                   'F1':f1_score(y_test,discrete_preds),\n                   'TP':confusion[1][1]/test_ones,\n                   'FP':confusion[0][1]/test_zeros,\n                   'TN':confusion[0][0]/test_zeros,\n                   'FN':confusion[1][0]/test_ones,                   \n                  })\n    \n    return my_pipeline,discrete_preds,df_train,df_test,scores","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:23:19.230148Z","iopub.execute_input":"2021-08-25T20:23:19.230425Z","iopub.status.idle":"2021-08-25T20:23:19.256224Z","shell.execute_reply.started":"2021-08-25T20:23:19.230399Z","shell.execute_reply":"2021-08-25T20:23:19.255216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Neural network model**","metadata":{}},{"cell_type":"code","source":"def get_model(params):\n    \n    if params['classifier_type'] == 'NN':\n        if params['pca']: feature_num = params['n_components']\n        else: feature_num = params['max_features']    \n    \n        model = Sequential()\n        #model.add(Embedding(feature_num,128))\n        #model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n        model.add(Dense(128,activation='relu',\n              input_shape=(feature_num,)))\n        model.add(Dense(64,activation='relu'))\n        model.add(Dense(1,activation='sigmoid'))\n        model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n   \n        model.summary()\n    \n    if params['classifier_type'] == 'SVM':\n        cparams = dict({'max_iter':1000,'C':params['C'],'class_weight':params['class_weight']})\n        model = svm.LinearSVC(**cparams)\n        \n    if params['classifier_type'] == 'RFC':\n        model = RandomForestClassifier()\n        \n\n    return model#KerasClassifier(model_nn)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:23:19.257532Z","iopub.execute_input":"2021-08-25T20:23:19.257916Z","iopub.status.idle":"2021-08-25T20:23:19.274281Z","shell.execute_reply.started":"2021-08-25T20:23:19.257884Z","shell.execute_reply":"2021-08-25T20:23:19.273334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Goes through each parameter set and builds dataframe with accuracy scores","metadata":{}},{"cell_type":"code","source":"headers = ['classifier_type',\n           'splits',\n           'n_samples',\n           'ngram_range',\n           'trim features',\n           'pca','n_components',\n           'max_features',\n           'pvalue limit',\n           'multiplier',\n           'precision',\n           'jaccard',\n           'recall',\n           'F1',\n           'TP', 'FP','TN','FN']\ndf_scores = pd.DataFrame(columns=headers)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:23:19.275518Z","iopub.execute_input":"2021-08-25T20:23:19.275891Z","iopub.status.idle":"2021-08-25T20:23:19.297739Z","shell.execute_reply.started":"2021-08-25T20:23:19.275861Z","shell.execute_reply":"2021-08-25T20:23:19.296658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p1 = dict({'classifier_type':'SVM',\n           'min_df':1,\n           'max_df':0.9,\n           'smooth_idf':1,\n           'sublinear_tf':1,\n           'ngram_range':(2,10),\n           'max_features':None,\n           'C':1.0,\n           'cv':5,\n           'analyzer':'char_wb',\n           'trim features':False,\n           'pvalue limit':0.4,\n           'class_weight':None,\n           'multiplier':1,\n           'n_components':400,\n           'epochs':10,\n           'pca':False})\n\np2 = p1.copy()\np2['classifier_type'] = 'NN'\np2['max_features'] = 20000\np2['pca'] = True","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-25T20:23:19.299095Z","iopub.execute_input":"2021-08-25T20:23:19.299513Z","iopub.status.idle":"2021-08-25T20:23:19.312Z","shell.execute_reply.started":"2021-08-25T20:23:19.299481Z","shell.execute_reply":"2021-08-25T20:23:19.310841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2021-08-15T16:59:29.571092Z","iopub.execute_input":"2021-08-15T16:59:29.571374Z","iopub.status.idle":"2021-08-15T16:59:29.584045Z","shell.execute_reply.started":"2021-08-15T16:59:29.571345Z","shell.execute_reply":"2021-08-15T16:59:29.582781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_list = [p1]\n\nfor i,p in enumerate(params_list):\n    \n    start = time.time()\n    model,discrete_preds,df_train,df_test,scores = param_score(df,p)\n    df_scores = df_scores.append(scores,ignore_index=True)\n\n    end = time.time()\n    elapsed = end - start\n    \n    remaining_seconds = elapsed*(len(params_list)-i-1)\n    print(\"Done: {:.5f}, Remaining: {:<25}\".format((i+1)/len(params_list),str(datetime.timedelta(seconds=remaining_seconds))),end=\"\\r\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-25T20:23:26.007812Z","iopub.execute_input":"2021-08-25T20:23:26.008242Z","iopub.status.idle":"2021-08-25T20:24:49.294693Z","shell.execute_reply.started":"2021-08-25T20:23:26.008209Z","shell.execute_reply":"2021-08-25T20:24:49.29371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average of accuracy scores","metadata":{}},{"cell_type":"code","source":"df_scores[\"avg score\"]=df_scores[['precision','recall','jaccard','F1','TP','TN']].values.mean(axis=1)\ndf_scores","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:24:49.296597Z","iopub.execute_input":"2021-08-25T20:24:49.297056Z","iopub.status.idle":"2021-08-25T20:24:49.331672Z","shell.execute_reply.started":"2021-08-25T20:24:49.297011Z","shell.execute_reply":"2021-08-25T20:24:49.330646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Select parameter set with highest average accuracy","metadata":{}},{"cell_type":"code","source":"df_scores.sort_values(by='avg score', ascending=False, inplace=True)\ndf_scores.head(1)\n\n#df_scores.loc[0,'avg score']","metadata":{"execution":{"iopub.status.busy":"2021-08-15T16:59:40.302659Z","iopub.status.idle":"2021-08-15T16:59:40.303121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification explainer","metadata":{}},{"cell_type":"code","source":"txt_instance = \"its so hot out\"\n\nexplainer = lime_text.LimeTextExplainer(class_names=\n            np.unique(df_train['is_offensive']))\nexplained = explainer.explain_instance(txt_instance, \n            model.predict_proba, num_features=5)\nexplained.show_in_notebook(text=txt_instance, predict_proba=True)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-08-15T16:59:40.304045Z","iopub.status.idle":"2021-08-15T16:59:40.304459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot evaluation curves and confusion matrix","metadata":{}},{"cell_type":"code","source":"def plot_score_curves(clf,X,Y):\n     \n    ax = plt.gca()\n\n    preds = clf.predict_proba(X)[:,1]\n    discrete_preds = clf.predict(X)\n    \n    clf_score = brier_score_loss(Y,preds,pos_label=1)\n    frac_of_positives,mean_predicted_value = cal.calibration_curve(Y,preds,n_bins=20)\n    ax.plot(mean_predicted_value,frac_of_positives,\"s-\",label=\"Sigmoid calibration (Brier loss={:.4f})\".format(clf_score))\n\n    clf_score = brier_score_loss(Y,discrete_preds,pos_label=1)\n    frac_of_positives,mean_predicted_value = cal.calibration_curve(Y,discrete_preds,n_bins=20)\n    ax.plot(mean_predicted_value,frac_of_positives,\"s-\",label=\"Discrete predictions (Brier loss={:.4f})\".format(clf_score))\n\n    ax.plot([0,1],[0,1],\"s--\",label=\"Perfectly calibrated\".format(clf_score))\n\n    plt.legend()\n    \n    plot_roc_curve(clf,X,Y)\n    \n    plot_precision_recall_curve(clf,X,Y)\n    \n    plot_confusion_matrix(clf,X,Y)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:24:49.333151Z","iopub.execute_input":"2021-08-25T20:24:49.333433Z","iopub.status.idle":"2021-08-25T20:24:49.342027Z","shell.execute_reply.started":"2021-08-25T20:24:49.333406Z","shell.execute_reply":"2021-08-25T20:24:49.340808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_score_curves(model,df_test['text'],df_test['is_offensive'])","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:24:49.343282Z","iopub.execute_input":"2021-08-25T20:24:49.343575Z","iopub.status.idle":"2021-08-25T20:25:14.992749Z","shell.execute_reply.started":"2021-08-25T20:24:49.343546Z","shell.execute_reply":"2021-08-25T20:25:14.991692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_score_curves(model,df_train['text'],df_train['is_offensive'])","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:28:47.599504Z","iopub.execute_input":"2021-08-25T20:28:47.600014Z","iopub.status.idle":"2021-08-25T20:30:25.916943Z","shell.execute_reply.started":"2021-08-25T20:28:47.599976Z","shell.execute_reply":"2021-08-25T20:30:25.915464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\n\ndf_samp = df_train\n\ndf_samp['prediction'] = model.predict(df_train['text']) #discrete_preds\n\nfor i in range(4):\n    fig.add_subplot(2,2,i+1)\n    #try:\n    label = (i+1) % 2\n    \n    if 0 <= i <= 1:\n        wc = get_wordcloud(df_samp,text_label='text',target_label='is_offensive',value=label)\n        plt.title('Ground Truth: %s' %label)\n    else:   \n        wc = get_wordcloud(df_samp,text_label='text',target_label='prediction',value=label)\n        plt.title('Prediction: %s' %label)\n   #fig = plt.figure(figsize=(10,5))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    #except:\n     #   pass\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-15T17:43:26.822935Z","iopub.execute_input":"2021-08-15T17:43:26.823587Z","iopub.status.idle":"2021-08-15T17:43:58.380281Z","shell.execute_reply.started":"2021-08-15T17:43:26.823542Z","shell.execute_reply":"2021-08-15T17:43:58.379211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}