{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimage_path = '/kaggle/input/kermany2018/oct2017/OCT2017 '\noct_csv_path = '/kaggle/input/oct-csv/'\ntrain_dir = image_path + \"/train/\"\nvalid_dir = image_path + \"/val/\"\ntest_dir = image_path + \"/test/\"","metadata":{"execution":{"iopub.status.busy":"2021-08-13T23:26:15.501205Z","iopub.execute_input":"2021-08-13T23:26:15.501555Z","iopub.status.idle":"2021-08-13T23:26:15.508251Z","shell.execute_reply.started":"2021-08-13T23:26:15.501523Z","shell.execute_reply":"2021-08-13T23:26:15.507131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\ncols = [x.upper() for x in classes]\ndirs = [train_dir, valid_dir, test_dir]\nlabel = {0: 'CNV', 1: 'DME', 2: 'DRUSEN', 3: 'NORMAL'}\nIMG_SIZE = 224\n\n# if we should read the directory structre, if False then use the CSV files already saved\n# Once you generate the csv files you should probably download them and re-upload into kaggle and set this to FALSE\nREGEN = False ","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.57949Z","iopub.execute_input":"2021-08-13T20:24:48.580403Z","iopub.status.idle":"2021-08-13T20:24:48.589461Z","shell.execute_reply.started":"2021-08-13T20:24:48.580233Z","shell.execute_reply":"2021-08-13T20:24:48.588252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_df (path, classes=classes):\n  df = pd.DataFrame(columns=['FILENAME', 'CNV', 'DME', 'DRUSEN', 'NORMAL'])\n  for sub_dir in classes:\n    condition = {'NORMAL': 0, 'CNV': 0, 'DME':0, 'DRUSEN': 0}\n    files = os.listdir(path + sub_dir)\n    if (sub_dir== 'NORMAL'):\n      condition['NORMAL'] = 1\n    elif (sub_dir == 'CNV'):\n      condition['CNV'] = 1\n    elif (sub_dir == 'DME'):\n      condition['DME'] = 1\n    else:\n      condition['DRUSEN']= 1\n    for f in files:\n      df = df.append({'FILENAME': path +  sub_dir  + \"/\" + f, \n                      'NORMAL': condition['NORMAL'], \n                      'CNV': condition['CNV'],\n                      'DME': condition['DME'],\n                      'DRUSEN': condition['DRUSEN']}, ignore_index=True)\n  return df","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.592325Z","iopub.execute_input":"2021-08-13T20:24:48.593192Z","iopub.status.idle":"2021-08-13T20:24:48.604663Z","shell.execute_reply.started":"2021-08-13T20:24:48.593148Z","shell.execute_reply":"2021-08-13T20:24:48.603734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generting the DataFrames of the filenames\n# this is primarily used so we can sub-sample files easier for the different training strategies\nif (REGEN):\n  train_df = create_df(train_dir)\n  valid_df = create_df(valid_dir)\n  test_df = create_df(test_dir)\n  train_df.to_csv(\"train_data.csv\")\n  valid_df.to_csv(\"valid_data.csv\")\n  test_df.to_csv(\"test_data.csv\")\nelse:\n  train_df = pd.read_csv(oct_csv_path + \"train_data.csv\")\n  valid_df = pd.read_csv(oct_csv_path + \"valid_data.csv\")\n  test_df = pd.read_csv(oct_csv_path + \"test_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.606923Z","iopub.execute_input":"2021-08-13T20:24:48.607705Z","iopub.status.idle":"2021-08-13T20:24:48.826079Z","shell.execute_reply.started":"2021-08-13T20:24:48.607662Z","shell.execute_reply":"2021-08-13T20:24:48.825106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Training Data: \", train_df.shape)\nprint (\"Validation Data: \", valid_df.shape)\nprint (\"Test Data: \", test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.82758Z","iopub.execute_input":"2021-08-13T20:24:48.827999Z","iopub.status.idle":"2021-08-13T20:24:48.838237Z","shell.execute_reply.started":"2021-08-13T20:24:48.827957Z","shell.execute_reply":"2021-08-13T20:24:48.837274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing out the # of samples for each subsample percentage \nprint (\"Trainig Data percentages:\")\nprint (\" 1% ==> \", int(.01 * train_df.shape[0]))\nprint (\" 5% ==> \", int(.05 * train_df.shape[0]))\nprint (\"10% ==> \", int(.1  * train_df.shape[0]))\nprint (\"25% ==> \", int(.25 * train_df.shape[0]))\nprint (\"50% ==> \", int(.5  * train_df.shape[0]))\nprint (\"75% ==> \", int(.75 * train_df.shape[0]))\nprint (\"90% ==> \", int(.9  * train_df.shape[0]))\nprint (\"98% ==> \", int(.98 * train_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.839967Z","iopub.execute_input":"2021-08-13T20:24:48.84043Z","iopub.status.idle":"2021-08-13T20:24:48.852373Z","shell.execute_reply.started":"2021-08-13T20:24:48.840386Z","shell.execute_reply":"2021-08-13T20:24:48.851134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sampling 50% of the data\nsample = train_df.sample(frac=0.5, random_state=10, axis=0)\nsample.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.854101Z","iopub.execute_input":"2021-08-13T20:24:48.854713Z","iopub.status.idle":"2021-08-13T20:24:48.878229Z","shell.execute_reply.started":"2021-08-13T20:24:48.854671Z","shell.execute_reply":"2021-08-13T20:24:48.877007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# determine class weights to feed into neural network during training\ndef get_classweight(df):\n  total = df.shape[0]\n  num_norm = df['NORMAL'].sum()\n  num_cnv = df['CNV'].sum()\n  num_dme = df['DME'].sum()\n  num_drusen = df['DRUSEN'].sum()\n  norm_weight = (1/num_norm) * (total/4)\n  cnv_weight = (1/num_cnv) * (total/4)\n  dme_weight = (1/num_dme) * (total/4)\n  drusen_weight = (1/num_drusen) * (total/4)\n  class_weight = {0 : cnv_weight, 1: dme_weight,\n                  2 : drusen_weight, 3: norm_weight}\n  return class_weight","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.879939Z","iopub.execute_input":"2021-08-13T20:24:48.880343Z","iopub.status.idle":"2021-08-13T20:24:48.888152Z","shell.execute_reply.started":"2021-08-13T20:24:48.880305Z","shell.execute_reply":"2021-08-13T20:24:48.88704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weight = get_classweight(sample)\nclass_weight","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.891842Z","iopub.execute_input":"2021-08-13T20:24:48.892453Z","iopub.status.idle":"2021-08-13T20:24:48.906623Z","shell.execute_reply.started":"2021-08-13T20:24:48.892406Z","shell.execute_reply":"2021-08-13T20:24:48.905439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nimport tensorflow.keras.applications as app\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:48.908758Z","iopub.execute_input":"2021-08-13T20:24:48.909528Z","iopub.status.idle":"2021-08-13T20:24:53.836237Z","shell.execute_reply.started":"2021-08-13T20:24:48.909485Z","shell.execute_reply":"2021-08-13T20:24:53.835105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_datagen = ImageDataGenerator(rotation_range=90, width_shift_range=[-.1,.1], height_shift_range=[-.1,.1],\n                                         shear_range=0.25, zoom_range=0.3, horizontal_flip=True,\n                                         vertical_flip=True, rescale = 1./255., validation_split=0.1)\n\n# Setting the imgages to come from the dataframe where we specify the filenames and columns to use for \"labels\"\ntrain_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"training\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)\nvalid_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"validation\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:24:53.837701Z","iopub.execute_input":"2021-08-13T20:24:53.838148Z","iopub.status.idle":"2021-08-13T20:25:44.137Z","shell.execute_reply.started":"2021-08-13T20:24:53.838105Z","shell.execute_reply":"2021-08-13T20:25:44.135257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the model based on Xception Network\ninput_layer = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nbase_model = app.xception.Xception(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE,3))\nbase_model.trainable = True\n\nx = base_model(input_layer)\nx = keras.layers.GlobalAveragePooling2D()(x)\noutput = keras.layers.Dense(4, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=input_layer, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:25:44.138516Z","iopub.execute_input":"2021-08-13T20:25:44.138946Z","iopub.status.idle":"2021-08-13T20:25:48.786183Z","shell.execute_reply.started":"2021-08-13T20:25:44.138903Z","shell.execute_reply":"2021-08-13T20:25:48.785226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code did not work, it caused I/O Error 5:\n# model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics='accuracy')\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=[tfa.metrics.F1Score(4,\"micro\"), \"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:25:48.787591Z","iopub.execute_input":"2021-08-13T20:25:48.787992Z","iopub.status.idle":"2021-08-13T20:25:48.815444Z","shell.execute_reply.started":"2021-08-13T20:25:48.787952Z","shell.execute_reply":"2021-08-13T20:25:48.814565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a checkpoint to save the best model so that we can reload it once training is complete\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"oct_xception50per.h5\", save_best_only=True)\n# Adding an an early stop callback to avoid overfitting in case the model is not improving after 5 consescutive epochs\nearlystop_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:25:48.816876Z","iopub.execute_input":"2021-08-13T20:25:48.81727Z","iopub.status.idle":"2021-08-13T20:25:48.822741Z","shell.execute_reply.started":"2021-08-13T20:25:48.81723Z","shell.execute_reply":"2021-08-13T20:25:48.8216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_imgs,  steps_per_epoch=1000, epochs=100, verbose=1, validation_data=valid_imgs, \n                    class_weight=class_weight, callbacks=[checkpoint_cb, earlystop_cb])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T20:25:48.824499Z","iopub.execute_input":"2021-08-13T20:25:48.825133Z","iopub.status.idle":"2021-08-13T23:18:13.388174Z","shell.execute_reply.started":"2021-08-13T20:25:48.825046Z","shell.execute_reply":"2021-08-13T23:18:13.386821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_datagen = ImageDataGenerator( rescale = 1./255.)\n\ntest_imgs = test_image_datagen.flow_from_dataframe(test_df, directory=None, x_col='FILENAME', y_col=cols, validate_filenames=True,\n                                        class_mode=\"raw\", target_size=(224,224), batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T23:18:13.394758Z","iopub.execute_input":"2021-08-13T23:18:13.39756Z","iopub.status.idle":"2021-08-13T23:18:14.151555Z","shell.execute_reply.started":"2021-08-13T23:18:13.397484Z","shell.execute_reply":"2021-08-13T23:18:14.150474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"oct_xception50per.h5\")\nmodel.evaluate(test_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T23:18:14.15303Z","iopub.execute_input":"2021-08-13T23:18:14.153437Z","iopub.status.idle":"2021-08-13T23:18:24.191023Z","shell.execute_reply.started":"2021-08-13T23:18:14.153393Z","shell.execute_reply":"2021-08-13T23:18:24.1901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotiting training results\nplt.figure(figsize=(32,12))\nplt.subplot(1,3,1)\nplt.plot(range(len(history.history[\"loss\"])), history.history['loss'], label=\"loss\")\nplt.plot(range(len(history.history[\"loss\"])), history.history['val_loss'], label=\"val_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(range(len(history.history[\"loss\"])), history.history[\"accuracy\"], label=\"accuracy\")\nplt.plot(range(len(history.history[\"loss\"])), history.history[\"val_accuracy\"], label=\"val_accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(range(len(history.history[\"loss\"])), history.history['f1_score'], label=\"loss\")\nplt.plot(range(len(history.history[\"loss\"])), history.history['val_f1_score'], label=\"val_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T23:26:20.563516Z","iopub.execute_input":"2021-08-13T23:26:20.563891Z","iopub.status.idle":"2021-08-13T23:26:21.245368Z","shell.execute_reply.started":"2021-08-13T23:26:20.563837Z","shell.execute_reply":"2021-08-13T23:26:21.244177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}