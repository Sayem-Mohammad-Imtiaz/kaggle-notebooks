{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Loading, Cleaning and Preprocessing","metadata":{}},{"cell_type":"code","source":"__author__ = \"Kabir Jaiswal\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"../input/enarm-20012019/ENARM_clean.csv\")\ndf=pd.DataFrame(data)\ndf.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename({'estado': 'region', 'universidad': 'university', 'concursantes':'contestants',\n           'seleccionados':'selected','promedio':'average_marks','año':'year'}, axis=1, inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df[\"region\"],df[\"year\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nclass ColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns \n\n    def fit(self,X,y=None):\n        return self \n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=ColumnLabelEncoder(columns = ['university']).fit_transform(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndata = df.values\nX, y = data[:, :-1], data[:, -1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape, y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Anaomaly Detection with Isolation Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\niso = IsolationForest(contamination=0.1)\nyhat = iso.fit_predict(X_train)\nmask = yhat != -1\nX_train, y_train = X_train[mask, :], y_train[mask]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import mean_absolute_error\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nyhat = model.predict(X_test)\nmae = mean_absolute_error(y_test, yhat)\nprint('MAE:' + str(mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Anaomaly Detection with Minimum Covariance Determinant","metadata":{}},{"cell_type":"code","source":"from sklearn.covariance import EllipticEnvelope\ndata = df.values\nX, y = data[:, :-1], data[:, -1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\nee = EllipticEnvelope(contamination=0.01)\nyhat = ee.fit_predict(X_train)\nmask = yhat != -1\nX_train, y_train = X_train[mask, :], y_train[mask]\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nyhat = model.predict(X_test)\nmae = mean_absolute_error(y_test, yhat)\nprint('MAE:' + str(mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_vals=[]\nfor i in range(990):\n    indvi=X_train[i]\n    indvi = np.array(indvi)\n    indvi = np.expand_dims(indvi, 0)\n    a=model.predict(indvi)\n    pred_vals.append(a[0])\nfor i in range(495):\n    indvi=X_test[i]\n    indvi = np.array(indvi)\n    indvi = np.expand_dims(indvi, 0)\n    a=model.predict(indvi)\n    pred_vals.append(a[0])\npred_vals","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q25 = np.percentile(pred_vals, 25)\nQ75 = np.percentile(pred_vals, 75)\nIQR = Q75 - Q25","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean=np.mean(pred_vals)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cheated=[]\nnot_cheated=[]\nfor i in range(len(pred_vals)):\n    if pred_vals[i] >  Q75  + 3.0 * IQR or  pred_vals[i] < Q25 - 3.0 * IQR:\n        cheated.append(i)\n    else:\n        not_cheated.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cheated),len(not_cheated)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport statistics\nx_axis = cheated\nmean = statistics.mean(x_axis)\nsd = statistics.stdev(x_axis)\n  \nplt.title(\"Normal Distribution for Cheated\")\nplt.plot(x_axis, norm.pdf(x_axis, mean, sd))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy.stats import norm\nimport statistics\nx_axis = not_cheated\nmean = statistics.mean(x_axis)\nsd = statistics.stdev(x_axis)\n  \nplt.title(\"Not Normal Distribution for Cheated\")\nplt.plot(x_axis, norm.pdf(x_axis, mean, sd))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Name of Faculties That cheated and the years","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv(\"../input/enarm-20012019/ENARM_clean.csv\")\ndf=pd.DataFrame(data)\ndf.rename({'estado': 'region', 'universidad': 'university', 'concursantes':'contestants',\n           'seleccionados':'selected','promedio':'average_marks','año':'year'}, axis=1, inplace=True)\nprint(\"The Names of Faculties which cheated\"+\"\\n\")\nfor i in range(len(cheated)):\n    print(df[\"university\"][cheated[i]],df[\"year\"][cheated[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}