{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **What is Churn Model?**"},{"metadata":{},"cell_type":"markdown","source":"*A churn model is a mathematical representation of how churn impacts your business. Churn calculations are built on existing data (the number of customers who left your service during a given time period). A predictive churn model extrapolates on this data to show future potential churn rates.*\n\n*In its simplest form, churn rate is calculated by dividing the number of customer cancellations within a time period by the number of active customers at the start of that period. Very valuable insights can be gathered from this simple analysis â€” for example, the overall churn rate can provide a benchmark against which to measure the impact of a model. And knowing how churn rate varies by time of the week or month, product line, or customer cohort can help inform simple customer segments for targeting as well.*"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/churn-modelling/Churn_Modelling.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Displaying info of dataset.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check if there are any NULL values present.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check correlation in your dataset.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Visualization**"},{"metadata":{},"cell_type":"markdown","source":"**Heat Map Correlation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = dataset.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting with Age**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(dataset, y= 'Age')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Age vs Gender**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(dataset, x=\"Age\", y=\"Gender\", orientation= 'h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Age vs Geography**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(dataset, x=\"Age\", y=\"Geography\", orientation= 'h')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting with Geography**"},{"metadata":{},"cell_type":"markdown","source":"**Geography vs Estimated Salary**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(dataset, x=\"Geography\", y=\"EstimatedSalary\", color = 'Gender', violinmode='overlay', hover_data=dataset.columns)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Geography vs Balance**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.violin(dataset, x=\"Geography\", y=\"Balance\", color = 'Gender', violinmode='overlay', hover_data=dataset.columns)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution Plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,7))\nsns.distplot(dataset.EstimatedSalary, color=\"green\", label=\"Estimated Salary\", kde= True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,7))\nsns.distplot(dataset.Balance, color=\"blue\", label=\"Estimated Salary\", kde= True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,7))\nsns.distplot(dataset.CreditScore, color=\"red\", label=\"Estimated Salary\", kde= True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pair Plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dataset.iloc[:, 3:-1].values\ny = dataset.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Encoding Categorical Data**"},{"metadata":{},"cell_type":"markdown","source":"**Label Encoding the \"Gender\" column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx[:, 2] = le.fit_transform(x[:, 2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One Hot Encoding the \"Geography\" column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')\nx = np.array(ct.fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Splitting the dataset into the Training set and Test set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Scaling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Building the ANN**"},{"metadata":{},"cell_type":"markdown","source":"**Importing Regularizers to add a penalty for weight size to the loss function and avoiding overfitting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.regularizers import l2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Initializing the ANN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ann = tf.keras.models.Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding the input layer and the first hidden layer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding first Dropout layer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.layers.Dropout(0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding the second hidden layer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding second Dropout layer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.layers.Dropout(0.6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adding the output layer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ann.add(tf.keras.layers.Dense(units= 1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training the ANN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ann.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ann_history = ann.fit(x_train, y_train, batch_size= 32, epochs= 100, validation_split= 0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing Training and Validation Loss**"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = ann_history.history['loss']\nloss_val = ann_history.history['val_loss']\nepochs = range(1,101)\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing Training and Validation Accuracy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = ann_history.history['accuracy']\nloss_val = ann_history.history['val_accuracy']\nepochs = range(1,101)\nplt.plot(epochs, loss_train, 'g', label='Training accuracy')\nplt.plot(epochs, loss_val, 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualizing Confusion Matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = ann.predict(x_test)\ny_pred = (y_pred > 0.5)\n\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Calculate the Accuracy\naccuracy = accuracy_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting on new data\nprint(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmd = ConfusionMatrixDisplay(cm, display_labels=['Stay','Leave'])\ncmd.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Evluating the ANN (Cross Validation)**"},{"metadata":{},"cell_type":"markdown","source":"**Wrapping k-fold cross validation into keras model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Builing the function\ndef ann_classifier():\n    ann = tf.keras.models.Sequential()\n    ann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n    ann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n    tf.keras.layers.Dropout(0.6)\n    ann.add(tf.keras.layers.Dense(units= 1, activation='sigmoid'))\n    ann.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\n    return ann","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Performing the Cross Validation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Passing values to KerasClassifier \nann = KerasClassifier(build_fn = ann_classifier, batch_size = 32, epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# We are using 5 fold cross validation here\naccuracies = cross_val_score(estimator = ann, X = x_train, y = y_train, cv = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the mean and standard deviation of the accuracies obtained\nmean = accuracies.mean()\nstd_deviation = accuracies.std()\nprint(\"Accuracy: {:.2f} %\".format(mean*100))\nprint(\"Standard Deviation: {:.2f} %\".format(std_deviation*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Tuning the ANN**"},{"metadata":{},"cell_type":"markdown","source":"**We use the Grid Search method for this task**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Builing the function\ndef ann_classifier(optimizer = 'adam'):\n    ann = tf.keras.models.Sequential()\n    ann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n    ann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n    tf.keras.layers.Dropout(0.6)\n    ann.add(tf.keras.layers.Dense(units= 1, activation='sigmoid'))\n    ann.compile(optimizer= optimizer, loss= 'binary_crossentropy', metrics= ['accuracy'])\n    return ann","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Passing values to KerasClassifier \nann = KerasClassifier(build_fn = ann_classifier, batch_size = 32, epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Using Grid Search CV to getting the best parameters\nparameters = {'batch_size': [25, 32],\n             'epochs': [100, 150],\n             'optimizer': ['adam', 'rmsprop']}\n\ngrid_search = GridSearchCV(estimator = ann, param_grid = parameters, scoring = 'accuracy', cv = 5, n_jobs = -1)\n\ngrid_search.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters:\", best_parameters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Running the ANN again based on parameters obtained above**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# defining the layers\nann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\nann.add(tf.keras.layers.Dense(units= 8, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\ntf.keras.layers.Dropout(0.6)\nann.add(tf.keras.layers.Dense(units= 1, activation='sigmoid'))\nann.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics= ['accuracy'])\nann.fit(x_train, y_train, batch_size= 32, epochs= 150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = ann.predict(x_test)\ny_pred = (y_pred > 0.5)\n\n# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Calculate the Accuracy\naccuracy = accuracy_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Confusion Matrix after tuning the ANN:\\n', cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy after tuning the ANN:', (accuracy)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Conclusion**"},{"metadata":{},"cell_type":"markdown","source":"***Therefore, after tuning the ANN model, accuracy reaches 86.3% and increases by only 1%.***"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}