{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nfrom __future__ import print_function\nimport pandas as pd\nfrom pandas import read_excel\nfrom sklearn import decomposition, preprocessing, svm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom itertools import cycle\nfrom scipy import interp\nfrom matplotlib import pyplot as plt\n%matplotlib inline","execution_count":202,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read in the input data\nproteinD = pd.read_csv(\"../input/77_cancer_proteomes_CPTAC_itraq.csv\",header = None, low_memory = False)\npatientD = pd.read_csv(\"../input/clinical_data_breast_cancer.csv\",header = None, low_memory = False)","execution_count":238,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14282bc93658eba38a32e3dd1e5cdaec50a59fca"},"cell_type":"code","source":"# Convert the above to numpy arrays\nbioData = proteinD.as_matrix()\npatientData = patientD.as_matrix()\npRef = bioData[0,3:bioData.shape[1]];","execution_count":239,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"28390677d6b50b054bdac63a06c32200e767d92d"},"cell_type":"code","source":"# Instead of replacing each missing value through some sort of interpolation, let's see how removing each row will effect the outcome.\n\ndOnly = bioData[1:bioData.shape[0],3:bioData.shape[1]].astype('float32');\ndOnly = dOnly[~np.isnan(dOnly).any(axis=1)]","execution_count":240,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1926a1213229d33f185bfb5f6585aaf09a6e580"},"cell_type":"code","source":"# First, classifying each patient by the 'PAM50 mRNA' label will be attempted.\nh = patientData[0,:];\npos = np.where(h == 'PAM50 mRNA')\npathology = patientData[1:patientData.shape[0], pos]","execution_count":241,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5546a8263979d14b4cc71ea4beeb4f6a3284a6ed"},"cell_type":"code","source":"pD = patientData[1:patientData.shape[0],0];\npD0 = [];\npD1 = [];\nfor i in range(0,pD.shape[0]-1):\n    cur = pD[i];\n    pD0.append(cur[5:12])\nfor i in range(0,pRef.shape[0]):\n    cur = pRef[i]\n    pD1.append(cur[0:7])","execution_count":242,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e99e220d4fbfe0c32be5b0d0d195fc6e69025c4c"},"cell_type":"code","source":"# Match up each group with the corresponding genomic data.\nd = np.zeros((1,len(dOnly[:,1])+1))\nfor i in range(0, len(pD1)-1):\n    for j in range(0,len(pD0)-1):\n        if pD1[i] == pD0[j]:\n            cur = np.hstack((dOnly[:,i].T,pathology[j][0]));\n            d = np.vstack((d,cur));\nd = np.delete(d, (0), axis=0)    ","execution_count":243,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e352b8862c020bb8f2203e7b5cb6234c42446fac"},"cell_type":"code","source":"# Just a bit of pre-processing...\ndR = d[:,0:d.shape[1]-1];\ndN = preprocessing.minmax_scale(dR, feature_range=(-1, 1), axis=0, copy=True)\nlabels = d[:,d.shape[1]-1];","execution_count":244,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bffe4607789f4c5498ac4ee95c18b91b13e70e0d"},"cell_type":"code","source":"# Each label was transformed to numeric form and then LDA was used to reduce dimensionality.\nle = preprocessing.LabelEncoder()\nle.fit(labels)\nnL = le.transform(labels);\n# nL = np.reshape(nL,(len(nL),1))\nlda = LinearDiscriminantAnalysis(n_components=3)\nX = lda.fit(dN, nL).transform(dN)  \nnL = np.reshape(nL,(len(nL),1))","execution_count":245,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"23cc52b2931a78416bef63a9c61f665f8c1c8190"},"cell_type":"code","source":"# This line just allows for easier plotting via sort.\nx = np.hstack((X,nL))\nx = x[x[:,3].argsort()]","execution_count":246,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cde7c32886acbfba245c4832fbe9b479c3395bdb"},"cell_type":"code","source":"# How many of each class?\ntype0 = sum(np.isin(x[:,3], 0));\ntype1 = sum(np.isin(x[:,3], 1));\ntype2 = sum(np.isin(x[:,3], 2));\ntype3 = sum(np.isin(x[:,3], 3));\n\n# Let's look at the first and second LDA loadings plot.\nq=0;\nr=1;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.scatter(x[0:type0,q],x[0:type0,r],s=25, c='blue', marker=\"s\", label=le.classes_[0])\nax1.scatter(x[type0:type0+type1,q],x[type0:type0+type1,r],s=25, c='black', marker=\"x\", label=le.classes_[1])\nax1.scatter(x[type0+type1:type0+type1+type2,q],x[type0+type1:type0+type1+type2,r],s=25, c='orange', marker=\"*\", label=le.classes_[2])\nax1.scatter(x[type0+type1+type2:type0+type1+type2+type3,q],x[type0+type1+type2:type0+type1+type2+type3,r],s=25, c='purple', marker=\"o\", label=le.classes_[3])\nplt.xlabel('LDA Loading #1',fontsize=18)\nplt.ylabel('LDA Loading #2',fontsize=18)\nplt.title('2D LDA Scatter Plot: \"PAM50 mRNA\"',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 12});\nplt.show()","execution_count":247,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db3d7bb5875eb2218d125df0f3601fb68db9d7c0"},"cell_type":"code","source":"# ... And then the second and third.\nq=1;\nr=2;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.scatter(x[0:type0,q],x[0:type0,r],s=25, c='blue', marker=\"s\", label=le.classes_[0])\nax1.scatter(x[type0:type0+type1,q],x[type0:type0+type1,r],s=25, c='black', marker=\"x\", label=le.classes_[1])\nax1.scatter(x[type0+type1:type0+type1+type2,q],x[type0+type1:type0+type1+type2,r],s=25, c='orange', marker=\"*\", label=le.classes_[2])\nax1.scatter(x[type0+type1+type2:type0+type1+type2+type3,q],x[type0+type1+type2:type0+type1+type2+type3,r],s=25, c='purple', marker=\"o\", label=le.classes_[3])\nplt.xlabel('LDA Loading #2',fontsize=18)\nplt.ylabel('LDA Loading #3',fontsize=18)\nplt.title('2D LDA Scatter Plot: \"PAM50 mRNA\"',fontsize=18)\nplt.legend(loc='lower left',prop={'size': 12});\nplt.show()","execution_count":248,"outputs":[]},{"metadata":{"_uuid":"437a4980c9026c330d0dd9f249eded69e6506b14"},"cell_type":"markdown","source":"There are definitely a few outliers, but the overall clustering doesn't look awful and it seems that the different LDA loading combinations picked up different features important for separation. I'll use a decision tree and 5-fold cross-validation to evaluate."},{"metadata":{"trusted":true,"_uuid":"ddb49755f4f0677ebc6a5fc994802377f31aba68"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nfiveF = cross_val_score(clf, x[:,0:3], x[:,3], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":249,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bac6bafe2b24299e29b809c3183e3d28f53aaed5"},"cell_type":"code","source":"# Time to check out the multi-class AUROC metric. This was obtained from the sklearn example at 'http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html'.\nn_classes = 4;\ny = label_binarize(x[:,3], classes=[0, 1, 2, 3])\nn_classes = y.shape[1]\n\nX_train, X_test, y_train, y_test = train_test_split(x[:,0:3], y, test_size=.5,\n                                                    random_state=0)\n                                                    \nrandom_state = np.random.RandomState(0)\nclassifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n                                 random_state=random_state))\ny_score = classifier.fit(X_train, y_train).decision_function(X_test)\n\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","execution_count":250,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6ad3130fd18a15b16d73c5fa651ed1f58b337b7"},"cell_type":"code","source":"lw = 2\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize=(10,10))\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['blue','black','orange','purple'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(le.classes_[i], roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.001])\nplt.xlabel('False Positive Rate',fontsize = 18)\nplt.ylabel('True Positive Rate',fontsize = 18)\nplt.title('Multi-Class ROC',fontsize = 18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":251,"outputs":[]},{"metadata":{"_uuid":"7e4c9dd00f375c41432197fc72aa83c4aa95b6b5"},"cell_type":"markdown","source":"The results above are promising and reasonable, especially since 'Basal-like' illustrated a strong separation with only two features in the previous plot of the 1st and 2nd LDA loadings while 'HER2-enriched' seemed to possess a high degree of overlap. Let's see how easily the same technique can group the various receptor status associations. 'ER Status' seems like a nice place to begin."},{"metadata":{"trusted":true,"_uuid":"d6cf50da4cd120289af9c5734405440eea7c9fef"},"cell_type":"code","source":"pos = np.where(h == 'ER Status')\npathology = patientData[1:patientData.shape[0], pos]\n\nd = np.zeros((1,len(dOnly[:,1])+1))\nfor i in range(0, len(pD1)-1):\n    for j in range(0,len(pD0)-1):\n        if pD1[i] == pD0[j]:\n            cur = np.hstack((dOnly[:,i].T,pathology[j][0]));\n            d = np.vstack((d,cur));\nd = np.delete(d, (0), axis=0) \n\ndR = d[:,0:d.shape[1]-1];\ndN = preprocessing.minmax_scale(dR, feature_range=(-1, 1), axis=0, copy=True)\nlabels = d[:,d.shape[1]-1];\n\nle = preprocessing.LabelEncoder()\nle.fit(labels)\nnL = le.transform(labels);\n# nL = np.reshape(nL,(len(nL),1))\nlda = LinearDiscriminantAnalysis(n_components=1)\nX = lda.fit(dN, nL).transform(dN)  \nnL = np.reshape(nL,(len(nL),1))\n\nx = np.hstack((X,nL))\nx = x[x[:,1].argsort()]","execution_count":252,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bb3727f17a276c05e1f17d4ceea42c929305941"},"cell_type":"code","source":"# There is only one LDA loading this time around.\ntype0 = sum(np.isin(x[:,1], 0));\ntype1 = sum(np.isin(x[:,1], 1));\n\n# Bar plot\nq=0;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.bar(np.linspace(1,type0,type0), x[0:type0,q], align='center', label=le.classes_[0])\nax1.bar(np.linspace(type0+1,type0+type1,type1), x[type0:type0+type1,q], align='center', label=le.classes_[1])\nplt.xlabel('Patient',fontsize=18)\nplt.ylabel('LDA Loading',fontsize=18)\nplt.title('1D LDA Bar Plot: \"ER Status\"',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 15});\nplt.show()","execution_count":253,"outputs":[]},{"metadata":{"_uuid":"2aaf6599e7ac8afcda3af84dc40b0aafc7b294fb"},"cell_type":"markdown","source":"Just as before, a five-fold CV using sklearn's decision-tree will be performed along with a single class ROC. This time, the cross-validation ROC curve will be utilized."},{"metadata":{"trusted":true,"_uuid":"f940817b54b55c439373bbc8ec1e871912260f3e"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nfiveF = cross_val_score(clf, x[:,0].reshape(x[:,0].shape[0],1), x[:,1], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":254,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c39074c1726fb57ac31be69e4f5d20337ca424ef"},"cell_type":"code","source":"X = x[:,0].reshape(x[:,0].shape[0],1);\ny = x[:,1];\nn_samples, n_features = X.shape\ncv = StratifiedKFold(n_splits=5)\nclassifier = svm.SVC(kernel='linear', probability=True,\n                     random_state=random_state)\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nplt.figure(figsize=(10,10))\ni = 0\nfor train, test in cv.split(X, y):\n    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n    # Compute ROC curve and area the curve\n    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    i += 1\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n         label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.title('Cross-Validation ROC: \"ER Status\"',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":255,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdf4f7b4aba1a9c3fd3cb8b3c1ced297dc87d162"},"cell_type":"code","source":"pos = np.where(h == 'PR Status')\npathology = patientData[1:patientData.shape[0], pos]\n\nd = np.zeros((1,len(dOnly[:,1])+1))\nfor i in range(0, len(pD1)-1):\n    for j in range(0,len(pD0)-1):\n        if pD1[i] == pD0[j]:\n            cur = np.hstack((dOnly[:,i].T,pathology[j][0]));\n            d = np.vstack((d,cur));\nd = np.delete(d, (0), axis=0) \n\ndR = d[:,0:d.shape[1]-1];\ndN = preprocessing.minmax_scale(dR, feature_range=(-1, 1), axis=0, copy=True)\nlabels = d[:,d.shape[1]-1];\n\nle = preprocessing.LabelEncoder()\nle.fit(labels)\nnL = le.transform(labels);\n# nL = np.reshape(nL,(len(nL),1))\nlda = LinearDiscriminantAnalysis(n_components=1)\nX = lda.fit(dN, nL).transform(dN)  \nnL = np.reshape(nL,(len(nL),1))\n\nx = np.hstack((X,nL))\nx = x[x[:,1].argsort()]\n\n# There is only one LDA loading this time around.\ntype0 = sum(np.isin(x[:,1], 0));\ntype1 = sum(np.isin(x[:,1], 1));\n\n# Bar plot\nq=0;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.bar(np.linspace(1,type0,type0), x[0:type0,q], align='center', label=le.classes_[0])\nax1.bar(np.linspace(type0+1,type0+type1,type1), x[type0:type0+type1,q], align='center', label=le.classes_[1])\nplt.xlabel('Patient',fontsize=18)\nplt.ylabel('LDA Loading',fontsize=18)\nplt.title('1D LDA Bar Plot: \"PR Status\"',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 15});\nplt.show()","execution_count":256,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"114834a59b526c2f97acdf8a9f20f95335280521"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nfiveF = cross_val_score(clf, x[:,0].reshape(x[:,0].shape[0],1), x[:,1], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":257,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"140a3880711c008215056d559a404e5b79fe6ef4"},"cell_type":"code","source":"X = x[:,0].reshape(x[:,0].shape[0],1);\ny = x[:,1];\nn_samples, n_features = X.shape\ncv = StratifiedKFold(n_splits=5)\nclassifier = svm.SVC(kernel='linear', probability=True,\n                     random_state=random_state)\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nplt.figure(figsize=(10,10))\ni = 0\nfor train, test in cv.split(X, y):\n    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n    # Compute ROC curve and area the curve\n    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    i += 1\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n         label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.title('Cross-Validation ROC: \"PR Status\"',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":258,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f77790b1c619b26757022ff6006d62cf89e555b0"},"cell_type":"code","source":"pos = np.where(h == 'HER2 Final Status')\npathology = patientData[1:patientData.shape[0], pos]\n\nd = np.zeros((1,len(dOnly[:,1])+1))\nfor i in range(0, len(pD1)-1):\n    for j in range(0,len(pD0)-1):\n        if pD1[i] == pD0[j]:\n            cur = np.hstack((dOnly[:,i].T,pathology[j][0]));\n            d = np.vstack((d,cur));\nd = np.delete(d, (0), axis=0)\n\n# This time, there was a patient who possessed a HER2 status of \"equivocal\". This needed to be taken care of.\nk = [];\nfor i in range(0,len(d[:,d.shape[1]-2])):\n    if d[i,d.shape[1]-1] != 'Positive' and d[i,d.shape[1]-1] != 'Negative':\n        k.append(i)\nd = np.delete(d, (k), axis=0)\n\ndR = d[:,0:d.shape[1]-1];\ndN = preprocessing.minmax_scale(dR, feature_range=(-1, 1), axis=0, copy=True)\nlabels = d[:,d.shape[1]-1];\n\nle = preprocessing.LabelEncoder()\nle.fit(labels)\nnL = le.transform(labels);\n# nL = np.reshape(nL,(len(nL),1))\nlda = LinearDiscriminantAnalysis(n_components=1)\nX = lda.fit(dN, nL).transform(dN)  \nnL = np.reshape(nL,(len(nL),1))\n\nx = np.hstack((X,nL))\nx = x[x[:,1].argsort()]\n\n# There is only one LDA loading this time around.\ntype0 = sum(np.isin(x[:,1], 0));\ntype1 = sum(np.isin(x[:,1], 1));\n\n# Bar plot\nq=0;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.bar(np.linspace(1,type0,type0), x[0:type0,q], align='center', label=le.classes_[0])\nax1.bar(np.linspace(type0+1,type0+type1,type1), x[type0:type0+type1,q], align='center', label=le.classes_[1])\nplt.xlabel('Patient',fontsize=18)\nplt.ylabel('LDA Loading',fontsize=18)\nplt.title('1D LDA Bar Plot: \"HER2 Final Status\"',fontsize=18)\nplt.legend(loc='upper left',prop={'size': 15});\nplt.show()","execution_count":259,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a154ff92ed09983de013a7367eb64c35868b6e0"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nfiveF = cross_val_score(clf, x[:,0].reshape(x[:,0].shape[0],1), x[:,1], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":260,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac40c1388670b35157701c6cd8e49b5635c627b2"},"cell_type":"code","source":"X = x[:,0].reshape(x[:,0].shape[0],1);\ny = x[:,1];\nn_samples, n_features = X.shape\ncv = StratifiedKFold(n_splits=5)\nclassifier = svm.SVC(kernel='linear', probability=True,\n                     random_state=random_state)\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\nplt.figure(figsize=(10,10))\ni = 0\nfor train, test in cv.split(X, y):\n    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n    # Compute ROC curve and area the curve\n    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    tprs[-1][0] = 0.0\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n\n    i += 1\nplt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n         label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nplt.plot(mean_fpr, mean_tpr, color='b',\n         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n         lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nplt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                 label=r'$\\pm$ 1 std. dev.')\n\nplt.xlim([-0.01, 1.01])\nplt.ylim([-0.01, 1.01])\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.title('Cross-Validation ROC: \"HER2 Final Status\"',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":261,"outputs":[]},{"metadata":{"_uuid":"9f9c3b3adf367ab4925274d67e112b935a4452f0"},"cell_type":"markdown","source":"Finally, it is time to try out separation by Reverse Phase Protein Array cluster data."},{"metadata":{"trusted":true,"_uuid":"5a56f9b659c5536c6b09c278da74a17f8a6c389a"},"cell_type":"code","source":"pos = np.where(h == 'RPPA Clusters')\npathology = patientData[1:patientData.shape[0], pos]\n\nd = np.zeros((1,len(dOnly[:,1])+1))\nfor i in range(0, len(pD1)-1):\n    for j in range(0,len(pD0)-1):\n        if pD1[i] == pD0[j]:\n            cur = np.hstack((dOnly[:,i].T,pathology[j][0]));\n            d = np.vstack((d,cur));\nd = np.delete(d, (0), axis=0)\n\nk = [];\nfor i in range(0,len(d[:,d.shape[1]-2])):\n    if d[i,d.shape[1]-1] == 'X':\n        k.append(i)\nd = np.delete(d, (k), axis=0)\n\ndR = d[:,0:d.shape[1]-1];\ndN = preprocessing.minmax_scale(dR, feature_range=(-1, 1), axis=0, copy=True)\nlabels = d[:,d.shape[1]-1];\n\nle = preprocessing.LabelEncoder()\nle.fit(labels)\nnL = le.transform(labels);\nlda = LinearDiscriminantAnalysis(n_components=3)\nX = lda.fit(dN, nL).transform(dN)  \nnL = np.reshape(nL,(len(nL),1))\n\nx = np.hstack((X,nL))\nx = x[x[:,3].argsort()]\n\n# This time, six groups are present\ntype0 = sum(np.isin(x[:,3], 0));\ntype1 = sum(np.isin(x[:,3], 1));\ntype2 = sum(np.isin(x[:,3], 2));\ntype3 = sum(np.isin(x[:,3], 3));\ntype4 = sum(np.isin(x[:,3], 4));\ntype5 = sum(np.isin(x[:,3], 5));\n\nq=0;\nr=1;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.scatter(x[0:type0,q],x[0:type0,r],s=25, c='blue', marker=\"s\", label=le.classes_[0])\nax1.scatter(x[type0:type0+type1,q],x[type0:type0+type1,r],s=25, c='black', marker=\"x\", label=le.classes_[1])\nax1.scatter(x[type0+type1:type0+type1+type2,q],x[type0+type1:type0+type1+type2,r],s=25, c='orange', marker=\"*\", label=le.classes_[2])\nax1.scatter(x[type0+type1+type2:type0+type1+type2+type3,q],x[type0+type1+type2:type0+type1+type2+type3,r],s=25, c='purple', marker=\"o\", label=le.classes_[3])\nax1.scatter(x[type0+type1+type2+type3:type0+type1+type2+type3+type4,q],x[type0+type1+type2+type3:type0+type1+type2+type3+type4,r],s=25, c='red', marker=\">\", label=le.classes_[4])\nax1.scatter(x[type0+type1+type2+type3+type4:type0+type1+type2+type3+type4+type5,q],x[type0+type1+type2+type3+type4:type0+type1+type2+type3+type4+type5,r],s=25, c='green', marker=\"^\", label=le.classes_[5])\nplt.xlabel('LDA Loading #1',fontsize=18)\nplt.ylabel('LDA Loading #2',fontsize=18)\nplt.title('2D LDA Scatter Plot: \"RPPA Clusters\"',fontsize=18)\nplt.legend(loc='lower left',prop={'size': 12});\nplt.show()","execution_count":262,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a0d1247379a202c095a185c4e61e02949d77c1e"},"cell_type":"code","source":"q=1;\nr=2;\nfig = plt.figure(figsize=(10,10))\nax1 = fig.add_subplot(111)\nax1.scatter(x[0:type0,q],x[0:type0,r],s=25, c='blue', marker=\"s\", label=le.classes_[0])\nax1.scatter(x[type0:type0+type1,q],x[type0:type0+type1,r],s=25, c='black', marker=\"x\", label=le.classes_[1])\nax1.scatter(x[type0+type1:type0+type1+type2,q],x[type0+type1:type0+type1+type2,r],s=25, c='orange', marker=\"*\", label=le.classes_[2])\nax1.scatter(x[type0+type1+type2:type0+type1+type2+type3,q],x[type0+type1+type2:type0+type1+type2+type3,r],s=25, c='purple', marker=\"o\", label=le.classes_[3])\nax1.scatter(x[type0+type1+type2+type3:type0+type1+type2+type3+type4,q],x[type0+type1+type2+type3:type0+type1+type2+type3+type4,r],s=25, c='red', marker=\">\", label=le.classes_[4])\nax1.scatter(x[type0+type1+type2+type3+type4:type0+type1+type2+type3+type4+type5,q],x[type0+type1+type2+type3+type4:type0+type1+type2+type3+type4+type5,r],s=25, c='green', marker=\"^\", label=le.classes_[5])\nplt.xlabel('LDA Loading #2',fontsize=18)\nplt.ylabel('LDA Loading #3',fontsize=18)\nplt.title('2D LDA Scatter Plot: \"RPPA Clusters\"',fontsize=18)\nplt.legend(loc='upper right',prop={'size': 12});\nplt.show()","execution_count":263,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08f7f00de406c538258683a65f3fcdda2681d1cc"},"cell_type":"code","source":"clf = DecisionTreeClassifier(random_state=0)\nfiveF = cross_val_score(clf, x[:,0:3], x[:,3], cv=5)\nprint(\"All: \", fiveF, \". \\nAverage: \", np.mean(fiveF) )","execution_count":264,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f1df3035939ceb56ebc1c9eb6627d75426a07ae"},"cell_type":"code","source":"n_classes = 6;\ny = label_binarize(x[:,3], classes=[0, 1, 2, 3, 4, 5])\nn_classes = y.shape[1]\n\nX_train, X_test, y_train, y_test = train_test_split(x[:,0:3], y, test_size=.5,\n                                                    random_state=0)\n                                                    \nrandom_state = np.random.RandomState(0)\nclassifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n                                 random_state=random_state))\ny_score = classifier.fit(X_train, y_train).decision_function(X_test)\n\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\nlw = 2\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure(figsize=(10,10))\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['blue','black','orange','purple'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(le.classes_[i], roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.001])\nplt.xlabel('False Positive Rate',fontsize=18)\nplt.ylabel('True Positive Rate',fontsize=18)\nplt.title('Multi-Class ROC: \"RPPA Clusters\"',fontsize=18)\nplt.legend(loc=\"lower right\", prop={'size': 15})\nplt.show()","execution_count":265,"outputs":[]},{"metadata":{"_uuid":"d42567d5f394573b89246938c45dc84a18f08c74"},"cell_type":"markdown","source":"The majority of the AUROC values are > .8, which isn't too bad, but... there are two groups possessing AUC values < .7.\n\nA different method of pre-processing (such as not leaving out potentially valuable rows due to one or two NaN values), a better suited characterization algorithm or many other adjustments could provide better results for these class separations. Overall, using this data seems to show potential for reasonably accurate breast cancer sub-type prediction."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}