{"cells":[{"metadata":{"_uuid":"f327f21f9ca18747132644e41d9d81c8897f7c42","_cell_guid":"d7f2c0e7-1ac6-44ce-9331-935cae94e711"},"cell_type":"markdown","source":"# In this nodebook, simple RNN and LTSM are used for spam detection\n\nHave a look at this notebook for spam detection tutorial. (dataset is same ). Misclassifidation number is only 16 by logistic regression implemented here:  https://nbviewer.jupyter.org/gist/Juice178/6f5040fe6afc542c8db87ca865d2f21c"},{"metadata":{"_uuid":"e9d88b117d32a845f84ff93c7aeba218ddae1ce3"},"cell_type":"markdown","source":"# 1 RNN"},{"metadata":{"_uuid":"52eda8550b87498b7760a9e31f1a8f9baff71798","trusted":true},"cell_type":"code","source":"from keras.layers import SimpleRNN, Embedding, Dense, LSTM\nfrom keras.models import Sequential\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9c5f2a038647fd85cd4af2cfef68be86f9dbe4e","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/SPAM text message 20170820 - Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1f882d1ac9a395820c0e53036bcad0c18e44d4b"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ef3bc07c5308f535e4dcb97f8024189e038be10"},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e84df1bd0a9ae46669516aa72e0e7198c527ffa2","trusted":false},"cell_type":"code","source":"texts = []\nlabels = []\nfor i, label in enumerate(data['Category']):\n    texts.append(data['Message'][i])\n    if label == 'ham':\n        labels.append(0)\n    else:\n        labels.append(1)\n\ntexts = np.asarray(texts)\nlabels = np.asarray(labels)\n\n\nprint(\"number of texts :\" , len(texts))\nprint(\"number of labels: \", len(labels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9cf5ffeb23fe3684c1878a5bde9d91325e0c06e","trusted":false},"cell_type":"code","source":"from keras.layers import SimpleRNN, Embedding, Dense, LSTM\nfrom keras.models import Sequential\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n# number of words used as features\nmax_features = 10000\n# cut off the words after seeing 500 words in each document(email)\nmaxlen = 500\n\n\n# we will use 80% of data as training, 20% as validation data\ntraining_samples = int(5572 * .8)\nvalidation_samples = int(5572 - training_samples)\n# sanity check\nprint(len(texts) == (training_samples + validation_samples))\nprint(\"The number of training {0}, validation {1} \".format(training_samples, validation_samples))\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint(\"Found {0} unique words: \".format(len(word_index)))\n\ndata = pad_sequences(sequences, maxlen=maxlen)\n\nprint(\"data shape: \", data.shape)\n\nnp.random.seed(42)\n# shuffle data\nindices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\n\n\ntexts_train = data[:training_samples]\ny_train = labels[:training_samples]\ntexts_test = data[training_samples:]\ny_test = labels[training_samples:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22c781ad87fb7ab793eb269b1ea9c2ab4963e951","trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_features, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nhistory_rnn = model.fit(texts_train, y_train, epochs=10, batch_size=60, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4c5ca3af59baa4dc8371cd548e5b3df240a7187","trusted":false},"cell_type":"code","source":"acc = history_rnn.history['acc']\nval_acc = history_rnn.history['val_acc']\nloss = history_rnn.history['loss']\nval_loss = history_rnn.history['val_loss']\nepochs = range(len(acc))\nplt.plot(epochs, acc, '-', color='orange', label='training acc')\nplt.plot(epochs, val_acc, '-', color='blue', label='validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, '-', color='orange', label='training acc')\nplt.plot(epochs, val_loss,  '-', color='blue', label='validation acc')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1abaf50046fcbb2528c2f9ec49f63595aa81649","trusted":false},"cell_type":"code","source":"pred = model.predict_classes(texts_test)\nacc = model.evaluate(texts_test, y_test)\nproba_rnn = model.predict_proba(texts_test)\nfrom sklearn.metrics import confusion_matrix\nprint(\"Test loss is {0:.2f} accuracy is {1:.2f}  \".format(acc[0],acc[1]))\nprint(confusion_matrix(pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbb77ce057f07b3ca61d722d64626ff09ef375da"},"cell_type":"markdown","source":"# LTSM"},{"metadata":{"_uuid":"40e1791210758d7fdbc4d263891cbd78d9321e0c","trusted":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_features, 32))\nmodel.add(LSTM(32))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nhistory_ltsm = model.fit(texts_train, y_train, epochs=10, batch_size=60, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa53b02daf2c1e0763dbd0b91f3008e82b14ed63","trusted":false},"cell_type":"code","source":"acc = history_ltsm.history['acc']\nval_acc = history_ltsm.history['val_acc']\nloss = history_ltsm.history['loss']\nval_loss = history_ltsm.history['val_loss']\nepochs = range(len(acc))\nplt.plot(epochs, acc, '-', color='orange', label='training acc')\nplt.plot(epochs, val_acc, '-', color='blue', label='validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, '-', color='orange', label='training acc')\nplt.plot(epochs, val_loss,  '-', color='blue', label='validation acc')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"902f023efbb2cd211c467c766098a00e21b923aa","trusted":false},"cell_type":"code","source":"pred = model.predict_classes(texts_test)\nacc = model.evaluate(texts_test, y_test)\nproba_ltsm = model.predict_proba(texts_test)\nfrom sklearn.metrics import confusion_matrix\nprint(\"Test loss is {0:.2f} accuracy is {1:.2f}  \".format(acc[0],acc[1]))\nprint(confusion_matrix(pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab3244e63bc8a268fd83bbb4a77df3173dbfcb72"},"cell_type":"markdown","source":"# Ensemble method (combining RNN and LTSM)"},{"metadata":{"_uuid":"86e118545bae8a5779e207e61759a916c8e70fa0","trusted":false},"cell_type":"code","source":"ensemble_proba = 0.3 * proba_rnn + 0.7 * proba_ltsm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ad14bf01502c0c5b4b7931355d879004e81cc02","trusted":false},"cell_type":"code","source":"ensemble_proba[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"110fe74ae8c9dda257e365ef27039bd442734f1e","trusted":false},"cell_type":"code","source":"ensemble_class = np.array([1 if i >= 0.5 else 0 for i in ensemble_proba])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c09211d550ab348e0bc9d8f92ac0d9c0e5662047","trusted":false},"cell_type":"code","source":"ensemble_class[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19d97525b8e61e79f54998f8346cfc540242932c","trusted":false},"cell_type":"code","source":"print(confusion_matrix(pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5ae675773d432160e4c84ad343d5f0d1a687bbb"},"cell_type":"markdown","source":"# How to improve further?\nUse ensemble method with logistic regression implemented above or other classifiers, which should imporve accuracy"},{"metadata":{"collapsed":true,"_uuid":"3085768caa9d2f31edac2adfc6b421b9894c233e","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}