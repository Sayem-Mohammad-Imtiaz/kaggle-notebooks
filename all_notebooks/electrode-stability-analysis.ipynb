{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom tqdm import tqdm\nimport os, torch\nimport torch.nn as nn\nfrom torch import optim\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n\ndata_path = '../input/electrode-stability-dataset/DATA.csv'\ndata = pd.read_csv(data_path, header=0, index_col=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:45.276655Z","iopub.execute_input":"2021-08-25T00:01:45.277281Z","iopub.status.idle":"2021-08-25T00:01:47.813901Z","shell.execute_reply.started":"2021-08-25T00:01:45.277135Z","shell.execute_reply":"2021-08-25T00:01:47.812475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show data columns\r\nprint(data.columns)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:47.815561Z","iopub.execute_input":"2021-08-25T00:01:47.815882Z","iopub.status.idle":"2021-08-25T00:01:47.822172Z","shell.execute_reply.started":"2021-08-25T00:01:47.815852Z","shell.execute_reply":"2021-08-25T00:01:47.820881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check unique values occurances in each column\r\nfor col in data.columns:\r\n    print(f'{col} has {len(data[col].unique())} unique values')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:47.824448Z","iopub.execute_input":"2021-08-25T00:01:47.824789Z","iopub.status.idle":"2021-08-25T00:01:47.85949Z","shell.execute_reply.started":"2021-08-25T00:01:47.824756Z","shell.execute_reply":"2021-08-25T00:01:47.858807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check columns data type to distinguish numercial data from categorical ones\r\nfor col in data.columns:\r\n    print(f'the {col} is of {data[col].dtype.name} data type')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:47.860682Z","iopub.execute_input":"2021-08-25T00:01:47.86106Z","iopub.status.idle":"2021-08-25T00:01:47.869031Z","shell.execute_reply.started":"2021-08-25T00:01:47.86103Z","shell.execute_reply":"2021-08-25T00:01:47.867978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize some categorical data\r\nbatch = 600\r\nfor idx in range(0, len(data['Electrode']), batch):\r\n    plt.scatter(x=data['Electrode'][idx:idx+batch], y=data['Stability. (H)'][idx:idx+batch])\r\n    plt.xlabel('Electrode')\r\n    plt.ylabel('Stability. (H)')\r\n    plt.title(f'Stability. (H) vs Electrode {idx+1} to {idx+batch} samples')\r\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:47.870511Z","iopub.execute_input":"2021-08-25T00:01:47.870813Z","iopub.status.idle":"2021-08-25T00:01:48.522441Z","shell.execute_reply.started":"2021-08-25T00:01:47.870783Z","shell.execute_reply":"2021-08-25T00:01:48.521512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select all object, boolean and category type columns and frop Ref. Publication date [year:mm:dd] column\r\ndata_categorical = data.select_dtypes(['object', 'bool', 'category']).drop(['Ref. Publication date [year:mm:dd]'], axis=1)\r\ndata_categorical.head()\r\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:48.523505Z","iopub.execute_input":"2021-08-25T00:01:48.523759Z","iopub.status.idle":"2021-08-25T00:01:48.556293Z","shell.execute_reply.started":"2021-08-25T00:01:48.523734Z","shell.execute_reply":"2021-08-25T00:01:48.555254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop columns with lots of missing or irrelevant data\r\nvalid_categorical_col = data_categorical.drop(['TL1-front', 'TL2-front', 'TL3-front', 'TL4-back', 'TL5-back', 'TL6-back', 'TL7-back'], axis=1).columns\r\nvalid_numerical_col = data.select_dtypes('float64').columns\r\n\r\n#visualize and check if 'blank' still exits in any column\r\nfor cat_col, num_col in zip(valid_categorical_col, valid_numerical_col):\r\n    print(f'{cat_col}: \\n{data[cat_col].value_counts()}\\n____________________________________')\r\n    print(f'{num_col}: \\n{data[num_col].value_counts()}\\n____________________________________\\n\\n\\n\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:48.557643Z","iopub.execute_input":"2021-08-25T00:01:48.557958Z","iopub.status.idle":"2021-08-25T00:01:48.582662Z","shell.execute_reply.started":"2021-08-25T00:01:48.557926Z","shell.execute_reply":"2021-08-25T00:01:48.581715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create new dataframe with relevant data\r\ndata_df = pd.DataFrame()\r\nfor cat_col in valid_categorical_col:\r\n    data_df[cat_col] = data[cat_col]\r\n\r\nfor num_col in valid_numerical_col:\r\n    data_df[num_col] = data[num_col]\r\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:48.585212Z","iopub.execute_input":"2021-08-25T00:01:48.585492Z","iopub.status.idle":"2021-08-25T00:01:48.609787Z","shell.execute_reply.started":"2021-08-25T00:01:48.585464Z","shell.execute_reply":"2021-08-25T00:01:48.608739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot all Stability. (H) against all features\r\nfor col in data_df.columns:\r\n    plt.scatter(x=data_df[col], y=data_df['Stability. (H)'])\r\n    plt.xlabel(f'{col}')\r\n    plt.ylabel('Stability. (H)')\r\n    plt.title(f'Stability. (H) vs {col}')\r\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:48.61227Z","iopub.execute_input":"2021-08-25T00:01:48.612572Z","iopub.status.idle":"2021-08-25T00:01:50.000825Z","shell.execute_reply.started":"2021-08-25T00:01:48.612541Z","shell.execute_reply":"2021-08-25T00:01:49.999687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#linear correlation analysis\r\ndata_df[valid_numerical_col].corr()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:50.002134Z","iopub.execute_input":"2021-08-25T00:01:50.002443Z","iopub.status.idle":"2021-08-25T00:01:50.018979Z","shell.execute_reply.started":"2021-08-25T00:01:50.002415Z","shell.execute_reply":"2021-08-25T00:01:50.017832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#encode categorical features\r\nlabel_enc = LabelEncoder()\r\nfor col in valid_categorical_col:\r\n    data_df[f'{col} Encode'] = label_enc.fit_transform(data_df[col]).reshape(-1)\r\ndata_df.head(100)\r\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:50.020391Z","iopub.execute_input":"2021-08-25T00:01:50.020686Z","iopub.status.idle":"2021-08-25T00:01:50.060943Z","shell.execute_reply.started":"2021-08-25T00:01:50.020657Z","shell.execute_reply":"2021-08-25T00:01:50.059924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize raw numerical data via distribution curve'\r\nfor col in valid_numerical_col:\r\n    data_df[col].plot.kde()\r\n    plt.title(f'{col} distribution curve')\r\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:50.062144Z","iopub.execute_input":"2021-08-25T00:01:50.062435Z","iopub.status.idle":"2021-08-25T00:01:50.697872Z","shell.execute_reply.started":"2021-08-25T00:01:50.062408Z","shell.execute_reply":"2021-08-25T00:01:50.696893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normaiization target with ln(x + 1)\r\nfor col in valid_numerical_col:\r\n    if col == 'Stability. (H)':\r\n        data_df[f'{col} (Normailzed)'] = np.log(data_df[col] + 1)\r\n        continue\r\n    data_df[f'{col} (Normailzed)'] = data_df[col]\r\n    print(f'{col} (Normailzed) \\n')\r\n    print(data_df[f'{col} (Normailzed)'].describe())\r\ndata_df.head(1000)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:50.699245Z","iopub.execute_input":"2021-08-25T00:01:50.699574Z","iopub.status.idle":"2021-08-25T00:01:50.766893Z","shell.execute_reply.started":"2021-08-25T00:01:50.699541Z","shell.execute_reply":"2021-08-25T00:01:50.766194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize normalized numerical data via distribution curve'\r\nfor col in valid_numerical_col:\r\n    new_col_name = f'{col} (Normailzed)'\r\n    data_df[new_col_name].plot.kde()\r\n    plt.title(f'distribution curve of {new_col_name}')\r\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:50.768292Z","iopub.execute_input":"2021-08-25T00:01:50.768763Z","iopub.status.idle":"2021-08-25T00:01:51.329102Z","shell.execute_reply.started":"2021-08-25T00:01:50.768722Z","shell.execute_reply":"2021-08-25T00:01:51.328283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Neural Newtork Model\r\n\r\nclass NNregressor(nn.Module):\r\n    def __init__(self, in_features, out_features):\r\n        super(NNregressor, self).__init__()\r\n        self.in_features = in_features\r\n        self.out_features = out_features\r\n\r\n        self.dense_layer_1 = nn.Sequential(\r\n            nn.Linear(self.in_features, self.in_features*3),\r\n            nn.BatchNorm1d(self.in_features*3),\r\n            nn.LeakyReLU(0.3),\r\n        )\r\n        self.dense_layer_2 = nn.Sequential(\r\n            nn.Linear(self.in_features*3, self.in_features*6),\r\n            nn.BatchNorm1d(self.in_features*6),\r\n            nn.LeakyReLU(0.3),\r\n        )\r\n        self.dense_layer_3 = nn.Sequential(\r\n            nn.Linear(self.in_features*6, self.in_features*9),\r\n            nn.BatchNorm1d(self.in_features*9),\r\n            nn.LeakyReLU(0.3),\r\n        )\r\n        self.dense_layer_4 = nn.Sequential(\r\n            nn.Linear(self.in_features*9, self.in_features*12),\r\n            nn.BatchNorm1d(self.in_features*12),\r\n            nn.LeakyReLU(0.3),\r\n        )\r\n        self.dense_layer_5 = nn.Sequential(\r\n            nn.Linear(self.in_features*12, self.out_features),\r\n        )\r\n        self.dropout_layer = nn.Dropout(0.2)\r\n\r\n        \r\n    def forward(self, feature):\r\n        output = self.dense_layer_1(feature)\r\n        output = self.dense_layer_2(output)\r\n        output = self.dense_layer_3(output)\r\n        output = self.dense_layer_4(output)\r\n        output = self.dense_layer_5(output)\r\n        #output = self.dropout_layer(output)\r\n        return output\r\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:51.330519Z","iopub.execute_input":"2021-08-25T00:01:51.331118Z","iopub.status.idle":"2021-08-25T00:01:51.495253Z","shell.execute_reply.started":"2021-08-25T00:01:51.331071Z","shell.execute_reply":"2021-08-25T00:01:51.494275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#select feature and target columns to train with\r\nfeature_label = []\r\ntarget_label = ['Stability. (H) (Normailzed)']\r\nfor col in valid_categorical_col:\r\n    feature_label.append(f'{col} Encode')\r\nfor col in valid_numerical_col:\r\n    if col == 'Stability. (H) (Normailzed)':\r\n        continue\r\n    feature_label.append(f'{col} (Normailzed)')\r\n\r\nfeature_data = data_df[feature_label].to_numpy().reshape(-1, len(feature_label))\r\ntarget_data = data_df[target_label].to_numpy().reshape(-1, 1)\r\n\r\nprint(f'feature data size: {feature_data.shape}')\r\nprint(f'Target data size: {target_data.shape}')\r\ndata_df[target_label].head()","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:51.496577Z","iopub.execute_input":"2021-08-25T00:01:51.496879Z","iopub.status.idle":"2021-08-25T00:01:51.525369Z","shell.execute_reply.started":"2021-08-25T00:01:51.496853Z","shell.execute_reply":"2021-08-25T00:01:51.5244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hyper-param\r\nin_features = len(feature_label)\r\nout_features = len(target_label)\r\ntest_size = 0.1\r\nlr = 1e-3\r\nepochs = 200\r\ntrain_batch_size = 600\r\n\r\n#set model\r\nregression_model = NNregressor(in_features, out_features)\r\nlossFunc = nn.MSELoss()\r\noptimizer = optim.Adam(regression_model.parameters(), lr=lr)\r\n\r\n#data_splice\r\ndef splice(X, y, test_size=test_size):\r\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\r\n    return X_train, X_test, y_train, y_test\r\n\r\n#numpy to tensor\r\ndef numpy_to_tensor(*array):\r\n    tensor = tuple(torch.Tensor(i) for i in array)\r\n    return tensor\r\n\r\nX_train, X_test, y_train, y_test = splice(feature_data, target_data)\r\nX_train, X_test, y_train, y_test = numpy_to_tensor(X_train, X_test, y_train, y_test)\r\n\r\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:51.52637Z","iopub.execute_input":"2021-08-25T00:01:51.526841Z","iopub.status.idle":"2021-08-25T00:01:51.571729Z","shell.execute_reply.started":"2021-08-25T00:01:51.52681Z","shell.execute_reply":"2021-08-25T00:01:51.570917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compute R2Score\r\ndef R2Score(actual, pred):\r\n    #convert the tensor parameters to numpy array and detach the gradient from pred\r\n    actual, pred = actual.numpy(), pred.detach().numpy()\r\n    actual, pred = actual.reshape(-1), pred.reshape(-1)\r\n    numerator = np.sum(np.square(actual - pred))\r\n    denominator = np.sum(np.square(actual - np.mean(actual)))\r\n    return 1 - (numerator/denominator)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:51.572725Z","iopub.execute_input":"2021-08-25T00:01:51.573123Z","iopub.status.idle":"2021-08-25T00:01:51.577902Z","shell.execute_reply.started":"2021-08-25T00:01:51.573094Z","shell.execute_reply":"2021-08-25T00:01:51.577251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training process\r\ndef training_process(X, y, epochs, batch_size):\r\n    total_loss = list()\r\n    total_R2Score = list()\r\n    for epoch in range(epochs):\r\n        print(f'Epoch no: {epoch+1}')\r\n        batch_loss = list()\r\n        batch_R2Score = list()\r\n        regression_model.train()\r\n        for idx in tqdm(range(0, len(X), batch_size)):\r\n            optimizer.zero_grad()\r\n            X_batch = X[idx:idx+batch_size]\r\n            y_batch = y[idx:idx+batch_size]\r\n            pred = regression_model(X_batch)\r\n            loss = torch.sqrt(lossFunc(pred, y_batch))\r\n            train_R2score = R2Score(y_batch, pred)\r\n            batch_R2Score.append(train_R2score)\r\n            batch_loss.append(loss.item())\r\n            loss.backward()\r\n            optimizer.step()\r\n        mean_batch_loss, mean_batch_R2Score = np.mean(batch_loss), np.mean(batch_R2Score)\r\n        print(f'RMSE batch_loss is: {mean_batch_loss} \\n R^2 Score: {mean_batch_R2Score}')\r\n        total_loss.append(mean_batch_loss)\r\n        total_R2Score.append(mean_batch_R2Score)\r\n\r\ntraining_process(X_train, y_train, epochs=epochs, batch_size=train_batch_size)\r\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:51.579653Z","iopub.execute_input":"2021-08-25T00:01:51.580107Z","iopub.status.idle":"2021-08-25T00:01:58.457004Z","shell.execute_reply.started":"2021-08-25T00:01:51.580076Z","shell.execute_reply":"2021-08-25T00:01:58.456015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing process\r\n\r\ndef inference(X, y):\r\n    comparison_df = pd.DataFrame()\r\n    comparison_df['actual'] = np.array(y).reshape(-1)\r\n    regression_model.eval()\r\n    with torch.no_grad():\r\n        pred = regression_model(X)\r\n        comparison_df['predicted'] = np.array(pred.detach()).reshape(-1)\r\n        RMSE_loss = torch.sqrt(lossFunc(pred, y))\r\n        test_R2Score = R2Score(y, pred)\r\n        print(f'RMSE: {RMSE_loss} \\n R^2 Score: {test_R2Score}')\r\n\r\n    #plot histogram of comparison\r\n    comparison_df.hist()\r\n\r\n    #plot bar chart of comparison\r\n    comparison_df.head(10).plot.bar()\r\ninference(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T00:01:58.458604Z","iopub.execute_input":"2021-08-25T00:01:58.459318Z","iopub.status.idle":"2021-08-25T00:01:59.053942Z","shell.execute_reply.started":"2021-08-25T00:01:58.459264Z","shell.execute_reply":"2021-08-25T00:01:59.05287Z"},"trusted":true},"execution_count":null,"outputs":[]}]}