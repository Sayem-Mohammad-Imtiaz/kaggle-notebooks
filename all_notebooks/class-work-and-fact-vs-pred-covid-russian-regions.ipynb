{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Подгружаем необходимые библиотеки для анализа данных и визуализации\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вам нужно форкнуть скрипт fetch, чтобы можно было его импортировать. Затем нужно File>Add Utility Script>fetch\n\nimport fetch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Используем скрипт от grwlf чтобы скачать последние данные с яндекса. Будем это делать в 2 ячейки:\n\ndata = fetch.fetch_yandex(dump_folder='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вторая ячейка, данные сохранятся в файл с именем времени скачивания. Запомним имя в переменную.\n\ndata, filepath = fetch.format_csse2(data, dump_folder='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Считываем исторические данные\n\nrussia = pd.read_csv('https://raw.githubusercontent.com/grwlf/COVID-19_plus_Russia/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_RU.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сфетченные данные считываем в нужном формате\n\nrussia_latest = pd.read_csv(filepath)\nrussia_latest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"russia.iloc[0,6]\n#.loc[0,'Province_State']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Исторические\n\nrussia.iloc[:,-3:].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Собираем все данные\n\nrus = russia.set_index('Province_State').join(russia_latest.set_index('Province_State')['Confirmed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rus.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вычисляем сегодня из имени файла\n\ntoday = filepath[:10]\ntoday2 = today[3:5]+'/'+today[:2]+'/'+today[-2:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переименовываем и убираем лишние колонки\n\nrus.drop(['UID','iso2','iso3','FIPS','Admin2','Country_Region','Lat','Long_','Combined_Key','code3'], axis=1, inplace=True)\nrus[today2] = rus['Confirmed']\ndel rus['Confirmed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Все данные есть:\n\nrus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Данные пока не обновились - обновление в 14:30 по НСК примерно\n\nrus['06/02/20'] = rus['06/03/20']\ndel rus['06/03/20']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = rus.T.iloc[-30:,:]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на последние 30 дней\n\ndf.plot(figsize=(15,10), legend=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Лучше взять логарифм, чтобы не смотреть только на Москву. Логарифма от 0 нет, поэтому добавляем 0.5\n\n(np.log(rus + 0.5).T).plot(figsize=(15,10), legend=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Все кривые выглядят схоже, поэтому я возьму средние значение и предположу, что они продолжатся для Новосибирской области.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# А что если бы всех поставить с 148+ случаями в начало графика?\n\ny = np.log(rus + 0.5).T\ny_m = y[y>5]\nprint ('Лог шкала:', [(one, np.round(np.exp(one),0)) for one in range(12)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_m.count().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_columns = []\n\nfor column in y_m.columns:\n    list_columns.append(y_m[column].count())\n    \nfilled = pd.Series(list_columns).max()\n\nprint('Макс кол-во наблюдений', filled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Пустой датафрейм\n\ny_gt_148 = pd.DataFrame(data = [[0 for i in range(len(y_m.columns))] for j in range(filled)], \\\n                        index = range(filled), columns = y_m.columns)\n\ny_gt_148","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Наполним датафрейм с первого наблюдения, где 148+ кейсов в логарифмической шкале\n\nfor i in range(len(y_m.columns)):\n    temp = y_m.iloc[:,i].dropna().reset_index(drop=True)\n    #print(temp)\n    y_gt_148.iloc[:temp.shape[0],i] = temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_gt_148 = y_gt_148.replace(0,np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_gt_148","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Пусть будет любое количество случаев, все вначале.\n\ny_gt_148.plot(figsize=(15,10), legend=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Давайте все линии начнем в одной точке\n\n# Самое большое значение для первого наблюдения\n\ny_gt_148.iloc[0,:].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подравняем все наблюдения на полученный максимум\n\ndelta = y_gt_148.iloc[0,:].max() - y_gt_148.iloc[0,:]\nall_in_one = y_gt_148 + delta\nall_in_one.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Пусть будут все исходить из одной точки.\n\nall_in_one.plot(figsize=(15,10), legend=None)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Давайте сравним Новосибирск с Москвой и другими схожими регионами. ","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Считаем список регионов для которых нужно предсказывать\n\nrussia_regions = pd.read_csv('/kaggle/input/russia-regions-in-sber-covid-competition/russia_regions.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"russia_regions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Манипуляции, чтобы выйти на нужный формат\n\n# Автономные области не названы, поможем назвать\n\nrussia_regions.loc[russia_regions['iso_code'] == 'RU-NEN', 'csse_province_state'] = 'Nenetskiy autonomous oblast'\nrussia_regions.loc[russia_regions['iso_code'] == 'RU-CHU', 'csse_province_state'] = 'Chukotskiy autonomous oblast'\n\n# Привести в соответствие с конкурсным перечнем регионов\n\nrus['ind'] = rus.index\n# Altay republic > Republic of Altay\nrus.loc[rus.index == 'Altay republic', 'ind'] = 'Republic of Altay'\nrus.set_index('ind', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_obl[sorted_obl['name']=='Новосибирская'].index[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Найдем области, похожие на Новосибирскую по населению\n\nsorted_obl = russia_regions.sort_values(['population']).reset_index()\n\nnsk_index = sorted_obl[sorted_obl['name']=='Новосибирская'].index[0]\n\nsorted_obl[nsk_index-2:nsk_index+3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_regions = list(sorted_obl[nsk_index-2:nsk_index+3]['csse_province_state'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_regions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_regions = selected_regions + ['Moscow']\nall_in_one[show_regions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_in_one[show_regions].plot(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(np.log(rus.loc[show_regions] + 0.5).T[-30:]).plot(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_30_days = np.log(rus.loc[show_regions] + 0.5).T[-30:]\nlast_30_days.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_30_days = last_30_days - last_30_days.loc['05/03/20']\nlast_30_days.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_30_days.plot(figsize=(15,10))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_100_days = np.log(rus.loc[show_regions] + 0.5).T[-100:]\n#last_100_days = last_30_days - last_30_days.loc['05/03/20']\nlast_100_days.plot(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d100 = last_100_days[last_100_days > 5]\n\nfilled2 = d100.count().max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nd100_eq = pd.DataFrame(data = [[0 for i in range(len(d100.columns))] for j in range(filled2)], \\\n                        index = range(filled2), columns = d100.columns)\n\n# Наполним датафрейм с первого наблюдения, где 148+ кейсов в логарифмической шкале\n\nfor i in range(len(d100.columns)):\n    temp = d100.iloc[:,i].dropna().reset_index(drop=True)\n    d100_eq.iloc[:temp.shape[0],i] = temp\n    \nd100_eq = d100_eq.replace(0,np.nan)\n\nprint(d100_eq.iloc[0,:].max())\n\ndelta = d100_eq.iloc[0,:].max() - d100_eq.iloc[0,:]\nd100_eq = d100_eq + delta\n\nprint(d100_eq.head())\n\nd100_eq.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d100.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d100['Novosibirsk oblast'].dropna().plot(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nsk = rus.loc['Novosibirsk oblast']\nnsk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nsk['06/01/20'] = 2914\nnsk['06/02/20'] = 3020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nsk.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del nsk['06/03/20']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nsk['06/03/20'] = 3122  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nsk.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nsk[nsk>150].plot(figsize=(15,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delta_nsk = nsk - nsk.shift()\n\ndelta_nsk = delta_nsk[delta_nsk>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delta_nsk.plot(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_nsk = np.log(nsk)\nlog_nsk = log_nsk[log_nsk>5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_nsk.plot(figsize=(15,10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_nsk.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nsk = pd.DataFrame(data = {'date' : pd.to_datetime(log_nsk.index), 'Nsk' : log_nsk.values, 'X' : range(1,44)})\n\ndf_nsk.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nsk.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Учимся на 10 днях и предсказываем на 30\n# Модель y = x^a или ln y = a * ln x\n\nX_train = np.log(df_nsk.loc[0:9,'X']).values.reshape(-1,1) \ny_train = np.log(df_nsk.loc[0:9,'Nsk']).values.reshape(-1,1)\n\nX_test = np.log(df_nsk.loc[10:39,'X']).values.reshape(-1,1) \ny_test = np.log(df_nsk.loc[10:39,'Nsk']).values.reshape(-1,1) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сделаем скользящим окном\n\nfor day in range(1,4):\n\n    X_train = np.log(df_nsk.loc[0 : 9 + day,'X']).values.reshape(-1,1) \n    y_train = np.log(df_nsk.loc[0 : 9 + day,'Nsk']).values.reshape(-1,1)\n\n    X_test = np.log(df_nsk.loc[10 + day : 39 + day,'X']).values.reshape(-1,1) \n    y_test = np.log(df_nsk.loc[10 + day : 39 + day,'Nsk']).values.reshape(-1,1) \n\n    # Скалируем признаки, для регрессии с регуляризацией хорошо\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n\n    # print(scaler.mean_, scaler.var_)\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    # Строим регрессию\n    from sklearn.linear_model import LinearRegression\n    reg = LinearRegression().fit(X_train_scaled, y_train)\n\n    # Функции для 2 метрик: первая - конкурсная, вторая - процент отклонения от истины\n    def MALE(pred, true):\n    #    print(np.log10((pred + 1) / (true + 1)))\n        return np.mean(np.abs(np.log10((pred + 1) / (true + 1))))\n\n    def AvgProc(pred, true):\n    #    print((pred-true)/true)\n        return np.mean(np.abs((pred-true)/true))\n\n    # Приводим у к кол-ву случаев\n    y_pred_test_exp = np.round(np.exp(np.exp(reg.predict(X_test_scaled))),0)\n    y_pred_train_exp = np.round(np.exp(np.exp(reg.predict(X_train_scaled))),0)\n    y_test_exp = np.round(np.exp(np.exp(y_test)),0)\n    y_train_exp = np.round(np.exp(np.exp(y_train)),0)\n\n    # Выводим результаты\n    print('coefs=', [(name,value) for (name,value) in zip(['ln NSK'],reg.coef_)], 'const=', reg.intercept_)\n    print('MALE test = ', MALE(y_pred_test_exp[:y_test.shape[0]], y_test_exp), 'MALE train =', MALE(y_pred_train_exp, y_train_exp))\n    print('AvgProc test = ', AvgProc(y_pred_test_exp[:y_test.shape[0]], y_test_exp), 'AvgProc train =', AvgProc(y_pred_train_exp, y_train_exp))\n\n\n    plt.figure(figsize=(15,10))\n\n    plt.plot(df_nsk.loc[10 + day : 39 + day,'date'], y_pred_test_exp) \n    plt.plot(df_nsk.loc[10 + day : 39 + day,'date'], y_test_exp)\n    plt.plot(df_nsk.loc[0 : 9 + day,'date'], y_pred_train_exp)\n    plt.plot(df_nsk.loc[0 : 9 + day,'date'], y_train_exp)\n\n    plt.legend()\n    plt.legend()\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Далее код из похожей задачи, может пригодиться","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # i это индекс, который будет меняться по регионам: берем первую область (край и т.п.)\n\n# scores = []\n# percent = []\n\n# for i in range(len(rus.T.columns)):\n\n#     obl = pd.DataFrame(rus.T.iloc[:,i].copy(), columns=[rus.T.iloc[:,i].name]) \n    \n#     # Исправим данные, где кол-во растет, потом падает: пусть только растет\n#     prev = 0\n#     obl_corrected = []\n\n#     for one in obl.iloc[:,0]:\n#         if one < prev:\n#             obl_corrected[-1] = one\n\n#         obl_corrected.append(one)  \n#         prev = one\n\n#     obl.iloc[:,0] = obl_corrected\n\n#     # Индекс приводим к формату даты\n#     obl.index = pd.to_datetime(obl.index) \n\n#     ## Делаем признаки\n\n#     # Порядковый номер дня в году - \"дата\" для всех\n#     obl['day_of_year'] = obl.index.dayofyear \n\n#     # Создаем day7 - на 1 возрастают дни (от начала года) со времени, когда кейсов стали больше 7 (после какого-то значения рост более стабильный)\n#     obl['day7'] = 0 \n#     idx_day_7 = obl.iloc[:,0]>7\n#     obl.loc[idx_day_7,'day7'] = obl.loc[idx_day_7,'day7'].index.dayofyear\n#     day_day7 = obl.loc[obl['day7'] > 0, 'day7'].min() - 1\n#     obl.loc[obl['day7'] > 0, 'day7'] -= day_day7 \n\n#     # Создаем apr6 - на 1 возрастают дни с 6 апреля - когда должны заметить карантин (30.03+7 дней) - траектория изменилась\n#     obl['apr6'] = 0 \n#     idx_apr_6 = obl.index >= '2020-04-06'\n#     obl.loc[idx_apr_6,'apr6'] = obl.loc[idx_apr_6,'apr6'].index.dayofyear\n#     day_apr6 = obl.loc[obl['apr6'] > 0, 'apr6'].min() - 1\n#     obl.loc[obl['apr6'] > 0, 'apr6'] -= day_apr6 \n    \n# #     # Создаем last7 - на 1 возрастают дни для последних 7 дней - больше учитываем последние данные\n# #     obl['last7'] = 0 \n# #     idx_last_7 = obl.index >= obl.index[-11]\n# #     obl.loc[idx_last_7,'last7'] = obl.loc[idx_last_7,'last7'].index.dayofyear\n# #     day_last7 = obl.loc[obl['last7'] > 0, 'last7'].min() - 1\n# #     obl.loc[obl['last7'] > 0, 'last7'] -= day_last7\n    \n# #     # И сделаем квадрат от last7\n# #     obl['last7_2'] = obl['last7'] ** 2\n\n#     pos_cases = obl.iloc[:,0]>0\n    \n#     # Давайте посмотрим на 2 режима - day7 (сверху) и apr6. Что видно?\n#     plt.figure(figsize=(15,10))\n#     plt.plot(np.log(obl.loc[pos_cases].iloc[:,0]))\n#     plt.scatter(obl.loc[pos_cases,'day7'].index,(obl.loc[pos_cases,'day7']>0)+0.1, label='day7')\n#     plt.scatter(obl.loc[pos_cases,'apr6'].index,(obl.loc[pos_cases,'apr6']>0), label='apr6')\n#     plt.title(obl.columns[0])\n#     plt.legend()\n#     plt.show()\n    \n# #     # Собираем Х\n# #     X_cols = ['day_of_year','day7','apr6','last7', 'last7_2']\n    \n# #     # до 26 обучаем, c 27 по 03 будем тестироваться\n# #     train = obl.loc[(pos_cases) & (obl.index<'2020-04-27')]    \n    \n# #     wk3 = ['2020-04-27','2020-04-28','2020-04-29','2020-04-30','2020-05-01','2020-05-02','2020-05-03']\n# #     test  = pd.DataFrame(index = pd.to_datetime(wk3), data = [], columns = X_cols)\n# #     test['day_of_year'] = test.index.dayofyear\n# #     count_down = test.index.dayofyear - test.index.dayofyear.min()\n# #     test['day7'] = count_down + train['day7'].max() + 1\n# #     test['apr6'] = count_down + train['apr6'].max() + 1\n# #     test['last7'] = count_down + 8\n# #     test['last7_2'] = test['last7'] ** 2\n\n# #     # Х в лог\n# #     X_train = np.log(train[X_cols] + 0.5)\n# #     y_train = np.log(train.iloc[:,0] + 0.5)\n# #     X_test = np.log(test[X_cols] + 0.5)\n\n# #     y_test  = obl.loc[obl.index>'2020-04-26',obl.columns[0]]\n# #     y_test = np.log(y_test + 0.5)\n\n# #     # Скалируем признаки, для регрессии с регуляризацией хорошо\n# #     from sklearn.preprocessing import StandardScaler\n# #     scaler = StandardScaler()\n# #     scaler.fit(X_train)\n# #     # print(scaler.mean_, scaler.var_)\n# #     X_train_scaled = scaler.transform(X_train)\n# #     X_test_scaled = scaler.transform(X_test)\n\n# #     # Строим регрессию\n# #     from sklearn.linear_model import LinearRegression\n# #     reg = LinearRegression().fit(X_train_scaled, y_train.values)\n\n# #     # Функции для 2 метрик: первая - конкурсная, вторая - процент отклонения от истины\n# #     def MALE(pred, true):\n# #     #    print(np.log10((pred + 1) / (true + 1)))\n# #         return np.mean(np.abs(np.log10((pred + 1) / (true + 1))))\n\n# #     def AvgProc(pred, true):\n# #     #    print((pred-true)/true)\n# #         return np.mean(np.abs((pred-true)/true))\n\n# #     # Приводим у к кол-ву случаев\n# #     y_pred_test_exp = np.round(np.exp(reg.predict(X_test_scaled))-0.5,0)\n# #     y_pred_train_exp = np.round(np.exp(reg.predict(X_train_scaled))-0.5,0)\n# #     y_test_exp = np.round(np.exp(y_test)-0.5,0)\n# #     y_train_exp = np.round(np.exp(y_train)-0.5,0)\n\n# #     # Обрабатываем \"Архангельский прыжок\" (резкое увеличение случаев - увеличиваем предсказ на 2/3 от скачка)\n# #     if i==2: \n# #         y_pred_test_exp = y_pred_test_exp + (y_train_exp[-1]-y_train_exp[-2])*(2/3)\n        \n# #     # Выводим результаты\n# #     print(obl.columns[0])\n# #     print('coefs=', [(name,value) for (name,value) in zip(X_cols,reg.coef_)], 'const=', reg.intercept_)\n# #     print('MALE test = ', MALE(y_pred_test_exp[:y_test.shape[0]], y_test_exp), 'MALE train =', MALE(y_pred_train_exp, y_train_exp))\n# #     print('AvgProc test = ', AvgProc(y_pred_test_exp[:y_test.shape[0]], y_test_exp), 'AvgProc train =', AvgProc(y_pred_train_exp, y_train_exp))\n\n# #     # Отрисуем предсказ\n# #     plt.figure(figsize=(15,10))\n    \n# #     wk3dt = pd.to_datetime(wk3)\n# #     for x,y in zip(y_test.index, y_test_exp):\n# #         label = \"{:.0f}\".format(y)\n# #         plt.annotate(label, # this is the text\n# #                      (x,y), # this is the point to label\n# #                      textcoords=\"offset points\", # how to position the text\n# #                      xytext=(0,-15), # distance from text to points (x,y)\n# #                      ha='center') # horizontal alignment can be left, right or center\n\n# #     for x,y in zip(wk3dt, y_pred_test_exp):\n# #         label = \"{:.0f}\".format(y)\n# #         plt.annotate(label, # this is the text\n# #                      (x,y), # this is the point to label\n# #                      textcoords=\"offset points\", # how to position the text\n# #                      xytext=(0,-15), # distance from text to points (x,y)\n# #                      ha='center') # horizontal alignment can be left, right or center\n\n# #     plt.title(obl.columns[0]+' predict')\n\n# #     plt.plot(wk3dt, y_pred_test_exp, 'ro-', label='pred')\n# #     plt.plot(y_test.index, y_test_exp, 'bo-', label='fact')\n\n# #     plt.legend()\n# #     plt.grid()\n# #     plt.show()\n\n# #     # Отрисуем модель\n# #     plt.figure(figsize=(15,10))\n\n# #     for x,y in zip(y_train.index, y_train_exp):\n# #         label = \"{:.0f}\".format(y)\n# #         plt.annotate(label, # this is the text\n# #                      (x,y), # this is the point to label\n# #                      textcoords=\"offset points\", # how to position the text\n# #                      xytext=(0,-15), # distance from text to points (x,y)\n# #                      ha='center') # horizontal alignment can be left, right or center\n\n# #     for x,y in zip(y_train.index, y_pred_train_exp):\n# #         label = \"{:.0f}\".format(y)\n# #         plt.annotate(label, # this is the text\n# #                      (x,y), # this is the point to label\n# #                      textcoords=\"offset points\", # how to position the text\n# #                      xytext=(0,-15), # distance from text to points (x,y)\n# #                      ha='center') # horizontal alignment can be left, right or center\n\n# #     plt.title(obl.columns[0]+' fit')\n\n# #     plt.plot(y_train.index, y_pred_train_exp, 'ro-', label='pred')\n# #     plt.plot(y_train.index, y_train_exp, 'bo-', label='fact')\n\n# #     plt.legend()\n# #     plt.grid()\n# #     plt.show()\n    \n# #     scores.append((obl.columns[0], MALE(y_pred_test_exp[:y_test.shape[0]], y_test_exp)))\n# #     percent.append((obl.columns[0], AvgProc(y_pred_test_exp[:y_test.shape[0]], y_test_exp)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# errors = pd.DataFrame([(one[0],one[1],two[1]) for (one,two) in zip(scores,percent)], columns=['Region','MALE','percent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.set_option('display.max_rows', None)\n# print (errors.sort_values('MALE', ascending=False))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.set_option('display.max_rows', 10)\n# print (pd.DataFrame(scores).sort_values([1], ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SCORE Avg MALE\n\n# np.mean([two for (one,two) in scores]), np.mean([two for (one,two) in percent])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}