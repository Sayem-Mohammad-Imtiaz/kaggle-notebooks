{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Loan Defaulter"},{"metadata":{},"cell_type":"markdown","source":"This case study aims to give you an idea of applying EDA in a real business scenario and developing a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers."},{"metadata":{},"cell_type":"markdown","source":"It aims to identify patterns which indicate if a client has difficulty paying their installments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc. This will ensure that the consumers capable of repaying the loan are not rejected. Identification of such applicants using EDA is the aim of this case study."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supressing the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nimport itertools\n%matplotlib inline\n\n# Styling the plot\nstyle.use('ggplot')\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adjusting Output Views\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.expand_frame_repr', False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the Dataset\napp = pd.read_csv('../input/loan-defaulter/application_data.csv')\nprev = pd.read_csv('../input/loan-defaulter/previous_application.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Understanding the dataset"},{"metadata":{},"cell_type":"markdown","source":"### 1.1.a. Inspecting Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"app.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Data types of each of the column in application data\napp.info(verbose= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking statistical information about the numerical columns\napp.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1.b. Inspecting Previous Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data types of each of the column in previous application data\nprev.info(verbose= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking statistical information about numerical columns in previous application dataset\nprev.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"### 2.1.a. Checking NULL values and Unnecessary Variables in Application dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of null values in each column\nround((app.isnull().sum()/len(app)*100.00), 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: There are many columns with more than 40% missing values.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us plot a bar graph to look at the proportion of null values with a benchmark of 40%\nplt.figure(figsize = [25,7])\nplt.title(\"Proportion of Null Values in Application Dataset\",fontsize=20)\nplt.xlabel(\"Column Names\", fontsize=15)\nplt.ylabel(\"Percentage of null values\", fontsize= 15)\nplt.xticks(rotation=90)\nax = sns.barplot(app.columns,round((app.isnull().sum()/app.shape[0])*100,2), color = 'blue')\nax.axhline(40, ls='--',color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing the columns names along their %age of NULL values\napp_miss = pd.DataFrame((app.isnull().sum()/len(app))*100).reset_index()\napp_miss.columns = ['Column Name', 'Null Value %age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns having more than 40% Null Values\napp_miss_40 = app_miss[app_miss['Null Value %age']>=40]\napp_miss_40","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(app_miss_40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: 49 columns have more than 40% NULL values of which most are related to the apartment details and won't help in our analysis. Hence, we will drop these columns.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"app_missing = pd.DataFrame((app.isnull().sum()/len(app))*100).reset_index()\napp_missing.columns = ['Column Name', 'Percentage of NULL values']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns having NULL Values\napp_missing = app_missing[app_missing['Percentage of NULL values'] > 0]\napp_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_ANNUITY\napp.AMT_ANNUITY.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, there are only 12 rows with missing values. So, we can delete these records\napp = app[~app.AMT_ANNUITY.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_GOODS_PRICE\napp.AMT_GOODS_PRICE.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('AMT_GOODS_PRICE')\nax = sns.boxplot(y = app.AMT_GOODS_PRICE)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can clearly see that there are many outliers. So, imputing the NULL values with median\napp.AMT_GOODS_PRICE = app.AMT_GOODS_PRICE.fillna(app.AMT_GOODS_PRICE.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NAME_TYPE_SUITE\napp.NAME_TYPE_SUITE.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, NAME_TYPE_SUITE is a categorical variable and have a lower NULL percentage.\n# So, we will use mode to impute the NULL values for this variable\napp.NAME_TYPE_SUITE = app.NAME_TYPE_SUITE.fillna(app.NAME_TYPE_SUITE.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OCCUPATION_TYPE\n# This column has more than 30% NULL values. So, we will make a separate category 'Unknown' for the NULL values\napp.OCCUPATION_TYPE = app.OCCUPATION_TYPE.fillna('Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNT_FAM_MEMBERS\napp.CNT_FAM_MEMBERS.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, there are just 2 records with missing values. So, we will delete these rows.\napp = app[~app.CNT_FAM_MEMBERS.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DAYS_LAST_PHONE_CHANGE\napp.DAYS_LAST_PHONE_CHANGE.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, there is just 1 record with missing values. So, we will delete these rows.\napp = app[~app.DAYS_LAST_PHONE_CHANGE.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT variables\napp[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n         'AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, these are the number of enquires and it can only be integers. So, imputing the NULL values with median\n# as median is an integer\namt = ['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\n       'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']\n\nfor i in amt:\n    app[i].fillna(app[i].median(),inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SOCIAL variables\napp[['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n     'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, these variables indicate the number of people and it can only be integers.\n# So, imputing the NULL values with median.\nsoc = ['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n     'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']\n\nfor i in soc:\n    app[i].fillna(app[i].median(),inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for the NULL values again\nprint(app.isnull().sum())\nprint('Shape: ', app.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the relationship of EXT_SOURCE variables with the TARGET variables\nsource = app[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'TARGET']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(source.corr(),\n            xticklabels= source.columns,\n            yticklabels= source.columns,\n            annot=True,\n            cmap = 'Reds')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: Since, the correlation of the EXT_SOURCE variables is very low with the TARGET variable, we can drop these.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding these SOURCE variables to the above 49 variables which are to be dropped\napp_unwanted = app_miss_40['Column Name'].to_list() + ['EXT_SOURCE_2', 'EXT_SOURCE_3']\nlen(app_unwanted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importance of FLAG_DOCUMENTS\napp_flag = app.loc[:, 'FLAG_DOCUMENT_2':'FLAG_DOCUMENT_21']\napp_flag['TARGET'] = app['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For the ease of undertanding, replacing the 1 and 0 in TARGET variable with 'Defaulter' and 'Non-Defaulter' respectively\napp_flag['TARGET'] = app_flag['TARGET'].replace({1 : 'Defaulter', 0 : 'Non-Defaulter'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the countplot of FLAG_DOCUMENTS with TARGET VARIABLE\nfig = plt.figure(figsize=(25,25))\nfor a, b in zip(app_flag, range(0,20)):                         # range(0,20) : for 20 FLAG_DOCUMENTS\n    plt.subplot(4,5,b+1)\n    ax = sns.countplot(app_flag[a], hue = app_flag['TARGET'], palette = ['blue', 'pink'])\n    plt.ylabel(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: People who submitted FLAG_DOCUMENT_3 are more likely to not default on loan and hence, this must be an important document. While the other FLAG_DOCUMENTS follow a similar pattern that is even if they did not submit, they were able to repay the loan. So, we should retain this FLAG_DOCUMENT_3 column and drop the remaining FLAG_DOCUMENTS.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"flag_cols = ['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n             'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10',\n             'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12','FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n             'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n             'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app_unwanted = app_unwanted + flag_cols\nlen(app_unwanted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importance of Contact-related Columns\ncontact = app.loc[:, 'FLAG_MOBIL':'FLAG_EMAIL']\ncontact['TARGET'] = app['TARGET']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation of Contact-related information with the TARGET variable\nplt.figure(figsize = (8,7))\nsns.heatmap(contact.corr(),\n            cmap=\"Reds\",\n            annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: As we can see from the above heatmap that there is no significant impact of Contact-related information on TARGET variables and would not affect our analysis. So, we can drop these columns.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"contact_cols = ['FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE',\n       'FLAG_PHONE', 'FLAG_EMAIL']\napp_unwanted = app_unwanted + contact_cols\nlen(app_unwanted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping these 76 variables from our Application Dataset\napp.drop(labels=app_unwanted, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the shape of our dataframe after dropping these columns\napp.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: After dropping these unwanted variables, we are left with 46 variables in our application dataset.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for the Numerical columns in the remaining dataset\napp.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: We can see that columns related to the DAYS are negative. So, let's convert them into positive values.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DAYS Columns\napp.loc[:,\"DAYS_BIRTH\": \"DAYS_ID_PUBLISH\"] = abs(app.loc[:,\"DAYS_BIRTH\": \"DAYS_ID_PUBLISH\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1.b. Checking NULL values and Unncecessary Variables in Previous Application dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of null values in each column\nround((prev.isnull().sum()/len(prev)*100.00), 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us plot a bar graph to look at the proportion of null values with a benchmark of 40%\nplt.figure(figsize = [25,7])\nplt.title(\"Proportion of Null Values in Previous Application Dataset\",fontsize=20)\nplt.xlabel(\"Columns\", fontsize=15)\nplt.ylabel(\"%null values\", fontsize= 15)\nplt.xticks(rotation=90)\nax = sns.barplot(prev.columns,round((prev.isnull().sum()/prev.shape[0])*100,2), color = 'blue')\nax.axhline(40, ls='--',color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: There are quite a few columns with more than 40% missing values.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Storing columns names along their %age of NULL values\nprev_miss = pd.DataFrame((prev.isnull().sum()/len(prev))*100).reset_index()\nprev_miss.columns = ['Column Name', 'Null Value %age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns having more than 40% Null Values\nprev_miss_40 = prev_miss[prev_miss['Null Value %age']>=40]\nprev_miss_40","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(prev_miss_40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: 11 columns have more than 40% NULL values. Hence, we will drop these columns.`"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"prev_miss[prev_miss['Null Value %age'] < 40]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding 4 more variables to the unwanted list which won't help in our analysis\nprev_unwanted = prev_miss_40['Column Name'].to_list() + ['WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START',\n                        'FLAG_LAST_APPL_PER_CONTRACT','NFLAG_LAST_APPL_IN_DAY']\nlen(prev_unwanted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping these unwanted variables from our Previous Application dataset\nprev.drop(labels = prev_unwanted, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.info(verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Handling NULL values in previous dataframe.\n#Checking null values percentage of each column.\n(prev.isnull().sum()/len(prev)).sort_values(ascending=False)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_GOODS_PRICE\nprev.AMT_GOODS_PRICE.plot.box();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As there are many outliers in this column, we will use median to impute null values.\nprev.AMT_GOODS_PRICE = prev.AMT_GOODS_PRICE.fillna(prev.AMT_GOODS_PRICE.median())\nprev.AMT_GOODS_PRICE.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNT_PAYMENT\nprev.CNT_PAYMENT.plot.box();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.CNT_PAYMENT.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the NAME_CONTRACT_STATUS against NULL values in the CNT_PAYMENT.\nprev[prev.CNT_PAYMENT.isnull()][\"NAME_CONTRACT_STATUS\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, many of the orders were canceled or refused indicating that loan was not even started.\n# So, there can not be any payment against them.  \nprev.CNT_PAYMENT = prev.CNT_PAYMENT.fillna(0)\nprev.CNT_PAYMENT.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_ANNUITY\nprev.AMT_ANNUITY.isnull().sum()\nprev.AMT_ANNUITY.plot.box();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can see from the boxplot, AMT_ANNUITY has many outliers, \n# therefore we will impute null values using median in this case too.\nprev.AMT_ANNUITY=prev.AMT_ANNUITY.fillna(prev.AMT_ANNUITY.median())\nprev.AMT_ANNUITY.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PRODUCT_COMBINATION\n# As this is a categorial column, we will use mode to impute the missing values.\nprev.PRODUCT_COMBINATION = prev.PRODUCT_COMBINATION.fillna(prev.PRODUCT_COMBINATION.mode()[0])\nprev.PRODUCT_COMBINATION.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_CREDIT\nprev.AMT_CREDIT.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As there is only a single missing value, we will drop this record\nprev = prev[~prev.AMT_CREDIT.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.a. Inspecting Data Types of Variables in Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"app.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"app.nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = ['NAME_CONTRACT_TYPE','CODE_GENDER','NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE',\n                       'NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE','WEEKDAY_APPR_PROCESS_START',\n                       'ORGANIZATION_TYPE','FLAG_OWN_CAR','FLAG_OWN_REALTY','LIVE_CITY_NOT_WORK_CITY',\n                       'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','REG_REGION_NOT_WORK_REGION',\n                       'LIVE_REGION_NOT_WORK_REGION','REGION_RATING_CLIENT','WEEKDAY_APPR_PROCESS_START',\n                       'REGION_RATING_CLIENT_W_CITY'\n                      ]\nfor a in cat_col:\n    app[a] =pd.Categorical(app[a])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"app.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2.b. Inspecting Data Types of Variables in Previous Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting Categorical columns from Object to categorical \ncat_col = ['NAME_CONTRACT_TYPE', 'NAME_CASH_LOAN_PURPOSE','NAME_CONTRACT_STATUS','NAME_PAYMENT_TYPE',\n                    'CODE_REJECT_REASON','NAME_CLIENT_TYPE','NAME_GOODS_CATEGORY','NAME_PORTFOLIO',\n                   'NAME_PRODUCT_TYPE','CHANNEL_TYPE','NAME_SELLER_INDUSTRY','NAME_YIELD_GROUP','PRODUCT_COMBINATION']\n\nfor i in cat_col:\n    prev[i] =pd.Categorical(prev[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.a Data Engineering on Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating client's age in year format\napp['AGE'] = app['DAYS_BIRTH'] // 365","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AGE column\nbins = [0, 20, 30, 40, 50, 100]\nlabels = ['0-20', '20-30', '30-40', '40-50', '50+']\napp['AGE_GROUP'] = pd.cut(app.AGE, bins = bins, labels= labels)\napp.AGE_GROUP.value_counts(normalize=True)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_CREDIT\nbins = [0,100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000,10000000]\nlabels = ['0-100K','100K-200K', '200K-300K','300K-400K','400K-500K','500K-600K','600K-700K','700K-800K',\n       '800K-900K','900K-1M', '1M Above']\napp['AMT_CREDIT_RANGE'] = pd.cut(app.AMT_CREDIT, bins=bins, labels=labels)\napp.AMT_CREDIT_RANGE.value_counts(normalize=True)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_INCOME_TOTAL\nbins = [0,100000,200000,300000,400000,500000,600000,700000,800000,900000,1000000,10000000]\nlabels = ['0-100K','100K-200K', '200K-300K','300K-400K','400K-500K','500k-600K','600K-700K','700K-800K',\n       '800K-900K','900K-1M', '1M Above']\napp['AMT_INCOME_RANGE'] = pd.cut(app.AMT_INCOME_TOTAL, bins=bins, labels=labels)\napp.AMT_INCOME_RANGE.value_counts(normalize=True)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_INCOME_RANGE\napp = app[~app.AMT_INCOME_RANGE.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# YEARS_EMPLOYED\napp['YEARS_EMPLOYED'] = app['DAYS_EMPLOYED'] // 365\nbins = [0,5,10,20,30,40,50,60,1000]\nlabels = ['0-5','5-10','10-20','20-30','30-40','40-50','50-60','60 above']\napp['EMPLOYMENT_YEAR_RANGE'] = pd.cut(app['YEARS_EMPLOYED'],bins=bins,labels=labels)\napp.EMPLOYMENT_YEAR_RANGE.value_counts(normalize = True)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('YEARS_EMPLOYED')\nax = sns.distplot(app.YEARS_EMPLOYED);\nax.set_facecolor('white')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`Observation: Since, YEARS_EMPLOYED has values approx 1000 indicating that the person has been working for 1000 years which is impossible. Hence this column has a lot of incorrect values. So, we will drop 'DAYS_EMPLOYED', 'YEARS_EMPLOYED', 'EMPLOYMENT_YEAR_RANGE' so that it does not hinder with our analysis later on.`"},{"metadata":{"trusted":true},"cell_type":"code","source":"app.drop(['DAYS_EMPLOYED', 'YEARS_EMPLOYED', 'EMPLOYMENT_YEAR_RANGE'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3.b. Data Engineering on Previous Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DAYS_DECISION\nprev.DAYS_DECISION.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Negative days value to Positive\nprev.DAYS_DECISION = abs(prev.DAYS_DECISION)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(prev.DAYS_DECISION);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Binning the DAYS_DECISION to get a better look at the variable\nbins = [0,500,1000,1500,2000,2500,3000]\nlabels = ['0-500', '500-1000', '1000-1500', '1500-2000', '2000-2500', '2500-3000']\nprev['DAYS_DECISION_GROUP'] = pd.cut(prev.DAYS_DECISION, bins = bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.DAYS_DECISION_GROUP.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prev.nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4.a. Outliers in Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"app.dtypes","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\ncol_1 = ['AMT_ANNUITY','AMT_INCOME_TOTAL','AMT_CREDIT','AMT_GOODS_PRICE','CNT_CHILDREN','DAYS_BIRTH']\nfor i in col_1:\n    plt.subplot(2,3,col_1.index(i)+1)\n    ax = sns.boxplot(y=app[i])\n    plt.title(i)\n    plt.ylabel(\"\")\n    ax.set_facecolor('white')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(app[['AMT_ANNUITY','AMT_INCOME_TOTAL','AMT_CREDIT','AMT_GOODS_PRICE', 'CNT_CHILDREN','DAYS_BIRTH']].describe(), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- AMT_INCOME_TOTAL: There is an outlier very far from the normal data. Since it is an Income column there might be wealthy people included in the dataset.\n- 75% of applicants have taken a credit amount less than 800K.\n- AMT_GOODS_PRICE also has number of outliers, but these goods prices are matching with the credit amount since they may have taken the loan for purchasing those goods.\n- DAYS_BIRTH column doesn't have any outliers, this shows that DAYS_BIR."},{"metadata":{},"cell_type":"markdown","source":"### 2.4.b. Outliers in Previous Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 10))\n\ncol_2 = ['AMT_ANNUITY','AMT_APPLICATION','AMT_CREDIT','AMT_GOODS_PRICE','DAYS_DECISION','CNT_PAYMENT','SELLERPLACE_AREA']\n\nfor i in col_2:\n    plt.subplot(2,4,col_2.index(i)+1)\n    ax = sns.boxplot(y=prev[i])\n    plt.title(i)\n    plt.ylabel(\"\")\n    ax.set_facecolor('white')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(prev[['AMT_ANNUITY','AMT_APPLICATION','AMT_CREDIT','AMT_GOODS_PRICE','SELLERPLACE_AREA',\n            'DAYS_DECISION','CNT_PAYMENT']].describe(), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- DAYS_DECISION has few amount of outliers indicating that the previous application decisions were taken in a few days        when the application was last applied\n- AMT_ANNUITY, AMT_APPLICATION, AMT_CREDIT, AMT_GOODS_PRICE, SELLERPLACE_AREA are distributed compactly with huge            outliers and are quite a few in number.\n- Since, AMT_GOODS_PRICE has a number of outliers. To buy these goods people apply for a larger amount of loan (thus, indicating why there are outliers in the AMT_APPLICATION) and hence, receive higher amount of Credits explaining the outliers in the AMT_CREDIT column."},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### 3.1.a. Data Imbalance in Application Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Checking if the data is Imbalanced\nImbalance = app.TARGET.value_counts().reset_index()\n\nplt.figure(figsize=(10,10))\nx= ['Non-Defaulter','Defaulter']\nImbalance.plot.pie(autopct='%1.1f%%', y=\"TARGET\",\n                   labels=[\"Non-Defaulters\",\"Defaulters\"], shadow=True,\n                   explode=(0.2,0), legend=False, colors=[\"#DC143C\",\"#FFF8DC\"])\nplt.ylabel(\"\")\nplt.title(\"Imbalance Plotting\")\nax.set_facecolor(\"white\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the percentage of defaulters and non-Defaulters in the dataset, using the target column.\n# Non-Defaulter ---> 0 \n# Defaulter ---> 1\nDefaulter_percent = round((np.sum(app.TARGET) / len(app))*100, 2)\nNon_Defaulter_percent = round((app.shape[0]-np.sum(app.TARGET))/app.shape[0]*100,2)\nprint(\"Percentage of Non-defaulter and Defaulter datas are:\",\n      Non_Defaulter_percent,\"% and\",Defaulter_percent, '%')\nprint(\"Imbalance Ratio of Non-Defaulter to Defaulter in the data is:\",\n      round(Non_Defaulter_percent/Defaulter_percent,2),\": 1\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2. Univariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.a. Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Customized function for Univariate Categorical Analysis\n\ndef cat_univ(data, var, broad=False, log = False,\n             loc = 'upper right', label_rotate = False):# var = categorical variable under analysis\n    data = data\n    var = var\n    \n    if loc == 'upper left':\n        loc = 'upper left'\n    else:\n        'upper right'\n        \n    if broad:\n        fig, ax = plt.subplots(1,2, figsize = (20,7))\n    else:\n        fig, ax = plt.subplots(1,2,figsize=(10,5))\n\n    def_perc = data[[var,\"TARGET\"]].groupby(var, as_index=False).mean()\n    def_perc['TARGET'] = def_perc['TARGET']*100\n    def_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n    \n    # Subplot 1\n    ax1 = sns.countplot(data = data, x = var, hue = 'TARGET', ax = ax[0])\n    ax1.set_title(var, fontdict = {'fontsize': 13, 'color': 'red'})\n    ax1.legend(['Non-Defaulter', 'Defaulter'], loc = loc)\n    ax1.set_ylabel('Number of Customers')\n    if (label_rotate):\n        ax1.set_xticklabels(ax1.get_xticklabels(), rotation = 90)\n    \n    if log:                              # Using log scale to increase the readibility of the graph\n        ax1.set_yscale('log')\n        ax1.set_ylabel(\"Count (log)\",fontdict={'fontsize' : 10, 'fontweight' : 3})  \n    \n    # Subplot 2\n    ax2 = sns.barplot(data=def_perc ,x=var, y=\"TARGET\", palette='Set1', ax = ax[1], order=def_perc[var])\n    ax2.set_title('Percentage Defaulters', fontdict = {'fontsize': 13, 'color': 'red'})\n    ax2.set_ylabel('Percentage of Defaulters')\n    if (label_rotate):\n        ax2.set_xticklabels(ax2.get_xticklabels(), rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# NAME_CONTRACT_TYPE\ncat_univ(app, 'NAME_CONTRACT_TYPE', broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- There are very less customers with revolving loans and 5% of them have not repaid the loan.\n- Approximately 8% of people with cash loans have not repaid the loan."},{"metadata":{"trusted":true},"cell_type":"code","source":"# CODE_GENDER\ncat_univ(app, 'CODE_GENDER')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Female customers have taken more loans but male customers have higher number of defaulters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# FLAG_OWN_CAR\ncat_univ(app, 'FLAG_OWN_CAR')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- People who don't own a car have take more number of loans but the percentage of defaulters for both the categories is almost the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"# FLAG_OWN_REALTY\ncat_univ(app, 'FLAG_OWN_REALTY')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- People who own Realty have taken more number of loans but the percentage of defaulters for the categories is almost the same."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# NAME_HOUSING_TYPE\ncat_univ(app, 'NAME_HOUSING_TYPE', label_rotate=True, broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- People with House/Apartment have taken most number of loans.\n- Higher percentage of people who have not repaid the loans live in either Rented Apartments or with their parents."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# NAME_FAMILY_STATUS\ncat_univ(app, 'NAME_FAMILY_STATUS', label_rotate=True, broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Married people have taken most number of loans.\n- Civil Marriage folks and Single/Unmarried are the ones who defaulted on the most number of loans.\n- Widows have defualted on least number of loans."},{"metadata":{"trusted":true},"cell_type":"code","source":"# NAME_EDUCATION_TYPE\ncat_univ(app, 'NAME_EDUCATION_TYPE', loc = 'upper left', label_rotate=True, broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation: \n- People who have done Secondary/secondary special education have taken higher number of loans.\n- People with Lower Secodary although have taken a very few number of loans but have the highest default percentage amongst them.\n- People with Academic degree have less than 2% of defaulting rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"# NAME_INCOME_TYPE\ncat_univ(app, 'NAME_INCOME_TYPE', loc = 'upper left', label_rotate=True, broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- People who are working have highest number of loans.\n- Although females on maternity leaves have taken significantly lower number of loans but have approximately 40% default rate amongst them which is the highest in any category.\n- People who are unemployed have a default rate of more than 35%."},{"metadata":{"trusted":true},"cell_type":"code","source":"# REGION_RATING_CLIENT\ncat_univ(app, 'REGION_RATING_CLIENT', broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Most of the people who have applied for loans are living in REGION_RATING_CLIENT 2.\n- Applicants living in REGION_RATING_1 have defaulted least no. of loans where as applicants living in REGION_RATING_3 \n  have defaulted most number of loans."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# OCCUPATION_TYPE\ncat_univ(app, 'OCCUPATION_TYPE',log = True, loc ='upper left', broad = True, label_rotate=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Laborers have taken most no. of loans followed by Sales staff, core staff, Managers.\n- Low-skill Labourers have defaulted most no. of loans(approx. 17%) followed by Waiters/Barmen staff, Drivers, Secondary staff.\n- For a very high number of applications occupation type information is unknmown."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# ORGANIZATION_TYPE\ncat_univ(app, 'ORGANIZATION_TYPE', broad=True, log = True, label_rotate=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Most of the people who applied for loan are from Business Entity Type 3.\n- For a very high number of applications, Organization type information is missing(XNA).\n- Industry Type 12, Trade type 4 has less defaulters(less than 4%), therefore the applicants from these organizations can be trusted.\n- Transport type 3 have more than 15% of defaulters, making it the category with highest defaulters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# FLAG_DOCUMENT_3\ncat_univ(app, 'FLAG_DOCUMENT_3', log = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- We can see that the percentage of Defaulters is similar for both kinds of people, it doesn't depend on wether the applicant has submitted FLAG_DOCUMENT_3."},{"metadata":{"trusted":true},"cell_type":"code","source":"# AGE_GROUP\ncat_univ(app, 'AGE_GROUP', log = True, broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- All age group from 20 to 50+ have applied for loans and most defaulters are in 20-40 age group."},{"metadata":{"trusted":true},"cell_type":"code","source":"# AMT_CREDIT_RANGE\ncat_univ(app, 'AMT_CREDIT_RANGE', label_rotate=True, broad = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- People with credit amount between 400K-600K tend to default more than others."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# AMT_INCOME_RANGE\ncat_univ(app, 'AMT_INCOME_RANGE', broad=True, label_rotate = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations:\n- Most of the applicants have income less than 300K.\n- Applicants with income more than 700K are less likely to default.\n- Applicants with income less than 300K are more likely to default."},{"metadata":{},"cell_type":"markdown","source":"#### 3.2.b. Numerical Univariate and Bivariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing the dataset on the basis of TARGET column\nNon_Defaulter_df = app.loc[app['TARGET']==0] # Non-Defaulters\nDefaulter_df = app.loc[app['TARGET']==1] # Defaulters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting pairplots for the AMOUNT with respect to the TARGET variable.\namt = app[[ 'AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY', 'AMT_GOODS_PRICE', 'TARGET']]\nax = sns.pairplot(amt, hue = 'TARGET', palette='husl')\nax.fig.legend(['Non-Defaulter', 'Defaulter'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations from individual Distribution plots `(Univariate Numerical Analysis)`:\n- Most number of loans are given for goods price below 10 lakhs.\n- Most people pay annuity below 50000 for the credit loan.\n- Credit amount of the loan is mostly less then 10 lakhs.\n- The repayers and defaulters distribution overlap in all the plots and hence we cannot use any of these variables in         isolation to make a decision."},{"metadata":{},"cell_type":"markdown","source":"Observations from Scatter Plots `(Bivariate Analysis)`:\n- AMT_CREDIT and AMT_GOODS_PRICE are highly correlated, as the points are forming a straight line, thus showing a linear     relationship between the two.\n- We can see that as AMT_CREDIT & AMT_GOODS_PRICE exceeds 3M, the proportion of defaulters decreases significantly.\n- When AMT_ANNUITY > 150K & AMT_CREDIT > 3M, the percentage of defaulters decreases."},{"metadata":{},"cell_type":"markdown","source":"### 3.4. Correlation"},{"metadata":{},"cell_type":"markdown","source":"#### 3.4.a. Correlation for Non-Defaulters"},{"metadata":{"trusted":true},"cell_type":"code","source":"Non_Defaulter_df.drop(['SK_ID_CURR', 'TARGET', 'DAYS_BIRTH'], axis = 1, inplace = True)\nNon_Defaulter_corr = Non_Defaulter_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation for Non-Defaulter\nmask = np.zeros_like(Non_Defaulter_corr)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize = (11,9))\nwith sns.axes_style('white'):\n    ax = sns.heatmap(Non_Defaulter_corr, mask = mask, square=True, linewidths=1, cmap = 'YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation for Non-Defaulter Data:\n- - These variables are intercorrelated with each other:\n  1. AMT_CREDIT\n  2. AMT_INCOME_TOTAL\n  3. AMT_GOODS_PRICE\n  4. AMT_ANNUITY\n- A high degree correlation can be seen between CNT_CHILDREN and CNT_FAM_MEMBERS."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top-10 Correlation for the Non-Defaulter\nNon_Defaulter_corr_10 = Non_Defaulter_corr.unstack().reset_index()\nNon_Defaulter_corr_10.columns = ['Column 1', 'Column 2', 'Correlation']\nNon_Defaulter_corr_10['Correlation'] = abs(Non_Defaulter_corr_10['Correlation'])\nNon_Defaulter_corr_10 = Non_Defaulter_corr_10[Non_Defaulter_corr_10['Correlation'] != 1 ]\nNon_Defaulter_corr_10.sort_values(by = 'Correlation', ascending = False, inplace = True)\nNon_Defaulter_corr_10.drop_duplicates(subset = 'Correlation', keep = 'first', inplace = True)\nNon_Defaulter_corr_10.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.4.b. Correlation for Defaulters"},{"metadata":{"trusted":true},"cell_type":"code","source":"Defaulter_df.drop(['SK_ID_CURR', 'TARGET', 'DAYS_BIRTH',], axis = 1, inplace = True)\nDefaulter_corr = Defaulter_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation for Defaulter\nmask = np.zeros_like(Defaulter_corr)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize = (11,9))\nwith sns.axes_style('white'):\n    ax = sns.heatmap(Defaulter_corr, mask = mask, square=True, linewidths=1, cmap = 'YlGnBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation for Defaulter Data:\n- - These variables are intercorrelated with each other:\n  1. AMT_CREDIT\n  2. AMT_INCOME_TOTAL\n  3. AMT_GOODS_PRICE\n  4. AMT_ANNUITY\n- A high degree correlation can be seen between CNT_CHILDREN and CNT_FAM_MEMBERS."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top-10 Correlation for the Defaulter\nDefaulter_corr_10 = Defaulter_corr.unstack().reset_index()\nDefaulter_corr_10.columns = ['Column 1', 'Column 2', 'Correlation']\nDefaulter_corr_10['Correlation'] = abs(Defaulter_corr_10['Correlation'])\nDefaulter_corr_10 = Defaulter_corr_10[Defaulter_corr_10['Correlation'] != 1 ]\nDefaulter_corr_10.sort_values(by = 'Correlation', ascending = False, inplace = True)\nDefaulter_corr_10.drop_duplicates(subset = 'Correlation', keep = 'first', inplace = True)\nDefaulter_corr_10.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.5. Merged DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging application DataFrame and Previous Application dataframe.\ncombined = pd.merge(app,prev,how=\"inner\",on=\"SK_ID_CURR\")\ncombined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the Statistics of the combined dataframe.\nround(combined.describe(),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividing combined dataset on the basis of target column.\ncombined_Def= combined[combined.TARGET==1] # Defaulters\ncombined_Non_Def= combined[combined.TARGET==0] # Non-Defaulters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking shape of these datasets.\nprint(\" Combined_Def:\",combined_Def.shape,\"\\n\",\"Combined_Non_Def:\", combined_Non_Def.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Customized function for plotting loan purpose vs loan status for both defaulters and non defaulters seperately.\ndef combined_univ(data, col, hue, log):\n    data = data\n    col = col\n    hue = hue\n    \n    plt.figure(figsize=(20,7))\n    ax=sns.countplot(x=col, \n                  data=data,\n                  hue= hue,\n                  palette= 'Set1',\n                  order=data[col].value_counts().index)\n    \n\n    if log:\n        plt.yscale('log')\n        \n    if data is combined_Def:\n        plt.title(\"Purpose of loan vs diff. Loan Status for Defaulters\" ,\n                  fontdict={'fontsize' : 20, 'fontweight' : 5, 'color' : 'Blue'})\n    elif data is combined_Non_Def:\n        plt.title(\"Purpose of loan vs diff. Loan Status for Non-Defaulters\" ,\n                  fontdict={'fontsize' : 20, 'fontweight' : 5, 'color' : 'Blue'})\n    else:\n        plt.title(\"Purpose of loan vs diff. Loan for all the applicants\",\n                  fontdict={'fontsize' : 20, 'fontweight' : 5, 'color' : 'Blue'})\n\n    plt.legend(loc = \"upper right\")\n    plt.xticks(rotation=90, ha='right')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Countplot for all the applicants\ncombined_univ(data = combined, col = 'NAME_CASH_LOAN_PURPOSE', hue = 'NAME_CONTRACT_STATUS',log=True)\n# countplot for Defaulters\ncombined_univ(data = combined_Def, col = 'NAME_CASH_LOAN_PURPOSE', hue = 'NAME_CONTRACT_STATUS', log = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Purpose of loan is unknown for very high number of applicants.\n- Banks have rejected high number of applications taken for Repair and Other purposes, also applicants have refused these offers more number of times. \n-  There are few places where proportion of Non-Defaulters is significantly higher.\n   \n   They are-\n   1. 'Buying a garage'\n   2. 'Business development'\n   3. 'Buying land'\n   4. 'Buying a new car'\n   5. 'Education'\n   \n   Hence we can focus on these purposes for which default percentage is less."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the Contract Status based on loan repayment status and whether there is any business loss or financial loss.\nplt.figure(figsize = (10,5))\nax=sns.countplot(data=combined,x=\"NAME_CONTRACT_STATUS\",hue=\"TARGET\",palette=[\"blue\",\"pink\"])\nax.legend(['Non-Defaulter', 'Defaulter'])\nplt.title(\"Contract Status vs TARGET\" , fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- 90% of clients who cancelled their loan previously have successfully repayed their current loan, bank should record the\n  reason for cancellation of these clients and bring in some policies accordingly as so they can be potential customers\n  for the bank.\n- Major portion of clients who have been previously refused a loan have payed back the loan in current case. Refual reason should be recorded for further analysis as these clients would turn into potential repaying customer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the relationship between people who defaulted in last 60 days \n# being in client's social circle and contract status.\nplt.figure(figsize = (10,5))\nax= sns.pointplot(data=combined, x=\"NAME_CONTRACT_STATUS\", y='DEF_60_CNT_SOCIAL_CIRCLE',\n                  hue=\"TARGET\", palette=[\"blue\",\"pink\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n- Clients who have average of 0.13 or higher DEF_60_CNT_SOCIAL_CIRCLE score tend to default more and hence client's social circle has to be analysed before providing the loan."},{"metadata":{},"cell_type":"markdown","source":"# 4. Conclusions"},{"metadata":{},"cell_type":"markdown","source":"`After analysing the datasets, we can see that there are quite a few variables through which the bank can see what are the driving factors as to who can repay the loan.`"},{"metadata":{},"cell_type":"markdown","source":"Factors which indicate that the person will be a `Non-Defaulter` are:\n1. LOANS_EDUCATION_TYPE: People who have Academic Degrees have less defaults as compared to other people.\n2. NAME_INCOME_TYPE: Students and Businessmen have no defaults.\n3. NAME_FAMILY_STATUS: Widows are least likely to default on the loans.\n4. AMT_INCOME_TOTAL: Customers who have income in the range of 700K and 800K are least likely to default.\n5. ORGANIZATION_TYPE: Clients with Trade Type:4 & 6, Industry Type:12 Transport Type: 1 are least likely to default."},{"metadata":{},"cell_type":"markdown","source":"Factors which indicate that the person will be a `Defaulter` are:\n1. CODE_GENDER: Male Customers are more likely to default than females.\n2. NAME_FAMILY_STATUS: People who are single or have done Civil Marriage are more likely to default.\n3. NAME_INCOME_TYPE: Clients who are on maternity leave or are Unemployed are most likely to default on their payments.\n4. NAME_HOUSING_TYPE: People who live with in rented apartments or with their parents are more likely to default on loan.\n5. OCCUPATION_TYPE: Low-Skilled Labourers are most likely to default on the loan.\n6. AGE_GROUP: People in the Age Group of 20-40 have are most likely to default on the loan."},{"metadata":{},"cell_type":"markdown","source":"The following variables indicate the people from the below categories tend to default on the loan which can be prevented by providing them loans at higher interest rate to cushion any default risk and further, preventing any business loss:\n    \n  1. NAME_HOUSING_TYPE: People living in the Rented Apartments are the ones who take a large number of loans but also have a higher default rate. So, completely shutting them off would be loss for the business.\n  2. AMT_CREDIT: There are a large chunk of people who earn in the range of 100K and 200K and also those people have a higher default rate. So, keeping a higher interest rate would make sense\n  3. NAME_EDUCATION_TYPE: People with Secondary/Special education applied for most Percentage of loans and thus, keeping a nominal interest rate for those folks would help in the business.\n  4. NAME_CASH_LOAN_PURPOSE: Loans taken for the purpose of Repairs have a higher default rate and hence, the bank charges a higher interest rate for that client which the client cannot bear and hence, cancel the loan in other stages of the application.\n  5. OCCUPATION_TYPE: There are quite a few low-skilled and other labourers who apply for the loans and these people also have a higher default rate. Since, these people also have low incomes so the bank should keep a decent amount of interest rate which would not lead to carry out any defaults for these people."},{"metadata":{},"cell_type":"markdown","source":"`More Suggestions:`\n- There are a significant number of people who had cancelled the loan application but have now turned into Repayers. So, the bank could collect the information on what made them cancel the service and improve on those services for the clients.\n- Almost 85% of the clients who were refused the loan in the previous application have repayed the loan or have no difficulty in repaying the loan. Thus, refusing these clients any further would be bad for business and hence, bank should recheck the reasons behind the refusals for these customers."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}