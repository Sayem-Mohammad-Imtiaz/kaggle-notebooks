{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Chest X-ray classification (CNN, transfer learning)"},{"metadata":{},"cell_type":"markdown","source":"## Initial settings"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"### Setting seeds and disabling multithreading to provide reproducible results ###\nfrom os import environ\nenviron['PYTHONHASHSEED'] = '0'\n\nimport random as rn\nimport numpy as np\nimport tensorflow as tf\n\nSEED = 1234\nnp.random.seed(SEED)\nrn.seed(SEED)\n\nsession_conf = tf.ConfigProto(\n    intra_op_parallelism_threads=1,\n    inter_op_parallelism_threads=1)\ntf.set_random_seed(SEED)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n\nfrom keras import backend as K\n\nK.set_session(sess)\n\n### Necessary imports and settings ###\nimport functools\nimport operator\nimport shutil\nimport timeit\nfrom os import listdir, mkdir, path\nimport pandas as pd\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.initializers import glorot_uniform\nfrom keras.layers import (Activation, BatchNormalization, Conv2D, Dense,\n                          Dropout, Flatten, MaxPooling2D)\nfrom keras.losses import binary_crossentropy\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom matplotlib import image\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nroot_dir = \"../input/all/All/\"  # original path for the dataset (relational, from kernel)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data analysis and preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"### File with true labels ###\ngtruth = pd.read_csv(root_dir + 'GTruth.csv', header=0)\ndf = pd.DataFrame(gtruth.head())\ndf","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"### Distribution of data in classes ###\nlabels = ('Healthy', 'Pneumonia')\ncounts = (\n    np.count_nonzero(gtruth[\"Ground_Truth\"]),\n    np.count_nonzero(gtruth[\"Ground_Truth\"] == 0))\n\nprint(counts)\n\nplt.pie(counts, labels=labels, colors=('#BFBFBF', '#808080'), autopct='%1.f%%')\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"### Loading dataset sample (first 10 images) ###\nsample_size = 10\nimg_sample = [(fname, image.imread(root_dir + fname))\n              for i, fname in enumerate(listdir(root_dir))\n              if fname.endswith('.jpeg') and 5 < i < sample_size]\n\n### Show sample images along with their filename and shape ###\nrows, columns = 2, 2\nfig = plt.figure(figsize=(6, 6))\nfor index, img in enumerate(img_sample):\n    print('Filename:', img[0], ' shape:', img[1].shape)\n    fig.add_subplot(rows, columns, index + 1)\n    # matplotlib displays single-channel images in greenish color, so it's necessary to choose a gray colormap\n    plt.imshow(img[1], cmap=plt.cm.gray)\nplt.subplots_adjust(left=1, right=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Creating directories for train-validation-test sets ###\nbase_dir = '../pneumonia-chest-x-ray'\n\ntry:\n    mkdir(base_dir)\nexcept FileExistsError:\n    shutil.rmtree(base_dir)\n    mkdir(base_dir)\n\ntrain_dir = path.join(base_dir, 'train')\nvalidation_dir = path.join(base_dir, 'validation')\ntest_dir = path.join(base_dir, 'test')\n\ntry:\n    mkdir(train_dir)\n    mkdir(validation_dir)\n    mkdir(test_dir)\nexcept FileExistsError:\n    pass\n\ntrain_1_dir = path.join(train_dir, 'healthy')\ntrain_0_dir = path.join(train_dir, 'pneumonia')\nvalidation_1_dir = path.join(validation_dir, 'healthy')\nvalidation_0_dir = path.join(validation_dir, 'pneumonia')\ntest_1_dir = path.join(test_dir, 'healthy')\ntest_0_dir = path.join(test_dir, 'pneumonia')\n\ntry:\n    mkdir(train_1_dir)\n    mkdir(train_0_dir)\n    mkdir(validation_1_dir)\n    mkdir(validation_0_dir)\n    mkdir(test_1_dir)\n    mkdir(test_0_dir)\nexcept FileExistsError:\n    pass\n\n### Determine lists of id's of images in classes ###\nclass_0_full = [np.array2string(row[0]) for row in gtruth.values if row[1] == 0]\nclass_1_full = [np.array2string(row[0]) for row in gtruth.values if row[1] != 0]\n\n### Take first 1280 images from every class ###\nclass_0 = rn.sample(class_0_full, 1280)\nclass_1 = rn.sample(class_1_full, len(class_0))\n\nprint(\"Number of images in classes: \\nclass 0 - pneumonia:\", len(class_0),\n      \"\\nclass 1 - healthy:\", len(class_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Splitting the data into train-val-test sets/directories ###\nfor i, (img_0, img_1) in enumerate(zip(class_0, class_1)):\n    fname_0 = img_0 + '.jpeg'\n    fname_1 = img_1 + '.jpeg'\n    if i < 0.8 * len(class_0):\n        shutil.copyfile(path.join(root_dir, fname_0),\n                        path.join(train_0_dir, fname_0))\n        shutil.copyfile(path.join(root_dir, fname_1),\n                        path.join(train_1_dir, fname_1))\n    elif i < 0.9 * len(class_0):\n        shutil.copyfile(path.join(root_dir, fname_0),\n                        path.join(validation_0_dir, fname_0))\n        shutil.copyfile(path.join(root_dir, fname_1),\n                        path.join(validation_1_dir, fname_1))\n    else:\n        shutil.copyfile(path.join(root_dir, fname_0),\n                        path.join(test_0_dir, fname_0))\n        shutil.copyfile(path.join(root_dir, fname_1),\n                        path.join(test_1_dir, fname_1))\n\n### Number of images in train-validation-test sets ###\nn_train = len(listdir(train_1_dir)) + len(listdir(train_0_dir))\nn_val = len(listdir(validation_1_dir)) + len(listdir(validation_0_dir))\nn_test = len(listdir(test_1_dir)) + len(listdir(test_0_dir))\nprint('Train images:', n_train)\nprint('Validation images:', n_val)\nprint('Test images:', n_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. CNN model - initialization and training"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Preparing image generators with rescaling, resizing ###\nbatch_size = 64\nv_batch_size = 64\ninput_size = (128, 128)\ninput_shape = input_size + (3, )\n\ntrain_datagen = ImageDataGenerator(rescale=1. / 255)\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=input_size,\n    batch_size=batch_size,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=input_size,\n    batch_size=v_batch_size,\n    class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### CNN model with batch normalization and dropout ###\nmodel = Sequential()\n\nmodel.add(Conv2D(16, (3, 3), input_shape=input_shape, kernel_initializer=glorot_uniform(seed=SEED)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), kernel_regularizer=l2(0.01), kernel_initializer=glorot_uniform(seed=SEED)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), kernel_regularizer=l2(0.01), kernel_initializer=glorot_uniform(seed=SEED)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(rate=0.3, seed=SEED))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, kernel_regularizer=l2(0.01), kernel_initializer=glorot_uniform(seed=SEED)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=SEED)))\n\nmodel.compile(optimizer=SGD(lr=0.01, nesterov=True),\n              loss=binary_crossentropy,\n              metrics=['accuracy'])\n\n### Details of the model ###\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Defining callbacks ###\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=3,\n    verbose=1,\n    mode='auto',\n    min_lr=0.0001)\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    verbose=1,\n    mode='auto')\nmodel_checkpoint = ModelCheckpoint(\n    filepath='weights.h5',\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    save_weights_only=True,\n    mode='auto')\n\n### Importing module for execution timing\nstart_time = timeit.default_timer()\n\n### Fitting model to the data ###\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.n // batch_size,\n    epochs=50,\n    shuffle=False,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // v_batch_size,\n    callbacks=[reduce_lr, early_stopping, model_checkpoint])\n\ncnn_training_time = timeit.default_timer() - start_time\n\nmodel.load_weights('weights.h5')\nmodel.save('pneumonia-chest-x-ray-cnn.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. CNN model - evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Accuracy and loss plots ###\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = [n + 1 for n in range(len(acc))]\nfig = plt.figure(figsize=(12, 4))\n\nfig.add_subplot(1, 2, 1)\nplt.plot(epochs, acc, 'k', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b:', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nfig.add_subplot(1, 2, 2)\nplt.plot(epochs, loss, 'k', label='Training loss')\nplt.plot(epochs, val_loss, 'b:', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Predict classes for test images ###\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=input_size,\n    shuffle=False,\n    batch_size=v_batch_size,\n    class_mode='binary')\ncnn_test_score = model.evaluate_generator(\n    test_generator,\n    steps=test_generator.n // v_batch_size)\n\nprint(\"Test set:\\n loss: %.4f, accuracy: %.4f\\nTraining time: %.0fs\" %\n      (cnn_test_score[0], cnn_test_score[1], cnn_training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Get numerical predictions for test set images ###\ntest_generator.reset()\npredictions = model.predict_generator(\n    test_generator,\n    steps=test_generator.n // v_batch_size)\n\n### True and predicted labels ###\ntrue_labels = test_generator.labels.tolist()\npred_labels = [1 if p > 0.5 else 0 for p in predictions.ravel()]\n\n### Confusion matrix ###\ntn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\nprint(\"TP: %3i   FP: %3i\\nFN: %3i   TN: %3i\\n\" % (tp, fp, fn, tn))\n\n### Classification metrics ###\nprint(\n    classification_report(\n        true_labels,\n        pred_labels,\n        target_names=['pneumonia', 'healthy']))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"### Prepare list of predictions and corresponding filenames ###\npred_with_filenames = {}\nfiles = test_generator.filenames\nfiles.sort()\nfor filename, pred in zip(files, predictions):\n    pred_with_filenames[filename.split('/')[1]] = pred[0]\n\n### Show sample test images from class 0 (pneumonia) with their predictions ###\nimagelist = listdir(test_0_dir)\nrn.shuffle(imagelist)\ntest_img_sample = [(filename, image.imread(test_0_dir + '/' + filename))\n                   for i, filename in enumerate(imagelist) if i < 10]\nrows, columns = 2, 5\nfig = plt.figure(figsize=(16, 8))\nfor index, img in enumerate(test_img_sample):\n    fig.add_subplot(rows, columns, index + 1)\n    plt.imshow(img[1], cmap=plt.cm.gray)\n    value = pred_with_filenames[img[0]]\n    label = \"pneumonia\" if value > 0.5 else \"healthy\"\n    title = \"Predicted value: %.2f\\nPredicted label: %s\" % (value, label)\n    print(title)\n    plt.title(title)\nplt.subplots_adjust(left=1, right=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Transfer learning models - training and evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Transfer learning - MobileNet(16 MB), Xception (88MB), InceptionV3 (92 MB), ResNet50 (98MB), VGG16 (528 MB) with feature extraction ###\nmodels_dict = {}\nmodel_names = [\"MobileNet\", \"Xception\", \"InceptionV3\", \"ResNet50\", \"VGG16\"]\ninput_sizes = [(224, 224), (299, 299), (299, 299), (224, 224), (224, 224)]\nfeatures_dim = [[7, 7, 1024], [10, 10, 2048], [8, 8, 2048], [7, 7, 2048],\n                [7, 7, 512]]\nmodel_list = [MobileNet, Xception, InceptionV3, ResNet50, VGG16]\nfor i, m in enumerate(model_names):\n    models_dict[m] = {}\n    models_dict[m]['object'] = model_list[i]\n    models_dict[m]['input_size'] = input_sizes[i]\n    models_dict[m]['input_shape'] = input_sizes[i] + (3, )\n    models_dict[m]['features_dim'] = features_dim[i]\n    models_dict[m]['dense_input_dim'] = functools.reduce(operator.mul, features_dim[i], 1)\n    models_dict[m]['weights_filename'] = m.lower() + '_weights.h5'\n    models_dict[m]['model_filename'] = 'pneumonia-chest-x-ray-' + m.lower() + '.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1. / 255)\nbatch_size = 64\n\nfor m, data in models_dict.items():\n    base_model = data['object'](\n        input_shape=data['input_shape'],\n        weights='imagenet',\n        include_top=False)\n\n    def extract_features(directory, sample_count):\n        shape = tuple([sample_count] + data['features_dim'])\n        features = np.zeros(shape=shape)\n        labels = np.zeros(shape=(sample_count))\n        generator = datagen.flow_from_directory(\n            directory,\n            target_size=data['input_size'],\n            batch_size=batch_size,\n            class_mode='binary')\n        i = 0\n        for inputs_batch, labels_batch in generator:\n            features_batch = base_model.predict(inputs_batch)\n            features[i * batch_size:(i + 1) * batch_size] = features_batch\n            labels[i * batch_size:(i + 1) * batch_size] = labels_batch\n            i += 1\n            if i * batch_size >= sample_count:\n                break\n        return features, labels\n\n    start_time = timeit.default_timer()\n\n    train_features, train_labels = extract_features(train_dir, n_train)\n    validation_features, validation_labels = extract_features(validation_dir, n_val)\n    test_features, test_labels = extract_features(test_dir, n_test)\n\n    feature_extraction_time = timeit.default_timer() - start_time\n    data['feature_extraction_time'] = feature_extraction_time\n\n    train_features = np.reshape(train_features, (n_train, data['dense_input_dim']))\n    validation_features = np.reshape(validation_features, (n_val, data['dense_input_dim']))\n    test_features = np.reshape(test_features, (n_test, data['dense_input_dim']))\n\n    model = Sequential()\n    model.add(Dense(512, activation='relu', input_dim=data['dense_input_dim']))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.compile(\n        optimizer=Adam(lr=0.00001),\n        loss=binary_crossentropy,\n        metrics=['accuracy'])\n\n    model_checkpoint = ModelCheckpoint(\n        filepath=data['weights_filename'],\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=True,\n        save_weights_only=True,\n        mode='auto')\n    early_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        verbose=1,\n        mode='auto')\n\n    start_time = timeit.default_timer()\n\n    history = model.fit(\n        train_features,\n        train_labels,\n        epochs=50,\n        batch_size=batch_size,\n        validation_data=(validation_features, validation_labels),\n        callbacks=[early_stopping, model_checkpoint])\n    model.load_weights(data['weights_filename'])\n    model.save(data['model_filename'])\n\n    training_time = timeit.default_timer() - start_time\n    data['training_time'] = training_time\n\n    ### Accuracy and loss plots ###\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = [n + 1 for n in range(len(acc))]\n    fig = plt.figure(figsize=(12, 4))\n\n    fig.add_subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'k', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'b:', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    fig.add_subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'k', label='Training loss')\n    plt.plot(epochs, val_loss, 'b:', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\n    ### Predict classes for test images ###\n    test_score = model.evaluate(\n        test_features, \n        test_labels,\n        steps= n_test // v_batch_size)\n\n    data['test_score'] = test_score\n    \n    ### Get numerical predictions for test set images ###\n    predictions = model.predict(\n        test_features,\n        batch_size= n_test // v_batch_size)\n\n    ### True and predicted labels ###\n    pred_labels = [1 if p > 0.5 else 0 for p in predictions.ravel()]\n\n    ### Confusion matrix ###\n    tn, fp, fn, tp = confusion_matrix(test_labels, pred_labels).ravel()\n    print(\"TP: %3i   FP: %3i\\nFN: %3i   TN: %3i\\n\" % (tp, fp, fn, tn))\n\n    ### Classification metrics ###\n    print(\n        classification_report(\n            test_labels,\n            pred_labels,\n            target_names=['pneumonia', 'healthy']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Print results of CNN and transfer learning models ###\nprint(\"Model name: Custom CNN\\n\\tTraining time: {:.0f}s\\n\\tAccuracy: {:.2%}\".format(cnn_training_time, cnn_test_score[1]))\nfor m, data in models_dict.items():\n    print(\n        \"Model name: {}\\n\\tFeature extraction time: {:.0f}s\\n\\tTraining time: {:.0f}s\\n\\tTotal computing time: {:.0f}s\\n\\tAccuracy: {:.2%}\"\n        .format(m, data['feature_extraction_time'], data['training_time'],\n                data['feature_extraction_time']+data['training_time'],\n                data['test_score'][1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Note: despite using CPU, disabling multithreading and setting seeds the results are not reproducible.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":1}