{"cells":[{"metadata":{"_cell_guid":"f50766d0-0154-4733-8894-6984b74a7dc0","_uuid":"68a5c456f183742147f9af65e2d6970f44043620","colab_type":"text","id":"0wrZwOwFzJaj"},"cell_type":"markdown","source":"* https://www.kaggle.com/sunmiyoon/one-hour-analysis-written-in-both-eng-and-kor/comments#290148 를 따라하기\n* https://www.kaggle.com/primaryobjects/voicegender\n* https://pandas.pydata.org/pandas-docs/stable/10min.html"},{"metadata":{"_cell_guid":"49eb84da-b204-43f3-8656-1144d54538e7","_uuid":"b0a268bcc6d3a6f8f407d6c2ad4a52be24aba880","colab_type":"code","id":"_7h9Hwk5zLb1","colab":{"autoexec":{"wait_interval":0,"startup":false}},"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":94,"outputs":[]},{"metadata":{"_cell_guid":"a64db608-7f60-4c5d-ba2e-16860196e5bf","_uuid":"4f2fa257df1ff346233f5e0f5afea3deee00f20c"},"cell_type":"markdown","source":"data를 읽은 후,\n1. label로부터 gender(float64)를 만들고,\n2. train set과 test set으로 나눈다."},{"metadata":{"_cell_guid":"256ae22b-de60-41ed-a7bd-d670430926a1","_uuid":"a14cc750cbb58844cecb1e4f2293da2b8035b0d9","trusted":true},"cell_type":"code","source":"_data = pd.read_csv('../input/voice.csv')\nv_data = _data.reindex(columns=list(_data.columns) + ['gender'])\n#v_data.dtypes\n_len = len(v_data)\nprint(_len)\nprint(v_data.at[3167, 'label'])\nfor i in range(_len):\n    if v_data.at[i, 'label'] == 'male':\n        v_data.at[i, 'gender'] = 1.0\n    else:\n        v_data.at[i, 'gender'] = 0.0\nprint(v_data.at[3167, 'gender'])\nv_data = v_data.drop(['label'], axis=1)\n# shuffling\nv_data = v_data.reindex(np.random.permutation(v_data.index))\nprint(len(v_data.columns), v_data.columns)\n_split = _len - 1000\ntrain = v_data[0:_split]\ntest = v_data[_split:-1]\nprint(len(train), len(test))","execution_count":150,"outputs":[]},{"metadata":{"_cell_guid":"99ee547b-e191-4758-8756-8f2dac28f5b2","_uuid":"f4417741145e29860000cd5c851dfa4c642e9896","colab_type":"text","id":"P6sokq1I65E-"},"cell_type":"markdown","source":"## Data scanning\n데이터 스캔\n\n---\n\n* 분석 전에 날것의 데이터를 그대로 스캔하는 것이 중요합니다. 어떤 변수들이 들어있고, 각자의 데이터 타입은 무엇인지, 어떤 변수는 dummy로 사용하고 어떤 변수는 numerical 로 사용 할 것인지 염두해 두면서 데이터를 스캔합니다."},{"metadata":{"_cell_guid":"ef0e75ef-8191-45e6-ab8e-f771785f5025","_uuid":"d075df6ef13486583be599dbb74624e8d224474f","colab_type":"code","id":"4XBpxxP9ztZr","colab":{"autoexec":{"wait_interval":0,"startup":false}},"trusted":true},"cell_type":"code","source":"print(train.tail(2))\n# print(test.head(2))\n# print(v_data.tail(2))\n# print(test.tail(2))\n# v_data.size\n# v_data.columns","execution_count":101,"outputs":[]},{"metadata":{"_cell_guid":"7be176c8-471b-46d4-aaef-030d7569d25d","_uuid":"95341723f2d0e38ea18e66f4d27118e77b117cba"},"cell_type":"markdown","source":"## Summary Statistics\n요약 통계\n\n---"},{"metadata":{"_cell_guid":"e9300836-ebaf-49cf-873e-0c2d71cc7a6d","_uuid":"14d6ca40f823bfb83f4d4e011069c823a6671164","colab_type":"code","id":"18fvZkSp1UbX","colab":{"autoexec":{"wait_interval":0,"startup":false}},"trusted":true},"cell_type":"code","source":"print(train.describe())","execution_count":102,"outputs":[]},{"metadata":{"_cell_guid":"95cab832-ffd0-43b3-946b-a5984f3cf12a","_uuid":"3627566cb1386630ef6cd77526174643ca118b04","colab_type":"text","id":"2zxcCwDKz11G"},"cell_type":"markdown","source":"### Correlation matrix\n* First I see the correlation matrix to see the rough relationships between features(variables). If there is strong relationship between independent variables (Xs on the right side), we could not trust the coefficient of them. It could be under-estimated or over-estimated than a real effect to dependent variable(Y on the left side).  \n* 첫번째로, 상관관계 테이블을 이용하여 변수들간의 상관관계를 살펴봅니다. 만약 독립변수(Xs)들 간에 상관관계가 높다면 회귀분석의 결과(coefficient)를 신뢰하기가 힘들어 집니다. 예를 들면, A라는 변수와 B라는 두 독립변수의 상관관계가 매우 높다면 A의 계수를 온전히 A가 Y에 미치는 영향이라고 해석하기 어렵습니다. "},{"metadata":{"_uuid":"474bc4e0eede770876b15cd20c96fcedd8c3c308","colab":{"autoexec":{"wait_interval":0,"startup":false}},"_cell_guid":"e05d3c96-eacc-4724-96f0-679c048df5af","colab_type":"code","id":"fX8eMTmkz0o1","scrolled":true,"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nf, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(train.corr(), vmax=.8, square=True);","execution_count":103,"outputs":[]},{"metadata":{"_cell_guid":"cfe1abbe-a359-4673-9745-8b62735f6c7e","_uuid":"e5112a1c5ffe4845b17973bbcd447e143c8783bc","colab_type":"text","id":"xfsgVR26077-"},"cell_type":"markdown","source":"* 두 변수의 상관관계가 높은 것이 히트맵에서는 하얀 칸으로 표시됩니다. 상관관계가 매우 높은 페어는 다음과 같습니다.\n * meanfreq - median\n * meanfreq - Q25\n * meanfreq - Q75\n * meanfreq - mode\n * meanfreq - centroid\n * sd - IQR\n * sd - sfm\n * median - Q25\n * median - Q75\n * median - mode\n * median - centroid\n * centroid - median\n * Q25 - centroid\n * Q75 - centroid\n * skew - kurt\n * sp.ent - sfm\n * mode - centroid\n * meandom - maxdom\n * meandom - dfrange\n * maxdom - dfrange\n \n 각 페어 당 label과 상관관계가 더 높은 변수 하나만 포함시킵니다.\n* 특정 변수가 Y에 미치는 영향을 정확하게 설명하고 싶다면 이 과정이 필수적입니다. 하지만 단지 Y를 잘 예측하는 것이 모델의 목적이라면 굳이 이 단계에서 변수를 제거 할 필요는 없습니다."},{"metadata":{"_uuid":"cfda6a4e6408ac52cc0aa1ff2c715cdda99f9e3c","colab":{"autoexec":{"wait_interval":0,"startup":false},"output_extras":[{},{},{},{},{},{},{},{},{},{}],"height":1975,"base_uri":"https://localhost:8080/"},"executionInfo":{"timestamp":1517630686399,"user_tz":-540,"status":"ok","elapsed":29826,"user":{"displayName":"SuParX -K","userId":"111511142349300350880","photoUrl":"//lh4.googleusercontent.com/-8ofbni1a6NY/AAAAAAAAAAI/AAAAAAAAANg/5S0y1RLk-Pc/s50-c-k-no/photo.jpg"}},"_cell_guid":"6f077b16-e8da-4bb2-b514-2e9369732e1c","collapsed":true,"outputId":"b2b57784-d018-4f2d-ea89-9fcd9dac79df","colab_type":"code","id":"idRo15m40w-M","trusted":true},"cell_type":"code","source":"def strongerRelationSalePrice(f1, f2):\n    f1Corr = train.corr().loc[f1,'gender']\n    f2Corr = train.corr().loc[f2,'gender']\n#     print(f1Corr, f2Corr)\n    return (f1, f2) if (f1Corr >= f2Corr) else (f2, f1)\n\ndef print_stronger(f1, f2):\n    print('{} > {}'.format(strongerRelationSalePrice(f1, f2)[0], strongerRelationSalePrice(f1, f2)[1]))","execution_count":104,"outputs":[]},{"metadata":{"_cell_guid":"453c5862-eca0-45c7-a56e-a8e181cae608","_uuid":"a80f3a6258a1c257c7787d7c6d93299b296d70be","trusted":true},"cell_type":"code","source":"print_stronger('meanfreq', 'median')\nprint_stronger('meanfreq', 'Q25')\nprint_stronger('meanfreq', 'Q75')\nprint_stronger('meanfreq', 'mode')\nprint_stronger('meanfreq', 'centroid')\nprint_stronger('sd', 'IQR')\nprint_stronger('sd', 'sfm')\nprint_stronger('median', 'Q25')\nprint_stronger('median', 'Q75')\nprint_stronger('median', 'mode')\nprint_stronger('median', 'centroid')\nprint_stronger('Q25', 'centroid')\nprint_stronger('Q75', 'centroid')\nprint_stronger('skew', 'kurt')\nprint_stronger('sp.ent', 'sfm')\nprint_stronger('mode', 'centroid')\nprint_stronger('meandom', 'maxdom')\nprint_stronger('meandom', 'dfrange')\nprint_stronger('maxdom', 'dfrange')\nprint_stronger('mode', 'Q75')","execution_count":51,"outputs":[]},{"metadata":{"_cell_guid":"19dabc3e-dd84-4b1e-8369-55ef57d3bd27","_uuid":"5b8aad1c7efe751c3666770a1e2434dd97d8df57"},"cell_type":"markdown","source":"* Q75 > mode > meanfreq > centroid > median > Q25\n* IQR > sd > sfm\n* kurt > skew\n* sp.ent > sfm\n* meandom > dfrange > maxdom"},{"metadata":{"_cell_guid":"417dbcc7-9721-4a15-8f26-61d8b9ca300f","_uuid":"0d6101e142e1a96488b2d5b8ce3438f54ba89f5a","trusted":true},"cell_type":"code","source":"train = train.drop(['mode', 'meanfreq', 'centroid', 'median', 'Q25', 'sd', 'sfm', 'skew', 'sfm', 'dfrange', 'maxdom'], axis=1)\ntest = test.drop(['mode', 'meanfreq', 'centroid', 'median', 'Q25', 'sd', 'sfm', 'skew', 'sfm', 'dfrange', 'maxdom'], axis=1)\nprint(len(train.columns), train.columns)","execution_count":105,"outputs":[]},{"metadata":{"_cell_guid":"77462fb0-a7f8-41dc-8d69-8b2d40fcfd07","_uuid":"0afa0cbe4ec6707b7c436ead769b46b2da9869ff","trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(train.corr(), vmax=.8, square=True)","execution_count":106,"outputs":[]},{"metadata":{"_cell_guid":"08c89dd2-0267-4836-a138-82d39eab6fa8","_uuid":"a218a31cff76d30a9a19fc0fd5161b6de8d1bfc1","colab_type":"text","id":"CGKGHrIF3Yt3"},"cell_type":"markdown","source":"## Histogram and Scatter chart\n히스토그램과 스캐터 차트\n\n---"},{"metadata":{"_cell_guid":"8e307aac-2b5d-4f86-97b8-60a115de2142","_uuid":"2eb0cf38a90f812a085b86c79deaa2401ab0cbba"},"cell_type":"markdown","source":"* 먼저, 가장 중요한 gender 데이터를 확인 해 봐야 합니다. gender에 음수는 없는지, 말도 안되게 큰 값은 없는지 체크하면서 데이터가 과연 활용할만한 데이터인지 살펴봐야 합니다. 물론 캐글은 깨끗한 데이터를 제공하니 이런 문제가 많지 않지만, 웹 크롤링을 얻은 데이터나 실생활 또는 업무에서 만날 수 있는 데이터들은 이처럼 깨끗하지 않습니다. 아웃라이어를 처리하는 방법에는 winsorization, truncation 등이 있습니다. "},{"metadata":{"_cell_guid":"50902e7c-dff7-42f2-9259-88de57a69266","_uuid":"30b4f644aab948aa4877dbb9d15457da157cd2f1","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# I think this graph is more elegant than pandas.hist()\n# train['SalePrice'].hist(bins=100)\nsns.distplot(train['gender'])","execution_count":107,"outputs":[]},{"metadata":{"_cell_guid":"41e0c0b9-9bb5-4302-9d42-5e0f07e42745","_uuid":"e6672e88fd8d8f81b693d00dc8cffb83b0cd51c5"},"cell_type":"markdown","source":"### Scatter chart\n산점도, 스캐터 차트\n* Y축은 모두 gender이고, 독립변수를 X축에 맞춰 모든 변수에 대해 산점도를 그렸습니다. 데이터 시각화는 보기에 멋있어 보이기 위해 하는 것만은 아닙니다. 이렇게 모든 독립변수들에 대해 산점도를 뿌리면 어떤 변수가 특히 종속변수과 연관이 있는지, 다시 말하면 얼마나 종속변수를 설명해 주는지 한 눈에 볼 수 있습니다. 예를 들어, OverallQual과 SalePrice가 양의 관계를 보이며 산점도가 우상향하는 형태를 보이는 것을 확인 할 수 있습니다. 데이터가 수평에 가깝게 뿌려져 있다면 그 변수는 gender 와 낮은 관계를 가진다고 해석할 수도 있습니다. 하지만 이 데이터셋의 경우에는 변수의 갯수도 많고, 변수들간 관계가 복잡하기 때문에 회귀분석을 하기 이전에 성급하게 결론을 내려서는 안 됩니다."},{"metadata":{"_cell_guid":"58ae8e5f-65b7-4373-b8de-073872e0075b","_uuid":"e587d5b63b057f112856dc62914356908ace7f2d","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 6, figsize=(15, 7), sharey=True)\nfor col, a in zip(train.columns, axes.flatten()):\n    if col == 'gender':   \n        a.set_title(col)\n        a.scatter(df['gender'], df['gender'])\n    else:\n        df = train[['gender', col]].dropna()\n        a.set_title(col)\n        a.scatter(df[col], df['gender'])","execution_count":108,"outputs":[]},{"metadata":{"_cell_guid":"9c609489-677c-4b5c-b04b-61fc1b2d865d","_uuid":"31a677951867135feebabe0ab6d06a298c5fe278"},"cell_type":"markdown","source":"* 이 data를 lab5-ex.ipynb에 적용해보자."},{"metadata":{"_cell_guid":"e0838e42-3c6e-4e9d-a33b-99e123d5554a","_uuid":"47f6ee865812fba380d77e0e28fbc7399f48f3c8","trusted":true},"cell_type":"code","source":"# Lab 5 Logistic Regression Classifier\nimport tensorflow as tf\nimport numpy as np\ntf.set_random_seed(743)  # for reproducibility\n\n# collect data\nx_data = train.loc[:,['Q75','IQR','kurt','sp.ent']].values\ny_data = train.loc[:,['gender']].values","execution_count":109,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50d5e7710be110d63824a7ae0e8a9f103b53b1b9"},"cell_type":"code","source":"print(x_data[0],y_data[0])\n#len(x_data)\ntype(x_data)\n#y_data","execution_count":132,"outputs":[]},{"metadata":{"_cell_guid":"3b35b8ee-d93a-4f26-8125-4ae8c93f3ce6","_uuid":"0a3c66a5f34558c94ed81cb6e2dd71278f57b79e"},"cell_type":"markdown","source":"* build a model"},{"metadata":{"_cell_guid":"96d082be-032d-4ef8-b1cb-b553e699d3db","collapsed":true,"_uuid":"aa7e4f464089d88df78b12b64af67fae69409fa5","trusted":true},"cell_type":"code","source":"X = tf.placeholder(tf.float32, shape=[None, 4])\nY = tf.placeholder(tf.float32, shape=[None, 1])\nW = tf.Variable(tf.random_normal([4, 1]), name='weight')\nb = tf.Variable(tf.random_normal([1]), name='bias')\n\n# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\nhypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n\ncost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n\npredicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))","execution_count":146,"outputs":[]},{"metadata":{"_cell_guid":"efefee66-788a-46df-bb7d-7467a8faa6c3","_uuid":"6250915f0410f05b9b16796f3d7798610346609d"},"cell_type":"markdown","source":"* train a model"},{"metadata":{"_cell_guid":"9f74f332-1adb-4d73-affe-b8b1d0ae4ea9","_uuid":"e0642813daea30a7ac87f3ec8c6b4306ab2357cc","trusted":true},"cell_type":"code","source":"sess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\nfor step in range(2000):\n    cost_val, _ = sess.run([cost, optimizer], feed_dict={X: x_data, Y: y_data})\n    if step % 10 == 0:\n        print(step, cost_val)\n\nx_test = test.loc[:,['Q75','IQR','kurt','sp.ent']].values\ny_test = test.loc[:,['gender']].values\nh, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_test, Y: y_test})\nprint(\"Accuracy: \", a)\nprint(c[0:8], y_test[0:8])","execution_count":147,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"version":"0.3.2","views":{},"provenance":[],"name":"SPX_lab4_softmax_cost_graph.ipynb","default_view":{},"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}