{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Health insurance cost prediction"},{"metadata":{},"cell_type":"markdown","source":"![Insurance cost](https://www.getinsuredonline.com/wp-content/uploads/2020/08/the-importance-of-having-health-insurance.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Build different 5 models on insurance data :\n"},{"metadata":{},"cell_type":"markdown","source":"### * 1- linear regression \n### * 2-linear regression -after removing the outliers- \n### * 3-Ensemble - bagging-\n### * 4-Lofistic regression \n### * 5-logistic regression -after removing the outliers- "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/insurance/insurance.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### No null values found in the dataset!"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(9,5))\nsns.heatmap(df.isnull(), cbar=False, cmap=\"YlGnBu_r\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From graph we can make sure there are no null values !"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract unique values of region attribute so later we can conert to numeric and use it in the model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.region.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.describe()\ndf.describe().transpose() #for more organization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['age'].median())\nprint(df['bmi'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=df.corr()\nc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check duplicates rows then drop them !"},{"metadata":{"trusted":true},"cell_type":"code","source":"if len(df[df.duplicated()]) > 0:\n    print(\"No. of duplicated entries: \", len(df[df.duplicated()]))\n    print(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)).head())\nelse:\n    print(\"No duplicated entries found\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.index[581], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot to discover outliers!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.boxplot(data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Frome graph we can notice thet there is some outliers in charges attributes ! , However we will see accuracy with and without removing outliers to if see our models are roubust to them and give a good accuracy? or not ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\n((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert sex to 1 for female and 0 male:\n\ndf.sex.loc[df['sex']=='female']=1\ndf.sex.loc[df['sex']=='male']=0\n\n#convert smoker to 1 for yes and 0 for no :\ndf.smoker.loc[df['smoker']=='yes']=1\ndf.smoker.loc[df['smoker']=='no']=0\n\n#convert region to numeric :\nregions={'region':{'southwest':1, 'southeast':2, 'northwest':3, 'northeast':4}}\ndf.replace(regions,inplace=True)\ndf.head()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('CleanedInsurance.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(c[\"charges\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.2]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### From above and correaltopn tabe we can see that there is no strong corelations on the data , However there are many cases where  variables might not show a strong bivariate correlation but may show a strong association in regression , so lets build our model and see the accuracy!"},{"metadata":{},"cell_type":"markdown","source":"## visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(c, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Female', 'Male']\nsize = df['sex'].value_counts()\ncolors = ['red', 'blue']\nexplode = [0, 0.1]\n\nplt.rcParams['figure.figsize'] = (5, 5)\nplt.pie(size, colors = colors, explode = explode, labels = labels, shadow = True, autopct = '%.2f%%')\nplt.title('sex', fontsize = 20)\nplt.axis('off')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15, 8)\nsns.countplot(df['age'], palette = 'hsv')\nplt.title('Distribution of Age', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"smoker\", kind=\"count\",hue = 'sex', palette=\"cool\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"children\", kind=\"count\", palette=\"pink\", data=df, size = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)\nplt.title('Pairplot for the Data', fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"bmi\", y=\"charges\", data=df, palette='Set2', hue='sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['charges'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['bmi'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"feature_cols = ['age', 'bmi','children']\n# multiple scatter plots, note that we're not including 'sex' and 'smoker', why? because it is catogoricalÿ©\nsns.pairplot(df, x_vars=feature_cols, y_vars='charges', kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter plot to seeif there is a dependency between attributes smoker and charges accross different ages\nplt.figure(figsize=(8,6))\nsns.scatterplot(df.age, df.charges,hue=df.smoker,palette= ['red','green'] ,alpha=0.6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter plot to see if there is a dependency between attributes sex and charges accross different ages\nplt.figure(figsize=(8,6))\nplt.figure(figsize=(8,6))\nsns.scatterplot(df.age, df.charges,hue=df.sex,palette= ['blue','red'] )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter plot to see if there is a dependency between attributes sex and charges accross different ages\nplt.figure(figsize=(8,6))\nplt.figure(figsize=(8,6))\nsns.scatterplot(df.bmi, df.charges,hue=df.sex,palette= 'Set2' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.title('Relation between children and Charges')\n#sns.regplot(x=df['children'],y=df['charges'])\nsns.barplot(x=df['children'], y=df['charges'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"charges = df['charges'].groupby(df.region).sum().sort_values(ascending = True)\nf, ax = plt.subplots(1, 1, figsize=(8, 6))\nax = sns.barplot(charges.head(), charges.head().index, palette='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(12, 8))\nax = sns.barplot(x='region', y='charges', hue='sex', data=df, palette='cool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.lmplot(x = 'age', y = 'charges', data=df, hue='smoker', palette='Set1')\nax = sns.lmplot(x = 'bmi', y = 'charges', data=df, hue='smoker', palette='Set2')\nax = sns.lmplot(x = 'children', y = 'charges', data=df, hue='smoker', palette='Set3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['charges'].min())\nprint(df['charges'].max())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['charges_bins'] = pd.cut(df['charges'], bins=[0, 1300, 26000, 39000, 52000, 65000])\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a countplot based on the amount of charges\nplt.figure(figsize=(12,4))\nsns.countplot(x='charges_bins', data=df, palette='husl') \nplt.title('Number of people paying x amount\\n for each charges category', size='23')\nplt.xticks(rotation='25')\nplt.ylabel('Count',size=18)\nplt.xlabel('Charges',size=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Start Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1- build model without removing outliers!"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['age','sex','bmi','children','smoker','region'] # a lsit of the predictors\nX1 = df[feature_cols] # subsetting our data to only the predictors\ny1 = df['charges'] # our response variable\n#X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1)\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1,train_size=0.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Pick a new random training and test set\n\nlinreg = LinearRegression()\nlinreg.fit(X_train1, y_train1)\ny_pred = linreg.predict(X_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pair the feature names with the coefficients\nzip(feature_cols, linreg.coef_)\nprint(feature_cols)\nprint(linreg.intercept_)\nprint(linreg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score it on our test set to get a better sense of out of sample performance\nlinreg.score(X_test1, y_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linreg.score(X_train1, y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint('MAE:', metrics.mean_absolute_error(y_test1, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test1, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test1, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff = y_test1 - y_pred\ndiff.hist(bins = 40)\nplt.title('Histogram of prediction errors')\nplt.xlabel('cost prediction error')\nplt.ylabel('Frequency')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"                fig = px.scatter(x=y_test1, y=y_pred, labels={'x': 'ground truth', 'y': 'prediction'})\n                fig.add_shape(\n                    type=\"line\", line=dict(dash='dash'),\n                    x0=y1.min(), y0=y1.min(),\n                    x1=y1.max(), y1=y1.max()\n                )\n                fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Bundling our previous work into a function ###\ndef learning_curves(estimator, data, features, target, train_sizes, cv):\n    train_sizes, train_scores, validation_scores = learning_curve(\n    estimator, data[features], data[target], train_sizes =\n    train_sizes,\n    cv = cv, scoring = 'neg_mean_squared_error')\n    train_scores_mean = -train_scores.mean(axis = 1)\n    validation_scores_mean = -validation_scores.mean(axis = 1)\n\n    plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    title = 'Learning curves for a ' + str(estimator).split('(')[0] + ' model'\n    plt.title(title, fontsize = 18, y = 1.03)\n    plt.legend()\n\n### Plotting the two learning curves ###\n\nfrom sklearn.ensemble import RandomForestRegressor\ntrain_sizes = [1, 100, 500, 800, 900, 1000]\nfeatures = ['age','sex','bmi','children','smoker','region']\ntarget = ['charges']\nplt.figure(figsize = (16,5))\n\nfor model, i in [(DecisionTreeRegressor(), 1), (LinearRegression(),2)]:\n    plt.subplot(1,2,i)\n    learning_curves(model, df, features, target, train_sizes, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### using null model "},{"metadata":{"trusted":true},"cell_type":"code","source":"average_charges = df['charges'].mean()\naverage_charges","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_rows = df.shape[0]\nnum_rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_model_predictions = [average_charges]*num_rows\nnull_model_predictions","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y1, null_model_predictions))\nprint('MSE:', metrics.mean_squared_error(y1, null_model_predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y1, null_model_predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we are beating the null model "},{"metadata":{},"cell_type":"markdown","source":"### Train data using ensemble (bagging) and see its performance !\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingRegressor\n#from sklearn import tree\n#model = BaggingRegressor(tree.DecisionTreeRegressor(random_state=1))\n#model.fit(X_train1, y_train1)\n#model.score(X_test1,y_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn import model_selection\n# from sklearn.ensemble import BaggingClassifier\n# from sklearn.tree import DecisionTreeClassifier\n\n# seed = 7\n# kfold = model_selection.KFold(n_splits=10, random_state=seed)\n# cart = DecisionTreeClassifier()\n# num_trees = 100\n# model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n# results = model_selection.cross_val_score(model, X1, y1, cv=kfold)\n# print(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nestimators = list(range(1, 20))\naccuracyTest = []\naacuracyTrain=[]\nfor n_estimators in estimators:\n    clf = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n                            max_samples=0.2,\n                            n_estimators=n_estimators).fit(X_train1, y_train1)\n    acc = clf.score(X_test1, y_test1)\n    accuracyTest.append(acc)\n    acc1 = clf.score(X_train1, y_train1)\n    aacuracyTrain.append(acc1)\n    fig = px.scatter(x=y_test1, y=clf.predict(X_test1), labels={'x': 'ground truth', 'y': 'prediction'})\n    fig.add_shape(\n    type=\"line\", line=dict(dash='dash'),\n    x0=y1.min(), y0=y1.min(),\n    x1=y1.max(), y1=y1.max()\n    )\n    fig.show()\n\nplt.plot(estimators, accuracyTest)\nplt.xlabel(\"Number of estimators\")\nplt.ylabel(\"Accuracy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracyTest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(accuracyTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(accuracyTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(aacuracyTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf1 = BaggingRegressor(base_estimator=DecisionTreeRegressor(),\n#                             n_estimators=10,\n#                             bootstrap=False,\n#                             bootstrap_features=False,\n#                             random_state=5).fit(X_train1, y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf1.estimators_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train data with linear regression again BUT after removing outliers to see their affect in the model !"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\n((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q1 = df['charges'].quantile(0.25)\nq3=df['charges'].quantile(0.75)\niqr = q3 - q1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"charges = df[df['charges']< (q1 - 1.5 * iqr)]\ncharges = df[df['charges']> (q3 + 1.5 * iqr)]\ncharges.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfWithoutOutlier = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\ndfWithoutOutlier.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfWithoutOutlier.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfWithoutOutlier.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['age','sex','bmi','children','smoker','region'] # a lsit of the predictors\nX2 = dfWithoutOutlier[feature_cols] # subsetting our data to only the predictors\ny2 = dfWithoutOutlier['charges'] # our response variable\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X1, y1)\n# Pick a new random training and test set\n\nlinreg = LinearRegression()\nlinreg.fit(X_train2, y_train2)\ny_pred = linreg.predict(X_test2)\n# score it on our test set to get a better sense of out of sample performance\nlinreg.score(X_test2, y_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linreg.score(X_train2, y_train2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The accuracy very bad as a random model !! which indicates that the outliers must not remove and they are significant "},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regrssion :"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean=df['charges'].mean()\n# median=df['charges'].median()\n# print(median)\n# #we will consider any value higher than mean as expensive (1) otherwise normal price(0).\n\ndf2=df\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I chose the threshold based on some articles and resourcese that reference the avg cost of the insurance in US is 9596"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.loc[df['charges'] <= 9596, 'charges'] = 0 #on or under avarage\ndf2.loc[df['charges'] > 9596, 'charges'] = 1 # above avarage\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3=dfWithoutOutlier\ndf3.loc[df3['charges'] <= 9596, 'charges'] = 0 #on or under avarage\ndf3.loc[df3['charges'] > 9596, 'charges'] = 1 # above avarage\ndf3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(['charges']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"charges\", kind=\"count\", palette=\"cool\", data=df3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"charges\", kind=\"count\", palette=\"cool\", data=df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['age','sex','bmi','children','smoker','region'] # a lsit of the predictors\nX = df2[feature_cols] # subsetting our data to only the predictors\ny = df2['charges'] # our response variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split data to train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nprint (X_train.shape,X_test.shape,y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n# instantate our model\nlogreg = LogisticRegression()\n# fit our model to our training set\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score it on our test set to get a better sense of out of sample performance\nlogreg.score(X_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pair the feature names with the coefficients\nzip(feature_cols, logreg.coef_)\nprint(feature_cols)\nprint(logreg.intercept_)\nprint(logreg.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Witout outliers !"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['age','sex','bmi','children','smoker','region'] # a lsit of the predictors\nX4 = df3[feature_cols] # subsetting our data to only the predictors\ny4 = df3['charges'] # our response variable\n#split data to train and test\nX_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4)\n# instantate our model\nlogreg = LogisticRegression()\n# fit our model to our training set\nlogreg.fit(X_train4, y_train4)\nlogreg.score(X_test4, y_test4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nLR_prediction = logreg.predict(X_test)\nconfusion_matrix = confusion_matrix(y_test.tolist(), LR_prediction.tolist())\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names=[1,0] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\n\nsns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\n\nplt.tight_layout()\nplt.figure(figsize=(5,2))\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error = pd.DataFrame({'Actual': y_test, 'Predicted': LR_prediction})\nerror.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n# Compute error between our test predictions and the actual values.\nmean_squared_error(LR_prediction, y_test.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# generate class probabilities\nprobs = logreg.predict_proba(X_test)\nprint (probs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}