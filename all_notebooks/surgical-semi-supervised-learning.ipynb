{"cells":[{"metadata":{},"cell_type":"markdown","source":"<pre style=\"border: 1px dashed;\">\n<div style=\"margin-left: 35%;\">\n     _____\n    [IIIII]\n     )\"\"\"(\n    /     \\\n   /       \\\n   |`-...-'|\n   |asprin |\n _ |`-...-'j    _\n(\\)`-.___.(I) _(/)\n  (I)  (/)(I)(\\)\n     (I)        \n\n<b>Surgical</b>\n      Semi-Supervised Learning\n</div>\n</pre>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"dataset\" style=\"color:black; background:white; border:0.5px dotted;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/surgical-dataset-binary-classification/Surgical-deepnet.csv'\ndf = pd.read_csv(path)\ndf = shuffle(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate indices for splits\n\ntest_ind = round(len(df)*0.25)\ntrain_ind = test_ind + round(len(df)*0.01)\nunlabeled_ind = train_ind + round(len(df)*0.74)\n\n\n# Partition the data\n\ntest = df.iloc[:test_ind]\ntrain = df.iloc[test_ind:train_ind]\nunlabeled = df.iloc[train_ind:unlabeled_ind]\n\n\n# Assign data to train, test, and unlabeled sets\n\nX_train = train.drop('complication', axis=1)\ny_train = train.complication\n\nX_unlabeled = unlabeled.drop('complication', axis=1)\n\nX_test = test.drop('complication', axis=1)\ny_test = test.complication\n\n\n# Check dimensions of data after splitting\n\nprint(f\"X_train dimensions: {X_train.shape}\")\nprint(f\"y_train dimensions: {y_train.shape}\\n\")\n\nprint(f\"X_test dimensions: {X_test.shape}\")\nprint(f\"y_test dimensions: {y_test.shape}\\n\")\n\nprint(f\"X_unlabeled dimensions: {X_unlabeled.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"distribution\" style=\"color:black; background:white; border:0.5px dotted;\"> \n    <center>Distribution\n        <a class=\"anchor-link\" href=\"#distribution\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts().plot(kind='bar')\nplt.xticks([0,1], ['No Complication', 'Complication'])\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"supervised\" style=\"color:black; background:white; border:0.5px dotted;\"> \n    <center>Supervised Learning\n        <a class=\"anchor-link\" href=\"#supervised\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{},"cell_type":"markdown","source":"Use the logistic regression classifier to predict on the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(max_iter=1000)\n\nclf.fit(X_train, y_train)\ny_hat_test = clf.predict(X_test)\ny_hat_train = clf.predict(X_train)\n\ntrain_f1 = f1_score(y_train, y_hat_train)\ntest_f1 = f1_score(y_test, y_hat_test)\n\nprint(f\"Train f1 Score: {train_f1}\")\nprint(f\"Test f1 Score: {test_f1}\")\n\nplot_confusion_matrix(clf, X_test, y_test, cmap='Blues', normalize='true', display_labels=['No Comp.', 'Complication']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"semisupervised\" style=\"color:black; background:white; border:0.5px dotted;\"> \n    <center>Semi-Supervised Learning\n        <a class=\"anchor-link\" href=\"#semisupervised\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{},"cell_type":"markdown","source":"<b>Pseudocode</b>:<br>\n1. Train Logistic Regression classifer on the labeled trainning data.\n2. Use the classifer to predict labels for all unlabeled data.\n3. Concatenante the pseudo-labeled data with the labeled training data.\n4. Use trained classifer to make predictions for the labeled test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initiate iteration counter\niterations = 0\n\n# Containers to hold f1_scores and # of pseudo-labels\ntrain_f1s = []\ntest_f1s = []\npseudo_labels = []\n\n# Assign value to initiate while loop\nhigh_prob = [1] \n\n# Loop will run until there are no more high-probability pseudo-labels\nwhile len(high_prob) > 0:\n        \n    # Fit classifier and make train/test predictions\n    clf = LogisticRegression(max_iter=1000)\n    clf.fit(X_train, y_train)\n    y_hat_train = clf.predict(X_train)\n    y_hat_test = clf.predict(X_test)\n\n    # Calculate and print iteration # and f1 scores, and store f1 scores\n    train_f1 = f1_score(y_train, y_hat_train)\n    test_f1 = f1_score(y_test, y_hat_test)\n    print(f\"Iteration {iterations}\")\n    print(f\"Train f1: {train_f1}\")\n    print(f\"Test f1: {test_f1}\")\n    train_f1s.append(train_f1)\n    test_f1s.append(test_f1)\n   \n    # Generate predictions and probabilities for unlabeled data\n    print(f\"Now predicting labels for unlabeled data...\")\n\n    pred_probs = clf.predict_proba(X_unlabeled)\n    preds = clf.predict(X_unlabeled)\n    prob_0 = pred_probs[:,0]\n    prob_1 = pred_probs[:,1]\n\n    # Store predictions and probabilities in dataframe\n    df_pred_prob = pd.DataFrame([])\n    df_pred_prob['preds'] = preds\n    df_pred_prob['prob_0'] = prob_0\n    df_pred_prob['prob_1'] = prob_1\n    df_pred_prob.index = X_unlabeled.index\n    \n    # Separate predictions with > 99% probability\n    high_prob = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > 0.99],\n                           df_pred_prob.loc[df_pred_prob['prob_1'] > 0.99]],\n                          axis=0)\n    \n    print(f\"{len(high_prob)} high-probability predictions added to training data.\")\n    \n    pseudo_labels.append(len(high_prob))\n\n    # Add pseudo-labeled data to training data\n    X_train = pd.concat([X_train, X_unlabeled.loc[high_prob.index]], axis=0)\n    y_train = pd.concat([y_train, high_prob.preds])      \n    \n    # Drop pseudo-labeled instances from unlabeled data\n    X_unlabeled = X_unlabeled.drop(index=high_prob.index)\n    print(f\"{len(X_unlabeled)} unlabeled instances remaining.\\n\")\n    \n    # Update iteration counter\n    iterations += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"analysis\" style=\"color:black; background:white; border:0.5px dotted;\"> \n    <center>Analysis\n        <a class=\"anchor-link\" href=\"#analysis\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(6,8))\nax1.plot(range(iterations), test_f1s)\nax1.set_ylabel('f1 Score')\nax2.bar(x=range(iterations), height=pseudo_labels)\nax2.set_ylabel('Pseudo-Labels Created')\nax2.set_xlabel('# Iterations');\n\nplot_confusion_matrix(clf, X_test, y_test, cmap='Blues', normalize='true',\n                     display_labels=['No Comp.', 'Complication']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"reference\" style=\"color:black; background:white; border:0.5px dotted;\"> \n    <center>Reference\n        <a class=\"anchor-link\" href=\"#reference\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{},"cell_type":"markdown","source":"Doug Steen - [Medium](https://towardsdatascience.com/a-gentle-introduction-to-self-training-and-semi-supervised-learning-ceee73178b38)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}