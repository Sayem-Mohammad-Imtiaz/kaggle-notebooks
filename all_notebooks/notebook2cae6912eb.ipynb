{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA Case Study","metadata":{}},{"cell_type":"markdown","source":"<b> Authors: Kanishk Mehta, Adnan Ahmed\n    </b>\n","metadata":{}},{"cell_type":"markdown","source":"**Email ID's**: kanishkmehta1995@gmail.com , adnanahmed348@gmail.com","metadata":{}},{"cell_type":"markdown","source":"The aim of this group case study is to apply EDA in a real business scenario. Besides an understanding of EDA, we shall also develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers.","metadata":{}},{"cell_type":"markdown","source":"## Problem Statement Synthesis","metadata":{}},{"cell_type":"markdown","source":"It is hard for the company to give loans to people with no credit history. We work in a consumer finance company which specializes in lending various types of loans to urban customers. We have to analyze patterns in the data. This will ensure that the applicants are capable of repaying the loan are not rejected.\n\nWhen a loan application is recieved, there are two main risks associated with the bank's decision:\n\n","metadata":{}},{"cell_type":"markdown","source":"<p> 1. If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company </p>\n2. If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company","metadata":{}},{"cell_type":"markdown","source":"The two scenarios that we are are concerned with are:\n<br>1. The client with payment difficulties</br>\n<br>2. Paid on Time (named \"All other cases\")</br>\n","metadata":{}},{"cell_type":"markdown","source":"<br>The four decisions that can be taken by client/ company comprise of the below selection:</br>\n    <br><b>Approved:</b> The company has approved the loan application\n    <br><b>Cancelled:</b> The client cancelled the loan application sometime during the approval. (Bad pricing or changed their mind)\n    <br><b>Refused:</b> The company has refused the loan application\n    <br><b>Unused Offer:</b> Loan has been cancelled by the client, but on different stage of progress","metadata":{}},{"cell_type":"markdown","source":"### Business Objectives\n\nThis case study aims to identify patterns which indicate if a client has difficulty paying their instalments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc. This will ensure that the consumers capable of repaying the loan are not rejected. Identification of such applicants using EDA is the aim of this case study.","metadata":{}},{"cell_type":"markdown","source":"### Datasets\n\n<b>application_data.csv:</b> Contains all the information of the client at the time of application.The data is about whether a client has payment difficulties\n<b>previous_application.csv:</b> Contains information about the clientâ€™s previous loan data. It contains the data whether the previous application had been Approved, Cancelled, Refused or Unused offer<br>\n<b>columns_description.csv:</b> Data dictionary which describes the meaning of the variables","metadata":{}},{"cell_type":"markdown","source":"### Results expected:\nAnalysis in the form of a presentation<br>\nMissing Value Check (with explanation)<br>\nOutlier Check (with explanation)<br>\nChecking data Imbalance (Imabalance Ratio)<br>\nExplain the results of univariate, segmented univariate and bivariate analysis<br>\nFind top 10 correlations for Client with payment difficulties and all other cases<br>\nInclude visualizations (Insights should explain why the variable is important for differentiating the clients with payment difficulties with all other cases)","metadata":{}},{"cell_type":"markdown","source":"### Evalutation Rubrics:\nIdentify and report the data quality issues (20%)<br>\nInterpret variables correctly where required, mention them in the comments or text (20%)<br>\nAddress data-quality issues appropriately (10%)<br>\nData is in the right format (10%)<br>\nString and date manipulation is done correctly (10%)<br>\nThe right problem is solved (50%)<br>\nUnivariate and Segmented Univariate analysis is done correctly (Identify 5 important driver variables) (50%)<br>\nBusiness-driven, type-driven and data-driven metrics are created for the important variables and utilised for analysis (50%)<br>\nBivariate analysis is performed correctly and is able to identify the important combinations of driver variables (50%)<br>\nThe most useful insights are explained correctly in the comments (50%)<br>\nThe axes and important data points are labelled correctly (50%)<br>\nThe presentation has a clear structure, is not too long, and explains the most important results concisely (10%)<br>\nThe recommendations to solve the problems are realistic, actionable and coherent with the analysis (10%)<br>\nIf any assumptions are made, they are stated clearly (10%)<br>\nCustom functions are used to perform repetitive tasks (10%)<br>","metadata":{}},{"cell_type":"markdown","source":"<font color= 'purple'>**Import the libraries**</font>\n","metadata":{}},{"cell_type":"code","source":"# Import the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random as rd\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport matplotlib.ticker as ticks\n\n#Additional web scrapping libraries\nfrom bs4 import BeautifulSoup as soup\nfrom urllib.request import urlopen as uReq\n\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To display the all the columns and get the max rows\npd.set_option('max_rows',None)\npd.set_option('display.max_columns',200)\nsns.set_style('whitegrid')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Understanding the Data","metadata":{}},{"cell_type":"markdown","source":"###  <font color= 'purple'>**1.1 Loading the data set**</font>","metadata":{}},{"cell_type":"code","source":"#Location of the data sets.\n\npath1 = r'../input/bank-loan-risk-analysis/application_data.csv'\n\npath2 = r'../input/bank-loan-risk-analysis/previous_application.csv'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Applicaiton Dataset","metadata":{}},{"cell_type":"code","source":"#Loading the Application dataset\n\napp = pd.read_csv(path1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of the data sets\n\nprint('Shape of the Application dataframe :',app.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the information about variables and their respective data types.\n\napp.info(verbose=True)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Preparation","metadata":{}},{"cell_type":"markdown","source":"### <font color= 'purple'>**2.1 Missing values**</font>","metadata":{}},{"cell_type":"markdown","source":"**Strategy  for handling the missing values** : \n\n>- If the percentage of the missing values are `quite significant` for particular columns then we drop those columns.\n>- If the percentage of the missing values are `insignificant` and we want to retain those columns then we can handle the missing values in those columns\n>>- To handle those missing values for particular columns different approaches can be taken into account.\n>>- Different kinds of columns such as categorical and numerical, moreover handling the two kinds of the columns requires different approaches\n>>- To handle the missing data for the categorical column we can use mode if the number of missing values are not significant. If the number of missing values are somewhat significant then a separate category can be created to handle the missing values.\n>>- For the Numerical variables mean,median and mode is generally used to impute the values if the missing values are significant in number and if the number of values are not significant we can drop those records/impute them.","metadata":{}},{"cell_type":"markdown","source":"#### Application Dataset","metadata":{}},{"cell_type":"code","source":"# Checking the columns for missing values\napp.isna().sum()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the number of columns that have missing records\napp.isna().sum()[app.isna().sum()>0].count()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conveting the absolute missing values count of the columns into percentage\n\nmissing_values_perc = (app.isna().sum() / app.shape[0])*100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_perc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = missing_values_perc.index.to_list()\nvals = missing_values_perc.to_list()\nmissing = pd.DataFrame({'Columns':cols,'Missing_Perc':vals})\nmissing.sort_values(by='Missing_Perc')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting missing value percentage for application dataset\n\nfig = plt.figure(figsize=(20,10))\n\nax = sns.pointplot(data=missing,x='Columns',y='Missing_Perc',color='blue')\n\nax.axhline(50,color='r',linestyle='--')\n\nplt.xlabel('Columns',fontsize=15)\n\nplt.ylabel('Missing Percentage',fontsize=15)\n\nplt.xticks(rotation=90)\n\nplt.yticks(fontsize=18)\n\nplt.title('Missing Values % for current Applications',fontsize=25)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the records with more than 40% of the missing values.\nmissing_more_than_50  =  missing_values_perc[missing_values_perc>=50]\nmissing_more_than_50","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the names of the column variables which has more than 40% missing values\nmissing_more_than_50.index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Columns which have the significant number of missing records(more likely to be equal or more than 40% ) are to be dropped.\napp1  =  app.drop(columns=missing_more_than_50.index)\napp1.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop the columns which are not required\n\napp1 = app1.drop(columns=['FLAG_DOCUMENT_2',\n       'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5',\n       'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8',\n       'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11',\n       'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n       'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n       'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',\n       'FLAG_DOCUMENT_21','FLAG_MOBIL','FLAG_EMP_PHONE','FLAG_WORK_PHONE',\n       'FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL','DAYS_LAST_PHONE_CHANGE',\n       'REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION','LIVE_REGION_NOT_WORK_REGION',\n       'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','LIVE_CITY_NOT_WORK_CITY','EXT_SOURCE_2',\n       'EXT_SOURCE_3','REGION_RATING_CLIENT_W_CITY','YEARS_BEGINEXPLUATATION_AVG','FLOORSMAX_AVG',\n       'YEARS_BEGINEXPLUATATION_MODE','FLOORSMAX_MODE','YEARS_BEGINEXPLUATATION_MEDI',\n       'FLOORSMAX_MEDI','TOTALAREA_MODE','EMERGENCYSTATE_MODE'])","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The above are the columns which will be further used for data analysis. ","metadata":{}},{"cell_type":"code","source":"# Again to check the percentage of the missing values to handle them differently\n\n(app1.isnull().sum()[app1.isnull().sum()>0] / app1.shape[0])*100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Amount Annuity Variable**","metadata":{}},{"cell_type":"code","source":"app1.AMT_ANNUITY.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Since the number of missing values in the AMT_ANNUITY column are very less so we can go on and impute the missing data with the mean value but since the max value is very high, imputing the data with median values will be a better approach","metadata":{}},{"cell_type":"markdown","source":"**Goods Price Variable** ","metadata":{}},{"cell_type":"code","source":"app1.AMT_GOODS_PRICE.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> For AMT_GOODS_PRICE column it will be better if median is used because the column has the high values as the price can differ from product to product so imputing the missing values with median will be a better approach.","metadata":{}},{"cell_type":"markdown","source":"**NAME_TYPE_SUITE Variable**","metadata":{}},{"cell_type":"code","source":"# Check the NAME_TYPE_SUITE variable\n\napp1.NAME_TYPE_SUITE.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.NAME_TYPE_SUITE.mode()[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font> : 'Unaccompained' holds approx 81% of the total values so imputing the missing values with the mode value will be a suitable approach.","metadata":{}},{"cell_type":"markdown","source":"**OCCUPATION_TYPE Variable**","metadata":{}},{"cell_type":"code","source":"# Check the OCCUPATION_TYPE variable\n\napp1.OCCUPATION_TYPE.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the percentage of the missing data for OCCUPATION_TYPE variable\n(app1.OCCUPATION_TYPE.isna().sum() / app1.shape[0])*100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment** </font> : In the Occupation Type Variable there are approximately 31% of the missing values so imputing these values with the mode will not be a good idea. Since the percentage of the missing values are high, the missing data can be imputed by creating another category by the name 'Other'.","metadata":{}},{"cell_type":"markdown","source":"**CNT_FAM_MEMBERS variable**","metadata":{}},{"cell_type":"code","source":"app1.CNT_FAM_MEMBERS.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> For CNT_FAM_MEMBERS we cannot use the mean here for this one thus we impute the missing values with 0.0 as the values are missing at random.","metadata":{}},{"cell_type":"markdown","source":"**SK_ID_CURR Variable**","metadata":{}},{"cell_type":"code","source":"# To check client ID for duplicate values\n\napp1.SK_ID_CURR.nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Again checking the summary statistics for the numerical columns\napp1.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> While looking at the summary statistics for the numerical columns, it can be seen that there are few columns with the negative values. It would be better if these values are converted to the positive so that it would not affect the analysis. ","metadata":{}},{"cell_type":"markdown","source":"### <font color='purple'>**2.2 Checking the Data Types**</font>","metadata":{}},{"cell_type":"code","source":"app1.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1['DAYS_REGISTRATION'] = app1['DAYS_REGISTRATION'].astype('int64')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1['AMT_REQ_CREDIT_BUREAU_YEAR'] =app1['AMT_REQ_CREDIT_BUREAU_YEAR'].astype('Int64') \napp1['AMT_REQ_CREDIT_BUREAU_QRT'] =app1['AMT_REQ_CREDIT_BUREAU_QRT'].astype('Int64') \napp1['AMT_REQ_CREDIT_BUREAU_WEEK'] =app1['AMT_REQ_CREDIT_BUREAU_WEEK'].astype('Int64') \napp1['AMT_REQ_CREDIT_BUREAU_MON'] =app1['AMT_REQ_CREDIT_BUREAU_MON'].astype('Int64') \napp1['AMT_REQ_CREDIT_BUREAU_DAY'] =app1['AMT_REQ_CREDIT_BUREAU_DAY'].astype('Int64') \napp1['AMT_REQ_CREDIT_BUREAU_HOUR'] =app1['AMT_REQ_CREDIT_BUREAU_HOUR'].astype('Int64') ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1['DEF_60_CNT_SOCIAL_CIRCLE'] =app1['DEF_60_CNT_SOCIAL_CIRCLE'].astype('Int64') \napp1['OBS_60_CNT_SOCIAL_CIRCLE'] =app1['OBS_60_CNT_SOCIAL_CIRCLE'].astype('Int64') \napp1['DEF_30_CNT_SOCIAL_CIRCLE'] =app1['DEF_30_CNT_SOCIAL_CIRCLE'].astype('Int64') \napp1['OBS_30_CNT_SOCIAL_CIRCLE'] =app1['OBS_30_CNT_SOCIAL_CIRCLE'].astype('Int64')  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'> **Comment** </font> : \n> 1. Some columns such as SOCIAL_CIRCLE type, AMT_REQ_CREDIT type, CNT_FAM_MEMBERS are having float datatype instead of integer datatype because of the missing values present in these columns so they can be converted to integer data type.\n\n> 2. DAYS_REGISTRATION column is in float format instead of integer format so converting it into integer as it has no missing values. Rest all the numeric columns are correctly divided into integer and float.","metadata":{}},{"cell_type":"markdown","source":"### <font color='purple'>**2.2.1 Standardizing the values for Application Dataframe**</font>","metadata":{}},{"cell_type":"markdown","source":"**DAYS_BIRTH**","metadata":{}},{"cell_type":"code","source":"# Convert the Days_Birth column\n\napp1.DAYS_BIRTH = app1.DAYS_BIRTH.abs()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DAYS_EMPLOYED**","metadata":{}},{"cell_type":"code","source":"# Convert the DAYS_EMPLOYED column\n\napp1.DAYS_EMPLOYED = app1.DAYS_EMPLOYED.abs()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DAYS_REGISTRATION**","metadata":{}},{"cell_type":"code","source":"# Convert the DAYS_REGISTRATION column\n\napp1.DAYS_REGISTRATION = app1.DAYS_REGISTRATION.abs()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DAYS_ID_PUBLISH**","metadata":{}},{"cell_type":"code","source":"# Convert the DAYS_ID_PUBLISH column\n\napp1.DAYS_ID_PUBLISH = app1.DAYS_ID_PUBLISH.abs()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DAYS_BIRTH**","metadata":{}},{"cell_type":"code","source":"# Now to see if we can calculate the age of the client \n\napp1['Age_Range'] = (app1.DAYS_BIRTH / 365).round(2)\napp1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Since the client's ages are more of the float values so categorizing them by following binning method can help in further analysis.","metadata":{}},{"cell_type":"code","source":"# Taking the bins and the labels\nbins = [0,30,40,50,60,100]\nlabels = ['<30','30-40','40-50','50-60','60+']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Binnig the age column\napp1['AGE_RANGE'] = pd.cut(app1.Age_Range,bins=bins,labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Age_Range column after making bins out of it\napp1.drop(columns='Age_Range',inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CODE_GENDER Column**","metadata":{}},{"cell_type":"code","source":"# Checking the Gender Column\napp1.CODE_GENDER.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.CODE_GENDER.replace('XNA',np.nan,inplace=True)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font> : Gender Column has 4 'XNA' values which are most probably the missing values and are less in number when compared to the other values. Hence, these values can be replaced and since the count of female values is the highest for gender column so 'XNA' can be replaced with 'Female'.","metadata":{}},{"cell_type":"markdown","source":"**ORGANIZATION_TYPE Variable**","metadata":{}},{"cell_type":"code","source":"app1['ORGANIZATION_TYPE'].value_counts()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font> : For ORGANIZATION_TYPE column there are 'XNA' values and 'other' column is also present, thus we can say that these XNA values are most probably the missing values. Moreover, these values are quite high, hence mode cannot be used here. The other way we can deal with these values is to either impute them with 'Unkown' category or we can ignore it while doing analysis.","metadata":{}},{"cell_type":"markdown","source":"### <font color= 'purple'>**2.3 Outlier Detection and Treatment**</font> ","metadata":{}},{"cell_type":"code","source":"# Setting the seaborn style\nsns.set_style('white')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AMT_INCOME_TOTAL Variable**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nax = sns.boxplot(data=app1.AMT_INCOME_TOTAL,orient='h',color='r')\nax.set_xscale('linear')\nax.xaxis.set_major_locator(ticks.MultipleLocator(2000000))\nax.set_title('Income Total Amount',fontsize=50)\nplt.xticks(rotation=90)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.AMT_INCOME_TOTAL.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font>As the max value is 1.17 X 10^8 which is infact a very high value but this is a valid value as income can vary from people to people. Hence, deleting the values can be an option but another better approach is to bin the values into categories then there it will be covered.","metadata":{}},{"cell_type":"code","source":"app1.AMT_INCOME_TOTAL.quantile([0.33,.34,.66,0.90,0.92,0.94,0.95,0.96,0.98,0.99,1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins = [0, 100000, 200000, 300000, 400000,200000000]\nlabels = ['Very Low','Low','Medium','High','Very High']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1['INCOME_RANGE'] = pd.cut(app1.AMT_INCOME_TOTAL,bins=bins,labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AMT_ANNUITY Variable**","metadata":{}},{"cell_type":"code","source":"# Checking the AMT_ANNUITY variable\n\nfig = plt.figure(figsize=(20,5))\nax = sns.boxplot(data=app1.AMT_ANNUITY,orient='h')\nax.set_xscale('linear')\nax.xaxis.set_major_locator(ticks.MultipleLocator(10000))\nax.set_title('Annuity Amount',fontsize=50)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.AMT_ANNUITY.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font>: There are outliers in the column AMT_ANNUITY so by taking bins the values can be a good approach to handle them.","metadata":{}},{"cell_type":"code","source":"app1['AMT_ANNUITY'].quantile([0.33,0.66,0.9,0.92,0.94,0.95,0.96,0.98,0.99,1.0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting up bins and labels for AMT_ANNUITY\n\nbins = [0,10000,20000,30000,40000,500000]\nlabels = ['Very Low','Low','Medium','High','Very High']\n\napp1['ANNUITY_RANGE'] = pd.cut(app1['AMT_ANNUITY'],bins=bins,labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AMT_GOODS_PRICE Variable**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nax = sns.boxplot(data=app1.AMT_GOODS_PRICE,orient='h',color='brown')\nax.set_xscale('linear')\nax.xaxis.set_major_locator(ticks.MultipleLocator(100000))\nax.set_title('Goods Amount',fontsize=50)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.AMT_GOODS_PRICE.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.AMT_GOODS_PRICE.quantile([0.75,0.80,0.85,0.90,0.95,0.96,0.97,0.98,0.99,1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font> : In the Goods Price column there are outliers present but these prices can vary from product to product. So, no action will be taken on this variable","metadata":{}},{"cell_type":"markdown","source":"**AMT_CREDIT Variable**","metadata":{}},{"cell_type":"code","source":"app1.AMT_CREDIT.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nax = sns.boxplot(data=app1.AMT_CREDIT,orient='h',color='orange')\nax.set_xscale('linear')\nax.xaxis.set_major_locator(ticks.MultipleLocator(100000))\nax.set_title('Credit Amount',fontsize=50)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.AMT_CREDIT.quantile([0.20,.33,.66,.90,.92,.94,.95,.96,.98,.99,1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'> **Comment** </font> : There are outliers after the 99 percentile values i.e 1.8 x 10^6 and it can be seen these outliers are in chunk thus we want to retain then as well, so binning them will be a good option here.","metadata":{}},{"cell_type":"code","source":"# Creating bins and labels for AMT_CREDIT column\nbins = [0,300000,600000,900000,1200000,5000000]\nlabels = ['Very Low','Low','Medium','High','Very High']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Binning the AMT_CREDIT column\napp1['CREDIT_RANGE'] = pd.cut(x=app1.AMT_CREDIT,bins=bins,labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DAYS_BIRTH Variable**","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nax = sns.boxplot(data=app1.DAYS_BIRTH,orient='h',color='darkcyan')\nax.set_xscale('linear')\nax.xaxis.set_major_locator(ticks.MultipleLocator(1000))\nax.set_title('Age',fontsize=50)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> By plotting the box plot for the client's Age column, it was found that there are no outliers in the DAYS_BIRTH column.","metadata":{}},{"cell_type":"markdown","source":"**DAYS_EMPLOYED Variable**","metadata":{}},{"cell_type":"code","source":"app1.DAYS_EMPLOYED.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\nax = sns.boxplot(app1.DAYS_EMPLOYED,orient='h',color='yellow')\nax.set_title('Days Employed',fontsize=50)\nax.xaxis.set_major_locator(ticks.MultipleLocator(10000))\nplt.xticks(rotation=90)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"years = 365243 / 365\nyears","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1['DAYS_EMPLOYED'].quantile([.8,0.82,0.95,0.98,0.99,1.0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1['DAYS_EMPLOYED'].value_counts().sort_index().tail(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'> **Comment** </font>: For the Days Employed column, some records are having the value as 365243 which is not a possible value as in years it is nearly 1000 years, hence it is an invalid value. A better approach to handle these records is to replace these values with a near high value to last lowest percentile value like 20000 as last highest value is 17912.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,5))\n\nax = sns.boxplot(app1.DAYS_ID_PUBLISH,orient='h',color='olive')\n\nax.set_title('Days Id Publish',fontsize=50)\n\nax.xaxis.set_major_locator(ticks.MultipleLocator(1000))\n\nplt.xticks(rotation=90)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font> : There are no outliers in the DAYS_ID_PUBLISH column so we can leave it as it is.","metadata":{}},{"cell_type":"markdown","source":"**SOCIAL_CIRCLE Variables**","metadata":{}},{"cell_type":"code","source":"app1.describe().loc[:,'OBS_30_CNT_SOCIAL_CIRCLE':'DEF_60_CNT_SOCIAL_CIRCLE']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for the SOCIAL CIRCLE columns \n\nl=['OBS_30_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE']\ncolor=['red','yellow','black','blue','darkcyan','orange','green','olive','brown']\n\nfig=plt.figure(figsize=(15,20))\nfig.subplots_adjust(hspace = .2, wspace=.2)\n\nfor i in enumerate(l):\n    plt.subplot(4,2,i[0]+1)\n    sns.boxplot(y=app1[i[1]],color=rd.choice(color))\n    plt.title(i[1],fontsize=10)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1[app1.DEF_60_CNT_SOCIAL_CIRCLE==24]","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The Social Circle columns have only one huge outlier and the entry index of that record is 148403. Since there exists only one record having the invalid value so we can drop this record.","metadata":{}},{"cell_type":"markdown","source":"## 3. ANALYSIS : Application Dataframe","metadata":{}},{"cell_type":"markdown","source":"### <font color='purple'>3.1 Data Imbalance Check</font>","metadata":{}},{"cell_type":"code","source":"# Checking the TARGET column for imbalance data in percentage\napp1.TARGET.value_counts(normalize=True)*100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the graphs\n\nfig, (ax1,ax2) = plt.subplots(1,2,figsize =(20,8))\n\nax = sns.countplot(app1.TARGET,ax=ax1)\n\nax1.set_title('TARGET',fontsize=20)\n\nplt.setp(ax1.xaxis.get_majorticklabels(),fontsize=18)\n\nax2 = plt.pie(x=app1.TARGET.value_counts(normalize=True),autopct='%.2f',textprops={'fontsize':15},shadow=True,labels=['No Payment Issues','Payment Issues'],wedgeprops = {'linewidth': 5}) \n\nplt.title('Distribution of the Target Variable',fontsize=20)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the Imbalance Percentage\n\nprint('Imbalance Percentage is : %.2f'%(app1.TARGET.value_counts(normalize=True)[0]/app1.TARGET.value_counts(normalize=True)[1]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font>: It can be seen from the TARGET column that 91.93% of the people have no payment issues and on the other hand 8.07% people are having payment difficulties. The imbalance percentage for the target variable is 11.39%.","metadata":{}},{"cell_type":"code","source":"app1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>**3.2 Categorical Variables**</font>","metadata":{}},{"cell_type":"code","source":"# Setting the style for the plots\nsns.set_style(style = 'whitegrid',rc={\"grid.linewidth\": 5})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app1.nunique().sort_values()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font>: By checking the unique value count for each column, we can distinguish between categorical and numerical variables from the application dataset. We can say that the values less than 40 are categorical columns and values more than 40 are basically the continous variables.\n","metadata":{}},{"cell_type":"code","source":"# Function for univariate analysis\ndef plots(l,rows=1,cols=1,rot=90):\n        \n    if cols>1:\n        fig, (ax1,ax2) = plt.subplots(nrows=rows,ncols=cols,figsize=(30,10))\n        fig.subplots_adjust(hspace = .2, wspace=.2)\n    \n    else:\n        fig, (ax1,ax2) = plt.subplots(nrows=rows,ncols=cols,figsize=(30,30))\n        fig.subplots_adjust(hspace = .5, wspace=.1)\n    \n    \n    # Subplot 1 : countplot \n    first = sns.countplot(data = app1 , hue = 'TARGET', palette='inferno',x=l,ax=ax1)\n    first.set_title(l,fontsize=30)\n    first.set_yscale('log')\n    first.legend(labels=['Loan Repayers','Loan Defaulters'],fontsize=20)\n    plt.setp(first.xaxis.get_majorticklabels(), rotation=rot,fontsize=25)\n    plt.setp(first.yaxis.get_majorticklabels(),fontsize=18)\n\n\n    # Percentage of the mean values for defaulters\n    default_percentage = (app1.groupby(by=l)['TARGET'].mean()*100).sort_values()\n    \n    # Subplot 2 : barplot\n    sec = sns.barplot(x=default_percentage.index,y=default_percentage,ax=ax2)\n    sec.set_title(f'Default % in {l}',fontsize=30)\n    sec.set_yscale('linear')\n    plt.setp(sec.xaxis.get_majorticklabels(), rotation=rot,fontsize=25)\n    plt.setp(sec.yaxis.get_majorticklabels(),fontsize=18)\n    return None\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.1 Categorical Ordered Variables","metadata":{}},{"cell_type":"markdown","source":"The categorical Ordered columns are as follows :\n\n1. NAME_EDUCATION_TYPE\n2. CREDIT_RANGE\n3. INCOME_RANGE\n4. ANNUITY_RANGE","metadata":{}},{"cell_type":"code","source":"list_Cat_num = ['NAME_EDUCATION_TYPE','CREDIT_RANGE','INCOME_RANGE','ANNUITY_RANGE']\n\nfor i in list_Cat_num:\n    plots(i,1,2,rot=50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>**Comments**</font> :\n\n> 1. When we talk about the clients with respect to their Education type, those clients that have education status as secondary/ special secondary are approaching more for the loans while clients with education status as lower secondary are most at default. There is another category of incomplete higher which can also be considered for the loans.\n\n> 2. For the CREDIT_RANGE variable, clients having the very low and low credit amounts are taking the most loans and on the other hand clients with low credit amounts are generally likely to default more so bank should consider them less while giving out the loans. Bank should focus more on the clients who have taken very high credit amounts.\n\n> 3. As it can be seen from the graphs, income ranges from very low to meduim has the highest number of applications but it is adviced to focus more on the clients with atleast medium ranged income values or greater than medium values.\n\n> 4. For AMT_ANNUITY column, most of the applications are from the low or medium ranged AMT_ANNUITY values but on the other hand, medium ranged values should be considered less for loan approval as they are highly at default. So, bank should consider low or very high ranged AMT_ANNUITY valued customers for loans.\n","metadata":{}},{"cell_type":"markdown","source":"### 3.2.2 Categorical Unordered Variables","metadata":{}},{"cell_type":"markdown","source":"The unordered categorical columns are as follows :\n\n1. AGE_RANGE\n2. REGION_RATING_CLIENT\n3. CNT_FAM_MEMBERS\n4. CNT_CHILDREN\n5. FLAG_OWN_CAR\n6. FLAG_OWN_REALTY\n7. CODE_GENDER\n8. NAME_CONTRACT_TYPE\n9. NAME_INCOME_TYPE\n10. NAME_FAMILY_STATUS\n11. NAME_HOUSING_TYPE\n12. OCCUPATION_TYPE","metadata":{}},{"cell_type":"code","source":"list_categories = ['AGE_RANGE','REGION_RATING_CLIENT','CNT_FAM_MEMBERS','CNT_CHILDREN']\n\nfor i in list_categories:\n    plots(i,1,2,rot=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>**Comments**</font> :\n\n> 1. In the AGE_RANGE variable, clients of age group lower than or equal to 30 have the maximum payment defaults. Clients with age group between 30 to 50 have taken the most number of loans and are preferred to target as they have less number of loan defaults.\n\n> 2. It can be seen from the REGION_RATING_CLIENT variable that clients from  the regions where rating is 2 are taking the maximum number of the loans and have lesser loan default ratio than other regions, thus it can be considered to target. Moreover, clients from region as rating 3 are pretty much more prone to default.\n\n> 3. The clients having the 11 and 13 family members have the highest default rate of 100% and most of the loans are taken by those clients who have less family members.\n\n> 4. Clients having no children are the ones who have taken the most number of loans, on the other hand clients having 9 and 11 children are defaulting the most.","metadata":{}},{"cell_type":"code","source":"list_categories = ['FLAG_OWN_CAR','FLAG_OWN_REALTY','CODE_GENDER','NAME_CONTRACT_TYPE']\n\nfor val in list_categories:\n    plots(val,1,2,rot=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>**Comments**</font> :\n\n> 1. Clients having their own flat/house are much likely to repay the loans than those who do not and same can be observed for those who has their own vehicals.\n\n> 2. As it can be seen from the graphs, females are taking more loans than males and are doing much better than the males in repaying the loans while males have taken less number of loans as compared to the females and on the other hand, their defaulting percentage is high.\n\n> 3. It seems clients are interested more towards the cash loans type contract and are defaulting more on the loans while the revolving loan type contract are performing much better.","metadata":{}},{"cell_type":"code","source":"list_categories = ['NAME_INCOME_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE']\n\nfor i in list_categories:\n    plots(i,1,2,rot=50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>**Comments**</font> :\n\n\n> 1. In the NAME_INCOME_TYPE variable, clients who are either businessman or student are pretty much likely to repay the loans and also for the working clients. While considering the clients who are Unemployed or are on Maternity Leave should be less likely be the ones for giving out the loan.\n\n> 2. Clients that are single or hold civil marriage as their family status must be considered less while giving out loans because they are the ones with high default ratio. For the clients with the separated family status should be chosen very carefully when giving out loans. Married clients are approaching the bank more for the loans and can be considered to give out loans.\n\n> 3. The clients that have own their own house/apartment or are using office apartment should be considered more often while giving out loans as clients living in the rented apartments are very risky to be considered for giving loans.\n\n","metadata":{}},{"cell_type":"code","source":"plots('OCCUPATION_TYPE',1,2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>**Comments**</font> :\n\n> It is very risky to consider Low-skilled Laborers when considering clients on giving loans as the percentage of defaulters for this category is the most from other categories. Clients having the occupation such as Accountants,High skill tech staff,Managers,HR and IT staff or the \"other\" category are pretty much safe to consider for giving out loans and even small amount of loans to labourers can be given.","metadata":{}},{"cell_type":"code","source":"# Plotting the ORGANIZATION_TYPE separately \n\nplots('ORGANIZATION_TYPE',rows=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment**</font>: \n\n> 1. By looking at the graph:\n\n>> **a)** Industry Type : All industries except type 1,3,4,8,13 can be chosen for giving out loans more frequently as their default % is lower than these 5.\n\n>> **b)** Transport Type : Bank should focus more on giving out loans to the transport type 1 and 2 as they are more likely to repay the loans on time than others.\n\n>> **c)** It can be seen that organizations such as  Universities,Schools,Government can be beneficial ones to target for giving out loans as their chances to default out on loans are quite less.\n\n> 2. Those organizations should be targeted more for the loans whose default % are quite lower than 10% when compared to other organizations.","metadata":{}},{"cell_type":"markdown","source":"### **3.2.3 Numeric - Categorical Variables**","metadata":{}},{"cell_type":"code","source":"# Dividing the data set into 2 parts target_0 : Loan Repayers and target_1 : Loan Defaulters\n\ntarget_0 = app1[app1['TARGET']==0]\n\ntarget_1 = app1[app1['TARGET']==1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a function for bivariate analysis\n\ndef cat_num_bivar(x=None,y=None,hue=None,est=np.mean,rot=90):\n    plt.style.use('dark_background')\n    fig ,(ax1,ax2) = plt.subplots(1,2,figsize=(20,10))\n    first = sns.barplot(data=target_0,x=x,y=y,hue=hue,palette='Set3',estimator=est,ax=ax1)\n    first.set_title(f'Target 0 : {x} vs {y}',fontsize=20)\n    plt.setp(first.xaxis.get_majorticklabels(),rotation=rot,fontsize=25)\n    plt.setp(first.yaxis.get_majorticklabels(),fontsize=18)\n\n    sec  = sns.barplot(data=target_1,x=x,y=y,hue=hue,palette='Set3',estimator=est,ax=ax2)\n    sec.set_title(f'Target 1 : {x} vs {y}',fontsize=20)\n    plt.setp(sec.xaxis.get_majorticklabels(),rotation=rot,fontsize=25)\n    plt.setp(sec.yaxis.get_majorticklabels(),fontsize=18)\n\n    plt.show()\n    return None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Education vs Income**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar(x='NAME_EDUCATION_TYPE',y='AMT_CREDIT')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :** </font> Candidates who are having the academic degrees or higher education atleast are most likey to repay the loans where the credit amount that they have taken is less than 720000. On the other hand, some of these clients from these two categories are also the ones are defaulting and moreover the ones with values over 720000 are mostly defaulting. So, clients having secondary/ special secondary or with incompletely higher are pretty much safe to approach for loans.","metadata":{}},{"cell_type":"markdown","source":"**Occupation vs Income**","metadata":{}},{"cell_type":"code","source":"# Plotting the graphs with estimator as median\n\ncat_num_bivar('OCCUPATION_TYPE','AMT_INCOME_TOTAL',est=np.median)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> As Income variable has outliers so it is better to choose median than mean estimator, clients with occupations such as Managers, accountants, realty agents, IT staff, drivers are having good income. So out of these categories Managers and realty agents must not be chosen much for loan approvals as they are more likeyly to default on the loans. Moreover, categories with income lower than 150000 can be considered more for loans.","metadata":{}},{"cell_type":"markdown","source":"**Income type vs Credit**","metadata":{}},{"cell_type":"code","source":"# Plotting the graphs\n\ncat_num_bivar('NAME_INCOME_TYPE','AMT_CREDIT')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comments**</font> : \n\n1. The credit amount is the highest for the businessman while clients who are having pensions are taking low credit amount from the bank.\n\n2. Clients having their own businesses or are students, repaying the loans completely whereas clients who are on maternity leave are least ones to be considered for giving out the loans. Care should be taken for State servants and for commercial clients while considering for loan approval.","metadata":{}},{"cell_type":"markdown","source":"**Housing type  vs Income**","metadata":{}},{"cell_type":"code","source":"# Plotting the graph with estimator as median\n\ncat_num_bivar('NAME_HOUSING_TYPE','AMT_INCOME_TOTAL',est=np.median)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The clients having the highest incomes are living in office apartments and the clients living with parents are earning quite less than others but are more prone to default the loans. The clients living in CO-OP apartments are much likely to default the most. Hence, bank should focus more towards clients having their own house/apartment or living in office apartments.","metadata":{}},{"cell_type":"markdown","source":"**CODE_GENDER vs AMT_INCOME_TOTAL**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar('CODE_GENDER','AMT_INCOME_TOTAL',est=np.median)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Fromt the above plots, we can say that males are earning more than females, on the other hand the default rate for the males are much higher.","metadata":{}},{"cell_type":"markdown","source":"### 3.2.4 Categorical - Categorical Variables","metadata":{}},{"cell_type":"code","source":"def cat_cat(data1,data2,x,hue,scale='linear',order=None,rot=90):\n    plt.style.use('dark_background')\n    fig= plt.figure(figsize=(20,10))\n    plt.subplot(1,2,1)\n\n    sns.countplot(data = data1,x=x,hue=hue,hue_order=order,palette='Spectral')\n    plt.title(f'target 0 :{x} vs {hue}',fontsize=20)\n    plt.yscale(scale)\n    plt.xticks(rotation=rot,fontsize=25)\n    plt.legend(fontsize=16)\n    \n    plt.subplot(1,2,2)\n    sns.countplot(data = data2,x=x,hue=hue,hue_order=order,palette='Spectral')\n    plt.title(f'target 1 :{x} vs {hue}',fontsize=20)\n    plt.yscale(scale)\n    plt.xticks(rotation=rot,fontsize=25)\n    plt.legend(fontsize=16)\n    plt.show()\n    return None\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Name_housing vs Gender**","metadata":{}},{"cell_type":"code","source":"cat_cat(target_0,target_1,'NAME_HOUSING_TYPE','CODE_GENDER','log',['M','F'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font>\n\nFrom the above plots it can be seen that males living with thier parents are much more likely to default than females. Females are more defaulting on the loans but the recovery rate is much better as compared to males.","metadata":{}},{"cell_type":"markdown","source":"**Occupation vs Family Status**","metadata":{}},{"cell_type":"code","source":"cat_cat(target_0,target_1,'OCCUPATION_TYPE','NAME_FAMILY_STATUS',scale='log')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Married and single clients are approaching the bank more for the loans on the other hand widows are approaching the less for the loans and are less likely to default. Married laborers are defaulting more as compared to single/not married.","metadata":{}},{"cell_type":"markdown","source":"**Income type vs Education type**","metadata":{}},{"cell_type":"code","source":"cat_cat(target_0,target_1,'NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','log')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Clients with higher education who are on the maternity leave are less in number for taking loans and defaulting the most, so they should be less considered and for the unemployed ones clients with Secondary/ secondary special are mostly at default.","metadata":{}},{"cell_type":"markdown","source":"**NAME_FAMILY_STATUS vs FLAG_OWN_REALTY**","metadata":{}},{"cell_type":"code","source":"cat_cat(target_0,target_1,'NAME_FAMILY_STATUS',hue='FLAG_OWN_REALTY',scale='log',order=['Y','N'],rot=70)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment -**</font> From the above plot it can be seen that clients who own their own realty are approaching the bank more often for the loans and are more prone to default than those who do not own the realty.","metadata":{}},{"cell_type":"markdown","source":"**INCOME_RANGE vs CODE_GENDER**","metadata":{}},{"cell_type":"code","source":"cat_cat(target_0,target_1,'INCOME_RANGE',hue='CODE_GENDER',scale='log',order=['M','F'],rot=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Females are earning more than the males and there are more number of males that are earning very high amount. Females with either low or very low incomes are much likely to default than males but on the other hand males with higher incomes are defaulting more than females.","metadata":{}},{"cell_type":"markdown","source":"## <font color='purple'>3.3 Numerical Variables</font>","metadata":{}},{"cell_type":"markdown","source":"### 3.3.1 Univariate Analysis","metadata":{}},{"cell_type":"code","source":"list_numerics=['AMT_ANNUITY','AMT_CREDIT','AMT_INCOME_TOTAL','AMT_GOODS_PRICE','DAYS_BIRTH']\n\ndef plots_numeric_univ(l):\n        sns.set_style(style='whitegrid')\n        fig=plt.figure(figsize=(50,5))\n        plt.subplot(1,5,1)\n        sns.distplot(target_0[l],hist=False,label='Loan Repayers',color='green')\n        sns.distplot(target_1[l],hist=False,label='Loan Defaulters',color='red')\n        plt.title(l,fontsize=20)\n        plt.show()\n        \nfor i in list_numerics:\n    plots_numeric_univ(i)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'> **Comments :**</font>\n\n> 1. For AMT_ANNUITY variable, most of the clients have the amount less than 50000 and default rate is higher than repayer rate. \n\n> 2. The clients having the Credit value less than 1M are applying more for the loans.\n\n> 3. The clients are applying more for the loans for the goods price less than 1M and for the higher goods price clients are repaying loans\n\n> 4. For DAYS_BIRTH variable, clients who are less than 40yrs of age are more prone to default on loans than the others.\n","metadata":{}},{"cell_type":"markdown","source":"### 3.3.2 Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"# Creating the function for the numeric bivariate analysis\n\ndef plots_numeric_biv(x,y):\n    sns.set_style(style='whitegrid')\n    fig=plt.figure(figsize=(15,6))\n    sns.scatterplot(data=target_0, y = y, x = x,label='Loan Repayers',color='darkcyan')\n    sns.scatterplot(data=target_1, y = y, x = x,label='Loan Defaulters',color='red')\n    plt.title(f'{x} vs {y}',fontsize=20)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AMT_ANNUITY vs AMT_GOODS_PRICE**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv('AMT_ANNUITY','AMT_GOODS_PRICE')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The AMT_ANNUITY and AMT_GOODS_PRICE are correlated but the correlation is not that strong as the values are pretty much distributed for higher Annuity and Goods price values. Hence, for AMT_ANNUITY less than 70000 are more prone to default while values greater than 70000 the defaulters tend to decrease.","metadata":{}},{"cell_type":"markdown","source":"**AMT_ANNUITY vs AMT_CREDIT**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv('AMT_ANNUITY','AMT_CREDIT')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The AMT_ANNUITY and AMT_CREDIT are fairly correlated with each other and the number of defaulters tend to go down as the  AMT_ANNUITY increases. Most of the defaulters are having AMT_ANNUITY values less than 60000.","metadata":{}},{"cell_type":"markdown","source":"**AMT_GOODS_PRICE vs AMT_CREDIT**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv('AMT_GOODS_PRICE','AMT_CREDIT')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'> **Comment :** </font> The graph show a pretty strong correlation between AMT_GOODS_PRICE and AMT_CREDIT, clients having high goods price are most likely to repay the loans as majority of defaulters are having goods price less than 1.4 million. ","metadata":{}},{"cell_type":"code","source":"# PLotting the pairplot \nl=['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']\nsns.pairplot(data = app1, vars=l,hue='TARGET',palette=['b','orange'])\nplt.xticks(fontsize=25)\nplt.yticks(fontsize=25)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Correlation : Application Dataset","metadata":{}},{"cell_type":"markdown","source":"### <font color='purple'>TARGET 0 : Loan Repayer</font>","metadata":{}},{"cell_type":"code","source":"# Dropping the columns which are not required\ncols_drop = ['SK_ID_CURR','AMT_REQ_CREDIT_BUREAU_HOUR',\n       'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n       'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n       'AMT_REQ_CREDIT_BUREAU_YEAR','OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_0 = target_0.drop(columns=cols_drop)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\n\ncorr = target_0.corr().abs()\ncorr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise the correlation using heatmaps\n\nfig = plt.figure(figsize=(12,10))\n\nsns.heatmap(data=corr,annot=True,cmap='RdYlGn_r',linewidths=.5,center=0.1)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unstacking the TARGET_0 variable\nc = corr.abs()\ns=c.unstack()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding top 10 correlation among the people with no payment issues\n\ntarget_0_corr = s[s.index.get_level_values(0)!= s.index.get_level_values(1)].sort_values(ascending=False,kind='quicksort').drop_duplicates()\n\ndf = pd.DataFrame(target_0_corr)\n\ndf = df.reset_index().rename(columns={'level_0':'Var1','level_1':'Var2',0:'Correlation'}).dropna()\n\ndf.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>TARGET 1 : Loan Defaulter</font>","metadata":{}},{"cell_type":"code","source":"# Drop the columns which are not required\ntarget_1 = target_1.drop(columns=cols_drop)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the correlation matrix for the Loan defaulter data frame\ncorr_t1 = target_1.corr().abs()\n\ncorr_t1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PLotting the heatmap \nfig = plt.figure(figsize=(12,10))\n\nsns.heatmap(data=corr_t1,annot=True,cmap='RdYlGn_r',linewidths=0.5,center=0.1)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c1 = corr_t1\n\ns1 = c1.unstack()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 10 Correlations from target_1 : Loan Defaulter data frame\n\ntarget_1_corr = s1[s1.index.get_level_values(0)!= s1.index.get_level_values(1)].sort_values(ascending=False,kind='quicksort').drop_duplicates()\n\ndf = pd.DataFrame(target_1_corr)\n\ndf = df.reset_index().rename(columns={'level_0':'Var1','level_1':'Var2',0:'Correlation'}).dropna()\n\ndf.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color='purple'>Comments </font>:\n\n> For target variable there is no correlation as there are empty space in the graph and NAN in the tables while comparing with other variables.\n\n> Credit amount is highly correlated with amount of goods price which is slightly different from target 0 i.e Loan Repayers.\n\n> The correlation is strong between family member and children counts, although the correlation increases for the defaulters.\n\n> The loan annuity correlation with credit amount and also with goods price has slightly reduced in defaulters(0.748) when compared to repayers(0.777)\n\n> We can also see that repayers have high correlation in number of days employed(0.62) when compared to defaulters(0.58).\n\n> Days_birth and number of children correlation has reduced to 0.256 in defaulters when compared to 0.336 in repayers.","metadata":{}},{"cell_type":"markdown","source":"## 5. Previous Application Dataset","metadata":{}},{"cell_type":"markdown","source":"### <font color='purple'>**5.1 Loading the Data**</font>","metadata":{}},{"cell_type":"code","source":"# Fetching the dataset\n\n## 'app' variable takes the dataset application_data.csv as Data Frame\n\nf = path2\n# Count the lines\nnum_lines = sum(1 for l in open(f))\n# Sample size - in this case ~50%\nsize = int(num_lines // 2)\n# The row indices to skip - make sure 0 is not included to keep the header!\nrd.seed(100)\nskip_idx = rd.sample(range(1, num_lines), num_lines - size)\n# Read the data\nprev_app = pd.read_csv(f, skiprows=skip_idx)\n\nprev_app.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the dataset\nprev_app.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values check\nprev_app.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the style for the plots\nsns.set_style(style='whitegrid')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the absolute missing values into percentage\n\nmissing_prev = ((prev_app.isna().sum() / prev_app.shape[0])*100)\n\ncols1 = missing_prev.index.to_list()\n\nvals1 = missing_prev.to_list()\n\nmissing_prev_app = pd.DataFrame({'Columns':cols1,'Missing_prev_Percentage':vals1})\n\nmissing_prev_app.sort_values(by='Missing_prev_Percentage')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color='purple'>5.2 Missing Values check</font>","metadata":{}},{"cell_type":"code","source":"# Plot for missing values in previous application data frame\nfig = plt.figure(figsize=(20,8))\n\nax = sns.pointplot(data = missing_prev_app, x='Columns', y = missing_prev_app.Missing_prev_Percentage,color='blue')\n\nax.axhline(50,color='red',linestyle='--')\n\nax.set_title('Missing Values % for Previous Applications ',fontsize=20)\n\nax.set_xlabel('Columns',fontsize=15)\n\nax.set_ylabel('Missing Percentage',fontsize=15)\n\nax.set_xticklabels(labels=cols1,rotation=90)\n\n\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the columns with more than 50 % missing values\nprev_app.drop(columns=missing_prev[missing_prev>=50].index,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_app.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev_app.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Merged Dataset","metadata":{}},{"cell_type":"code","source":"# Merge the datasets\nmerged_df = app1.merge(right=prev_app,on='SK_ID_CURR')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of the data\nmerged_df.shape","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> After merging the datasets if was found that some columns have the name for example, `abc_x` and `abc_y`  so `x` - **means that the column represents the application dataset columns** and `y` - **represents the columns from the previous application dataset**.","metadata":{}},{"cell_type":"markdown","source":"**DAYS_DECISION Variable**","metadata":{}},{"cell_type":"code","source":"merged_df['DAYS_DECISION'] = merged_df['DAYS_DECISION'].abs()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The values has some negative values so let's convert them into positive","metadata":{}},{"cell_type":"code","source":"merged_df.nunique().sort_values()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color='purple'>6.1 Categorical Variables</font>","metadata":{}},{"cell_type":"code","source":"# Dividing the merged dataset into two parts on the basis of Loan Approval and Loan Refusal\n\ndf1= merged_df[merged_df['NAME_CONTRACT_STATUS']=='Approved']\n\ndf2= merged_df[merged_df['NAME_CONTRACT_STATUS']=='Refused']\n\ndf3= merged_df[merged_df['NAME_CONTRACT_STATUS']=='Canceled']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to analyze the categorical columns\n\ndef cat_1(x,hue,scale='linear',order=None,rot=90,hspc=0.3):\n    plt.figure(figsize=(25,25))\n    \n    plt.subplots_adjust(wspace=0.3,hspace=hspc)\n    plt.subplot(2,2,1)\n    sns.countplot(data = df1,x=x,hue=hue,hue_order=order,palette=['darkcyan','darkgrey'])\n    plt.title(f'Approved :{x} ',fontsize=20)\n    plt.yscale(scale)\n    plt.xticks(rotation=rot,fontsize=18)\n    plt.yticks(fontsize=15)\n    plt.legend(labels=['Loan Repayers','Loan Defaulters'],fontsize=16)\n        \n    plt.subplot(2,2,2)\n    sns.countplot(data = df2,x=x,hue=hue,hue_order=order,palette=['darkcyan','darkgrey'])\n    plt.title(f'Refused :{x} ',fontsize=20)\n    plt.yscale(scale)\n    plt.xticks(rotation=rot,fontsize=18)\n    plt.yticks(fontsize=15)\n    plt.legend(labels=['Loan Repayers','Loan Defaulters'],fontsize=16)\n    \n    # default % in approval\n    ax=(df1.groupby(by=x)['TARGET'].mean()*100).sort_values()\n    \n    \n    plt.subplot(2,2,3)\n    a = sns.barplot(x=ax.index,y=ax)\n    a.set_title(f'Default % in Approval : {x}',fontsize=20)\n    a.set_yscale('linear')\n    plt.setp(a.xaxis.get_majorticklabels(), rotation=rot,fontsize=18)\n    plt.setp(a.yaxis.get_majorticklabels(),fontsize=18)\n    \n    \n    # default % in refused\n    ax1=(df2.groupby(by=x)['TARGET'].mean()*100).sort_values()\n    \n    plt.subplot(2,2,4)\n    a = sns.barplot(x=ax1.index,y=ax1)\n    a.set_title(f'Default % in Refusal : {x}',fontsize=20)\n    a.set_yscale('linear')\n    plt.setp(a.xaxis.get_majorticklabels(), rotation=rot,fontsize=18)\n    plt.setp(a.yaxis.get_majorticklabels(),fontsize=18)\n    \n    plt.show()\n    return None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NAME_CLIENT_TYPE**","metadata":{}},{"cell_type":"code","source":"cat_1(x='NAME_CLIENT_TYPE',hue='TARGET',scale='log',rot=50,hspc=0.4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The bank is approving loans for repeater and new clients where new clients are actually making more defaults than the repeaters. So, bank should primarily focus more on refreshed/repeaters.","metadata":{}},{"cell_type":"markdown","source":"**PRODUCT_COMBINATION**","metadata":{}},{"cell_type":"code","source":"cat_1(x='PRODUCT_COMBINATION',hue='TARGET',scale='log',hspc=0.7)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Bank has approved the loans highly for POS categories and they are less likely to default than other categories like cash X / car, hence, bank can consider to give out loans POS categories more.","metadata":{}},{"cell_type":"markdown","source":"**NAME_SELLER_INDUSTRY**","metadata":{}},{"cell_type":"code","source":"cat_1(x='NAME_SELLER_INDUSTRY',hue='TARGET',scale='log',hspc=0.5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> While looking at the distribution graphs, bank is giving loans more towards the categories like consumer electronics,connectivity,furniture. The most of the default done by the category is Auto technology. Hence, banks should approve more loans for the categories like tourism, furniture, clothing, consumer electronics.","metadata":{}},{"cell_type":"markdown","source":"**NAME_PRODUCT_TYPE**","metadata":{}},{"cell_type":"code","source":"cat_1(x='NAME_PRODUCT_TYPE',hue='TARGET',scale='log',rot=50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Bank is approving loans more for the product type category X-sell and can be considered more to give out loans. Bank is actually refusing the loans to X- sell more than walk-ins and it can be seen form the graphs that walk-ins are more prone to default than X-sell.","metadata":{}},{"cell_type":"markdown","source":"**NAME_CASH_LOAN_PURPOSE**","metadata":{}},{"cell_type":"code","source":"cat_1(x='NAME_CASH_LOAN_PURPOSE',hue='TARGET',scale='log',hspc=0.7)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Categories like repairs, other, urgent needs, buying a used car are getting more approvals from the bank, out of which urgent needs is most at default. Bank is approving the loans for a particular category Money for a third person which a very risky driving factor for the bank to give out loans on. Bank is on the other hand has refused to give the loans for the Money for a third person which is the correct step taken by the bank but on the other hand bank is also refusing the categories which may turn out to be beneficial for the bank itself, those categories are - Buying a new car/used car, garage, home or a holiday home/ land.","metadata":{}},{"cell_type":"markdown","source":"**NAME_CONTRACT_TYPE**","metadata":{}},{"cell_type":"code","source":"cat_1(x='NAME_CONTRACT_TYPE_y',hue='TARGET',scale='log',rot=50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Bank is approving loans more in general for consumer loans and refusing the loans more oftenly for the cash loans. From the above graphs, it is clearly visible that revolving loans should be considered less for the approval whereas consumer loans / cash loans can be considered more oftenly for the loans.","metadata":{}},{"cell_type":"code","source":"merged_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Funciton for numerical - categorical analysis\n\ndef cat_num_bivar_merged(x=None,y=None,hue=None,est=np.median,rot=90):\n    plt.style.use('dark_background')\n    \n    fig = plt.figure(figsize=(30,13))\n    plt.subplots_adjust(wspace=0.3)\n    \n    plt.subplot(1,3,1)\n    first = sns.barplot(data=df1,x=x,y=y,hue=hue,palette='Set3',estimator=est)\n    first.set_title(f'Approval : {x} vs {y}',fontsize=18)\n    plt.setp(first.xaxis.get_majorticklabels(),rotation=rot,fontsize=25)\n    plt.setp(first.yaxis.get_majorticklabels(),fontsize=18)\n    \n\n    plt.subplot(1,3,2)\n    sec = sns.barplot(data=df2,x=x,y=y,hue=hue,palette='Set3',estimator=est)\n    sec.set_title(f'Refusal : {x} vs {y}',fontsize=18)\n    plt.setp(sec.xaxis.get_majorticklabels(),rotation=rot,fontsize=25)\n    plt.setp(sec.yaxis.get_majorticklabels(),fontsize=18)\n    \n    plt.subplot(1,3,3)\n    third = sns.barplot(data=df3,x=x,y=y,hue=hue,palette='Set3',estimator=est)\n    third.set_title(f'Cancelled : {x} vs {y}',fontsize=18)\n    plt.setp(third.xaxis.get_majorticklabels(),rotation=rot,fontsize=25)\n    plt.setp(third.yaxis.get_majorticklabels(),fontsize=18) \n    \n    plt.show()\n    return None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NAME_PRODUCT_TYPE vs AMT_GOODS_PRICE_y**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar_merged(x='NAME_PRODUCT_TYPE',y='AMT_GOODS_PRICE_y',rot=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> Banks are giving most approvals to X-sell type goods on the basis of price but it can be seen from the refusal section that X-sell is getting more rejections as the clients are not able to cope up with the price which is the strong reason. Hence, that is why clients are mostly cancelling their applications of the loan due to this reason as it can be seen graphically, the of most rejections from the clients are for the higher priced goods. Lastly, a driving solution is to lower the goods price from the seller's side.","metadata":{}},{"cell_type":"markdown","source":"**NAME_SELLER_INDUSTRY vs AMT_GOODS_PRICE_y**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar_merged(x='NAME_SELLER_INDUSTRY',y='AMT_GOODS_PRICE_y',rot=90)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> For 'XNA' we will ignore the observation as they are missing values or Unknowns.\nFrom the above plots, it can be seen that tourism is getting the highest number of approvals followed by MLM partners from the bank. The loan applications for the tourism of many clients is rejected as they are not capable of repaying the loan due to the high package prices most probably. So, the tourism industry should lower the prices so that more clients can be provided with loans and so the bank/industry can make profits.","metadata":{}},{"cell_type":"markdown","source":"**PRODUCT_COMBINATION vs AMT_GOODS_PRICE_y**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar_merged(x='PRODUCT_COMBINATION',y='AMT_GOODS_PRICE_y',rot=90)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The categories like cash street: low and cash X-sell: low have the highest price and it can be clearly seen from the graph that banks are giving approvals for those clients that can take the loans but on the refusal side these two are getting mostly refused due to the very high prices as clients are finding difficult to repay the loans on such ammount due to which bank is facing a loss of interest from the clients so bringing down the rates of the combined goods can help the bank to get more approvals on client loan applications. Lastly, POS industry with interest category is also getting cancellations from the client's side as the price of the goods are very much higher as compared to others so clients might have received worst pricing from the sellers which is why they are cancelling their loan applications. However, lowering the price can help getting the bank more approvals.","metadata":{}},{"cell_type":"markdown","source":"**NAME_GOODS_CATEGORY vs AMT_GOODS_PRICE_y**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar_merged(x='NAME_GOODS_CATEGORY',y='AMT_GOODS_PRICE_y',rot=90)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The most of the approvals done by the bank are on the categories like vehicles, tourism, Medical supplies, direct sales, medicine. The most of the refusals by the bank are on the categories like weapon, Additional service, tourism, direct sales. The clients are taking their applications down most prabably down to the higher package prices for the tourism and other categories like medical supplies. So, lowering the prices can be a solution.","metadata":{}},{"cell_type":"markdown","source":"**NAME_CASH_LOAN_PURPOSE vs AMT_GOODS_PRICE_y**","metadata":{}},{"cell_type":"code","source":"cat_num_bivar_merged(x='NAME_CASH_LOAN_PURPOSE',y='AMT_GOODS_PRICE_y',rot=90)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The bank is approving loans for the clients who wants to buy a home or new car mostly and on the other hand the refusals are highest for the categories like buying a new car, buying a home and buying a holiday home or land. The applications cancelled by the clients are fot eh buying a home where the clients are most probably be losing the interest because high price possibility.","metadata":{}},{"cell_type":"markdown","source":"## <font color='purple'>6.2 Numerical Variables</font>","metadata":{}},{"cell_type":"code","source":"# Plotting the numeric variables \n\nlist_cat = ['AMT_ANNUITY_y','AMT_CREDIT_y','AMT_GOODS_PRICE_y','AMT_APPLICATION']\n\ndef plots_numeric_univ_merged(l):\n        sns.set_style('whitegrid')\n    \n        fig=plt.figure(figsize=(30,6))\n        plt.subplot(1,2,1)\n        ax=sns.distplot(df1[l],hist=False,label='Approved',color='green')\n        ax=sns.distplot(df2[l],hist=False,label='Refused',color='red')\n        ax=sns.distplot(df3[l],hist=False,label='Canceled',color='orange')\n        plt.title(l,fontsize=20)\n        plt.xticks(fontsize=15) \n        plt.show()\n        return None\n        \nfor i in list_cat:\n    plots_numeric_univ_merged(i)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> \n\n> 1. Most of the approvals for the amount annuity variable are for the values less than 300000.\n\n> 2. Clients with lower credit amounts are having much approvals than those facing refusals.\n\n> 3. As the price amount of the goods increases there is an increase in loan applicaiton refusal.\n\n> 4. Clients with application amount within 0 to 1M have most number of approvals.","metadata":{}},{"cell_type":"code","source":"ord1= ['Approved','Refused','Canceled','Unused offer']\n\ndef plots_numeric_biv_merged(x,y,order=None):\n    \n    fig=plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,2,1)\n    \n    sns.scatterplot(data=merged_df, y = y, x = x,hue='NAME_CONTRACT_STATUS',palette=['g','r','yellow','white'],hue_order=order)\n    \n    plt.title(f'{x} vs {y}',fontsize=20)\n    \n    plt.xticks(fontsize=18)\n    \n    plt.yticks(fontsize=18)\n    \n    plt.show()\n    \n    return None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**AMT_ANNUITY_y vs AMT_CREDIT_y**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv_merged('AMT_ANNUITY_y','AMT_CREDIT_y',order=ord1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> AMT_ANNUITY_y and AMT_CREDIT_y have a correlation but not a strong one, most of the loan refusals are less than the amount annuity of 100000.","metadata":{}},{"cell_type":"markdown","source":"**AMT_GOODS_PRICE_y vs AMT_CREDIT_y**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv_merged('AMT_GOODS_PRICE_y','AMT_CREDIT_y',order=ord1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The correlation is strong between amount goods and amount credit continous variables and the distribution seems to be nearly equal for approval and refusal of loans. For the cancelled applications, it is more sparsely distributed for higher goods price.","metadata":{}},{"cell_type":"markdown","source":"**AMT_ANNUITY_y vs AMT_GOODS_PRICE_y**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv_merged('AMT_ANNUITY_y','AMT_GOODS_PRICE_y',order=ord1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> The correlation between AMT_ANNUITY_y and AMT_GOODS_PRICE_y is weak and it can be seen for higher goods price and amount annuity between 0 - 100000 there are highest number of refusals.","metadata":{}},{"cell_type":"markdown","source":"**AMT_GOODS_PRICE_y vs AMT_APPLICATION**","metadata":{}},{"cell_type":"code","source":"plots_numeric_biv_merged('AMT_GOODS_PRICE_y','AMT_APPLICATION',order=ord1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font> There is a pretty strong correlation between Goods Price and application. As the goods price amount increases, application amount increases linearly and the distribution of refusal loans seems to increase.","metadata":{}},{"cell_type":"code","source":"(merged_df.groupby('NAME_CONTRACT_STATUS')['TARGET'].value_counts(normalize=True)*100)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,8))\nsns.countplot(data=merged_df,x='NAME_CONTRACT_STATUS',hue='TARGET',palette='rocket')\nplt.legend(['Loan Repayers','Loan Defaulters'])\nplt.yscale('log')\nplt.xticks(fontsize=25)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font color='purple'>**Comment :**</font>\n\n> 1. Bank has approved the loan for approx 92% clients who can actually repay the loans without any trouble. On the other hand banks are approving loans for the clients who are most likely to default and their percentage is 7.6%.\n\n> 2. The clients are cancelling the applications from their side as they might be losing interest in taking the loan from the bank because of high price issues with the products as most of them are actually capable to pay the loans without any issue, hence dropping the product prices can attract more clients into loans.\n\n> 3. Bank is actually refusing the loans of those clients who can repay their loans easily without any issues and this percentage is 88%. So, bank needs to focus more on the clients like them.","metadata":{}},{"cell_type":"markdown","source":"## 7. Conclusion\nThis case study aims to identify patterns which indicate if a client has difficulty paying their instalments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc. We aim to understand the driving factors behind loan defaults for different types of applicants.\n\nAnalysis was conducted on the prospective clients based on the their current as well as previous application data. Recommendations and insights were provided for the same.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}