{"cells":[{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:30.647781Z","start_time":"2020-07-23T02:41:29.871948Z"},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization & Preprocess","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data load","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:30.670795Z","start_time":"2020-07-23T02:41:30.649811Z"},"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/world-happiness-report-2019/world-happiness-report-2019.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:30.679824Z","start_time":"2020-07-23T02:41:30.672612Z"},"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocess","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:30.686491Z","start_time":"2020-07-23T02:41:30.681708Z"},"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:30.697339Z","start_time":"2020-07-23T02:41:30.68799Z"},"trusted":true},"cell_type":"code","source":"# replace nan with mean\ndf.fillna(df.mean(), inplace=True)\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data visualization","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:31.192942Z","start_time":"2020-07-23T02:41:30.699346Z"},"trusted":true},"cell_type":"code","source":"#heatmap using seaborn\n#set the context for plotting \nsns.set(context=\"paper\", font=\"monospace\")\n#set the matplotlib figure\nfig, axe = plt.subplots(figsize=(12,8))\n#Generate color palettes \ncmap = sns.diverging_palette(220, 10, center=\"light\", as_cmap=True)\n#draw the heatmap\nsns.heatmap(df.corr(), vmax=1, square =True, cmap=cmap, annot=True ) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Dataset ","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:31.208Z","start_time":"2020-07-23T02:41:31.196965Z"},"trusted":true},"cell_type":"code","source":"X = df.drop(['Ladder', 'SD of Ladder', 'Country (region)'], axis=1)\ny = df['Ladder']\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:31.215897Z","start_time":"2020-07-23T02:41:31.210192Z"},"trusted":true},"cell_type":"code","source":"#data split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\nprint(\"X_train shape {} and size {}\".format(X_train.shape,X_train.size))\nprint(\"X_test shape {} and size {}\".format(X_test.shape,X_test.size))\nprint(\"y_train shape {} and size {}\".format(y_train.shape,y_train.size))\nprint(\"y_test shape {} and size {}\".format(y_test.shape,y_test.size))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling data","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:31.225846Z","start_time":"2020-07-23T02:41:31.218239Z"},"trusted":true},"cell_type":"code","source":"#Standardize training and test datasets.\n#==============================================================================\n# Feature scaling is to bring all the independent variables in a dataset into\n# same scale, to avoid any variable dominating  the model. Here we will not \n# transform the dependent variables.\n#==============================================================================\nindependent_scaler = StandardScaler()\nX_train = independent_scaler.fit_transform(X_train)\nX_test = independent_scaler.transform(X_test)\nprint(X_train[0:5,:])\nprint(\"test data\")\nprint(X_test[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:34:20.908569Z","start_time":"2020-07-23T02:34:20.906478Z"}},"cell_type":"markdown","source":"## Perform Random Forest Regression","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:31.235771Z","start_time":"2020-07-23T02:41:31.227576Z"},"trusted":true},"cell_type":"code","source":"# One Hot Encoding\nfeature = pd.get_dummies(X)\n# List of features for later use\nfeature_list = list(feature.columns)\nfeatures_num = np.size(feature_list)\n# Convert to numpy arrays\nfeatures = np.array(feature)\nprint(\"features numbers: \", features_num)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:36.38247Z","start_time":"2020-07-23T02:41:31.237796Z"},"trusted":true},"cell_type":"code","source":"# model apply\nntree_list = [10, 20, 50, 100, 200, 500, 1000]\nmtry_list = [int(0.5*features_num**0.5),\n             int(features_num**0.5), int(2*features_num**0.5)]\nbest_ntree = 0\nbest_mtry = 0\nbest_error = 9999999999999\nbest_model = None\nbest_y_pred = 0\ncount = 0\ntotal_models = len(ntree_list) * len(mtry_list)\nfor ntree in ntree_list:\n    for mtry in mtry_list:\n        count += 1\n        print(\"Training model %i out of %i...\" % (count, total_models))\n        print(\"ntree: %i, mtry: %i\" % (ntree, mtry))\n        rfg = RandomForestRegressor(n_estimators=ntree,\n                                    max_features=mtry,\n                                    bootstrap=True,\n                                    random_state=0)\n        rfg.fit(X_train, y_train)\n        # predict the test dataset\n        y_pred = rfg.predict(X_test)\n        # compute square root error\n        error = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n        if error < best_error:\n            best_ntree = ntree\n            best_mtry = mtry\n            best_error = error\n            best_model = rfg\n            print(\"Found new optimal model\")\n            print(best_model)\n            print(\"The error of model RFR : %6f\" % best_error)\n            print(\"best_ntree: %i, best_mtry: %i\" % (best_ntree, best_mtry))\n            print(\n                \"========================================================================\")\n# print optimal results\nprint(\"========================================================================\")\nprint('Finished tuning model')\nprint('Optimal model')\nprint(best_model)\nprint(\"The error of model RFR : %6f\" % best_error)\nprint(\"best_ntree: %i, best_mtry: %i\" % (best_ntree, best_mtry))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Result Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Predication VS Reality","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:37.174247Z","start_time":"2020-07-23T02:41:36.385055Z"},"trusted":true},"cell_type":"code","source":"# predict the test dataset\ny_pred = best_model.predict(X_test)\ntest = pd.DataFrame({'Predicted':y_pred, \n                     'Actual':y_test})\nfig= plt.figure(figsize=(16,8))\ntest = test.reset_index()\ntest = test.drop(['index'],axis=1)\nplt.plot(test[:50])\nplt.legend(['Actual','Predicted'])\nsns.jointplot(x='Actual',y='Predicted',data=test,kind=\"reg\", joint_kws={'line_kws':{'color':'red'}})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance","execution_count":null},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:37.190561Z","start_time":"2020-07-23T02:41:37.176255Z"},"trusted":true},"cell_type":"code","source":"# Get numerical feature importances\nimportances = list(best_model.feature_importances_)\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse=True)\n# Print out the feature and importances \n[print('Variable: {:20}    Importance: {}'.format(*pair)) for pair in feature_importances]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:37.197267Z","start_time":"2020-07-23T02:41:37.192692Z"},"trusted":true},"cell_type":"code","source":"def features(feature_importances):\n    # sorted importances of features\n    feature_list = [x[0] for x in feature_importances][::-1]\n    importances = [x[1] for x in feature_importances][::-1]\n    # list of x locations for plotting\n    y_values = list(range(len(importances)))\n    # Make a bar chart\n    plt.barh(y_values, importances, orientation = 'horizontal', color = 'r', edgecolor = 'k', linewidth = 1.2)\n    # Tick labels for x axis\n    plt.yticks(y_values, feature_list, rotation='horizontal')\n    # Axis labels and title\n    plt.xlabel('Importance') \n    plt.ylabel('Feature')\n    plt.title('Feature Importance')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-07-23T02:41:37.39217Z","start_time":"2020-07-23T02:41:37.199153Z"},"trusted":true},"cell_type":"code","source":"# feature importance\nfeatures(feature_importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}