{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Description: \n* **DOMAIN:** Smartphone, Electronics  \n\n* **CONTEXT:** India is the second largest market globally for smartphones after China. About 134 million smartphones were sold across India in the year 2017 and is estimated to increase to about 442 million in 2022. India ranked second in the average time spent on mobile web by smartphone users across Asia Pacific. The combination of very high sales volumes and the average smartphone consumer behaviour has made India a very attractive market for foreign vendors. As per Consumer behaviour, 97% of consumers turn to a search engine when they are buying a product vs. 15% who turn to social media. If a seller succeeds to publish smartphones based on user’s behaviour/choice at the right place, there are 90% chances that user will enquire for the same. This Case Study is targeted to build a recommendation system based on individual consumer’s behaviour or choice.\n\n* **DATA DESCRIPTION:**  \n• author : name of the person who gave the rating  \n• country : country the person who gave the rating belongs to  \n• data : date of the rating  \n• domain: website from which the rating was taken from  \n• extract: rating content  \n• language: language in which the rating was given  \n• product: name of the product/mobile phone for which the rating was given  \n• score: average rating for the phone  \n• score_max: highest rating given for the phone  \n• source: source from where the rating was taken  \n\n* **PROJECT OBJECTIVE:** We will build a recommendation system using popularity based and collaborative filtering methods to recommend mobile phones to a user which are most popular and personalised respectively.","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents <a id=\"toc\"></a>\n* [# Import Libraries](#import_libraries)  \n1. [Data Prepration and cleaning](#data_prepration)  \n    1.1. [Load the dataset](#load_data)  \n    1.2. [Merge dataset](#merge_data)  \n    1.3. [Basic Analysis](#basic_analysis)  \n    1.4. [Modification 1: revs1: Data cleaning, Imputation and rounding-off](#clean_impute_round-off)  \n    1.5. [Data split](#data_split)  \n2. [Analysis](#analysis)\n3. [Recommend top 5 mobile phones using popularity based model](#popularity_model)\n4. [Collaborative filtering based models](#collaborative_filtering)  \n    4.1 [SVD](#svd)  \n    4.2 [kNNWithMeans_Item based](#knnwithmeans_item_based)  \n    4.3 [kNNWithMeans_User based](#knnwithmeans_user_based)  \n5. [Show RMSE value and comparison](#rmse)  \n6. [Average ratings for test users](#average_rating)  \n7. [Summary (findings and Inferences)](#summary_inferences)\n8. [Recommend top 5 products for test users](#recommend_top_5)  \n9. [Results with cross_validation techniques](#cross_validation)  \n10. [In what business scenario you should use popularity based Recommendation Systems?](#q10)  \n11. [In what business scenario you should use CF based Recommendation Systems ?](#q11)\n12. [What other possible methods can you think of which can further improve the recommendation for different users ?](#q12)","metadata":{}},{"cell_type":"markdown","source":"## #. Import libraries <a id=\"import_libraries\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"markdown","source":"[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"# Main libraries\nimport os\nimport pandas as pd\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization libraries\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.express as px","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries for recommendation systems\nfrom collections import defaultdict\nfrom surprise import SVD\nfrom surprise import KNNWithMeans\nfrom surprise import Dataset\nfrom surprise import accuracy\nfrom surprise import Reader\nfrom surprise.model_selection import cross_validate\nfrom surprise.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install translate\n!pip install google-trans-new","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google_trans_new import google_translator\nfrom translate import Translator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"display.max_rows\", 50, \"display.max_columns\", 50)\npd.set_option('display.max_colwidth', None)\nplt.style.use('bmh')\n# create contants\nRS=612","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data preparation and basic cleaning <a id=\"data_prepration\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"markdown","source":"[Go to top](#toc)","metadata":{}},{"cell_type":"markdown","source":"### 1.1.  Load the dataset <a id=\"load_data\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"%%time\n#Loading Data files\nreview_1 = pd.read_csv('../input/recommendation-system/phone_user_review_file_1.csv', encoding='iso-8859-1')\nreview_2 = pd.read_csv('../input/recommendation-system/phone_user_review_file_2.csv', encoding='iso-8859-1')\nreview_3 = pd.read_csv('../input/recommendation-system/phone_user_review_file_3.csv', encoding='iso-8859-1')\nreview_4 = pd.read_csv('../input/recommendation-system/phone_user_review_file_4.csv', encoding='iso-8859-1')\nreview_5 = pd.read_csv('../input/recommendation-system/phone_user_review_file_5.csv', encoding='iso-8859-1')\nreview_6 = pd.read_csv('../input/recommendation-system/phone_user_review_file_6.csv', encoding='iso-8859-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'review_1: Rows: {review_1.shape[0]} and Columns: {review_1.shape[1]}\\n')\nprint(f'review_2: Rows: {review_2.shape[0]} and Columns: {review_2.shape[1]}\\n')\nprint(f'review_3: Rows: {review_3.shape[0]} and Columns: {review_3.shape[1]}\\n')\nprint(f'review_4: Rows: {review_4.shape[0]} and Columns: {review_4.shape[1]}\\n')\nprint(f'review_5: Rows: {review_5.shape[0]} and Columns: {review_5.shape[1]}\\n')\nprint(f'review_6: Rows: {review_6.shape[0]} and Columns: {review_6.shape[1]}\\n')\nprint(f'Total rows: {review_1.shape[0]+review_2.shape[0]+review_3.shape[0]+review_4.shape[0]+review_5.shape[0]+review_6.shape[0]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Check whether the column names are same in all the dataframes: ')\nall(np.unique(review_1.columns.tolist()) == np.unique(review_1.columns.tolist()+\n                                                      review_2.columns.tolist()+\n                                                      review_3.columns.tolist()+\n                                                      review_4.columns.tolist()+\n                                                      review_5.columns.tolist()+\n                                                      review_6.columns.tolist()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2. Merge dataset <a id=\"merge_data\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"#Merge the data into a single dataframe \nreviews = pd.concat([review_1,review_2,review_3,review_4,review_5,review_6], ignore_index=True)\ndel review_1, review_2, review_3, review_4, review_5, review_6\nprint(f'reviews: Rows: {reviews.shape[0]} and Columns: {reviews.shape[1]}\\n')\nprint('Top 5 rows of the data: ')\ndisplay(reviews.head())\nprint('Bottom 5 rows of the data: ')\ndisplay(reviews.tail())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviews.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Except **score** and **score_max** (which are of float type) all other features are of object type \n* feature **date** should be of datetype\n* Also, **score, score_max, extract and author**: columns seems to have Null values","metadata":{}},{"cell_type":"markdown","source":"### 1.3. Basic analysis <a id=\"basic_analysis\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"df=reviews.isna().sum().round(2)\ndf1 = (df*100/reviews.shape[0]).round(2)\nprint('Missing count and percentages for each column are: \\n',df.astype('str') +' ('+ df1.astype('str')+'%)')\n\n#fig = px.bar(x=df.index, y=df1,text = df.astype('str') +'('+ df1.astype('str')+'%)',\n#             title=\"Count (text) and Percentage(yaxis) of missing values in all the features (data: reviews)\")\n#fig.update_xaxes(title_text= 'Features')\n#fig.update_yaxes(title_text= 'Percentage of Missing values')\n#fig.show()\ndel df, df1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus these three features have approx 4.5% missing values\n'score' and 'score_max' have exactly same number of missing values","metadata":{}},{"cell_type":"code","source":"print('Number of unique values in each feature: \\n',reviews.nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"i.e. score_max for all the phones is 10 throughout.","metadata":{}},{"cell_type":"code","source":"# Top 10 Non-english users\nreviews[reviews['lang']!='en']['author'].value_counts(ascending=False)[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 10 Non-english products\nreviews[reviews['lang']!='en']['product'].value_counts(ascending=False)[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, a multiple similar names, with different details exist in product list. For eg:  \n* Huawei P8lite zwart / 16 GB and  \n* Huawei P8 Lite Smartphone, Display 5\" IPS, Processore Octa-Core 1.5 GHz, Memoria Interna da 16 GB, 2 GB RAM, Fotocamera 13 MP, monoSIM, Android 5.0, Bianco [Italia]  \nare exactly same models","metadata":{}},{"cell_type":"markdown","source":"Another observation is that 'phone_url' column also contains the phone name and model information. Let's check what extra information is present in 'product column'","metadata":{}},{"cell_type":"code","source":"# print the frequency count of phone_url column\nreviews['phone_url'].value_counts(ascending=False).head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frequency count of 'product' column for 'samsung-galaxy-s-iii' type phone\nreviews[reviews[\"phone_url\"]=='/cellphones/samsung-galaxy-s-iii/'][['product']].value_counts().head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Exra information is generally:  \n* phone memory: 8Gb/16GB/32GB etc\n* phone colour: Marble white, Blue, Red etc\n* carrier: AT&T, Verizon etc\n\nAnother observation is that these specifications are not present in all the product names, for eg: \nthere is no-way available to differentiate between the 2 products below:  \n'Samsung Galaxy S III Cellular Phone' and   \n'Samsung Galaxy S III SPH-L710 - 16GB - Marble White (Sprint) Smartphone'\n\nThus differentiating information is not same in all the product details. \nAlso, the goal is to recommend a phone not the carrier. and other specs like color etc are of low importance in recommendation. The only consistent differentiating information in all the product names is the 'phone manufacturer and model number', which can also be extracted from 'phone_url' column.\nLet's check for other phone names as well","metadata":{}},{"cell_type":"code","source":"# frequency count of 'product' column for 'apple-iphone-5s' type phone\nreviews[reviews[\"phone_url\"]=='/cellphones/apple-iphone-5s/'][['product']].value_counts().head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frequency count of 'product' column for 'samsung-galaxy-s6' type phone\nreviews[reviews[\"phone_url\"]=='/cellphones/samsung-galaxy-s6/'][['product']].value_counts().head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frequency count of 'product' column for 'samsung-galaxy-s5' type phone\nreviews[reviews[\"phone_url\"]=='/cellphones/samsung-galaxy-s5/'][['product']].value_counts().head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As can be seen, same pattern is visible for the most comun types of phones. Thus it is better to use phone name and model number rather than other details mentioned in 'product' column","metadata":{}},{"cell_type":"code","source":"reviews['phone'] = reviews['phone_url'].str.split(\"/\").apply(lambda col: col[2]).replace('-', ' ', regex=True)\nreviews['product'] = reviews['phone']\nreviews['phone'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviews['product'].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product = reviews['product'].value_counts()[:10]\nprint('Distribution of number of ratings per item (Clipped at 10): \\n',product)\nsns.barplot(y=product.index,x=product)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users = reviews['author'].value_counts(dropna=False)[:10]\nprint('Distribution of number of ratings per user(Clipped at 10): \\n',users)\nusers.index = users.index.map(str)\nsns.barplot(y=users.index,x=users)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Following observations are made:  \n1. Most active user is 'Amazon customer'\n2. 'Anonymous' and 'unknown' users are those whose names are not known. Thus we can use this to impute blank values in 'author' column\n3. Many names are similar but in different languages like 'Amazon customer' and 'Cliente Amazon'. Let's search for these first and cleanup the differences due to language","metadata":{}},{"cell_type":"markdown","source":"names like 'einer Kundin', 'einem Kunden','Anonymous' and 'unknown' can be interpreted in the same way i.e. an 'unknown customer'. Let's replace these names too","metadata":{}},{"cell_type":"code","source":"unknowns = ['Anonymous','einer Kundin','einem Kunden', 'unknown','Anonymous ']\nreviews['author'].replace(to_replace = unknowns, \n                          value = 'Anonymous', \n                          inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users = reviews['author'].value_counts(dropna=False)[:10]\nprint('Distribution of number of ratings per user(Clipped at 10): \\n',users)\nusers.index = users.index.map(str)\nsns.barplot(y=users.index,x=users)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the score column of the data\nprint('Uniqe values in the \"score\" feature: \\n',reviews.score.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's round it off to nearest integer","metadata":{}},{"cell_type":"code","source":"relevant_features=['author','product','score']\n# irrelvant_features=['phone_url','date','lang','country','source','domain','score_max','extract']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of duplicate rows: ', reviews.duplicated().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orgnl_rows = reviews.shape[0]\norgnl_columns = reviews.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4. Modification 1: revs1: Data cleaning, Imputation and rounding-off <a id=\"clean_impute_round-off\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"revs1 = reviews.copy()\n\n# Delete data which is not useful anymore, to save memory\ndel reviews\n\n# Step1: remove irrelevant features\nrevs1 = revs1.loc[:,relevant_features]\nprint(f'Step1: revs1 Shape after removing irrelevant features: Rows: {revs1.shape[0]} and Columns: {revs1.shape[1]}\\n')\n\n# Step2: Round-off score feature to nearest integer\nrevs1['score'] = revs1['score'].round(0).astype('Int64')\nprint('Step2: Round-off: Unique values in the \"score\" feature(after rounding-off): \\n',list(revs1.score.unique()))\n\n# Step3: Impute missing values in score feature with median\nrevs1['score'] = revs1['score'].fillna(revs1['score'].median())\nprint('\\nStep3: Imputation of \"score\"  with median and \"author\" with \"Anonymous\"')\n\n# Step4: remove samples with missing values in 'Product' and 'author' feature and also 'Anonymous' values\nrevs1.dropna(inplace=True)\nrevs1 = revs1[revs1[\"author\"] != 'Anonymous']\nprint(f'\\nStep4: revs1 Shape(after removing missing values): Rows: {revs1.shape[0]} and Columns: {revs1.shape[1]}\\n')\n\n# Step5: remove duplicates, if any\nrevs1 = revs1.drop_duplicates()\nprint(f'Step5: revs1 Shape(after removing duplicates): Rows: {revs1.shape[0]} and Columns: {revs1.shape[1]}\\n')\n\nprint(f'Overall {round(100 - revs1.shape[0]*100/orgnl_rows,2)}% samples are dropped\\n')\nrevs1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.5. Data split <a id=\"data_split\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"# separate 1 million data samples\nrevs_1m = revs1.sample(n=1000000, random_state=RS)\nprint(f'revs2 Shape: Rows: {revs_1m.shape[0]} and Columns: {revs_1m.shape[1]}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Analysis <a id=\"analysis\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"# 1. Most rated features\nprint('Most rated features/products: \\n\\n',revs_1m['product'].value_counts().head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find out which rating is given highest number of times\nsns.countplot(data=revs_1m , x='score')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"revs1[revs1['score']==10]['author'].value_counts().head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Users with highest number of reviews\nprint('Users with highest number of reviews: \\n\\n',revs_1m['author'].value_counts().head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Select data with products having >50 ratings and users who have given > 50 ratings\nauthor50 = revs1['author'].value_counts()\nauthor50 = author50[author50>50].index.tolist() # list of authors with > 50 ratings\nprint('Number of authors who have given >50 rating: ', len(author50))\n\nproduct50 = revs1['product'].value_counts()\nproduct50 = product50[product50>50].index.tolist() # list of products with > 50 ratings\nprint('Number of products with >50 rating: ', len(product50))\n\nrevs_50 = revs1[(revs1['author'].isin(author50)) & (revs1['product'].isin(product50))]\nprint(f'\\nrevs_50: Rows: {revs_50.shape[0]} and Columns: {revs_50.shape[1]}\\n')\ndel author50, product50\nrevs_50.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"revs_50['author'].unique()[:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"revs_50['product'].unique()[:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#target = 3000\ntop50_product = revs1['product'].value_counts()[0:50].rename('rating_count').to_frame()\ntop50_product['mean_ratings']=revs1[revs1['product'].isin(top50_product.index.tolist())].groupby(['product'])['score'].mean().astype('float64').round(1)\ntop50_product.sort_values(by='mean_ratings',inplace=True)\nprint('Number of products with >'+str(target)+' rating: ', len(top50_product))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter(top50_product, x=top50_product.index, y=\"mean_ratings\", size=\"rating_count\", size_max=60,\n                  height=800,title=\"Visualisation of mean ratings vs rating count for highest rated 50 phones\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Recommend top 5 mobile phones using popularity based model <a id=\"popularity_model\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"def popularity_rec(data):\n    ratings_mean_count = pd.DataFrame(data.groupby('product')['score'].mean())\n    ratings_mean_count['rating_counts'] = data.groupby('product')['score'].count()\n    ratings_mean_count = ratings_mean_count.sort_values(by=['score','rating_counts'], ascending=[False,False])\n    print('Top 5 recommendations for the products are: \\n')\n    display(ratings_mean_count.head())\n    return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the data from the most popular phones amongst the most frequent users\npopularity_rec(revs_50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if we consider the original data (excluding 'Anonymous' users)\npopularity_rec(revs1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"field_length = revs1.author.astype(str).map(len)\nprint (revs1.iloc[field_length.argmax(),0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Collaborative filtering based models <a id=\"collaborative_filtering\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"markdown","source":"### 4.1. Collaborative filtering model using SVD <a id=\"svd\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"# Rearrange columns for SVD and prepare train and testsets\nrevs50_ = Dataset.load_from_df(revs_50[['author','product','score']], Reader(rating_scale=(1, 10)))\ntrainset, testset = train_test_split(revs50_, test_size=.25,random_state=RS)\n\nprint('top 3 values from trainset: \\n')\nfor key,value in {k: v for k, v in trainset.ur.items() if k <= 2}.items(): print(key,'-> ',value,'\\n')\nprint('\\ntop 3 values from testset: ', *testset[0:3], sep='\\n\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Objective: To get top_n recommendation for each user\ndef get_top_n(predictions, n=5):\n    # First map the predictions to each user.\n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # Then sort the predictions for each user and retrieve the n highest ones.\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n\n    return top_n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# fit and predict using svd\ndef svd_func(train, test):\n    svd = SVD(random_state=RS)\n    svd.fit(train)\n    svd_pred = svd.test(test)\n    return svd_pred, svd\n\nsvd_pred, svd = svd_func(trainset,testset)\nprint('First few prediction values: \\n',svd_pred[0:2])\nprint('\\nRMSE value(test-set): ',round(accuracy.rmse(svd_pred),2),'\\n') # compute RMSE\nsvd_rmse = round(accuracy.rmse(svd_pred),2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Collaborative filtering model using kNNWithMeans_Item based <a id=\"knnwithmeans_item_based\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"%%time\n# fit and predict using knn\ndef knn_item(train, test):\n    knn_i = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': False})\n    knn_i.fit(train)\n    knn_i_pred = knn_i.test(test)\n    return knn_i_pred, knn_i\n\nknn_i_pred, knn_i = knn_item(trainset, testset)\nprint('First few prediction values: \\n',knn_i_pred[0:2])\nprint('\\nRMSE value(Item-based Model, test-set): ',round(accuracy.rmse(knn_i_pred),2),'\\n') # compute RMSE\nknn_i_rmse = round(accuracy.rmse(knn_i_pred),2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. Collaborative filtering model using kNNWithMeans_User based <a id=\"knnwithmeans_user_based\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"%%time\n# fit and predict using knn\ndef knn_user(train, test):\n    knn_u = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})\n    knn_u.fit(train)\n    knn_u_pred = knn_u.test(test)\n    return knn_u_pred, knn_u\n\nknn_u_pred, knn_u = knn_user(trainset, testset)\nprint('First few prediction values: \\n',knn_u_pred[0:2])\nprint('\\nRMSE value(User-based Model, test-set): ',round(accuracy.rmse(knn_u_pred),2),'\\n') # compute RMSE\nknn_u_rmse = round(accuracy.rmse(knn_u_pred),2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Show RMSE value and comparison <a id=\"rmse\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"# Comparison of RMSE scores from different collaorative algorithms\nsns.barplot(x=['svd_rmse','knn_i_rmse', 'knn_u_rmse'],y=[svd_rmse,knn_i_rmse, knn_u_rmse])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best RMSE score is given by knn (item based), so let's use it for further analyssi","metadata":{}},{"cell_type":"markdown","source":"## 6. Average ratings for test users <a id=\"average_rating\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"svd_pred_df=pd.DataFrame(svd_pred, columns=['uid', 'iid', 'rui', 'est', 'details'])\nprint('average prediction for test users: ',svd_pred_df['est'].mean())\nprint('average rating  by test users: ',svd_pred_df['rui'].mean())\nprint('average prediction error for test users: ',(svd_pred_df['rui']-svd_pred_df['est']).abs().mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_i_pred_df=pd.DataFrame(knn_i_pred, columns=['uid', 'iid', 'rui', 'est', 'details'])\nprint('average prediction for test users: ',knn_i_pred_df['est'].mean())\nprint('average rating  by test users: ',knn_i_pred_df['rui'].mean())\nprint('average prediction error for test users: ',(knn_i_pred_df['rui']-knn_i_pred_df['est']).abs().mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn_u_pred_df=pd.DataFrame(knn_u_pred, columns=['uid', 'iid', 'rui', 'est', 'details'])\nprint('average prediction for test users: ',knn_u_pred_df['est'].mean())\nprint('average rating  by test users: ',knn_u_pred_df['rui'].mean())\nprint('average prediction error for test users: ',(knn_u_pred_df['rui']-knn_u_pred_df['est']).abs().mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Summary (findings and Inferences) <a id=\"summary_inferences\"></a>\n[Go to top](#toc)\n\n1. Most popular phone (rated 10 by highest number of people):  \n        * Overall: verykool t742\n        * Amongst top users: samsung e1120       \n2. Overall data is highly skewed towards 'Amazon customers' from different countries. This may also be because 'Amazon' is the biggest trader for phones in the world. Although correct 'user' names from 'Amazon' should have used.\n3. Most of the authors have given the rating of '10' or '8'\n4. Both knn_i(item-based) and knn_u(user-based) have roughly similar RMSE","metadata":{}},{"cell_type":"markdown","source":"## 8. Recommend top 5 products for test users <a id=\"recommend_top_5\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"%%time\n#recommend top 5 products for test users\ntop_5 = get_top_n(knn_i_pred,5)\nprint('Top 5 recommendations for all test users are: \\n')\nfor key,value in top_5.items(): print(key,'-> ',value,'\\n') # to print all the recommendations for all the users\n#print('Top 5 recommendations for 3 users are: \\n')\n#for key,value in {k: v for k, v in top_5.items() if k in ['Amazon Customer','Cliente Amazon',\"Client d'Amazon\"]}.items(): print(key,'-> ',value,'\\n')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Results with cross_validation techniques <a id=\"cross_validation\"></a>\n[Go to top](#toc)","metadata":{}},{"cell_type":"code","source":"%%time\nsvd_cv = cross_validate(svd,revs50_, measures=['RMSE'], cv=5, verbose=False)\nprint('\\n Mean svd cv score:', round(svd_cv['test_rmse'].mean(),2),'\\n')\nsvd_cv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nknn_i_cv = cross_validate(knn_i,revs50_, measures=['RMSE'], cv=5, verbose=False)\nprint('\\n Mean knn_i_cv score:', round(knn_i_cv['test_rmse'].mean(),2),'\\n')\nknn_i_cv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nknn_u_cv = cross_validate(knn_u,revs50_, measures=['RMSE'], cv=5, verbose=False)\nprint('\\n Mean knn_u_cv score:', round(knn_u_cv['test_rmse'].mean(),2),'\\n')\nknn_u_cv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparison of RMSE scores(mean cv) from different collaorative algorithms\nsns.barplot(y=['svd_cv_rmse','knn_i_cv_rmse', 'knn_u_cv_rmse'],\n            x=[svd_cv['test_rmse'].mean(),knn_i_cv['test_rmse'].mean(), knn_u_cv['test_rmse'].mean()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, for cv scores too, knn_i is giving a better performance","metadata":{}},{"cell_type":"markdown","source":"**10: In what business scenario you should use popularity based Recommendation Systems ?** <a id=\"q10\"></a>\n[Go to top](#toc)\n\n> Popularity based recommendation systems can be useful in multiple scenarios like:  \n> 1. When there is no data about the user and items.\n> 2. When it is required to show most popular items in different categories along with personalized results like: \n>     * Most popular punjabi songs or most popular english songs on a music website/app\n>     * Most popular trend in cwestern wear or traditional wear\n>     * Most popular holiday packages for honeymoon trips, or bike trips or himalayan trips etc","metadata":{}},{"cell_type":"markdown","source":"**11: In what business scenario you should use CF based Recommendation Systems ?**  <a id=\"q11\"></a>\n[Go to top](#toc)\n> Collaborative filtering is useful in scenarios like: \n> 1. Giving personalised recommendation to the user, when user history or item data is available. Some examples can be:\n>     * Personalized movie recommendation of movie sites like Netflix, Amazon Prime, Youtube etc","metadata":{}},{"cell_type":"markdown","source":"**12: What other possible methods can you think of which can further improve the recommendation for different users ?**  <a id=\"q12\"></a>\n[Go to top](#toc)\n> Other from Popularity and Collaborative Filtering, hybrid recommendation methods like Content+Collaborative method, Demographic, Utility based, and Knowledge based recommendation system can also be used.","metadata":{}}]}