{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set(style=\"white\")\nimport matplotlib.pyplot as plt\n\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, normalize\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load csv as pandas frame and drop useless columns\ndata = pd.read_csv('../input/churn-for-bank-customers/churn.csv', index_col='RowNumber')\\\n    .drop(['Surname', 'CustomerId'], axis=1)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Geography'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# converts categorical features to integers\ndef label_encoder(data_: pd.DataFrame(), columns_name_: list):\n    le = LabelEncoder()\n    for i in columns_name_:\n        le.fit(data_[i])\n        data_[i] = le.transform(data_[i])\n    return data_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = label_encoder(data, ['Geography', 'Gender'])\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.CreditScore.describe())\n\nplt.title('CreditScore')\nplt.hist(data.CreditScore)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.Balance.describe())\n\nplt.title('Balance')\nplt.hist(data.Balance)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.EstimatedSalary.describe())\n\nplt.title('EstimatedSalary')\nplt.hist(data.EstimatedSalary)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Exited')\n\nsns.barplot(x=data['Exited'].value_counts().keys(),\n            y=data['Exited'].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Tenure')\n\nsns.barplot(x=data['Tenure'].value_counts().keys(),\n            y=data['Tenure'].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Gender')\n\nsns.barplot(x=['male', 'female'],\n            y=data['Gender'].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('NumOfProducts')\n\nsns.barplot(x=data['NumOfProducts'].value_counts().keys(),\n            y=data['NumOfProducts'].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('HasCrCard')\n\nsns.barplot(x=data['HasCrCard'].value_counts().keys(),\n            y=data['HasCrCard'].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('IsActiveMember')\n\nsns.barplot(x=data['IsActiveMember'].value_counts().keys(),\n            y=data['IsActiveMember'].value_counts().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Min:', data['Age'].min(),\n      '\\nMax:', data['Age'].max())\nval_count = data['Age'].value_counts()\nplt.title('Age')\nplt.plot([i for i in range(data['Age'].min(), data['Age'].max() + 1)],\n         [val_count[i] if i in val_count else 0 for i in range(data['Age'].min(), data['Age'].max() + 1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=['France', 'Germany', 'Spain'],\n            y=[*data['Geography'].value_counts().values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation table\n\ncorr = data.corr()\nf, ax = plt.subplots(figsize=(10, 10))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, mask=None, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data, hue=\"Exited\", palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data on train, val and test\nx_tr, x_te, y_tr, y_te = train_test_split(\n    data.iloc[:, :-1], data['Exited'], random_state=42, test_size=0.2, shuffle=True)\nx_tr, x_val, y_tr, y_val = train_test_split(\n    x_tr, y_tr, random_state=42, test_size=0.2, shuffle=True)\nprint(x_tr.shape)\nprint(x_val.shape)\nprint(x_te.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train models and predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_score = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate auc (if possible), accuracy, f-metric and recall; return pandas frame\ndef calc_score(y_true, y_pred, y_pred_proba=None):\n    return pd.DataFrame(data={'metrics': ['auc', 'acc', 'f1', 'recall'],\n                              'single model': [roc_auc_score(y_true, y_pred_proba).round(3)\\\n                                               if y_pred_proba is not None else '-',\n                                               accuracy_score(y_true, y_pred).round(3),\n                                               f1_score(y_true, y_pred).round(3),\n                                               recall_score(y_true, y_pred).round(3)]})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test sklearn models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\n\n# coss-validation\ndef kfold(model, split: int, X, y, x_test):\n    \"\"\"\n    :param model: sklearn model\n    :param split: number of folds\n    :param X: train data\n    :param y: target\n    :param x_test: test data, which need to predict\n    :return: np.array with predictions on x_test\n    \"\"\"\n    pred_cross_val = []\n    # init KFold\n    kf = KFold(n_splits=split, shuffle=False)\n    kf.get_n_splits(X)\n    for train_index, test_index in kf.split(X):\n        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        # init new model with same parameters\n        model_ = copy.copy(model)\n        model_.fit(X_train, y_train)\n        pred_cross_val.append(model_.predict(x_test))\n    # mean prediction\n    pred_cross_val = np.array(pred_cross_val).mean(axis=0)\n    pred_cross_val = np.around(pred_cross_val)\n    return pred_cross_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LogReg model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_tr, y_tr)\n# calculate score for single model on validation sample\nscore = calc_score(y_val, lr.predict(x_val))\n\n# predict and calculate score for cross-validation model on validation sample\npred_cross_val = kfold(LogisticRegression(), 2, x_tr.values, y_tr.values, x_val)\n# add column 'cross. val. model' in score\nscore['cross. val. model'] = calc_score(y_val, pred_cross_val)['single model']\n\n# predict and calculate score for cross-validation model on test sample\npred_cross_val = kfold(LogisticRegression(), 2, x_tr.values, y_tr.values, x_te)\nfinal_score['LogisticRegression'] = calc_score(y_te, pred_cross_val)['single model'][1]\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(10)\nknn.fit(x_tr, y_tr)\n# calculate score for single model on validation sample\nscore = calc_score(y_val, knn.predict(x_val))\n\n# predict and calculate score for cross-validation model on validation sample\npred_cross_val = kfold(KNeighborsClassifier(10), 2, x_tr.values, y_tr.values, x_val)\nscore['cross. val. model'] = calc_score(y_val, pred_cross_val)['single model']\n\n# predict and calculate score for cross-validation model on test sample\npred_cross_val = kfold(KNeighborsClassifier(10), 2, x_tr.values, y_tr.values, x_te)\nfinal_score['KNeighborsClassifier'] = calc_score(y_te, pred_cross_val)['single model'][1]\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test gradboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\ncatb = CatBoostClassifier(learning_rate=0.1, boosting_type='Ordered', verbose=0)\ncatb.fit(x_tr, y_tr, eval_set=(x_val, y_val), use_best_model=True)\n\n# predict and calculate score for single model on validation sample\nscore = calc_score(y_val, catb.predict(x_val), catb.predict_proba(x_val)[:, 1])\n\n# predict and calculate score for cross-validation model on test sample\nfinal_score['CatBoostClassifier'] = calc_score(y_te, catb.predict(x_te),\n                                        catb.predict_proba(x_te)[:, 1])['single model'][1]\n\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(learning_rate=0.1, n_estimators=100)\nlgbm.fit(x_tr, y_tr)\n\n# predict and calculate score for single model on validation sample\nscore = calc_score(y_val, lgbm.predict(x_val), lgbm.predict_proba(x_val)[:, 1])\n\n# predict and calculate score for cross-validation model on test sample\nfinal_score['LGBMClassifier'] = calc_score(y_te, lgbm.predict(x_te),\n                                              lgbm.predict_proba(x_te)[:, 1])['single model'][1]\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradboost ensemble","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = []\npred_proba = []\npred.append(catb.predict(x_te))\npred_proba.append(catb.predict_proba(x_te)[:, 1])\npred.append(lgbm.predict(x_te))\npred_proba.append(lgbm.predict_proba(x_te)[:, 1])\n# mean prediction\npred = np.array(pred).mean(axis=0).round()\npred_proba = np.array(pred_proba).mean(axis=0)\n\n# calculate ensemble score\ncalc_score(y_te, pred, pred_proba)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Neural Networks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import Dense, Dropout, LeakyReLU\nfrom keras import Sequential\nfrom keras.metrics import Accuracy, AUC\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss and auc on each epoch\ndef ploting(history):\n    # print(history.history.keys())\n    ac = []\n    for i in history.history.keys():\n        ac.append(i)\n    loss = history.history[ac[0]]\n    val_loss = history.history[ac[2]]\n    acc = history.history[ac[1]]\n    val_acc = history.history[ac[3]]\n    epochs = range(1, len(loss) + 1)\n    fig = plt.figure(figsize=(10, 10))\n    ax1 = fig.add_subplot(2, 1, 1)\n    ax2 = fig.add_subplot(2, 1, 2)\n    ax1.plot(epochs, loss, 'bo', label='Training loss')\n    ax1.plot(epochs, val_loss, 'b', label='Validation loss', color='r')\n    ax1.set_title('Training and validation loss')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n    ax2.plot(epochs, acc, 'bo', label='Training acc')\n    ax2.plot(epochs, val_acc, 'b', label='Validation acc', color='r')\n    ax2.set_title('Training and validation accuracy')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('AUC')\n    ax2.legend()\n    for ax in fig.axes:\n        ax.grid(True)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare data for NN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize and split data on train, val and test\nscaler = StandardScaler()\nscaler.fit(data.iloc[:, :-1])\n\nx_tr, x_te, y_tr, y_te = train_test_split(\n    data.iloc[:, :-1], data['Exited'], random_state=42, test_size=0.2, shuffle=True)\nx_tr, x_val, y_tr, y_val = train_test_split(\n    x_tr, y_tr, random_state=42, test_size=0.2, shuffle=True)\nprint(x_tr.shape)\nprint(x_val.shape)\nprint(x_te.shape)\n\nx_tr = scaler.transform(x_tr)\nx_val = scaler.transform(x_val)\nx_te = scaler.transform(x_te)\n\ny_tr = y_tr.values.reshape(-1, 1)\ny_val = y_val.values.reshape(-1, 1)\ny_te = y_te.values.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create model","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"activation = LeakyReLU(alpha=0.2)\n\n# create model\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=x_tr.shape[-1], activation=activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(32, activation=activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(16, activation=activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(8, activation=activation))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nprint(model.summary())\n\n# compile model\nmodel.compile(optimizer=Adam(lr=0.001),\n              loss='binary_crossentropy',\n              metrics=[AUC()])\n\n# fit model\nhist = model.fit(x_tr, y_tr,\n          batch_size=64, epochs=150,\n          validation_data=(x_val, y_val), verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting(hist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score = calc_score(y_val,\n                      model.predict(x_val).reshape(-1).round(),\n                      model.predict(x_val).reshape(-1))\nfinal_score['NeuroClassifier'] = calc_score(y_te,\n                model.predict(x_te).reshape(-1).round(),\n                model.predict(x_te).reshape(-1))['single model'][1]\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Convolution Neural Networks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import (Dropout, LeakyReLU, Conv1D,\n                          MaxPooling1D, GlobalAveragePooling1D, BatchNormalization)\nfrom keras import Sequential\nfrom keras.metrics import Accuracy, AUC\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create model","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"activation = 'sigmoid'\n\nmodel = Sequential()\nmodel.add(Conv1D(64, 3, input_shape=(10, 1), padding='same', activation=activation))\nmodel.add(MaxPooling1D(2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Conv1D(64, 3, padding='same', activation=activation))\nmodel.add(MaxPooling1D(2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(GlobalAveragePooling1D())\n#model.add(Dropout(0.25))\nmodel.add(Dense(1, activation='sigmoid'))\n\nprint(model.summary())\n\nmodel.compile(optimizer=Adam(lr=0.001),\n              loss='binary_crossentropy',\n              metrics=[AUC()])\n\nprint(x_tr.reshape(-1, x_tr.shape[1], 1).shape)\nprint(x_val.reshape(-1, x_tr.shape[1], 1).shape)\nhist = model.fit(x_tr.reshape(-1, x_tr.shape[1], 1), y_tr,\n          batch_size=256, epochs=200,\n          validation_data=(x_val.reshape(-1, x_val.shape[1], 1),\n                           y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ploting(hist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"score = calc_score(y_val,\n                      model.predict(x_val.reshape(-1, x_tr.shape[1], 1)).reshape(-1).round(),\n                      model.predict(x_val.reshape(-1, x_tr.shape[1], 1)).reshape(-1))\nfinal_score['CNNClassifier'] = calc_score(y_te,\n                model.predict(x_te.reshape(-1, x_tr.shape[1], 1)).reshape(-1).round(),\n                model.predict(x_te.reshape(-1, x_tr.shape[1], 1)).reshape(-1))['single model'][1]\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models' rating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort models' score\nimport operator\nsort_dict = sorted(final_score.items(), key=operator.itemgetter(1), reverse=True)\nsort_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rating\ndef visualize(column=0):\n    y = [x[1] for x in sort_dict]\n    labels = [x[0] for x in sort_dict]\n    shift = 0.78\n    plt.figure(figsize=(15, 10))\n    graph = sns.barplot(x=(np.asarray(y) - shift), y=labels,\n                        palette=sns.color_palette(\"RdYlGn_r\", len(y)),\n                        edgecolor=\".2\", linewidth=2)\n    plt.xticks([i / 100 for i in range(0, 11)], [\"%.2f\" % (i / 100 + shift) for i in range(0, 11)])\n    for i, v in enumerate(y):\n        graph.text(v - shift - 0.009, i + 0.05, \"%.4f\" % v, color='darkslategray', fontweight='bold', size=14)\n    plt.title('Rating accuracy')\n    plt.show()\n\nvisualize(0)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}