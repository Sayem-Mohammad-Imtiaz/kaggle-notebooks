{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T15:22:34.64078Z","iopub.execute_input":"2021-05-29T15:22:34.641423Z","iopub.status.idle":"2021-05-29T15:22:41.383454Z","shell.execute_reply.started":"2021-05-29T15:22:34.641311Z","shell.execute_reply":"2021-05-29T15:22:41.382267Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Library\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nimport numpy as np\nfrom pydub import AudioSegment\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras.models as models\nimport tensorflow.keras.layers as layers\nimport IPython\nimport sklearn\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom tqdm import tqdm\nimport IPython.display as ipd\n\n%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:20:32.918542Z","iopub.execute_input":"2021-05-29T16:20:32.919004Z","iopub.status.idle":"2021-05-29T16:20:32.931233Z","shell.execute_reply.started":"2021-05-29T16:20:32.918967Z","shell.execute_reply":"2021-05-29T16:20:32.929958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datasets chainsaw and crackling fire\nPATH_CHAINSAW = \"../input/environmental-sound-classification-50/audio/audio/16000/\"\nCSV_CHAINSAW = \"../input/environmental-sound-classification-50/esc50.csv\"\n\n#datasets gun shot\nCSV_GUNSHOT = \"../input/urbansound8k/UrbanSound8K.csv\" ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.033971Z","iopub.execute_input":"2021-05-29T15:22:51.034304Z","iopub.status.idle":"2021-05-29T15:22:51.039023Z","shell.execute_reply.started":"2021-05-29T15:22:51.034272Z","shell.execute_reply":"2021-05-29T15:22:51.037834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read csv\ndf_chainsaw = pd.read_csv(CSV_CHAINSAW)\ndf_gunshot = pd.read_csv(CSV_GUNSHOT)\n\nprint(df_chainsaw.head())\nprint(df_gunshot.head())","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.041012Z","iopub.execute_input":"2021-05-29T15:22:51.041338Z","iopub.status.idle":"2021-05-29T15:22:51.124509Z","shell.execute_reply.started":"2021-05-29T15:22:51.041308Z","shell.execute_reply":"2021-05-29T15:22:51.123503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chainsaw = df_chainsaw.loc[df_chainsaw['category'].isin(['chainsaw', 'crackling_fire'])]\ngunshot = df_gunshot[df_gunshot['class'] == 'gun_shot']\n\nchainsaw = chainsaw.drop(['esc10', 'src_file', 'take'], axis=1)\ngunshot = gunshot.drop(['fsID', 'start', 'end', 'classID', 'salience'], axis=1)\nprint(chainsaw)\nprint(gunshot)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.125946Z","iopub.execute_input":"2021-05-29T15:22:51.126261Z","iopub.status.idle":"2021-05-29T15:22:51.153148Z","shell.execute_reply.started":"2021-05-29T15:22:51.126232Z","shell.execute_reply":"2021-05-29T15:22:51.152167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rename the columns\ngunshot = gunshot.rename(columns={'class': 'category', 'slice_file_name': 'filename'})\ngunshot","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.154486Z","iopub.execute_input":"2021-05-29T15:22:51.154904Z","iopub.status.idle":"2021-05-29T15:22:51.190423Z","shell.execute_reply.started":"2021-05-29T15:22:51.154856Z","shell.execute_reply":"2021-05-29T15:22:51.189467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#combined chainsaw and gunshot datasets\ncombined_datasets = pd.concat([chainsaw, gunshot])\ncombined_datasets","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.191994Z","iopub.execute_input":"2021-05-29T15:22:51.192409Z","iopub.status.idle":"2021-05-29T15:22:51.215188Z","shell.execute_reply.started":"2021-05-29T15:22:51.192378Z","shell.execute_reply":"2021-05-29T15:22:51.214237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = combined_datasets['category'].unique()\nprint(classes)\n\nclass_dict = {i:x for x,i in enumerate(classes)}\n# class_dict\n\ncombined_datasets['target'] = combined_datasets['category'].map(class_dict)\n# combined_datasets","metadata":{"execution":{"iopub.status.busy":"2021-05-29T17:07:22.228058Z","iopub.execute_input":"2021-05-29T17:07:22.228476Z","iopub.status.idle":"2021-05-29T17:07:22.237369Z","shell.execute_reply.started":"2021-05-29T17:07:22.228427Z","shell.execute_reply":"2021-05-29T17:07:22.236112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = combined_datasets.drop_duplicates(subset=['target'])\nsample_df","metadata":{"execution":{"iopub.status.busy":"2021-05-29T17:02:49.945254Z","iopub.execute_input":"2021-05-29T17:02:49.945689Z","iopub.status.idle":"2021-05-29T17:02:49.960405Z","shell.execute_reply.started":"2021-05-29T17:02:49.945637Z","shell.execute_reply":"2021-05-29T17:02:49.959387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this cell just to practice of iterrows function\n# for index, row in sample_df.iterrows():\n#     print(type(row[0]))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.262929Z","iopub.execute_input":"2021-05-29T15:22:51.263277Z","iopub.status.idle":"2021-05-29T15:22:51.266611Z","shell.execute_reply.started":"2021-05-29T15:22:51.263248Z","shell.execute_reply":"2021-05-29T15:22:51.265631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"signals = {}\nmel_spectrograms = {}\nmfccs = {}\n\nfor index, row in sample_df.iterrows():\n    if row['category'] == 'gun_shot':\n        PATH_GUNSHOT = '../input/urbansound8k/fold' + str(row[1]) + '/' + row[0]\n        signal2, rate2 = librosa.load(PATH_GUNSHOT, res_type = 'kaiser_fast') #signal2 % rate2 indicated for gunshot\n        signals[row[3]] = signal2\n        mel_spec = librosa.feature.melspectrogram(y=signal2 , sr=rate2, n_fft=2048, hop_length=512)\n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n        mel_spectrograms[row[3]] = mel_spec\n        mfcc = librosa.feature.mfcc(signal2 , rate2 , n_mfcc=13, dct_type=3)\n        mfccs[row[3]] = mfcc\n    else:\n        signal1, rate1 = librosa.load(PATH_CHAINSAW + row[0])\n        signals[row[3]] = signal1\n        mel_spec = librosa.feature.melspectrogram(y=signal1, sr=rate1, n_fft=2048, hop_length=512)\n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n        mel_spectrograms[row[3]] = mel_spec\n        mfcc = librosa.feature.mfcc(signal1, rate1, n_mfcc=13, dct_type=3)\n        mfccs[row[3]] = mfcc","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:51.267916Z","iopub.execute_input":"2021-05-29T15:22:51.268328Z","iopub.status.idle":"2021-05-29T15:22:52.719125Z","shell.execute_reply.started":"2021-05-29T15:22:51.268299Z","shell.execute_reply":"2021-05-29T15:22:52.717801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_signal(signal):\n    \"\"\"\n    this function will take the signal dictionary and plot the signals\n    \"\"\"\n    fig , axes = plt.subplots(nrows=2, ncols=2 , sharex =False ,sharey=True,\n                             figsize=(40,20))\n    fig.suptitle('Time series',size=50)\n    i=0\n    for x in range(5):\n        for y in range(2):\n            axes[x,y].set_title(list(signal.keys())[i])\n            axes[x,y].plot(list(signal.values())[i])\n            axes[x,y].get_xaxis().set_visible(False)\n            axes[x,y].get_yaxis().set_visible(False)\n            i +=1\n            \n            \ndef dis_feature(mfccs, cmap=None):\n    \"\"\"\n    this function will take the mfcc/mel_spectrogram dictionary and plot the signals\n    \"\"\"\n    fig ,axes= plt.subplots(nrows=2 , ncols=2 , sharex=False, sharey=True , figsize=(40,20))\n    fig.suptitle('mel', size=50)\n    i=0\n    for x in range(5):\n        for y in range(2):\n            axes[x,y].set_title(list(mfccs.keys())[i])\n            axes[x,y].imshow(list(mfccs.values())[i], cmap=cmap,interpolation='nearest')\n            axes[x,y].get_xaxis().set_visible(False)\n            axes[x,y].get_yaxis().set_visible(False)\n            i+=1","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:52.725317Z","iopub.execute_input":"2021-05-29T15:22:52.726218Z","iopub.status.idle":"2021-05-29T15:22:52.744721Z","shell.execute_reply.started":"2021-05-29T15:22:52.726164Z","shell.execute_reply":"2021-05-29T15:22:52.743024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_signal(signals)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:52.74727Z","iopub.execute_input":"2021-05-29T15:22:52.74827Z","iopub.status.idle":"2021-05-29T15:22:54.089463Z","shell.execute_reply.started":"2021-05-29T15:22:52.748216Z","shell.execute_reply":"2021-05-29T15:22:54.087255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dis_feature(mel_spectrograms)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:54.091264Z","iopub.status.idle":"2021-05-29T15:22:54.09236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dis_feature(mfccs, cmap='hot')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:54.094036Z","iopub.status.idle":"2021-05-29T15:22:54.094831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio = AudioSegment.from_file('../input/urbansound8k/fold2/100652-3-0-0.wav', format='WAV')\naudio2, samplerate = librosa.load('../input/urbansound8k/fold2/100652-3-0-0.wav')\n\nprint(len(np.array(audio.get_array_of_samples())))\nprint(len(audio2))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:54.095935Z","iopub.status.idle":"2021-05-29T15:22:54.096589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_df)\nfor index, a in sample_df.iterrows():\n    print(type(a))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:54.09778Z","iopub.status.idle":"2021-05-29T15:22:54.098437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k, n = librosa.load('../input/urbansound8k/fold2/100652-3-0-0.wav')\nj = librosa.get_duration(k, sr=n)\nif librosa.get_duration(k) == 3.0:\n    print(\"harisno\")\n# silence = AudioSegment.silent(duration=pad_ms-len(audio))\n# padded = audio + silence  # Adding silence after the audio\n# padded.export('padded-file.wav', format='wav')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:22:54.099526Z","iopub.status.idle":"2021-05-29T15:22:54.100164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_datasets","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:23:06.229798Z","iopub.execute_input":"2021-05-29T15:23:06.230401Z","iopub.status.idle":"2021-05-29T15:23:06.250157Z","shell.execute_reply.started":"2021-05-29T15:23:06.230327Z","shell.execute_reply":"2021-05-29T15:23:06.24854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X , y = [] , []\nfor index, data in tqdm(combined_datasets.iterrows()):\n    if data['category'] == 'gun_shot':\n        #padding\n        #di sini aku padding karena beberapa dataset itu ada yg di bawah 2 detik, sedangkan aku butuh narik sample dari suatu audio 2 detik secara acak, jadi aku pake silent untuk nambahin durasi suatu audio hingga 5 detik\n        pad_ms = 5000 #ini durasi yg kita inginkan\n        PATH_GUNSHOT = '../input/urbansound8k/fold' + str(data[1]) + '/' + data[0] #ini directory file datasets (perlu diinget di sini menggunakan iterrows, jadi jangan lupa ada index sama series)\n        signal2, rate2 = librosa.load(PATH_GUNSHOT, res_type = 'kaiser_fast') #load data, menggunakan kaiser fast biar lebih cepat ekstraknya\n        if librosa.get_duration(signal2, sr=rate2) < pad_ms/1000.0: #nah buat fungsi di mana jika ada audio di bawah 5 detik, dia akan dipadding\n            audio = AudioSegment.from_wav('../input/urbansound8k/fold' + str(data[1]) + '/' + data[0]) #awalnya pake PATH_GUNSHOT tapi gatau kenapa ga ke-call, jadinya ditulis ulang\n            silence = AudioSegment.silent(duration=pad_ms-len(audio)) #ini silence alias tambahan durasi agar 5 detik\n            padded = audio + silence #ini hasil padding\n            new_file = 'padded-file'+ str(index) + '.wav' #ini nama file padding yang akan diexport (ditaruh di output)\n            padded.export(new_file, format='wav') #exported\n            #./padded-file.wav\n            signal22, rate22 = librosa.load('./'+ new_file, res_type='kaiser_fast') #load, tapi khusus file padded\n            for i in range(3): #ngambil 3 sample suara selama 2 detik pada 1 audio\n                n = np.random.randint(0, len(signal22)-(rate22*2)) #dikurang rate*2 berarti dikurang 2 detik\n                sig_22 = signal22[n: int(n+(rate22*2))] #ditambah rate*2 artinya durasi ditambah 2 detik\n                mfcc_22 = librosa.feature.mfcc(sig_22, sr=rate22, n_mfcc=13) #just another thing\n                X.append(mfcc_22) \n                y.append(data[2])\n        else:\n            for i in range (3):\n                n = np.random.randint(0, len(signal2)-(rate2*2)) #frekuensi = banyaknya cuplikan yg terjadi dalam 1 detik\n                sig_2 = signal2[n: int(n+(rate2*2))]\n                mfcc_2 = librosa.feature.mfcc(sig_2, sr=rate2, n_mfcc=13)\n                X.append(mfcc_2)\n                y.append(data[2])\n    else: #untuk category non-gunshot\n        signal1, rate1 = librosa.load(PATH_CHAINSAW + data[0])\n        for i in range(3):\n            n = np.random.randint(0, len(signal1) - (rate1*2))\n            sig_1 = signal1[n: int(n+rate1*2)]\n            mfcc_1 = librosa.feature.mfcc(sig_1, sr=rate1, n_mfcc= 13)\n            X.append(mfcc_1)\n            y.append(data[2])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:23:09.464586Z","iopub.execute_input":"2021-05-29T15:23:09.465164Z","iopub.status.idle":"2021-05-29T15:24:50.394293Z","shell.execute_reply.started":"2021-05-29T15:23:09.465114Z","shell.execute_reply":"2021-05-29T15:24:50.391897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#THIS CELL JUST ONLY ONCE TO RUN!!!! REMEMBER, ONLY ONCE!!!!\nX = np.array(X)\ny = np.array(y)\n\ny = tf.keras.utils.to_categorical(y, num_classes=3) #jan sampe fungsi ini di-run lebih dari sekali. RUN ULANG DARI AWAL JIKA FUNGSI INI RUNNED MORE THAN ONCE\nX = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n\nX.shape\ny.shape ","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:26:08.174454Z","iopub.execute_input":"2021-05-29T15:26:08.174867Z","iopub.status.idle":"2021-05-29T15:26:08.189853Z","shell.execute_reply.started":"2021-05-29T15:26:08.174833Z","shell.execute_reply":"2021-05-29T15:26:08.188682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train , x_val , y_train , y_val = train_test_split(X , y ,test_size=0.2, random_state=2020)\nINPUT_SHAPE = (13, 87, 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:26:13.133568Z","iopub.execute_input":"2021-05-29T15:26:13.133985Z","iopub.status.idle":"2021-05-29T15:26:13.142683Z","shell.execute_reply.started":"2021-05-29T15:26:13.133934Z","shell.execute_reply":"2021-05-29T15:26:13.141451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MODEL DARI 85% VALIDATION\nmodel =  models.Sequential([\n                          layers.Conv2D(16 , (3,3),activation = 'relu',padding='valid', input_shape = INPUT_SHAPE),\n                          layers.Conv2D(16, (3,3), activation='relu',padding='valid'),\n\n                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n\n                          layers.Conv2D(64, (3,3), activation='relu',padding='valid'),\n                          layers.Conv2D(32, (3,3), activation='relu',padding='valid'),\n                          layers.GlobalAveragePooling2D(),\n\n\n                          layers.Dense(32 , activation = 'relu'),\n                          layers.Dense(3 , activation = 'softmax')\n])\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'acc')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:13.648132Z","iopub.execute_input":"2021-05-29T16:30:13.649221Z","iopub.status.idle":"2021-05-29T16:30:13.768795Z","shell.execute_reply.started":"2021-05-29T16:30:13.649156Z","shell.execute_reply":"2021-05-29T16:30:13.76788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #MODEL NICO\n# model =  models.Sequential([\n#     layers.Conv2D(64 , (3,3),activation = 'relu',padding='same', input_shape = INPUT_SHAPE),\n#     layers.BatchNormalization(),\n#     layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n#     layers.BatchNormalization(),\n#     layers.MaxPooling2D((2,2), strides=(2,2)),\n#     layers.Dropout(0.2),\n\n#     layers.Conv2D(128, (3,3), activation='relu',padding='same'),                      \n#     layers.BatchNormalization(),\n#     layers.Conv2D(128, (3,3), activation='relu',padding='same'),\n#     layers.BatchNormalization(),\n#     layers.MaxPooling2D((2,2), strides=(2,2)),\n#     layers.Dropout(0.2),\n\n#     layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n#     layers.BatchNormalization(),\n#     layers.Conv2D(256, (3,3), activation='relu',padding='same'),\n#     layers.BatchNormalization(),\n#     layers.MaxPooling2D((2,2), strides=(2,2)),    \n#     layers.Dropout(0.2),\n\n#     layers.GlobalAveragePooling2D(),\n\n#     layers.Dense(256 , activation = 'relu'),\n#     layers.Dense(256 , activation = 'relu'),\n#     layers.Dense(len(classes) , activation = 'softmax')\n# ])\n\n# model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:36:02.009464Z","iopub.execute_input":"2021-05-29T15:36:02.009859Z","iopub.status.idle":"2021-05-29T15:36:02.2155Z","shell.execute_reply.started":"2021-05-29T15:36:02.009825Z","shell.execute_reply":"2021-05-29T15:36:02.214394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('path/to/location')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary(./padded-file7382.wav)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:28.971338Z","iopub.execute_input":"2021-05-29T16:30:28.97187Z","iopub.status.idle":"2021-05-29T16:30:28.982712Z","shell.execute_reply.started":"2021-05-29T16:30:28.971835Z","shell.execute_reply":"2021-05-29T16:30:28.981491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%mkdir \"cpkt\"\n%mkdir \"logs\"","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:26:23.019468Z","iopub.execute_input":"2021-05-29T15:26:23.02003Z","iopub.status.idle":"2021-05-29T15:26:24.503551Z","shell.execute_reply.started":"2021-05-29T15:26:23.019967Z","shell.execute_reply":"2021-05-29T15:26:24.50234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOGDIR = \"logs\"\nCPKT = \"cpkt/\"","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:26:29.035421Z","iopub.execute_input":"2021-05-29T15:26:29.035865Z","iopub.status.idle":"2021-05-29T15:26:29.040297Z","shell.execute_reply.started":"2021-05-29T15:26:29.035823Z","shell.execute_reply":"2021-05-29T15:26:29.039415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this callback is used to prevent overfitting.\ncallback_1 = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=False\n)\n\n#this checkpoint saves the best weights of model at every epoch\ncallback_2 = tf.keras.callbacks.ModelCheckpoint(\n    CPKT, monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='auto', save_freq='epoch', options=None\n)\n\n#this is for tensorboard\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGDIR)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T15:26:32.327658Z","iopub.execute_input":"2021-05-29T15:26:32.328245Z","iopub.status.idle":"2021-05-29T15:26:32.341482Z","shell.execute_reply.started":"2021-05-29T15:26:32.328205Z","shell.execute_reply":"2021-05-29T15:26:32.339911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train,y_train ,\n            validation_data=(x_val,y_val),\n            epochs=100,\n            callbacks = [callback_1 , callback_2 , tensorboard_callback])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:30:36.724223Z","iopub.execute_input":"2021-05-29T16:30:36.724754Z","iopub.status.idle":"2021-05-29T16:31:01.922036Z","shell.execute_reply.started":"2021-05-29T16:30:36.724719Z","shell.execute_reply":"2021-05-29T16:31:01.920813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing audio\nsig , sr = librosa.load('../input/chainsaw-testing/chainsaw-01.wav', sr=16000)\nipd.display(ipd.Audio(sig, rate=sr))\nlibrosa.display.waveplot(y = sig, sr = sr)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:31:42.716875Z","iopub.execute_input":"2021-05-29T16:31:42.717516Z","iopub.status.idle":"2021-05-29T16:31:44.863394Z","shell.execute_reply.started":"2021-05-29T16:31:42.717477Z","shell.execute_reply":"2021-05-29T16:31:44.862296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class conf:\n    sr = 16000\n    duration = 3\n    hop_length = 340*duration\n    fmin = 20\n    fmax = sr // 2\n    n_mels = 128\n    n_fft = n_mels * 20\n    samples = sr * duration\n    epochs = 30\n    \nnew_model = models.load_model('../input/chainsaw-testing/')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:31:49.844495Z","iopub.execute_input":"2021-05-29T16:31:49.844903Z","iopub.status.idle":"2021-05-29T16:31:51.687506Z","shell.execute_reply.started":"2021-05-29T16:31:49.84487Z","shell.execute_reply":"2021-05-29T16:31:51.686209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def audio_to_melspectrogram(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(audio, \n                                                 sr=conf.sr,\n                                                 n_mels=conf.n_mels,\n                                                 hop_length=conf.hop_length,\n                                                 n_fft=conf.n_fft,\n                                                 fmin=conf.fmin,\n                                                 fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    return spectrogram\n\ndef split_audio(audio_data, w, h, threshold_level, tolerence=10):\n    split_map = []\n    start = 0\n    data = np.abs(audio_data)\n    threshold = threshold_level*np.mean(data[:25000])\n    inside_sound = False\n    near = 0\n    for i in range(0,len(data)-w, h):\n        win_mean = np.mean(data[i:i+w])\n        if(win_mean>threshold and not(inside_sound)):\n            inside_sound = True\n            start = i\n        if(win_mean<=threshold and inside_sound and near>tolerence):\n            inside_sound = False\n            near = 0\n            split_map.append([start, i])\n        if(inside_sound and win_mean<=threshold):\n            near += 1\n    return split_map","metadata":{"execution":{"iopub.status.busy":"2021-05-29T16:31:55.21314Z","iopub.execute_input":"2021-05-29T16:31:55.213552Z","iopub.status.idle":"2021-05-29T16:31:55.223882Z","shell.execute_reply.started":"2021-05-29T16:31:55.213512Z","shell.execute_reply":"2021-05-29T16:31:55.222315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sound_clips = split_audio(sig, 10000, 2500, 15, 10)\nduration = len(sig)\ni = 1\n\nfor intvl in sound_clips:\n    clip, index = librosa.effects.trim(sig[intvl[0]:intvl[1]],       \n                                       top_db=20, frame_length=512, hop_length=64)\n    mel_spec = audio_to_melspectrogram(conf, clip)\n    testing = np.array(mel_spec)\n    testing = testing.reshape(1, testing.shape[0], testing.shape[1], 1)\n    pred = new_model.predict(testing)\n    \n    blank = np.zeros(intvl[0]-0)\n    blank2 = np.zeros(duration-intvl[1])\n    temp = np.append(blank,clip)\n    temp = np.append(temp,blank2)\n    librosa.display.waveplot(y = temp, sr = sr, )\n    \n    print(\"Clip Number :\", i)\n    print(\"Interval from : \", intvl[0]/16000, \" to \",intvl[1]/16000, \"seconds\")\n    i += 1\n    if(pred.max() > 0.8):\n        print(\"Results : \", classes[np.argmax(pred)-1], \"\\n\")\n    else:\n        print(\"Results : Unknown\")\n        print(\"Confidence Level : \", pred)\n        print(\"Highest Confidence Level : \", classes[np.argmax(pred)-1], \" of \", np.max(pred)*100, \"%\\n\")\n        ipd.display(ipd.Audio(clip, rate=sr))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T17:13:25.933461Z","iopub.execute_input":"2021-05-29T17:13:25.933993Z","iopub.status.idle":"2021-05-29T17:13:27.244983Z","shell.execute_reply.started":"2021-05-29T17:13:25.933952Z","shell.execute_reply":"2021-05-29T17:13:27.243972Z"},"trusted":true},"execution_count":null,"outputs":[]}]}