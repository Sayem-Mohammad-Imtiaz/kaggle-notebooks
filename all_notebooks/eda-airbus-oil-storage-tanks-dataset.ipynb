{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Standard libraries\nimport datetime\nimport random\nimport json\nimport ast\nimport glob\n\n# Third-party libraries\nimport PIL.Image\nimport PIL.ImageDraw\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Jupyter widgets\nfrom IPython.core.display import display, HTML\n\n# Configurations\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 1: Images\nCreate the dataframe with the JPEG images available on disk.","metadata":{}},{"cell_type":"code","source":"# Location of dataset\nDATASET_PATH = '../input/airbus-oil-storage-detection-dataset'\n\n# List all images in the folder\nimage_list = [filename.split('/')[-1].split('.')[0] for filename in glob.glob(DATASET_PATH + \"/images/*.jpg\")]\nimage_ids = pd.DataFrame(image_list).rename(columns={0:\"image_id\"})\nprint(\"Number of images in folder: {}\".format(len(image_ids)))\nimage_ids.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 2: Annotations\nNow, we want to add the bounding box informations to the dataframe. A bounding box is a rectangle around the object detected. We only need to know the coordinates of 2 points to describe a bounding box, for example top-left and bottom-right.\n![](assets/bbox_image.jpg)","metadata":{}},{"cell_type":"code","source":"# convert a string record into a valid python object\ndef f(x): \n    return ast.literal_eval(x.rstrip('\\r\\n'))\n\n# read the CSV with annotations\nlabels = pd.read_csv(DATASET_PATH + '/annotations.csv',\n        converters={'bounds': f})\n\n# just in case, join annotations with image list\n#labels = image_ids.merge(right=labels, how='left')\n\n# print first lines\nlabels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of unique 'image_ids' in annotations: {}\".format(len(labels['image_id'].unique())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of annotations: {}\".format(len(labels)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Available classes: {}\".format(labels['class'].unique().tolist()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 3: Compute some statistics\nCompute the number of objects in each image and store it in a dataframe named `histo`","metadata":{}},{"cell_type":"code","source":"histo = labels.image_id.value_counts()\nprint(\"Images with more than 400 oil storage tanks\")\nhisto[(histo > 400)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add number of storage tanks per tile in the dataframe and sort it\nlabels.at[:, 'records'] = labels.loc[:, 'image_id'].apply(lambda image_id: histo.loc[image_id])\nlabels = labels.sort_values(by=['records'], ascending=False)\nlabels.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the histogram of objects per image\nplt.figure(figsize=(25, 15))\nplt.title(\"Number of Oil Storage Tanks per image\")\nplt.grid(which='both')\ng = sns.countplot(x='image_id', data=labels)\nplt.xlabel(\"image_id\")\nplt.ylabel(\"n row per image_id\")\n\n# Rotate x labels\ng.set_xticklabels(labels=g.get_xticklabels(), rotation=90);\n# Or hide them\n# g.set_xticklabels(labels=[None]);\n\nplt.savefig(\"objects-per-image.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 4: Plot some images","metadata":{}},{"cell_type":"code","source":"# Create polygon from bounds\ndef create_polygon_from_bounds(bbox):\n    (xmin, ymin, xmax, ymax) = bbox\n    coords = []\n    coords.append((xmin, ymin))\n    coords.append((xmin, ymax))\n    coords.append((xmax, ymax))\n    coords.append((xmax, ymin))\n    coords.append((xmin, ymin))\n    return coords\n\ndef overlay_image(image_id, bbox_df):\n    img = PIL.Image.open(DATASET_PATH + \"/images/\" + image_id + '.jpg')\n    draw = PIL.ImageDraw.Draw(img)\n\n    for k, row in bbox_df[bbox_df['image_id'] == image_id].iterrows():\n        geometry = create_polygon_from_bounds(row['bounds'])\n        draw.polygon(geometry, outline=(255,0,0))\n        #draw.text(geometry[0], row['class'], fill=(255,0,0))\n        \n    return img\n\n# select a random image or images with most annotations\n#pickone = random.choice(image_ids.to_numpy().tolist())[0]\npickone = \"1fcb9fee-da89-43f8-83d9-b5d17575f5e6\" # 893 annotations\n#pickone = \"9892f3a0-f541-43b8-bc62-d640701841f7\" # 540 annotations\n\nimg = overlay_image(pickone, labels)\nfilename = \"oil-storage-sample.jpg\"\nimg.save(filename)\ndisplay(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part 5: More Exploratory Data Analysis\n### Compute width and height of each storage tanks\nAdd the width and the height in pixels of each storage tanks to the dataframe.\nThen display some usefull statistics and plot an histogram.","metadata":{}},{"cell_type":"code","source":"def getWidth(bounds):\n    try: \n        (xmin, ymin, xmax, ymax) = bounds\n        return np.abs(xmax - xmin)\n    except:\n        return np.nan\n\ndef getHeight(bounds):\n    try: \n        (xmin, ymin, xmax, ymax) = bounds\n        return np.abs(ymax - ymin)\n    except:\n        return np.nan\n# Create width and height\nlabels.loc[:,'width'] = labels.loc[:,'bounds'].apply(getWidth)\nlabels.loc[:,'height'] = labels.loc[:,'bounds'].apply(getHeight)\n\n# Display head\nlabels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### What conclusion can we draw from these statistics ?\nAre they any annotations that we can discard ?","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25, 15))\nsns.distplot(labels[labels['width'].notnull()]['width'])\nplt.xlim(0, 150)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25, 15))\nsns.distplot(labels[labels['width'].notnull()]['height'])\nplt.xlim(0, 150)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compute the aspect ratio of each storage tanks\nClean the results in order to remove NaN elements.\nThen display some useful statistics and plot an histogram.","metadata":{}},{"cell_type":"code","source":"labels.at[:,'aspect_ratio'] = labels[['height', 'width']].max(axis=1) / labels[['height', 'width']].min(axis=1)\nlabels['aspect_ratio'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"safe_labels = labels[(np.isfinite(labels['aspect_ratio'])) & labels['aspect_ratio'].notnull()]\nsafe_labels['aspect_ratio'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25, 15))\nsns.distplot(safe_labels['aspect_ratio'], bins = 100)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Based on these informations, can we discard some annotations ?\nDisplay annotations with unusual aspect ratio bounding box.","metadata":{}},{"cell_type":"code","source":"# Filter records with an aspect ratio > 2.5 and display them.\nstrange_labels = safe_labels.loc[safe_labels['aspect_ratio'] > 2.5]\nstrange_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickone = strange_labels.sample()\nprint(pickone)\nimg = overlay_image(pickone['image_id'].tolist()[0], pickone)\ndisplay(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cleaning by aspect ratio\nVery small objects (typically under 5 pixels) will not be correctly managed by YOLO and might not be oil storage tanks anyhow. Aspect ratios over 2.5 seems very weird as well. Remove them from the training dataset.","metadata":{}},{"cell_type":"code","source":"keep_tags_wt_width_over_px = 5\nkeep_tags_wt_height_over_px = 5\nbb_aspect_ratio_upper_limit =  2.5\n                                \nfilter_too_small = np.logical_or(safe_labels['width'] < keep_tags_wt_width_over_px, safe_labels['height'] < keep_tags_wt_width_over_px)\nprint(sum(filter_too_small), \"records too small\")\nfilter_ratio_too_high = safe_labels['aspect_ratio'] > bb_aspect_ratio_upper_limit\nprint(sum(filter_ratio_too_high), \"records with too high aspect ratio \")\n\ncleaned_labels = safe_labels[np.logical_not(np.logical_or(filter_too_small,filter_ratio_too_high))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}