{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.stats.weightstats import ztest\nfrom scipy.stats import sem\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read in the Data\n\nThis data was taken from the Kaggle competition [Heart Failure Prediction](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data). The purpose of this analysis is to determine what factors contribute to heart failure and develop a model that can help prediction whether or not a heart failure will occur based on the data provided."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore the Data"},{"metadata":{},"cell_type":"markdown","source":"The description on each column are as follows:\n- age: Age of the patient\n- anaemia: Decrease of red blood cells or hemoglobin (boolean)\n- creatinine_phosphokinase: Level of CPK enzyme\n- diabetes: If the patient has diabetes (boolean)\n- ejection_fraction: Percentage of blood leaving the head at each contraction (percentage)\n- high_blood_pressure: If the patient has hypertension (boolean)\n- platelets: Platelets in the blood\n- serum_creatinine: Level of serum creatinine\n- serum_sodium: Level of serum sodium\n- sex: 0 = Female, 1 = Male\n- smoking: If the patient smokes (boolean)\n- time: Follow-up period in days\n- DEATH_EVENT: If the patient deceased during the follow-up period (boolean)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on a quick glance, there does not appear to be any null values or any outstanding faults with the data."},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\n\nAs stated above, the purpose is to determine if there are any factors that could contribute, or signify, a higher chance of a heart failure. Therefore I want to see how the averages for each feature compare between death events and non-death events then see if those averages are statistically different from each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the average of features grouped by 'DEATH_EVENT'\navg_by_death = data.groupby('DEATH_EVENT').mean().transpose()\nprint('Total number of deaths: %i' %data['DEATH_EVENT'].sum())\nprint('Percent of DEATH_EVENTS: %f' %(data['DEATH_EVENT'].sum()/len(data)))\navg_by_death","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the standard error in the means by DEATH_EVENT\nsem_by_death = data.groupby('DEATH_EVENT').sem().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the averages have been calculated, I want to test their statistical significance to determine how different the averages are across `DEATH_EVENT`. The following determines the averages of each feature, based on death events, and calculates if the differences are statically significant."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.columns[:-1]:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the statistical significance between averages amongst features with 0.05 significance\nfor col in data.columns[:-1]:\n    # Z test for statistical difference between average DEATH_EVENT by column\n    non_death_events = data[data['DEATH_EVENT'] == 0][col]\n    death_events = data[data['DEATH_EVENT'] == 1][col]\n    \n    ttest, pval = ztest(x1 = non_death_events, x2 = death_events)\n    \n    if pval <= 0.05:\n        print('The null hypothesis can be rejected for %s. The averages are statistically different' %col)\n    else:\n        print('The null hypothesis cannot be rejected %s. The averages are not statistically different' %col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only features that seem to have statistically different means across `DEATH_EVENT` are `age`, `time`, `serum_creatinine`, `serum_sodium`, and `ejection_fraction`. Interestingly, `high_blood_pressure`, `diabetes`, `smoking`, or `sex` don't appear to be significant factors that could help predict heart failures based on the data. The above analysis is visualized below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot box plots for non-boolean columns\nfor col in data.columns[:-1]:\n    figure = go.Figure()\n    figure.add_trace(go.Bar(name = 'DEATH_EVENT = 1',\n                            x = ['DEATH_EVENT = 1'],\n                            y = [avg_by_death[1][col]],\n                            error_y = dict(type='data', array = [sem_by_death[1][col]])))\n    figure.add_trace(go.Bar(name = 'DEATH_EVENT = 0',\n                            x = ['DEATH_EVENT = 0'],\n                            y = [avg_by_death[0][col]],\n                            error_y = dict(type='data', array = [sem_by_death[0][col]])))\n    figure.update_layout(title_text = 'Mean ' + col)\n    figure.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"96 out of 299 observations are death events."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Plot the correlation graph between variables\n_ = plt.figure(figsize=(15,15))\n_ = sns.heatmap(data.corr(), cmap='coolwarm', annot=True)\n_ = plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, `age`, `ejection_fraction`, `serum_creatinine`, `serum_sodium`, and `time` appear to have the highest correlation to `DEATH_EVENT` which will be focused on in the following anayses. Also worth noting:\n- There's a slight correlation between `age` and `serum_creatinine`\n- There's a slight correlation between `sex` and `ejection_fraction`\n- There's a slight correlation between `age` and `time`\n"},{"metadata":{},"cell_type":"markdown","source":"### Gender Analysis\n\nLike stated above, it's an interesting note that `gender`, `high_blood_pressure`, `diabetes`, and `smoking` don't play a role in determining a `DEATH_EVENT` according to this data. The following investigates these variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to plot pie charts for boolean variables colored by DEATH_EVENT\ndef cat_pie_by_de(category, category_true_label, category_false_label):\n    '''Plots pie charts for a given category by DEATH_EVENT'''\n    \n    # Creates value counts for a true/false (positive/negative) boolean value by DEATH_EVENT\n    true_de = data.loc[(data[category] == 1) & (data['DEATH_EVENT'] == 1), 'DEATH_EVENT'].count()\n    true_nde = data.loc[(data[category] == 1) & (data['DEATH_EVENT'] == 0), 'DEATH_EVENT'].count()\n    false_de = data.loc[(data[category] == 0) & (data['DEATH_EVENT'] == 1), 'DEATH_EVENT'].count()\n    false_nde = data.loc[(data[category] == 0) & (data['DEATH_EVENT'] == 0), 'DEATH_EVENT'].count()\n    \n    # Creates lists for true/false (positive/negative) boolean values with death and non-death counts\n    true_pie_values = [true_de,  true_nde]\n    false_pie_values = [false_de, false_nde]\n    \n    # Creates labels for the pie charts\n    true_labels = ['%s Death Events' %category_true_label, '%s non-Death Events' %category_true_label]\n    false_labels = ['%s Death Events' %category_false_label, '%s non-Death Events' %category_false_label]\n    \n    # Makes a subplot for two pie charts\n    figure = make_subplots(rows = 1, cols = 2,\n                      column_widths=[0.5,0.5],\n                      specs = [[{\"type\":\"pie\"}, {\"type\":\"pie\"}]])\n    \n    # Creates a pie chart for true (positive) boolean values colored by DEATH_EVENT\n    figure.add_trace(\n        go.Pie(labels = true_labels, values = true_pie_values, title = category_true_label),\n        row = 1, col = 1)\n    \n    # Creates a pie chart for false (negative) boolean values colored by DEATH_EVENT\n    figure.add_trace(\n        go.Pie(labels = false_labels, values = false_pie_values, title = category_false_label),\n        row = 1, col = 2)\n\n    # Adds a title to the pie charts\n    figure.update_layout(title = \"Death Event by %s\" %category)\n\n    # Plots the charts\n    figure.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the pie charts for sex\ncat_pie_by_de(category = 'sex',\n              category_true_label = 'Male',\n              category_false_label = 'Female')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the pie chart above, the percentages between `DEATH_EVENT` for both genders don't differ too significantly which might explain why it it's not helpful to determine `DEATH_EVENT` according to this data."},{"metadata":{},"cell_type":"markdown","source":"### High Blood Pressure Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the pie charts for high blood pressure\ncat_pie_by_de(category = 'high_blood_pressure',\n              category_true_label = 'High Blood Pressure',\n              category_false_label = 'Non-High Blood Pressure')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly, the percentages are noticibly different but somehow not enough to be a reliable feature to distinguish `DEATH_EVENT`. Based on the `high_blood_pressure` bar chart above, the means to seem to be different, but possibly due to the small sample size, there isn't enough data to confidently say that these means are statistically different. I would like to see if numerical data, instead of binary, would be a better determinant(s) in predicting `DEATH_EVENT`. It's worth noting that of the four categetories being investigated now, `high_blood_pressure` has the highest absolute correlation with `DEATH_EVENT`."},{"metadata":{},"cell_type":"markdown","source":"### Diabetes Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the pie charts for diabetes\ncat_pie_by_de(category = 'diabetes',\n             category_true_label = 'Diabetic',\n             category_false_label = 'Non-Diabetic')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As with `sex`, the means aren't too different which explains why it's not a significant feature in predicting `DEATH_EVENT`."},{"metadata":{},"cell_type":"markdown","source":"### Smoking Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the pie charts for smoking\ncat_pie_by_de(category='smoking',\n             category_true_label = 'Smoker',\n             category_false_label = 'Non-Smoker')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of the four features investigated, `smoking` was the most surprising since it's a known fact that smoking increases ones chance in developing heart disease. But according to the data, the means aren't statistically different resulting in a weak correlation with `DEATH_EVENT`. That could be due to how the data was collected and by whom; perhaps the data was collected from a group of individuals with known heart conditions."},{"metadata":{},"cell_type":"markdown","source":"## Data Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List features to be included in model\nfeatures = ['age', 'ejection_fraction', 'serum_creatinine', 'time', 'serum_sodium']\n\n# Split data into features and target variable\nX = data[features]\ny = data['DEATH_EVENT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into training and test sets while keeping ratio of DEATH_EVENT\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.2, \n                                                    random_state = 159,\n                                                    stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_data(model_name, probability = False, grid_search = False, param_grid = None):\n    '''With given model, fit, predict, and display various metrics from the data'''\n    # Instantiate and fit model to train data\n    model = model_name\n    \n    #-------------------------------------------------------------------\n    # Check if grid_search is true and if true, param_grid is specified\n    if grid_search:\n        assert param_grid != None\n        \n        print('Performing Grid Search Cross Validation')\n        \n        # Perform grid search\n        model_cv = GridSearchCV(model, param_grid, cv = 2)\n        model_cv.fit(X_train, y_train)\n        \n        # Print best parameters & score\n        print('Best model parameters:')\n        for param in model_cv.best_params_:\n            print('\\t %s = %s' % (param, str(model_cv.best_params_[param])))\n        print('Best score = %f' %model_cv.best_score_)\n        \n        # Set model to best_estimator\n        model = model_cv.best_estimator_\n    #-------------------------------------------------------------------\n    \n    # Fit training data to model\n    model.fit(X_train, y_train)\n    \n    # Make predictions from the trained model\n    predictions = model.predict(X_test)\n    \n    # Print the classification report\n    print(classification_report(y_test, predictions))\n    \n    # Plot the confusion matrix\n    conf_matrix = confusion_matrix(y_test, predictions)\n    \n    figure1 = ff.create_annotated_heatmap(conf_matrix,\n                                         x = [0, 1],\n                                         y = [0, 1],\n                                         colorscale = 'Blues')\n    figure1.update_layout(title='Confusion Matrix',\n                         xaxis = dict(title='Predicted Values', side='bottom'),\n                         yaxis = dict(title='True Values', autorange='reversed'))\n    \n    figure1.show()\n    \n    # Plot the ROC curve and print AUC metric\n    y_pred_prob = model.predict_proba(X_test)[:,1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n    \n    figure2 = px.area(x = fpr, y = tpr,\n                 title = 'ROC Curve',\n                 labels=dict(x = 'False Positive Rate', y = 'True Positive Rate'),\n                 width = 700, height = 700)\n    \n    figure2.add_shape(type = 'line',\n                      line = dict(dash = 'dash'),\n                      x0 = 0, y0 = 0,\n                      x1 = 1, y1 = 1)\n    \n    figure2.show()\n    \n    print('AUROC score = %f' %roc_auc_score(y_test, y_pred_prob))\n    \n    # Return model accuracy and AUROC score\n    model_accuracy = accuracy_score(y_test, predictions)\n    auroc = roc_auc_score(y_test, y_pred_prob)\n    \n    return model_accuracy, auroc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a data frame with model metrics\nmodel_metrics = dict()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, auc = model_data(LogisticRegression())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_metrics['Logistic Regression'] = [acc, auc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'n_estimators':[5, 10, 20, 50, 75, 100],\n             'min_samples_split':[2, 5], \n             'max_depth':[5, 10, 15]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, auc = model_data(RandomForestClassifier(random_state = 789), grid_search = True, param_grid = param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_metrics['Random Forest'] = [acc, auc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, auc = model_data(XGBClassifier())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_metrics['XGBoost Classifier'] = [acc, auc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, auc = model_data(svm.SVC(probability = True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_metrics['Support Vector Machine'] = [acc, auc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'n_neighbors':[3, 5, 7],\n             'weights':['uniform', 'distance']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, auc = model_data(KNeighborsClassifier(), grid_search = True, param_grid = param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_metrics['K-Nearest Neighbors'] = [acc, auc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display metric data from models\npd.DataFrame.from_dict(model_metrics,\n                       orient = 'index',\n                       columns = ['Model Accuracy', 'AUROC'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Of the models developed, the XGBoost classifier seems to have performed best in terms of accuracy and AUROC score with $90\\%$ and $0.959$ respectfully followed closely by the Random Forest model at $~87\\%$ accuracy and $0.937$ AUROC score."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}