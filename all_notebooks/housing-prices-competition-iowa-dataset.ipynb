{"cells":[{"metadata":{},"cell_type":"markdown","source":"Well, this is my personal view for predicting the Sale Price of a houses in Iowa.\nAs this being my very first machine learning problem (and also Competition), I'm really excited of how this turned out.\n\nAs I learn along, maybe in the future I'll be able to bring this kernel to absolute perrrfection. ^^"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Imputs\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Setup**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Read the data\nX = pd.read_csv('../input/iowa-house-prices/train.csv', index_col = 'Id')\nX_test = pd.read_csv('../input/iowa-house-prices/test.csv', index_col ='Id')\n\n#Filter from target column null values\nX.dropna(axis = 0, subset = ['SalePrice'], inplace = True)\ny = X['SalePrice']\n\n#Filter out the target column from X dataset\nX.drop(axis = 1, labels = ['SalePrice'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check for Leakage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verify if there are the same number of columns in both test and train data\nprint(X.shape)\nprint((X.columns == X_test.columns).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MoSold, YrSOld, SaleType, SaleCondition won't be available for a prediction for the new house\n#so these columns will be dropped\nleakage_columns = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition']\nX.drop(labels = leakage_columns, axis = 1, inplace = True)\nX_test.drop(labels = leakage_columns, axis = 1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Preparation: Numerical Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n\ncols_with_nulls = X[numerical_cols].isnull().sum()\nprint(cols_with_nulls[cols_with_nulls > 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\ndf = X[['LotFrontage', 'MasVnrArea', 'GarageYrBlt']].dropna(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we'll impute the mode, as the distributions is asymetric and the mean is influenced by outliers\nplt.figure(figsize = (12,4))\nsns.distplot(a = df['LotFrontage'], bins = 30, norm_hist=False, kde=True, color = 'blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we'll use most frequent, as the distribution is strongly asymetric to the right\nplt.figure(figsize = (12,4))\nsns.distplot(a = df['MasVnrArea'], bins = 30, norm_hist=False, kde=True, color = 'purple')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for this distribution mean should work just fine :)\nplt.figure(figsize = (12,4))\nsns.distplot(a = df['GarageYrBlt'], bins = 30, norm_hist=False, kde=True, color = 'orange')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are only 3 columns with missing values, and they are small in number, so we'll apply Simple Imputation\nfrom sklearn.impute import SimpleImputer\n\nnumerical_cols_median = ['LotFrontage']\nnumerical_transformer_median = SimpleImputer(strategy = 'median')\n\nnumerical_cols_mod = ['MasVnrArea']\nnumerical_transformer_mod = SimpleImputer(strategy = 'most_frequent')\n\nnumerical_cols_mean = ['GarageYrBlt']\nnumerical_transformer_mean = SimpleImputer(strategy = 'mean')\n\nnumerical_cols_remain = set(numerical_cols) - set(numerical_cols_mean) - set(numerical_cols_median) - set(numerical_cols_mod)\nnumerical_cols_remain = list(numerical_cols_remain)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preparation: Categorical Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\ncols_with_nulls_categs = X[categorical_cols].isnull().sum()\ncols_with_nulls_categs[cols_with_nulls_categs > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Because there are a few columns with too many missing values, we'll filter them out from the data\nX.drop(labels = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], axis = 1, inplace = True)\nX_test.drop(labels = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Redo categorical_cols\ncategorical_cols = [col for col in X.columns if X[col].dtype == 'object']\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncateg_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy = 'most_frequent')),\n                                         ('onehot', OneHotEncoder(handle_unknown = 'ignore'))])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bundle Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\npreprocessor = ColumnTransformer(transformers=[('num_median', numerical_transformer_median, numerical_cols_median),\n                                               ('num_mod', numerical_transformer_mod, numerical_cols_mod),\n                                               ('num_mean', numerical_transformer_mean, numerical_cols_mean),\n                                               ('num_rest', numerical_transformer_mean, numerical_cols_remain),\n                                              ('cat', categ_transformer, categorical_cols)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the training data into train & valid\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model 1: XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nxgboost_1 = XGBRegressor(learning_rate = 0.05, n_estimators=1000, random_state=0)\npipeline_1 = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('model', xgboost_1)])\npipeline_1.fit(X_train, y_train)\npreds_1 = pipeline_1.predict(X_valid)\nmae = mean_absolute_error(y_valid, preds_1)\nprint('MAE 1:', mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost (with GridSearch), finding the best params[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_prep = preprocessor.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'learning_rate' : [0.1, 0.08, 0.05, 0.03, 0.01], 'n_estimators' : [50, 100, 200, 500, 700, 1000]}\ngrid = GridSearchCV(XGBRegressor(), param_grid, cv = 5, verbose=5)\n\ngrid.fit(X_train_prep, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best params:', grid.best_params_)\nprint('Best estim:', grid.best_estimator_)\nprint('Best score:', grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model 2: XGBoost with best Params"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgboost_2 = XGBRegressor(learning_rate=0.01, n_estimators= 1000)\n\npipeline_2 = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('model', xgboost_2)])\n\npipeline_2.fit(X_train, y_train)\n\npreds_2 = pipeline_2.predict(X_valid)\nmae = mean_absolute_error(y_valid, preds_2)\nprint('MAE 2:', mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, this is it.\nLoved this project!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}