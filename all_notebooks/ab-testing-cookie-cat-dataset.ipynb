{"cells":[{"metadata":{},"cell_type":"markdown","source":"Cookie Cats is a hugely popular mobile puzzle game developed by Tactile Entertainment. It's a classic \"connect three\"-style puzzle game where the player must connect tiles of the same color to clear the board and win the level. It also features singing cats.\n\nAs players progress through the levels of the game, they will **occasionally encounter gates that force them to wait a non-trivial amount of time or make an in-app purchase to progress**. In addition to driving in-app purchases, these gates serve the important purpose of giving players an enforced break from playing the game, hopefully resulting in that the player's enjoyment of the game being increased and prolonged.\n\n***But where should the gates be placed? Initially, the first gate was placed at level 30. In this project, we're going to analyze an AB-test where we moved the first gate in Cookie Cats from level 30 to level 40. In particular, we will look at the impact on player retention.***","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The data is from 90,189 players that installed the game while the AB-test was running. The variables are:\n\n* userid - a unique number that identifies each player.\n* version - whether the player was put in the control group (gate_30 - a gate at level 30) or the test group (gate_40 - a gate at level 40).\n* sum_gamerounds - the number of game rounds played by the player during the first week after installation\n* retention_1 - did the player come back and play 1 day after installing?\n* retention_7 - did the player come back and play 7 days after installing?\n* When a player installed the game, he or she was randomly assigned to either gate_30 or gate_40","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy.stats import binom\nimport numpy as np\nimport pandas as pd \nfrom scipy.stats import norm\nimport math as mt\nnp.set_printoptions(suppress=True)\nimport statsmodels.stats.api as sms\nfrom scipy.stats import norm\nimport scipy.stats as stats\nimport plotly.graph_objs as go\nimport plotly.graph_objects as go\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, plot_mpl\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining some utility function to calculate standard deviation of proportions, z-score, comparing two proportions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_sd_when_population_sd_is_not_given(p,n):\n    sd = np.sqrt((p*(1-p))/n)\n    return round(sd,4)\n\n#Returns: z-score for given alpha\ndef get_z_score(alpha):\n    return norm.ppf(alpha)\n\ndef ztest_comparing_two_proportions(X1,X2,n1,n2):\n    p1_hat = X1/n1\n    p2_hat = X2/n2\n    p_bar = (X1+X2)/(n1+n2)\n    q_bar = (1-p_bar)\n    z_numerator= p1_hat-p2_hat\n    z_denominator = np.sqrt((1/n1+1/n2)*p_bar*q_bar)\n    z_statistic = z_numerator/z_denominator\n    p_value = norm().cdf(z_statistic)\n    return z_numerator, p_value,z_denominator,z_statistic","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading in the data and columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mobile-games-ab-testing/cookie_cats.csv')\nprint(data.info())\nprint(data['version'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Control and Treatment Groups**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In an A/B/C../N testing experiment, we are looking to see whether one or more **explanatory variables**, e.g., change in the color of the button, change in the fonts on the webpage, affect the **response variable**. That is the metrics we selected to measure like conversion rate, retention rate, or people buying more stuff.\n\nThe people are assigned into at least two different groups, using proper **random sampling** techniques like cluster sampling, stratified sampling depending upon the use case. That way, the groups aren’t biased.\n\nOne group acts as the **control group**, which is the group that does nothing, receives nothing, or isn’t changed the way they are working. The other group is called the **treatment group** (also called the experimental group), a group that does something, receives something, or gets a new feature that we are trying to launch. The classic example of this is in medical studies, where the treatment group receives some new drug, and the control group receives a placebo, or sugar pill.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gate_30 = data[data['version']=='gate_30']  #control\ngate_40 = data[data['version']=='gate_40']  #Treatment\nprint(gate_30.head())\nprint(gate_40.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  **Null Hypothesis and Alternate hypothesis: What question do we want to answer?**\n\n\n### 1-Day Retention\n\n**did the 1-Day Retention rate increased after moving the gate to level 40?**\n**h0** = gate40<=gate30 **ha** = gate40>30\n\n### 7-Day Retention\n\n**did the 7-Day Retention rate increased after moving the gate to level 40?**\n**h0** = gate40<=gate30 **ha** = gate40>30","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Invariate Matrix**\n\n- Invariate metrics are used for \"sanity checks\", that is, to make sure our experiment (the way we presented a change to a part of the population, as well as the way we collected the data) is not inherently wrong.\n- we pick metrics that we consider not to change (not to be affected) because of our experiment and later make sure these metrics don't change drastically between our control and experiment groups.\n\nsum_gamerounds is the invariate metric which we expect to be same between control and treatment group","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Evaluation Metrics What is your success metric?**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Evaluation metrics are the metrics in which we expect to see a change, and are relevant to the business goals we aim to achieve.\n- For each metric, we state a **Minimum Detectable Effect:** - which marks the minimum change which is practically significant to the business. For instance, stating that any increase in retention that is under `1%`, even if statistically significant, is not practical to the business.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Retention-1 Day\n> Baseline Retention-1 Day: 0.448\n> Minimum Detectable Effect: 0.01\n> alpha: 5%\n> beta: 20%\n> 1-beta: 80%\n> Number of groups = 2 (control and Treatment)\n> sample size = 45489 Treatment/group\n> total sample size = 90,189 enrollments\n\n> Retention-7 Day\n> Baseline Retention-7 Day: 0.19018\n> Minimum Detectable Effect: 0.01\n> alpha: 5%\n> beta: 20%\n> 1 - beta: 80%\n> Number of groups = 2 (control and Treatment)\n> sample size = 45489 Treatment/group\n> total sample size = 90,189 enrollments\n> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Exploring Data Distribution of the Invariate Matrix between Control and Treatment Group**\nWe expect this metric to be same between the two groups to ensure the data collection is not biased","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x0 = gate_30['sum_gamerounds']\nx1 = gate_40['sum_gamerounds'] \nfig = go.Figure()\nfig.add_trace(go.Box(x=x0, name='gate_30 (control_group)'))\nfig.add_trace(go.Box(x=x1, name='gate_40 (experiment_group)'))\nfig.update_layout(legend=dict(x=.6,y=0.97, traceorder='reversed', font_size=16))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing the outlier since it can severly affect the distribution and statics**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gate_30=gate_30[gate_30['sum_gamerounds']!=gate_30['sum_gamerounds'].max()]\nx0 = gate_30['sum_gamerounds']\nx1 = gate_40['sum_gamerounds'] \n\nfig = go.Figure()\nfig.add_trace(go.Box(x=x0, name='gate_30 (control_group)'))\nfig.add_trace(go.Box(x=x1, name='gate_40 (experiment_group)'))\nfig.update_layout(legend=dict(x=.6,y=0.97, traceorder='reversed', font_size=16))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Invariate Matrix distribution across Control and Treatment Group**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gameround_gate_40 = gate_40['sum_gamerounds'].value_counts()\ngameround_gate_40=gameround_gate_40.sort_values(ascending=False)\ngameround_gate_30 = gate_30['sum_gamerounds'].value_counts()\ngameround_gate_30=gameround_gate_30.sort_values(ascending=False)\npd.set_option(\"max_rows\", None)\npd.set_option('display.max_columns', None)\nimport warnings\nwarnings.filterwarnings('ignore')\ncolors=['#151515','#f0c24f']\nfig = go.Figure()\nfig.add_trace(go.Scatter(y=gameround_gate_30, mode='lines+markers',marker_color=colors[0], name='gate_30 (experiment_group)'))\nfig.add_trace(go.Scatter(y=gameround_gate_40, mode='lines+markers',marker_color=colors[1], name='gate_40 (control_group)'))\nfig.update_layout(title=\"Count of userid vs count of games played\", \n                 legend=dict(x=.05,y=0.95, traceorder='reversed', font_size=16), width=600,height=600,\n                 yaxis=dict(title=\"Count of useid\",titlefont=dict(\n                          color=\"#1f77b4\"),tickfont=dict(color=\"#1f77b4\")))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normal Approximation of sum_gamerounds**\n“How many gamerounds were played by userids in each group”. We can invoke the Central Limit Theorem. As we’re interested in the average conversion, or average time spent on the site, this averaging of an underlying distribution means our final estimate will be well approximated by a normal distribution.\n\n**Two sample z-test for the difference between means**\n\n> **Null Hypothesis** = gate_40_sum_gamerounds = gate_40_sum_gamerounds\n\n> **Alternate Hypothesis** = gate_40_sum_gamerounds != gate_40_sum_gamerounds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gate_30_mean= gate_30['sum_gamerounds'].mean()\ngate_30_std=gate_30['sum_gamerounds'].std()\ngate_40_mean= gate_40['sum_gamerounds'].mean()\ngate_40_std=gate_40['sum_gamerounds'].std()\npoopled_std = np.sqrt(((gate_30_std)**2/gate_30.shape[0]) + ((gate_40_std)**2/gate_40.shape[0]))\npooled_mean = gate_30_mean-gate_40_mean\nz_score =  pooled_mean/poopled_std\np= norm().cdf(z_score)\nprint(f\"Zscore is {z_score:0.2f}, p-value is {(1-p)*2:0.3f} (two tailed), {p:0.3f} (one tailed)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Welch t-Test (easier and direct way to do it)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import ttest_ind\norder_value_control_group = gate_30['sum_gamerounds'].to_list()\norder_value_experimental_group = gate_40['sum_gamerounds'].to_list()\nzscore, prob= ttest_ind(order_value_control_group, order_value_experimental_group, equal_var=False)\nprint(f\"Zscore is {zscore:0.2f}, p-value is {prob:0.3f} (two tailed), {prob/2:0.3f} (one tailed)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion on the Invariate Metric \n**Since the p-value is greater than 0.05 we fail to reject the null hypothesis and the two distributions seem to be same and hence we are good to proceed as this indicates there is no bias in the data between the control and treatment group**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"colors=['#de3d83','#00b8b8','#e4bd0b']\nfig = go.Figure()\nclick_rate = np.linspace(0, 100, 10000)\nprob_a = norm(gate_40_mean, gate_30_std).pdf(click_rate)\nprob_b = norm(gate_30_mean, gate_40_std).pdf(click_rate)\nfig.add_trace(go.Scatter(y=prob_a , x=click_rate, mode='lines+markers',marker_color=colors[0], name='gate_40'))\nfig.add_trace(go.Scatter(y=prob_b , x=click_rate, mode='lines+markers',marker_color=colors[1], name='gate_30'))\nfig.update_layout(title=\"Probability Density Function for gate_30 and gate_40 <br> for  sum_gamerounds (Invariate Matrix) \", \n                 legend=dict(x=.05,y=0.95, traceorder='reversed', font_size=16), \n                 width=600,\n                 height=600,\n                 yaxis=dict(\n                          title=\"Probability Density Function P(x)\",\n                 titlefont=dict(\n                          color=\"#1f77b4\"\n                                ),\n                 tickfont=dict(\n                        color=\"#1f77b4\"\n                               )\n  ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Samples Needed to perform the experiment How many samples need to be in the experiment?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I used the control group probability as a proxy for the baseline significance level and set the practical significance level, confidence level and sensitivity to 1%, 95% and 80% respectively. Using these values I calculated the minimum sample size required for each test group to make sure there was sufficient data to draw statistically robust conclusions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.stats.api as sms\nbaseline_cvr=0.448\nalpha=0.05\npower=0.8\nmini_diff=0.01\neffect_size=sms.proportion_effectsize(baseline_cvr, baseline_cvr+mini_diff)\nsample_size=sms.NormalIndPower().solve_power(effect_size=effect_size, power=power, alpha=alpha, ratio=1)\nprint('Required sample size for Retention Day 1 metric ~ {0:.1f}'.format(sample_size) + ' per group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline_cvr_day7=0.19018\nalpha_day7=0.05\npower_day7=0.8\nmini_diff_day7=0.01\neffect_size_day7=sms.proportion_effectsize(baseline_cvr_day7, baseline_cvr_day7+mini_diff_day7)\nsample_size_day7=sms.NormalIndPower().solve_power(effect_size=effect_size_day7, power=power_day7, alpha=alpha_day7, ratio=1)\nprint('Required sample size for Retention Day 7 metric ~ {0:.1f}'.format(sample_size_day7) + ' per group')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Relationship between Minimum sample size required vs minimum detectable difference**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"samplesize_list=[]\nbaseline=0.448\ndeltas=np.arange(0.005, 0.025, 0.001)\nfor delta in deltas:\n  prob2=baseline+delta\n  effect_size=sms.proportion_effectsize(baseline, prob2)\n  sample_size=sms.NormalIndPower().solve_power(effect_size=effect_size, power=0.8, alpha=0.05, ratio=1)\n  samplesize_list.append(sample_size)\ncolors=['#151515','#f0c24f']\nfig = go.Figure()\nfig.add_trace(go.Scatter(y=samplesize_list , x=deltas, mode='lines+markers',marker_color=colors[1]))\nfig.update_layout(title=\"Minimum required sample size for minimum detectable delta/effective size <br> for Retention Day 1 metric\", \n                 legend=dict(x=.05,y=0.95, traceorder='reversed', font_size=16), \n                 width=500,\n                 height=500,\n                 yaxis=dict(\n                          title=\"Required Sample Size\",\n                 titlefont=dict(\n                          color=\"#1f77b4\"\n                                ),\n                 tickfont=dict(\n                        color=\"#1f77b4\"\n                               )),\n                xaxis=dict(\n                          title=\"Minimum Detectable Effective Size\",\n                 titlefont=dict(\n                          color=\"#1f77b4\"\n                                ),\n                 tickfont=dict(\n                        color=\"#1f77b4\"\n                               )\n  ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samplesize_list=[]\nbaseline=0.19018\ndeltas=np.arange(0.005, 0.025, 0.001)\nfor delta in deltas:\n  prob2=baseline+delta\n  effect_size=sms.proportion_effectsize(baseline, prob2)\n  sample_size=sms.NormalIndPower().solve_power(effect_size=effect_size, power=0.8, alpha=0.05, ratio=1)\n  samplesize_list.append(sample_size)\ncolors=['#00b8b8','#f0c24f']\nfig = go.Figure()\nfig.add_trace(go.Scatter(y=samplesize_list , x=deltas, mode='lines+markers',marker_color=colors[0]))\nfig.update_layout(title=\"Minimum required sample size for minimum detectable delta/effective size <br> for Retention Day 7 metric\", \n                 legend=dict(x=.05,y=0.95, traceorder='reversed', font_size=16), \n                 width=500,\n                 height=500,\n                 yaxis=dict(\n                          title=\"Required Sample Size\",\n                 titlefont=dict(\n                          color=\"#1f77b4\"\n                                ),\n                 tickfont=dict(\n                        color=\"#1f77b4\"\n                               )),\n                xaxis=dict(\n                          title=\"Minimum Detectable Effective Size\",\n                 titlefont=dict(\n                          color=\"#1f77b4\"\n                                ),\n                 tickfont=dict(\n                        color=\"#1f77b4\"\n                               )\n  ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  z-test for comparing two proportions 1-day retention","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#1-day rretention\n#h0 = gate40<=gate30\n#ha = gate40>30\ngame_30_day1_retention = gate_30['retention_1'].sum()\ngame_40_day1_retention = gate_40['retention_1'].sum()\ngame_30_count=gate_30.shape[0]\ngame_40_count=gate_40.shape[0]\nprint(f'game_30 p1 {game_30_day1_retention/game_30_count:.3f}')\nprint(f'game_40 p2 {game_40_day1_retention/game_40_count:.3f}')\nmean, p_value,me,z_statistic1 = ztest_comparing_two_proportions(game_40_day1_retention, game_30_day1_retention,game_40_count,game_30_count)\nprint(f'zscore for 1-day retention {z_statistic1:.3f}')\nprint(f'p-value for 1-day retention {1-p_value:.3f}')\nprint(f'Probablity that gate_40 increasted the 1-day retention (gate_40-gate_30>0) {p_value:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\ncolors=['#00b8b8','#de3d83']\n\nrate_b=game_40_day1_retention/game_40_count\nrate_a=game_30_day1_retention/game_30_count\nstd_a = sample_sd_when_population_sd_is_not_given(rate_a,game_30_count)\nstd_b=sample_sd_when_population_sd_is_not_given(rate_b,game_40_count)\n\np_hat_1day=rate_b - rate_a\np_hat_1day_std = np.sqrt(std_a**2 + std_b**2)\n\nz_score = p_hat_1day / p_hat_1day_std\np = norm(p_hat_1day, p_hat_1day_std)\nx = np.linspace(-0.02, 0.02, 1000)\ny = p.pdf(x)\narea_under_curve = p.sf(0)\n\n\nprint(f\"zscore is {z_score:0.3f}, with p-value {norm().sf(z_score):0.3f}\")\n\nx_value = norm(loc=p_hat_1day,scale=p_hat_1day_std).isf(norm().sf(z_score))\npx=np.arange(0.0,.02,0.00100)\nfig.add_trace(go.Scatter(y=y , x=x, mode='lines+markers',marker_color=colors[0], name='pdf(gate_40-gate_30)'))\nfig.add_trace(go.Scatter(\n    y=norm.pdf(px,loc=p_hat_1day,scale=p_hat_1day_std), \n    x=px,  mode='lines',name=\"prob(gate_40-gate_30>0) \",\n    fill='tozeroy',\n    fillcolor=colors[1],\n    line=dict(color='#f43530', width=.1))) # fill to trace0 y\n\nfig.add_annotation(x=.002,y=10,\n            text=\"Area under the curve {}\".format(area_under_curve.round(4)))\nfig.update_annotations(dict(xref=\"x\",yref=\"y\",showarrow=True, arrowhead=7,ax=130,ay=-60))\n\nfig.update_layout(title=\"PDF of gate_40-gate_30 1-Day Retention\", \n                 legend=dict(x=.40,y=0.95, traceorder='reversed', font_size=16),  width=600,height=600,yaxis=dict(title=\"Probability Density Function P(x)\", titlefont=dict(color=\"#1f77b4\"),tickfont=dict(color=\"#1f77b4\")))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  z-test for comparing two proportions 7-day retention","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#7-day rretention\n#h0 = gate40<=gate30\n#ha = gate40>30\ngame_30_day7_retention = gate_30['retention_7'].sum()\ngame_40_day7_retention = gate_40['retention_7'].sum()\ngame_30_count=gate_30.shape[0]\ngame_40_count=gate_40.shape[0]\nprint(f'game_30_ret7 p1 {game_30_day7_retention/game_30_count:.4f}')\nprint(f'game_40_ret7 p2 {game_40_day7_retention/game_40_count:.4f}')\nmean7, p_value7,me7,z_statistic7 = ztest_comparing_two_proportions(game_40_day7_retention, game_30_day7_retention,game_40_count,game_30_count)\nprint(f'zscore for 7-day retention {z_statistic7:.4f}')\nprint(f'p-value for 7-day retention {1-p_value7:.4f}')\nprint(f'Probablity that gate_40 increasted the 7-day retention (gate_40-gate_30>0) {p_value7:.3f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\ncolors=['#00b8b8','#de3d83']\n\nrate_b_day7=game_40_day7_retention/game_40_count\nrate_a_day7=game_30_day7_retention/game_30_count\nstd_a_day7 = sample_sd_when_population_sd_is_not_given(rate_a_day7,game_30_count)\nstd_b_day7=sample_sd_when_population_sd_is_not_given(rate_b_day7,game_40_count)\n\n\np_hat_day7=rate_b_day7 - rate_a_day7\np_std_hat_day7= np.sqrt(std_a_day7**2 + std_b_day7**2)\n\n\nz_score_day7 = (p_hat_day7) / (p_std_hat_day7)\np_day7 = norm(p_hat_day7, (p_std_hat_day7))\nx_day7 = np.linspace(-0.02, 0.02, 1000)\ny_day7 = p_day7.pdf(x_day7)\narea_under_curve_day7 = p_day7.sf(0)\n\nprint(f\"zscore is {z_score_day7:0.3f}, with p-value {norm().sf(z_score_day7):0.3f}\")\n\nx_value_day7 = norm(loc=p_hat_day7,scale=p_std_hat_day7).isf(norm().sf(z_score_day7))\npx_day7=np.arange(0.0,.02,0.00100)\nfig.add_trace(go.Scatter(y=y_day7 , x=x_day7, mode='lines+markers',marker_color=colors[0], name='pdf(gate_40-gate_30)'))\nfig.add_trace(go.Scatter(\n    y=norm.pdf(px_day7,loc=p_hat_day7,scale=p_std_hat_day7), \n    x=px_day7,  mode='lines',name=\"prob(gate_40-gate_30>0)\",\n    fill='tozeroy',\n    fillcolor=colors[1],\n    line=dict(color='#f43530', width=.1))) # fill to trace0 y\n\nfig.add_annotation(x=.002,y=10,\n            text=\"Area under the curve {}\".format(area_under_curve_day7.round(3)))\nfig.update_annotations(dict(xref=\"x\",yref=\"y\",showarrow=True, arrowhead=7,ax=130,ay=-60))\n\nfig.update_layout(title=\"PDF of gate_40-gate_30 7-Day Retention\", \n                 legend=dict(x=.40,y=0.95, traceorder='reversed', font_size=16),  width=600,height=600,yaxis=dict(title=\"Probability Density Function P(x)\", titlefont=dict(color=\"#1f77b4\"),tickfont=dict(color=\"#1f77b4\")))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions and Recommendation of the ab-test","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- **Retention Day-1, The probability that the 1-Day retention will increase by moving the gate level to 40  is 0.037 and hence we will not recommend moving the gate**\n- **Retention Day-7, The probability that the 7-Day retention will increase by moving the gate level to 40  is 0.001 and hence we will not recommend moving the gate**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}