{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv(\"../input/fer2018/fer20131.csv\")\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target Maping"},{"metadata":{"trusted":true},"cell_type":"code","source":"emotions = {0:'Angry', 1:'Fear', 2:'Happy',3:'Sad', 4:'Surprise', 5:'Neutral'}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"values_count = raw_data['Usage'].value_counts()\nsizes =[values_count[0],values_count[1],values_count[-1]]\nplt.figure(figsize=(7,7))\ng = plt.pie(sizes,autopct='%1.1f%%',shadow=False,explode=(0,0.05,0.05),\n           wedgeprops={\"edgecolor\":\"k\",'linewidth': 1, 'linestyle': 'dashed', 'antialiased': True},\n           labels = [\"Training = {}\".format(values_count[0]),\"Testing = {}\".format(values_count[-1]),\n                    \"Devlopment = {}\".format(values_count[1])])\nplt.title(\"Data Distribution\")\nplt.legend(loc = 4)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Pre-process"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainig_data = raw_data[raw_data['Usage'] == 'Training'].iloc[:,:-1]\ntesting_data = raw_data[raw_data['Usage'] == 'PrivateTest'].iloc[:,:-1]\ndev_data = raw_data[raw_data['Usage'] == 'PublicTest'].iloc[:,:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(raw_data):\n#     raw_data['pixels'] = raw_data['pixels'].apply(lambda x: np.array(x.split(),dtype=np.float32).reshape((48,48)))\n    pixels = []\n    target = []\n    for x,y in zip(raw_data['pixels'],raw_data['emotion']):\n        pixels.append(np.array(x.split(),dtype=np.float32))\n        target.append(y)\n\n    return np.array(pixels,dtype=np.float32).reshape((len(pixels),48,48,1)),np.array(target,dtype=np.float32).reshape((len(target),1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,y_train = get_data(trainig_data)\nX_test,y_test = get_data(testing_data)\nX_dev,y_dev = get_data(dev_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train shape : \",X_train.shape)\nprint(\"Y_train shape : \",y_train.shape)\nprint(\"X_dev shape : \",X_dev.shape)\nprint(\"Y_dev shape : \",y_dev.shape)\nprint(\"X_test shape : \",X_test.shape)\nprint(\"Y_test shape : \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Distribution with target"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(y_train,y_test,y_dev):\n    plt.figure(figsize=(10,10))\n    plt.subplot(3,1,1)\n    unique_data,frequency = np.unique(y_train,return_counts=True)\n    sns.barplot(x=np.vectorize(emotions.get)(unique_data),y=frequency)\n    \n    plt.subplot(3,1,2)\n    unique_data,frequency = np.unique(y_test,return_counts=True)\n    sns.barplot(x=np.vectorize(emotions.get)(unique_data),y=frequency)\n    \n    plt.subplot(3,1,3)\n    unique_data,frequency = np.unique(y_dev,return_counts=True)\n    sns.barplot(x=np.vectorize(emotions.get)(unique_data),y=frequency)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_distribution(y_train,y_test,y_dev)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see here Distribution of all data are same"},{"metadata":{},"cell_type":"markdown","source":"## Visualization Data in Lower Dimention"},{"metadata":{},"cell_type":"markdown","source":"* t-Distributed Stochastic Neighbor Embedding (t-SNE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\nmodel = TSNE(n_components=2, random_state=1)\ntsne_data = model.fit_transform(X_train[0:1000].reshape(len(X_train[0:1000]),2304))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_data_np = np.hstack((tsne_data,y_train[0:1000]))\ntsne_dataframe = pd.DataFrame(data=tsne_data_np,columns=[\"Dim_1\",\"Dim_2\",\"label\"])\n\nplt.figure(figsize=(10,10))\nsns.scatterplot(x=\"Dim_1\",y=\"Dim_2\",data=tsne_dataframe,hue='label', palette=\"Set3\")\nplt.title(\"TSNE\")\nplt.legend(title='emotions', loc='upper left', labels=['Angry', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral'])\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Principal component analysis (PCA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import decomposition\npca = decomposition.PCA()\npca.n_components = 2\npca_data = pca.fit_transform(X_train[0:1000].reshape(len(X_train[0:1000]),2304))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_data_np = np.hstack((pca_data,y_train[0:1000]))\npca_dataframe = pd.DataFrame(data=pca_data_np,columns=[\"1st_principal\",\"2nd_principal\",\"label\"])\n\nplt.figure(figsize=(10,10))\nsns.scatterplot(x=\"1st_principal\",y=\"2nd_principal\",data=pca_dataframe,hue='label', palette=\"Set3\")\nplt.title(\"PCA\")\nplt.legend(title='emotions', loc='upper left', labels=['Angry', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral'])\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{},"cell_type":"markdown","source":"* preapere target values with One-Hot Encoding for softmax function"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train/255.0\nX_test = X_test/255.0\nX_dev = X_dev/255.0\n\ny_train = (np.arange(6) == y_train[:]).astype(np.float32)\ny_test = (np.arange(6) == y_test[:]).astype(np.float32)\ny_dev = (np.arange(6) == y_dev[:]).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    \n    model.add(Conv2D(64, (3, 3), input_shape=input_shape, padding='same'))\n#     model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n#     model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(512,(3,3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(512,(3,3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    \n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    \n    model.add(Dense(6, activation='softmax'))\n    \n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy','mean_squared_error'],optimizer='adam')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = my_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.tensorflow_backend.clear_session()\npath_model='model_filter.h5'\nmodel=my_model() \n# K.set_value(model.optimizer.lr,1e-4) \nh=model.fit(x=X_train,y=y_train, \n            batch_size=128, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_dev,y_dev),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the MAE"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(h.history['loss'], label='MAE (testing data)')\nplt.plot(h.history['val_loss'], label='MAE (validation data)')\nplt.title('MAE')\nplt.ylabel('MAE value')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the MSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot history: MSE\nplt.plot(h.history['mean_squared_error'], label='MSE (testing data)')\nplt.plot(h.history['val_mean_squared_error'], label='MSE (validation data)')\nplt.title('MSE')\nplt.ylabel('MSE value')\nplt.xlabel('No. epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=0)\nprint (\"model %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}