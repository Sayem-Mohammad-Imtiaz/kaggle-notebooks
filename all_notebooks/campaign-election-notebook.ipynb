{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **What is the data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/electionfinance/CandidateSummaryAction1.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare data for analysis\n1. drop all columns with above 90% missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first, visualize missing values\nimport missingno as msn\nmsn.matrix(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#process data values\n\ndata['cov_sta_dat'] = pd.to_datetime(data['cov_sta_dat'])\ndata['cov_end_dat'] = pd.to_datetime(data['cov_end_dat'])\n\ndata['campaign_duration'] = (data['cov_end_dat'] - data['cov_sta_dat']).dt.days","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation** \n1. data contains messy features \n2. create a function to deal with features with high percentage of missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function to check all columns with missing data greater than 90% and drop them\n\ndef process_missing_data(data, threshold, inplace_value):\n    #create a list to hold columns with missing value above threshold\n    drop_cols = []\n    \n    #create a variable to store all columns in the dataframe\n    all_cols = data.columns\n    \n    #calculate all columns with missing values percentage greater than the threshold\n    missing_percentage = (data[all_cols].isna().sum()/len(data))*100\n    \n    #create a dataframe to store all candidate columns and their percentage\n    missing_df = pd.DataFrame({\"cols\":all_cols, \"percentage\":missing_percentage})\n    \n    #check for threshold condition\n    missing_filtered = missing_df[missing_df['percentage'] >= threshold] \n    drop_cols.append(missing_filtered[\"cols\"].tolist())\n    \n    #drop candidate columns\n    drop_cols = drop_cols[0]\n    data.drop(columns=drop_cols, inplace= inplace_value)\n    \n    return data.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#call function on data\nprocess_missing_data(data=data, threshold=90, inplace_value=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Explore the data**"},{"metadata":{},"cell_type":"markdown","source":"**First, we see what offices the candidates are campaigning for**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['can_off'].value_counts(normalize=True, sort=True) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Basically, there are three offices namely**\n* H : house of represenatative\n* S : senator\n* P : presidency\n\n**create three dataframes based on the candidate office**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first, convert the net_con column to a float data type and modify data inplace\ndef converter(data, data_col):\n    value = data[data_col].str.replace('$','').str.replace(',','').str.replace('(','-').str.replace(')','').astype('float32')\n    data[data_col] = value\n    return data.head()\n\n#call the function on the net_con feature\nconverter(data=data, data_col=\"net_ope_exp\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**replace all the nan columns in the winner with N as they represent the losers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['winner'] = data['winner'].fillna('N')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**inference**\n1. we are making use of the net_con feature as this is the feature that represents the total expenses of each candidate leading up to the election period"},{"metadata":{"trusted":true},"cell_type":"code","source":"H_df = data.loc[data['can_off'] == \"H\"] \nS_df = data.loc[data['can_off'] == \"S\"]\nP_df = data.loc[data['can_off'] == \"P\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the shape of the data\n\nprint(f'The shape of the House of assembly data is {H_df.shape}')\nprint(f'The shape of the senate data is {S_df.shape}')\nprint(f'The shape of the presidential data is {P_df.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# let's start by analyzing the house of representative data"},{"metadata":{},"cell_type":"markdown","source":"**Since we are interested in the finances of the campaign, lets see how much is spent on campaign in each district in a state**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Amt_per_sta_ds = H_df.groupby(['can_off_sta', 'can_off_dis'])['net_ope_exp'].sum().to_frame(name = \"total_dis_sum\").reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Amt_per_sta_ds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the state with high spending\n\nplt.figure(figsize=(20,10))\n\nax = sns.barplot(x=\"can_off_sta\", y=\"total_dis_sum\", data=Amt_per_sta_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see that the highest spending state in terms of house of reps election is the MT, let's now go further to analyze the state with the highest net_contribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"mt_comp = H_df.loc[H_df['can_off_sta'] == 'MT']\nmt_comp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x='can_nam', y='net_ope_exp', hue = 'winner',data=mt_comp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n1. **we can see the state has just one district with only two competitors, yet they have the higest rate of spending this can be due to a various reasons that are sadly not contained in the data. suggestions include:**\n    * The cost of getting things done in that state is relatively high in comparison to other states\n    * Being in direct competition creates just one collision point for the candidates \n2. **we can also see that the candidate with the highest spending won the election**\n\n\n    "},{"metadata":{},"cell_type":"markdown","source":"we can clearly see that for state MT with just one district, the higest spender won the vote, however, before we conclude, let's check how long each candidate campaigned for.\n* reason behind this is the fact that time plays a role in the maturity of an investment. so assuming the campaign is the investemnt, net_con is the invested capital, how long will it take for the said investement to mature. \n* naturally, the longer you keep your investment, the higher your profit gets, therefore, it should hold that the longer you campaign, the more likely it is for you to win, we check if this assumption holds"},{"metadata":{"trusted":true},"cell_type":"code","source":"mt_comp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x='can_nam', y='campaign_duration',hue='winner', data=mt_comp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* The investment assumption holds"},{"metadata":{},"cell_type":"markdown","source":"**Next, we seek to find out the number of candidates vying for a sit in a district(competitors) generally **"},{"metadata":{"trusted":true},"cell_type":"code","source":"competitors = H_df.groupby(['can_off_sta', 'can_off_dis'])['can_id'].count().to_frame(name = \"num_of_comp\").reset_index()\n#eliminate data points where num_of_comp <= 1\n#this means that these positions are unopposed\ncompetitors = competitors[competitors['num_of_comp'] > 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"competitors.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n\nax = sns.barplot(x=\"can_off_dis\", y=\"num_of_comp\", data=competitors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* here we can see every district represented in our dataset clearly"},{"metadata":{},"cell_type":"markdown","source":"### Before generalizing, let's pick a state at random and test the result of our early analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"al_comp = H_df.loc[H_df['can_off_sta'] == 'AL']\nal_comp.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nax = sns.barplot(x='can_id', y='net_ope_exp', hue = 'winner',data=al_comp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference**\n* assumption on the relationship between how much a candidate spends on election and winning holds\n* visualize to see what the range of highest amount spent is"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(12,8)})\nsns.set(style=\"white\", color_codes=True)\nsns.jointplot(x=H_df[\"net_ope_exp\"], y=H_df[\"votes\"], kind='kde', color=\"skyblue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**by this inspection, we can see the concentration of where the most money is spent and the expected voters**"},{"metadata":{},"cell_type":"markdown","source":"# Haven explored the house of rep dataset, we move to explore senetorial campaigns"},{"metadata":{"trusted":true},"cell_type":"code","source":"S_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights**\n* **Article I, section 3 of the USA Constitution states that** \n* The Senate of the United States shall be composed of two Senators from each State, chosen by the Legislature thereof, for six Years; and each Senator shall have one Vote. Immediately after they shall be assembled in Consequence of the first Election, they shall be divided as equally as may be into three Classes."},{"metadata":{},"cell_type":"markdown","source":"**Focus**\n* our aim is to check for a relationship in the finance and voting tournout so we proceed in line\n* by research the voters column of the dataframe should be empty as the election is not open to public voting\n\n**inference**\n* check to ascertain second focus"},{"metadata":{"trusted":true},"cell_type":"code","source":"prf1 = S_df['votes'].isna().count()\nprf2 =  len(S_df['votes'])\n\nprint(prf1)\nprint(prf2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* research holds so we proceed to drop the votes feature in our dataframe\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"S_df.drop(columns='votes', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#first, we check amount spent per state \nAmt_per_sta_ds = S_df.groupby(['can_off_sta', 'can_off_dis'])['net_ope_exp'].sum().to_frame(name = \"total_dis_sum\").reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Amt_per_sta_ds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize to see the highest spending state\n\nplt.Figure(figsize=(20,10))\nax = sns.barplot(x='can_off_sta', y='total_dis_sum', data=Amt_per_sta_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Obeservation**\n* three states show high total money spent which are **FL, PA and WI**\n* analyze the winners of these three states to observe trends"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create the three dataframes\nfl_comp = S_df.loc[S_df['can_off_sta'] == 'FL']\npa_comp = S_df.loc[S_df['can_off_sta'] == 'PA']\nnv_comp = S_df.loc[S_df['can_off_sta'] == 'NV']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check winners in FL\n\nax = sns.barplot(x='can_nam', y='net_ope_exp', hue='winner', data=fl_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* the highest spender wasn't the winner, to check why this is happening, we inspect with our investment analogy and check how long they have been campaigning for\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fl_comp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x='can_nam', y='campaign_duration', hue='winner', data=fl_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* we still come short in our investment idealogy, next we check for the number of party affiliation in the respective district"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x='can_nam', y='net_ope_exp', hue='can_par_aff', data=fl_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**observation**\n* we can see a variation in their party affiliations , lets check if they are from the majority or minority party for that state\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fl_comp['can_par_aff'].value_counts(normalize=True, sort=True).plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* we have our inlier insight as we can see, the party affiliation plays a big role in the voting outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check winners in PA\n\nax = sns.barplot(x='can_nam', y='net_ope_exp', hue='winner', data=pa_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* here we can see that right off the box, the candidate with the highest contribution won the election, we will test the other assumption of investment time and party affiliation next\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.style.use('seaborn-white')\nplt.subplot(121)\nax = sns.barplot(x='can_nam', y='campaign_duration', hue='winner', data=pa_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"campaign duration\")\n\n\nplt.subplot(122)\npa_comp['can_par_aff'].value_counts(normalize=True, sort=True).plot()\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"dominant party\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nax = sns.barplot(x='can_nam', y='net_ope_exp', hue='can_par_aff', data=pa_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"campaign duration\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference**\n* assumption fails. this can be a function of the coefficient of that variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"#check winners in PA\n\nax = sns.barplot(x='can_nam', y='net_ope_exp', hue='winner', data=nv_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* holds to our first assumption, as we can see\n* test investment and party assumption"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-white')\nplt.subplot(121)\nax = sns.barplot(x='can_nam', y='campaign_duration', hue='winner', data=nv_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"campaign duration\")\n\n\nplt.subplot(122)\nnv_comp['can_par_aff'].value_counts(normalize=True, sort=True).plot()\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"dominant party\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x='can_nam', y='net_ope_exp', hue='can_par_aff', data=nv_comp)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"campaign duration\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Presidential Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"P_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dataframe grouped by total amount spent\nAmt_per_sta_ds = P_df.groupby(['can_nam', 'winner', 'can_par_aff', 'campaign_duration'])['net_ope_exp'].sum().to_frame(name = \"total_dis_sum\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sort result\nAmt_per_sta_ds = Amt_per_sta_ds.sort_values(by = ['total_dis_sum'], ascending=False).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create visualization to reach an assumption on which section of the data points could be candidates to win the election\nAmt_per_sta_ds['total_dis_sum'].plot()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select first 20 data points as candidates\nAmt_per_sta_ds = Amt_per_sta_ds.iloc[:20, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Amt_per_sta_ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check winner\nax = sns.barplot(x='can_nam', y = 'total_dis_sum', hue='winner', data=Amt_per_sta_ds)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**observation**\n* first assumption did not hold, lets find if our data has the ability to give insight to why this is by analyzing the campaign duration and party affiliation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-white')\nplt.subplot(121)\nax = sns.barplot(x='can_nam', y='campaign_duration', hue='winner', data=Amt_per_sta_ds)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"campaign duration\")\n\n\nplt.subplot(122)\nAmt_per_sta_ds['can_par_aff'].value_counts(normalize=True, sort=True).plot()\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"dominant party\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x='can_nam', y='total_dis_sum', hue='can_par_aff', data=Amt_per_sta_ds)\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',  \n)\nplt.title(\"campaign duration\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**\n* MYSTERY SOLVED!!! Party affiliations solved the problem"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# MODEL BUILDING\n\n* The features that we've analyzed to matter include\n    * net_ope_exp\n    * winner\n    * votes\n    * can_par_aff\n    * can_off\n    * can_off_dis\n    * can_off_sta\n    * can_inc_cha_ope_sea\n    * campaign_duration\n    \n* create two dataframes for classification and regression tasks\n    * create two subframes from the original frames for granularity of prediction\n        * Regression_data\n            * H_model_data_reg\n            * P_model_data_reg\n            * S_model_data_reg\n        * Classification_data\n            * H_model_data_cla\n            * P_model_data_cla\n            * S_model_data_cla\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create regression data\nRegression_data = data[['can_off', 'can_off_sta', 'can_off_dis', 'can_inc_cha_ope_sea', 'net_ope_exp', 'can_par_aff','campaign_duration','votes']]\n\n\n#create classification data\nClassification_data = data[['can_off', 'can_off_sta', 'can_off_dis', 'can_inc_cha_ope_sea', 'net_ope_exp', 'can_par_aff','campaign_duration','winner']]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Check regression analysis possibility**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Regression_data.isna().sum()/len(Regression_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Inference**\n* approximately 80% of the votes data is missing, this will make regression analysis inaccurate, therefore, we will not look into extracting data for regression analysis"},{"metadata":{},"cell_type":"markdown","source":"# Proceed to check classification possibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Handle missing data in classification data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n\nClassification_data['can_off_dis'] = imp_mode.fit_transform(Classification_data[['can_off_dis']]).copy()\nClassification_data['can_inc_cha_ope_sea'] = imp_mode.fit_transform(Classification_data[['can_inc_cha_ope_sea']]).copy()\nClassification_data['net_ope_exp'] = Classification_data['net_ope_exp'].fillna(-99999999999999999999999).copy()\nClassification_data['can_par_aff'] = imp_mode.fit_transform(Classification_data[['can_par_aff']]).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"remove a single uninformative data point that affects the pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"Classification_data = Classification_data[Classification_data.can_par_aff != 'PPT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make respective dataframes\nH_model_data_cla = Classification_data.loc[Classification_data['can_off'] == 'H']\nP_model_data_cla = Classification_data.loc[Classification_data['can_off'] == 'P']\nS_model_data_cla = Classification_data.loc[Classification_data['can_off'] == 'S']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build classification pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = H_model_data_cla.iloc[:,:-1]\ny = H_model_data_cla.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# determine categorical and numerical features\n\n\n\nnumerical_ix = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_ix = X.select_dtypes(include=['object', 'bool']).columns\n\n\n# define the data preparation for the columns\nt = [('cat', OneHotEncoder(), categorical_ix), ('num', MinMaxScaler(), numerical_ix)]\ncol_transform = ColumnTransformer(transformers=t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define base the model\n\nmodel = XGBClassifier(learning_rate=0.1,min_child_weight=100)\n# define the data preparation and modeling pipeline\npipeline = Pipeline(steps=[('prep',col_transform), ('m', model) ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test pipeline and base model on House of rep data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#divide data into train and test split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pipeline.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_true=y_val, y_pred=y_pred))\nprint(f'accuracy of the base model on house of rep election is {accuracy_score(y_val, y_pred) * 100}%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create function to test different models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model_(models_dict, X_train, y_train, X_val, y_val):\n    \"\"\"\n    a function that takes in a dictionary of models along with train and test data\n    to calculate the f1_score and accuracy score of the built pipeline then return a dataframe as the output\n    \n    \"\"\"\n    metrics = {}\n    for i in models_dict:\n        model_name = str(i)\n        model = models_dict[i]\n        \n        pipeline = Pipeline(steps=[('prep',col_transform), ('m', model) ])\n        pipeline.fit(X_train, y_train)\n        test_pred = pipeline.predict(X_val)\n        metric_1 = accuracy_score(y_val, test_pred) * 100\n        metric_2 = f1_score(y_val, test_pred, average='weighted')\n        metrics[i] = metric_1, metric_2\n        \n    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Accuracy score', 'f1_score'])\n    return metrics_df\n        \n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a dictionary of classification models\ncandidate_models = {'xgboost':XGBClassifier(), 'log_reg': LogisticRegression(), 'svm':SVC(), 'random forest': RandomForestClassifier() }\n\n#cal test_model_function\ntest_model_(candidate_models, X_train, y_train, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## kindly upvote or comment, which ever you feel obliged to do \n## Also feel free to copy and reuse as you wish"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}