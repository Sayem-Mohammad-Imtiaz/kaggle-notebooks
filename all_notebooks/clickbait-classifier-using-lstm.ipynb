{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing libraries","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"FILE_PATH = '/kaggle/input/clickbait-dataset/clickbait_data.csv'\ndata = pd.read_csv(FILE_PATH)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text = data['headline'].values\nlabels = data['clickbait'].values\ntext_train, text_test, y_train, y_test = train_test_split(text, labels)\nprint(text_train.shape, text_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenize text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 5000\nmaxlen = 500\nembedding_size = 32\n\ntokenizer = Tokenizer(num_words=vocab_size)\ntokenizer.fit_on_texts(text)\n\nX_train = tokenizer.texts_to_sequences(text_train)\nx_test = tokenizer.texts_to_sequences(text_test)\n\nX_train = pad_sequences(X_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define and train model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=3,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size=512, validation_data=(x_test, y_test), epochs=20, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('weights.h5')\nmodel.save('model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot training metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nx = range(1, len(acc) + 1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(x, acc, 'b', label='Training acc')\nplt.plot(x, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(x, loss, 'b', label='Training loss')\nplt.plot(x, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot confusion matrix and metrics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [round(i[0]) for i in model.predict(x_test)]\ncm = confusion_matrix(y_test, preds)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Not clickbait', 'Clickbait'], fontsize=16)\nplt.yticks(range(2), ['Not clickbait', 'Clickbait'], fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tn, fp, fn, tp = cm.ravel()\n\nprecision = tp/(tp+fp)\nrecall = tp/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run predictions on arbitrary user input","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = ['My biggest laugh reveal ever!', 'Learning game development with Unity', 'A tour of Japan\\'s Kansai region', '12 things NOT to do in Europe']\ntoken_text = pad_sequences(tokenizer.texts_to_sequences(test), maxlen=maxlen)\npreds = [round(i[0]) for i in model.predict(token_text)]\nfor (text, pred) in zip(test, preds):\n    label = 'Clickbait' if pred == 1.0 else 'Not Clickbait'\n    print(\"{} - {}\".format(text, label))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}