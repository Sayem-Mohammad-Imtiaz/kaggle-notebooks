{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importando e lendo o Dataframe com a  biblioteca Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nnoshow = pd.read_csv('../input/medicalappointmentnoshown/KaggleV2-May-2016.csv',sep = ',')\nnoshow.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Verificando a presença de valores nulos dentro do dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"noshow.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Relação entre a Variável Target (noshow) com todas as variáveis categóricas do dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('--> No-show vs Alcoholism')\nprint(noshow.groupby(['No-show','Alcoholism'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n\nprint('--> No-show vs Diabetes')\nprint(noshow.groupby(['No-show','Diabetes'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n\nprint('--> No-show vs SMS_received')\nprint(noshow.groupby(['No-show','SMS_received'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n\n\nprint('--> No-show vs Hipertension')\nprint(noshow.groupby(['No-show','Hipertension'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n\nprint('--> No-show vs Scholarship')\nprint(noshow.groupby(['No-show','Scholarship'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n\nprint('--> No-show vs Handcap')\nprint(noshow.groupby(['No-show','Handcap'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n\nprint('--> No-show vs Gender')\nprint(noshow.groupby(['No-show','Gender'])['PatientId'].count())\nprint('-------------------------------------------------------------------')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribuição das idades por no show"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\nbox1 = plt.subplots()\nbox1 = sns.boxplot(x='No-show', y='Age', data=noshow)\nbox1.set_title('Boxplot do ano pela presença ou não de no show')\nbox1.set_xlabel('Paciente teve no show?')\nbox1.set_ylabel('Idade')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grafico = sns.FacetGrid(noshow, col='No-show')\ngrafico.map(sns.distplot, 'Age', rug=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Substituição das idades negativas\nNesse caso foi utilizado a mediana de quem possui desfecho negativo devido a presença de valores abaixo de ser ter ocorrido em pessoas com desfecho negativo"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filtrando pessoas com idade negativa\nnoshow[noshow['Age']<0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#capturando as mediana das pessoas com desfecho dnegativo\nmedian_noshow_no = noshow[noshow['No-show']=='No']['Age'].median()\nmedian_noshow_no","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nnoshow['Age'] = np.where(noshow['Age']<1,median_noshow_no,noshow['Age'])\nprint('No-show = Não com ajuste')\nprint('----------------------------')\nprint(noshow.loc[noshow['No-show'] == 'No','Age'].describe()) #nova descrição de idade","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Criando faixa etária"},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions  = [ noshow['Age'] < 10\n               , (noshow['Age'] < 20) & (noshow['Age']>= 10)\n               , (noshow['Age'] < 30) & (noshow['Age']>= 20)\n               , (noshow['Age'] < 40) & (noshow['Age']>= 30)\n               , (noshow['Age'] < 50) & (noshow['Age']>= 40)\n               , (noshow['Age'] < 60) & (noshow['Age']>= 50)\n               , (noshow['Age'] < 70) & (noshow['Age']>= 60)\n               ,  noshow['Age'] >= 70 ]\n\nchoices     = ['0-10','10-20','20-30','30-40','40-50','50-60','60-70','>70']\n\nnoshow['fx_etaria'] = np.select(conditions, choices, default=np.nan)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transformação das variáveis datetime\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"noshow['ScheduledDay'] = pd.to_datetime(noshow['ScheduledDay'])\nnoshow['AppointmentDay'] = pd.to_datetime(noshow['AppointmentDay'])\n\n#variaveis relacionada a scheduled\nnoshow['Scheduled_Month'] = noshow['ScheduledDay'].apply(lambda x: x.month)\nnoshow['Scheduled_Year'] = noshow['ScheduledDay'].apply(lambda x: x.year)\nnoshow['Scheduled_WeekDay'] = noshow['ScheduledDay'].apply(lambda x: x.strftime(\"%A\"))\n\n#variaveis reacionadas ao appointment\nnoshow['Appointment_Month'] = noshow['AppointmentDay'].apply(lambda x: x.month)\nnoshow['Appointment_Year'] = noshow['AppointmentDay'].apply(lambda x: x.year)\nnoshow['Appointment_WeekDay'] = noshow['AppointmentDay'].apply(lambda x: x.strftime(\"%A\"))\n\n#Diferenca entre datas\nnoshow['DeltaScheduleAppointment_Days'] = noshow['ScheduledDay']-noshow['AppointmentDay']\nnoshow['DeltaScheduleAppointment_Days'] = noshow['DeltaScheduleAppointment_Days']/np.timedelta64(1,'D')\n\n#tratando dados diferenca negativa\nnoshow['DeltaScheduleAppointment_Days'] = np.where(noshow['DeltaScheduleAppointment_Days'] < 0 \n                                                   ,0,noshow['DeltaScheduleAppointment_Days'] )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OneHotEncoder nas variavéis categoricas Gender, Handcap, Appointment_WeekDay,Scheduled_WeekDay e faixa etária\nAplicando OneHotEncoder as variavéis se transformam em novas colunas onde 1 representa o valor afirmativo e 0 o valor negativo\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from category_encoders.one_hot import OneHotEncoder\nnoshow_bin = noshow\n\nbinarizar = OneHotEncoder(cols= ['Gender','Handcap','Appointment_WeekDay','Scheduled_WeekDay','fx_etaria'],use_cat_names=True)\nbinarizar.fit(noshow_bin)\nnoshow_bin = binarizar.transform(noshow_bin)\n\nnoshow_bin.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Padronizando das variáveis contínuas \npadronização = x - média/desvio padrao \nO processo faz com que todas minhas variaveis numéricas permanecam na mesma escala"},{"metadata":{"trusted":true},"cell_type":"code","source":"noshow_bin.reset_index()\n\nfrom sklearn import preprocessing\npadronizar = preprocessing.StandardScaler().fit(noshow_bin[['Age','Scheduled_Month','Scheduled_Year'\n                                                            ,'Appointment_Month','Appointment_Year'\n                                                            ,'DeltaScheduleAppointment_Days']])\n\nnoshow_bin[['Age','Scheduled_Month','Scheduled_Year','Appointment_Month','Appointment_Year'\n,'DeltaScheduleAppointment_Days']] = padronizar.transform(noshow_bin[['Age'\n                                                                     ,'Scheduled_Month'\n                                                                     ,'Scheduled_Year'\n                                                                     ,'Appointment_Month'\n                                                                     ,'Appointment_Year'\n                                                                     ,'DeltaScheduleAppointment_Days']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Separando variável target das features"},{"metadata":{"trusted":true},"cell_type":"code","source":"noshow_bin.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = noshow_bin.loc[:,['Age','Appointment_Month', 'Appointment_Year','Scheduled_Year','DeltaScheduleAppointment_Days'\n                      ,'Scheduled_Month'#numericos\n                      ,'Gender_F', 'Gender_M','Scholarship','Hipertension','Diabetes', 'Alcoholism'#categoricos\n                      , 'Handcap_0.0', 'Handcap_1.0', 'Handcap_2.0','Handcap_3.0', 'Handcap_4.0'\n                      , 'SMS_received','Scheduled_WeekDay_Friday'\n                      ,'Scheduled_WeekDay_Wednesday', 'Scheduled_WeekDay_Tuesday'\n                      ,'Scheduled_WeekDay_Thursday', 'Scheduled_WeekDay_Monday'\n                      ,'Scheduled_WeekDay_Saturday','Appointment_WeekDay_Friday'\n                      , 'Appointment_WeekDay_Tuesday','Appointment_WeekDay_Monday'\n                      , 'Appointment_WeekDay_Wednesday','Appointment_WeekDay_Thursday'\n                      , 'Appointment_WeekDay_Saturday','fx_etaria_60-70', 'fx_etaria_50-60'\n                      , 'fx_etaria_0-10', 'fx_etaria_>70','fx_etaria_20-30', 'fx_etaria_30-40'\n                      , 'fx_etaria_10-20','fx_etaria_40-50']]\ny = noshow_bin.loc[:,'No-show']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nx[['Gender_F', 'Gender_M','Scholarship','Hipertension','Diabetes', 'Alcoholism'\n          , 'Handcap_0.0', 'Handcap_1.0', 'Handcap_2.0','Handcap_3.0', 'Handcap_4.0'\n          , 'SMS_received','Scheduled_WeekDay_Friday'\n          ,'Scheduled_WeekDay_Wednesday', 'Scheduled_WeekDay_Tuesday'\n          ,'Scheduled_WeekDay_Thursday', 'Scheduled_WeekDay_Monday'\n          ,'Scheduled_WeekDay_Saturday','Appointment_WeekDay_Friday'\n          , 'Appointment_WeekDay_Tuesday','Appointment_WeekDay_Monday'\n          , 'Appointment_WeekDay_Wednesday','Appointment_WeekDay_Thursday'\n          , 'Appointment_WeekDay_Saturday','fx_etaria_60-70', 'fx_etaria_50-60'\n          , 'fx_etaria_0-10', 'fx_etaria_>70','fx_etaria_20-30', 'fx_etaria_30-40'\n          , 'fx_etaria_10-20','fx_etaria_40-50']].apply(LabelEncoder().fit_transform)\n\ny = LabelEncoder().fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dividindo o dataframe em 70% treino e 30% teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_treino, x_teste, y_treino, y_teste = train_test_split(x,y,test_size=0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Xgboost\nmodelo baseando em gradient boosting onde o previsor sucessor é criado baseado no residuo do previsor antecessor"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import recall_score,accuracy_score,classification_report,confusion_matrix\n\nxgboost_ = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.8, learning_rate = 0.2,\n                max_depth = 7, n_estimators = 100,random_state=0)\nxgboost_.fit(x_treino,y_treino)\n\n#realização do predict\nprevisoes = xgboost_.predict(x_teste)\n\nprint('recall:' , recall_score(previsoes,y_teste))\nprint('accuracy:' , accuracy_score(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(confusion_matrix(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(classification_report(previsoes,y_teste))\n\nxgb.plot_importance(xgboost_)\nplt.show() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visulaizando feature_importance\nfeature = []\nfor feature in zip(x_treino, xgboost_.feature_importances_):\n    print(feature)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tuning Hiperparâmetros - Grid Search - Xgboost\nTentar todos as combinações possíveis utilizando os hiperparametros passados, foi utilizado os hiperparametros:\nlearning_rate = taxa de aprendizado, max_depth = máxima rofundidade das arvores, colsample_bytree = porcentagem de colunas utilizadas em cada árvore"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparametros = [{'learning_rate':[0.01,0.1,0.2],\n                'max_depth':[5,7],\n                'colsample_bytree':[0.7,0.8,0.9]}]\n\nxgboost = xgb.XGBClassifier(objective ='reg:logistic', n_estimators = 100,random_state=0)\n\ngrid_search =  GridSearchCV(xgboost,parametros,scoring='recall',cv=4,verbose=1)\n\ngrid_search.fit(x_treino,y_treino)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melhores hiperparametros\ngrid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skopt import dummy_minimize\nimport lightgbm as lgb   \ngradient = lgb.LGBMClassifier(learning_rate=0.09955911573844406 #resultado do randomsearch\n                             ,colsample_bytree=0.7472177953903952  #resultado do randomsearch\n                             ,max_depth=6  #resultado do randomsearch\n                             ,n_estimators=176  #resultado do randomsearch\n                              ,random_state=0\n                                )\ngradient.fit(x_treino,y_treino)\nprevisoes = gradient.predict(x_teste)\nprint('recall:' , recall_score(previsoes,y_teste))\nprint('accuracy:' , accuracy_score(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(confusion_matrix(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(classification_report(previsoes,y_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tuning Hiperparâmetros - Random Search - LGBM\nAo invés de tentar todas as combinações possíveis como o Gridsearch ela seleciona o valor aleatório para o hiperparametro e vai testando aleatoriamente as combinações o random search vai executar o número de iterações definido pelo usuário e no final terá como saida os melhores hiperparametros dessa busca aleatoria em n iterações"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skopt import dummy_minimize\nfrom lightgbm import LGBMClassifier\ndef treinar_modelo(params):\n    learning_rate = params[0]\n    colsample_bytree = params[1]\n    max_depth = params[2]\n    n_estimators= params[3]\n    \n    print(params, '\\n')\n    \n    modelo = LGBMClassifier(learning_rate=learning_rate\n                         ,colsample_bytree=colsample_bytree\n                         ,max_depth=max_depth\n                         ,n_estimators=n_estimators,random_state = 0)\n    modelo.fit(x_treino, y_treino)\n    \n    previsoes = modelo.predict(x_treino)\n    \n    return -recall_score(y_treino, previsoes,average=\"binary\")\n\nspace = [(1e-3, 1e-1, 'log-uniform'), #learning rate\n         (0.7,0.9),#colsample_bytree\n         (5,9), #max_depth\n         (100, 200)] #n_estimators\n\nresultado = dummy_minimize(treinar_modelo, space, random_state=1, verbose=1, n_calls=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultado.x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visulaizando feature_importance\nfeature_lgbm = []\nfor feature_lgbm in zip(x_treino, gradient.feature_importances_):\n    print(feature_lgbm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection - LGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\n#Treinando o modelo usando as features mais importantes\nthresholds = sorted(gradient.feature_importances_,reverse=True) #ordenando as features com mais poder \n\nfor thresh in thresholds:\n    selection = SelectFromModel(gradient, threshold=thresh, prefit=True)\n    select_x_treino = selection.transform(x_treino)\n\n    #treinando o modelo\n    selection_model = lgb.LGBMClassifier(learning_rate=0.09955911573844406 #resultado do randomsearch\n                             ,colsample_bytree=0.7472177953903952  #resultado do randomsearch\n                             ,max_depth=6  #resultado do randomsearch\n                             ,n_estimators=176  #resultado do randomsearch\n                              ,random_state=0\n                                )\n    selection_model.fit(select_x_treino, y_treino)\n\n    #avaliando os modelos\n    select_x_teste = selection.transform(x_teste)\n    y_pred = selection_model.predict(select_x_teste)\n    previsoes= [round(value) for value in y_pred]\n    accuracy = accuracy_score(previsoes,y_teste)\n    recall = recall_score(previsoes,y_teste)\n    print(\"Thresh=%.3f, n=%d, Recall:%.2f%%, Accuracy: %.2f%%\" % (thresh, select_x_treino.shape[1]\n                                                                 ,recall*100.0, accuracy*100.0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bagging \nAlgoritmo baseado em árvores de decisão na qual ele faz a amostragem com repetição (bootstrap) nas instâncias onde cada conjunto de amostras resultará em um modelo diferente, sendo que a previsão final será estimada baseada em hard voting, nesse desafio como estamos tratando de um problema de classificação o valor estimado será baseada na frequencia em relação a previsão de todas arvores de decisão criadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import recall_score,accuracy_score,classification_report,confusion_matrix\n\nmodelo = BaggingClassifier(bootstrap=True,n_jobs = -1,n_estimators=100)\nmodelo.fit(x_treino,y_treino)\nprevisoes = modelo.predict(x_teste)\nprint('recall:' , recall_score(previsoes,y_teste))\nprint('accuracy:' , accuracy_score(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(confusion_matrix(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(classification_report(previsoes,y_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest\nGeralmente é um algoritmo de bagging ou pasting com max_sample ajustada para o número de instancias do meu dataframe,ou seja irá utilizar todas as linhas do dataframe.Além disso, possui uma aleatoriedade nas caracteristicas selecionadas,ou seja para cada árvore de decisão é selecionada um subconjunto de caracteristicas/feautures.Logo nem todas minhas árvores vão ser iguais"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import recall_score,accuracy_score,classification_report,confusion_matrix\n\nmodelo = RandomForestClassifier(max_depth=5, random_state=0,n_estimators=100)\nmodelo.fit(x_treino,y_treino)\nprevisoes = modelo.predict(x_teste)\nprint('recall:' , recall_score(previsoes,y_teste))\nprint('accuracy:' , accuracy_score(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(confusion_matrix(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(classification_report(previsoes,y_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regressão logistica"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import recall_score,accuracy_score,classification_report,confusion_matrix\n\nmodelo = LogisticRegression(random_state=0,solver='liblinear',penalty='l1')\nmodelo.fit(x_treino,y_treino)\nprevisoes = modelo.predict(x_teste)\nprint('recall:' , recall_score(previsoes,y_teste))\nprint('accuracy:' , accuracy_score(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(confusion_matrix(previsoes,y_teste))\nprint('---------------------------------------------')\nprint(classification_report(previsoes,y_teste))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algoritmo final"},{"metadata":{"trusted":true},"cell_type":"code","source":"#transformando o feature inportance do modelo LGBM em um dataframe\nresults=pd.DataFrame()\nresults['columns']=x_treino.columns\nresults['importances'] = gradient.feature_importances_\nresults.sort_values(by='importances',ascending=False,inplace=True)\nresults.reset_index().head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_treino, x_teste, y_treino, y_teste = train_test_split(x,y,test_size=0.3,random_state=1)\n#Cortando as features de acordo com os modelos rodados na etapa feautre selection com lgbm\nfeatures_final = results.iloc[:31,0] #Resultado com feature selection \n\n#redefinindo x_treino e x_teste\nx_treino = x_treino.loc[:,features_final]\nx_teste = x_teste.loc[:,features_final]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reaplicado o algoritimo\ngradient = lgb.LGBMClassifier(learning_rate=0.09955911573844406 #resultado do randomsearch\n                             ,colsample_bytree=0.7472177953903952  #resultado do randomsearch\n                             ,max_depth=6  #resultado do randomsearch\n                             ,n_estimators=176  #resultado do randomsearch\n                              ,random_state=0\n                                )\ngradient.fit(x_treino,y_treino)\nprevisoes = gradient.predict(x_teste)\nprint('Resultado final:')\nprint('----------------------------------------')\nprint('Dos exemplos que são noshow positivo qual a porcetangem de acerto do modelo?')\nprint('recall final:' , recall_score(previsoes,y_teste)*100)\nprint('----------------------------------------')\nprint('Porcentagem de acerto da minhas observações?')\nprint('accuracy final:', accuracy_score(previsoes,y_teste)*100)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}