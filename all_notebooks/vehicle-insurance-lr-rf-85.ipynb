{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA\nI have done EDA and Baseline Model[ here](https://www.kaggle.com/arunkumar13111/vehicle-insurance-prediction-auc-84). In this notebook, i will  explore following classification algoithms for understanding.\n1. Logistic Regression\n2. RandomForest"},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data \ntrain = pd.read_csv(\"/kaggle/input/health-insurance-cross-sell-prediction/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/health-insurance-cross-sell-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.info(),test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split numerical and categorical feature\nnum_feature = [\"Age\",\"Vintage\",\"Annual_Premium\"]\ncat_feature = [\"Gender\",\"Driving_License\",\"Region_Code\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\",\"Policy_Sales_Channel\"]\n\n# convert into integer\ntrain[\"Policy_Sales_Channel\"] = train[\"Policy_Sales_Channel\"].astype(\"int\")\ntrain[\"Region_Code\"] = train[\"Region_Code\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"psc_tot = train[\"Policy_Sales_Channel\"].value_counts()\ntrain[\"psc_count\"] = train[\"Policy_Sales_Channel\"].map(psc_tot)\npsc_scount = train[train[\"Response\"]==1].groupby(\"Policy_Sales_Channel\")[\"Response\"].count()\ntrain[\"psc_scount\"] = train[\"Policy_Sales_Channel\"].map(psc_scount)\ntrain[\"psc_success_rate\"] = (train[\"psc_scount\"]/train[\"psc_count\"])*100\ntrain[\"psc_success_rate\"].fillna(0,inplace=True)\nreg_tot = train[\"Region_Code\"].value_counts()\ntrain[\"reg_count\"] = train[\"Region_Code\"].map(reg_tot)\npsc_scount = train[train[\"Response\"]==1].groupby(\"Region_Code\")[\"Response\"].count()\ntrain[\"reg_scount\"] = train[\"Region_Code\"].map(psc_scount)\ntrain[\"reg_success_rate\"] = (train[\"reg_scount\"]/train[\"reg_count\"])*100\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Binning the Age \ntrain[\"Age_Cat\"]= pd.cut(train[\"Age\"],bins=[10,20,30,40,50,60,70,80,90,100],labels=[1,2,3,4,5,6,7,8,9])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"# Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode the categorical varriable (encoding policy sales channel and Region Code makes high cardinality so i avoid encoding for this fields )\nohe = OneHotEncoder(sparse=False)        \ntransformed_train_data = ohe.fit_transform(train[[\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"]])\n\n# # the above transformed_data is an array so convert it to dataframe\nencoded_train_data = pd.DataFrame(transformed_train_data, index=train.index)        \nencoded_train_data.columns = ohe.get_feature_names([\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\"])\ntrain_data = pd.concat([train, encoded_train_data], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc =  StandardScaler()\nvintage_scaled_array = sc.fit_transform(train_data[[\"Vintage\",\"Region_Code\",\"Policy_Sales_Channel\",\"psc_success_rate\",\"reg_success_rate\"]])\n\nminmaxsc = MinMaxScaler()\nannual_premium_scaled_array = minmaxsc.fit_transform(train_data[[\"Annual_Premium\"]])\n\ntrain_data[[\"Vintage\",\"Region_Code\",\"Policy_Sales_Channel\",\"psc_success_rate\",\"reg_success_rate\"]] = vintage_scaled_array\ntrain_data[\"Sc_Annual_Premium\"] = annual_premium_scaled_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = train_data.drop([\"id\",\"Age\",\"Age_Cat\",\"Gender\",\"Vehicle_Age\",\"psc_count\",\"psc_scount\",\"reg_count\",\"reg_scount\",\"Vintage\",\"Annual_Premium\",\"Previously_Insured\",\"Driving_License\",\"Vehicle_Damage\",\"Response\"], axis=1)\ntrainY = train_data[\"Response\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling\nHere target(Response) is a imbalanced data, So i have used stratified cross validation method\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nlogreg = LogisticRegression(random_state=0,max_iter=1000)\nmodels = {\n    \"Logistic Regression\":logreg,\n}\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor model_name,model in models.items():\n    scores = []\n    train_scores = []\n    for train_indx,val_indx in skf.split(X=trainX,y=trainY):\n        #get train and test data     \n        X_train,X_val = trainX.loc[train_indx],trainX.loc[val_indx]\n        Y_train,Y_val = trainY[train_indx],trainY[val_indx]\n        model.fit(X_train,Y_train)\n        #make a prediction\n        Y_predict = model.predict_proba(X_val)\n\n        accuracy = roc_auc_score(Y_val,Y_predict[:,1])\n        Ytrain_predict = model.predict_proba(X_train)\n        train_accuracy = roc_auc_score(Y_train,Ytrain_predict[:,1])        \n        print(\"train\",train_accuracy)\n        print(\"test\",accuracy)\n        scores.append(accuracy)\n        train_scores.append(train_accuracy)\n    print(\"Mean Accurracy of test {0} is {1}\".format(model_name,np.mean(scores)))\n    print(\"Mean Accurracy of train {0} is {1}\".format(model_name,np.mean(train_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding(Ordinal Encoder)"},{"metadata":{"trusted":true},"cell_type":"code","source":"oe = OrdinalEncoder()\ntrain[[\"Gender\",\"Vehicle_Damage\",\"Vehicle_Age\",\"Age_Cat\"]] = oe.fit_transform(train[[\"Gender\",\"Vehicle_Damage\",\"Vehicle_Age\",\"Age_Cat\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = train.drop([\"id\",\"Age\",\"Vintage\",\"psc_count\",\"psc_scount\",\"reg_count\",\"reg_scount\",\"Response\"], axis=1)\ntrainY = train[\"Response\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nrf = RandomForestClassifier(n_estimators=7,max_depth=10)\nmodels = {\n    \"rf\":rf,\n}\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor model_name,model in models.items():\n    scores = []\n    train_scores = []\n    for train_indx,val_indx in skf.split(X=trainX,y=trainY):\n        #get train and test data     \n        X_train,X_val = trainX.loc[train_indx],trainX.loc[val_indx]\n        Y_train,Y_val = trainY[train_indx],trainY[val_indx]\n        model.fit(X_train,Y_train)\n        #make a prediction\n        Y_predict = model.predict_proba(X_val)\n\n        accuracy = roc_auc_score(Y_val,Y_predict[:,1])\n        Ytrain_predict = model.predict_proba(X_train)\n        train_accuracy = roc_auc_score(Y_train,Ytrain_predict[:,1])        \n        print(\"train\",train_accuracy)\n        print(\"test\",accuracy)\n        scores.append(accuracy)\n        train_scores.append(train_accuracy)\n    print(\"Mean Accurracy of test {0} is {1}\".format(model_name,np.mean(scores)))\n    print(\"Mean Accurracy of train {0} is {1}\".format(model_name,np.mean(train_scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}