{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nimport cv2 as cv\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nimport cv2 \nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom keras.optimizers import SGD\nfrom keras.callbacks import TensorBoard\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n      #for filename in filenames:\n       #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"traindf=pd.read_csv(\"/kaggle/input/detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Train.csv\")\nprint(traindf.shape)\ntestdf=pd.read_csv(\"/kaggle/input/detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Test.csv\")\nprint(testdf.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.head()\ntestdf.head()\nprint(traindf.shape)\ntraindf.loc[traindf['Frame_ID'] == 'frame0.jpg']['Emotion']\nclass_names =np.unique(traindf['Emotion'])\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\nprint(class_names_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nimport cv2\nvidcap = cv2.VideoCapture('detect-emotions-of-your-favorite-toons/96714c94-6-Dataset/Dataset/Test Tom and jerry.mp4')\n\ndef getFrame(sec):\n    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n    hasFrames,image = vidcap.read()\n    if hasFrames:\n        cv2.imwrite(\"/kaggle/input/detect-emotions-of-your-favorite-toons/frames/train_frames/\"+str(count)+\".jpg\", image) # save frame as JPG file\n    return hasFrames,image\ntrain_images =[]\nIMAGE_SIZE = (150,150)\nsec = 1\nframeRate = 1 #//it will capture image in each 0.5 second\ncount=1\nsuccess,image = getFrame(sec)\nwhile success:\n    count = count + 1\n    sec = sec + frameRate\n    sec = round(sec, 2)\n    success = getFrame(sec)\n    \n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = (150, 150)\ndataset = '/kaggle/input/detect-emotions-of-your-favorite-toons/frames/train_frames'\noutput = []\ntrain_images = []\ntrain_labels = []\nfor files in tqdm(os.listdir(dataset)):\n    try:\n        label = class_names_label[traindf.loc[traindf['Frame_ID'] == files]['Emotion'].values[0]]\n    except:\n        #do nothing\n        a=1\n    img_path=os.path.join(dataset, files)\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, IMAGE_SIZE) \n    train_images.append(image)\n    train_labels.append(label)\ntrain_images = np.array(train_images, dtype = 'float32')/255\ntrain_labels = np.array(train_labels, dtype = 'int32') \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_images[1].shape)\nplt.imshow(train_images[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = (150, 150)\ndataset = '/kaggle/input/detect-emotions-of-your-favorite-toons/frames/test_frames'\noutput = []\ntest_images = []\nfor files in tqdm(os.listdir(dataset)):\n    img_path=os.path.join(dataset, files)\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, IMAGE_SIZE) \n    test_images.append(image)\ntest_images = np.array(test_images, dtype = 'float32')/255 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_images[2].shape)\nplt.imshow(test_images[2])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(train_images,train_labels,test_size=0.3)\ninput_shape = x_train.shape[1:]\n# Normalize data.\nx_train = x_train.astype('float32') \ny_train = y_train.astype('float32') \nprint(input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(x_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()\n\n\nclassifier.add(Conv2D(32,(3,3), input_shape = (150,150, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Conv2D(32,(3,3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size = (2,2)))\nclassifier.add(Conv2D(32,(3,3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size = (2,2)))\nclassifier.add(Conv2D(32,(3,3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size = (2,2)))\nclassifier.add(Dropout(0.5))\nclassifier.add(Flatten())\nclassifier.add(Dense(output_dim = 300, activation = 'relu'))\nclassifier.add(Dense(output_dim = 100, activation = 'relu'))\nclassifier.add(Dense(output_dim = 5, activation = 'softmax'))\n\n# Compiling the CNN\nfrom keras import optimizers\n\n\nclassifier.compile(optimizer = Adam(lr=0.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\nepochs=100\nclassifier.fit(x_train,\n             y_train,\n             batch_size=32,\n             nb_epoch=epochs,\n             verbose=1,\n             validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = classifier.evaluate(x_val, y_val, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}