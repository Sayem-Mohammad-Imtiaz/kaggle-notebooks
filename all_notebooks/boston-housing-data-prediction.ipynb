{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing = pd.read_csv(\"../input/california-housing-prices/housing.csv\")\nhousing.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"housing = pd.read_csv(\"../input/california-housing-prices/housing.csv\")\nhousing.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.hist(bins = 50, figsize = (20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating test set "},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_train_test(data, test_ratio):\n    np.random.seed(42)\n    shuffeled_indices = np.random.permutation(len(data))\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffeled_indices[:test_set_size]\n    train_indices = shuffeled_indices[test_set_size:]\n    return data.iloc[train_indices], data.iloc[test_indices]\n\ntrain_set, test_set = split_train_test(housing, 0.2)\nprint(len(train_set), \"train +\", len(test_set), \"test\")\n\nimport hashlib\ndef test_set_check(identifier, test_ratio, hash):\n    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n\ndef split_train_test_by_id(data, test_ratio, id_column, hash = hashlib.md5):\n    ids = data[id_column]\n    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n    return data.loc[~in_test_set], data.loc[in_test_set]\n\nhousing_with_id = housing.reset_index()\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\nhousing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")\ntrain_set.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\nhousing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace = True)\nhousing.head()\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n strat_train_set = housing.loc[train_index]\n strat_test_set = housing.loc[test_index]\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying Property measurement for every data set  "},{"metadata":{"trusted":true},"cell_type":"code","source":"housing[\"income_cat\"].value_counts() / len(housing)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"strat_train_set[\"income_cat\"].value_counts() / len(housing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"strat_test_set[\"income_cat\"].value_counts() / len(housing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droped the 'income_cat' colum for restoring the data set\nfor set in (strat_test_set, strat_train_set):\n    set.drop([\"income_cat\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Backup the train data set \nhousing_new = strat_train_set.copy()\n# plot the train data set \nhousing_new.plot(kind = \"scatter\", x = \"longitude\", y = \"latitude\", alpha =  0.1,\n    s = housing_new[\"population\"] /100, label = \"population\",\n    c = \"median_house_value\", cmap = plt.get_cmap(\"jet\"), colorbar = True ,)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding Out the corelation coefficient\ncorr_matrix = housing_new.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning Data\n# Separationg a targeted column to apply cleaning functions\nhousing_new = strat_train_set.drop(\"median_house_value\", axis = 1)\nhousing_labels = strat_train_set[\"median_house_value\"].copy()\n\n# Eleminating invalid values\nmedian =  housing_new[\"total_bedrooms\"].median()\nhousing_new[\"total_bedrooms\"].fillna(median)\n# using sklearn imputer for filling up the missing value\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(strategy = \"median\")\nhousing_num = housing_new.drop(\"ocean_proximity\", axis=1)\nimputer.fit(housing_num)\n#imputer stores missing values in it's stattistics_ instance.\nimputer.statistics_\n#implementing imputer to all numarical valuses\n#finding out the median value for the dataset to train the imputer model\nhousing_num.median().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying the imputer model to the new dataset\nx = imputer.transform(housing_num)\n#this is holding a numpy array. So we need to convert to the pandas dataframe formate\nhousing_tr = pd.DataFrame(x, columns=housing_num.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We leftout \"oceans_proximity\" columns because of text attribute. So now converting this text labels to numbers to calculate the median value\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nhousing_cat = housing[\"ocean_proximity\"]\nhousing_cat_encoded = encoder.fit_transform(housing_cat)\nhousing_cat_encoded\n#showing the encoded text values\nprint(encoder.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting this to OneHotEncoder to find out the more similer values in this array\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse = True)\nhousing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\nhousing_cat_1hot.toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sparse matrix is matrix which contains most of the zero elements. On the contrast dense matrix contains the most no zero elements "},{"metadata":{"trusted":true},"cell_type":"code","source":"# using LabelBinarizer to convert this sparse matrix to dense matrix\nfrom sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer()\nhousing_cat_1hot = encoder.fit_transform(housing_cat) \nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom Transformar \nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nrooms_ix, bedroom_ix, population_ix, household_ix = 3,4,5,6\n    \nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True):\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n        \n    def fit(self, X, y = None):\n        return self\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] / X[: , household_ix]\n        population_per_household = X[:, population_ix] / X[:, household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedroom_ix] / X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing_new.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transformation Pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n    ('imputer', Imputer(strategy = \"median\")),\n    ('attribs_adder', CombinedAttributesAdder()),\n    ('std_scaler', StandardScaler()),\n])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Labelbinizer to transform Cat (text) pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.base import BaseEstimator, TransformerMixin\n# from sklearn_features.transformers import DataFrameSelector\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names=attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values\n    \n# Custom LabelBinarizer \nclass MYLabelBinarizer(BaseEstimator, TransformerMixin):\n    def __init__(self, sparse_output=False):\n        self.sparse_output = sparse_output\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X, y=None):\n        enc = LabelBinarizer(sparse_output=self.sparse_output)\n        return enc.fit_transform(X)\n    \nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector(num_attribs)),\n    ('imputer', Imputer(strategy = \"median\")),\n    ('attr_adder', CombinedAttributesAdder()),\n    ('std_scaler', StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    ('selector', DataFrameSelector (cat_attribs)),\n    ('label_binarizer', MYLabelBinarizer()),\n])\n\nfull_pipeline = FeatureUnion( transformer_list=[\n    (\"num_pipeline\", num_pipeline),\n    (\"cat_pipeline\", cat_pipeline),\n])\n\n# Applying Pipeline to training dataset\n\nhousing_perpared = full_pipeline.fit_transform(housing_new)\nhousing_perpared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_perpared.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression model appliying to perpared dataset\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(housing_perpared, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_labels.iloc[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_new.iloc[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction with Linear Regression model \n\n# some_data = housing.iloc[:5]\n# some_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(housing_new)\nprint(\"Predictions: \\t\", lin_reg.predict(some_data_prepared))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}