{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport re\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/labeledTrainData.tsv', sep='\\t')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain, xvali, ytrain, yvali = train_test_split(df.review, df.sentiment, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Buid Vocabulary"},{"metadata":{"trusted":true},"cell_type":"code","source":"def CleanDocument(document):\n    # replace < br/> with new_line_tag\n    clean_doc = re.sub(r'\\<br /\\>', 'new_line_tag ', document)\n    # remove punctuation\n    clean_doc = re.sub(r'\\W', ' ', clean_doc)\n    # map numbers to NUMBERS\n    return clean_doc.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean train data\nxtrain_after_clean = xtrain.apply(CleanDocument)\nxtrain_after_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# map word to id\ndef GetVocabulary(data):\n    vocabulary = dict()\n    wid = 0\n    for document in data:\n        words = document.split()\n        for w in words:\n            if w not in vocabulary:\n                vocabulary[w] = wid\n                wid += 1\n    return vocabulary\n\nvocab_dict = GetVocabulary(xtrain_after_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert document to vectors\ndef Document2Vector(document, vocabulary):\n    doc_vec = np.zeros(len(vocabulary))\n    out_of_voc = 0\n\n    words = document.split()\n    for w in words:\n        if w in vocabulary:\n            wid = vocabulary[w]\n            doc_vec[wid] += 1\n        else:\n            out_of_voc += 1\n    return doc_vec, out_of_voc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_matrix = []\n\nfor document in xtrain_after_clean:\n    doc_vec, _ = Document2Vector(document,vocab_dict)\n    train_matrix.append(doc_vec)\n\nprint(len(train_matrix))\nprint(train_matrix[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def NaiveBayes_train(train_matrix, labels):\n    '''\n    Calculate the log of p(pos), p(neg), p(word|pos) vector, p(word|neg) vector\n    '''\n    num_docs = len(train_matrix)\n    num_words = len(train_matrix[0])\n    \n    pos_count, neg_count = 0, 0\n    pos_total_word, neg_total_word = 0, 0\n    pos_word_vector = np.ones(num_words)\n    neg_word_vector = np.ones(num_words)\n    \n    for i in range(num_docs):\n        if (i + 1) % 2000 == 0:\n            print('Training %d/%d...' % (i+1, num_docs))\n        if labels[i] == 1:\n            pos_count += 1\n            pos_total_word += sum(train_matrix[i])\n            pos_word_vector += train_matrix[i]\n        else:\n            neg_count += 1\n            neg_total_word += sum(train_matrix[i])\n            neg_word_vector += train_matrix[i]\n            \n    p_pos = np.log(pos_count / num_docs)\n    p_neg = np.log(neg_count / num_docs)\n    p_pos_word_vector = np.log(pos_word_vector / (pos_total_word + num_words))\n    p_neg_word_vector = np.log(neg_word_vector / (neg_total_word + num_words))\n    \n    return p_pos, p_pos_word_vector, p_neg, p_neg_word_vector, pos_total_word, neg_total_word\n\n\np_pos, p_pos_word_vector, p_neg, p_neg_word_vector, pos_total_word, neg_total_word = NaiveBayes_train(train_matrix, ytrain.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predictions with NB classifier\ndef predict(test_vector, p_pos, p_pos_word_vector, p_neg, p_neg_word_vector, pos_smoothing, neg_smoothing):\n    pos = np.sum(test_vector * p_pos_word_vector) + p_pos + pos_smoothing\n    neg = np.sum(test_vector * p_neg_word_vector) + p_neg + neg_smoothing\n    if pos > neg:\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions on validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean validation set\nxvali_after_clean = xvali.apply(CleanDocument)\nnum_words = len(vocab_dict)\npred_vali = []\n\nfor i, document in enumerate(xvali_after_clean):\n    if (i + 1) % 500 == 0:\n        print('Testing %d/%d...' % (i + 1, xvali_after_clean.shape[0]))\n    test_vec, out_of_voc = Document2Vector(document, vocab_dict)\n    if out_of_voc == 0:\n        pos_smoothing, neg_smoothing = 0, 0\n    else:\n        pos_smoothing = np.log(out_of_voc / (pos_total_word + num_words))\n        neg_smoothing = np.log(out_of_voc / (neg_total_word + num_words))\n        \n    output = predict(test_vec, p_pos, p_pos_word_vector, p_neg, p_neg_word_vector, pos_smoothing, neg_smoothing)\n    pred_vali.append(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nprint('Accuracy score: %s' % (accuracy_score(yvali, pred_vali)))\nprint('Classificatin report: ')\nprint(classification_report(yvali, pred_vali))\nprint('Confusion matrix: ')\nprint(confusion_matrix(yvali, pred_vali))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}