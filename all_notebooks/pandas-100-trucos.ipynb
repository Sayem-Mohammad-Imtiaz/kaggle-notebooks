{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bienvenido a este kernel\n\n* Este kernel es una recopilación de trucos de pandas publicados por Kevin Markham semanalmente.\n\nPuedes encontrar los trucos originales de los 100 pandas (creados por [Kevin Markham](https://www.linkedin.com/in/justmarkham/) desde los datos de la escuela) en esta página: \n\nhttps://www.dataschool.io/python-pandas-tips-and-tricks/\n\n## <span style=\"color:green\">*Si quieres aprender ** sklearn **, mira este kernel con trucos y consejos:</span>\n\nhttps://www.kaggle.com/python10pm/sklearn-24-best-tips-and-tricks"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"tabla_de_contenido\"></a>\n# Tabla de contenido\n\n[Importando bibliotecas y configurando algunas funciones auxiliares] (#Importaciones)\n\n[Truco 100: carga de muestra de un archivo de macrodatos] (#truco100)\n\n[Truco 99: Cómo evitar Sin nombre: 0 columnas] (#truco99)\n\n[Truco 98: convierte un DF ancho en uno largo] (#truco98)\n\n[Truco 97: convierte el año y el día del año en una sola columna de fecha y hora] (#truco97)\n\n[Truco 96: Diagramas interactivos listos para usar en pandas] (#truco96)\n\n[Truco 95: cuenta los valores que faltan] (#truco95)\n\n[Truco 94: ahorra memoria corrigiendo los tipos de fechas] (#truco94)\n\n[Truco 93: combina las categorías pequeñas en una sola categoría llamada \"Otros\" (usando frecuencias)] (#truco93)\n\n[Truco 92: columna de Objeto limpio con datos mixtos usando expresiones regulares] (#truco92)\n\n[Truco 91: Creación de un conjunto de datos de series temporales para realizar pruebas] (#truco91)\n\n[Truco 90: mover columnas a una ubicación específica] (#truco90)\n\n[Truco 89: Divide los nombres en nombre y apellido] (#truco89)\n\n[Truco 88: reacomodar columnas en un DF] (#truco88)\n\n[Truco 87: agrega tu fecha y hora por y filtra los fines de semana] (#truco87)\n\n[Truco 86: agregaciones con nombre; evita el índice múltiple] (#truco86)\n\n[Truco 86bis: agregaciones con nombre en varias columnas; evita el índice múltiple] (#truco86)\n\n[Truco 85: convierte un tipo de valores en otros] (#truco85)\n\n[Truco 84: Mostrar menos filas en un df] (#truco84)\n\n[Truco 83: Corrija los tipos de datos al importar el df] (#truco83)\n\n[Truco 82: seleccionar datos por etiqueta y posición (iloc y loc encadenados)] (#trick82)\n\n[Truco 81: use aplicar (tipo) para ver si tiene tipos de datos mixtos] (#truco81)\n\n[Truco 80: seleccione varios sectores de columnas de un df] (#truco80)\n\n[Truco 79: recuento de filas que coinciden con una condición] (#truco79)\n\n[Truco 78: realiza un seguimiento de la procedencia de tus datos cuando utilizas varias fuentes] (#truco78)\n\n[Truco 77: Combina las categorías pequeñas en una sola categoría llamada \"Otros\" (usando dónde)] (#truco77)\n\n[Truco 76: filtra en pandas solo las categorías más grandes.] (#Truco76)\n\n[Truco 75: cuenta el número de palabras en una serie de pandas] (#truco75)\n\n[Truco 74: Webscraping usando read_html () y parámetro de coincidencia] (#truco74)\n\n[Truco 73: Elimina una columna y guárdala como una serie separada] (#truco73)\n\n[Truco 72: Convertir variable continua en categórica] (#truco72)\n\n[Truco 71: Leer datos de un PDF (tabula py)] (#truco71)\n\n[Truco 70: Imprime la versión actual de pandas y sus dependencias] (#truco70)\n\n[Truco 69: comprueba si 2 series son \"similares\"] (#truco69)\n\n[Truco 68: Webscraping usando read_html ()] (#truco68)\n\n[Truco 67: Crea nuevas columnas o sobrescribe usando assing] (#truco67)\n\n[Truco 66: Cree un montón de columnas nuevas usando un bucle for y f-strings df [f '{col} _new']] (#truco66)\n\n[Truco 65: seleccione columnas usando f-strings (nuevo en pandas 3.6 +)] (#truco65)\n\n[Truco 64: Corregir \"SettingWithCopyWarning\" al crear nuevas columnas] (#truco64)\n\n[Truco 63: Calcule el recuento continuo con grupos usando cumcount () + 1] (#truco63)\n\n[Truco 62: Corregir \"SettingWithCopyWarning\" al cambiar columnas usando loc] (#truco62)\n\n[Truco 61: lectura de JSON desde la web en un df] (#truco61)\n\n[Truco 60: Creación de totales acumulados con la función cumsum] (#truco60)\n\n[Truco 59: Combina la salida de una agregación con el df original usando transform] (#truco59)\n\n[Truco 58: utilice encabezados y saltos para deshacerse de datos incorrectos o filas vacías durante la importación] (#truco58)\n\n[Truco 57: Accediendo a los grupos de un objeto groupby (get_group ())] (#truco57)\n\n[Truco 56: aplique asignaciones a todo el df (applymap)] (#truco56)\n\n[Truco 55: filtrar un df con varios criterios usando reduce] (#truco55)\n\n[Truco 54: Calcula la diferencia entre cada fila y la anterior (diff ())] (#truco54)\n\n[Truco 53: mezclar filas de un df (df.sample ())] (#truco53)\n\n[Truco 52: Hacer tramas con pandas] (#truco52)\n\n[Truco 51: Concatenar cadenas de 2 columnas] (#truco51)\n\n[Truco 50: agregación con nombre con varias columnas que pasan tupples (nuevo en pandas 0.25)] (#truco50)\n\n[Truco 49: Muestreo con pandas (con reemplazo y pesos)] (#truco49)\n\n[Truco 48: Parámetros útiles al usar pd.read_csv ()] (# truco48)\n\n[Truco 47: crea una fila para cada elemento de una lista (explotar)] (#truco47)\n\n[Truco 46: Almacene NaN en un tipo entero con Int64] (#truco46)\n\n[Truco 45: Crea filas para valores separados por comas en una celda (Assing y explotar)] (#truco45)\n\n[Truco 44: usa una variable local dentro de una consulta en pandas (usando @)] (#truco44)\n\n[Truco 43: ¡¡¡Crea una fila para cada elemento de una lista (explotar) !!! ¡¡¡Truco 47 duplicado !!!] (#truco43)\n\n[Truco 42: Nueva función de agregación -> last ()] (#truco42)\n\n[Truco 41: Categorías ordenadas (de pandas.api.types import CategoricalDtypee)] (#truco41)\n\n[Truco 40: Estilo que df rápido con hide_index () y set_caption ()] (#truco40)\n\n[Truco 39: una codificación activa (get_dummies ())] (#truco39)\n\n[Truco 38: Pandas datetime (muchos ejemplos)] (#truco38)\n\n[Truco 37: Pandas cortando loc e iloc (6 ejemplos)] (#truco37)\n\n[Truco 36: Convertir de UTC a otra zona horaria] (#truco36)\n\n[Truco 35: consulta una columna que tenga espacios en el nombre (usando comillas invertidas)] (#truco35)\n\n[Truco 34: Explore un conjunto de datos con creación de perfiles] (#truco34)\n\n[Truco 33: Opciones de visualización de pandas] (#truco33)\n\n[Truco 32: filtrar un df con consulta y evitar variables intermedias] (#truco32)\n\n[Truco 31: Ver todas las columnas de un gran df] (#truco31)\n\n[Truco 30: fusión de pandas -> ver de dónde vienen las columnas (indicador = Verdadero)] (#truco30)\n\n[Truco 29: Acceda a numpy dentro de pandas (sin importar numpy como np)] (#truco29)\n\n[Truco 28: agregación por varias columnas (usando agg)] (#truco28)\n\n[Truco 27: agregación sobre series temporales (remuestreo)] (#truco27)\n\n[Truco 26: Dar formato a diferentes columnas de un df (usando diccionarios)] (#truco26)\n\n[Truco 25: 3 formas de cambiar el nombre de las columnas] (#truco25)\n\n[Truco 24: copie datos de Excel a pandas rápidamente (read_clipboard ())] (#truco24)\n\n[Truco 23: Complete los valores faltantes en los datos de series de tiempo (interpolar ())] (#truco23)\n\n[Truco 22: Cree DataFrames para probar] (#truco22)\n\n[Truco 21: divide una columna de cadena en varias columnas] (#truco21)\n\n[Truco 20: crea columnas de fecha y hora a partir de varias columnas] (#truco20)\n\n[Truco 19: muestra el uso de memoria de un df y cada columna] (#truco19)\n\n[Truco 18: leer y escribir en un archivo comprimido (csv.zip)] (#truco18)\n\n[Truco 17: seleccione varias filas / columnas con loc] (#truco17)\n\n[Truco 16: convierte valores continuos en categóricos (cut ())] (#truco16)\n\n[Truco 15: Remodelar un MultiIndex df (unstack ())] (#truco15)\n\n[Truco 14: Creación de df de juguete (3 métodos)] (#truco14)\n\n[Truco 13: Evita la serie de listas TRAP] (#truco13)\n\n[Truco 12: fusionar conjuntos de datos y comprobar la unicidad] (#truco12)\n\n[Truco 11: cambie el nombre de todas las columnas con el mismo patrón] (#truco11)\n\n[Truco 10: comprueba la igualdad de 2 series] (#truco10)\n\n[Truco 9: Reducir el uso de memoria de un df durante la importación] (#truco9)\n\n[Truco 8: Usar glob para generar un df a partir de varios archivos !!! Truco 78 duplicado !!!] (#truco8)\n\n[Truco 7: Manejo de valores perdidos (NaN)] (#truco7)\n\n[Truco 6: divide un df en 2 subconjuntos aleatorios] (#truco6)\n\n[Truco 5: convierte números almacenados como cadenas (coaccionar)] (#truco5)\n\n[Truco 4: seleccione columnas por dtype] (#truco4)\n\n[Truco 3: filtrar un df por múltiples condiciones (isin e inverso usando ~)] (#truco3)\n\n[Truco 2: orden inverso de un gl] (#truco2)\n\n[Truco 1: agregue un prefijo o sufijo a todas las columnas] (#truco1)\n"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"Importar\"></a>\n# Importar bibliotecas y configurar algunas funciones auxiliares\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# basic libraries\nimport os\nimport numpy as np\nimport pandas as pd\n\n# this will allow us to print all the files as we generate more in the kernel\ndef print_files():\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n# check Trick 91 for an example\ndef generate_sample_data(): # creates a fake df for testing\n    number_or_rows = 20\n    num_cols = 7\n    cols = list(\"ABCDEFG\")\n    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n    df.index = pd.util.testing.makeIntIndex(number_or_rows)\n    return df\n\n# check Trick 91 for an example\ndef generate_sample_data_datetime(): # creates a fake df for testing\n    number_or_rows = 365*24\n    num_cols = 2\n    cols = [\"sales\", \"customers\"]\n    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n    df.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\n    return df\n\n# show several prints in one cell. This will allow us to condence every trick in one cell.\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nprint_files()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco100\"></a>\n# Truco 100: carga de muestra de big data\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_Dec19.csv\")\nprint(\"The shape of the df is {}\".format(df.shape))\n\ndel df\n\ndf = pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_Dec19.csv\", skiprows = lambda x: x>0 and np.random.rand() > 0.01)\nprint(\"The shape of the df is {}. It has been reduced 10 times!\".format(df.shape))\n\n\n'''\nCómo funciona:\nskiprows acepta una función que se evalúa con el índice entero.\nx> 0 se asegura de que los encabezados no se omitan\nnp.random.rand ()> 0.01 devuelve  99% del empate, por lo que se salta el 99% del tiempo.\nTenga en cuenta que estamos usando skiprows\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco99\"></a>\n# Truco 99: Cómo evitar Innominado: 0 columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"zip_code\": [12345, 56789, 101112, 131415],\n\"fabrica\": [100, 400, 500, 600],\n\"almacen\": [200, 300, 400, 500],\n\"minorista\": [1, 2, 3, 4]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# guardar en csv\ndf.to_csv(\"trick99data.csv\")\n\ndf = pd.read_csv(\"trick99data.csv\")\ndf\n# Para evitar Innominado: 0\n\ndf = pd.read_csv(\"trick99data.csv\", index_col=0)\n# o al guardar df = pd.read_csv (\"trick99data.csv\", indice = Falso)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco98\"></a>\n# Truco 98: convierte un DF ancho en uno largo\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"zip_code\": [12345, 56789, 101112, 131415],\n\"fabrica\": [100, 400, 500, 600],\n\"almacen\": [200, 300, 400, 500],\n\"minorista\": [1, 2, 3, 4]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Nosotros tenemos que asignar\n\n# tipo_ubicacion se genera automáticamente a partir de las columnas que quedan después de especificar id_vars (también puede pasar una lista)\ndf = df.melt(id_vars = \"zip_code\", var_name = \"location_type\", value_name = \"distance\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco97\"></a>\n# Truco 97: Convierte el año y el día del año en una sola columna de fecha y hora\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Truco 97\n# Convierte\nd = {\\\n\"año\": [2019, 2019, 2020],\n\"dia_del_año\": [350, 365, 1]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: crea una columna combinada\ndf[\"conjunto\"] = df[\"año\"]*1000 + df[\"dia_del_año\"]\ndf\n\n# Step 2: convert to datetime\ndf[\"fecha\"] = pd.to_datetime(df[\"conjunto\"], format = \"%Y%j\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco96\"></a>\n# Truco 96: parcelas interactivas listas para usar en pandas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.__version__)\n# Se requiere la versión 0.25 o superior de Pandas y necesita hvplot\n\nimport pandas as pd\ndf = pd.read_csv(\"../entrada/bebidas-por-pais/bebidasporpais.csv\")\ndf\n\n# este no es interactivo\ndf.plot(kind = \"dispersion\", x = \"porciones_alcohol\", y = \"raciones_vino\")\n\n# ejecutar!pip instalar hvplot\n#pd.opciones.trazar.respaldos = \"hvplot\"\n#df.plot(kind = \"dispersion\", x = \"porciones_alcohol\", y = \"raciones_vino\", c = \"continente\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco95\"></a>\n# Truco 95: Cuenta los valores perdidos\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\\\n\"col1\": [2019, 2019, 2020],\n\"col2\": [350, 365, 1],\n\"col3\": [np.nan, 365, None]\n}\n\ndf = pd.DataFrame(d)\ndf\n\n# Solucion 1\ndf.isnull().sum().sum()\n\n# Solucion 2\ndf.isna().sum()\n\n# Solucion 3\ndf.isna().any()\n\n# Solucion 4:\ndf.isna().any(axis = None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco94\"></a>\n# Truco 94: ahorra memoria fijando tu fecha\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/titanic/train.csv\", usecols = [\"Pclass\", \"Sex\", \"Parch\", \"Cabin\"])\ndf\n\n# veamos cuanto ocupa nuestro df en memoria\ndf.memory_usage(deep = True)\n\n# convertir a tipos de datos más pequeños\ndf = df.astype({\"Pclass\":\"int8\",\n                \"Sex\":\"category\", \n                \"Parch\": \"Sparse[int]\", # la mayoría de los valores son 0\n                \"Cabin\":\"Sparse[str]\"}) # la mayoría de los valores son NaN\n\ndf.memory_usage(deep = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco93\"></a>\n# Truco 93: combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando frecuencias)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: cuenta las frecuencias\nfrequencies = df[\"genre\"].value_counts(normalize = True)\nfrequencies\n\n# Paso 2: establezca su umbral y filtre las categorías más pequeñas\nthreshold = 0.1\nsmall_categories = frequencies[frequencies < threshold].index\nsmall_categories\n\n# Paso 3: reemplace los valores\ndf[\"genre\"] = df[\"genre\"].replace(small_categories, \"Other\")\ndf[\"genre\"].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco92\"></a>\n# Truco 92: Columna de objeto limpio con datos mixtos usando expresiones regulares\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"d = {\"cliente\": [\"A\", \"B\", \"C\", \"D\"], \"ventas\":[1100, 950.75, \"$400\", \"$1250.35\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Paso 1: verifique los tipos de datos\ndf[\"ventas\"].apply(type)\n\n# Paso 2: usa expresiones regulares\ndf[\"ventas\"] = df[\"ventas\"].replace(\"[$,]\", \"\", regex = True).astype(\"flotador\")\ndf\ndf[\"ventas\"].apply(type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco91\"></a>\n# Truco 91: Crear un conjunto de datos de series de tiempo para realizar pruebas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Soluciom 1\nnumber_or_rows = 365*24 # horas en un año\npd.util.testing.makeTimeDataFrame(number_or_rows, freq=\"H\")\n\n# Solucion 2\nnum_cols = 2\ncols = [\"ventas\", \"clientes\"]\ndf = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\ndf.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco90\"></a>\n# Truco 90: Mover columnas a una ubicación específica\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[15, 20], \"B\":[20, 25], \"C\":[30 ,40], \"D\":[50, 60]}\ndf = pd.DataFrame(d)\ndf\n\n# Using insert\ndf.insert(3, \"C2\", df[\"C\"]*2)\ndf\n\n# Other solution\ndf[\"C3\"] = df[\"C\"]*3 # create a new columns, it will be at the end\ncolumns = df.columns.to_list() # create a list with all columns\nlocation = 4 # specify the location where you want your new column\ncolumns = columns[:location] + [\"C3\"] + columns[location:-1] # reaarange the list\ndf = df[columns] # create te dataframe in with the order of columns you like\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco89\"></a>\n# Truco 89: Divide los nombres en nombre y apellido\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.Series([\"Geordi La Forge\", \"Deanna Troi\", \"Datos\"]).to_frame()\ndf.rename({0:\"nombres\"}, inplace = True, axis = 1)\ndf\n#                              split on first space  \ndf[\"nombre\"] = df[\"nombres\"].str.split(n = 1).str[0]\ndf[\"apellido\"] = df[\"nombres\"].str.split(n = 1).str[1]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco88\"></a>\n# Truco 88: Reorganizar columnas en un df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\n\n# Solucion 1\ndf[[\"A\", \"C\", \"D\", \"F\", \"E\", \"G\", \"B\"]].head() # no se modifica en su lugar\n\n# Solucion 2\ncols_to_move = [\"A\", \"G\", \"B\"]\n\nnew_order = cols_to_move + [c for c in df.columns if c not in cols_to_move] # genera tu nuevo pedido\ndf[new_order].head()\n\n# Solucion 3: usando índice\ncols = df.columns[[0, 5 , 3, 4, 2, 1, 6]] # df.columns devuelve una serie con índice, usamos la lista para ordenar el índice como queramos -> así ordenamos las columnas\ndf[cols].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco87\"></a>\n# Truco 87: Agregue su fecha y hora por y filtre los fines de semana\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()\ndf.shape\ndf.head()\n\n# Paso 1: remuestrear por D. Básicamente agregue por día y use to_frame () para convertirlo en marco\ndaily_sales = df.resample(\"D\")[\"sales\"].sum().to_frame()\ndaily_sales\n\n# Paso 2: filtra los fines de semana\nweekends_sales = daily_sales[daily_sales.index.dayofweek.isin([5, 6])]\nweekends_sales\n\n'''\ndía de la semana\n0  lunes\n1  martes\n2  miércoles\n3  jueves\n4  viernes\n5  sábado\n6  domingo\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco86\"></a>\n# Truco 86: Agregaciones con nombre: evita el índice múltiple\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.head()\n\n# Problema 1\nprint(\"El problema se basa en que no sabemos el nombre de la columna.\")\ndf.groupby(\"Pclass\")[\"Age\"].agg([\"mean\", \"max\"])\n\n# Problema 2\nprint(\"El problema se basa en que tenemos multi indice\")\ndf.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"]})\n\n# Solución nueva en pandas 0.25 y superior\nprint(\"Now we have solved the previous problems by specifyig the column final name we want.\")\nprint(\"BUT IT ONLY WORKS WITH A COLUMN. TO THIS KIND OF OPERATIONS ON MULTIPLE COLUMNS CHECK THE NEXT CELL\")\ndf.groupby(\"Pclass\")[\"Age\"].agg(age_mean = \"mean\", age_max = \"max\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco86bis\"></a>\n# Truco 86bis: Agregaciones con nombre en varias columnas; evita el índice múltiple\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_agg(x):\n    names = {\n        'age_mean': x['Age'].mean(),\n        'age_max':  x['Age'].max(),\n        'fare_mean': x['Fare'].mean(),\n        'fare_max': x['Fare'].max()\n    } # definir sus operaciones y nombres de columnas personalizados\n\n    return pd.Series(names, index=[ key for key in names.keys()]) # todas las columnas que cree en el diccionario anterior estarán en esta lista de comprensión\n\ndf.groupby('Pclass').apply(my_agg)\n\n# referencia\n# https://stackoverflow.com/questions/44635626/rename-result-columns-from-pandas-aggregation-futurewarning-using-a-dict-with\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco85\"></a>\n# Truco 85: Convierte un tipo de valores en otros\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Haz algunas funciones rápidas en el DF\nd = {\"gender\":[\"male\", \"female\", \"male\"], \"color\":[\"red\", \"green\", \"blue\"], \"age\":[25, 30, 15]}\ndf = pd.DataFrame(d)\ndf\n\n# Solucion\nmap_dict = {\"male\":\"M\", \"female\":\"F\"}\ndf[\"gender_mapped\"] = df[\"gender\"].map(map_dict) # usar diccionarios para mapear valores\ndf[\"color_factorized\"] = df[\"color\"].factorize()[0] # usando factorizar: devuelve una tupla de matrices (array([0, 1, 2]), Index(['red', 'green', 'blue'], dtype='object')) that's why we select [0]\ndf[\"age_compared_boolean\"] = df[\"age\"] < 18 # devuelve un valor volado Verdadero Falso\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco84\"></a>\n# Truco 84: Mostrar menos filas en un df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Este df ocupa demasiado espacio\")\ndf = generate_sample_data()\ndf\n\nprint(\"usando set_option para ahorrar espacio en la pantalla\")\npd.set_option(\"display.max_rows\", 6)\ndf\n\nprint(\"use reset_option all para restablecer los valores predeterminados\")\npd.reset_option(\"all\")\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco83\"></a>\n# Truco 83: Corrija los tipos de datos al importar el df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n\n# Paso 1: vamos al tipo de fecha de las columnas\ncol_types = df.dtypes.to_frame()\ncol_types.rename({0:\"type\"}, inplace = True, axis = 1)\ncol_types\ncol_types.to_csv(\"trick83data.csv\")\n\n# Paso 2: Vamos a importar los datos anteriores y convertirlos en un diccionario.\ncol_dict = pd.read_csv(\"trick83data.csv\", index_col = 0)[\"type\"].to_dict()\n\n# Paso 3\nprint(\"Original dictionary\")\ncol_dict\ncol_dict[\"country\"] = \"category\"\ncol_dict[\"continent\"] = \"category\"\nprint(\"Modified dictionary\")\ncol_dict\n\n# Paso 4: usa el diccionario para importar los datos\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", dtype=col_dict)\ndf.dtypes\n\n# Nota: tenga en cuenta que puede usar el dict del paso 1 y pegarlo así\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", \\\ndtype=\n{'country': 'category',\n 'beer_servings': 'int64',\n 'spirit_servings': 'int64',\n 'wine_servings': 'int64',\n 'total_litres_of_pure_alcohol': 'float64',\n 'continent': 'category'})\n# Sin embargo, si tiene muchas columnas, esto puede resultar confuso\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco82\"></a>\n# Truco 82: seleccionar datos por etiqueta y posición (iloc y loc encadenados)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", index_col=\"country\")\ndf.iloc[15:20, :].loc[:, \"beer_servings\":\"wine_servings\"]\n# iloc se usa para filtrar las filas y ubicar las columnas","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco81\"></a>\n# Truco 81: use aplicar (tipo) para ver si tiene tipos de datos mixtos\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"clientes\":[\"A\", \"B\", \"C\", \"D\", \"E\"], \"ventas\":[100, \"100\", 50, 550.20, \"375.25\"]}\ndf = pd.DataFrame(d)\n# todo parece, pero esta operación bloquea df [\"ventas\"]. sum (). Tenemos tipos de datos mixtos\ndf.dtypes\ndf[\"ventas\"].apply(type) # Wow, podemos ver que tenemos int, str, float en una columna\ndf[\"ventas\"].apply(type).value_counts() # Ver el número de cada valor\ndf[\"ventas\"] = df[\"ventas\"].astype(float) # convertir los datos a flotar\ndf[\"ventas\"].sum()\ndf[\"ventas\"].apply(type).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco80\"></a>\n# Truco 80: Seleccione varias secciones de columnas de un df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data().T\ncols_str = list(map(str, list(df.columns))) # para que podamos hacer df [\"0\"] como cadena para el ejemplo\ndf.columns = cols_str\n\n# Usando la concatenación de pandas\n# si alguna vez está confundido acerca del eje = 1 o el eje = 0, simplemente coloque eje = \"columnas\" o eje = \"filas\"\npd.concat([df.loc[:, \"0\":\"2\"], df.loc[:, \"6\":\"10\"], df.loc[:, \"16\":\"19\"]], axis = \"columns\") # ------------------> here we are selecting columns converted to strings\n\n# Usando listas\n# tenga en cuenta que df.columns es una serie con índice, por lo que estamos usando índice para filtrar # -------------------------> aquí estamos seleccionando el índice de columnas\ndf[list(df.columns[0:3]) + list(df.columns[6:11]) + list(df.columns[16:20])]\n\n# Usando numpy\ndf.iloc[:, np.r_[0:3, 6:11, 16:20]] # probablemente la solución más hermosa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco79\"></a>\n# Truco 79: recuento de filas que coinciden con una condición\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\ndf.shape\n\n# valores absolutos\n(df[\"A\"] < 5).sum()\nprint(\"In the columns A we have {} of rows that are below 5\".format((df[\"A\"] < 5).sum()\n\n# porcentaje\n(df[\"A\"] < 5).mean()\nprint(\"In the columns A the values that are below 5 represent {}%\".format((df[\"A\"] < 5).mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco78\"></a>\n# Truco 78: realice un seguimiento de la procedencia de sus datos cuando utilice varias fuentes\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generemos algunos datos falsos\ndf1 = generate_sample_data()\ndf2 = generate_sample_data()\ndf3 = generate_sample_data()\n# df1.head()\n# df2.head()\n# df3.head()\ndf1.to_csv(\"trick78data1.csv\")\ndf2.to_csv(\"trick78data2.csv\")\ndf3.to_csv(\"trick78data3.csv\")\n\n# Paso 1 generar lista con el nombre del archivo\nlf = []\nfor _,_, files in os.walk(\"/kaggle/working/\"):\n    for f in files:\n        if \"trick78\" in f:\n            lf.append(f)\n            \nlf\n\n# Puede usar esto en su máquina local\n#desde glob import glob\n#files = glob(\"trick78.csv\")\n\n# Paso 2: crear una nueva columna llamada nombre de archivo y el valor es archivo\n# Aparte de esto, solo estamos concatenando los diferentes marcos de datos\ndf = pd.concat((pd.read_csv(file).assign(filename = file) for file in lf), ignore_index = True)\ndf.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco77\"></a>\n# Truco 77: combine las categorías pequeñas en una sola categoría llamada \"Otros\" (usando dónde)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\ndf = pd.DataFrame(d)\ndf[\"genre\"].value_counts()\n\n# Paso 1: cuenta las frecuencias\ntop_four = df[\"genre\"].value_counts().nlargest(4).index\ntop_four\n\n# Paso 2: actualice el df\ndf_updated = df.where(df[\"genre\"].isin(top_four), other = \"Other\")\ndf_updated[\"genre\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco76\"></a>\n# Truco 76: filtra en pandas solo las categorías más grandes.\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.columns = map(str.lower, list(df.columns)) # convertir encabezados a tipo inferior\ndf.shape\n# seleccione los 3 mejores géneros\ntop_genre = df[\"genre\"].value_counts().to_frame()[0:3].index\n\n# Ahora vamos a filtrar el df con el género superior.\ndf_top = df[df[\"genre\"].isin(top_genre)]\ndf_top\ndf_top.shape\ndf_top[\"genre\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco75\"></a>\n# Truco 75: cuenta el número de palabras en una serie de pandas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\", usecols=[\"Title\"])\ndf[\"Words\"] = df[\"Title\"].str.count(\" \") + 1\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco74\"></a>\n# Truco 74: Webscraping usando read_html () y parámetro de coincidencia\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ejecute esto en su máquina local\n# url = \"https://es.wikipedia.org/wiki/Twitter\"\n# tables = pd.read_html (url)\n# len (tablas)\n\n# matching_tables = pd.read_html (url, match = \"Seguidores\")\n# tablas_coincidentes [0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco73\"></a>\n# Truco 73: eliminar una columna y almacenarla como una serie separada\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.head()\n\nmeta = df.pop(\"Metascore\").to_frame()\ndf.head()\nmeta.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco72\"></a>\n# Truco 72: Convertir variable continua en categórica (cortar y qcut)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\ndf.head()\n\n# Usando cortar puede especificar los bordes del contenedor\npd.cut(df[\"Metascore\"], bins = [0, 25, 50, 75, 99]).head()\n\n# Usando qcut puede especificar el número de bins y llenar generar de aproximadamente el mismo tamaño\npd.qcut(df[\"Metascore\"], q = 3).head()\n\n# cut y qcut aceptan el tamaño de la bandeja de etiquetas\npd.qcut(df[\"Metascore\"], q = 4, labels = [\"awful\", \"bad\", \"average\", \"good\"]).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco71\"></a>\n# Truco 71: Leer datos de un PDF (tabula py)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tendrás que ejecutarlo en tu máquina local\n#from tabula import read_pdf\n# df = read_pdf (\"test.pdf\", paginas = \"todo\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco70\"></a>\n# Truco 70: Imprime la versión actual de pandas y sus dependencias\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.__version__)\nprint(pd.show_versions())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco69\"></a>\n# Truco 69: comprueba si 2 series son \"similares\"\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[1, 2, 3, 4,], \"B\":[1.0, 2.0, 3.0, 4.0], \"C\":[1.00000, 2.00000, 3.00000, 4.000003], \"D\":[1.0, 2.0, 3.0, 4.0], \"E\":[4.0, 2.0, 3.0, 1.0]}\ndf = pd.DataFrame(d)\ndf\n\ndf[\"A\"].equals(df[\"B\"]) # Ellos requieren tipos de datos idénticos\ndf[\"B\"].equals(df[\"C\"])\ndf[\"B\"].equals(df[\"D\"])\ndf[\"B\"].equals(df[\"E\"]) # y el mismo orden\n\nprint(pd.testing.assert_series_equal(df[\"A\"], df[\"B\"], check_names=False, check_dtype=False)) # assertion passes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco68\"></a>\n# Truco 68: Web Scraping usando read_html ()\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendrá que ejecutar esto en su máquina local\n#apple_stocks = pd.read_html(\"https://finance.yahoo.com/quote/AAPL/history?p=AAPL\")\n#pd.concat([apple_stocks[0], apple_stocks[1]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco67\"></a>\n# Truco 67: crea nuevas columnas o sobrescribe usando Assing y establece un título para el df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", usecols=[\"continent\", \"beer_servings\"])\ndf.head()\n\n(df.assign(continent = df[\"continent\"].str.title(),\n           beer_ounces = df[\"beer_servings\"]*12,#                                     this will allow yo set a title\n           beer_galons = lambda df: df[\"beer_ounces\"]/128).query(\"beer_galons > 30\").style.set_caption(\"Average beer consumption\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco66\"></a>\n# Truco 66: Cree un montón de columnas nuevas usando un bucle for y f-strings df [f '{col} _new']\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"d = {\"state\":[\"ny\", \"CA\", \"Tx\", \"FI\"], \"country\":[\"USA\", \"usa\", \"UsA\", \"uSa\"], \"pop\":[1000000, 2000000, 30000, 40000]}\ndf = pd.DataFrame(d)\ndf\n\nint_types = [\"int64\"]\n# creating new columns\nfor col in df.columns:\n    ctype = str(df[col].dtype)\n    if ctype in int_types:\n        df[f'{col}_millions'] = df[col]/1000000\n    elif ctype == \"object\":\n        df[f'{col}_new'] = df[col].str.upper()\n        # you can also drop the columns\n        df.drop(col, inplace = True, axis = \"columns\")\n        \ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco65\"></a>\n# Trick 65: seleccione columnas usando f-strings (nuevo en pandas 3.6+)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf\n\ndrink = \"wine\"\n\n# nos permite iterar rápidamente sobre columnas\ndf[f'{drink}_servings'].to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco64\"></a>\n# Truco 64: Corrección de \"SettingWithCopyWarning\" al crear nuevas columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\ndf\n\n# Recibiendo esta desagradable advertencia\nmales = df[df[\"gender\"] == \"Male\"]\nmales[\"abbreviation\"] = \"M\"\n\n# Arreglando el error\nprint(\"Fixing the warning with print\")\nmales = df[df[\"gender\"] == \"Male\"].copy()\nmales[\"abbreviation\"] = \"M\"\nmales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco63\"></a>\n# Truco 63: Calcule el recuento continuo con grupos usando cumcount () + 1\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[\"Car\", \"Truck\", \"Car\", \"Truck\", \"cAr\", \"Car\", \"Truck\", \"Moto\"]}\ndf = pd.DataFrame(d)\ndf\n\n# Fijación de columnas\ndf[\"salesperson\"] = df[\"salesperson\"].str.title()\ndf[\"item\"] = df[\"item\"].str.title()\n\ndf[\"count_by_person\"] = df.groupby(\"salesperson\").cumcount() + 1\ndf[\"count_by_item\"] = df.groupby(\"item\").cumcount() + 1\ndf[\"count_by_both\"] = df.groupby([\"salesperson\",\"item\"]).cumcount() + 1\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco62\"></a>\n# Truco 62: Corregir \"SettingWithCopyWarning\" al cambiar columnas usando loc\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\ndf\n\n# Recibiendo esta desagradable advertencia\ndf[df[\"gender\"] == \"Male\"][\"gender\"] = 1\ndf[df[\"gender\"] == \"Female\"][\"gender\"] = 0\n\n\nprint(\"Fix using loc\")\ndf.loc[df[\"gender\"] == \"Male\", \"gender\"] = 1\ndf.loc[df[\"gender\"] == \"Female\", \"gender\"] = 0\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco61\"></a>\n# Truco 61: Leer JSON de la web en un df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"url = \"https://github.com/justmarkham?tab=repositories\"\n\n# ejecutarlo en su máquina local\n# df = pd.read_json(url)\n# df = df[df[\"fork\"] == False]\n# df.shape\n# df.head()\n\n# lc = [\"name\", \"stargazers_count\", \"forks_count\"]\n# df[lc].sort_values(\"stargazers_count\", asending = False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco60\"></a>\n# Truco 60: Creación de totales acumulados con la función cumsum\n[Regrese a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\ndf = pd.DataFrame(d)\ndf\n\ndf[\"running_total\"] = df[\"item\"].cumsum()\ndf[\"running_total_by_person\"] = df.groupby(\"salesperson\")[\"item\"].cumsum()\ndf\n\n# otras funciones útiles son cummax(), cummin(), cumprod()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco59\"></a>\n# Truco 59: Combine la salida de una agregación con el df original usando transform\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"orderid\":[1, 1, 1, 2, 2, 3, 4, 5], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"This is the output we want to aggregate to the original df\")\ndf.groupby(\"orderid\")[\"item\"].sum().to_frame()\n\ndf[\"total_items_sold\"] = df.groupby(\"orderid\")[\"item\"].transform(sum)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco58\"></a>\n# Truco 58: Use encabezados y saltos para deshacerse de datos incorrectos o filas vacías durante la importación\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tenemos filas vacías y datos incorrectos\ndf = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\")\ndf\n\n# importando datos correctos\ndf = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\", header = 2, skiprows = [3,4])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco57\"></a>\n# Truco 57: Accediendo a los grupos de un objeto groupby (get_group ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\")\ndf\n\ngbdf = df.groupby(\"Genre\")\ngbdf.get_group(\"Horror\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco56\"></a>\n# Truco 56: Aplicar asignaciones o funciones a todo el df (applymap)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\"A\":[\"Male\", \"Female\", \"Female\", \"Male\"], \"B\":[\"x\", \"y\", \"z\", \"A\"], \"C\":[\"male\", \"female\", \"male\", \"female\"], \"D\":[1, 2, 3, 4]})\ndf\n\n# primero usemos applymap para convertir y estandarizar el texto\ndf = df.applymap(lambda x: x.lower() if type(x) == str else x)\n\nmapping = {\"male\":0, \"female\":1}\n\nprint(\"PROBLEM: Applies to the whole df but retruns None\")\ndf.applymap(mapping.get)\n\nprint(\"Get the correct result but you have to specify the colums. If you don't want to do this, check the next result\")\ndf[[\"A\", \"C\"]].applymap(mapping.get)\n\nprint(\"Condtional apply map: if can map --> map else return the same value\")\ndf = df.applymap(lambda x: mapping[x] if x in mapping.keys() else x)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco55\"></a>\n# Truco 55: filtrar un df con múltiples criterios usando reducir\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf\n\nprint(\"Classical filter hard to read and mantain.\")\ndf[(df[\"continent\"] == \"Europe\") & (df[\"beer_servings\"] > 150) & (df[\"wine_servings\"] > 50) & (df[\"spirit_servings\"] < 60)]\n\nprint(\"You can split it across multiple lines to make it more readable. But it's still hard to read.\")\ndf[\n    (df[\"continent\"] == \"Europe\") & \n    (df[\"beer_servings\"] > 150) & \n    (df[\"wine_servings\"] > 50) & \n    (df[\"spirit_servings\"] < 60)\n]\n\nprint(\"Solution saving criteria as objects\")\n\ncr1 = df[\"continent\"] == \"Europe\"\ncr2 = df[\"beer_servings\"] > 150\ncr3 = df[\"wine_servings\"] > 50\ncr4 = df[\"spirit_servings\"] < 60\n\ndf[cr1 & cr2 & cr3 & cr4]\n\nprint(\"Solution using reduce\")\nfrom functools import reduce\n\n# crea nuestros criterios usando lambda\n# lambda toma 2 parámetros, xey\n# reduce los combina y por cada cr en el (cr1, cr2, cr3, cr4)\ncriteria = reduce(lambda x, y: x & y, (cr1, cr2, cr3, cr4))\ndf[criteria]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco54\"></a>\n# Truco 54: Calcula la diferencia entre cada fila y la anterior (diff ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf[\"A_diff\"] = df[\"A\"].diff() # calcular la diferencia entre 2 filas\ndf[\"A_diff_pct\"] = df[\"A\"].pct_change()*100 # calcula la variación porcentual entre 2 filas\n\n\ndf.style.format({\"A_diff_pct\":'{:.2f}%'})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco53\"></a>\n# Truco 53: mezclar filas de un df (df.sample ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\n\ndf.sample(frac = 0.5, random_state = 2)\ndf.sample(frac = 0.5, random_state = 2).reset_index(drop = True) # reset index after shuffeling\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco52\"></a>\n# Truco 52: Hacer tramas con pandas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\n\ndf.plot(kind = \"line\")\ndf.plot(kind = \"bar\")\ndf.plot(kind = \"barh\")\ndf.plot(kind = \"hist\")\ndf.plot(kind = \"box\")\ndf.plot(kind = \"kde\")\ndf.plot(kind = \"area\")\n\n# las siguientes parcelas requieren x , y\ndf.plot(x = \"A\", y = \"B\", kind = \"scatter\")\ndf.plot(x = \"A\", y = \"B\", kind = \"hexbin\")\ndf.plot(x = \"A\", y = \"B\", kind = \"pie\") # aquí puede pasar solo x pero necesita agregar subparcelas = Verdadero\n\n# otras parcelas están disponibles a través de pd.plotting\n# más sobre trazar https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco51\"></a>\n# Truco 51: Concatenar cadenas de 2 columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Solución 1: usando str.cat\ndf[\"Name\"].str.cat(df[\"Sex\"], sep = \", \").head()\n\n# usando + signo\ndf[\"Name\"] + \", \" + df[\"Sex\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco50\"></a>\n# Truco 50: Agregación con nombre con varias columnas que pasan tupples (nuevo en pandas 0.25)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n\n# Grupo típico\nprint(\"Problem: MultiIndex\")\ndf.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"], \"Survived\": \"mean\"})\n\n# Tenga en cuenta que esto se ha cubierto en 86 y 86 bis.\n# Esta es solo una forma más de hacerlo.\nprint(\"Named aggregation\")\ndf.groupby(\"Pclass\").agg(avg_age = (\"Age\", \"mean\"),\n                        max_age = (\"Age\", \"max\"), \n                        survival_rate = (\"Survived\", \"mean\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco49\"></a>\n# Truco 49: Muestreo con pandas (con reemplazo y pesos)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\": [100, 200, 300, 400, 100], \"W\":[10, 5, 0, 3, 8]}\ndf = pd.DataFrame(d)\ndf\n\n# con reemplazo\ndf.sample(n = 5, replace = True, random_state = 2)\n\n# sumando pesos\ndf.sample(n = 5, replace = True, random_state = 2, weights = \"W\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco48\"></a>\n# Truco 48: Parámetros útiles al usar pd.read_csv ()\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\ndf.head()\ndf.dtypes\n\n# Vamos a importar las columnas country y beer_servings, convertirlas a string y float64 respectevly\n# Importa solo las primeras 5 filas y subproceso 0 como nans\ndf = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\",\n                    usecols=[\"country\", \"beer_servings\"],\n                    dtype={\"country\":\"category\", \"beer_servings\":\"float64\"},\n                    nrows = 5,\n                    na_values = 0.0)\ndf.head()\ndf.dtypes\n\n# mas sobre read_csv en https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco47\"></a>\n# Truco 47: crea una fila para cada elemento en una lista (explotar)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"Players\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n\nprint(\"Notice that we have a list of players for each team. Let's generate a row for each player.\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Using explode to generate new rows for each player.\")\ndf1 = df.explode(\"Players\")\ndf1\n\nprint(\"Reverse this operation with groupby and agg\")\ndf[\"Imploded\"] = df1.groupby(df1.index)[\"Players\"].agg(list)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco46\"></a>\n# Truco 46: Almacene NaN en un tipo entero con Int64 (no int64)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Default series\")\nser1 = pd.Series([10, 20])\nser1\n\nprint(\"Let's add a NaN to an int64 series\")\nser1 = pd.Series([10, 20, np.nan])\nser1 # Observe que se ha convertido a float64\n\nprint(\"But if we use Int64 than everything will work\")\nser1 = pd.Series([10, 20, np.nan], dtype = \"Int64\")\nser1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco45\"></a>\n# Truco 45: Cree filas para valores separados por comas en una celda (Assing y explotar)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"Players\":[\"Ter Stegen, Semedo, Piqué, Lenglet, Alba, Rakitic, De Jong, Sergi Roberto, Messi, Suárez, Griezmann\",\n               \"Courtois, Carvajal, Varane, Sergio Ramos, Mendy, Kroos, Valverde, Casemiro, Isco, Benzema, Bale\"]}\n\nprint(\"Notice that we have a list of players for each team separated by commas. Let's generate a row for each player.\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Notice that we have converted to something similar seen in example 47.\")\ndf.assign(Players = df[\"Players\"].str.split(\",\"))\n\nprint(\"Now add explode and done.\")\ndf.assign(Players = df[\"Players\"].str.split(\",\")).explode(\"Players\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco44\"></a>\n# Truco 44: usa una variable local dentro de una consulta en pandas (usando @)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf\n\n# crear una media de variable local\nmean = df[\"A\"].mean()\n\n# ahora usemos dentro de una consulta de pandas usando @\ndf.query(\"A > @mean\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco43\"></a>\n# Truco 43: ¡Crea una fila para cada elemento de una lista (explotar)! ¡¡¡Truco 47 duplicado !!!\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parece que este truco está duplicado, pasa al siguiente\n# Decidí quedarme, así que en el futuro no habrá confusión si consulta el material original\n# y este kernel\nd = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n    \"Players\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n\nprint(\"Notice that we have a list of players for each team. Let's generate a row for each player.\")\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Using explode to generate new rows for each player.\")\ndf1 = df.explode(\"Players\")\ndf1\n\nprint(\"Reverse this operation with groupby and agg\")\ndf[\"Imploded\"] = df1.groupby(df1.index)[\"Players\"].agg(list)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco42\"></a>\n# Truco 42: Nueva función de agregación -> last ()\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"patient\":[1, 2, 3, 1, 1, 2], \"visit\":[2015, 2016, 2014, 2016, 2017, 2020]}\ndf = pd.DataFrame(d)\ndf.sort_values(\"visit\")\n\nprint(\"Let's get the last visit for each patient\")\ndf.groupby(\"patient\")[\"visit\"].last().to_frame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco41\"></a>\n# Truco 41: Categorías ordenadas (de pandas.api.types import CategoricalDtypee)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas.api.types import CategoricalDtype\nd = {\"ID\":[100, 101, 102, 103], \"quality\":[\"bad\", \"very good\", \"good\", \"excellent\"]}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Let's create our own categorical order.\")\ncat_type = CategoricalDtype([\"bad\", \"good\", \"very good\", \"excellent\"], ordered = True)\ndf[\"quality\"] = df[\"quality\"].astype(cat_type)\ndf\n\nprint(\"Now we can use logical sorting.\")\ndf = df.sort_values(\"quality\", ascending = True)\ndf\n\nprint(\"We can also filter this as if they are numbers. AMAZING.\")\ndf[df[\"quality\"] > \"bad\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco40\"></a>\n# Truco 40: Estilo que df rápido con hide_index () y set_caption ()\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\nprint(\"Original df\")\ndf\n\ndf.style.hide_index().set_caption(\"Styled df with no index and a caption\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco39\"></a>\n# Truco 39: Una codificación en caliente (get_dummies ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\", usecols = [2, 4, 5, 11], nrows = 10)\ndf\n\npd.get_dummies(df) # Observe que podemos eliminar una columna de cada una ya que esta información está contenida en las demás\n\npd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco38\"></a>\n# Truco 38: Pandas datetime (muchos ejemplos)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()\ndf = df.sample(500)\ndf[\"Year\"] = df[\"index\"].dt.year\ndf[\"Month\"] = df[\"index\"].dt.month\ndf[\"Day\"] = df[\"index\"].dt.day\ndf[\"Hour\"] = df[\"index\"].dt.hour\ndf[\"Minute\"] = df[\"index\"].dt.minute\ndf[\"Second\"] = df[\"index\"].dt.second\ndf[\"Nanosecond\"] = df[\"index\"].dt.nanosecond\ndf[\"Date\"] = df[\"index\"].dt.date\ndf[\"Time\"] = df[\"index\"].dt.time\ndf[\"Time_Time_Zone\"] = df[\"index\"].dt.timetz\ndf[\"Day_Of_Year\"] = df[\"index\"].dt.dayofyear\ndf[\"Week_Of_Year\"] = df[\"index\"].dt.weekofyear\ndf[\"Week\"] = df[\"index\"].dt.week\ndf[\"Day_Of_week\"] = df[\"index\"].dt.dayofweek\ndf[\"Week_Day\"] = df[\"index\"].dt.weekday\ndf[\"Week_Day_Name\"] = df[\"index\"].dt.weekday_name\ndf[\"Quarter\"] = df[\"index\"].dt.quarter\ndf[\"Days_In_Month\"] = df[\"index\"].dt.days_in_month\ndf[\"Is_Month_Start\"] = df[\"index\"].dt.is_month_start\ndf[\"Is_Month_End\"] = df[\"index\"].dt.is_month_end\ndf[\"Is_Quarter_Start\"] = df[\"index\"].dt.is_quarter_start\ndf[\"Is_Quarter_End\"] = df[\"index\"].dt.is_quarter_end\ndf[\"Is_Leap_Year\"] = df[\"index\"].dt.is_leap_year\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco37\"></a>\n# Truco 37: Pandas cortando loc e iloc (6 ejemplos)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf\n\n# using loc --> labels\ndf.loc[0, \"A\"]\n\n# using iloc --> position\ndf.iloc[0, 0]\n\n# mixing labels and position with loc\ndf.loc[0, df.columns[0]]\n\n# mixing labels and position with loc\ndf.loc[df.index[0], \"A\"]\n\n# mixing labels and position with iloc\ndf.iloc[0, df.columns.get_loc(\"A\")]\n\n# mixing labels and position with iloc\ndf.iloc[df.index.get_loc(0), 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco36\"></a>\n# Truco 36: Convertir de UTC a otra zona horaria\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = pd.Series(range(1552194000, 1552212001, 3600))\ns = pd.to_datetime(s, unit = \"s\")\ns\n\n# establecer la zona horaria en la zona horaria actual (UTC)\ns = s.dt.tz_localize(\"UTC\")\ns\n\n# establecer zona horaria en otra zona horaria (Chicago)\ns = s.dt.tz_convert(\"America/Chicago\")\ns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco35\"></a>\n# Truco 35: Consulta una columna que tenga espacios en el nombre (usando comillas invertidas)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"colum_without_space\":np.array([1, 2, 3, 4, 5, 6]), \"column with space\":np.array([1, 2, 3, 4, 5, 6])*2}\ndf = pd.DataFrame(d)\ndf\n\nprint(\"Query a column without space\")\ndf.query(\"colum_without_space > 4\")\nprint(\"Query a column with space using backticks ``\")\nprint(\"This is a backtick ``\")\ndf.query(\"`column with space` > 8\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco34\"></a>\n# Truco 34: Explore un conjunto de datos con creación de perfiles\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\n\ndf = generate_sample_data()\n\ndf\n\nprint(\"Generating report with pandas profiling\")\ndf.profile_report()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco33\"></a>\n# Truco 33: opciones de visualización de pandas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# usa pd.describe_option() para ver todo\n# max_rows\n# max_columns\n# max_colwidth\n# precision\n# date_dayfirst\n# date_yearfirst\n\ndf = generate_sample_data_datetime()[:10].reset_index()\ndf[\"sales\"] = df[\"sales\"].astype(\"float\")\ndf\n\npd.set_option(\"display.max_rows\",5)\npd.set_option(\"display.max_columns\",3)\npd.set_option('display.width', 1000)\npd.set_option('display.date_dayfirst', True)\npd.describe_option()\n\npd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n# pd.set_option ('display.width') # restaurar uno por uno","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco32\"></a>\n# Truco 32: Filtrar un df con consulta y evitar variables intermedias\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:10]\ndf[\"A\"] = pd.Series([\"APP\", \"GOO\", \"APP\", \"GOO\", \"MIC\", \"MIC\", \"APP\", \"GOO\", \"MIC\", \"APP\"])\ndf.rename(columns = {\"A\":\"stock\"}, inplace = True)\nprint(\"Original df\")\ndf\n\nprint(\"Filter data using intermediate variables\")\ntemp = df.groupby(\"stock\").mean()\ntemp \n\nfv = temp[\"B\"].sort_values(ascending = False)[1] # filtrar por el segundo gran. De esta forma cada vez que generamos datos de muestra tendremos un resultado\ntemp[temp[\"B\"] < fv]\n\nprint(\"Filter using query\")\ndf.groupby(\"stock\").mean().query(\"B < {}\".format(fv))\ndf.groupby(\"stock\").mean().query(\"B < @fv\")\ndf.groupby(\"stock\").mean().query(\"B < 10\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco31\"></a>\n# Truco 31: Ver todas las columnas de un gran df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n\ndf = generate_sample_data()\ndf1 = df.copy(deep = True)\ndf = df.append(df1)\n\nprint(\"Imagine we have a big df where we can see all the columns ...\")\ndf.T.head() # Nosotros estamos transponiendo SOLO PARA CREAR UN DF GIGANTE\n\n# Solucion 1\nprint(\"Solution 1 using pd.set_option display.max_columns\")\npd.set_option(\"display.max_columns\", None)\ndf.T.head()\npd.reset_option('^display.', silent=True) # restaurar a los valores predeterminados\n\n# Solucion 2\nprint(\"Another clever solution using Traspose\")\ndf.T.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco30\"></a>\n# Truco 30: Pandas se fusionan -> vea de dónde vienen las columnas (indicador = Verdadero)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf1 = df.copy(deep = True)\ndf1 = df1.drop([0, 1, 2], axis = \"rows\") # suelte un índice solo para ver el funcionamiento de ejemplo\ndf.head()\ndf1.head()\n\npd.merge(df, df1, how = \"left\", indicator = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco29\"></a>\n# Truco 29: Acceda a numpy dentro de pandas (sin importar numpy como np)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas se basa en numpy, por lo que podemos acceder a todas las funciones de numpy desde pandas\npd.np.random.rand(2, 3)\npd.np.nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco28\"></a>\n# Truco 28: agregando por múltiples columnas (usando agg)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\nprint(\"Original df\")\ndf\n\nprint(\"Groupby continent beer_servings\")\ndf.groupby(\"continent\")[\"beer_servings\"].mean()\n\nprint(\"Using agg to pass multiple functions\")\ndf.groupby(\"continent\")[\"beer_servings\"].agg([\"mean\", \"count\"])\n\nprint(\"Using describe over a groupby object\")\ndf.groupby(\"continent\")[\"beer_servings\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco27\"></a>\n# Truco 27: agregación sobre series temporales (remuestreo)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()\n\nprint(\"Original df\")\ndf\nprint(\"Let's resample/groupby by month\")\ndf.resample(\"M\")[\"sales\"].sum()\n\nprint(\"Let's resample/groupby by day\")\ndf.resample(\"D\")[\"sales\"].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick26\"></a>\n# Truco 26: formatear diferentes columnas de un df (usando diccionarios)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()[:10]\ndf.rename(columns = {\"index\":\"time\"}, inplace = True)\ndf[\"sales_100\"] = df[\"sales\"]*100\nprint(\"Original df\")\ndf.head()\n\n# declarar un dictado de formato: individual para cada columna\nfd = {\"time\":\"{:%d/%m/%y}\", \"sales\":\"${:.2f}\", \"customers\":\"{:,}\"}\ndf.style.format(fd)\ndf\n\n# agregue más formato\n(df.style.format(fd)\n .hide_index()\n .highlight_min(\"sales\", color =\"red\")\n .highlight_max(\"sales\", color =\"green\")\n .background_gradient(subset = \"sales_100\", cmap =\"Blues\")\n .bar(\"customers\", color = \"lightblue\", align = \"zero\")\n .set_caption(\"A df with different stylings\")\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco25\"></a>\n# Truco 25: 3 formas de cambiar el nombre de las columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head(2)\n\n# Solucion 1\ndf.rename({\"A\":\"col_1\", \"B\":\"col_2\"}, axis = \"columns\", inplace = True)\ndf.head(2)\n\n# Solucion 2\ndf.columns = [\"col1\", \"col2\", \"col3\", \"col4\",\"col5\", \"col6\", \"col7\"] # la lista debe ser igual al número de columnas\ndf.head(2)\n\n# Solucion 3\ndf.columns = df.columns.str.title() # aplicar cualquier método de cadena a los nombres de las columnas\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco24\"></a>\n# Truco 24: Copie datos de Excel a pandas rápidamente (read_clipboard ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tendrá que verificar esto en su máquina local\n# Útil para importar rápidamente\n# Paso 1: copie una tabla de la hoja de Excel usando ctrl + c (al portapapeles)\n# Paso 2: ejecuta este comando\n# df = pd.read_clipboard ()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco23\"></a>\n# Truco 23: Complete los valores faltantes en los datos de series de tiempo (interpolar ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"col1\":[100, 120 ,140, np.nan, 160], \"col2\":[9, 10, np.nan, 7.5, 6.5]}\ndf = pd.DataFrame(d)\ndf.index = pd.util.testing.makeDateIndex()[0:5]\nprint(\"Original df\")\ndf\nprint(\"DataFrame after interpolate\")\ndf.interpolate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco22\"></a>\n# Truco 22: Crea DataFrames para probar\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Contains random values\")\ndf1 = pd.util.testing.makeDataFrame() # contiene valores aleatorios\ndf1\nprint(\"Contains missing values\")\ndf2 = pd.util.testing.makeMissingDataframe() # contiene valores perdidos\ndf2\nprint(\"Contains datetime values\")\ndf3 = pd.util.testing.makeTimeDataFrame() # contiene valores de fecha y hora\ndf3\nprint(\"Contains mixed values\")\ndf4 = pd.util.testing.makeMixedDataFrame() # contiene valores mixtos\ndf4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco21\"></a>\n# Truco 21: Divide una columna de cadena en varias columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"name\":[\"John Artur Doe\", \"Jane Ann Smith\", \"Nico P\"], \"location\":[\"Los Angeles, CA\", \"Washington, DC\", \"Barcelona, Spain\"]}\ndf = pd.DataFrame(d)\ndf\n\ndf[[\"first\", \"middle\", \"last\"]] = df[\"name\"].str.split(\" \", expand = True)\ndf[\"city\"] = df[\"location\"].str.split(\",\", expand = True)[0]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco20\"></a>\n# Truco 20: crea columnas de fecha y hora a partir de varias columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"day\":[1, 2, 10 ,25, 12], \"month\":[1, 2, 4, 5, 6], \"year\":[2000, 2001, 2010, 2015, 2020]}\ndf = pd.DataFrame(d)\ndf[\"date\"] = pd.to_datetime(df[[\"day\", \"month\", \"year\"]])\ndf\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco19\"></a>\n# Truco 19: Muestra el uso de memoria de un df y cada columna\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime().reset_index()\ndf.columns = [\"date\", \"sales\", \"customers\"]\ndf\n\nprint(\"Show the global usage of memory of the df\")\ndf.info(memory_usage = \"deep\")\nprint()\nprint(\"Show the usage of memory of every column\")\ndf.memory_usage(deep = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco18\"></a>\n# Truco 18: Leer y escribir en un archivo comprimido (csv.zip)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf.head()\n\nprint(\"Writing data to a csv.zip file\")\ndf.to_csv(\"trick18data.csv.zip\")\n\nprint(\"Deleting df\")\ndel df\n\nprint(\"Importing data from a csv.zip file\")\ndf = pd.read_csv(\"/kaggle/working/trick18data.csv.zip\", index_col=0)\ndf.head()\n\n# otros archivos de compresión compatibles .gz, .bz2, .xz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco17\"></a>\n# Truco 17: Seleccione varias filas y columnas con loc\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\nprint(\"Original df\")\ndf\n\nprint(\"Using a slice (inclusive)\")\ndf.loc[0:4, \"A\":\"E\"]\n\nprint(\"Using a list\")\ndf.loc[[0,4], [\"A\",\"E\"]]\n\nprint(\"Using a condition\")\ndf.loc[df[\"A\"] > 10, [\"A\",\"E\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco16\"></a>\n# Truco 16: Convierte valores continuos en categóricos (cortar ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf[\"A\"] = df[\"A\"] + 5\ndf.rename(columns = {\"A\":\"age\"}, inplace = True)\ndf.sample(5)\n\ndf[\"age_groups\"] = pd.cut(df[\"age\"], bins = [0, 18, 65, 99], labels = [\"kids\", \"adult\", \"elderly\"])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"trick15\"></a>\n# Truco 15: Remodelar un MultiIndex df (desapilar ())\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(\"Original df\")\ndf.head()\n\nprint(\"Groupby and create a MultiIndex df\")\nprint(\"Notice we have a df with MultiIndex (Sex and Pclass)\")\ndf.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().to_frame()\n\nprint(\"Reshaping using unstack\")\nprint(\"Now we can interact with it like with a normal df\")\ndf.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().unstack()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco14\"></a>\n# Trick 14: Creacion de df juguete\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Método 1: de un dictado\npd.DataFrame({\"A\":[10 ,20], \"B\":[30, 40]})\n\n# Método 2: usando numpy\npd.DataFrame(np.random.rand(2, 3), columns = list(\"ABC\"))\n\n# Método 3: usar funcionalidades integradas de pandas\npd.util.testing.makeMixedDataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco13\"></a>\n# Truco 13: Evita la serie de listas TRAP\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"A\":[1, 2, 3], \"B\":[[10, 20], [40, 50], [60, 70]]}\ndf = pd.DataFrame(d)\nprint(\"Notice that the column B has as values lists\")\ndf\nprint(\"Convert it to normal series\")\ndf_ = df[\"B\"].apply(pd.Series)\ndf_\n\nprint(\"Join the 2 df\")\npd.merge(df, df_, left_index = True, right_index = True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco12\"></a>\n# Truco 12: fusionar conjuntos de datos y verificar la unicidad\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:10]\ndf1 = df.copy(deep = True)\ndf = df.drop([0, 1, 2])\ndf1 = df1.drop([8, 9])\ndf\ndf1\n\ndf_one_to_one = pd.merge(df, df1, validate = \"one_to_one\")\ndf_one_to_one\n\ndf_one_to_many = pd.merge(df, df1, validate = \"one_to_many\")\ndf_one_to_many\n\ndf_many_to_one = pd.merge(df, df1, validate = \"many_to_one\")\ndf_many_to_one\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco11\"></a>\n# Truco 11: cambie el nombre de todas las columnas con el mismo patrón\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\ndf = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf.columns = [\"Passenger ID\", \"Survived\", \"Pclass\", \"Name         \", \"Sex\", \"Age\", \"Sib SP\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"] # creating column names for the example\ndf\ndf1 = df.copy(deep = True)\n\nprint(\"Replace all spaces with undescore and convert to lower\")\nprint(\"Notice the Passenger and Sib SP column now has underscore\")\ndf.columns = df.columns.str.replace(\" \", \"_\").str.lower()\ndf.head()\n\nprint(\"Remove trailing (at the end) whitesapce and convert to lower\")\nprint(\"Notice the Passenger and Sib SP column now has underscore\")\ndf1.columns = df1.columns.str.lower().str.rstrip()\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco10\"></a>\n# Truco 10: comprueba la igualdad de 2 series\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[[\"A\", \"B\"]][:5]\ndf[\"A\"] = pd.Series([15, 15, 18, np.nan, 12])\ndf[\"B\"] = pd.Series([15, 15, 18, np.nan, 12])\ndf\n\nprint(\"Don't use ==, it does not handle NaN properly\")\nprint(\"Notice that element 4 of each list is np.nan but == still returns False\")\ndf[\"A\"] == df[\"B\"]\n\nprint(\"Using equals. Now we get True, so the 2 series are equal\")\ndf[\"A\"].equals(df[\"B\"])\n\nprint(\"Equals also works for df\")\ndf1 = df.copy(deep = True)\ndf.equals(df1)\n\nprint(\"== of df has the same issue as for series\")\ndf == df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco9\"></a>\n# Truco 9: ¡Reduzca el uso de memoria de un df al importar! ¡¡¡Truco 83 duplicado !!!\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_files()\n\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"])\ndf.dtypes\ndf.memory_usage(deep = True)\n\nprint(\"Importing only a few columns and converting to proper dtype\")\ndf = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"], \\\n                dtype = {\"Genre\":\"category\", \"Metascore\":\"Int64\", \"Year\":\"int8\"})\ndf.dtypes\ndf.memory_usage(deep = True) # observe cómo el género y el año consumen ahora menos memoria","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco8\"></a>\n# Truco 8: ¡Usar glob para generar un df a partir de varios archivos! ¡¡¡Truco 78 duplicado !!!\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generemos algunos datos falsos\ndf1 = generate_sample_data()\ndf2 = generate_sample_data()\ndf3 = generate_sample_data()\n# df1.head()\n# df2.head()\n# df3.head()\ndf1.to_csv(\"trick8data1.csv\", index = False)\ndf2.to_csv(\"trick8data2.csv\", index = False)\ndf3.to_csv(\"trick8data3.csv\", index = False)\n\n# Paso 1 generar lista con el nombre del archivo\nlf = []\nfor _,_, files in os.walk(\"/kaggle/working/\"):\n    for f in files:\n        if \"trick8data\" in f:\n            lf.append(f)\n            \nlf\n\n#Puede usar esto en su máquina local\n#desde glob import glob\n#files = glob(\"trick8.csv\")\n\n# Paso 2: hacemos lo mismo que en el truco 78, excepto que no creamos una nueva columna del origen de las filas (archivo del que provienen)\ndf = pd.concat((pd.read_csv(file) for file in lf), ignore_index = True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco7\"></a>\n# Truco 7: lidiar con los valores perdidos (NaN)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.util.testing.makeMissingDataframe().reset_index() # contiene valores perdidos\ndf.rename(columns = {\"index\":\"A\"})\ndf1 = df.copy(deep = True)\ndf\n\nprint(\"Calculate the % of missing values in each row\")\ndf.isna().mean() # calcular el% de valores perdidos en cada fila\nprint(\"Droping any columns that have missing values. Only column A wil remain\")\ndf.dropna(axis = \"columns\") # eliminar cualquier columna que tenga valores perdidos\nprint(\"Droping any rows that have missing values.\")\ndf1.dropna(axis = \"rows\") # eliminar cualquier fila que tenga valores perdidos\nprint(\"Droping column where missing values are above a threshold\")\ndf.dropna(thresh = len(df)*0.95, axis = \"columns\") # eliminar cualquier fila que tenga valores perdidos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco6\"></a>\n# Truco 6: Divide un df en 2 subconjuntos aleatorios\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()\ndf_1 = df.sample(frac = 0.7)\ndf_2 = df.drop(df_1.index) # solo funciona si el índice df es único\n\ndf.shape\ndf_1.shape\ndf_2.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco5\"></a>\n# Truco 5: Convierte números almacenados como cadenas (coaccionar)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {\"col1\":[\"1\", \"2\", \"3\", \"stuff\"], \"col2\":[\"1\", \"2\", \"3\", \"4\"]}\ndf = pd.DataFrame(d)\ndf.astype({\"col2\":\"int\"}) # esto fallará para col1 -> ValueError: literal inválido para int () con base 10: 'cosas'\n\nprint(\"Notice that now stuff got converted to NaN\")\ndf.apply(pd.to_numeric, errors = \"coerce\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco4\"></a>\n# Truco 4: Seleccione columnas por dtype\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data_datetime()[:10].reset_index()\ndf[\"string_col\"] = list(\"ABCDEABCDE\")\ndf[\"sales\"] = df[\"sales\"].astype(\"float\")\nprint(\"Original df\")\ndf\n\nprint(\"Select numerical columns\")\ndf.select_dtypes(include = \"number\")\n\nprint(\"Select string columns\")\ndf.select_dtypes(include = \"object\")\n\nprint(\"Select datetime columns\")\ndf.select_dtypes(include = [\"datetime\", \"timedelta\"])\n\nprint(\"Select miscelaneous\")\ndf.select_dtypes(include = [\"number\", \"object\", \"datetime\", \"timedelta\"])\n\nprint(\"Select by passing the dtypes you need\")\ndf.select_dtypes(include = [\"int8\", \"int16\", \"int32\", \"int64\", \"float\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco3\"></a>\n# Truco 3: Filtrar un df por múltiples condiciones (isin e inverso usando ~)\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\ndf[\"A\"] = [1, 2, 3, 4, 5]\n\nprint(\"Filter using multiple |\")\ndf[(df[\"A\"] == 1) | (df[\"A\"] == 3)]\n\nprint(\"Filter using isin\")\ndf[df[\"A\"].isin([1, 3])]\n\nprint(\"Invert using ~ (ctrl + alt + 4)\")\ndf[~df[\"A\"].isin([1, 3])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco2\"></a>\n# Truco 2: Orden inverso de un df\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\ndf\n\nprint(\"Reverse column order\")\ndf.loc[:, ::-1]\n\nprint(\"Reverse row order\")\ndf.loc[::-1]\n\nprint(\"Reverse row order and reset index\")\ndf.loc[::-1].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"truco1\"></a>\n# Truco 1: Agregue un prefijo o sufijo a todas las columnas\n[Volver a la tabla de contenido](#tabla_de_contenido)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = generate_sample_data()[:5]\nprint(\"Original df\")\ndf\n\nprint(\"Add prefix\")\ndf.add_prefix(\"1_\")\n\nprint(\"Add suffix\")\ndf.add_suffix(\"_Z\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fin\n# Muchas gracias. Si hiciste hasta el final, habrás aprendido muchos pandas"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}