{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords \nfrom unicodedata import normalize\nfrom nltk.stem import SnowballStemmer\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **PROCESO DE ENTRENAMIENTO DE ALGORITMOS**\n\nAntes de entrenar un algoritmo, ***recabaremos información del csv*** para comparar los datos iniciales con los finales. \nDebemos limpiar los datos que con los que este va a trabajar y presentarlos en el formato adecuado para este algoritmo, pero antes, los datos preprocesados deben formar parte de la bolsa de palabras con la que trabajará el algoritmo.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Para posteriormente poder comprobar la reducción de palabras y letras después del preprocesado ***añadimos dos columnas*** al dataframe inicial, donde la ***primera*** corresponde al ***número de palabras*** que hay por línea y la ***segunda*** el ***número de caracteres***.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def csv_len(data) :\n    \n    words = []\n    letters = []\n    sentiments = []\n    tweets = []\n    \n    for index, tweet in data.iterrows():\n        tweet_split = tweet.Tweet.split()\n        \n        sentiments.append(tweet.Sentiment)\n        tweets.append(tweet.Tweet)\n        letters.append(len(tweet.Tweet))\n        words.append(len(tweet_split))\n    \n    data['Tweet'] = tweets\n    data['Sentiment'] = sentiments\n    data['Words'] = words\n    data['Letters'] = letters\n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A través de los datos recogidos en la función csv_len ***mostraremos un gráfico*** donde ***muestra los rangos de cantidad de palabras y letras*** con las que estamos trabajando, haciendo así más visuales los datos recogidos.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def graphic(data_len) :\n    \n    fig,ax = plt.subplots(figsize=(5,5))\n    plt.boxplot(data_len)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***En el preprocesamiento: *** \n\n1. Eliminaremos ****enlaces*** (comienzan por http o https y terminan por .com o .es), ***menciones***, ***hashtags*** y ***retweets***.\nEl siguiente paso sería eliminar: \n1. Los ***caracteres duplicados***, en este caso se contempla que si un caracter se repite 3 veces se sustituirá por una sola ocurrencia de este.\n2. Las ***risas*** (hahaha, jajaja) contemplando que puedan ser con cualquier vocal.\n3. Eliminamos las tildes o caracteres de raros que se encuentren en las letras.\n4. Eliminamos cualquier ***caracter que no sean letras***, ya que estos no tienen ningún valor.\n5. Se sustituyen los ***tabuladores*** por espacios en blanco.\n6. Si hay varios ***espacios en blanco*** se sustituyen por ***un solo espacio***.\n7. ***Eliminamos espacios*** al comienzo del tweet y al final.\n8. ***Eliminamos los saltos de línea*** que puedan existir en cualquier parte de la cadena.\n9. Eliminamos ***Stopwords***: es decir eliminamos la palabras vacías que por sí solas no tienen ningún tipo de significado, sino que sirven para acompañar o modificar a otras palabras.\n10. Reducimos las palabras presentes a su ***raíz*** correspondiente.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(data) :\n    \n    tweets = []\n    sentiment = []\n\n    for index, tweet in data.iterrows():\n        words_cleaned=\"\"\n        tweet_clean = tweet.Tweet.lower()\n    \n        words_cleaned =\" \".join([word for word in tweet_clean.split()\n            if 'http://' not in word\n            and 'https://'not in word\n            and '.com' not in word\n            and '.es' not in word\n            and not word.startswith('@')\n            and not word.startswith('#')\n            and word != 'rt'])\n        \n        \n        tweet_clean = re.sub(r'\\b([jh]*[aeiou]*[jh]+[aeiou]*)*\\b',\"\",words_cleaned)\n        tweet_clean = re.sub(r'(.)\\1{2,}',r'\\1',tweet_clean)\n        tweet_clean = re.sub(\n            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n            normalize( \"NFD\", tweet_clean), 0, re.I)\n        tweet_clean = re.sub(\"[^a-zA-Z]\",\" \",tweet_clean)\n        tweet_clean = re.sub(\"\\t\", \" \", tweet_clean)\n        tweet_clean = re.sub(\" +\", \" \",tweet_clean) \n        tweet_clean = re.sub(\"^ \", \"\", tweet_clean)\n        tweet_clean = re.sub(\" $\", \"\", tweet_clean)\n        tweet_clean = re.sub(\"\\n\", \"\", tweet_clean)\n        \n        words_cleaned=\"\"\n        stemmed =\"\"\n        \n        stop_words = set(stopwords.words('english'))\n        stemmer = SnowballStemmer('english')\n        \n        tokens = word_tokenize(tweet_clean)\n        \n        words_cleaned =[word for word in tokens if not word in stop_words]\n        stemmed = \" \".join([stemmer.stem(word) for word in words_cleaned])\n        \n        \n    \n        sentiment.append(tweet.Sentiment)\n        tweets.append(stemmed)\n    \n    data['Tweet'] = tweets\n    data['Sentiment'] = sentiment\n    data.loc[:,['Sentiment','Tweet']]\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Corpus: *Sem-Eval ***","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"En primer lugar obtenemos el dataframe de entrenamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/semevaldatadets/semeval-2017-train.csv', delimiter='\t')\ntrain.columns = ['Sentiment', 'Tweet']\ntrain.rename(columns={'label': 'Sentiment','text' : 'Tweet'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En segundo lugar obtenemos el dataframe de predicción.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/semevaldatadets/semeval-2017-test.csv', delimiter='\t')\ntest.columns = ['Sentiment', 'Tweet']\ntest.rename(columns={'label': 'Sentiment','text' : 'Tweet'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. Recogida de información.**\n\nComprobamos los diferentes valores de sentimientos que hay tanto en el dataframe test como en el train. En este caso hay tres (-1, 0, 1) donde cada uno tiene un valor de filas asignado. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.Sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos la ***palabras y letras por tweet*** del dataframe train antes del preprocesado.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = csv_len(train)\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***palabras*** por tweet antes del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(train['Words'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***letras*** por tweet antes del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(train['Letters'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos la ***palabras y letras por tweet*** del dataframe test antes del preprocesado.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test = csv_len(test)\ntest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***palabras*** por tweet antes del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(test['Words'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***letras*** por tweet antes del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(test['Letters'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Preprocesamiento de datos.** \n\nLimpiamos los datos con los que trabajará el algoritmo utilizando la función ***\"preprocessing\"***.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cleaned = preprocessing(train)\ntrain_cleaned.loc[:,['Sentiment','Tweet']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cleaned = preprocessing(test)\ntest_cleaned.loc[:,['Sentiment','Tweet']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Guardamos el preprocesaiento.** \n\nGuardamos los datos preprocesados en un csv para poder descargarlos y utilizarlos en un notebook para entrenar los clasificadores.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final = train_cleaned.loc[:,['Sentiment','Tweet']]\ntrain_final\ntrain_final.to_csv('semevalTrain.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_final = test_cleaned.loc[:,['Sentiment','Tweet']]\ntest_final\ntest_final.to_csv('semevalTest.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos la ***palabras y letras por tweet*** del dataframe train después del preprocesado.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cleaned = csv_len(train_cleaned)\ntrain_cleaned","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***palabras*** por tweet después del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(train_cleaned['Words'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***letra*** por tweet después del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(train_cleaned['Letters'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos la ***palabras y letras por tweet*** del dataframe test después del preprocesado.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cleaned = csv_len(test_cleaned)\ntest_cleaned","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***palabras*** por tweet después del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(test_cleaned['Words'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostramos el ***gráfico*** asociado a las ***letra*** por tweet después del preprocesamiento.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"graphic(test_cleaned['Letters'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}