{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One review\ndf['review'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Text Cleaning**\n\n1. Sample 10,000 rows\n2. Remove html tags\n3. Converting every thing to lower case\n4. Remove special characters\n5. Removing Stop words\n6. Stemming","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#1\n#df=df.sample(10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n#Clearly seem that here is no missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sentiment'].replace({'positive': 1, 'negative': 0}, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2\n# Using regex library to remove html tags\nimport re\nclean=re.compile('<.*?>')\nprint(df.iloc[2].review)\n# Test After Cleaning of one data\nre.sub(clean,'',df.iloc[2].review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to clean html tags\ndef clean_html(text):\n    clean=re.compile('<.*?>')\n    return re.sub(clean,'',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review']=df['review'].apply(clean_html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3\n#converting everything to lower\ndef convert_lower(text):\n    return text.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review']=df['review'].apply(convert_lower)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#4\n#function to remove special characters\ndef remove_special(text):\n    x=''\n    \n    for i in text:\n        #checking is the character in the given string is alphanumeric or not\n        if i.isalnum(): \n            x+=i\n        else:\n            x+=' '\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review']=df['review'].apply(remove_special)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5\n# Remove the stop words\n# using natural language tool kit and stopwords class\nimport nltk \nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef remove_stopwords(text):\n    x=[]\n    for i in text.split():\n        if i not in stopwords.words('english'):\n            x.append(i)\n    y=x[:]\n    x.clear()\n    return y\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review']=df['review'].apply(remove_stopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6\n# Perform stemming\nfrom nltk.stem.porter import PorterStemmer\nps=PorterStemmer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stem_words(text):\n    y=[]\n    for i in text:\n        y.append(ps.stem(i))\n    z=y[:]\n    y.clear()\n    return z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stem_words(['I','Loved','Loving','it'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review']=df['review'].apply(stem_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#join back\ndef join_back(list_input):\n    return \" \".join(list_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review']=df['review'].apply(join_back)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the input features\n# Using CountVectorizer class\nX=df.iloc[:,0:-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=cv.fit_transform(df['review']).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking the output\ny=df.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next step: Split the data in two parts\n# X,y\n# training set\n# test set(Already know the result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\nclf1=GaussianNB()\nclf2=MultinomialNB()\nclf3=BernoulliNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1.fit(X_train,y_train)\nclf2.fit(X_train,y_train)\nclf3.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1=clf1.predict(X_test)\ny_pred2=clf2.predict(X_test)\ny_pred3=clf3.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Gaussian:',accuracy_score(y_test,y_pred1)*100,'%')\nprint('Multinomial:',accuracy_score(y_test,y_pred2)*100,'%')\nprint('Bernoulli:',accuracy_score(y_test,y_pred3)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating accurary of GaussianNB manually\nprint(np.sum(y_test==y_pred1)/y_pred1.shape[0]*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the reviews\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All positive reviews\nnorm_text_pos=\"\"\nfor i in range(0,df.shape[0]):\n    if(df.iloc[i].sentiment==1):\n        norm_text_pos+=df.iloc[i].review\nlen(norm_text_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#word cloud for positive review words\nplt.figure(figsize=(10,10))\npositive_text=norm_text_pos\nWC=WordCloud(width=1000,height=500,max_words=500,min_font_size=5)\npositive_words=WC.generate(positive_text)\nplt.imshow(positive_words,interpolation='bilinear')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All negative reviews\nnorm_text_neg=\"\"\nfor i in range(0,df.shape[0]):\n    if(df.iloc[i].sentiment==0):\n        norm_text_neg+=df.iloc[i].review\nlen(norm_text_neg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word cloud for negative review words\nplt.figure(figsize=(10,10))\nnegative_text=norm_text_neg\nWC=WordCloud(width=1000,height=500,max_words=500,min_font_size=5)\nnegative_words=WC.generate(negative_text)\nplt.imshow(negative_words,interpolation='bilinear')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion:\n\n### 1. We can observed that both Bernoulli naive bayes and Multinomial naive bayes model performing well compared to Gaussian naive bayes.\n\n### 2. We can also use other different classification algorithms to see which one predicts best.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}