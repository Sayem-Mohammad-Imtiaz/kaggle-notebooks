{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bank marketing campaigns dataset - Opening Term Deposit","metadata":{}},{"cell_type":"markdown","source":"## Problem Statement","metadata":{}},{"cell_type":"markdown","source":"#### Bank marketing campaigns dataset analysis # Opening a Term Deposit. It is a dataset that describing Portugal bank marketing campaigns results. Conducted campaigns were based mostly on direct phone calls, offering bank client to place a term deposit. If after all marking afforts client had agreed to place deposit - target variable marked 'yes', otherwise 'no'\n\n#### To identify potential customers who opened term deposit in their bank.","metadata":{}},{"cell_type":"markdown","source":"## Packages used:-","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nimport numpy as np\n\nimport scipy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split,KFold\n\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom scipy.stats import skew,kurtosis,boxcox,boxcox_normmax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\nfrom sklearn.metrics import accuracy_score,precision_score,roc_auc_score,f1_score,recall_score,auc,make_scorer\n\nfrom sklearn.metrics import confusion_matrix,classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport statsmodels.api as sm\n\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Algorithms Used:-\n\n1.     Logistic Regression\n           1.1 LR Bagging Classifier\n           1.2 LR Adaboost Classifier\n           1.3 LR Kfold Bagging Classifier\n2.     Decision Tree\n           2.1 Decision Tree - Gini - Regularized\n           2.2 Decision Tree - Entropy - Regularized\n           2.3 Decision Tree - Bagging Classifier\n           2.4 Decision Tree - Adaboost Classifier\n           2.5 Decision Tree - Gradient Classifier\n3.     Random Forest\n           3.1 Random Forest - Entropy - Regularized\n           3.2 Random Forest - Kfold Bagging Classifier\n           3.3 Random Forest - Adaboost Classifier\n           3.4 Random Forest - Gradient Classifier\n4.     KNN\n           4.1 KNN - Bagging Classifier\n           4.2 KNN - Parameter Optimization\n5.     SVM\n6.     Naive Bayes - GausianNB","metadata":{}},{"cell_type":"markdown","source":"## Import dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/bank-marketing-campaigns-dataset/bank-additional-full.csv',sep=';')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing or Data Cleaning:-","metadata":{}},{"cell_type":"markdown","source":"### Check duplicates:-","metadata":{}},{"cell_type":"code","source":"df[df.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove duplicates:-","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reseting Index:-","metadata":{}},{"cell_type":"code","source":"df.reset_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop('index',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Null Check:-","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Datatype Check:-","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stats Check:-","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Columns Check:-","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Age:-\n* Check Outliers ,Skewness or Kurtosis detected or not.\n* Outliers - Data points deviates significantly than other data points\n            - Data points which falls long way than other data points\nNote : If any Outliers,Skewness or Kurtosis detected, then do boxcox transformation            ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.distplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Distribution of age')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Its deviate slightly at right side.**\nIt should follow the normal distrubution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.boxplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Boxplot - Outliers Detection')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Outliers detected, so we do boxcox transformation**","metadata":{}},{"cell_type":"markdown","source":"### Skewness & Kurtosis\n* #### skewness = 0 : normally distributed.\n* #### skewness > 0 : more weight in the left tail of the distribution.\n* #### skewness < 0 : more weight in the right tail of the distribution.\n* #### Kurtosis = 3 : normally distributed - Mesokurtic\n* #### Kurtosis > 3 : normally distributed - Leptokurtic\n* #### Kurtosis < 3 : normally distributed - Platykurtic","metadata":{}},{"cell_type":"code","source":"import scipy #Scientific Python\nprint('Skewness',scipy.stats.skew(df.age))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy #Scientific Python\nprint('Kurtosis',scipy.stats.kurtosis(df.age))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Boxcox Transformation Technique:-","metadata":{}},{"cell_type":"code","source":"from scipy.stats import boxcox,boxcox_normmax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.age = boxcox(df.age,boxcox_normmax(df.age))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After Boxcox Transform:-","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.distplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Distribution of age - After Boxcox transformation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note :- Its not following the normal distribution even after doing boxcox transformation. Better we can drop this column.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.boxplot(df.age)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.title('Boxplot for Outliers Detection - After Boxcox transformation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now the outliers are removed after the boxcox technique","metadata":{}},{"cell_type":"markdown","source":"### Skewness & Kurtosis after Boxcox Transformation","metadata":{}},{"cell_type":"code","source":"print('Skewness after Boxcox',scipy.stats.skew(df.age))\nprint('Kurtosis after Boxcox',scipy.stats.kurtosis(df.age))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Both the Skewness & Kurtosis are reduced after Boxcox Transformation.\n\n* Before Boxcox:-\n    *     Skewness 0.7845316793906337\n    *     Kurtosis 0.7908715485573286\n* After Boxcox :-\n    *     Skewness -0.006389818305811041\n    *     Kurtosis -0.38321858182694646","metadata":{}},{"cell_type":"markdown","source":"### Convert all categorical variable into numerical structure","metadata":{}},{"cell_type":"markdown","source":"#### Job:-","metadata":{}},{"cell_type":"code","source":"df.job.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.job.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nl_enc = LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.job = l_enc.fit_transform(df.job)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.job.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Marital:-","metadata":{}},{"cell_type":"code","source":"print(df.marital.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sorted(df.marital.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.marital = df.marital.replace(['divorced', 'married', 'single', 'unknown'],[0,1,2,3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Education:-","metadata":{}},{"cell_type":"code","source":"df.education.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sorted(df.education.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.education = df.education.replace(['basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown'],\n                                    [0,1,2,3,4,5,6,7])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.education.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Default:-","metadata":{}},{"cell_type":"code","source":"df.default.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sorted(df.default.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.default = df.default.replace(['no', 'unknown', 'yes'],[0,1,2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Housing:-","metadata":{}},{"cell_type":"code","source":"df.housing = df.housing.replace(['no', 'unknown', 'yes'],[0,1,2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loan:-","metadata":{}},{"cell_type":"code","source":"df.loan = df.loan.replace(['no', 'unknown', 'yes'],[0,1,2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Contact:-","metadata":{}},{"cell_type":"code","source":"df.contact = df.contact.replace(['telephone', 'cellular'],[1,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Month:-","metadata":{}},{"cell_type":"code","source":"print(sorted(df.month.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.month = df.month.replace(['apr', 'aug', 'dec', 'jul', 'jun', 'mar', 'may', 'nov', 'oct', 'sep'],range(0,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Day_of_week:-","metadata":{}},{"cell_type":"code","source":"print(sorted(df.day_of_week.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.day_of_week = df.day_of_week.replace(['fri', 'mon', 'thu', 'tue', 'wed'],[0,1,2,3,4])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Poutcome:-","metadata":{}},{"cell_type":"code","source":"print(sorted(df.poutcome.unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.poutcome = df.poutcome.replace(['failure', 'nonexistent', 'success'],[0,1,2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### y - Output Variable or Dependent Variable:-","metadata":{}},{"cell_type":"code","source":"df.y.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.y = df.y.replace(['no', 'yes'],[0,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## To check class Imbalanced or not:-","metadata":{}},{"cell_type":"code","source":"df.y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df.y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Note :- Dataset is highly imbalanced so we need to use below technique to overcome this problem after the Train Test Split\n#### SMOTE - SYNTHATIC MINORITY OF OVER SAMPLING TECHNIQUE","metadata":{}},{"cell_type":"markdown","source":"### To Identify Significant Variable:-","metadata":{}},{"cell_type":"markdown","source":"#### Correlation Graph:- Check Multicolinearity\n*     Correlation between 2 input variables should be very low - Weak Correlation\n*     Correlation between input & output variables should be very high - Strong Correlation\n\nNote: We can straight away remove those input columns which is having more correlated.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(),\n            annot=True,\n            linewidth=.5,\n            center = 0,\n            cbar=False,\n            cmap='YlGnBu')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Below columns are highly correlated with another input columns except y column, so dropping the same.","metadata":{}},{"cell_type":"code","source":"df = df.drop(['marital','contact','pdays','previous', 'emp.var.rate', 'cons.price.idx',\n       'cons.conf.idx', 'euribor3m', 'nr.employed','duration'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Difine X & y variables:-","metadata":{}},{"cell_type":"code","source":"X = df.loc[:,df.columns != 'y']\ny = df.loc[:,df.columns == 'y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OLS Method (Oridinary Least Square) - To Identify Significant Variable\n### p-value <= 0.05","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n\nols = sm.OLS(y,X).fit()\n\nprint(ols.summary2())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Note : P-value should be less than or equal to 0.05\n#### From the above result, we are removing the age , loan, month coulumns,because of its P-value > 0.05","metadata":{}},{"cell_type":"code","source":"df = df.drop(['age','loan','month'],axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.loc[:,df.columns != 'y']\ny = df.loc[:,df.columns == 'y']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## To check class Imbalanced or not.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data is highly imbalanced, So apply SMOTE on your trining datset.\n#### Note:- Dont apply SMOTE on testing data because its our original dataset which needs to be predicted\n#### Over Sampling the Minority Class - by SMOTE (Synthetic Minority Over Sampling Technique)","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nos = SMOTE(random_state = 2)\n\nos_X, os_y = os.fit_resample(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os_y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now both the classes are balanced equally :)","metadata":{}},{"cell_type":"markdown","source":"### Algorithms Used:-\n*     Logistic Regression\n*     Decision Tree\n*     Random Forest\n*     KNN\n    ","metadata":{}},{"cell_type":"markdown","source":"## Model 1 :- Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"#### 1.1 Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = LogisticRegression()\n\n# Train Your Model\nLR.fit(os_X,os_y)\n\n# Predict the model\nLR_predicted_y = LR.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nLR_CM = confusion_matrix(y_test,LR_predicted_y)\nprint(LR_CM)\n\n# Accuracy Score\nAccuracy = round(accuracy_score(y_test,LR_predicted_y)*100,2)\nprint('LR_Accuracy is ', Accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification Report\nprint(classification_report(y_test,LR_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.2 LR - Bagging Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bagging Classifier Technique\nLR_Bagged = BaggingClassifier(base_estimator=LR,random_state=0)\n\n# Train your model\nLR_Bagged.fit(os_X,os_y)\n\n# Predict the model\nLR_Bagged_predicted_y = LR_Bagged.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nLR_Bagged_CM = confusion_matrix(y_test,LR_Bagged_predicted_y)\nprint(LR_Bagged_CM)\n\n# Accuracy Score\nLR_Bagged_Accuracy = round(accuracy_score(y_test,LR_Bagged_predicted_y)*100,2)\nprint('LR_Bagged_Accuracy is ', LR_Bagged_Accuracy)\n\n# Classification Report\nprint(classification_report(y_test,LR_Bagged_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.3 LR - Boosting Classifier","metadata":{}},{"cell_type":"code","source":"# Boosting Classifier Technique\nLR_Ada_Boost = AdaBoostClassifier(base_estimator=LR,random_state=0)\n\n# Train your model\nLR_Ada_Boost.fit(os_X,os_y)\n\n# Predict the model\nLR_Adaboost_predicted_y = LR_Ada_Boost.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nLR_Adaboost_CM = confusion_matrix(y_test,LR_Adaboost_predicted_y)\nprint(LR_Adaboost_CM)\n\n# Accuracy Score\nLR_Adaboost_Accuracy = round(accuracy_score(y_test,LR_Adaboost_predicted_y)*100,2)\nprint('LR_Adaboost_Accuracy is ', LR_Adaboost_Accuracy)\n\n# Classification Report\nprint(classification_report(y_test,LR_Adaboost_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.4 Parameter Optimization\n*     GridSearchCV\n*     RandomisedSearchCV","metadata":{}},{"cell_type":"code","source":"param = {'n_estimators': np.arange(1,10)}\nkfold = KFold(n_splits=5, shuffle=True, random_state=0)\n\n# LR_Bagged_GS = GridSearchCV(LR_Bagged,param, cv= kfold ,scoring= accuracy_score) # Taking more time consumption, went through RandomisedSearchCV\n# LR_Bagged_GS.fit(X,y)\n\nLR_Bagged_RS = RandomizedSearchCV(LR_Bagged,param, cv= kfold ,scoring= accuracy_score)\nLR_Bagged_RS.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(LR_Bagged_GS.best_params_)\nprint(LR_Bagged_RS.best_params_)\n# LR_RS_n_estimators = LR_Bagged_RS['n_estimators']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_Bagged_Kfold = BaggingClassifier(base_estimator=LR,n_estimators=1,random_state=0)\n\n# Train your model\nLR_Bagged_Kfold.fit(os_X,os_y)\n\n# Predict your model\nLR_Bagged_Kfold_predicted_y = LR_Bagged_Kfold.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nLR_Bagged_Kfold_CM = confusion_matrix(y_test,LR_Bagged_Kfold_predicted_y)\nprint(LR_Bagged_Kfold_CM)\n\n# Accuracy Score\nLR_Bagged_Kfold_Accuracy = round(accuracy_score(y_test,LR_Bagged_Kfold_predicted_y)*100,2)\nprint('LR_Bagged_Kfold_Accuracy is ', LR_Bagged_Kfold_Accuracy)\n\n# Classification Report\nprint(classification_report(y_test,LR_Bagged_Kfold_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(4506/(4506+377))\nprint(1057/(1057+6413))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 2:- Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DT_Gini = DecisionTreeClassifier() # Fully growned tree which has more bias and variance error\n\n# Train the model\nDT_Gini.fit(os_X,os_y)\n\n# Predict the model\nDT_Gini_predicted_y = DT_Gini.predict(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nDT_Gini_CM = confusion_matrix(y_test,DT_Gini_predicted_y)\nprint(DT_Gini_CM)\n\n# Accuracy Score\nDT_Gini_Accuracy_Score = round(accuracy_score(y_test,DT_Gini_predicted_y)*100,2)\nprint('DT_Gini_Accuracy_Score is ', DT_Gini_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Gini_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.1 Decision Tree - Regularized","metadata":{}},{"cell_type":"code","source":"DT_Gini_Semi_Grown = DecisionTreeClassifier(max_depth=3,random_state=0)\n\n# Train the model\nDT_Gini_Semi_Grown.fit(os_X,os_y)\n\n# Predict the model\nDT_Gini_Semi_Grown_predicted_y = DT_Gini_Semi_Grown.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nDT_Gini_Semi_Grown_CM = confusion_matrix(y_test,DT_Gini_Semi_Grown_predicted_y)\nprint(DT_Gini_Semi_Grown_CM)\n\n# Accuracy Score\nDT_Gini_Semi_Grown_Accuracy_Score = round(accuracy_score(y_test,DT_Gini_Semi_Grown_predicted_y)*100,2)\nprint('DT_Gini_Semi_Grown_Accuracy_Score is ', DT_Gini_Semi_Grown_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Gini_Semi_Grown_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.2 Decision Tree - Entropy Method - Regularized","metadata":{}},{"cell_type":"code","source":"DT_Entropy_Semi_Grown = DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=0)\n\n# Train the model\nDT_Entropy_Semi_Grown.fit(os_X,os_y)\n\n# Predict the model\nDT_Entropy_Semi_Grown_predicted_y = DT_Entropy_Semi_Grown.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nDT_Entropy_Semi_Grown_CM = confusion_matrix(y_test,DT_Entropy_Semi_Grown_predicted_y)\nprint(DT_Entropy_Semi_Grown_CM)\n\n# Accuracy Score\nDT_Entropy_Semi_Grown_Accuracy_Score = round(accuracy_score(y_test,DT_Entropy_Semi_Grown_predicted_y)*100,2)\nprint('DT_Entropy_Semi_Grown_Accuracy_Score is ', DT_Entropy_Semi_Grown_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Entropy_Semi_Grown_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.3 Decision Tree - Bagging Classifier","metadata":{}},{"cell_type":"code","source":"DT_Bagged = BaggingClassifier(base_estimator=DT_Gini_Semi_Grown,n_estimators=1)\n\nDT_Bagged.fit(os_X,os_y)\n\nDT_Bagged_predicted_y = DT_Bagged.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nDT_Bagged_CM = confusion_matrix(y_test,DT_Bagged_predicted_y)\nprint(DT_Bagged_CM)\n\n# Accuracy Score\nDT_Bagged_Accuracy_Score = round(accuracy_score(y_test,DT_Bagged_predicted_y)*100,2)\nprint('DT_Bagged_Accuracy_Score is ', DT_Bagged_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Bagged_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.4 Decision Tree - Adaboost Classifier","metadata":{}},{"cell_type":"code","source":"DT_Adaboost = AdaBoostClassifier(base_estimator=DT_Gini_Semi_Grown,n_estimators=1)\n\nDT_Adaboost.fit(os_X,os_y)\n\nDT_Adaboost_predicted_y = DT_Adaboost.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nDT_Adaboost_CM = confusion_matrix(y_test,DT_Adaboost_predicted_y)\nprint(DT_Adaboost_CM)\n\n# Accuracy Score\nDT_Adaboost_Accuracy_Score = round(accuracy_score(y_test,DT_Adaboost_predicted_y)*100,2)\nprint('DT_Adaboost_Accuracy_Score is ', DT_Adaboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Adaboost_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2.4 Decision Tree - Gradient Boost Classifier","metadata":{}},{"cell_type":"code","source":"DT_Gboost = GradientBoostingClassifier(n_estimators=1)\n\nDT_Gboost.fit(os_X,os_y)\n\nDT_Gboost_predicted_y = DT_Gboost.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nDT_Gboost_CM = confusion_matrix(y_test,DT_Gboost_predicted_y)\nprint(DT_Gboost_CM)\n\n# Accuracy Score\nDT_Gboost_Accuracy_Score = round(accuracy_score(y_test,DT_Gboost_predicted_y)*100,2)\nprint('DT_Gboost_Accuracy_Score is ', DT_Gboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,DT_Gboost_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 3:- Random Foresst","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RF_Gini = RandomForestClassifier(n_estimators=100,criterion='gini',random_state=0)\n\nRF_Gini.fit(os_X,os_y)\n\nRF_Gini_predicted_y = RF_Gini.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nRF_Gini_CM = confusion_matrix(y_test,RF_Gini_predicted_y)\nprint(RF_Gini_CM)\n\n# Accuracy Score\nRF_Gini_Accuracy_Score = round(accuracy_score(y_test,RF_Gini_predicted_y)*100,2)\nprint('RF_Gini_Accuracy_Score is ', RF_Gini_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Gini_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.1 Random Forest - Entropy Method","metadata":{}},{"cell_type":"code","source":"RF_Entropy = RandomForestClassifier(n_estimators=100,criterion='entropy',random_state=0)\n\nRF_Entropy.fit(os_X,os_y)\n\nRF_Entropy_predicted_y = RF_Entropy.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nRF_Entropy_CM = confusion_matrix(y_test,RF_Entropy_predicted_y)\nprint(RF_Entropy_CM)\n\n# Accuracy Score\nRF_Entropy_Accuracy_Score = round(accuracy_score(y_test,RF_Entropy_predicted_y)*100,2)\nprint('RF_Entropy_Accuracy_Score is ', RF_Entropy_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Entropy_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2 Random Forest - Parameter Optimization","metadata":{}},{"cell_type":"code","source":"param = {'n_estimators': np.arange(1,10)}\nkfold = KFold(n_splits=5, shuffle=True, random_state=0)\n\nRF_RS = RandomizedSearchCV(RF_Gini,param, cv= kfold ,scoring= accuracy_score)\nRF_RS.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(RF_RS.best_params_)\nprint(RF_RS.best_estimator_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RF_RS_Kfold = BaggingClassifier(base_estimator=RF_Gini,n_estimators=1,random_state=0)\n\n# Train your model\nRF_RS_Kfold.fit(os_X,os_y)\n\n# Predict your model\nRF_RS_Kfold_predicted_y = RF_RS_Kfold.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nRF_RS_Kfold_CM = confusion_matrix(y_test,RF_RS_Kfold_predicted_y)\nprint(RF_RS_Kfold_CM)\n\n# Accuracy Score\nRF_RS_Kfold_Accuracy_Score = round(accuracy_score(y_test,RF_RS_Kfold_predicted_y)*100,2)\nprint('RF_RS_Kfold_Accuracy_Score is ', RF_RS_Kfold_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_RS_Kfold_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3 Random Forest - Adaboost Classifier","metadata":{}},{"cell_type":"code","source":"RF_Adaboost = AdaBoostClassifier(base_estimator=RF_Gini,n_estimators=1,random_state=0)\n\nRF_Adaboost.fit(os_X,os_y)\n\nRF_Adaboost_predict_y = RF_Adaboost.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nRF_Adaboost_CM = confusion_matrix(y_test,RF_Adaboost_predict_y)\nprint(RF_Adaboost_CM)\n\n# Accuracy Score\nRF_Adaboost_Accuracy_Score = round(accuracy_score(y_test,RF_Adaboost_predict_y)*100,2)\nprint('RF_Adaboost_Accuracy_Score is ', RF_Adaboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Adaboost_predict_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.4 Random Forest - Gradientboost Classifier","metadata":{}},{"cell_type":"code","source":"RF_Gboost = GradientBoostingClassifier(n_estimators=1)\n\nRF_Gboost.fit(os_X,os_y)\n\nRF_Gboost_predicted_y = RF_Gboost.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nRF_Gboost_CM = confusion_matrix(y_test,RF_Gboost_predicted_y)\nprint(RF_Gboost_CM)\n\n# Accuracy Score\nRF_Gboost_Accuracy_Score = round(accuracy_score(y_test,RF_Gboost_predicted_y)*100,2)\nprint('RF_Gboost_Accuracy_Score is ', RF_Gboost_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,RF_Gboost_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 4:- KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN = KNeighborsClassifier(n_neighbors=2)\n\nKNN.fit(os_X,os_y)\n\nKNN_predicted_y = KNN.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nKNN_CM = confusion_matrix(y_test,KNN_predicted_y)\nprint(KNN_CM)\n\n# Accuracy Score\nKNN_Accuracy_Score = round(accuracy_score(y_test,KNN_predicted_y)*100,2)\nprint('KNN_Accuracy_Score is ', KNN_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,KNN_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4.1 KNN - Bagged Classifier","metadata":{}},{"cell_type":"code","source":"KNN_Bagged = BaggingClassifier(base_estimator=KNN,n_estimators=1,random_state=0)\n\nKNN_Bagged.fit(os_X,os_y)\n\nKNN_Bagged_predicted_y = KNN_Bagged.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nKNN_Bagged_CM = confusion_matrix(y_test,KNN_Bagged_predicted_y)\nprint(KNN_Bagged_CM)\n\n# Accuracy Score\nKNN_Bagged_Accuracy_Score = round(accuracy_score(y_test,KNN_Bagged_predicted_y)*100,2)\nprint('KNN_Bagged_Accuracy_Score is ', KNN_Bagged_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,KNN_Bagged_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### 4.2 KNN - Parameter Optimization ","metadata":{}},{"cell_type":"code","source":"param = {'n_neighbors':np.arange(1,50),\n         'weights':['uniform','distance']}\nKNN_RS = RandomizedSearchCV(KNN,param,cv=5,scoring='roc_auc')\n\nKNN_RS.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_RS.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_RS.best_params_\nKNN_RS_params = KNN_RS.best_params_\n\nknn_weights = KNN_RS_params['weights']\nknn_n_neighbors = KNN_RS_params['n_neighbors']\n\nKNN1 = KNeighborsClassifier(n_neighbors=knn_n_neighbors, weights=knn_weights)\n\nKNN1.fit(os_X,os_y)\n\nKNN1_predicted_y = KNN1.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nKNN1_CM = confusion_matrix(y_test,KNN1_predicted_y)\nprint(KNN1_CM)\n\n# Accuracy Score\nKNN1_Accuracy_Score = round(accuracy_score(y_test,KNN1_predicted_y)*100,2)\nprint('KNN1_Accuracy_Score is ', KNN1_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,KNN1_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 5:- SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM = SVC()\n\nSVM.fit(os_X,os_y)\n\nSVM_predicted_y = SVM.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nSVM_CM = confusion_matrix(y_test,SVM_predicted_y)\nprint(SVM_CM)\n\n# Accuracy Score\nSVM_Accuracy_Score = round(accuracy_score(y_test,SVM_predicted_y)*100,2)\nprint('SVM_Accuracy_Score is ', SVM_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,SVM_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model 6:- Naive Bias","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NB = GaussianNB()\n\nNB.fit(os_X,os_y)\n\nNB_predicted_y = NB.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nNB_CM = confusion_matrix(y_test,NB_predicted_y)\nprint(NB_CM)\n\n# Accuracy Score\nNB_Accuracy_Score = round(accuracy_score(y_test,NB_predicted_y)*100,2)\nprint('NB_Accuracy_Score is ', NB_Accuracy_Score)\n\n# Classification Report\nprint(classification_report(y_test,NB_predicted_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Note : Finally I choose the model GaussianNB as best model to identify potential customers who opening the term deposit. Even though the model has very low accuracy but the FPR rate is very less.\n####        For better Accuracy model, we can take KNN model as 75.58 % Accuracy Score.[](http://)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}