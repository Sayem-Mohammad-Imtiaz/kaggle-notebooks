{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import modules"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.word2vec import Word2Vec\nfrom sklearn.naive_bayes import BernoulliNB,MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom scipy.sparse import csr_matrix\nimport string","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\")\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data basic information"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Response distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(\"Rating\").count().plot.pie(y=\"Review\",autopct=\"%.2f%%\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here instead of taking the original rating as our class labels\n# we will define 5 stars as our positive class and all the rating below 5 stars as our negative class\n# because the rating are subjective and for those 1-3 stars, the total proportion is very little\n# and would share a lot in common in attitudes or sentiments (negative)\n# furthermore, we will include 4 stars in the negative class to make class more balanced\ndf[\"Response\"] = (df[\"Rating\"]>4).astype(np.int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data split"},{"metadata":{},"cell_type":"markdown","source":"# No preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# shuffle the pd.DataFrame before train test split\nnp.random.seed(1234)\nindices = np.arange(df.shape[0])\nnp.random.shuffle(indices)\n\n# tokenize the reviews\ndf = df.iloc[indices].reset_index(drop=True)\ncorpus = df[\"Review\"].apply(word_tokenize)\n\n# train test split\nsplit_ind = 16000 # splitting index\ntrain_corpus = corpus[:split_ind]\ntest_corpus = corpus[split_ind:]\ndct = Dictionary(train_corpus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label = df[\"Response\"].to_numpy()[:split_ind]\ntest_label = df[\"Response\"].to_numpy()[split_ind:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Term-document matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the bow format corpus into scipy compressed sparse\n# row matrix in order to fit into the machine memory\ndef corpus2csr(bow,n_terms=None):\n    data = []\n    indices = []\n    indptr = [0,]\n    for i,sent in enumerate(bow):\n        n_words = len(sent)\n        indptr.append(indptr[-1]+n_words)\n        for (idx,cnt) in sent:\n            indices.append(idx)\n            data.append(cnt)\n    if n_terms is not None:\n        n_col = max(indices)\n        assert n_col <= n_terms,\"Total columns should be less than n_terms\"\n        if n_col < n_terms-1:\n            paddings = n_terms-n_col-1\n            data.extend([0 for _ in range(paddings)])\n            indices.extend(list(range(n_col+1,n_terms)))\n            indptr[-1] = indptr[-1]+paddings\n    return csr_matrix(tuple(map(np.array,[data,indices,indptr])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_terms = len(dct.keys())\ntrain_bow = list(map(dct.doc2bow,train_corpus))\ntrain_sparse = corpus2csr(train_bow,n_terms)\ntest_bow = list(map(dct.doc2bow,test_corpus))\ntest_sparse = corpus2csr(test_bow,n_terms)\ntrain_sparse.shape,test_sparse.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary term: present or absent\nclf_nb = BernoulliNB()\nclf_nb.fit(train_sparse,train_label)\ntrain_acc = clf_nb.score(train_sparse,train_label)\ntest_acc = clf_nb.score(test_sparse,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# multinomial term\nclf_nb = MultinomialNB()\nclf_nb.fit(train_sparse,train_label)\ntrain_acc = clf_nb.score(train_sparse,train_label)\ntest_acc = clf_nb.score(test_sparse,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier()\nclf_rf.fit(train_sparse,train_label)\ntrain_acc = clf_rf.score(train_sparse,train_label)\ntest_acc = clf_rf.score(test_sparse,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classical preprocessing\n\n(stemming and removing the stopwords & punctuations)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# stemmer and remove stopwords\nstemmer = PorterStemmer()\nstopwords_en = stopwords.words(\"english\")\npunctuations = [ch for ch in string.punctuation]\nstopw_punct = set(stopwords_en+punctuations)\ncorpus_preprocessed = []\nfor sent in corpus:\n    corpus_preprocessed.append([stemmer.stem(word).lower() for word in sent\\\n                    if stemmer.stem(word).lower() not in stopw_punct])\n\n# train test split\nsplit_ind = 16000 # splitting index\ntrain_corpus = corpus_preprocessed[:split_ind]\ntest_corpus = corpus_preprocessed[split_ind:]\ndct = Dictionary(train_corpus)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Term-document matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_terms = len(dct.keys())\ntrain_bow = list(map(dct.doc2bow,train_corpus))\ntrain_sparse = corpus2csr(train_bow,n_terms)\ntest_bow = list(map(dct.doc2bow,test_corpus))\ntest_sparse = corpus2csr(test_bow,n_terms)\ntrain_sparse.shape,test_sparse.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary term: present or absent\nclf_nb = BernoulliNB()\nclf_nb.fit(train_sparse,train_label)\ntrain_acc = clf_nb.score(train_sparse,train_label)\ntest_acc = clf_nb.score(test_sparse,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# multinomial term\nclf_nb = MultinomialNB()\nclf_nb.fit(train_sparse,train_label)\ntrain_acc = clf_nb.score(train_sparse,train_label)\ntest_acc = clf_nb.score(test_sparse,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier()\nclf_rf.fit(train_sparse,train_label)\ntrain_acc = clf_rf.score(train_sparse,train_label)\ntest_acc = clf_rf.score(test_sparse,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word2Vec preprocessing\n\nusing CBOW"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_corpus = corpus[:split_ind]\ntest_corpus = corpus[split_ind:]\nw2v_model = Word2Vec(train_corpus,size=128,min_count=3,seed=1234,iter=10)\n# extract word embeddings and average on documents\nembeddings = w2v_model.wv\nvocabulary = set(embeddings.vocab.keys())\ntrain_doc2vec = np.array([np.mean([embeddings[word] for word in sent if word in vocabulary],axis=0) for sent in train_corpus])\ntest_doc2vec = np.array([np.mean([embeddings[word] for word in sent if word in vocabulary],axis=0) for sent in test_corpus])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test goodness of embeddings\nprint(embeddings.most_similar(positive=[\"man\",\"king\"],negative=[\"woman\",\"queen\"]))\nprint(embeddings.similar_by_word(\"man\"))\nprint(embeddings.similar_by_word(\"woman\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lr = LogisticRegression(max_iter=300)\nclf_lr.fit(train_doc2vec,train_label)\ntrain_acc = clf_lr.score(train_doc2vec,train_label)\ntest_acc = clf_lr.score(test_doc2vec,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier(max_depth=12)\nclf_rf.fit(train_doc2vec,train_label)\ntrain_acc = clf_rf.score(train_doc2vec,train_label)\ntest_acc = clf_rf.score(test_doc2vec,test_label)\nprint(\"Train accuracy is {}\".format(train_acc))\nprint(\"Test accuracy is {}\".format(test_acc))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}