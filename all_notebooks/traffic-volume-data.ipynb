{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Generic library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv(\"../input/Train.csv\")\ntest_df=pd.read_csv(\"../input/Test.csv\")\nsubmission_df=pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train size : rows\",train_df.shape[0],\" and columns\",train_df.shape[1])\nprint(\"Test size : rows\",test_df.shape[0],\" and columns\",test_df.shape[1])\nprint(\"Submission size : rows\",submission_df.shape[0],\" and columns\",submission_df.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns.difference(test_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"source\"] = \"train\"\ntest_df[\"source\"] = \"test\"\ndf = pd.concat([train_df,test_df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify discrete and continous columns\ncol_disc=[]\ncol_medium=[]\ncol_cont=[]\nprint(\"Attributes with their distinct count and their classification\")\nfor i in df.columns:\n    if df[i].nunique() <=10:\n        print(i,\"==\",df[i].nunique(),\"== disc\")\n        col_disc.append(i)\n    elif (df[i].nunique() >10 and df[i].nunique() <100):\n        col_medium.append(i)    \n        print(i,\"==\",df[i].nunique(),\"== medium\")\n    else:\n        col_cont.append(i)\n        print(i,\"==\",df[i].nunique(),\"== cont\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in col_disc:\n    print(i ,\"with distinct values \\n\",df[i].unique())\nfor i in col_medium:\n    print(i ,\"with distinct values \\n\",df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cov()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['traffic_volume'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_cont_key_df=df[col_cont]\nnum_cont_list=col_cont_key_df.columns.drop(\"date_time\")\nsns.pairplot(data=df,vars=num_cont_list,hue='weather_type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_cont_key_df=df[col_cont]\nnum_cont_list=col_cont_key_df.columns.drop(\"date_time\")\nsns.pairplot(data=df,vars=num_cont_list,hue='is_holiday')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.boxplot(data=df,orient=\"h\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func=dict(Count='count',Avg='mean',Median='median',Deviation='std',Min='min',Max='max')\ndf.groupby(\"weather_type\").agg({\n        'traffic_volume': agg_func,\n    }).sort_values(('traffic_volume', 'Count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 20))\nsns.boxplot(data=df,x=df[\"weather_type\"],y=df[\"traffic_volume\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func=dict(Count='count',Avg='mean',Median='median',Deviation='std',Min='min',Max='max')\ndf.groupby(\"is_holiday\").agg({\n        'traffic_volume': agg_func,\n    }).sort_values(('traffic_volume', 'Count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 20))\nsns.boxplot(data=df,x=df[\"is_holiday\"],y=df[\"traffic_volume\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func=dict(Count='count',Avg='mean',Median='median',Deviation='std',Min='min',Max='max')\ndf.groupby(\"weather_description\").agg({\n        'traffic_volume': agg_func,\n    }).sort_values(('traffic_volume', 'Count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df[\"weather_type\"],df[\"is_holiday\"], values=df.traffic_volume, aggfunc='median',dropna=False,margins=True,margins_name=\"Total Median\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func=dict(Count='count',Avg='mean',Median='median',Deviation='std',Min='min',Max='max')\ndf.groupby([\"is_holiday\",\"weather_type\"]).agg({\n        'traffic_volume': agg_func,\n    }).sort_values(('traffic_volume', 'Count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_func=dict(Count='count',Avg='mean',Median='median',Deviation='std',Min='min',Max='max')\ndf.groupby([\"weather_type\",\"weather_description\"]).agg({\n        'traffic_volume': agg_func,\n    }).sort_values(('traffic_volume', 'Count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding\ncat_col=['weather_type','is_holiday','weather_description']\none_hot=pd.get_dummies(df[cat_col])\ntraffic_vol_procsd_df=pd.concat([df,one_hot],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot['traffic_volume']=df['traffic_volume']\none_hot.corr()['traffic_volume'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traffic_dt_df=traffic_vol_procsd_df.drop(columns=['weather_type','is_holiday','weather_description'])\ntraffic_dt_df.set_index('date_time',inplace=True)\ntraffic_dt_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final = traffic_dt_df[traffic_dt_df.source==\"train\"]\ntest_final = traffic_dt_df[traffic_dt_df.source==\"test\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final.drop(columns=\"source\",inplace=True)\ntest_final.drop(columns=\"source\",inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split train and data\ntrain_X = train_final.drop(columns=[\"traffic_volume\"])\ntrain_Y = train_final[\"traffic_volume\"]\ntest_X = test_final.drop(columns=[\"traffic_volume\"])\ntest_Y = test_final[\"traffic_volume\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_final[train_final[\"traffic_volume\"]==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import cross_val_score\n\nmodel_metrics={}\ndef calc_metrics_and_predict(model,model_label,train_X,test_X,train_Y,test_Y,test_final, scaler,cv):\n    if scaler is not None:\n        # Scaling\n        print(\"Scaling applied\")\n        train_X = scaler.fit_transform(train_X)\n        test_X = scaler.transform(test_X)\n    print(\"fit data\")    \n    model.fit(train_X, train_Y)\n    print(\"predict data\")\n    yhat_train = model.predict(train_X)\n    rmse=np.sqrt(mean_squared_error(train_Y, yhat_train))\n    mae=mean_absolute_error(train_Y,yhat_train)\n    #mape=np.mean(np.abs((train_Y - yhat_train) / train_Y)) * 100\n    mape=mae * 100\n    if cv==True:\n        print(\"Cross-Validation score\")\n        scores = cross_val_score(model, train_X, train_Y, cv = 10,scoring='neg_mean_squared_error') \n        avg_cross_val_score = np.mean(np.sqrt(np.abs(scores)))\n    else:\n        avg_cross_val_score=None\n    #avg_cross_val_score=0\n    model_metrics[model_label]=[rmse,mae,mape,avg_cross_val_score]\n    # Predict test data and add to test_fnal dataframe\n    test_final[model_label] =  model.predict(test_X)\n    return model_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear regression\nfrom sklearn.linear_model import LinearRegression\n\nlinear_model = LinearRegression()\n        \nmodel_metrics=calc_metrics_and_predict(linear_model,'linear_reg',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear model with cross-validation\nfrom sklearn.model_selection import cross_val_score\na = cross_val_score(linear_model, train_X, train_Y, cv=10, scoring='neg_mean_squared_error')\nnp.mean(np.sqrt(np.abs(a)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Regularization technique\nfrom sklearn.linear_model import Ridge, Lasso \n\n# List to maintain the different cross-validation scores \ncross_val_scores_ridge = [] \n  \n# List to maintain the different values of alpha \nalpha = [] \n  \n# Loop to compute the different values of cross-validation scores \nfor i in range(1, 9): \n    ridgeModel = Ridge(alpha = i * 0.25) \n    ridgeModel.fit(train_X, train_Y) \n    scores = cross_val_score(ridgeModel, train_X, train_Y, cv = 10,scoring='neg_mean_squared_error') \n    avg_cross_val_score = np.mean(np.sqrt(np.abs(scores)))\n    cross_val_scores_ridge.append(avg_cross_val_score) \n    alpha.append(i * 0.25) \n  \n# Loop to print the different values of cross-validation scores \nfor i in range(0, len(alpha)): \n    print(str(alpha[i])+' : '+str(cross_val_scores_ridge[i])) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building ridge model\nridgeModel = Ridge(alpha = 1 * 0.25) \nmodel_metrics=calc_metrics_and_predict(ridgeModel,'regularization',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN implementation\n#from sklearn.neighbors import KNeighborsRegressor\n#from sklearn.preprocessing import StandardScaler\n#from sklearn.preprocessing import PolynomialFeatures\n#from math import sqrt\n\n\n# Scaling\n#train_scaled_X = StandardScaler().fit_transform(train_X)\n      \n\n#df_len=round(sqrt(len(traffic_dt_df)))\n#Train Model and Predict  \n#for k in range(3,7):\n#    neigh = KNeighborsRegressor(n_neighbors = k).fit(train_scaled_X,train_Y)\n#    yhat_train = neigh.predict(train_scaled_X)\n#    train_rmse=sqrt(mean_squared_error(train_Y,yhat_train))\n#    print(\"RMSE for train : \",train_rmse,\" with k =\",k)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict on testing data:\nfrom sklearn.neighbors import KNeighborsRegressor\n\nneigh = KNeighborsRegressor(n_neighbors = 3)\nmodel_metrics=calc_metrics_and_predict(neigh,'KNN',train_X,test_X,train_Y,test_Y,test_final,StandardScaler(),True)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian NB\nfrom sklearn.naive_bayes import GaussianNB\n\nNB=GaussianNB()\n\nmodel_metrics=calc_metrics_and_predict(NB,'NB_Gaussian',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics\n\n\n# MultinomialNB\nfrom sklearn.naive_bayes import MultinomialNB\n\nNB=MultinomialNB()\n\nmodel_metrics=calc_metrics_and_predict(NB,'NB_MultinomialNB',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics\n\n\n# Bernoulli\nfrom sklearn.naive_bayes import BernoulliNB\n\nBL=BernoulliNB()\n\nmodel_metrics=calc_metrics_and_predict(BL,'NB_BernoulliNB',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfm=RandomForestRegressor(random_state = 0, criterion='mse',n_jobs = -1, \n        n_estimators = 100, max_depth = None,min_samples_leaf=1,min_samples_split=2)\n\nmodel_metrics=calc_metrics_and_predict(rfm,'Random_forest',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree regressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = DecisionTreeRegressor()\n\n\n# Choose some parameter combinations to try\nparameters = {'criterion' : ['mse','mae','friedman_mse'],\n              'max_features': ['log2', 'sqrt','auto'],\n              'max_depth': range(2,16,2), \n              'min_samples_split': range(2,16,2),\n              'min_samples_leaf': range(2,16,2)             \n\n             }\n\n\n\n\n#print(\"Grid search started\")\n#start_time = time.time()\n# Run the grid search\n#grid_obj = GridSearchCV(clf, parameters, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n#grid_obj = grid_obj.fit(train_X, train_Y)\n#elapsed_time = time.time() - start_time\n#print(elapsed_time)\n# Set the clf to the best combination of parameters\n#clf = grid_obj.best_estimator_\n#clf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above code run for so long and found below hyper parameter. So i commented code\nparameters = {'criterion' : ['mse','mae'], 'max_features': ['log2', 'sqrt','auto'], 'max_depth': [80, 90, 100, 110], 'min_samples_split': [8,10,12], 'min_samples_leaf': [3, 4, 5]\n\nDecisionTreeRegressor(criterion='mse', max_depth=100, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=5, min_samples_split=8, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best')"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nclf=DecisionTreeRegressor(criterion='mse', max_depth=100, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=5, min_samples_split=8, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter='best')\n\n\nmodel_metrics=calc_metrics_and_predict(clf,'Decision_Tree',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ada boost classifier\nfrom sklearn.ensemble import AdaBoostClassifier,AdaBoostRegressor\n#dtree = DecisionTreeClassifier(criterion='',max_depth=1)\n\nadabst_fit = AdaBoostRegressor(base_estimator= clf,n_estimators=5000,learning_rate=0.05,random_state=42)\n\nmodel_metrics=calc_metrics_and_predict(clf,'Adaboost',train_X,test_X,train_Y,test_Y,test_final,None,True)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradientboost Classifier\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngbc_fit = GradientBoostingRegressor(loss='quantile',learning_rate=0.05,n_estimators=200,min_samples_split=8,min_samples_leaf=5,max_depth=100,random_state=42,max_features='log2')\n\n#gbc_fit = GradientBoostingRegressor(base_estimator= clf,n_estimators=5000,learning_rate=0.05,random_state=42)\n\n    \nmodel_metrics=calc_metrics_and_predict(gbc_fit,'Gradient_boosting',train_X,test_X,train_Y,test_Y,test_final,None,False)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Xgboost Classifier\nimport xgboost as xgb\n\nxgb_fit = xgb.XGBRegressor(learning_rate=0.05,n_estimators=100,min_samples_split=8,min_samples_leaf=5,max_depth=100,random_state=42,max_features='log2' )\n\n\n\nmodel_metrics=calc_metrics_and_predict(xgb_fit,'XGBoosting',train_X,test_X,train_Y,test_Y,test_final,None,False)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from vecstack import stacking\n\n# Get your data\n\n# Initialize 1st level models\n\n# Get your stacking features in a single line\n#S_train, S_test = stacking(models, X_train, y_train, X_test, regression = True, verbose = 2)\n\n# Use 2nd level model with stacking features\n#Complete examples\n#Regression\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom vecstack import stacking\n\n\n# Caution! All models and parameter values are just \n# demonstrational and shouldn't be considered as recommended.\n# Initialize 1st level models.\nmodels = [\n    linear_model,\n    neigh,\n    rfm,\n#    xgb_fit\n    ]\n    \n# Compute stacking features\nS_train, S_test = stacking(models, train_X, train_Y, test_X, \n    regression = True, metric = mean_absolute_error, n_folds = 4, \n    shuffle = True, random_state = 0, verbose = 2)\n\n# Initialize 2nd level model\n#model = XGBRegressor(seed = 0, n_jobs = -1, learning_rate = 0.1,     n_estimators = 100)\nmodel_stacking= xgb_fit\n\n# Fit 2nd level model\nmodel_stacking = model_stacking.fit(S_train, train_Y)\n\n# Predict\ny_pred = model_stacking.predict(S_train)\n\n# Final prediction score\nprint('Final prediction score: [%.8f]' % mean_absolute_error(train_Y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_metrics=calc_metrics_and_predict(model_stacking,'Stacking',train_X,test_X,train_Y,test_Y,test_final,None,False)\nmodel_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_comparison_df=pd.DataFrame.from_dict(model_metrics)\nmodel_comparison_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_final.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_final.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_lst=['linear_reg', 'regularization',\n       'KNN', 'NB_Gaussian', 'NB_MultinomialNB', 'NB_BernoulliNB',\n       'Random_forest', 'Decision_Tree', 'Adaboost', 'Gradient_boosting', 'XGBoosting',\n       'Stacking']\nfor i in models_lst:\n    Linear_submission = test_final[[i]]\n    Linear_submission.head(2)\n    #Linear_submission.columns = submission_df.columns\n    Linear_submission.to_csv(i+\".csv\")\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}