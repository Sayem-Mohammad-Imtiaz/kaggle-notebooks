{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Import Libraries thats needed from pytorch,torchvision,Keras,Opencv**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\n\n#pytorch utils\nimport torch\nimport torchvision\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\n\n%matplotlib inline\nfrom tensorflow.keras.utils import plot_model\n\n# Splitting data\nfrom sklearn.model_selection import train_test_split\n\n# Metrics \nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Deep Learning\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout\n#from tensorflow.keras.applications.resnet import ResNet50\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get the Base Path for the training Images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = '../input/final-trainzip/'\nprint(os.listdir(base_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get the Length of the classes as each class is a folder of pictures in Training folder**"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = len(os.listdir(os.path.join(base_path,'Train')))\nclasses","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get all the folders from the Train folder to a list(train_folders)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\ntrain_folders = sorted(glob('../input/final-trainzip/Train/*'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading, showing and showing random images in a grid using Opencv**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(img_path, resize=True):\n  img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n\n  if resize:\n    img = cv2.resize(img, (64, 64), interpolation = cv2.INTER_AREA)\n\n  return img\n\ndef show_image(img_path):\n  img = load_image(img_path)\n  plt.imshow(img)\n  plt.axis('off')\n\ndef show_sign_grid(image_paths):\n  images = [load_image(img) for img in image_paths]\n  images = torch.as_tensor(images)\n  images = images.permute(0, 3, 1, 2)\n  grid_img = torchvision.utils.make_grid(images, nrow=11)\n  plt.figure(figsize=(24, 12))\n  plt.imshow(grid_img.permute(1, 2, 0))\n  plt.axis('off');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Images from each folder of the Training Set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_images = [np.random.choice(glob(f'{tf}/*png')) for tf in train_folders]\nshow_sign_grid(sample_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Just a Random Image from the Folder 42, 10th Image**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_path = glob(f'{train_folders[42]}/*png')[10]\nshow_image(img_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting all the Images from the folder to a data listafter resizing to height and width desired**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[]\nlabels=[]\n\nheight = 30\nwidth = 30\nchannels = 3\nclasses = 43\nn_inputs = height * width*channels\n\nfor i in range(classes) :\n    path = \"../input/final-trainzip/Train/{0}/\".format(i)\n    Class=os.listdir(path)\n    for a in Class:\n        try:\n            image=cv2.imread(path+a)\n            image_from_array = Image.fromarray(image, 'RGB')\n            size_image = image_from_array.resize((height, width))\n            data.append(np.array(size_image))\n            labels.append(i)\n        except AttributeError:\n            print(\" \")\n            \nCells=np.array(data)\nlabels=np.array(labels)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing Shape of the data and the labels\nprint(f'Shape of the data {Cells.shape}')\nprint(f'Shape of the labels {labels.shape}')\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into training and validation data \nX_train, X_val, y_train, y_val = train_test_split(Cells, labels, test_size=0.25, random_state=42)\n\n# normalize the input data\nX_train = X_train/255.\nX_val = X_val/255.\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One hot encoding of the data as Ml algorithms cannot work with categorical data.\n#All categorical data must be converted to numbers\nfrom keras.utils import to_categorical\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Deep Neural Networks with convolution layers, Max pooling layers, Dense and Drop out layers are picked to customize for this dataset and the output layer activation function is Softmax and all the hidden layers activation function is ReLU.**\n\n**Loss function used is: Categorical Loss function\nOptimizer for gradient update used is : Adam**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(rate=0.5))\n\nmodel.add(Dense(43, activation='softmax'))\n\n#model compilation with loss fn and optimizer of adam\nmodel.compile(\n    loss='categorical_crossentropy', \n    optimizer='Adam', \n    metrics=['accuracy']\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training for 10 epochs**"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nhistory = model.fit(X_train, y_train, batch_size= 64, epochs=epochs,validation_data=(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plotting Accuracy and Loss**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nprint(\"Training set accuracy is:\",\"{:.2f}%\".format(max(history.history['accuracy'])*100))\nprint(\"Validation set accuracy is:\",\"{:.2f}%\".format(max(history.history['val_accuracy'])*100))\n\n\nplt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nprint(\"Training Loss:\",\"{:.4f}\".format(min(history.history['loss'])))\nprint(\"Validation Loss:\",\"{:.4f}\".format(min(history.history['val_loss'])))\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get the Images from the Test Folder**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_folder = '../input/gtsrb-german-traffic-sign/Test'\nsample_images = [np.random.choice(glob(f'{img_folder}/*png')) for i in img_folder]\nshow_sign_grid(sample_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get the Test.csv file and Iterate through Images**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=pd.read_csv(\"../input/gtsrb-german-traffic-sign/Test.csv\")\nlabels=y_test['Path'].values\ny_test=y_test['ClassId'].values\n\ndata=[]\n\nfor f in labels:\n    image=cv2.imread('../input/gtsrb-german-traffic-sign/Test/'+ f.replace('Test/', ''))\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((height, width))\n    data.append(np.array(size_image))\n\nX_test=np.array(data)\nX_test = X_test.astype('float32')/255 \npred = model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Test score accuracy is:\",\"{:.2f}%\".format(accuracy_score(y_test, pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_confusion_matrix(confusion_matrix):\n\n  cm = confusion_matrix.copy()\n\n  cell_counts = cm.flatten()\n\n  cm_row_norm = cm / cm.sum(axis=1)[:, np.newaxis]\n\n  row_percentages = [\"{0:.2f}\".format(value) for value in cm_row_norm.flatten()]\n\n  cell_labels = [f\"{cnt}\\n{per}\" for cnt, per in zip(cell_counts, row_percentages)]\n  cell_labels = np.asarray(cell_labels).reshape(cm.shape[0], cm.shape[1])\n\n  df_cm = pd.DataFrame(cm_row_norm)\n\n  hmap = sns.heatmap(df_cm, annot=cell_labels, fmt=\"\", cmap=\"Blues\")\n  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n  plt.ylabel('True Class')\n  plt.xlabel('Predicted Class')\n  plt.title('Confusion Matrix')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import plot_confusion_matrix\ncm = confusion_matrix(y_test,pred)\nshow_confusion_matrix(cm)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}