{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bank Marketing Dataset\n\nThis dataset contains information about a Portuguese bank marketing campaign. It's goal is to predict if the client will subscribe to a term deposit, indicated by the variable 'y'.\n\nMore information about this database can be found at: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nfrom sklearn.preprocessing import OrdinalEncoder, RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom tqdm.notebook import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\nimport os\nprint(os.listdir(\"../input/bank-marketing-dataset\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Opening database"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/bank-marketing-dataset/bank.csv')\ndf = df.rename(columns={'deposit': 'y'})\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, this dataset have a lot of categorical features.\n\nTo begin our study, we should have a look at the 'y' distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['y'].value_counts().plot.bar()\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot shows that there are a considerable unbalance between the classes, our model should consider that.\n\nNow, let's check the categorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','poutcome']\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(20,20))\nfor i, col in enumerate(categorical_cols):\n    row_index = (i % 3)\n    col_index = int(i / 3)\n    fig.add_subplot(df[col].value_counts().plot.bar(ax=axes[row_index, col_index], title=col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols = ['balance', 'day','duration', 'campaign', 'pdays', 'previous']\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20,20))\nfor i, col in enumerate(numerical_cols):\n    row_index = (i % 3)\n    col_index = i // 3\n    fig.add_subplot(df[col].value_counts().plot.hist(ax=axes[row_index, col_index], title=col))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyzing the influence of the age\n\nTo check how the age influence the 'y', we can calculate the success rate (number of 'yes' divided by number of 'no') for each age and plot it"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[['age', 'y']]\ndata['y'] = data['y'].apply(lambda y: 1 if y == 'yes' else 0)\ndata = data.groupby('age')['y'].mean() * 100\ndata.plot.bar(figsize=(15, 5), title='Success Rate x Age')\nplt.ylabel('Success Rate (%)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this plot, we can conclude that older people tend to have higher chance tp subscribe to a term deposit. Also, young people can also have a high chance to subscribe, which reduces as the person gets older and get stabilize at 30 years old, growing again only after the 60 years."},{"metadata":{},"cell_type":"markdown","source":"## Analyzing the influence of the job\n\nWith a similar analysis, we can plot the number of 'yes' per job"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[df['y'] == 'yes'].groupby(df['job'])\nN = 12\ndata['job'].count().nlargest(N).plot.bar(figsize=(15, 5),\n                                           title='Number of subscriptions per Job')\nplt.grid(True)\nplt.ylabel(\"Number of Subscriptions\")\nplt.xlabel(\"Job\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, this plot shows that 'jobs' with a possible economical stability have a higher number of subscriptions, as 'management', 'technician', 'blue-collar' and 'admin'. "},{"metadata":{},"cell_type":"markdown","source":"## Analyzing the influence of the marital\n\nWe will apply the same logic as before"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[df['y'] == 'yes'].groupby(df['marital'])\nN = 3\ndata['marital'].count().nlargest(N).plot.bar(figsize=(15, 5),\n                                           title='Number of subscriptions per Marital')\nplt.ylabel(\"Number of Subscriptions\")\nplt.show()\nprint('Proportion from the biggest number to the second one: {}'.format(\n      data['marital'].count().nlargest(N)[0] / data['marital'].count().nlargest(N)[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Married people have a higher number of subscriptions (almost 70% bigger than single), followed by single and divorced (in last)."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing the data\n\nNow, we could analyze the correlation of the variables to have a better knowledge of how much each one is important to predict 'y'.\n\nFirst, we need to transform the categorical column into numerical:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.copy()\ndata['loan'] = data['loan'].apply(lambda x: 1 if x == 'yes' else 0)\ndata['housing'] = data['housing'].apply(lambda x: 1 if x == 'yes' else 0)\ndata['default'] = data['default'].apply(lambda x: 1 if x == 'yes' else 0)\ndata['y'] = data['y'].apply(lambda x: 1 if x == 'yes' else 0)\ndata = pd.get_dummies(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's check the skewness of the numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['duration'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df['duration'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The data is not in a normal distribution, so let's transform it\ndata['duration'] = np.log(data['duration'] + 1)\nsns.distplot(data['duration'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(data['duration'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(data['age'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['age'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The data is not in a normal distribution, so let's transform it\ndata['age'] = np.log(data['age'])\nsns.distplot(data['age'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['age'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sns.distplot(data['balance'], fit=norm)\nfig = plt.figure()\nres = stats.probplot(data['balance'], plot=plt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Balance has a lot of zero values, so let's keep it for this study.\n\nFinally, separating the 'y' column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = data['y']\ndata = data.drop(columns=['y'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the model\n\nFor this study, we will test the acuraccy of some classifiers, like RandomForest, kNN, SVC and LogistcRegression.\n\nOur final model will be the best between those"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_scores(model):\n    kf = KFold(n_folds, shuffle=True).get_n_splits(data.values)\n    score = cross_val_score(model, data.values, y_train, scoring='accuracy', cv = kf, n_jobs=-1)\n    return(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators':[50, 100, 150, 200, 250],\n    'max_depth': [None, 2, 3, 4, 5]\n}\nforest = Pipeline([('scaler', RobustScaler()),\n                   ('model', GridSearchCV(RandomForestClassifier(n_jobs=-1), params))])\nparams = {'kernel':('linear', 'rbf'), 'C':range(1, 10)}\nsvc = Pipeline([('scaler', RobustScaler()),\n                ('model', GridSearchCV(SVC(class_weight='balanced', max_iter=1000, gamma='scale'), params))])\nparams = {'n_neighbors' : range(3, 10)}\nknn = Pipeline([('scaler', RobustScaler()),\n                ('model', GridSearchCV(KNeighborsClassifier(n_jobs=-1), params))])\nlogistic = Pipeline([('scaler', RobustScaler()), ('model', LogisticRegression(class_weight='balanced', n_jobs=-1))])\n\nmodels = [forest, svc, knn, logistic]\nn_folds = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each model, we will perform a grid search, for the best parameters, and then perform a 5-Fold Cross Validation, shuffling the data for each fold"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"scores = [model_scores(model) for model in tqdm(models)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = [np.mean(score) for score in scores]\nfinal_precision = max(precision)\nprint('Final model accuracy-score: {:.2f}%'.format(final_precision))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}