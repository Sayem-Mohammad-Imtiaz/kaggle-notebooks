{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Table of content","metadata":{"papermill":{"duration":0.032198,"end_time":"2020-09-24T10:28:34.559924","exception":false,"start_time":"2020-09-24T10:28:34.527726","status":"completed"},"tags":[],"id":"vSGBPG7mS2pS"}},{"cell_type":"markdown","source":"1. [Importing relevent libraries](#01)\n\n2. [Loading Dataset](#02)\n\n3. [Distributions](#03)\n    - [Age Distribution](#3.1)\n    - [Ethnicity Distribution](#3.2)\n    - [Gender Distribution](#3.3)\n    - [Sample Images](#3.4)\n\n4. [Helper Functions and Classes](#04)\n    - [For GPU utilization](#4.1)\n    - [For splitting dataset](#4.2)\n    - [For image classification](#4.3)\n    - [For training and validation](#4.4)\n    - [For evaluation metrics](#4.5)\n\n5. [Model for Gender Prediction](#05)\n    - [Create TensorDataset](#5.1)\n    - [Split dataset and create dataloader](#5.2)\n    - [Build and train model](#5.3)\n    - [Evaluating training history](#5.4)\n    - [Performance on test data](#5.5)\n    - [Saving model](#5.6)\n\n6. [Model for Ethnicity Prediction](#06)\n    - [Create TensorDataset](#6.1)\n    - [Split dataset and create dataloader](#6.2)\n    - [Build and train model](#6.3)\n    - [Evaluating training history](#6.4)\n    - [Performance on test data](#6.5)\n    - [Saving model](#6.6)\n\n7. [Model for Age Prediction](#07)\n    - [Create TensorDataset](#7.1)\n    - [Split dataset and create dataloader](#7.2)\n    - [Build and train model](#7.3)\n    - [Evaluating training history](#7.4)\n    - [Performance on test data](#7.5)\n    - [Saving model](#7.6)\n\n8. [Future Work](#08)\n  ","metadata":{"id":"bvGvnPuRoe16"}},{"cell_type":"markdown","source":"## Importing relevent libraries <a id=\"01\"></a>","metadata":{"papermill":{"duration":0.027633,"end_time":"2020-09-24T10:28:34.61626","exception":false,"start_time":"2020-09-24T10:28:34.588627","status":"completed"},"tags":[],"id":"ngykKpO9S2pT"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nimport plotly.figure_factory as ff","metadata":{"id":"6usbk23TqSiV","execution":{"iopub.status.busy":"2021-07-03T19:04:50.268866Z","iopub.execute_input":"2021-07-03T19:04:50.269196Z","iopub.status.idle":"2021-07-03T19:04:50.27451Z","shell.execute_reply.started":"2021-07-03T19:04:50.269166Z","shell.execute_reply":"2021-07-03T19:04:50.273411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Dataset <a id=\"02\"></a>","metadata":{"papermill":{"duration":0.028723,"end_time":"2020-09-24T10:28:42.539261","exception":false,"start_time":"2020-09-24T10:28:42.510538","status":"completed"},"tags":[],"id":"QIP4VzXkS2pU"}},{"cell_type":"code","source":"df = pd.read_csv('../input/age-gender-and-ethnicity-face-data-csv/age_gender.csv')\nethnicity_list = [\"White\", \"Black\", \"Asian\", \"Indian\", \"Hispanic\"]\ngender_list = ['Male', 'Female']\nage_list = ['Baby','Child','Adult','Elderly']\ndf.drop (columns={'img_name'},inplace=True)\ndf.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":23.074222,"end_time":"2020-09-24T10:29:05.641714","exception":false,"start_time":"2020-09-24T10:28:42.567492","status":"completed"},"tags":[],"id":"xgi9A06cS2pU","outputId":"ae27e805-445f-4c7c-bde6-582a8a868faa","execution":{"iopub.status.busy":"2021-07-03T19:04:50.332493Z","iopub.execute_input":"2021-07-03T19:04:50.332735Z","iopub.status.idle":"2021-07-03T19:04:51.779508Z","shell.execute_reply.started":"2021-07-03T19:04:50.332711Z","shell.execute_reply":"2021-07-03T19:04:51.778611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total rows: {}'.format(df.shape[0]))\nprint('Total columns: {}'.format(df.shape[1]))","metadata":{"papermill":{"duration":0.03833,"end_time":"2020-09-24T10:29:05.708238","exception":false,"start_time":"2020-09-24T10:29:05.669908","status":"completed"},"tags":[],"id":"IyIhAKTZS2pV","outputId":"c719176a-291f-4d71-dafa-777cf402a460","execution":{"iopub.status.busy":"2021-07-03T19:04:51.781865Z","iopub.execute_input":"2021-07-03T19:04:51.782267Z","iopub.status.idle":"2021-07-03T19:04:51.787658Z","shell.execute_reply.started":"2021-07-03T19:04:51.782228Z","shell.execute_reply":"2021-07-03T19:04:51.786518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at element from the dataframe. the Pixel column consist of pixel values as strings. In order to apply any deep learning Algorithm we need to first convert these pixel values to a desirable format i.e. each image in dataset to be of the shape `(1, 48, 48)` ","metadata":{"id":"n1tVnkJiymeQ"}},{"cell_type":"code","source":"# Converting pixels into numpy array\ndf['pixels']=df['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\"))\n\n# normalizing pixels data\ndf['pixels'] = df['pixels']/255\n\nX = np.array(df['pixels'].tolist())\nX = X.reshape(-1,1,48,48)\nX.shape","metadata":{"id":"foFdsEfJyuPc","outputId":"55e7385e-c14e-42ab-f4c6-41f600029099","execution":{"iopub.status.busy":"2021-07-03T19:04:51.789535Z","iopub.execute_input":"2021-07-03T19:04:51.789924Z","iopub.status.idle":"2021-07-03T19:05:06.268383Z","shell.execute_reply.started":"2021-07-03T19:04:51.789889Z","shell.execute_reply":"2021-07-03T19:05:06.267538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the code above you can see that the bins are:\n\n- 0 to 2 = ‘Toddler/Baby’\n- 3 to 17 = ‘Child’\n- 18 to 65 = ‘Adult’\n- above 65 =’Elderly’\n","metadata":{"id":"PLDt2PGxKcYo"}},{"cell_type":"code","source":"df['age_bins'] = pd.cut(df['age'],bins=[0,2,17,65,150],labels=range(4))","metadata":{"id":"Kq9PfrQsJLsM","execution":{"iopub.status.busy":"2021-07-03T19:05:06.269712Z","iopub.execute_input":"2021-07-03T19:05:06.270077Z","iopub.status.idle":"2021-07-03T19:05:06.277715Z","shell.execute_reply.started":"2021-07-03T19:05:06.270024Z","shell.execute_reply":"2021-07-03T19:05:06.276988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"ViN9TKpfPrPG","outputId":"9e17f888-1fa6-4aee-bec5-f0b7a96d8917","execution":{"iopub.status.busy":"2021-07-03T19:05:06.281532Z","iopub.execute_input":"2021-07-03T19:05:06.281815Z","iopub.status.idle":"2021-07-03T19:05:06.302264Z","shell.execute_reply.started":"2021-07-03T19:05:06.281781Z","shell.execute_reply":"2021-07-03T19:05:06.301414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distributions <a id=\"03\"></a>","metadata":{"papermill":{"duration":0.037214,"end_time":"2020-09-24T10:29:05.774178","exception":false,"start_time":"2020-09-24T10:29:05.736964","status":"completed"},"tags":[],"id":"-POiZf8OS2pW"}},{"cell_type":"code","source":"# calculating distributions\nage_dist = df['age_bins'].value_counts()\nage_dist.index = age_list\nethnicity_dist = df['ethnicity'].value_counts()\nethnicity_dist.index = ethnicity_list\ngender_dist = df['gender'].value_counts()\ngender_dist.index = gender_list","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.178782,"end_time":"2020-09-24T10:29:05.981305","exception":false,"start_time":"2020-09-24T10:29:05.802523","status":"completed"},"tags":[],"id":"ff_PKPLIS2pX","execution":{"iopub.status.busy":"2021-07-03T19:05:06.305424Z","iopub.execute_input":"2021-07-03T19:05:06.305802Z","iopub.status.idle":"2021-07-03T19:05:06.315422Z","shell.execute_reply.started":"2021-07-03T19:05:06.305764Z","shell.execute_reply":"2021-07-03T19:05:06.314482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Age Distribtion <a id=\"3.1\"></a>","metadata":{"papermill":{"duration":0.029835,"end_time":"2020-09-24T10:29:06.040161","exception":false,"start_time":"2020-09-24T10:29:06.010326","status":"completed"},"tags":[],"id":"eA4P0StVS2pX"}},{"cell_type":"code","source":"px.bar(x=age_dist.index, y=age_dist.values, title='Age Distribution', labels={'x':'age','y':'count'}, width=800, height=400)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.181115,"end_time":"2020-09-24T10:29:06.251089","exception":false,"start_time":"2020-09-24T10:29:06.069974","status":"completed"},"tags":[],"id":"ZWVXh6VVS2pY","outputId":"cbd8e7dd-705e-4090-c4b5-594dc0674603","execution":{"iopub.status.busy":"2021-07-03T19:05:06.316836Z","iopub.execute_input":"2021-07-03T19:05:06.31731Z","iopub.status.idle":"2021-07-03T19:05:06.376161Z","shell.execute_reply.started":"2021-07-03T19:05:06.317275Z","shell.execute_reply":"2021-07-03T19:05:06.375328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ethnicity Distribution <a id=\"3.2\"></a>","metadata":{"papermill":{"duration":0.030047,"end_time":"2020-09-24T10:29:06.311925","exception":false,"start_time":"2020-09-24T10:29:06.281878","status":"completed"},"tags":[],"id":"fpu6j6DLS2pZ"}},{"cell_type":"code","source":"px.bar(x=ethnicity_dist.index, y=ethnicity_dist.values, title='Ethnicity Distribution', labels={'x':'Ethnicity','y':'count'}, width=800, height=400)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.047568,"end_time":"2020-09-24T10:29:06.390757","exception":false,"start_time":"2020-09-24T10:29:06.343189","status":"completed"},"tags":[],"id":"fRne0jrFS2pZ","outputId":"b43a0522-bccd-459e-9c6d-e71bbbf59ac3","execution":{"iopub.status.busy":"2021-07-03T19:05:06.377464Z","iopub.execute_input":"2021-07-03T19:05:06.377804Z","iopub.status.idle":"2021-07-03T19:05:06.433449Z","shell.execute_reply.started":"2021-07-03T19:05:06.377769Z","shell.execute_reply":"2021-07-03T19:05:06.432455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gender Distribution <a id=\"3.3\"></a>","metadata":{"papermill":{"duration":0.030852,"end_time":"2020-09-24T10:29:06.453845","exception":false,"start_time":"2020-09-24T10:29:06.422993","status":"completed"},"tags":[],"id":"MGKMm7ylS2pa"}},{"cell_type":"code","source":"px.bar(x=gender_dist.index, y=gender_dist.values, title='Gender Distribution', labels={'x':'Gender','y':'count'}, width=800, height=400)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.049129,"end_time":"2020-09-24T10:29:06.533952","exception":false,"start_time":"2020-09-24T10:29:06.484823","status":"completed"},"tags":[],"id":"XRFMBkmqS2pa","outputId":"a7def7b6-33fe-48d2-984d-6496b40fe67f","execution":{"iopub.status.busy":"2021-07-03T19:05:06.434738Z","iopub.execute_input":"2021-07-03T19:05:06.435092Z","iopub.status.idle":"2021-07-03T19:05:06.492298Z","shell.execute_reply.started":"2021-07-03T19:05:06.435042Z","shell.execute_reply":"2021-07-03T19:05:06.491525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sample Images <a id=\"3.4\"></a>","metadata":{"id":"7kf5VxlNw_oP"}},{"cell_type":"code","source":"plt.figure(figsize=(14,14))\nfor i in range(3720,3736):\n  plt.subplot(4,4,(i%16)+1)\n  plt.xticks([])\n  plt.yticks([])\n  plt.imshow(X[i].squeeze(),cmap='gray')\n  plt.title(ethnicity_list[df['ethnicity'].iloc[i]] + \" \" + gender_list[df['gender'].iloc[i]] + \" Age:\" + str(df['age'].iloc[i]))\n  ","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.004995,"end_time":"2020-09-24T10:29:07.797839","exception":false,"start_time":"2020-09-24T10:29:06.792844","status":"completed"},"tags":[],"id":"LumCkSJeS2pb","outputId":"25481f2c-4d5f-4e1a-ad5d-32f1479df0fe","execution":{"iopub.status.busy":"2021-07-03T19:05:06.493442Z","iopub.execute_input":"2021-07-03T19:05:06.493751Z","iopub.status.idle":"2021-07-03T19:05:07.103422Z","shell.execute_reply.started":"2021-07-03T19:05:06.493716Z","shell.execute_reply":"2021-07-03T19:05:07.102355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions and Classes <a id=\"04\"></a>","metadata":{"id":"s4rSwknBC_BL"}},{"cell_type":"markdown","source":"### For GPU utilization <a id=\"4.1\"></a>\n","metadata":{"id":"LYTsvNGslXxY"}},{"cell_type":"markdown","source":"To seamlessly use a GPU, if one is available, we define a couple of helper functions (get_default_device & to_device) and a helper class DeviceDataLoader to move our model & data to the GPU as required.","metadata":{"id":"QLSuONsJDsof"}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n","metadata":{"id":"BC6eIu-ClTxL","execution":{"iopub.status.busy":"2021-07-03T19:05:07.104828Z","iopub.execute_input":"2021-07-03T19:05:07.105194Z","iopub.status.idle":"2021-07-03T19:05:07.115613Z","shell.execute_reply.started":"2021-07-03T19:05:07.105156Z","shell.execute_reply":"2021-07-03T19:05:07.114786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on where you're running this notebook, your default device could be a CPU (torch.device('cpu')) or a GPU (torch.device('cuda'))","metadata":{"id":"4qEGSurZl3eh"}},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"id":"x50X3a7nl4-6","outputId":"6978eb62-93e3-4ff2-fc38-ce0c076e45f5","execution":{"iopub.status.busy":"2021-07-03T19:05:07.117015Z","iopub.execute_input":"2021-07-03T19:05:07.117397Z","iopub.status.idle":"2021-07-03T19:05:07.12723Z","shell.execute_reply.started":"2021-07-03T19:05:07.11736Z","shell.execute_reply":"2021-07-03T19:05:07.126305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For splitting dataset <a id=\"4.2\"></a>\n","metadata":{"id":"QxuW5ucGJp_J"}},{"cell_type":"markdown","source":"While building real world machine learning models, it is quite common to split the dataset into 3 parts:\n\n1. **Training set** - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n2. **Validation set** - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n3. **Test set** - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.","metadata":{"id":"AkAY2TawDoyZ"}},{"cell_type":"code","source":"random_seed = 42\ntorch.manual_seed(random_seed)\ndef train_validation_test(dataset, val_size: int = 0, test_size: int = 0):\n  train_size = len(dataset) - val_size - test_size \n  if (test_size == 0 or val_size == 0 ):\n    return random_split(dataset, [train_size, (val_size + test_size)])\n  else:\n    return random_split(dataset, [train_size, val_size, test_size])","metadata":{"id":"yy5ekvZOJp_L","execution":{"iopub.status.busy":"2021-07-03T19:05:07.12901Z","iopub.execute_input":"2021-07-03T19:05:07.129287Z","iopub.status.idle":"2021-07-03T19:05:07.137236Z","shell.execute_reply.started":"2021-07-03T19:05:07.129257Z","shell.execute_reply":"2021-07-03T19:05:07.136486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For image classification <a id=\"4.3\"></a>","metadata":{"id":"VkLhMsRZwF8u"}},{"cell_type":"code","source":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"id":"WgbZ6gLOJp_Q","execution":{"iopub.status.busy":"2021-07-03T19:05:07.138763Z","iopub.execute_input":"2021-07-03T19:05:07.139189Z","iopub.status.idle":"2021-07-03T19:05:07.150374Z","shell.execute_reply.started":"2021-07-03T19:05:07.139155Z","shell.execute_reply":"2021-07-03T19:05:07.149135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For training and validation <a id=\"4.4\"></a>","metadata":{"id":"2H5iUK7fxY0h"}},{"cell_type":"markdown","source":"We'll define two functions: `fit` and `evaluate` to train the model using gradient descent and evaluate its performance on the validation set.","metadata":{"id":"rrOyxcVixeSR"}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history\n\ndef plot_accuracies(history):\n  accuracies = [x['val_acc'] for x in history]\n  fig = px.line(x = range(len(accuracies)), y = accuracies, title='Accuracy vs. No. of epochs', labels={'x': 'Epoch', 'y':'Accuracy'},width=800, height=400)\n  fig.show()\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x = list(range(len(train_losses))), y = train_losses,\n                        mode='lines+markers',\n                        name='Training'))\n    fig.add_trace(go.Scatter(x = list(range(len(val_losses))), y = val_losses,\n                        mode='lines+markers',\n                        name='Validation'))\n    fig.update_layout(title='Loss vs. No. of epochs',\n                   xaxis_title='Epoch',\n                   yaxis_title='Loss', width=800, height=400)\n    fig.show()\n\n# Helper function which returns the predicted label for a single image tensor\ndef predict_label(img, model, label_classes):\n  # Convert to a batch of 1\n  xb = to_device(img.unsqueeze(0), device)\n  # Get predictions from model\n  yb = model(xb)\n  # Pick index with highest probability\n  _, preds  = torch.max(yb, dim=1)\n  # Retrieve the class label\n  if label_classes:\n    return label_classes[preds[0].item()]\n  else: \n    return preds[0].item()\n","metadata":{"id":"WeAn1C1fxeSR","execution":{"iopub.status.busy":"2021-07-03T19:05:07.151753Z","iopub.execute_input":"2021-07-03T19:05:07.152223Z","iopub.status.idle":"2021-07-03T19:05:07.167633Z","shell.execute_reply.started":"2021-07-03T19:05:07.152188Z","shell.execute_reply":"2021-07-03T19:05:07.166621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For evaluation metrics <a id=\"4.5\"></a>","metadata":{"id":"H8jaDnWTxYwh"}},{"cell_type":"code","source":"def draw_confusion_matrix(class_labels,model, batch_loader):\n  nb_classes = len(class_labels)\n\n  confusion_matrix = torch.zeros(nb_classes, nb_classes)\n  with torch.no_grad():\n      for (images, classes) in batch_loader:\n        outputs = model(images)\n        _, preds = torch.max(outputs, dim=1)\n        for t, p in zip(classes.view(-1), preds.view(-1)):\n          confusion_matrix[t.long(), p.long()] += 1\n\n\n  # set up figure \n  fig = ff.create_annotated_heatmap(confusion_matrix.tolist(), x=class_labels, y=class_labels, colorscale='Viridis')\n\n\n  # add custom xaxis title\n  fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                          x=0.5,\n                          y=-0.15,\n                          showarrow=False,\n                          text=\"Predicted value\",\n                          xref=\"paper\",\n                          yref=\"paper\"))\n\n  # add custom yaxis title\n  fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                          x=-0.15,\n                          y=0.5,\n                          showarrow=False,\n                          text=\"Real value\",\n                          textangle=-90,\n                          xref=\"paper\",\n                          yref=\"paper\"))\n\n  # adjust margins to make room for yaxis title\n  fig.update_layout(margin=dict(t=50, l=200))\n\n  # add colorbar\n  fig['data'][0]['showscale'] = True\n  fig.show()","metadata":{"id":"Z70Mex-PsINL","execution":{"iopub.status.busy":"2021-07-03T19:05:07.168919Z","iopub.execute_input":"2021-07-03T19:05:07.169379Z","iopub.status.idle":"2021-07-03T19:05:07.180973Z","shell.execute_reply.started":"2021-07-03T19:05:07.169342Z","shell.execute_reply":"2021-07-03T19:05:07.179801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\n\ndef get_metrics(batch_loader, model, average_setting = 'binary'):\n  preds=[];truth=[]\n  with torch.no_grad():\n      for (images, classes) in batch_loader:\n        outputs = model(images)\n        _, pred = torch.max(outputs, dim=1)\n        preds = preds + pred.cpu().tolist()\n        truth = truth + classes.cpu().tolist()\n  print('F1: {}'.format(f1_score(truth, preds,average=average_setting)))\n  print('Precision: {}'.format(precision_score(truth, preds, average=average_setting)))\n  print('Recall: {}'.format(recall_score(truth, preds, average=average_setting)))","metadata":{"id":"0JKVNvq0xRhz","execution":{"iopub.status.busy":"2021-07-03T19:05:07.182234Z","iopub.execute_input":"2021-07-03T19:05:07.182681Z","iopub.status.idle":"2021-07-03T19:05:07.192219Z","shell.execute_reply.started":"2021-07-03T19:05:07.182646Z","shell.execute_reply":"2021-07-03T19:05:07.191432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model for Gender Prediction <a id=\"05\"></a>","metadata":{"id":"1E5OWlGOhfPz"}},{"cell_type":"markdown","source":"### Create TensorDataset <a id=\"5.1\"></a>","metadata":{"papermill":{"duration":0.037719,"end_time":"2020-09-24T10:29:07.947886","exception":false,"start_time":"2020-09-24T10:29:07.910167","status":"completed"},"tags":[],"id":"jvW7MfRTS2pc"}},{"cell_type":"code","source":"X_tensor = torch.from_numpy(X)\ny = torch.from_numpy(np.array(df['gender']))\ndataset = TensorDataset(X_tensor,y)","metadata":{"id":"3KFi4Ww4kk8J","execution":{"iopub.status.busy":"2021-07-03T19:05:07.193828Z","iopub.execute_input":"2021-07-03T19:05:07.194138Z","iopub.status.idle":"2021-07-03T19:05:07.204669Z","shell.execute_reply.started":"2021-07-03T19:05:07.19411Z","shell.execute_reply":"2021-07-03T19:05:07.203854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numeric label for each element corresponds to index of the element's label in the list of classes.","metadata":{"id":"KylRsYg2Jp_F"}},{"cell_type":"code","source":"dataset.classes = gender_list\nprint(dataset.classes)","metadata":{"id":"O-XOdz6KJp_G","outputId":"b912ac24-e649-4a93-ce39-70b14b4b01fe","execution":{"iopub.status.busy":"2021-07-03T19:05:07.206508Z","iopub.execute_input":"2021-07-03T19:05:07.20767Z","iopub.status.idle":"2021-07-03T19:05:07.21566Z","shell.execute_reply.started":"2021-07-03T19:05:07.207632Z","shell.execute_reply":"2021-07-03T19:05:07.214915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split dataset and create dataloader <a id=\"5.2\"></a>","metadata":{"papermill":{"duration":0.037719,"end_time":"2020-09-24T10:29:07.947886","exception":false,"start_time":"2020-09-24T10:29:07.910167","status":"completed"},"tags":[],"id":"ZGivED545w4r"}},{"cell_type":"code","source":"# split dataset train/validation/test\ntrain_ds, val_ds, test_ds = train_validation_test(dataset=dataset,val_size=2500,test_size=1000)\n\nbatch_size=128\n# create batchs using dataloader\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)","metadata":{"id":"lWXX_hHGJp_M","execution":{"iopub.status.busy":"2021-07-03T19:05:07.217171Z","iopub.execute_input":"2021-07-03T19:05:07.217643Z","iopub.status.idle":"2021-07-03T19:05:07.226351Z","shell.execute_reply.started":"2021-07-03T19:05:07.217482Z","shell.execute_reply":"2021-07-03T19:05:07.225517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build and train model <a id=\"5.3\"></a>","metadata":{"papermill":{"duration":0.037718,"end_time":"2020-09-24T10:29:08.163085","exception":false,"start_time":"2020-09-24T10:29:08.125367","status":"completed"},"tags":[],"id":"kC-jwJycS2pd"}},{"cell_type":"code","source":"class GenderModel(ImageClassificationBase):\n  def __init__(self):\n    super().__init__()\n    self.network = nn.Sequential(\n        # 1st Convolution Layer\n        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),      # 1 x 48 x 48 -> 16 x 48 x 48\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),                                              # 16 x 48 x 48 -> 16 x 24 x 24\n        nn.BatchNorm2d(16),\n        nn.Dropout(0.2),\n\n        # 2nd Convolution Layer\n        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),                # 16 x 24 x 24 -> 32 x 22 x 22\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),                                              # 16 x 24 x 24 -> 32 x 22 x 22\n        nn.BatchNorm2d(32),\n        nn.Dropout(0.2),\n\n        # 3rd Convolution Layer\n        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(64),\n        nn.Dropout(0.2),\n\n         # 4th Convolution Layer\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(128),\n        nn.Dropout(0.2),\n\n        # fully connected layer\n        nn.Flatten(),\n        nn.Linear(128 * 1 * 1,128),\n        nn.Dropout(0.5),\n        nn.Linear(128,256),\n        nn.Dropout(0.5),\n        nn.Linear(256,2)\n    )\n  def forward(self, images):\n    return self.network(images)","metadata":{"id":"F4xrvghlJp_Q","execution":{"iopub.status.busy":"2021-07-03T19:05:07.228001Z","iopub.execute_input":"2021-07-03T19:05:07.228349Z","iopub.status.idle":"2021-07-03T19:05:07.240359Z","shell.execute_reply.started":"2021-07-03T19:05:07.228314Z","shell.execute_reply":"2021-07-03T19:05:07.239475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now wrap our training and validation data loaders using `DeviceDataLoader` for automatically transferring batches of data to the GPU (if available), and use `to_device` to move our model to the GPU (if available).","metadata":{"id":"zdlOEla3Jp_R"}},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nmodel = to_device(GenderModel(), device)","metadata":{"id":"vx3BnG8IJp_R","execution":{"iopub.status.busy":"2021-07-03T19:05:07.241422Z","iopub.execute_input":"2021-07-03T19:05:07.241957Z","iopub.status.idle":"2021-07-03T19:05:07.255005Z","shell.execute_reply.started":"2021-07-03T19:05:07.24192Z","shell.execute_reply":"2021-07-03T19:05:07.254017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we begin training, let's instantiate the model once again and see how it performs on the validation set with the initial set of parameters.","metadata":{"id":"mGbR0ClAJp_S"}},{"cell_type":"code","source":"history = evaluate(model, val_dl)\nprint(\"Untrained Accuracy: \", history['val_acc'])\nprint(\"Untrained Loss: \", history['val_loss'])","metadata":{"id":"rWO9y9TrJp_S","outputId":"c11ba4df-694d-4f8c-a7b8-b85f103c2396","execution":{"iopub.status.busy":"2021-07-03T19:05:07.256227Z","iopub.execute_input":"2021-07-03T19:05:07.256565Z","iopub.status.idle":"2021-07-03T19:05:07.436662Z","shell.execute_reply.started":"2021-07-03T19:05:07.256531Z","shell.execute_reply":"2021-07-03T19:05:07.43575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The initial accuracy is around 50%, which is what one might expect from a randomly intialized model (since it has a 1 in 2 chance of getting a label right by guessing randomly).\n\nWe'll use the following *hyperparmeters* (learning rate, no. of epochs, batch_size etc.) to train our model.","metadata":{"id":"WEuauDpwJp_S"}},{"cell_type":"code","source":"num_epochs = 15\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"id":"HdSA8RWDJp_S","execution":{"iopub.status.busy":"2021-07-03T19:05:07.439707Z","iopub.execute_input":"2021-07-03T19:05:07.439966Z","iopub.status.idle":"2021-07-03T19:05:07.446335Z","shell.execute_reply.started":"2021-07-03T19:05:07.439939Z","shell.execute_reply":"2021-07-03T19:05:07.445502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","metadata":{"id":"vZK4Y2XrJp_T","outputId":"624d3ff7-87d7-4b27-850e-4d138ee799d7","execution":{"iopub.status.busy":"2021-07-03T19:05:07.449397Z","iopub.execute_input":"2021-07-03T19:05:07.449646Z","iopub.status.idle":"2021-07-03T19:05:33.337218Z","shell.execute_reply.started":"2021-07-03T19:05:07.449613Z","shell.execute_reply":"2021-07-03T19:05:33.335791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating training history <a id=\"5.4\"></a>","metadata":{"id":"IsIFWYVJAqdK"}},{"cell_type":"markdown","source":"We can also plot the valdation set accuracies to study how the model improves over time.","metadata":{"id":"55K2kRe6Jp_T"}},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"id":"KYgnxqQQJp_T","outputId":"646a4ea7-f9dc-4656-d4ea-b1a8c839266b","execution":{"iopub.status.busy":"2021-07-03T19:05:33.339684Z","iopub.execute_input":"2021-07-03T19:05:33.339951Z","iopub.status.idle":"2021-07-03T19:05:33.401931Z","shell.execute_reply.started":"2021-07-03T19:05:33.339923Z","shell.execute_reply":"2021-07-03T19:05:33.401135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also plot the training and validation losses to study the trend.","metadata":{"id":"dPmvnBsaJp_T"}},{"cell_type":"code","source":"plot_losses(history)","metadata":{"id":"KBpeN5YhJp_U","outputId":"d07c24ce-41b5-40b1-e31f-2dd194f5e62b","execution":{"iopub.status.busy":"2021-07-03T19:05:33.40355Z","iopub.execute_input":"2021-07-03T19:05:33.403887Z","iopub.status.idle":"2021-07-03T19:05:33.417835Z","shell.execute_reply.started":"2021-07-03T19:05:33.403851Z","shell.execute_reply":"2021-07-03T19:05:33.416724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_metrics(train_dl,model)","metadata":{"id":"pAOe3POHxtTv","outputId":"10558dda-fe5d-4125-fb52-05a49b477377","execution":{"iopub.status.busy":"2021-07-03T19:05:33.41944Z","iopub.execute_input":"2021-07-03T19:05:33.419883Z","iopub.status.idle":"2021-07-03T19:05:34.449517Z","shell.execute_reply.started":"2021-07-03T19:05:33.419845Z","shell.execute_reply":"2021-07-03T19:05:34.448552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance on Test Data <a id=\"5.5\"></a>","metadata":{"id":"IqN4ozY6Jp_U"}},{"cell_type":"markdown","source":"While we have been tracking the overall accuracy of a model so far, it's also a good idea to look at model's results on some sample images. Let's test out our model with some images from the predefined test dataset.","metadata":{"id":"OeMTcmCg0qjQ"}},{"cell_type":"code","source":"index=np.random.randint(0,712,25) # predicted label and their images\n\nplt.figure(figsize=(16,16))\n\nfor i in range(len(index)):\n    plt.subplot(5,5,(i%25)+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(test_ds[index[i]][0].squeeze())\n    plt.xlabel(\"Predicted :\" + predict_label(test_ds[index[i]][0],model,dataset.classes) \n    )\n    \nplt.show()","metadata":{"id":"C_fkqvIDJp_V","outputId":"57dcfe4d-30d7-4e1d-9561-42ffc94e982e","execution":{"iopub.status.busy":"2021-07-03T19:05:34.451012Z","iopub.execute_input":"2021-07-03T19:05:34.451296Z","iopub.status.idle":"2021-07-03T19:05:35.685045Z","shell.execute_reply.started":"2021-07-03T19:05:34.451268Z","shell.execute_reply":"2021-07-03T19:05:35.684335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a final step, let's also look at the overall loss and accuracy of the model on the test set. We expect these values to be similar to those for the validation set. If not, we might need a better validation set that has similar data and distribution as the test set (which often comes from real world data).","metadata":{"id":"yqZv8qKPJp_V"}},{"cell_type":"code","source":"test_dl = DeviceDataLoader(DataLoader(test_ds, batch_size*2), device)\nresult = evaluate(model, test_dl)\nprint(\"Test Accuracy: \",result['val_acc'])\nprint(\"Test Loss: \",result['val_loss'])\nget_metrics(test_dl,model)","metadata":{"id":"-1hjzFhUJp_V","outputId":"1cf936ec-774e-4e19-9da2-a72238221a65","execution":{"iopub.status.busy":"2021-07-03T19:05:35.686482Z","iopub.execute_input":"2021-07-03T19:05:35.68682Z","iopub.status.idle":"2021-07-03T19:05:35.753037Z","shell.execute_reply.started":"2021-07-03T19:05:35.686782Z","shell.execute_reply":"2021-07-03T19:05:35.752193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_confusion_matrix(gender_list,model,test_dl)","metadata":{"id":"GOKMzGg1n1W1","outputId":"530933cb-4d4a-4f37-de60-bf580e62f290","execution":{"iopub.status.busy":"2021-07-03T19:05:35.754657Z","iopub.execute_input":"2021-07-03T19:05:35.755024Z","iopub.status.idle":"2021-07-03T19:05:35.869833Z","shell.execute_reply.started":"2021-07-03T19:05:35.754975Z","shell.execute_reply":"2021-07-03T19:05:35.869008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving model <a id=\"5.6\"></a>","metadata":{"id":"Smk8znXkJp_W"}},{"cell_type":"markdown","source":"Since we've trained our model for a long time and achieved a resonable accuracy, it would be a good idea to save the weights of the model to disk, so that we can reuse the model later and avoid retraining from scratch.","metadata":{"id":"jT572grIHvIe"}},{"cell_type":"code","source":"folder_path = './'\nmodel_pth = 'GenderModel1.pth'","metadata":{"id":"WLLm-pIyJp_W","execution":{"iopub.status.busy":"2021-07-03T19:05:35.876375Z","iopub.execute_input":"2021-07-03T19:05:35.87662Z","iopub.status.idle":"2021-07-03T19:05:35.880597Z","shell.execute_reply.started":"2021-07-03T19:05:35.876595Z","shell.execute_reply":"2021-07-03T19:05:35.87961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), folder_path + model_pth)","metadata":{"id":"XInEP8odqMx0","execution":{"iopub.status.busy":"2021-07-03T19:05:35.882267Z","iopub.execute_input":"2021-07-03T19:05:35.882859Z","iopub.status.idle":"2021-07-03T19:05:35.894246Z","shell.execute_reply.started":"2021-07-03T19:05:35.882821Z","shell.execute_reply":"2021-07-03T19:05:35.893544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `.state_dict` method returns an `OrderedDict` containing all the weights and bias matrices mapped to the right attributes of the model. To load the model weights, we can redefine the model with the same structure, and use the `.load_state_dict` method.","metadata":{"id":"WsxZJi5fJp_W"}},{"cell_type":"code","source":"model2 = to_device(GenderModel(), device)","metadata":{"id":"Mb9KOT7GJp_W","execution":{"iopub.status.busy":"2021-07-03T19:05:35.897453Z","iopub.execute_input":"2021-07-03T19:05:35.897726Z","iopub.status.idle":"2021-07-03T19:05:35.907835Z","shell.execute_reply.started":"2021-07-03T19:05:35.897692Z","shell.execute_reply":"2021-07-03T19:05:35.906876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.load_state_dict(torch.load(folder_path+ model_pth,map_location=torch.device('cpu')))\nresult = evaluate(model2, test_dl)\nprint(\"Test Accuracy: \",result['val_acc'])\nprint(\"Test Loss: \",result['val_loss'])","metadata":{"id":"TFCWPlalJp_W","outputId":"fb1832d3-3a6e-4f58-85cf-01f98331fa61","execution":{"iopub.status.busy":"2021-07-03T19:05:35.909822Z","iopub.execute_input":"2021-07-03T19:05:35.910449Z","iopub.status.idle":"2021-07-03T19:05:35.943957Z","shell.execute_reply.started":"2021-07-03T19:05:35.910413Z","shell.execute_reply":"2021-07-03T19:05:35.943167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model for Ethnicity Prediction <a id=\"06\"></a>","metadata":{"id":"CVYYQzTBIDjc"}},{"cell_type":"markdown","source":"### Create TensorDataset <a id=\"6.1\"></a>","metadata":{"papermill":{"duration":0.037719,"end_time":"2020-09-24T10:29:07.947886","exception":false,"start_time":"2020-09-24T10:29:07.910167","status":"completed"},"tags":[],"id":"d2P9buJLIDjc"}},{"cell_type":"code","source":"X_tensor = torch.from_numpy(X)\ny = torch.from_numpy(np.array(df['ethnicity']))\ndataset = TensorDataset(X_tensor,y)","metadata":{"id":"OOsXOwWaIDjc","execution":{"iopub.status.busy":"2021-07-03T19:05:35.945502Z","iopub.execute_input":"2021-07-03T19:05:35.945842Z","iopub.status.idle":"2021-07-03T19:05:35.951143Z","shell.execute_reply.started":"2021-07-03T19:05:35.945808Z","shell.execute_reply":"2021-07-03T19:05:35.950113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numeric label for each element corresponds to index of the element's label in the list of classes.","metadata":{"id":"AJ9-8e-4IDjc"}},{"cell_type":"code","source":"dataset.classes = ethnicity_list\nprint(dataset.classes)","metadata":{"id":"-g8kjOr9IDjd","outputId":"91683b85-0433-456f-f420-d632f0fb7cfc","execution":{"iopub.status.busy":"2021-07-03T19:05:35.952842Z","iopub.execute_input":"2021-07-03T19:05:35.953329Z","iopub.status.idle":"2021-07-03T19:05:35.961216Z","shell.execute_reply.started":"2021-07-03T19:05:35.953294Z","shell.execute_reply":"2021-07-03T19:05:35.96023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split dataset and create dataloader <a id=\"6.2\"></a>","metadata":{"papermill":{"duration":0.037719,"end_time":"2020-09-24T10:29:07.947886","exception":false,"start_time":"2020-09-24T10:29:07.910167","status":"completed"},"tags":[],"id":"SrNOhIVsIDjd"}},{"cell_type":"code","source":"# split dataset train/validation/test\ntrain_ds, val_ds, test_ds = train_validation_test(dataset=dataset,val_size=2500,test_size=1000)\n\nbatch_size=128\n# create batchs using dataloader\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)","metadata":{"id":"CTHZX-HeIDje","execution":{"iopub.status.busy":"2021-07-03T19:05:35.962813Z","iopub.execute_input":"2021-07-03T19:05:35.963404Z","iopub.status.idle":"2021-07-03T19:05:35.972358Z","shell.execute_reply.started":"2021-07-03T19:05:35.963238Z","shell.execute_reply":"2021-07-03T19:05:35.971471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build and train model <a id=\"6.3\"></a>","metadata":{"papermill":{"duration":0.037718,"end_time":"2020-09-24T10:29:08.163085","exception":false,"start_time":"2020-09-24T10:29:08.125367","status":"completed"},"tags":[],"id":"6k4CqVCLIDje"}},{"cell_type":"code","source":"class EthnicityModel(ImageClassificationBase):\n  def __init__(self):\n    super().__init__()\n    self.network = nn.Sequential(\n        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(16),\n        nn.Dropout(0.2),\n\n        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(32),\n        nn.Dropout(0.2),\n\n        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(64),\n        nn.Dropout(0.2),\n\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(128),\n        nn.Dropout(0.2),\n\n        nn.Flatten(),\n        nn.Linear(128 * 1 * 1,128),\n        nn.Dropout(0.5),\n        nn.Linear(128,256),\n        nn.Dropout(0.5),\n        nn.Linear(256,5)\n    )\n  def forward(self, images):\n    return self.network(images)","metadata":{"id":"zn9CcvgRIDje","execution":{"iopub.status.busy":"2021-07-03T19:05:35.973818Z","iopub.execute_input":"2021-07-03T19:05:35.974321Z","iopub.status.idle":"2021-07-03T19:05:35.984898Z","shell.execute_reply.started":"2021-07-03T19:05:35.974284Z","shell.execute_reply":"2021-07-03T19:05:35.984091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now wrap our training and validation data loaders using `DeviceDataLoader` for automatically transferring batches of data to the GPU (if available), and use `to_device` to move our model to the GPU (if available).","metadata":{"id":"fLdx9FXLIDjf"}},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nmodel = to_device(EthnicityModel(), device)\nmodel","metadata":{"id":"OHrrxbnfIDjf","outputId":"61e50eb0-0c01-406b-d9fd-2ba456a5a94c","execution":{"iopub.status.busy":"2021-07-03T19:05:35.986346Z","iopub.execute_input":"2021-07-03T19:05:35.986835Z","iopub.status.idle":"2021-07-03T19:05:36.002985Z","shell.execute_reply.started":"2021-07-03T19:05:35.986798Z","shell.execute_reply":"2021-07-03T19:05:36.00201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we begin training, let's instantiate the model once again and see how it performs on the validation set with the initial set of parameters.","metadata":{"id":"zS6KCoaRIDjf"}},{"cell_type":"code","source":"history = evaluate(model, val_dl)\nprint(\"Untrained Accuracy: \", history['val_acc'])\nprint(\"Untrained Loss: \", history['val_loss'])","metadata":{"id":"TlifcDmbIDjf","outputId":"0bc45c14-8767-47e3-8e5d-a22a5295a897","execution":{"iopub.status.busy":"2021-07-03T19:05:36.004473Z","iopub.execute_input":"2021-07-03T19:05:36.004816Z","iopub.status.idle":"2021-07-03T19:05:36.18943Z","shell.execute_reply.started":"2021-07-03T19:05:36.004781Z","shell.execute_reply":"2021-07-03T19:05:36.188625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The initial accuracy is around 10%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n\nWe'll use the following *hyperparmeters* (learning rate, no. of epochs, batch_size etc.) to train our model.","metadata":{"id":"qMajSuQ9IDjf"}},{"cell_type":"code","source":"num_epochs = 20\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"id":"iDrxoNT8IDjf","execution":{"iopub.status.busy":"2021-07-03T19:05:36.192741Z","iopub.execute_input":"2021-07-03T19:05:36.193021Z","iopub.status.idle":"2021-07-03T19:05:36.199283Z","shell.execute_reply.started":"2021-07-03T19:05:36.192987Z","shell.execute_reply":"2021-07-03T19:05:36.198459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","metadata":{"id":"8YNV38eIIDjg","outputId":"966a882e-c3c8-49ab-859b-4d2e07f4d199","execution":{"iopub.status.busy":"2021-07-03T19:05:36.202471Z","iopub.execute_input":"2021-07-03T19:05:36.202719Z","iopub.status.idle":"2021-07-03T19:06:11.251803Z","shell.execute_reply.started":"2021-07-03T19:05:36.202695Z","shell.execute_reply":"2021-07-03T19:06:11.250762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating training history <a id=\"6.4\"></a>","metadata":{"id":"xXsPsI4EIDjg"}},{"cell_type":"markdown","source":"We can also plot the valdation set accuracies to study how the model improves over time.","metadata":{"id":"7mV3TlApIDjg"}},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"id":"Ik7ziUK9IDjg","outputId":"d5c89c86-43fa-4840-8610-bdd971afa141","execution":{"iopub.status.busy":"2021-07-03T19:06:11.254963Z","iopub.execute_input":"2021-07-03T19:06:11.255249Z","iopub.status.idle":"2021-07-03T19:06:11.314853Z","shell.execute_reply.started":"2021-07-03T19:06:11.255221Z","shell.execute_reply":"2021-07-03T19:06:11.314063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also plot the training and validation losses to study the trend.","metadata":{"id":"7sHykNmrIDjg"}},{"cell_type":"code","source":"plot_losses(history)","metadata":{"id":"G8JGEOQsIDjg","outputId":"78be1c63-4781-4d39-d25c-b0bf492ade79","execution":{"iopub.status.busy":"2021-07-03T19:06:11.316481Z","iopub.execute_input":"2021-07-03T19:06:11.316898Z","iopub.status.idle":"2021-07-03T19:06:11.330357Z","shell.execute_reply.started":"2021-07-03T19:06:11.316859Z","shell.execute_reply":"2021-07-03T19:06:11.329485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_metrics(train_dl,model, average_setting='weighted')","metadata":{"id":"Zf7YybxVyXw2","outputId":"24adffca-002d-4a74-c129-39f592d065a5","execution":{"iopub.status.busy":"2021-07-03T19:06:11.331566Z","iopub.execute_input":"2021-07-03T19:06:11.33208Z","iopub.status.idle":"2021-07-03T19:06:12.250296Z","shell.execute_reply.started":"2021-07-03T19:06:11.332028Z","shell.execute_reply":"2021-07-03T19:06:12.249208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance on Test Data <a id=\"6.5\"></a>","metadata":{"id":"azO0d2a2IDjh"}},{"cell_type":"markdown","source":"While we have been tracking the overall accuracy of a model so far, it's also a good idea to look at model's results on some sample images. Let's test out our model with some images from the predefined test dataset.","metadata":{"id":"ryV_HAvwIDjh"}},{"cell_type":"code","source":"index=np.random.randint(0,712,25) # predicted label and their images\n\nplt.figure(figsize=(16,16))\n\nfor i in range(len(index)):\n    plt.subplot(5,5,(i%25)+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(test_ds[index[i]][0].squeeze())\n    plt.xlabel(\"Predicted :\" + predict_label(test_ds[index[i]][0],model,dataset.classes) \n    )\n    \nplt.show()","metadata":{"id":"9QWUigQTIDjh","outputId":"e2add2bf-14e3-45fa-9064-305a2e4cf410","execution":{"iopub.status.busy":"2021-07-03T19:06:12.251841Z","iopub.execute_input":"2021-07-03T19:06:12.252379Z","iopub.status.idle":"2021-07-03T19:06:13.298163Z","shell.execute_reply.started":"2021-07-03T19:06:12.252336Z","shell.execute_reply":"2021-07-03T19:06:13.297336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a final step, let's also look at the overall loss and accuracy of the model on the test set. We expect these values to be similar to those for the validation set. If not, we might need a better validation set that has similar data and distribution as the test set (which often comes from real world data).","metadata":{"id":"tytvwFBdIDjh"}},{"cell_type":"code","source":"test_dl = DeviceDataLoader(DataLoader(test_ds, batch_size*2), device)\nresult = evaluate(model, test_dl)\nprint(\"Test Accuracy: \",result['val_acc'])\nprint(\"Test Loss: \",result['val_loss'])\nget_metrics(test_dl,model,'weighted')","metadata":{"id":"X07135RZIDjh","outputId":"5852ad2c-59d9-4d86-9ae1-34a909426ae3","execution":{"iopub.status.busy":"2021-07-03T19:06:13.299503Z","iopub.execute_input":"2021-07-03T19:06:13.300005Z","iopub.status.idle":"2021-07-03T19:06:13.365929Z","shell.execute_reply.started":"2021-07-03T19:06:13.299963Z","shell.execute_reply":"2021-07-03T19:06:13.36508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_confusion_matrix(ethnicity_list,model,test_dl)","metadata":{"id":"uBpISMIUr1GJ","outputId":"be0734b8-8c55-42bc-9bbb-70bf24fefaf4","execution":{"iopub.status.busy":"2021-07-03T19:06:13.367625Z","iopub.execute_input":"2021-07-03T19:06:13.36798Z","iopub.status.idle":"2021-07-03T19:06:13.504122Z","shell.execute_reply.started":"2021-07-03T19:06:13.367942Z","shell.execute_reply":"2021-07-03T19:06:13.503313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving model <a id=\"6.6\"></a>","metadata":{"id":"jIf2KrBqIDjh"}},{"cell_type":"markdown","source":"Since we've trained our model for a long time and achieved a resonable accuracy, it would be a good idea to save the weights of the model to disk, so that we can reuse the model later and avoid retraining from scratch.","metadata":{"id":"GCxxA6lLIDji"}},{"cell_type":"code","source":"folder_path = './'\nmodel_pth = 'EthnicityModel1.pth'\ntorch.save(model.state_dict(), folder_path + model_pth)","metadata":{"id":"jZDIMozlIDji","execution":{"iopub.status.busy":"2021-07-03T19:06:13.505644Z","iopub.execute_input":"2021-07-03T19:06:13.505976Z","iopub.status.idle":"2021-07-03T19:06:13.516224Z","shell.execute_reply.started":"2021-07-03T19:06:13.50594Z","shell.execute_reply":"2021-07-03T19:06:13.515351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `.state_dict` method returns an `OrderedDict` containing all the weights and bias matrices mapped to the right attributes of the model. To load the model weights, we can redefine the model with the same structure, and use the `.load_state_dict` method.","metadata":{"id":"X_ijXsBbIDji"}},{"cell_type":"code","source":" model2 = to_device(EthnicityModel(), device)","metadata":{"id":"l2myWPkEIDji","execution":{"iopub.status.busy":"2021-07-03T19:06:13.517737Z","iopub.execute_input":"2021-07-03T19:06:13.518338Z","iopub.status.idle":"2021-07-03T19:06:13.528577Z","shell.execute_reply.started":"2021-07-03T19:06:13.5183Z","shell.execute_reply":"2021-07-03T19:06:13.527729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.load_state_dict(torch.load(folder_path+ model_pth))\nresult = evaluate(model2, test_dl)\nprint(\"Test Accuracy: \",result['val_acc'])\nprint(\"Test Loss: \",result['val_loss'])","metadata":{"id":"K_X5HHwUIDji","outputId":"b8b4fb0a-186b-4787-b86d-475aa28bd03d","execution":{"iopub.status.busy":"2021-07-03T19:06:13.530114Z","iopub.execute_input":"2021-07-03T19:06:13.530489Z","iopub.status.idle":"2021-07-03T19:06:13.566786Z","shell.execute_reply.started":"2021-07-03T19:06:13.530452Z","shell.execute_reply":"2021-07-03T19:06:13.565971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model for Age Prediction <a id=\"07\"></a>","metadata":{"id":"ADthTB4Vl3hh"}},{"cell_type":"markdown","source":"### Create TensorDataset <a id=\"7.1\"></a>","metadata":{"papermill":{"duration":0.037719,"end_time":"2020-09-24T10:29:07.947886","exception":false,"start_time":"2020-09-24T10:29:07.910167","status":"completed"},"tags":[],"id":"tBw7ncbKIMIR"}},{"cell_type":"code","source":"X_tensor = torch.from_numpy(X)\ny = torch.from_numpy(np.array(df['age_bins']))\ndataset = TensorDataset(X_tensor,y)","metadata":{"id":"yLBFq9i5IMIS","execution":{"iopub.status.busy":"2021-07-03T19:06:13.567952Z","iopub.execute_input":"2021-07-03T19:06:13.568316Z","iopub.status.idle":"2021-07-03T19:06:13.573405Z","shell.execute_reply.started":"2021-07-03T19:06:13.568281Z","shell.execute_reply":"2021-07-03T19:06:13.57247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numeric label for each element corresponds to index of the element's label in the list of classes.","metadata":{"id":"ZNzbqAi7IMIS"}},{"cell_type":"code","source":"dataset.classes = age_list\nprint(dataset.classes)","metadata":{"id":"mzgFfOWmIMIS","outputId":"f81eaad6-28e2-4aed-e488-a8bc6e107dd5","execution":{"iopub.status.busy":"2021-07-03T19:06:13.574737Z","iopub.execute_input":"2021-07-03T19:06:13.575351Z","iopub.status.idle":"2021-07-03T19:06:13.58341Z","shell.execute_reply.started":"2021-07-03T19:06:13.575317Z","shell.execute_reply":"2021-07-03T19:06:13.582429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split dataset and create dataloader <a id=\"7.2\"></a>","metadata":{"papermill":{"duration":0.037719,"end_time":"2020-09-24T10:29:07.947886","exception":false,"start_time":"2020-09-24T10:29:07.910167","status":"completed"},"tags":[],"id":"GVAWA4RPIMIU"}},{"cell_type":"code","source":"# split dataset train/validation/test\ntrain_ds, val_ds, test_ds = train_validation_test(dataset=dataset,val_size=1500,test_size=500)\n\nbatch_size=128\n# create batchs using dataloader\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)","metadata":{"id":"z1SJjLiGIMIU","execution":{"iopub.status.busy":"2021-07-03T19:06:13.584932Z","iopub.execute_input":"2021-07-03T19:06:13.585433Z","iopub.status.idle":"2021-07-03T19:06:13.596809Z","shell.execute_reply.started":"2021-07-03T19:06:13.585394Z","shell.execute_reply":"2021-07-03T19:06:13.595981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build and train model <a id=\"7.3\"></a>","metadata":{"papermill":{"duration":0.037718,"end_time":"2020-09-24T10:29:08.163085","exception":false,"start_time":"2020-09-24T10:29:08.125367","status":"completed"},"tags":[],"id":"fUO_yIONIMIU"}},{"cell_type":"code","source":"class AgeModel(ImageClassificationBase):\n  def __init__(self):\n    super().__init__()\n    self.network = nn.Sequential(\n        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(16),\n        nn.Dropout(0.2),\n\n        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(32),\n        nn.Dropout(0.2),\n\n        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(64),\n        nn.Dropout(0.2),\n\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.BatchNorm2d(128),\n        nn.Dropout(0.2),\n\n        nn.Flatten(),\n        nn.Linear(128 * 1 * 1,128),\n        nn.Dropout(0.5),\n        nn.Linear(128,256),\n        nn.Dropout(0.5),\n        nn.Linear(256,4)\n    )\n  def forward(self, images):\n    return self.network(images)","metadata":{"id":"eWlYj_p-IMIV","execution":{"iopub.status.busy":"2021-07-03T19:06:13.598468Z","iopub.execute_input":"2021-07-03T19:06:13.598884Z","iopub.status.idle":"2021-07-03T19:06:13.609523Z","shell.execute_reply.started":"2021-07-03T19:06:13.598848Z","shell.execute_reply":"2021-07-03T19:06:13.608379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now wrap our training and validation data loaders using `DeviceDataLoader` for automatically transferring batches of data to the GPU (if available), and use `to_device` to move our model to the GPU (if available).","metadata":{"id":"l8S5PsxUIMIV"}},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nmodel = to_device(AgeModel(), device)\nmodel","metadata":{"id":"SqkomkRBIMIW","outputId":"29f5719d-4b4f-4550-cb14-4bb296b9d4e0","execution":{"iopub.status.busy":"2021-07-03T19:06:13.610773Z","iopub.execute_input":"2021-07-03T19:06:13.611179Z","iopub.status.idle":"2021-07-03T19:06:13.629582Z","shell.execute_reply.started":"2021-07-03T19:06:13.611144Z","shell.execute_reply":"2021-07-03T19:06:13.628943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we begin training, let's instantiate the model once again and see how it performs on the validation set with the initial set of parameters.","metadata":{"id":"BBhQxqtnIMIW"}},{"cell_type":"code","source":"history = evaluate(model, val_dl)\nprint(\"Untrained Accuracy: \", history['val_acc'])\nprint(\"Untrained Loss: \", history['val_loss'])","metadata":{"id":"Rdp_ElBAIMIW","outputId":"736b5ef9-b119-4159-cf24-1f6495f34443","execution":{"iopub.status.busy":"2021-07-03T19:06:13.632231Z","iopub.execute_input":"2021-07-03T19:06:13.632468Z","iopub.status.idle":"2021-07-03T19:06:13.785676Z","shell.execute_reply.started":"2021-07-03T19:06:13.632445Z","shell.execute_reply":"2021-07-03T19:06:13.784865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The initial accuracy is around 10%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n\nWe'll use the following *hyperparmeters* (learning rate, no. of epochs, batch_size etc.) to train our model.","metadata":{"id":"R9S-uQH4IMIX"}},{"cell_type":"code","source":"num_epochs = 20\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"id":"pTWzeCf_IMIX","execution":{"iopub.status.busy":"2021-07-03T19:06:13.788743Z","iopub.execute_input":"2021-07-03T19:06:13.789008Z","iopub.status.idle":"2021-07-03T19:06:13.806115Z","shell.execute_reply.started":"2021-07-03T19:06:13.78898Z","shell.execute_reply":"2021-07-03T19:06:13.801915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","metadata":{"id":"765hmjqRIMIY","outputId":"1dea32f5-3529-4268-e67c-2b5c677d511f","execution":{"iopub.status.busy":"2021-07-03T19:06:13.810089Z","iopub.execute_input":"2021-07-03T19:06:13.810435Z","iopub.status.idle":"2021-07-03T19:06:50.573651Z","shell.execute_reply.started":"2021-07-03T19:06:13.810398Z","shell.execute_reply":"2021-07-03T19:06:50.572706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating training history <a id=\"7.4\"></a>","metadata":{"id":"tv7ETIAWIMIY"}},{"cell_type":"markdown","source":"We can also plot the valdation set accuracies to study how the model improves over time.","metadata":{"id":"_D_nb2k-IMIY"}},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"id":"va_3Aya5IMIZ","outputId":"b7d25c7a-1c52-4535-f424-cf85d9ac45ad","execution":{"iopub.status.busy":"2021-07-03T19:06:50.576774Z","iopub.execute_input":"2021-07-03T19:06:50.577062Z","iopub.status.idle":"2021-07-03T19:06:50.640252Z","shell.execute_reply.started":"2021-07-03T19:06:50.577022Z","shell.execute_reply":"2021-07-03T19:06:50.639296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also plot the training and validation losses to study the trend.","metadata":{"id":"FGmil2ZyIMIc"}},{"cell_type":"code","source":"plot_losses(history)","metadata":{"id":"7U_6F6dfIMIc","outputId":"bbf4d2b9-33e5-46a4-a74f-52fbf9a2d5fe","execution":{"iopub.status.busy":"2021-07-03T19:06:50.64302Z","iopub.execute_input":"2021-07-03T19:06:50.643278Z","iopub.status.idle":"2021-07-03T19:06:50.65944Z","shell.execute_reply.started":"2021-07-03T19:06:50.643253Z","shell.execute_reply":"2021-07-03T19:06:50.658724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_metrics(train_dl,model, 'weighted')","metadata":{"id":"ygURWLUQyeSC","outputId":"d3595b92-353f-4544-81a9-a5be774918fc","execution":{"iopub.status.busy":"2021-07-03T19:06:50.660557Z","iopub.execute_input":"2021-07-03T19:06:50.660867Z","iopub.status.idle":"2021-07-03T19:06:52.067546Z","shell.execute_reply.started":"2021-07-03T19:06:50.660833Z","shell.execute_reply":"2021-07-03T19:06:52.06614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance on Test Data <a id=\"7.5\"></a>","metadata":{"id":"9ydmz85vIMIc"}},{"cell_type":"markdown","source":"While we have been tracking the overall accuracy of a model so far, it's also a good idea to look at model's results on some sample images. Let's test out our model with some images from the predefined test dataset.","metadata":{"id":"RHNZSUrKIMId"}},{"cell_type":"code","source":"index=np.random.randint(0,500,25) # predicted label and their images\n\nplt.figure(figsize=(16,16))\n\nfor i in range(len(index)):\n    plt.subplot(5,5,(i%25)+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(test_ds[index[i]][0].squeeze())\n    plt.xlabel(\"(\"+age_list[test_ds[index[i]][1].item()]+\") Predicted: \" + predict_label(test_ds[index[i]][0],model,dataset.classes) \n    )\n    \nplt.show()","metadata":{"id":"JYR_I_9pIMId","outputId":"a04a2e96-b9de-4ad4-f238-436849d33e4c","execution":{"iopub.status.busy":"2021-07-03T19:06:52.070903Z","iopub.execute_input":"2021-07-03T19:06:52.071206Z","iopub.status.idle":"2021-07-03T19:06:53.340209Z","shell.execute_reply.started":"2021-07-03T19:06:52.071176Z","shell.execute_reply":"2021-07-03T19:06:53.339379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As a final step, let's also look at the overall loss and accuracy of the model on the test set. We expect these values to be similar to those for the validation set. If not, we might need a better validation set that has similar data and distribution as the test set (which often comes from real world data).","metadata":{"id":"IWfREBf1IMId"}},{"cell_type":"code","source":"test_dl = DeviceDataLoader(DataLoader(test_ds, batch_size*2), device)\nresult = evaluate(model, test_dl)\nprint(\"Test Accuracy: \",result['val_acc'])\nprint(\"Test Loss: \",result['val_loss'])\nget_metrics(test_dl,model, 'weighted')","metadata":{"id":"va7uwppuIMIe","outputId":"6ebfa405-944b-4a6f-e302-28453a155d40","execution":{"iopub.status.busy":"2021-07-03T19:06:53.341794Z","iopub.execute_input":"2021-07-03T19:06:53.342157Z","iopub.status.idle":"2021-07-03T19:06:53.382642Z","shell.execute_reply.started":"2021-07-03T19:06:53.342108Z","shell.execute_reply":"2021-07-03T19:06:53.381826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_confusion_matrix(age_list,model,test_dl)","metadata":{"id":"v4mp66qcrQN4","outputId":"1c04a154-df76-4e35-c5f9-4c5550078a07","execution":{"iopub.status.busy":"2021-07-03T19:06:53.384376Z","iopub.execute_input":"2021-07-03T19:06:53.384713Z","iopub.status.idle":"2021-07-03T19:06:53.464764Z","shell.execute_reply.started":"2021-07-03T19:06:53.384677Z","shell.execute_reply":"2021-07-03T19:06:53.46398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving model <a id=\"7.6\"></a>","metadata":{"id":"D8024-oPl3ht"}},{"cell_type":"markdown","source":"Since we've trained our model for a long time and achieved a resonable accuracy, it would be a good idea to save the weights of the model to disk, so that we can reuse the model later and avoid retraining from scratch.","metadata":{"id":"Ifo92aOpl3ht"}},{"cell_type":"code","source":"folder_path = './'\nmodel_pth = 'AgeModel1.pth'\ntorch.save(model.state_dict(), folder_path + model_pth)","metadata":{"id":"nV34DBjQl3ht","execution":{"iopub.status.busy":"2021-07-03T19:06:53.465926Z","iopub.execute_input":"2021-07-03T19:06:53.46643Z","iopub.status.idle":"2021-07-03T19:06:53.475159Z","shell.execute_reply.started":"2021-07-03T19:06:53.466394Z","shell.execute_reply":"2021-07-03T19:06:53.474386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `.state_dict` method returns an `OrderedDict` containing all the weights and bias matrices mapped to the right attributes of the model. To load the model weights, we can redefine the model with the same structure, and use the `.load_state_dict` method.","metadata":{"id":"ojbH0mSel3ht"}},{"cell_type":"code","source":"model2 = to_device(AgeModel(), device)","metadata":{"id":"Zhbmn2Jyl3ht","execution":{"iopub.status.busy":"2021-07-03T19:06:53.476522Z","iopub.execute_input":"2021-07-03T19:06:53.476936Z","iopub.status.idle":"2021-07-03T19:06:53.487582Z","shell.execute_reply.started":"2021-07-03T19:06:53.47689Z","shell.execute_reply":"2021-07-03T19:06:53.486871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.load_state_dict(torch.load(folder_path+ model_pth))\nresult = evaluate(model2, test_dl)\nprint(\"Test Accuracy: \",result['val_acc'])\nprint(\"Test Loss: \",result['val_loss'])","metadata":{"id":"0Q7oI951l3ht","outputId":"f28d6f86-c73c-4822-a6a4-ed5bacd588c1","execution":{"iopub.status.busy":"2021-07-03T19:06:53.489188Z","iopub.execute_input":"2021-07-03T19:06:53.489518Z","iopub.status.idle":"2021-07-03T19:06:53.516511Z","shell.execute_reply.started":"2021-07-03T19:06:53.489484Z","shell.execute_reply":"2021-07-03T19:06:53.515681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Further Work <a id=\"8\"></a>","metadata":{"id":"uAESHPLiJp_X"}},{"cell_type":"markdown","source":"There's a lot of scope to experiment here, and we can use the interactive nature of Jupyter to play around with the various parameters. Here are a few ideas:\n* Try chaging the hyperparameters to achieve a higher accuracy within fewer epochs.\n* Try adding more convolutional layers, or increasing the number of channels in each convolutional layer\n\nIn Future, we can try to combine these three models into a singular model branched such that it's becomes capable of predicting each of these three targets simulatenously. We can also imply transfer learning algorithms for possible improvement. in accuracy.\n\nAnother possible addition to this note book would be face detection from images that can then be passed to these trained models for age, gender and ethnicity predictions.","metadata":{"id":"kQtyjLyyzdXQ"}},{"cell_type":"markdown","source":"## Acknowledgments <a id=\"9\"></a>\nFor Creating Helper Functions [PyTorch for Deep Learning - Full Course / Tutorial](https://www.youtube.com/watch?v=GIsg-ZUy0MY&t=24544s&ab_channel=freeCodeCamp.org)","metadata":{}}]}