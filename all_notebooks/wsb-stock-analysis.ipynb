{"cells":[{"metadata":{},"cell_type":"markdown","source":"# in progress "},{"metadata":{},"cell_type":"markdown","source":"## The aim of this notebook is to obtain for each post on wsb the name of the stock cited and then be able to make some analysis starting from this point"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize\n\nimport re\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wsb_words(date = 'today'):\n    \n    df = pd.read_csv('../input/reddit-wallstreetsbets-posts/reddit_wsb.csv')\n    df = df.drop(columns=['created','id','url','comms_num'])\n    df['body'] = df['body'].fillna(\"\")\n    df['text'] = df['title'] + ' ' + df['body']\n    df = df.drop(columns = ['body','title'])\n    df['timestamp'] = df['timestamp'].apply(lambda x: x[0:10])\n    \n#     stock = [\"AAL\",\"AAPL\",\"ABNB\",\"ACST\",\"AIKI\",\"AMD\",\"AMRN\",\"AMRS\",\"APHA\",\"ASRT\",\"ATNX\",\"ATOS\",\"AVGR\",\"AZN\",\"BIDU\",\"BILI\",\"BIOL\",\"BNGO\",\"BYND\",\"CAN\",\n#              \"CFMS\",\"CHFS\",\"CIDM\",\"CLOV\",\"CRBP\",\"CTRM\",\"CTXR\",\"DFFN\",\"DGLY\",\"DKNG\",\"EBON\",\"ECOR\",\"FB\",\"FCEL\",\"FGEN\",\"FRSX\",\"FUTU\",\"GEVO\",\"HEPA\",\"HIMX\",\n#              \"IDEX\",\"INO\",\"INPX\",\"INSG\",\"INTC\",\"ITRM\",\"JCS\",\"JD\",\"KMPH\",\"KOPN\",\"KXIN\",\"LI\",\"LKCO\",\"MARA\",\"MICT\",\"MIK\",\"MNKD\",\"MRNA\",\"MSFT\",\"MU\",\"MVIS\",\"NAKD\",\"NBRV\",\"NEPT\",\"NKLA\",\"NNDM\",\"NOVN\",\"NXTD\",\"OCGN\",\"OGI\",\"ONTX\",\n#              \"PDD\",\"PERI\",\"PLUG\",\"POWW\",\"PYPL\",\"RDHL\",\"RIOT\",\"ROKU\",\"SHIP\",\"SIRI\",\"SLGG\",\"SNDL\",\"SRNE\",\"SSKN\",\"TELL\",\"TIGR\",\"TLRY\",\"TNXP\",\"TRCH\",\"TSLA\",\"TXMD\",\"UAL\",\"VACQ\",\"VISL\",\"VTRS\",\"VUZI\",\"WIMI\",\"WKHS\",\"ZM\"]\n    \n#     stock = pd.read_csv('../input/stock-market-dataset/symbols_valid_meta.csv') \n#     stock = stock['Symbol'].tolist()\n#     stock_lower = [x.lower() for x in lista]\n#     stocks = stock + stock_lower    \n#     words = [\"an\",\"the\",\"of\",\"and\",\"a\",\"to\",\"in\",\"is\",\"you\",\"that\",\"it\",\"he\",\"was\",\"for\",\"on\",\"are\",\"as\",\"with\",\"his\",\"they\",\"I\",\"my\",\"than\",\"first\",\"water\",\"been\",\n#          \"call\",\"who\",\"oil\",\"its\",\"now\",\"find\",\"long\",\"down\",\"day\",\"did\",\"get\",\"come\",\"made\",\"may\",\"part\",\"some\",\"her\",\"would\",\"make\",\"like\",\"him\",\"into\",\"time\",\"has\",\"look\",\"two\",\"more\",\"write\",\n#          \"go\",\"see\",\"number\",\"no\",\"way\",\"could\",\"people\",\"there\",\"use\",\"an\",\"each\",\"which\",\"she\",\"do\",\"how\",\"their\",\"if\",\"will\",\"up\",\"other\",\"about\",\"out\",\"many\",\"then\",\"them\",\"these\",\"so\",\"at\",\"be\",\n#          \"this\",\"have\",\"from\",\"or\",\"one\",\"had\",\"by\",\"word\",\"but\",\"not\",\"what\",\"all\",\"were\",\"we\",\"when\",\"your\",\"can\",\"said\"]\n#     for element in stocks:\n#         if element in words:\n#             stocks.remove(element)\n\n\n    stock = (pd.read_csv('../input/amex-nyse-nasdaq-stock-histories/all_symbols.txt').iloc[:,0]).to_list()\n    stock_lower = [x.lower() for x in stock]\n    words = [\"an\",\"the\",\"of\",\"and\",\"a\",\"to\",\"in\",\"is\",\"you\",\"that\",\"it\",\"he\",\"was\",\"for\",\"on\",\"are\",\"as\",\"with\",\"his\",\"they\",\"I\",\"my\",\"than\",\"first\",\"water\",\"been\",\n             \"call\",\"who\",\"oil\",\"its\",\"now\",\"find\",\"long\",\"down\",\"day\",\"did\",\"get\",\"come\",\"made\",\"may\",\"part\",\"some\",\"her\",\"would\",\"make\",\"like\",\"him\",\"into\",\"time\",\"has\",\"look\",\"two\",\"more\",\"write\",\n             \"go\",\"see\",\"number\",\"no\",\"way\",\"could\",\"people\",\"there\",\"use\",\"an\",\"each\",\"which\",\"she\",\"do\",\"how\",\"their\",\"if\",\"will\",\"up\",\"other\",\"about\",\"out\",\"many\",\"then\",\"them\",\"these\",\"so\",\"at\",\"be\",\n             \"this\",\"have\",\"from\",\"or\",\"one\",\"had\",\"by\",\"word\",\"but\",\"not\",\"what\",\"all\",\"were\",\"we\",\"when\",\"your\",\"can\",\"said\"]\n    \n    for element in stock_lower:\n         if element in words:\n            stock_lower.remove(element)\n            \n    \n    stocks = stock + stock_lower\n            \n    sorted_values = np.sort(df['timestamp'].unique())\n    \n    lista_valori = []\n    \n    if date == 'today':\n        df = df[df['timestamp']==sorted_values[-1]]\n    elif date == 'all':\n        pass\n    else:\n        df = df[df['timestamp']==date]\n\n    jx = []\n    ix = []\n\n    for j in range(0,len(df['text'])):\n        for i in ((df['text'].iloc[j]).split()):\n            if i in stocks:\n                jx.append(j)\n                ix.append(i)\n    \n    \n    df_termini = pd.DataFrame({\"indici\":jx,\"valori\":ix})\n    \n    lista_termini = []\n    for i in range(0,len(df)):\n        lista_termini.append(df_termini['valori'][df_termini['indici'] == i].tolist())\n    \n    df['terms'] = lista_termini\n    df['terms'] = df['terms'].apply(lambda x: list(set(x)))\n    \n    df['terms'] = df['terms'].apply(lambda x: ' '.join(map(str, x)))\n    df['terms'] = df['terms'].apply(lambda x: ' '.join([word for word in x.split() if word not in ('I')]))\n\n    \n    df['text'] = df['text'].apply(lambda x: x.lower())\n    stop = stopwords.words('english')\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n    df['text'] = df['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n    df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in ('[',']','array','will','######(**[click','â€“',\"i'm\",'&#x200b;','&nbsp;','-','FOR','To','it.','/','would','for','HERE','&#x200B;','Array','*****','-','So','If','since','In','######(**[CLICK','It','You','What','And','lot','Some','got','itâ€™s','#','This','>','*','Is','They','My','Why','How','THIS','going',\"I'm\",'Iâ€™m','get','IS','We','WE','-','I','THE','The','TO','A','AND','NOT','ðŸš€ðŸš€ðŸš€','ðŸš€','ðŸš€ðŸš€')]))\n    \n    df = df.drop(columns=['timestamp'])\n    \n    return(df)\n\n    #     counter = Counter(\" \".join(text_clean).split()).most_common(100)\n    \n#     wordcloud = WordCloud(collocations=True).generate(' '.join(text_clean))\n    \n#      #plot the wordcloud object\n#     plt.figure(figsize=(14,14))\n#     plt.imshow(wordcloud)\n#     plt.axis('off')\n#     plt.show()\n#     return(counter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wsb_words()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}