{"cells":[{"metadata":{"_uuid":"b28b29bacdda91c5f763f7563641d7e249e79051","_cell_guid":"2dea43b5-0290-40a0-b4b1-643c26c5ed44","trusted":true,"collapsed":true},"cell_type":"code","source":"\n#Neural Network Tutorial:\n# In this Neural Network tutorial we will take a step forward and will discuss about the network of \n#Perceptrons called Multi-Layer Perceptron (Artificial Neural Network).\n\n\n#import the required libraries\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import  shuffle\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"58c43267705759074abef84fabcfd10cec6dcad2"},"cell_type":"code","source":"#function to read the sonar dataset\ndef read_dataset():\n    df = pd.read_csv(\"../input/sonar.all-data.csv\")\n    print(len(df.columns))\n    X = df[df.columns[1:60]].values\n    y=df[df.columns[60]]\n    #encode the depedent variable, single it has more than one class\n    encoder = LabelEncoder()\n    encoder.fit(y)\n    y = encoder.transform(y)\n    Y = one_hot_encode(y)\n    return(X,Y,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"889a448d103374104137e383d7eaf594412ff724"},"cell_type":"code","source":"#normalise the features of the dataset\ndef feature_normalize(features):\n    mu = np.mean(features,axis=0)\n    sigma = np.std(features,axis=0)\n    normalize_features = (features - mu) / sigma\n    return(normalize_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4bf838d9d57c6e273c9be3702e123d479082f89a"},"cell_type":"code","source":"#appending the bias\ndef append_bias_reshape(features):\n    n_training_samples = features.shape[0]\n    n_dim = features.shape[1]\n    features = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim+1])\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93b2a75c80de37e1d78ca66f33a869164cc8033b"},"cell_type":"code","source":"#define the one hot encode function\ndef one_hot_encode(labels):\n    n_labels = len(labels)\n    n_unique_labels = len(np.unique(labels))\n    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n    one_hot_encode[np.arange(n_labels), labels] = 1\n    return one_hot_encode","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"collapsed":true,"_uuid":"780b3cc400d8ce255251f5876bdeecc258360351"},"cell_type":"code","source":"#plot the graph for the data\ndef plot_points(features,labels):\n    normal = np.where(labels == 0)\n    outliers = np.where(labels == 1)\n    fig = plt.figure(figsize=(10,8))\n    plt.plot(features[normal ,0],features[normal ,1],'bx')\n    plt.plot(features[outliers,0],features[outliers ,1],'ro')\n    plt.xlabel('Latency (ms)')\n    plt.ylabel('Throughput (mb/s)')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b42067c4edc2570728b907b4b7608554eec49956"},"cell_type":"code","source":"#read the data\nX,Y,y = read_dataset() #X - Features , Y - Labels\nnormalized_featues = feature_normalize(X)\nplot_points(X,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"607b507ed976ffdb2d8f32e7692916f6ee14691e"},"cell_type":"code","source":"#Transform the data in training and testing\nX,Y = shuffle(X,Y,random_state=1)\ntrain_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6f7ffbad24f30b7be42864552381190add69331"},"cell_type":"code","source":"#print the shape of the train and test data values\nprint(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\nprint(test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ed87cc1ebe03525dea1e0c4b68698318a9bbdac9"},"cell_type":"code","source":"#define and initialize the variables to work with the tensors\nlearning_rate = 0.1\ntraining_epochs = 1000\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"45d8a246128d3866a0568ea34d4e2b5f7f735069"},"cell_type":"code","source":"cost_history = np.empty(shape=[1],dtype=float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"53959ff631454428f639e04e68e5aa311d25b82e"},"cell_type":"code","source":"n_dim = X.shape[1]\nn_class = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dbbd97acce538a0f898c479d26b80b9f199873eb"},"cell_type":"code","source":"x = tf.placeholder(tf.float32,[None,n_dim])\nW = tf.Variable(tf.zeros([n_dim,n_class]))\nb = tf.Variable(tf.zeros([n_class]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8d325637c44bc84355d4290dafff86bc84a7be7e"},"cell_type":"code","source":"#initialize all variables.\ninit = tf.global_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"914e77b31a8240e6dfc951aa5dda80a09ca3cb6e"},"cell_type":"code","source":"#define the cost function\ny_ = tf.placeholder(tf.float32,[None,n_class])\ny = tf.nn.softmax(tf.matmul(x, W)+ b)\ncost_function = tf.reduce_mean(-tf.reduce_sum((y_ * tf.log(y)),reduction_indices=[1]))\ntraining_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f575e5e5100a51fdae5d5c70ce5eb18724d9d2bb"},"cell_type":"code","source":"#initialize the session\nsess = tf.Session()\nsess.run(init)\nmse_history = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbf823472d101a26e06e020d8af404f81744295e"},"cell_type":"code","source":"#calculate the cost for each epoch\nfor epoch in range(training_epochs):\n    sess.run(training_step,feed_dict={x:train_x,y_:train_y})\n    cost = sess.run(cost_function,feed_dict={x: train_x,y_: train_y})\n    cost_history = np.append(cost_history,cost)\n    pred_y = sess.run(y, feed_dict={x: test_x})\n    print('epoch : ', epoch,  ' - ', 'cost: ', cost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"158b2bf42e67dd8a6982d9db0561697dde7460af"},"cell_type":"code","source":"\nmse = tf.reduce_mean(tf.square(pred_y - test_y))\nprint(\"MSE: %.4f\" % sess.run(mse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b5f54c99797bf9331e146d35609292683f2345a"},"cell_type":"code","source":"correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nprint(\"Accuracy: \",(sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4d00110d62abbd987153dfdc8a4d229803aef2d"},"cell_type":"code","source":"plt.plot(range(len(cost_history)),cost_history)\nplt.axis([0,training_epochs,0,np.max(cost_history)])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}