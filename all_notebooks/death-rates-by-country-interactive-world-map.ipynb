{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This kernel will take data from the John Hopkins sample, included in the *Uncover Covid19 Challenge*, and produce a geographical plot with a date slider.**\n\n**This is included as an introduction to geographical plotting and various data sources included in the challenge can be substituted in instead of the John Hopkins data.**\n\nTo view the final output, a html file called *temp-plot.html* can be downloaded."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport seaborn as sb\nimport numpy as np\nimport plotly\nimport sklearn as sk\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport plotly.offline as offline\nimport plotly.graph_objs as go \n\nfrom plotly.graph_objs import *\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\ninit_notebook_mode(connected=True) \n\n%matplotlib notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# hde school info\nhde_school = pd.read_csv(\"/kaggle/input/uncover/HDE/global-school-closures-covid-19.csv\")\n\n# John Hopkins data\njh_cases = pd.read_csv(\"/kaggle/input/uncover/johns_hopkins_csse/2019-novel-coronavirus-covid-19-2019-ncov-data-repository-confirmed-cases.csv\")\n\njh_deaths = pd.read_csv(\"/kaggle/input/uncover/johns_hopkins_csse/2019-novel-coronavirus-covid-19-2019-ncov-data-repository-deaths.csv\")\n\njh_rec = pd.read_csv(\"/kaggle/input/uncover/johns_hopkins_csse/2019-novel-coronavirus-covid-19-2019-ncov-data-repository-recovered.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making John Hopkins data ready for merge\njh_cases['DateTime'] = pd.to_datetime(jh_cases['date'])\njh_deaths['DateTime'] = pd.to_datetime(jh_deaths['date'])\njh_rec['DateTime'] = pd.to_datetime(jh_rec['date'])\n\njh_cases.rename(columns={\"country_region\":\"country\"},inplace=True)\njh_deaths.rename(columns={\"country_region\":\"country\"},inplace=True)\njh_rec.rename(columns={\"country_region\":\"country\"},inplace=True)\n\n# joining john hopkins data\njohn_hop = pd.merge(jh_cases, jh_deaths,on=[\"country\",\"DateTime\",\"province_state\"])\njohn_hop.drop(columns=[\"date_x\",\"date_y\",\"lat_x\",\"long_x\"])\njh_all = pd.merge(john_hop, jh_rec,how=\"left\",on=[\"country\",\"DateTime\",\"province_state\"])\njh_all.drop(columns=[\"date_x\",\"date_y\",\"lat_x\",\"long_x\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HDE School info has country names in a column, but where different regions exist, these follow after a comma\n#the following steps ensure a single consistent country field so that school info can be merged to John Hopkins data\n\ndef country(x):\n    for i in jh_all[\"country\"]:\n        if i in x:\n            return i\n\nhde_school[\"country_1\"] = hde_school[\"country\"].apply(lambda x: country(x))\n\nhde_school.drop_duplicates(subset=[\"country_1\",\"date\"],inplace=True)\n\nhde_school.drop(columns=\"country\",inplace=True)\n\nhde_school.rename(columns={\"country_1\":\"country\"},inplace=True)\n\nhde_school['DateTime'] = pd.to_datetime(hde_school['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hde_school.sort_values(by=[\"country\",\"DateTime\"]).drop_duplicates(subset=\"country\",keep=\"first\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sql merge used so that school info can be merged for every date after the school closure\nconn = sqlite3.connect(':memory:')\n\nhde_school.to_sql(\"hde_school\",conn,index=False)\njh_all.to_sql(\"john_hop\",conn,index=False)\n\nqry = '''\n    select  \n        john_hop.*,\n        hde_school.scale        \n    from\n        john_hop left join hde_school on\n        hde_school.DateTime <= john_hop.DateTime and \n        hde_school.country = john_hop.country\n    '''\n\njoint = pd.read_sql(qry,conn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Need to dedup by date, province and country\njoint.drop_duplicates(subset=[\"province_state\",\"country\",\"DateTime\"],inplace=True)\n\njoint[\"scale\"].fillna(\"None\",inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Where no school closures - the value is set to none\ndef schools(x):\n    if x in [\"Localized\",\"National\"]:\n        return 1\n    else:\n        return 0\n    \njoint[\"schools\"] = joint[\"scale\"].apply(lambda x: schools(x))\n\njoint[\"deathRate\"] = joint[\"deaths\"] / joint[\"confirmed\"]\n# Fill in where division by 0 causes null\njoint[\"deathRate\"].fillna(0,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the a list of graphical data\ndata_slider = []\n\nfor day in joint[\"date_x\"].unique():\n    \n    samp = joint[joint[\"date_x\"] == day]\n    \n    for col in samp.columns:  # I transform the columns into string type so I can:\n        samp[col] = samp[col].astype(str)\n        \n    samp[\"text\"] = samp[\"country\"] + \"Cases: \" + samp[\"confirmed\"] + \" Deaths:\" + samp[\"deaths\"] + \" School Closures: \" + samp[\"scale\"] + \" Recovered: \" +samp[\"recovered\"]\n                    \n    \n    data_one_year = dict(\n            type='choropleth', # type of map-plot\n            colorscale = \"Reds\",\n            reversescale = True,\n            locations = samp['country'], # the column with the country\n            locationmode = \"country names\",\n            z = samp['deathRate'].astype(float)*100, # the variable I want to color-code\n            text = samp['text'], # hover text\n            marker = dict(     # for the lines separating states\n                        line = dict (\n                                  color = 'rgb(255,255,255)', \n                                  width = 2) ),               \n            colorbar = dict(\n                        title = \"Virus Death Rate\")\n            ) \n       \n    \n    data_slider.append(data_one_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a slider based on the date\nsteps = []\n\nfor i in range(len(data_slider)):\n    step = dict(method='restyle',\n                args=['visible', [False] * len(data_slider)],\n                label='Date {}'.format(joint[\"date_x\"].unique()[i])) # label to be displayed for each step (year)\n    step['args'][1][i] = True\n    steps.append(step)\njoint[\"date_x\"].unique()\n\n##  I create the 'sliders' object from the 'steps' \n\nsliders = [dict(active=0, pad={\"t\": 1}, steps=steps)]  \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout = dict(geo=dict(\n        showframe=False,\n        showcoastlines=False,\n        projection_type='equirectangular'),\n        sliders=sliders\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=data_slider, layout=layout)\n\n# output saved as HTML - download and explore as desired\nplot(fig,validate=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}