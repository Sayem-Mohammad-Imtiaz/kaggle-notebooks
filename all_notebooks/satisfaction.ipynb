{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading and Tidying Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/airline-passenger-satisfaction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/airline-passenger-satisfaction/test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We need to convert our target feature to 1's 0's ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"satisfaction\"].value_counts() # i checked if there is another class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"satisfaction\"] = [1 if each == \"satisfied\" else 0 for each in train[\"satisfaction\"]]\ntest[\"satisfaction\"] = [1 if each == \"satisfied\" else 0 for each in test[\"satisfaction\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Unnamed: 0 and id column wont do any good for us, so lets just drop them\n* And we have no missing values. Thats nice. \n* (Later Update: Actually we do have missing values, i did not noticed till i get to the modeling part.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"Unnamed: 0\",\"id\"],axis=1,inplace = True)\ntest.drop([\"Unnamed: 0\",\"id\"],axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#i will rename some of the long named columns\ntrain.rename(columns = {\"Inflight wifi service\": \"wifi\",\n                        \"Departure/Arrival time convenient\": \"timeconv\",\n                        \"Ease of Online booking\": \"onlinebooking\",\n                        \"Departure Delay in Minutes\": \"depdel\",\n                        \"Arrival Delay in Minutes\": \"arrdel\"}, inplace = True)\n\ntest.rename(columns = {\"Inflight wifi service\": \"wifi\",\n                        \"Departure/Arrival time convenient\": \"timeconv\",\n                        \"Ease of Online booking\": \"onlinebooking\",\n                        \"Departure Delay in Minutes\": \"depdel\",\n                        \"Arrival Delay in Minutes\": \"arrdel\"}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* most columns are categorical, we have 2 numerical columns, and both seem to have some outliers. especially the departure delay feature. \n* we can just drop them because it will hurt our model but delay causes unsatisfactory (naturally) i'll decide to drop or not drop after eda.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* first i want to look at delays, and after that i will look at other features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data = train,col = \"satisfaction\", height = 6)\ng.map(sns.distplot, \"depdel\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(train[\"depdel\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data = train,col = \"satisfaction\", height = 6)\ng.map(sns.distplot, \"arrdel\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(train[\"arrdel\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* as expected graphs are so skewed, lets sort values and see if peoples who delayed their flights are satisfied or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sort_values(\"depdel\").groupby(\"Customer Type\").tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* seems like we dont have a bias in long delay times, so we can drop those outliers in order to help our modeling.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Q3 = np.quantile(train[\"depdel\"],0.75)\nQ1 = np.quantile(train[\"depdel\"],0.25)\n\nIQR = Q3 - Q1\n\nstep = IQR * 3\n\nmaxm = Q3 + step\nminm = Q3 - step\n\ntrain = train[train[\"depdel\"] < maxm]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now even if i visualize the delay times again it will look skewed, because most of our flights are took place with 0 delay (like half of all data). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data = train,col = \"satisfaction\", height = 6)\ng.map(sns.distplot, \"Flight Distance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It seems that if flight distance increases satisfaction is going up.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\",\"wifi\",\"timeconv\",\"onlinebooking\",\"Gate location\",\"Food and drink\",\"Online boarding\",\"Seat comfort\",\"Inflight entertainment\",\"On-board service\",\"Leg room service\",\"Baggage handling\",\"Checkin service\",\"Inflight service\",\"Cleanliness\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ctgplt(df,variable,to):\n    \n    \"Function for visualization of categorical variables.\"\n    \n    var = df[variable]\n    values=var.value_counts()\n    \n    f, ax = plt.subplots(figsize = (8,8))\n    sns.countplot(x = variable, hue = to, data = df)\n    \n    plt.show()\n    \n    print(\"{}:\\n{}\".format(variable,values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_cols:\n    ctgplt(train, i, \"satisfaction\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As i expected disyoal customers are not satisfied at all\n* People who are going to a personal travel are probably flying in eco class and thats why their satisfaction is so low. i will visualize this to confirm\n* Most people in business class are satisfied compared to other classes\n* Most people are complaint in wifi levels 1-2-3, but in 0 and 5 almost no complain at all. That is some weird statistics.\n* Time conv. satisfactions are almost equal to each other except 1 class.\n* Online booking have some negative impact on satisfaction\n* Gate location have same impact too. if airport is too big it is really exhaustive to get to the gate\n* Food and drink is as expected\n* Online boarding has some serious impact on low classes\n* Seat comfort has some negativity but also has some positive impact too\n* Peoples have some complaint on flight entertainment.\n* On board, leg room, inflight services and Cleanliness almost have the same distribution. like many features\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize = (12,8))\ntrain[\"Type of Travel\"].hist(by = train[\"Class\"],xrot =30,ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that most of the travels in eco class are personal travels.\n* And dissatisfactory on the business travels are also coming from eco class. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(16, 12))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, annot=True, mask=mask, cmap=cmap, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we can see that arrdel and depdel are highly correlated and they are not correlated with our target. so we can drop them.\n* Also gate location is not related with our target feature, i will drop that too.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"arrdel\",\"depdel\",\"Gate location\"],axis=1,inplace=True)\ntest.drop([\"arrdel\",\"depdel\",\"Gate location\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labelenc = [\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\"]\nscal = []\nfor each in train.columns:\n    if train[each].dtype == \"int64\" or train[each].dtype == \"float64\":\n        scal.append(each)\n\nle = LabelEncoder()\nscaler = MinMaxScaler()\n\n# Label Encoder\nfor each in labelenc:\n    train[each] = le.fit_transform(train[each])\n    test[each] = le.transform(test[each])\n\n# MinMax Scaler\ntrain[train.columns] = scaler.fit_transform(train[train.columns])\ntest[test.columns] = scaler.transform(test[test.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(\"satisfaction\",axis=1)\ny = train[\"satisfaction\"]\n\nX_test = test.drop(\"satisfaction\",axis=1)\ny_test = test[\"satisfaction\"]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = XGBClassifier(n_estimators = 300,max_depth = 3)\n\nxg.fit(X_train, y_train)\n\nprint(\"train score: \", xg.score(X_train, y_train))\nprint(\"vald score: \", xg.score(X_val, y_val))\n\npreds = xg.predict(X_test)\n\nprint(\"test score\",accuracy_score(y_test,preds))\nprint(\"roc-auc\",roc_auc_score(y_test,preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, preds)\nsns.heatmap(cf_matrix,annot = True, fmt=\"g\",cmap=\"Greens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(data=xg.feature_importances_,\n                        index= X_train.columns)\n\nimportances_sorted = importances.sort_values()\nplt.figure(figsize=(8,8))\nimportances_sorted.plot(kind='barh')\nplt.title('Features Importances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lg=LGBMClassifier(max_depth = 7, n_estimators = 250,n_jobs=-1)\n\nlg.fit(X_train,y_train)\n\nprint(\"train score: \", lg.score(X_train, y_train))\nprint(\"vald score: \", lg.score(X_val, y_val))\n\npreds = lg.predict(X_test)\n\nprint(\"test score\",accuracy_score(y_test,preds))\nprint(\"roc-auc\",roc_auc_score(y_test,preds))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that lightgbm gave us a better result","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, preds)\nsns.heatmap(cf_matrix,annot = True, fmt=\"g\",cmap=\"Greens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(data=lg.feature_importances_,\n                        index= X_train.columns)\n\nimportances_sorted = importances.sort_values()\nplt.figure(figsize=(8,8))\nimportances_sorted.plot(kind='barh')\nplt.title('Features Importances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* now i will select first 10 features and fit the model again lets see if our score will improve or not","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_selected = X_train[[\"Leg room service\",\"Seat comfort\",\"timeconv\",\"Customer Type\",\"Type of Travel\",\"Baggage handling\",\"Inflight service\",\"wifi\",\"Age\",\"Flight Distance\"]]\nX_val_selected = X_val[[\"Leg room service\",\"Seat comfort\",\"timeconv\",\"Customer Type\",\"Type of Travel\",\"Baggage handling\",\"Inflight service\",\"wifi\",\"Age\",\"Flight Distance\"]]\nX_test_selected = X_test[[\"Leg room service\",\"Seat comfort\",\"timeconv\",\"Customer Type\",\"Type of Travel\",\"Baggage handling\",\"Inflight service\",\"wifi\",\"Age\",\"Flight Distance\"]]\n\nlg2 = LGBMClassifier(max_depth=5, n_estimators=150, n_jobs=-1)\n\nlg2.fit(X_train_selected, y_train)\n\nprint(\"train score: \", lg2.score(X_train_selected, y_train))\nprint(\"vald score: \", lg2.score(X_val_selected, y_val))\n\npreds = lg2.predict(X_test_selected)\n\nprint(\"test score\",accuracy_score(y_test,preds))\nprint(\"roc-auc\",roc_auc_score(y_test,preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As expected, it did not. But our runtime is now shorter, if we tune the hyperparameters we could get a better accuracy. But i will not do that now cause it takes time. Why dont you do give it a try?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### **Thank you for reading, I hope you like it. See you in another notebook.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}