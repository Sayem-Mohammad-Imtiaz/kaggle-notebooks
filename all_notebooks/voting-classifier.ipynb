{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline\nimport missingno as msno\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/mobile-price-classification/train.csv')\ntest=pd.read_csv('../input/mobile-price-classification/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# checking missing value","metadata":{}},{"cell_type":"code","source":"#checking missing value\nmsno.matrix(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Effect of battery power on price ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[7,7])\nsns.boxplot(data=train,x='price_range',y='battery_power')\nsns.despine(offset=10, trim=True)\nplt.xlabel('Price Class');\nplt.title('The battery range in each price class');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see above the price class 3 has high battery power , so we can conclude that the more battery power the more increase in the price ","metadata":{}},{"cell_type":"code","source":"train['blue'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[7,7])\nsns.boxplot(data=train,x='price_range',y='blue')\nsns.despine(offset=10, trim=True)\nplt.xlabel('Price Class');\nplt.title('The battery range in each price class');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the feature blue effect on price range or not by seeing it's occurance in every price class ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[12,5])\nsns.countplot(hue='blue',x='price_range',data=train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since there are no difference in ocuurance of blue in each price class , we can deduce that it has no effect on pjone price ","metadata":{}},{"cell_type":"markdown","source":"Are any of price ranges has high range of clock speed than others ?","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"price_range\", y=\"clock_speed\", data=train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"oooh ! the range of clock speed is the same in all the 4 price class , so this feature has no effect in our our price ","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=[12,5])\nsns.countplot(hue='dual_sim',x='price_range',data=train)\nplt.title('number of dual sim in each price range ');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the 4 price range approximately have the same dual sim range , so may be this feature don't help us in our classification ","metadata":{}},{"cell_type":"code","source":"train['fc'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Are any of price ranges has high value of fc than others ?  ","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"price_range\", y=\"fc\", data=train)\nplt.title('range of fc ic each price class');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"approximately  the 4 ranges has the same fc , so also this feature has a weak effect in determining the range of the price ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=[12,5])\nsns.countplot(hue='four_g',x='price_range',data=train)\nplt.title('number of four_g  in each price range ');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The four price ranges have the advantage of four G   , so i think that these feature has no effect in our classification   ","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"price_range\", y=\"int_memory\", kind=\"boxen\",\n            data=train);\nplt.title('Range of int Memory in each price range  ');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So as we see, this feature effects in price range since the class 3 has high median and range than the three other ranges , and the class 1 has int memory than 2 and 0 , so we will take this feature in considration in our classification ","metadata":{}},{"cell_type":"code","source":"train['m_dep'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display the \nx = sns.boxplot(x=\"price_range\", y=\"m_dep\", data=train)\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the main of m_dep is the same in all price ranges !! ","metadata":{}},{"cell_type":"code","source":"train.corr()['price_range'].T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see there are avery weak relationships between the majorty of our feature and our target price ranges \n\nso we will choose one algorithm to calculate the most important features to use in our classification  ","metadata":{}},{"cell_type":"code","source":"X=train.drop(['price_range'],axis=1)\ny=train['price_range']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import Libraries\nfrom sklearn.feature_selection import SelectFromModel\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Feature Selection by KBest \nprint('Original X Shape is ' , X.shape)\n\n\nfrom sklearn.linear_model import LinearRegression\nthismodel = LinearRegression()\n\n\nFeatureSelection = SelectFromModel(estimator = thismodel, max_features = 10) # make sure that thismodel is well-defined\nX = FeatureSelection.fit_transform(X, y)\n\n#showing X Dimension \nprint('X Shape is ' , X.shape)\nprint('Selected Features are : ' , FeatureSelection.get_support())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import Libraries\nfrom sklearn.model_selection import train_test_split\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VOTING CLASSIFIER ","metadata":{}},{"cell_type":"code","source":"#Import Libraries\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n \n\n#loading models for Voting Classifier\nLRModel_ = LogisticRegression(solver='lbfgs', multi_class='multinomial',random_state=33)\nGBCModel_ = GradientBoostingClassifier(n_estimators=1000, learning_rate=1.0,max_depth=1, random_state=0)\nDTModel_ = DecisionTreeClassifier(criterion = 'entropy',max_depth=3,random_state = 33)\nRFModel_ = RandomForestClassifier(n_estimators=100, criterion='gini',max_depth=1, random_state=33)\nLDAModel_ = LinearDiscriminantAnalysis(n_components=3 ,solver='svd')\n\n#loading Voting Classifier\nVotingClassifierModel = VotingClassifier(estimators=[('LRModel',LRModel_),('GBCModel',GBCModel_),('DTModel',DTModel_),('RFModel',RFModel_),('LDAModel',LDAModel_)], voting='hard')\nVotingClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('VotingClassifierModel Train Score is : ' , VotingClassifierModel.score(X_train, y_train))\nprint('VotingClassifierModel Test Score is : ' , VotingClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = VotingClassifierModel.predict(X_test)\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}