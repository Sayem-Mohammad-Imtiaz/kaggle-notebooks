{"cells":[{"metadata":{},"cell_type":"markdown","source":"Я выбрал VAE Autoencoder, так как он с легкостью позволяет генерировать новые изображения, всего лишь передав ему одну единственную точку (x,y)."},{"metadata":{},"cell_type":"markdown","source":"В качестве датасета был использован следующий датасет https://www.kaggle.com/sshikamaru/fruit-recognition. Я выбрал датасет, содержащий изображения небольшого разрешения, всего 100х100 пикселей, так как VAE encoder  плохо подходит для генерации изображений высокого качества, лучше использовать GAN модели"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom keras import backend as K\nimport os\nfrom collections import defaultdict\nfrom shutil import copy\nfrom shutil import copytree, rmtree\nimport PIL\nimport glob\nfrom keras.preprocessing.image import img_to_array, array_to_img\nfrom keras import layers\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os\nimport shutil\nfrom keras.losses import binary_crossentropy\nimport imageio\n!pip install -q git+https://github.com/tensorflow/docs\nimport tensorflow_docs.vis.embed as embed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Без этой настройки, модель отказывается обучаться ("},{"metadata":{"trusted":true},"cell_type":"code","source":" tf.compat.v1.disable_eager_execution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Я решил создать мини-выборку из 4 классов, именно эти классы выбрал для большей наглядности (у каждого класса либо цвет, либо форма другая)"},{"metadata":{"trusted":true},"cell_type":"code","source":"food_list = ['Apple Granny Smith','Corn','Onion White','Limes']\nsrc_train = '/kaggle/input/fruit-recognition/train/train'\ndest_train = 'train_mini'\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вспомогательная функция для создания мини-датасетов\ndef dataset_mini(food_list, src, dest):\n  if os.path.exists(dest):\n    rmtree(dest) # удаляем папку мини-датасета (если такая есть), для того, чтобы в папке были только те классы, которые мы укажем\n  os.makedirs(dest)\n  for food_item in food_list :\n    print(\"Copying images into\",food_item)\n    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Создание тренировочной выборки с выбранными классами\")\ndataset_mini(food_list, src_train, dest_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Всего изображений в мини тренировочной выборке\")\n\n!find train_mini -type d -or -type f -printf '.' | wc -c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 112, 112\nIMG_SHAPE = (img_width, img_height, 3)\nlatent_dim = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./ 255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = datagen.flow_from_directory('train_mini/',  class_mode='input', \n                                        target_size=(img_width, img_height), batch_size=32, color_mode = 'rgb')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ниже описаны функции, необходимые для работы VAE, в частности своя loss функция для модели - совокупность Reconstruction-loss и KL-loss. А compute_latent это некий Reparameterization trick, позволяющий использовать градиентный спуск для нашей loss функции."},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_latent(x):\n    mu, sigma = x\n    batch = K.shape(mu)[0]\n    dim = K.int_shape(mu)[1]\n    eps = K.random_normal(shape=(batch,dim))\n    return mu + K.exp(sigma/2)*eps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kl_reconstruction_loss(true, pred):\n    # Reconstruction loss (binary crossentropy)\n    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * img_width * img_height\n\n    # KL divergence loss\n    kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n    # Total loss = 50% rec + 50% KL divergence loss\n    return K.mean(reconstruction_loss + kl_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Такую сложную структуру модели подсмотрел в данной работе - https://arxiv.org/pdf/1511.06434.pdf.\n(В работе указана картинка, не сам код) Да, она выглядит громоздкой, но эта цена за более качественную генерацию изображений."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ni = layers.Input(shape=IMG_SHAPE)\ncx = layers.Conv2D(filters=128, kernel_size=5, strides=2, padding='same', activation='relu')(i)\ncx = layers.BatchNormalization()(cx)\ncx = layers.Conv2D(filters=256, kernel_size=5, strides=2, padding='same', activation='relu')(cx)\ncx = layers.BatchNormalization()(cx)\ncx = layers.Conv2D(filters=512, kernel_size=5, strides=2, padding='same', activation='relu')(cx)\ncx = layers.BatchNormalization()(cx)\ncx = layers.Conv2D(filters=1024, kernel_size=5, strides=2, padding='same', activation='relu')(cx)\ncx = layers.BatchNormalization()(cx)\nx  = layers.Flatten()(cx)\nx  = layers.Dense(20, activation='relu')(x)\nx  = layers.BatchNormalization()(x)\n\nmu = layers.Dense(latent_dim)(x)\nsigma = layers.Dense(latent_dim)(x)\n\nlatent_space = layers.Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])\n\nconv_shape = K.int_shape(cx)\n\nd_i   = layers.Input(shape=(latent_dim, ))\nx     = layers.Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation='relu')(d_i)\nx     = layers.BatchNormalization()(x)\nx     = layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\ncx    = layers.Conv2DTranspose(filters=1024, kernel_size=5, strides=2, padding='same', activation='relu')(x)\ncx    = layers.BatchNormalization()(cx)\ncx    = layers.Conv2DTranspose(filters=512, kernel_size=5, strides=2, padding='same', activation='relu')(cx)\ncx    = layers.BatchNormalization()(cx)\ncx    = layers.Conv2DTranspose(filters=256, kernel_size=5, strides=2, padding='same', activation='relu')(cx)\ncx    = layers.BatchNormalization()(cx)\ncx    = layers.Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same', activation='relu')(cx)\ncx    = layers.BatchNormalization()(cx)\no     = layers.Conv2DTranspose(filters=3, kernel_size=3, activation='sigmoid', padding='same')(cx)\n\nencoder = Model(i, latent_space)\ndecoder = Model(d_i, o)\nvae_outputs = decoder(encoder(i))\nvae = Model(i,vae_outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vae.compile(optimizer='adam', loss=kl_reconstruction_loss)\nhistory = vae.fit(train_gen, epochs=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"А тут я изобразил сетку сгенерированных объектов из декодера, при передаче ему точек (x,y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_model = decoder\nx_values = np.linspace(-5, 5, 30)\ny_values = np.linspace(-5, 5, 30)\nfigure = np.zeros((112 * 30, 112 * 30,3))\nfor ix, x in enumerate(x_values):\n    for iy, y in enumerate(y_values):\n        latent_point = np.array([[x, y]])\n        generated_image = generator_model.predict(latent_point)[0]\n        figure[ix*112:(ix+1)*112, iy*112:(iy+1)*112] = generated_image\nplt.figure(figsize=(15, 15))\nplt.imshow(figure, extent=[5,-5,5,-5])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ниже визуализированы кластеры классов объектов из latent space"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_label_clusters(encoder, data, labels):\n    # display a 2D plot of the digit classes in the latent space\n    z_mean = encoder.predict(data)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c = labels.classes)\n    plt.colorbar()\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = glob.glob('train_mini/**/*.jpg', recursive= True)\nX_train = np.zeros((len(test_images), img_width, img_height, 3))\nfor i in range(len(test_images)):\n  image = tf.keras.preprocessing.image.load_img(test_images[i], target_size= (img_width, img_height))\n  X_train[i] = img_to_array(image) / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_label_clusters(encoder, X_train, train_gen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"А тут  создаются изображения для гифки, гифка показывает переход из одного класса в другой"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir images_for_gif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd images_for_gif\nfor x in np.arange(0,5,0.1):\n    latent_point = np.array([[x, -1]])\n    image = generator_model.predict(latent_point)[0]\n    plt.imshow(image)\n    plt.savefig('images_for_gif/' +'image' + str(x) + '.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anim_file = 'cvae.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('images_for_gif/image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed.embed_file(anim_file)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}