{"cells":[{"metadata":{"_uuid":"9d5fc382b963baff59f659fd586334b9be42e6a9"},"cell_type":"markdown","source":"# Part 3 (Modelling)"},{"metadata":{"_uuid":"dd83e5e72d9cfb18aa853212691545dec76c1033"},"cell_type":"markdown","source":"## Created by Konstantin Georgiev\n### Email: dragonflareful@gmail.com"},{"metadata":{"_uuid":"07b08d8e70a3b4a0723ab64bde1f0c5c851ad9a3"},"cell_type":"markdown","source":"Next up, just for fun, I'll try to apply logistic regression and make a model which will predict whether a product contains additives or not."},{"metadata":{"trusted":true,"_uuid":"fafabed2bee58b9e4c2764a170aa310c0c93787f"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nfrom nose.tools import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83686300bec61d7f65e9657d4af1c72f5de48bc4"},"cell_type":"markdown","source":"## Step 1 - Obtaining the data"},{"metadata":{"_uuid":"93de1f144b08ca48eab88b591678fca6a4c07f87"},"cell_type":"markdown","source":"First up, of course, we'll load the cleaned french products dataset from __Part 1__."},{"metadata":{"trusted":true,"_uuid":"dbc91940818b8f4632cf4c9a93fd553f23355f74"},"cell_type":"code","source":"world_food_data=pd.read_csv(\"../input/openfoodfactsclean/world_food_scrubbed.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3a9411331098a6055db32900f9d5c10db541d58"},"cell_type":"markdown","source":"As we previosly saw, the dataset should have 71091 observations and 13 features."},{"metadata":{"trusted":true,"_uuid":"f1dec8618ce2a95c916817ff6f9485bcdd3e225d"},"cell_type":"code","source":"assert_is_not_none(world_food_data)\nassert_equal(world_food_data.shape,(71091,13))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"625756f349bfcf5d388788d403d5baec46900681"},"cell_type":"code","source":"world_food_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0f39cf0af4a950c2522fe10ac667d801520d3a3"},"cell_type":"markdown","source":"## Step 2 - Preparing the data for modelling"},{"metadata":{"_uuid":"fc62169f176b92fad3f60c823a5fcf996d35f8c5"},"cell_type":"markdown","source":"I'm going to drop the columns which I'm not going to use for training and confirm that the number of features is __8__."},{"metadata":{"trusted":true,"_uuid":"298fb5cbe1c2c911dbf76bc4a124ee5784382275"},"cell_type":"code","source":"world_food_data.drop(columns=[\"product_name\",\"packaging\",\"additives_n\",\"fp_lat\",\"fp_lon\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ea922ddc64fbe9e599f6a63c01dddb3ca9ad2d3"},"cell_type":"code","source":"assert_equal(world_food_data.shape[1],8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cb3e168cca89af6f5250593a6858ce8a1a77d07"},"cell_type":"code","source":"world_food_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a3a384232ecc07b1fca56337b93406f5372b75e"},"cell_type":"markdown","source":"After that I'm going to prepare the data for modelling a bit.<br>First, I'll call the `pd.get_dummies()` function in `pandas` which will expand our features based on each unique row value and change these values to numeric ones. Next I'm going to drop the `contains_additives` column and use it as a __target__, since this will be our prediction."},{"metadata":{"trusted":true,"_uuid":"17e1631c26a22dd7b264d0e67416975251ad6574"},"cell_type":"code","source":"world_food_data_for_modelling=pd.get_dummies(world_food_data)\nworld_food_data_features=world_food_data_for_modelling.drop(columns=[\"contains_additives\"])\nworld_food_data_target=world_food_data.contains_additives","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a46e7d1ed2c2fe38241fcf899bd9d504ce2e08ae"},"cell_type":"code","source":"world_food_data_for_modelling.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da18276d17574008f480b5d0f48f9a57590a9860"},"cell_type":"markdown","source":"The features should be one less than the entire dataframe and the target should only be one column."},{"metadata":{"trusted":true,"_uuid":"cd8a1bea53a6db862e6eea68f6a5a4f0e840f9f6"},"cell_type":"code","source":"assert_equal(world_food_data_for_modelling.shape[1],1935)\nassert_equal(world_food_data_features.shape[1],1934)\nassert_equal(world_food_data_target.shape,(71091,))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfd2ad6518247cd0c9a384ef6d21c5d7caeaaf00"},"cell_type":"markdown","source":"For preprocessing I will use scipy's `MaxAbsScaler`, which scales each feature by its maximum absolute value."},{"metadata":{"trusted":true,"_uuid":"eae41d2e5e6279c8b74085efc4dbda76ca81de3a"},"cell_type":"code","source":"scaler=MaxAbsScaler()\nworld_food_data_features_scaled = scaler.fit_transform(world_food_data_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a242387058d04cea8b92853d73e4942a50077b18"},"cell_type":"code","source":"assert_is_not_none(world_food_data_features_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33cf8b1a3bc720dc3b3a45622368f04a545e6c34"},"cell_type":"code","source":"print(world_food_data_features_scaled)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe0294580459814bc013667ef666149d38a42ba3"},"cell_type":"markdown","source":"There are 71091 observations and 1934 features total so this takes a while to compute."},{"metadata":{"_uuid":"f238bd69634351092ed5f551f6cdf1ed9729b1b3"},"cell_type":"markdown","source":"## Step 3 - Training and test split and creating the model"},{"metadata":{"_uuid":"eb31dc32584485cd0ea196637c591e73bb59e8cb"},"cell_type":"markdown","source":"The next step would be to split the data into training and test sets. I've decided to go with a __70/30__ split, because if I did __80/20__ it would take a bit longer for the model to train."},{"metadata":{"trusted":true,"_uuid":"5fa67ae351422dcb7975bd59906a7cdaeff6a058"},"cell_type":"code","source":"features_train, features_test, target_train, target_test = train_test_split(\n    world_food_data_features_scaled, world_food_data_target, train_size = 0.7, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe68c78ac610118e4f6daafd546669368706f2b1"},"cell_type":"code","source":"print(\"Training data shapes: Features:{}, Labels:{}\".format(features_train.shape,target_train.shape))\nprint(\"Test data shapes: Features:{}, Labels:{}\".format(features_test.shape,target_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e37bdca4ec351159451ae0e903020ee6435b10e"},"cell_type":"markdown","source":"Now we have obtained our training and test set and we can apply a simple logistic regression model with no parameters and try to predict whether the test products contain additives or not."},{"metadata":{"trusted":true,"_uuid":"cc1158bcd4ec80e154123a3af4df1bb2a4576e57"},"cell_type":"code","source":"model=LogisticRegression()\nmodel.fit(features_train,target_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f147ceb373bc60030817665c212fa01994109d10"},"cell_type":"code","source":"assert_is_not_none(model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edc3acb06c35b28b61dd27dfedd9e156dad926db"},"cell_type":"markdown","source":"## Step 4 - Scoring the model"},{"metadata":{"_uuid":"b17515872bc8ff453e30f5e111e6363f88779a45"},"cell_type":"markdown","source":"The training is complete! Now we can see how well our model performed by printing the accuracy."},{"metadata":{"trusted":true,"_uuid":"c42412904e75ead734102537db67d5b0dbf3fd25"},"cell_type":"code","source":"score = model.score(features_test,target_test)\nprint(\"Additives prediction accuracy: {:.2f}\".format(score*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b274c131967a6725b76c3256df9ee742a010738"},"cell_type":"code","source":"assert_greater(score,0.5)\nassert_less_equal(score,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf084f622cb626c2644c0273a23331d5ba40a4e3"},"cell_type":"markdown","source":"The model has an overall accuracy of around __70%__. This isn't that bad considering that we used a simple regression model with no regularization applied.<br><br> This concludes our research. Now let's see what the results look like."},{"metadata":{"_uuid":"651ceb59eb95d29958b32d927ceae53430ebb537"},"cell_type":"markdown","source":"## Answers to the problem statements"},{"metadata":{"_uuid":"f376cf28b02b4dbcb02049a386cde952c3303ea9"},"cell_type":"markdown","source":"- __Which nutrient has the biggest impact on the nutrition grade?__<br><br>\n__Answer:__ Based on grouping and hypothesis testing the result was __fat__.<br><br>\n- __How do french meat and beverages compare to McDonalds meat and Starbucks beverages in terms of nutrients?__<br><br>\n__Answer:__ The french beverages proved to be a lot healhtier than Starbucks beverages, as they were mostly plant-based. The french meat proved to be less healthier than McDonalds meat in general.<br><br>\n- __Do other factors like food packaging, additive count and palm oil in the ingredients, have an impact on the nutrition value?__<br><br>\n__Answer:__ There seemed to be some indicators, but mostly these factors followed more or less the same patterns when compared to the nutrition value. So the answer here is no.<br><br>"},{"metadata":{"_uuid":"66c67b60a0e51ec63623aeb82994408ae6a472cb"},"cell_type":"markdown","source":"## Project conclusion"},{"metadata":{"_uuid":"5f6fd42e8d1f7ff5f777df82594487c79a79c66e"},"cell_type":"markdown","source":"In conclusion, I've made an attempt to make an in-depth research on the nutrition level of french products and what affects them by exploring the __Open Food Facts__ dataset and comparing it to the __Starbucks__ and __McDonalds__ datasets in terms of nutrtion value. I think the research was a success as I managed to answer the questions I laid out in the beginning of the project. I also hope that this project was of interest to the reader and that maybe it provided some helpful information on this topic."},{"metadata":{"_uuid":"1ff8131dae2d21aa361ce21fb6210fdcec2fd494"},"cell_type":"markdown","source":"## Resources"},{"metadata":{"_uuid":"2590595de85c39f01a5fe98866a54f2c548dfef2"},"cell_type":"markdown","source":"https://towardsdatascience.com/ - insights on Data Science and Machine Learning<br>\nhttps://www.webmd.com/diet - food nutrition statistics<br>\nhttps://www.foodnavigator.com/Article/2017/10/31/Nutri-Score-labelling-comes-into-force-in-France - information on the french nutrition scoring system<br>\nhttps://www.healthline.com/health/food-nutrition/ - information on the most crucial nutrients for the human body"},{"metadata":{"_uuid":"eb3739f21a5ad9fd34157f435e3046bc56da50fa"},"cell_type":"markdown","source":"## Communication and contacts"},{"metadata":{"_uuid":"e857b3a0d69a965e98147fe58af75eeaedf31ebb"},"cell_type":"markdown","source":"If you have any questions, criticism or suggestions feel free to email me at: dragonflareful@gmail.com<br>This project will be shared on my GitHub page: https://github.com/JadeBlue96 and it will be free to fork, use and manipulate to the public.<br>This project will also be submitted as a kernel at https://www.kaggle.com/openfoodfacts/world-food-facts/kernels.<br>I will also appreciate any type of feedback on this matter."},{"metadata":{"_uuid":"bd7009efc0a4547fa8743ceaada71b4987965d6b"},"cell_type":"markdown","source":"## Acknowledgements"},{"metadata":{"_uuid":"60a8c53fcdaed086ae55add3ac638a8ab48485cd"},"cell_type":"markdown","source":"Many thanks to Yordan Darakchiev (https://www.kaggle.com/iordan93) for his insights and examples on his Data Science course at SoftUni."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}