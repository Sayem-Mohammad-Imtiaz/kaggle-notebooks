{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"Apply the classification algorithms Naive Bayes, Logistic regression and K-Nearest neighbours on the attached imdb dataset of review texts and review sentiment.\n\nConvert the review text to Bag-of-Word (BOW) model with TF-IDF weights (text preprocessing should be applied first) and predict the review sentiment (positive or negative). Use label encoding to convert the sentiment feature to numerical values. The training/test split for the dataset should be 80/20.\n\nprint the accuracy score for each algorithm on the test dataset to find the most accurate model among the three created models."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as p\n\nds = p.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')[20000:25000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text preprocessing\n\nimport string\nfrom nltk.corpus import stopwords\nimport re\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nds['sentiment'].replace({'positive':1, 'negative':0}, inplace=True)\ndef conlow(txt):\n    return txt.lower()\nds['review'] = ds['review'].apply(conlow)\n\ndef delspec(txt):\n    a = ''\n    for c in txt:\n        if c.isalnum():\n            a = a + c\n        else:\n            a = a + ' '\n    return a\nds['review'] = ds['review'].apply(delspec)\n\nstopwords.words('english')\ndef delsw(txt):\n    a = []\n    for nsw in txt.split():\n        if nsw not in stopwords.words('english'):\n            a.append(nsw)\n    b = a[:]\n    a.clear()\n    return b\nds['review'] = ds['review'].apply(delsw)\n\nporstem = PorterStemmer()\nsv = []\ndef stemming(txt):\n    for s in txt:\n        sv.append(porstem.stem(s))\n    r = sv[:]\n    sv.clear()\n    return r\nds['review'] = ds['review'].apply(stemming)\ndef jb(li):\n    return \" \".join(li)   \nds['review'] = ds['review'].apply(jb)\n\nwordlem = WordNetLemmatizer()\ndef tokenize(str_input): \n    words = re.sub(r\"(?u)[^A-Za-z]\", \" \", str_input).lower().split(\" \")\n    words = [wordlem.lemmatize(word) for word in words if len(word)>2]\n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the review text to Bag-of-Word (BOW) model with TF-IDF weights\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(tokenizer=tokenize)\nvectors = vectorizer.fit_transform(ds['review'])\nX = p.DataFrame(vectors.toarray())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the training/test split for the dataset to 80/20\n\nfrom sklearn.model_selection import train_test_split\n\ny = ds.iloc[:,-1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes \n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\n\nmnb = MultinomialNB()\nmnb.fit(X_train,y_train)\ny_pred_mnb=mnb.predict(X_test)\nprint('Accuracy (Multinomial): ')\nprint(accuracy_score(y_test,y_pred_mnb))\n\ngnb = GaussianNB()\ngnb.fit(X_train,y_train)\ny_pred_gnb=gnb.predict(X_test)\nprint('Accuracy (Gaussian): ')\nprint(accuracy_score(y_test,y_pred_gnb))\n\n# Note: MultinomialNB works best with text data and gives better accuracy than GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression\n\nfrom sklearn import linear_model\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nC = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\nLRtrainAcc = []\nLRtestAcc = []\n\n\nfor param in C:\n    clf = linear_model.LogisticRegression(C=param)\n    clf.fit(X_train, y_train)\n    Y_predTrain = clf.predict(X_train)\n    Y_predTest = clf.predict(X_test)\n    LRtrainAcc.append(accuracy_score(y_train, Y_predTrain))\n    LRtestAcc.append(accuracy_score(y_test, Y_predTest))\n\nclf = linear_model.LogisticRegression(C=1.0)  \nprint('Accuracy (Logistic regression): ')\nprint(clf.fit(X_train, y_train).score(X_test,y_test))\nfig, ax1 = plt.subplots(1, 1, figsize=(12,6))\nax1.plot(C, LRtrainAcc, 'ro-', C, LRtestAcc,'bv--')\nax1.legend(['Training Accuracy','Test Accuracy'])\nax1.set_xlabel('C')\nax1.set_xscale('log')\nax1.set_ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Nearest neighbours\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nnumNeighbors = [1, 5, 10, 15, 20, 25, 30]\ntrainAcc = []\ntestAcc = []\n\nfor k in numNeighbors:\n    clf = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n    clf.fit(X_train, y_train)\n    Y_predTrain = clf.predict(X_train)\n    Y_predTest = clf.predict(X_test)\n    trainAcc.append(accuracy_score(y_train, Y_predTrain))\n    testAcc.append(accuracy_score(y_test, Y_predTest))\n\nclf = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\nclf.fit(X_train, y_train)\n\nprint('Accuracy (K-Nearest neighbors): ')\nprint(clf.score(X_test,y_test))\n\nplt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc,'bv--')\nplt.legend(['Training Accuracy','Test Accuracy'])\nplt.xlabel('Number of neighbors')\nplt.ylabel('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion:\n\nBased on the accuracy score for each algorithm, the most accurate model among the three created models is the Logistic regression algorithm model (accuracy = 0.853)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}