{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem statement"},{"metadata":{},"cell_type":"markdown","source":"Prepare a model for glass classification using KNN"},{"metadata":{},"cell_type":"markdown","source":"# Importing the libraries"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:20.820118Z","start_time":"2021-04-06T12:33:16.65809Z"},"trusted":true},"cell_type":"code","source":"from pandas import read_csv\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nimport seaborn as sn\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nimport numpy as np\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import RandomOverSampler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the dataset"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:20.852925Z","start_time":"2021-04-06T12:33:20.825412Z"},"trusted":true},"cell_type":"code","source":"glass = pd.read_csv(\"../input/glass/glass.csv\")","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:20.911774Z","start_time":"2021-04-06T12:33:20.858616Z"},"trusted":true},"cell_type":"code","source":"glass.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can just peek into few data points by using head function of pandas. By default, head function return top 5 values "},{"metadata":{},"cell_type":"markdown","source":"# Data Insights"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:20.927644Z","start_time":"2021-04-06T12:33:20.914839Z"},"trusted":true},"cell_type":"code","source":"glass.shape","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:20.959616Z","start_time":"2021-04-06T12:33:20.93069Z"},"trusted":true},"cell_type":"code","source":"glass.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations :-"},{"metadata":{},"cell_type":"markdown","source":"##### We could see that there are no null values in our dataset"},{"metadata":{},"cell_type":"raw","source":"Data Description:\n\nRI : refractive index\n\nNa: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 1-8)\n\nMg: Magnesium\n\nAI: Aluminum\n\nSi: Silicon\n\nK:Potassium\n\nCa: Calcium\n\nBa: Barium\n\nFe: Iron\n\nType: Type of glass: (class attribute)\n1 -- building_windows_float_processed\n 2 --building_windows_non_float_processed\n 3 --vehicle_windows_float_processed\n 4 --vehicle_windows_non_float_processed (none in this database)\n 5 --containers\n 6 --tableware\n 7 --headlamps\n \n "},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:20.983997Z","start_time":"2021-04-06T12:33:20.964341Z"},"trusted":true},"cell_type":"code","source":"dups = glass.duplicated()\nprint('Number of duplicate rows: %d' % dups.sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is one duplicate row, we will delete the duplicate row."},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:21.008489Z","start_time":"2021-04-06T12:33:20.987988Z"},"trusted":true},"cell_type":"code","source":"print('Number of rows before discarding duplicates = %d' % glass.shape[0])\n\nglass = glass.drop_duplicates()\nprint('Number of rows after discarding duplicates = %d' % glass.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary statistics"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:21.099041Z","start_time":"2021-04-06T12:33:21.014026Z"},"trusted":true},"cell_type":"code","source":"glass.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations :-"},{"metadata":{},"cell_type":"markdown","source":"1. We could see there is a lot of difference between 50% (percentile) value and the max value for K(Potassium) and Ca(Calcium). So there is a chance of having an outlier in these 2 columns. We will further check using boxplots\n2. We can see the min,max and standard deviations including 25,50 and 75 percentile values."},{"metadata":{},"cell_type":"markdown","source":"# Understanding the target variable"},{"metadata":{},"cell_type":"markdown","source":"##### Our main objective is to classify the type of glass based on weight percentage. We have a column Type which has the values from 1 to 7 which is to determine the glass type"},{"metadata":{},"cell_type":"markdown","source":"\n\n##### value_counts() method shows how many samples it is for the glass type. "},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:21.123007Z","start_time":"2021-04-06T12:33:21.106594Z"},"trusted":true},"cell_type":"code","source":"glass['Type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We can see the most frequent type of glasses are type 2 and type 1 in our data with the maximum value of 76 and 70. We can see the value counts of all the types. The data is imbalanced. The sets of data in which classes are not evenly distributed are called imbalanced datasets.The imbalance dataset can cause high/low accuracy value of the model due to a certain class."},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:21.454816Z","start_time":"2021-04-06T12:33:21.127034Z"},"trusted":true},"cell_type":"code","source":"sn.set(style = 'whitegrid', font_scale = 1.4)\nplt.subplots(figsize = (12,7))\nsn.countplot(x = 'Type', data = glass, palette = 'Pastel1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data visualization"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:21.794316Z","start_time":"2021-04-06T12:33:21.45698Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['RI'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:22.058916Z","start_time":"2021-04-06T12:33:21.79827Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Na'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:22.309049Z","start_time":"2021-04-06T12:33:22.064356Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Mg'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:22.527545Z","start_time":"2021-04-06T12:33:22.311649Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Al'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:22.736353Z","start_time":"2021-04-06T12:33:22.528885Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Si'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:23.014157Z","start_time":"2021-04-06T12:33:22.740694Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['K'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:23.230186Z","start_time":"2021-04-06T12:33:23.017481Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Ca'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:23.566841Z","start_time":"2021-04-06T12:33:23.233671Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Ba'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:23.870938Z","start_time":"2021-04-06T12:33:23.570556Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Fe'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:24.119794Z","start_time":"2021-04-06T12:33:23.872103Z"},"trusted":true},"cell_type":"code","source":"sn.boxplot(glass['Type'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations :-"},{"metadata":{},"cell_type":"markdown","source":"1. We can see there are outliers in all the columns except Mg. The Type column is also having outlier as we already saw the value counts are very less for type 7\n2. The median line for Mg and K is towards the upper quartile which means the data is skewed.We will check the distplots and confirm the same."},{"metadata":{},"cell_type":"markdown","source":"### Distplots"},{"metadata":{},"cell_type":"markdown","source":"Dist plots are used to check the distribution of the data, peak value(the observation having the highest frequecy) and check for skewness in the data"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:24.463832Z","start_time":"2021-04-06T12:33:24.124582Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['RI'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:24.889354Z","start_time":"2021-04-06T12:33:24.46885Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Na'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:25.314825Z","start_time":"2021-04-06T12:33:24.896406Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Mg'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:25.747311Z","start_time":"2021-04-06T12:33:25.31898Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Al'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:26.069767Z","start_time":"2021-04-06T12:33:25.750778Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Si'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:26.480357Z","start_time":"2021-04-06T12:33:26.074453Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['K'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:26.85326Z","start_time":"2021-04-06T12:33:26.484322Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Ca'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:27.062749Z","start_time":"2021-04-06T12:33:26.855321Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Ba'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:27.332866Z","start_time":"2021-04-06T12:33:27.065911Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Fe'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:27.637373Z","start_time":"2021-04-06T12:33:27.337547Z"},"trusted":true},"cell_type":"code","source":"sn.distplot(glass['Type'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations :-"},{"metadata":{},"cell_type":"markdown","source":"1. There is very high positive skewness in RI, Na, Al, K, Ca, Ba, Fe and Type\n2. There is negative skewness in Mg and Si"},{"metadata":{},"cell_type":"markdown","source":"# Heatmap"},{"metadata":{},"cell_type":"markdown","source":"##### Heatmap is a very effective technique to check the missing values in the dataset and to also understand if there is any correlation between the features of the data"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.031321Z","start_time":"2021-04-06T12:33:27.639395Z"},"trusted":true},"cell_type":"code","source":"Y = 'Type'\nX = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe']\n\n\nsn.heatmap(glass[X].isnull())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations :-"},{"metadata":{},"cell_type":"markdown","source":"1. We don't have any missing values in our dataset. If it was present, there would be a different colour shade appearing on the red background. "},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.353556Z","start_time":"2021-04-06T12:33:28.034591Z"},"trusted":true},"cell_type":"code","source":"sn.heatmap(glass[X].corr())","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.382647Z","start_time":"2021-04-06T12:33:28.355549Z"},"trusted":true},"cell_type":"code","source":"glass[X].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Separating feature data and Label data  and train-test split"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.40605Z","start_time":"2021-04-06T12:33:28.386228Z"},"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(glass.drop([\"Type\"], axis = 1),\n            columns=['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe'])\nY = glass.Type\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2, random_state = 30, stratify = Y)\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.453445Z","start_time":"2021-04-06T12:33:28.409674Z"},"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.480542Z","start_time":"2021-04-06T12:33:28.457437Z"},"trusted":true},"cell_type":"code","source":"Y_train","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.556791Z","start_time":"2021-04-06T12:33:28.48396Z"},"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.572199Z","start_time":"2021-04-06T12:33:28.561068Z"},"trusted":true},"cell_type":"code","source":"Y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grid Search for Algorithm Tuning"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.587927Z","start_time":"2021-04-06T12:33:28.576174Z"},"trusted":true},"cell_type":"code","source":"n_neighbors = np.array(range(1,40))\nparam_grid = dict(n_neighbors=n_neighbors)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:28.604312Z","start_time":"2021-04-06T12:33:28.591912Z"},"trusted":true},"cell_type":"code","source":"param_grid","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:31.603401Z","start_time":"2021-04-06T12:33:28.607882Z"},"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=10)\ngrid.fit(X_train, Y_train)\nprint(grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### After applying GridSearch, we got the best K (n_neighbors) value as 1, so we will be using the k= 1 for KNN Classifier algorithm"},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the CV results"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.214957Z","start_time":"2021-04-06T12:33:31.607958Z"},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \n%matplotlib inline\n# choose k between 1 to 41\nk_range = range(1, 41)\nk_scores = []\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, Y_train, cv=10)\n    k_scores.append(scores.mean())\n# plot to see clearly\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We could see that the model accuracy is very good for k values smaller than 5 and as the value increases the accuracy goes on decreasing"},{"metadata":{},"cell_type":"markdown","source":"# Using KNN Classifier for prediction"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.253678Z","start_time":"2021-04-06T12:33:35.218479Z"},"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors =1).fit(X_train,Y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We can see that the accuracy score which we have got for our model is 0.76 which is 76%. It is decent accuracy score. But the accuracy score can be misleading for imbalanced data. So we will use confusion matrix and classification report metrics further"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.269386Z","start_time":"2021-04-06T12:33:35.257666Z"},"trusted":true},"cell_type":"code","source":"confusion_matrix = confusion_matrix(Y_test,y_pred)\nprint (confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.298355Z","start_time":"2021-04-06T12:33:35.27336Z"},"trusted":true},"cell_type":"code","source":"print(classification_report(Y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### The precison,recall and f1 score for type 3 is very low. For type 1, the precison is low but recall and f1-score is good. Since the data is imbalanced, we can see the precision,recall values are affected. We will use oversamping technique as the data is very less and undersampling will cause data loss"},{"metadata":{},"cell_type":"markdown","source":"# Using Over Sampling for balancing the data"},{"metadata":{},"cell_type":"markdown","source":"##### We will use SMOTE over sampling technique for oversampling the data"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.320631Z","start_time":"2021-04-06T12:33:35.3015Z"},"trusted":true},"cell_type":"code","source":"sm = SMOTE(sampling_strategy = 'not majority', random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.364689Z","start_time":"2021-04-06T12:33:35.324734Z"},"trusted":true},"cell_type":"code","source":"x_resample, y_resample = sm.fit_resample(X, Y)\ny_df = pd.DataFrame(y_resample)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.39796Z","start_time":"2021-04-06T12:33:35.36743Z"},"trusted":true},"cell_type":"code","source":"y_df.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We could see the data is resampled now and all the type values are 76  now. Previously  type 1 and type 2  were having values 69 and 76 respectively, and other counts were very low. We will split the resampled data into training and test data and build a KNN model \n\n##### We will apply Standardization to make the scale free and to make data  consistent"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:35.433664Z","start_time":"2021-04-06T12:33:35.401166Z"},"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(x_resample, y_resample, test_size = .2, random_state = 40, stratify = y_resample)\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using GridSearch for Algorithm Tuning after resampling"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:37.227842Z","start_time":"2021-04-06T12:33:35.437179Z"},"trusted":true},"cell_type":"code","source":"n_neighbors = np.array(range(1,40))\nparam_grid = dict(n_neighbors=n_neighbors)\n\nmodel = KNeighborsClassifier()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=10)\ngrid.fit(X_train, Y_train)\nprint(grid.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### After applying GridSearch, we got the best K (n_neighbors) value as 1, so we will be using the k= 1 for KNN Classifier algorithm"},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the accuracy with different k values on sampled data"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:39.598332Z","start_time":"2021-04-06T12:33:37.230507Z"},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \n%matplotlib inline\n# choose k between 1 to 41\nk_range = range(1, 41)\nk_scores = []\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, Y_train, cv=10)\n    k_scores.append(scores.mean())\n# plot to see clearly\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### The accuracy value is high for low values of k (less than 5) and it descreases as we increase values of k"},{"metadata":{},"cell_type":"markdown","source":"# Using KNN with k=1 for model classification "},{"metadata":{},"cell_type":"markdown","source":"##### We had identified the k=1 is best parameter with GridSearch so using k as 1"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:39.629878Z","start_time":"2021-04-06T12:33:39.600328Z"},"trusted":true},"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors =1).fit(X_train,Y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### The accuracy is 0.89 which is 89% after applying sampling. But we will use confusion matrix and classification report to further check our accuracy"},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:39.645026Z","start_time":"2021-04-06T12:33:39.633041Z"},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(Y_test,y_pred)\nconfusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2021-04-06T12:33:39.67018Z","start_time":"2021-04-06T12:33:39.648022Z"},"trusted":true},"cell_type":"code","source":"print(classification_report(Y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### We could see the precision and recall values are more than 0.75 for all the 7 types which is very decent score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}