{"cells":[{"metadata":{},"cell_type":"markdown","source":"[![General Assembly Logo](https://camo.githubusercontent.com/1a91b05b8f4d44b5bbfb83abac2b0996d8e26c92/687474703a2f2f692e696d6775722e636f6d2f6b6538555354712e706e67)](https://generalassemb.ly/education/web-development-immersive)\n![Misk Logo](https://i.ibb.co/KmXhJbm/Webp-net-resizeimage-1.png)"},{"metadata":{},"cell_type":"markdown","source":"# Project_4 ___ Predicting the Microsoft Stock Market Using Time-Series Models; namely, Arima, Recurrent Neural Network (RNN) and FaceBook Prophet Models\n\n\n\n**Team Members:** Ibrahim Rizqallah Alzahrani - Abdulaziz Alsulami\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem Statement\n\n#### We aim to examine the best prediction model that we would be to use in predicting future stockmmarket (In our task, predicting the Microsoft stock market for ahead three months)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nnp.set_printoptions(precision=4)\nsns.set(font_scale=1.5)\nplt.style.use('fivethirtyeight')\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# this will filter out a lot of future warnings from statsmodels\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Loading autocorrelation ACF,PACF,plots, and seasonal decompose\n\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom pmdarima import auto_arima\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading data as dataframe\ndf = pd.read_csv('../input/microsoft-stock-market-2001-2021/MSFT_Stock.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying 1st five rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying number of rows and columns\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying names, count of rows, number of null values and data types of features\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying statistics information\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the first four features have nearly same value of mean, std, min, percentil range except max value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# resorting data frame as ascending according to date\n# displaying 1st five rows\ndf.sort_index(inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying last five rows\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting and displaying corrlation of features with values\nplt.figure(figsize=(12,6))\nsns.heatmap(\n    df.corr(), \n    annot=True,\n    )\nplt.title('Features Correlation');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Each feature has a perfect positive correlation with other features excpet volume has a low negative corrlation with other features"},{"metadata":{},"cell_type":"markdown","source":"** bold textMinimum and Maximum value of all features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating for loop to print the minimum stock price for each feature and number of stocks with date\nfor col in df.columns:\n    min_val = df[col].min()\n    print(df[df[col] == df[col].min()][col])\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In Mach 2009 all stock prices dropped at the low level except stock volume were at the low level in July 2020."},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating for loop to print the minimum stock price for each feature and number of stocks with date\nfor col in df.columns:\n    max_val = df[col].max()\n    print(df[df[col] == df[col].max()][col])\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# In January 2021 all stock prices rocket jump at the high level except sotck volume were at the high level in April 2006."},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(12, 12), constrained_layout=True) \nax = ax.ravel()\n\ncolors = ['red', 'blue', 'green', 'yellow']\ncols = [col for col in df.columns if col != 'volume']\n\nfor i in range(len(cols)):\n    df.iloc[:,i].plot(ax=ax[i], color=colors[i], )\n    ax[i].set(ylabel=cols[i])\n    ax[i].set_xticklabels(ax[i].get_xticklabels(),rotation=20)\n    ax[i].set_title(f'{cols[i]} size from 2002 unitl 2021');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We can see after 2016, there was a rocket jump in stock prices for all features. Befor 2016 most stock prices were less than 50, in 2009 stock prices were at the low level."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\ndf.iloc[:,-1].plot()\nplt.title('stock volume per from 2002 until 2021');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We can see stocks volume were less than half 300 Million even 2006, then it will jump at the high level to reach around 600 Million then dropped and still at same level less than 300 Milliion "},{"metadata":{},"cell_type":"markdown","source":"### Model\n**Autoregressive Integrated Moving Average aka ARIMA**\n\nARIMA, or Autoregressive Independent Moving Average is actually a combination of 3 models:\n* <strong>AR(p)</strong> Autoregression.\n* <strong>I(d)</strong> Integration - uses differencing of observations (subtracting an observation from an observation at the previous time step) in order to make the time series stationary\n* <strong>MA(q)</strong> Moving Average.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting index (date) to date time type\ndf.index = pd.to_datetime(df.index)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resampling to 4 Quarter (season)\ndf.resample('Q').mean().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = df.resample('Q').mean()[['close']]\n\nnew_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Visually examine the close rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['close'].plot(figsize=(12, 5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Do Time Series Decomposition to check for Seasonality"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = seasonal_decompose(new_df['close'],freq=30)\nresult.plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test for Stationarity\n\n#### if not, determine the d value (differencing)\n\n#### 1. Check if stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def autocorr_plots(y, lags=None):\n    fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n    plot_acf(y, lags=lags, ax=ax[0])\n    plot_pacf(y, lags=lags, ax=ax[1])\n    return fig, ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adf_test(new_df['close'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  our data is not stationary"},{"metadata":{},"cell_type":"markdown","source":"#### 2. Do differencing until we make our data stationary"},{"metadata":{},"cell_type":"markdown","source":"[Why would we difference?](https://otexts.com/fpp2/stationarity.html) Well, there is one assumption that is **required** for nearly every time series model: **stationarity**.\n- If our time series is stationary, then we do not need to difference and let $d=0$.\n- If our time series is not stationary, then we difference either once ($d=1$) or twice ($d=2$). Differenced data often is stationary, so we difference our data, then model that!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# d = 1\nadf_test(new_df['close'].diff().dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# d = 2\nadf_test(new_df['close'].diff().diff().dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# d = 3\nadf_test(new_df['close'].diff().diff().diff().dropna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After three times of differenced our data get a stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(ncols=2,figsize=(16,8))\n\nnew_df['close'].plot(lw=2.5, ax=ax[0])\nnew_df['close'].diff().diff().diff().dropna().plot(lw=2.5, ax=ax[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Create ACF and PACF plots\n#### Determine the p and q values (Manually)"},{"metadata":{},"cell_type":"markdown","source":"#### 1. Create ACF and PACF plots on our differenced data"},{"metadata":{"trusted":true},"cell_type":"code","source":"autocorr_plots(new_df['close'].diff().diff().diff().dropna(), lags=20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Using Auto-ARIMA to determine (p,d,q)"},{"metadata":{"trusted":true},"cell_type":"code","source":"auto_fit = auto_arima(new_df['close'], start_p=0, start_q=0,\n                          max_p=2, max_q=2, \n                          m=1,                     # m is used for seasonality, m=1 means no seasonality (cover this later)\n                          seasonal=False,          # We do not want seasonality here\n                          d=None,  # The order of first-differencing. If None (by default), automatically be selected\n                          trace=True,\n                          error_action='ignore',   # we don't want to know if an order does not work\n                          suppress_warnings=True,  # we don't want convergence warnings\n                          stepwise=True)           # set to stepwise\n\nauto_fit.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**What was the values of (p,d,q) suggested by auto-arima?**\n\nAs you can see the output of the summery, is suggests ARIMA(2,1,1) as the best based on AIC/BIC lowest values"},{"metadata":{},"cell_type":"markdown","source":"### 5. Fit ARIMA model\n#### 1. Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# See what are the ranges of our data\nnew_df.index.max(), new_df.index.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = new_df.loc[:'2019']\ndf_test = new_df.loc['2019':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the train and test sets on the axis ax\nfig, ax = plt.subplots(figsize=(12,6))\ndf_train.plot(ax=ax)\ndf_test.plot(ax=ax)\nax.legend(labels=['Train Data','Test Data']);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Fitting ARIMA models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nmodel = ARIMA(df_train,order=(2,1,1))\nres = model.fit()\nres.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot our fitted values for train data\n\ndf_train.diff().diff().diff().dropna().plot(legend = True,figsize=(12,8))\nres.fittedvalues.rename(\"Train Fitted Values\").plot(legend = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Predict values on the test dataset¶"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot our prediction for test data\n\n\nstart = len(df_train) \nend = len(df_train) + len(df_test) -1\n  \n# Predictions for the test set \n\n# Notice below typ='level' , it will predict the levels of the original variables (undifferenced)\npredictions = res.predict(start, end,typ ='levels',dynamic=False) # .rename(\"Test predicted\")  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare predictions to expected values\nfor i in range(len(predictions)):\n    print(f\"predicted={predictions[i]:<4.4}, expected={df_test['close'][i]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot predictions and actual test values \ntitle = 'Predicted test vs. Real test Unemployment Rate'\nax=predictions.plot(legend = True,figsize=(12,8),title=title) \ndf_test.plot(legend = True,ax=ax);\nax.legend(labels=['Test predicted','Test Data']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Evaluate the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tools.eval_measures import mse\nfrom statsmodels.tools.eval_measures import rmse\n\nerror1 = mse(df_test['close'], predictions)\nprint(f'ARIMA(2,1,1) MSE Error: {error1:11.10}')\n\nerror2 = rmse(df_test['close'], predictions)\nprint(f'ARIMA(2,1,1) RMSE Error: {error2:11.10}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df['close'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Forcast the Future"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do a forcast for 1 Quarter (3 months) (2021Q1 to 2021Q2)\nfcast = res.predict(start=len(df_test),end=len(df_test)+1,typ='levels',dynamic=False).rename('ARIMA(2,1,1) Forecast')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# starting and end points for forecasting for our previous model\n\nstart_1 = 3\nend_1 = len(df_train)+len(df_test)+1\nfig, ax = plt.subplots(figsize=(12,8)) \nres.plot_predict(start=start_1, end=end_1, ax =ax,)\nplt.legend(loc=2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recurrent Neural Network (LSTM Model)\n\n### It is worthy noted that LTSM model is sensitive to the scale of data; therefore, we will apply MinMax scaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom keras.models import Sequential\nfrom keras.layers import Dense,  LSTM\nfrom keras import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm= df.copy()\nlstm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm.reset_index(inplace=True)\nlstm.rename(columns={'index': 'date'}, inplace=True)\nlstm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The value that we want to predict is the 4th column (Close). Defining Y as this column\nL = len(lstm)\nY = lstm.iloc[:,4]\nY= np.array(Y)\nY= Y.reshape(-1,1)\nplt.plot(Y)\nplt.title('Distribution Closing Price for MS-Stock Market')\nplt.show(block= False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will use shifted versions of the Y column this is to say use 3 delays of Y as inputs to predict the output of our data.\nX1= Y[0:L-3,:]\nX2=Y[1:L-2,:]\nX3=Y[2:L-1,:]\nY = Y[3:L,:]\nX= np.concatenate([X1,X2,X3],axis=1)\nprint(f'X shape is {X.shape}')\nprint(f'Y shape is {Y.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n#standardising our data\nscaler = MinMaxScaler()\nscaler.fit(X)\nX = scaler.transform(X)\nscaler1 = MinMaxScaler()\nscaler1.fit(Y)\nY = scaler1.transform(Y)\nX= np.reshape(X, (X.shape[0],1,X.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the dataset into train and test sets\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let’s now define training and test sets for our model\n#4907 => 4997-90 => 1Q\n\nX_train = X[:4907,:,:]\nX_test = X[4907:,:,:]\nY_train = Y[:4907,:]\nY_test = Y[4907:,:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train), len(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 units is chosen, hyperbolic tangent for the activation. \n# input shape of (1,3) because we have 3 delays (the X1, X2 and X3 that we defined before). \n# hard sigmoid is used for reccurent activation.\n\nmodel = Sequential()\nmodel.add(LSTM(10,activation = 'tanh',input_shape = (1,3),recurrent_activation= 'hard_sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instatiating an output layer to the model. We use only one output for our model.\n\nmodel.add(Dense(1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Our neural network is created, it is now to be compiled. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss= 'mean_squared_error',optimizer = 'rmsprop', metrics=[metrics.mse])\nmodel.fit(X_train,Y_train,epochs=10,verbose=2)\nPredict = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.plot(Y_test,label = 'Test')\nplt.plot(Predict, label = 'Prediction')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(Y_test, Predict)\nprint('MSE Performance Metrics scores of RNN_LSTM model for Closing Price of MS Stock Market is:    ', mse)\nrmse = np.sqrt(mse)\nprint('RMSE Performance Metrics scores of RNN_LSTM model for Closing Price of MS Stock Market is:    ',rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scale back to the original scale"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = scaler1.inverse_transform(Y_train)\nY_train = pd.DataFrame(Y_train)\nY_train.index = pd.to_datetime(df.iloc[3:4910,0])\nY_test = scaler1.inverse_transform(Y_test)\nY_test = pd.DataFrame(Y_test)\nY_test.index = pd.to_datetime(df.iloc[4910:,0])\nPredict = model.predict(X_test)\nPredict = scaler1.inverse_transform(Predict)\nPredict = pd.DataFrame(Predict)\nPredict.index=pd.to_datetime(df.iloc[4910:,0])\nplt.figure(figsize=(15,10))\nplt.plot(Y_test)\nplt.plot(Predict)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating using Facebook Prophet model"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install fbprophet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pystan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation\nfrom fbprophet.diagnostics import performance_metrics\nfrom fbprophet.plot import plot_cross_validation_metric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/microsoft-stock-market-2001-2021/MSFT_Stock.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(inplace=True)\ndf.rename(columns={'index': 'date'}, inplace=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import DataFrame\nprophet= pd.DataFrame()\n\nprophet['date']= df.date\nprophet['close']= df.close\n\nprophet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet.columns=['ds','y']\n\nprophet.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet.dropna(inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet['ds']=pd.to_datetime(prophet.ds)\nprophet.plot(x='ds',y='y')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data into train and test to start running our model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet_train=prophet[:4820]\nprophet_test=prophet[4820:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Forecasting Closing Price of MS Stock Marketwith Prophet (Base model)\nGenerating a Quarter ahead forecast of MS Stock Marketwith using Prophet."},{"metadata":{"trusted":true},"cell_type":"code","source":"m=Prophet(seasonality_mode='multiplicative')\nm.fit(prophet_train)\nfuture=m.make_future_dataframe(periods=3,freq='MS')\nforecast=m.predict(prophet_test)\nforecast.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**yhat:** yhat is a notation traditionally used to represent the predicted values of a value y)\n\n**yhat_lower:** the lower bound of our forecasts\n\n**yhat_upper:** the upper bound of our forecasts"},{"metadata":{"trusted":true},"cell_type":"code","source":"m.plot(forecast)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = m.plot_components(forecast)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import plot_plotly, plot_components_plotly\n\nplot_plotly(m, forecast)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_components_plotly(m, forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.plot(forecast)\nax=forecast.plot(x='ds',y='yhat',legend=True,label='predictions',figsize=(12,8))\nprophet_test.plot(x='ds',y='y',legend=True,label='True Test Data',ax=ax,xlim=('2001-03-16', '2021-01-29'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validating the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initial training period.\ninitial= 2*365\ninitial= str(initial)+' days'\n\n#Period length that we perform the cross validation for.\nperiod= 2*90\nperiod=str(period)+' days'\n\n#Horizon of prediction essentially for each fold.\nhorizon = 90\nhorizon=str(horizon)+' days'\nprophet_cv=cross_validation(m,initial=initial,period=period,\nhorizon=horizon)\n\n# Performance Metrics of fb_cv\nperformance_metrics(prophet_cv)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_cross_validation_metric(prophet_cv,'rmse');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# changing trend points\nfrom fbprophet.plot import add_changepoints_to_plot\n\nfig=m.plot(forecast)\na=add_changepoints_to_plot(fig.gca(),m,forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(prophet_cv.y, prophet_cv.yhat)\nprint('MSE Performance Metrics scores of FaceBook Prophet model for Closing Price of MS Stock Market is:    ', mse)\nrmse = np.sqrt(mse)\nprint('RMSE Performance Metrics scores of FaceBook Prophet model for Closing Price of MS Stock Market is:    ',rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# As it was demonistrated that RNN Model has the best performance amongst the others; thus, the forecasting step is going to be based on RNN as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/microsoft-stock-market-2001-2021/MSFT_Stock.csv', index_col=0)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import TimeseriesGenerator\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\ntrain_RNN = pd.DataFrame(df.iloc[:,3])\n\n\nscaler.fit(train_RNN)\nscaled_train_RNN = scaler.transform(train_RNN)\n\nn_input = 4907\nn_features = 1\ngenerator = TimeseriesGenerator(scaled_train_RNN, scaled_train_RNN, length=n_input, batch_size=1)\n\n# define model\nmodel_RNN = Sequential()\nmodel_RNN.add(LSTM(10, activation='relu', input_shape=(n_input, n_features)))\nmodel_RNN.add(Dense(1))\nmodel_RNN.compile(optimizer='adam', loss='mse')\n# fit model\nmodel_RNN.fit_generator(generator,epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_RNN = []\n\neval_RNN = scaled_train_RNN[-n_input:]\ncurrent_RNN = eval_RNN.reshape((1, n_input, n_features))\n\nfor i in range(90):\n    current_pred_RNN = model_RNN.predict(current_RNN)[0]\n    forecast_RNN.append(current_pred_RNN) \n    current_RNN = np.append(current_RNN[:,1:,:],[[current_pred_RNN]],axis=1)\n\nforecast_RNN= scaler.inverse_transform(forecast_RNN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_RNN = pd.DataFrame({'Forecast':forecast_RNN.flatten()})\nforecast_RNN.index = np.arange('2021-01-30',90,dtype='datetime64[D]')\nforecast_RNN.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(dpi=120,figsize = (14,6))\nax = plt.axes()\nax.set(xlabel = 'Date',ylabel = 'Price',title = 'Forecast : (30-01-2021) to (30-03-2021)')\nforecast_RNN.plot(label = 'Forecast',ax=ax,color='red',lw=2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The RMSE scores of each of the appiled models as follow:**\n\n- ARIMA(2,1,1): RMSE Score 25.83997931\n- FaceBook Prophet: RMSE Score 7.461\n- Recurrent Neural Network (LSTM Model): RMSE Score 0.025\n\n#### In conclusion, RNN model predicts better than the other models; and, the closing stock price of Microsoft Market is expected to experience dramatic drops in the coming three months."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}