{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model, Sequential\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport time\nimport cv2 as cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom IPython.core.display import display, HTML","metadata":{"papermill":{"duration":5.656903,"end_time":"2021-05-22T20:19:43.076436","exception":false,"start_time":"2021-05-22T20:19:37.419533","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:02.111348Z","iopub.execute_input":"2021-05-27T03:27:02.111834Z","iopub.status.idle":"2021-05-27T03:27:08.12738Z","shell.execute_reply.started":"2021-05-27T03:27:02.111711Z","shell.execute_reply":"2021-05-27T03:27:08.126427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### input an image and get the shape","metadata":{"execution":{"iopub.status.busy":"2021-05-27T03:27:08.132129Z","iopub.execute_input":"2021-05-27T03:27:08.132482Z","iopub.status.idle":"2021-05-27T03:27:08.14156Z","shell.execute_reply.started":"2021-05-27T03:27:08.132445Z","shell.execute_reply":"2021-05-27T03:27:08.140484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpath=r'../input/eurosatland/archive (1)/2750/AnnualCrop/AnnualCrop_1.jpg'\nimg=plt.imread(fpath)\nprint (img.shape)\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T03:27:08.146478Z","iopub.execute_input":"2021-05-27T03:27:08.149321Z","iopub.status.idle":"2021-05-27T03:27:08.443578Z","shell.execute_reply.started":"2021-05-27T03:27:08.149279Z","shell.execute_reply":"2021-05-27T03:27:08.442743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### read in cvs files","metadata":{"papermill":{"duration":0.020034,"end_time":"2021-05-22T20:19:43.538967","exception":false,"start_time":"2021-05-22T20:19:43.518933","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df=pd.read_csv(r'../input/eurosatland/train (1).csv')\ntest_df=pd.read_csv(r'../input/eurosatland/train (1).csv')\nvalid_df=pd.read_csv(r'../input/eurosatland/validation.csv')\nprint (train_df.head())\nprint (train_df['Label'].value_counts())\nprint (test_df.head())\nprint (test_df['Label'].value_counts())\nprint (valid_df.head())\nprint(valid_df['Label'].value_counts())\n                    ","metadata":{"execution":{"iopub.status.busy":"2021-05-27T03:27:08.444876Z","iopub.execute_input":"2021-05-27T03:27:08.445209Z","iopub.status.idle":"2021-05-27T03:27:08.544912Z","shell.execute_reply.started":"2021-05-27T03:27:08.445173Z","shell.execute_reply":"2021-05-27T03:27:08.544098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### combine train, test valid dfs into one df so we can select our own train, test and valid datasets","metadata":{}},{"cell_type":"code","source":"df=pd.concat([train_df, test_df, valid_df],  axis=0).reset_index(drop=True)\nprint (df.head())\nbalance=df['Label'].value_counts()\nprint (balance)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T03:27:08.548769Z","iopub.execute_input":"2021-05-27T03:27:08.549062Z","iopub.status.idle":"2021-05-27T03:27:08.568468Z","shell.execute_reply.started":"2021-05-27T03:27:08.549034Z","shell.execute_reply":"2021-05-27T03:27:08.567498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create train, test and valid dataframes","metadata":{}},{"cell_type":"code","source":"train_split=.9\nvalid_split=.05\ndummy_split=valid_split/(1-train_split)\ntrain_df, dummy_df=train_test_split(df, train_size=train_split, shuffle=True, random_state=123)\nvalid_df, test_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\nprint('length train_df: ', len(train_df), '  length test_df: ', len(test_df), '  length valid_df: ', len(valid_df))\nbalance=train_df['Label'].value_counts()\nprint (balance)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T03:27:08.570674Z","iopub.execute_input":"2021-05-27T03:27:08.57103Z","iopub.status.idle":"2021-05-27T03:27:08.589979Z","shell.execute_reply.started":"2021-05-27T03:27:08.570993Z","shell.execute_reply":"2021-05-27T03:27:08.58885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### dataset is not balanced. Balance by having 2839 samples for each class","metadata":{}},{"cell_type":"code","source":"size=2839 # set number of samples for each class\nsamples=[]\ngroup=train_df.groupby('Label')\nfor label in train_df['Label'].unique():\n    Lgroup=group.get_group(label)\n    count=int(Lgroup['Label'].value_counts())   \n    sample=Lgroup.sample(size, axis=0)\n    samples.append(sample) \ntrain_df=pd.concat(samples, axis=0).reset_index(drop=True)\nprint (len(df))     \nprint (train_df['Label'].value_counts())  ","metadata":{"execution":{"iopub.status.busy":"2021-05-27T03:27:08.591639Z","iopub.execute_input":"2021-05-27T03:27:08.592038Z","iopub.status.idle":"2021-05-27T03:27:08.634725Z","shell.execute_reply.started":"2021-05-27T03:27:08.591999Z","shell.execute_reply":"2021-05-27T03:27:08.633597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create train, test, valid  generators","metadata":{"papermill":{"duration":0.021701,"end_time":"2021-05-22T20:19:58.277383","exception":false,"start_time":"2021-05-22T20:19:58.255682","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sdir=r'../input/eurosatland/archive (1)/2750'\ntrain_df['Label']=train_df['Label'].astype(str)\ntest_df['Label']=test_df['Label'].astype(str)\nvalid_df['Label']=valid_df['Label'].astype(str)\nheight=64\nwidth=64\nchannels=3\nbatch_size=40\nimg_shape=(height, width, channels)\nimg_size=(height, width)\nlength=len(test_df)\ntest_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \ntest_steps=int(length/test_batch_size)\nprint ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\ndef scalar(img):\n    return img/127.5-1  # scale pixel between -1 and +1\ngen=ImageDataGenerator()\nprint('for the train generator')\n\ntrain_gen=gen.flow_from_dataframe( train_df,sdir, x_col='Filename', y_col='Label', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\nprint('for the test generator')\ntest_gen=gen.flow_from_dataframe( test_df, sdir, x_col='Filename', y_col='Label', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\nprint('for the validation generator')\nvalid_gen=gen.flow_from_dataframe( valid_df, sdir, x_col='Filename', y_col='Label', target_size=img_size, class_mode='categorical',\n                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\nclasses=list(train_gen.class_indices.keys())\nclass_count=len(classes)\ntrain_steps=int(len(train_gen.labels)/batch_size)","metadata":{"papermill":{"duration":19.110969,"end_time":"2021-05-22T20:20:17.409329","exception":false,"start_time":"2021-05-22T20:19:58.29836","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:08.636151Z","iopub.execute_input":"2021-05-27T03:27:08.636661Z","iopub.status.idle":"2021-05-27T03:27:36.318548Z","shell.execute_reply.started":"2021-05-27T03:27:08.636624Z","shell.execute_reply":"2021-05-27T03:27:36.317643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create function to show some image examples","metadata":{"papermill":{"duration":0.021802,"end_time":"2021-05-22T20:20:17.499034","exception":false,"start_time":"2021-05-22T20:20:17.477232","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def show_image_samples(gen ):\n    test_dict=test_gen.class_indices\n    classes=list(test_dict.keys())    \n    images,labels=next(gen) # get a sample batch from the generator \n    plt.figure(figsize=(20, 20))\n    length=len(labels)\n    if length<25:   #show maximum of 25 images\n        r=length\n    else:\n        r=25\n    for i in range(r):\n        plt.subplot(5, 5, i + 1)\n        image=images[i]/255 # scale images between 0 and 1 becaue pre-processor set them between -1 and +1\n        plt.imshow(image)\n        index=np.argmax(labels[i])\n        class_name=classes[index]\n        plt.title(class_name, color='blue', fontsize=16)\n        plt.axis('off')\n    plt.show()","metadata":{"papermill":{"duration":0.031102,"end_time":"2021-05-22T20:20:17.552184","exception":false,"start_time":"2021-05-22T20:20:17.521082","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:36.319742Z","iopub.execute_input":"2021-05-27T03:27:36.320254Z","iopub.status.idle":"2021-05-27T03:27:36.328428Z","shell.execute_reply.started":"2021-05-27T03:27:36.320215Z","shell.execute_reply":"2021-05-27T03:27:36.327465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image_samples(train_gen)","metadata":{"papermill":{"duration":2.886823,"end_time":"2021-05-22T20:20:20.461058","exception":false,"start_time":"2021-05-22T20:20:17.574235","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:36.329709Z","iopub.execute_input":"2021-05-27T03:27:36.33015Z","iopub.status.idle":"2021-05-27T03:27:38.937576Z","shell.execute_reply.started":"2021-05-27T03:27:36.330114Z","shell.execute_reply":"2021-05-27T03:27:38.936524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### define function to print text in RGB foreground and background colors","metadata":{"papermill":{"duration":0.04529,"end_time":"2021-05-22T20:20:20.552266","exception":false,"start_time":"2021-05-22T20:20:20.506976","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True) # returns default print color to back to black\n    return","metadata":{"papermill":{"duration":0.054318,"end_time":"2021-05-22T20:20:20.65136","exception":false,"start_time":"2021-05-22T20:20:20.597042","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:38.938805Z","iopub.execute_input":"2021-05-27T03:27:38.939116Z","iopub.status.idle":"2021-05-27T03:27:38.946Z","shell.execute_reply.started":"2021-05-27T03:27:38.939086Z","shell.execute_reply":"2021-05-27T03:27:38.944756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create the model","metadata":{"papermill":{"duration":0.044545,"end_time":"2021-05-22T20:20:20.74029","exception":false,"start_time":"2021-05-22T20:20:20.695745","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_name='EfficientNetB1'\nbase_model=tf.keras.applications.EfficientNetB1(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \nx=base_model.output\nx=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.45, seed=123)(x)        \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=base_model.input, outputs=output)\nmodel.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy']) ","metadata":{"papermill":{"duration":7.854035,"end_time":"2021-05-22T20:20:28.639272","exception":false,"start_time":"2021-05-22T20:20:20.785237","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:38.947487Z","iopub.execute_input":"2021-05-27T03:27:38.948069Z","iopub.status.idle":"2021-05-27T03:27:44.978348Z","shell.execute_reply.started":"2021-05-27T03:27:38.948032Z","shell.execute_reply":"2021-05-27T03:27:44.977352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create a subclass of callbacks to control learning rate and print training results for each epoch","metadata":{"papermill":{"duration":0.050636,"end_time":"2021-05-22T20:20:28.77676","exception":false,"start_time":"2021-05-22T20:20:28.726124","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class LRA(keras.callbacks.Callback):\n    reset=False\n    count=0\n    stop_count=0\n    tepochs=0\n    def __init__(self,model, patience,stop_patience, threshold, factor, dwell, model_name, freeze,batches, initial_epoch):\n        super(LRA, self).__init__()\n        self.model=model\n        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n        self.stop_patience=stop_patience\n        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n        self.factor=factor # factor by which to reduce the learning rate\n        self.dwell=dwell\n        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it in self.lr\n        self.highest_tracc=0.0 # set highest training accuracy to 0\n        self.lowest_vloss=np.inf # set lowest validation loss to infinity\n        #self.count=0 # initialize counter that counts epochs with no improvement\n        #self.stop_count=0 # initialize counter that counts how manytimes lr has been adjustd with no improvement  \n        self.initial_epoch=initial_epoch \n        self.batches=batches\n        #self.epochs=epochs\n        best_weights=self.model.get_weights() # set a class vaiable so weights can be loaded after training is completed        \n        msg=' '\n        if freeze==True:\n            msgs=f' Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback'\n        else:\n            msgs=f' Starting training using base model { model_name} training all layers '            \n        print_in_color (msgs, (244, 252, 3), (55,65,80)) \n    def on_train_begin(self, logs=None):\n        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy',\n                                                                                              'V_loss','V_acc', 'LR', 'Next LR', 'Monitor', 'Duration', 'Batch')\n        print_in_color(msg, (244,252,3), (55,65,80)) \n        \n    def on_train_batch_begin(self, batch, logs=None):\n        msg='{0:83s}{1:4s}of {2:5s}'.format(' ', str(batch), str(self.batches))\n        print(msg, '\\r', end='') # prints over on the same line to show running batch count\n        \n        \n    def on_epoch_begin(self,epoch, logs=None):\n        self.now= time.time()\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        later=time.time()\n        duration=later-self.now \n        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n        current_lr=lr\n        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n        acc=logs.get('accuracy')  # get training accuracy \n        v_acc=logs.get('val_accuracy')\n        loss=logs.get('loss')\n        #print ( '\\n',v_loss, self.lowest_vloss, acc, self.highest_tracc)\n        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n            monitor='accuracy'\n            if acc>self.highest_tracc: # training accuracy improved in the epoch                \n                self.highest_tracc=acc # set new highest training accuracy\n                LRA.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n                self.count=0 # set count to 0 since training accuracy improved\n                self.stop_count=0 # set stop counter to 0\n                if v_loss<self.lowest_vloss:\n                    self.lowest_vloss=v_loss\n                color= (0,255,0)\n                self.lr=lr\n            else: \n                # training accuracy did not improve check if this has happened for patience number of epochs\n                # if so adjust learning rate\n                if self.count>=self.patience -1:\n                    color=(245, 170, 66)\n                    self.lr= lr* self.factor # adjust the learning by factor\n                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n                    self.count=0 # reset the count to 0\n                    self.stop_count=self.stop_count + 1\n                    if self.dwell:\n                        self.model.set_weights(LRA.best_weights) # return to better point in N space                        \n                    else:\n                        if v_loss<self.lowest_vloss:\n                            self.lowest_vloss=v_loss                                    \n                else:\n                    self.count=self.count +1 # increment patience counter                    \n        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n            monitor='val_loss'\n            if v_loss< self.lowest_vloss: # check if the validation loss improved \n                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n                LRA.best_weights=self.model.get_weights() # validation loss improved so save the weights\n                self.count=0 # reset count since validation loss improved  \n                self.stop_count=0  \n                color=(0,255,0)\n                self.lr=lr\n            else: # validation loss did not improve\n                if self.count>=self.patience-1:\n                    color=(245, 170, 66)\n                    self.lr=self.lr * self.factor # adjust the learning rate                    \n                    self.stop_count=self.stop_count + 1 # increment stop counter because lr was adjusted \n                    self.count=0 # reset counter\n                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n                    if self.dwell:\n                        self.model.set_weights(LRA.best_weights) # return to better point in N space\n                else: \n                    self.count =self.count +1 # increment the patience counter                    \n                if acc>self.highest_tracc:\n                    self.highest_tracc= acc\n        msg=f'{str(epoch+1):^3s}/{str(LRA.tepochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}'\n        print_in_color (msg,color, (55,65,80))\n        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n            print_in_color(msg, (0,255,0), (55,65,80))\n            self.model.stop_training = True # stop training","metadata":{"papermill":{"duration":0.075619,"end_time":"2021-05-22T20:20:28.903331","exception":false,"start_time":"2021-05-22T20:20:28.827712","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:27:44.979609Z","iopub.execute_input":"2021-05-27T03:27:44.979974Z","iopub.status.idle":"2021-05-27T03:27:45.005263Z","shell.execute_reply.started":"2021-05-27T03:27:44.979939Z","shell.execute_reply":"2021-05-27T03:27:45.004326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### instantiate the custom callback and train the model","metadata":{"papermill":{"duration":0.050709,"end_time":"2021-05-22T20:20:29.004405","exception":false,"start_time":"2021-05-22T20:20:28.953696","status":"completed"},"tags":[]}},{"cell_type":"code","source":"epochs =10\npatience= 1 # number of epochs to wait to adjust lr if monitored value does not improve\nstop_patience =3 # number of epochs to wait before stopping training if monitored value does not improve\nthreshold=.9 # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\nfactor=.5 # factor to reduce lr by\ndwell=True # experimental, if True and monitored metric does not improve on current epoch set  modelweights back to weights of previous epoch\nfreeze=False # if true free weights of  the base model\nbatches=int(len(train_gen.labels)/batch_size)\ncallbacks=[LRA(model=model,patience=patience,stop_patience=stop_patience, threshold=threshold,\n                   factor=factor,dwell=dwell, model_name=model_name, freeze=freeze, batches=batches,initial_epoch=0 )]\nLRA.tepochs=epochs  # used to determine value of last epoch for printing\nhistory=model.fit(x=train_gen,  epochs=epochs, verbose=0, callbacks=callbacks,  validation_data=valid_gen,\n               validation_steps=None,  shuffle=False,  initial_epoch=0)","metadata":{"papermill":{"duration":711.842806,"end_time":"2021-05-22T20:32:20.89787","exception":false,"start_time":"2021-05-22T20:20:29.055064","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:28:00.34853Z","iopub.execute_input":"2021-05-27T03:28:00.348862Z","iopub.status.idle":"2021-05-27T03:36:33.427979Z","shell.execute_reply.started":"2021-05-27T03:28:00.348832Z","shell.execute_reply":"2021-05-27T03:36:33.427221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### define function to plot the training data","metadata":{"papermill":{"duration":0.602551,"end_time":"2021-05-22T20:32:22.169153","exception":false,"start_time":"2021-05-22T20:32:21.566602","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def tr_plot(tr_data, start_epoch):\n    #Plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    #plt.style.use('fivethirtyeight')\n    plt.show()\n","metadata":{"papermill":{"duration":0.619728,"end_time":"2021-05-22T20:32:23.398038","exception":false,"start_time":"2021-05-22T20:32:22.77831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:37:00.083245Z","iopub.execute_input":"2021-05-27T03:37:00.083611Z","iopub.status.idle":"2021-05-27T03:37:00.097262Z","shell.execute_reply.started":"2021-05-27T03:37:00.08358Z","shell.execute_reply":"2021-05-27T03:37:00.096522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### define function to generate the confusion matrix and classification report","metadata":{"papermill":{"duration":0.603979,"end_time":"2021-05-22T20:32:24.610718","exception":false,"start_time":"2021-05-22T20:32:24.006739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def print_info( test_gen, preds, print_code, save_dir, subject ):\n    class_dict=test_gen.class_indices\n    labels= test_gen.labels\n    file_names= test_gen.filenames \n    error_list=[]\n    true_class=[]\n    pred_class=[]\n    prob_list=[]\n    new_dict={}\n    error_indices=[]\n    y_pred=[]\n    for key,value in class_dict.items():\n        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n    # store new_dict as a text fine in the save_dir\n    classes=list(new_dict.values())     # list of string of class names\n    dict_as_text=str(new_dict)\n    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n    dict_path=os.path.join(save_dir,dict_name)    \n    with open(dict_path, 'w') as x_file:\n        x_file.write(dict_as_text)    \n    errors=0      \n    for i, p in enumerate(preds):\n        pred_index=np.argmax(p)        \n        true_index=labels[i]  # labels are integer values\n        if pred_index != true_index: # a misclassification has occurred\n            error_list.append(file_names[i])\n            true_class.append(new_dict[true_index])\n            pred_class.append(new_dict[pred_index])\n            prob_list.append(p[pred_index])\n            error_indices.append(true_index)            \n            errors=errors + 1\n        y_pred.append(pred_index)    \n    if print_code !=0:\n        if errors>0:\n            if print_code>errors:\n                r=errors\n            else:\n                r=print_code           \n            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n            print_in_color(msg, (0,255,0),(55,65,80))\n            for i in range(r):                \n                split1=os.path.split(error_list[i])                \n                split2=os.path.split(split1[0])                \n                fname=split2[1] + '/' + split1[1]\n                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n                print_in_color(msg, (255,255,255), (55,65,60))\n                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n        else:\n            msg='With accuracy of 100 % there are no errors to print'\n            print_in_color(msg, (0,255,0),(55,65,80))\n    if errors>0:\n        plot_bar=[]\n        plot_class=[]\n        for  key, value in new_dict.items():        \n            count=error_indices.count(key) \n            if count!=0:\n                plot_bar.append(count) # list containg how many times a class c had an error\n                plot_class.append(value)   # stores the class \n        fig=plt.figure()\n        fig.set_figheight(len(plot_class)/3)\n        fig.set_figwidth(10)\n        plt.style.use('fivethirtyeight')\n        for i in range(0, len(plot_class)):\n            c=plot_class[i]\n            x=plot_bar[i]\n            plt.barh(c, x, )\n            plt.title( ' Errors by Class on Test Set')\n    y_true= np.array(labels)        \n    y_pred=np.array(y_pred)\n    if len(classes)<= 30:\n        # create a confusion matrix \n        cm = confusion_matrix(y_true, y_pred )        \n        length=len(classes)\n        if length<8:\n            fig_width=8\n            fig_height=8\n        else:\n            fig_width= int(length * .5)\n            fig_height= int(length * .5)\n        plt.figure(figsize=(fig_width, fig_height))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\n    clr = classification_report(y_true, y_pred, target_names=classes)\n    print(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"papermill":{"duration":0.664913,"end_time":"2021-05-22T20:32:25.881227","exception":false,"start_time":"2021-05-22T20:32:25.216314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:37:04.279195Z","iopub.execute_input":"2021-05-27T03:37:04.27952Z","iopub.status.idle":"2021-05-27T03:37:04.302299Z","shell.execute_reply.started":"2021-05-27T03:37:04.279492Z","shell.execute_reply":"2021-05-27T03:37:04.299569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### evaluate model on the test set then save the model","metadata":{"papermill":{"duration":0.604693,"end_time":"2021-05-22T20:32:27.089531","exception":false,"start_time":"2021-05-22T20:32:26.484838","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tr_plot(history,0)\nsave_dir=r'./'\nsubject='land use'\nacc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\nmsg=f'accuracy on the test set is {acc:5.2f} %'\nprint_in_color(msg, (0,255,0),(55,65,80))\nsave_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\nsave_loc=os.path.join(save_dir, save_id)\nmodel.save(save_loc)","metadata":{"papermill":{"duration":104.883468,"end_time":"2021-05-22T20:34:12.577243","exception":false,"start_time":"2021-05-22T20:32:27.693775","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:37:11.1493Z","iopub.execute_input":"2021-05-27T03:37:11.149647Z","iopub.status.idle":"2021-05-27T03:37:16.039611Z","shell.execute_reply.started":"2021-05-27T03:37:11.149615Z","shell.execute_reply":"2021-05-27T03:37:16.038829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### make predictions on test set and generate confusion matrix and classification report","metadata":{"papermill":{"duration":0.794181,"end_time":"2021-05-22T20:34:14.158049","exception":false,"start_time":"2021-05-22T20:34:13.363868","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print_code=0\npreds=model.predict(test_gen) \nprint_info( test_gen, preds, print_code, save_dir, subject )  ","metadata":{"papermill":{"duration":36.266562,"end_time":"2021-05-22T20:34:51.210202","exception":false,"start_time":"2021-05-22T20:34:14.94364","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-27T03:37:18.923232Z","iopub.execute_input":"2021-05-27T03:37:18.923548Z","iopub.status.idle":"2021-05-27T03:37:23.074961Z","shell.execute_reply.started":"2021-05-27T03:37:18.923519Z","shell.execute_reply":"2021-05-27T03:37:23.07393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.807941,"end_time":"2021-05-22T20:34:52.807707","exception":false,"start_time":"2021-05-22T20:34:51.999766","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.78828,"end_time":"2021-05-22T20:34:54.700794","exception":false,"start_time":"2021-05-22T20:34:53.912514","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}