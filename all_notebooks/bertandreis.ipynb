{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n\nimport numpy\nimport pandas\n%matplotlib inline\n\nReviews = pandas.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\nprint(Reviews.shape)\nprint(Reviews.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\n# First, let's make a small function to clean our strings, because as we have seen before, there are tons of unwanted punctuations and other useless tags\ndef clear_sentence(sentence: str) -> str:\n    '''A function to clear texts using regex.'''\n    sentence = re.sub(r'\\W', ' ', str(sentence))\n    sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n    sentence = re.sub(r'\\^[a-zA-Z]\\s+', ' ', sentence) \n    sentence = re.sub(r'\\s+', ' ', sentence, flags=re.I)\n    sentence = re.sub(r'^b\\s+', '', sentence)\n    sentence = sentence.lower()\n    return sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Reviews['review'] = [clear_sentence(sentence) for sentence in Reviews['review']]\n\n#x = Reviews['review'].tolist()\n#y = Reviews['sentiment'].tolist()\nReviews.sentiment = pandas.factorize(Reviews.sentiment)[0]\n#X_train, X_test, y_train, y_test = train_test_split(x, y_binary, test_size=0.2, random_state=0)\nprint(Reviews.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport transformers as ppb # pytorch transformers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n\n# Load pretrained model/tokenizer\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)\nmodel = model_class.from_pretrained(pretrained_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized = Reviews['review'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ninput_ids = torch.tensor(np.array(padded))\n\nwith torch.no_grad():\n    last_hidden_states = model(input_ids)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # Slice the output for the first position for all the sequences, take all hidden unit outputs\nfeatures = last_hidden_states[0][:,0,:].numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = df[1]\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_clf = LogisticRegression()\nlr_clf.fit(train_features, train_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_clf.score(test_features, test_labels)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}