{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import RFE\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read data :- \ndata=pd.read_csv('/kaggle/input/life-expectancy-who/Life Expectancy Data.csv')\ndata.head()\nprint(data.info())\nprint(data.shape)\nprint(data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform EDA:-\ndata.isna().sum()\n#we can see many columns do come with missing data let us deal with them one by one\n\n# Remove life expectancy where  ever it is zero as these are only one years data in the database for a country\ndata['Life expectancy '].fillna(0,inplace=True)\ndata=data[data['Life expectancy '] != 0]\n\n\n# A lot of countries do not have population details we can remove these rows.\ndata['Population'].fillna(0,inplace=True)\ndata=data[data['Population'] != 0]\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Missing Value Interpretation :\n\n#In order to find the Missing values let us take average of individual columns for that oarticulat country\nimport numpy as np\nco=data.copy()\nco[co== 0] = np.nan\ndata_mean=pd.pivot_table(co,index=['Country'],values=['Life expectancy ','Hepatitis B','Adult Mortality','Alcohol',' BMI ','Total expenditure','Population','Income composition of resources','GDP',' thinness 5-9 years','Schooling'],\n                         aggfunc=np.nanmean)\ndata_mean=pd.DataFrame(data_mean.to_records())\ndata_mean.fillna(0,inplace=True)\ndata.isna().sum()\ndata['Alcohol'].fillna(0,inplace=True)\n\n\n\n#from progressbar import ProgressBar\n#Alcohall fill with nanmean\n#Pbar=ProgressBar()\n\nfor i in data.index:\n    Cou=data.loc[i,'Country']\n    Alco =data.loc[i,'Alcohol']\n    S=data_mean[data_mean['Country'] == Cou]\n    M=S['Alcohol'].values[0]\n    S.index\n    if Alco == 0 :\n        data.loc[i,'Alcohol'] = M\n        \n#Hepa fill with nanmean\n        \ndata['Hepatitis B'].fillna(0,inplace=True)\nfor i in data.index:\n    Cou=data.loc[i,'Country']\n    Alco =data.loc[i,'Hepatitis B']\n    S=data_mean[data_mean['Country'] == Cou]\n    M=S['Hepatitis B'].values[0]\n    S.index\n    if Alco == 0 :\n        data.loc[i,'Hepatitis B'] = M\ndata.isna().sum() \n\n\n#Population has no relation to Life expectancy so we can remove that column\ndel data['Population']\ndata.isna().sum()\n\ndata['Total expenditure'].fillna(0,inplace=True)\n\n\nfor i in data.index:\n    Cou=data.loc[i,'Country']\n    Alco =data.loc[i,'Total expenditure']\n    S=data_mean[data_mean['Country'] == Cou]\n    M=S['Total expenditure'].values[0]\n    S.index\n    if Alco == 0 :\n        data.loc[i,'Total expenditure'] = M\ndata.isna().sum()        \n\n\ndata[' BMI '].fillna(0,inplace=True)\n\n\nfor i in data.index:\n    Cou=data.loc[i,'Country']\n    Alco =data.loc[i,' BMI ']\n    S=data_mean[data_mean['Country'] == Cou]\n    M=S[' BMI '].values[0]\n    S.index\n    if Alco == 0 :\n        data.loc[i,' BMI '] = M\ndata.isna().sum()    \n\n\n\n\n\n\n# thin ness we cannot averge it out so let us remove where ever it is 0, also delete Diphtheria where ever it zero we cannot calculate avergae  \ndata[' thinness  1-19 years'].fillna(0,inplace=True)\ndata=data[data[' thinness  1-19 years'] != 0]\ndata['Diphtheria '].fillna(0,inplace=True)\ndata=data[data['Diphtheria '] != 0]\ndata.isna().sum()\n\n\n#data.GDP.fillna(0,inplace=True)\n        \ndata['GDP'].fillna(0,inplace=True)\n\nfor i in data.index:\n    Cou=data.loc[i,'Country']\n    Alco =data.loc[i,'GDP']\n    S=data_mean[data_mean['Country'] == Cou]\n    M=S['GDP'].values[0]\n    S.index\n    if Alco == 0 :\n        data.loc[i,'GDP'] = M        \n        \ndata.isna().sum()\n#Finally there are no Missing values now.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get Dummies for Categorical Column : \nsec=pd.get_dummies(data['Status'])\nsec\nbackdata=data.copy()\ndata=pd.concat([data,sec],axis=1)\ndata=data.drop(['Country','Year','Status'],axis=1)\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test Train split :-\ndf_train,df_test=train_test_split(data,train_size=0.7,test_size=0.3,random_state=100)\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standard Scalar:-\nscaler=MinMaxScaler()\nvar=['Life expectancy ','Adult Mortality','infant deaths','Alcohol','percentage expenditure','Hepatitis B','Measles ',' BMI ','under-five deaths ','Polio','Total expenditure','Diphtheria ',' HIV/AIDS','GDP',' thinness  1-19 years',' thinness 5-9 years','Income composition of resources','Schooling']\ndf_train[var]=scaler.fit_transform(df_train[var])\ndf_train.head()\n# Split dependant and Independant data set\ny_train = df_train.pop('Life expectancy ')\nX_train=df_train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run RFE :- \n# RFE to get the most significant features\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 10)\nrfe = rfe.fit(X_train, y_train)\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))\ncols = X_train.columns[rfe.support_]\ncols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train_rfe = X_train[cols]\nX_train_rfe = sm.add_constant(X_train_rfe)\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending=False) \nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm=sm.OLS(y_train,X_train_rfe).fit()\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = cols.drop('GDP')\nX_train_rfe = X_train[cols]\nX_train_rfe = sm.add_constant(X_train_rfe)\nlm = sm.OLS(y_train, X_train_rfe).fit()\nprint(lm.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train[cols]\nX_train_rfe = sm.add_constant(X_train_rfe)\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending=False) \nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = cols.drop('under-five deaths ')\nX_train_rfe = X_train[cols]\nX_train_rfe = sm.add_constant(X_train_rfe)\nlm = sm.OLS(y_train, X_train_rfe).fit()\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = cols.drop('infant deaths')\nX_train_rfe = X_train[cols]\nX_train_rfe = sm.add_constant(X_train_rfe)\nlm = sm.OLS(y_train, X_train_rfe).fit()\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif = pd.DataFrame()\nvif['Features'] = X_train_rfe.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = 'VIF', ascending=False) \nvif\n# VIF is within the range which is less than 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = lm.predict(X_train_rfe)\nres = y_train - y_train_pred\nsns.distplot(res)\n# Residual mean falling 0 and is a normal distribution so model is significant  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Current :- R-squared: 83.7.%\n### Adjusted R-squared: 83.6%\n### P values are equal to 0\n### infant deaths, percentage expenditure , BMI ,Diphtheria Schooling having postive correlations\n### under-five deaths, Adult Mortality,HIV/AIDS having negative impact "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run on Test:-\ndf_test[var] = scaler.transform(df_test[var])\ndf_test.head()\ny_test=df_test.pop('Life expectancy ')\nX_test = df_test\nX_test\nX_test_rfe = X_test[cols]\nX_test_rfe.head()\nX_test_rfe.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_rfe = sm.add_constant(X_test_rfe)\nX_test_rfe.head()\n#Accuracy :-\ny_test_pred = lm.predict(X_test_rfe)\nr2_score(y_true=y_test, y_pred=y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model accuracy is good 84.37% \n##### We can see Where in countries where HIV/AIDS and Adult Mortality are more such countries has low life expectancy\n##### And in the countries where schooling numbers,Income composition of resources, BMI and Diphtheria and also percentage expenditure are more we can see they genearally have more life expectancy.\n\n\n## So if Countries wants to increase life expectancy of the people they realy should be focusing to have more kids covered in schooling and they need to increase the income of the people and Increase people percentage expendeture mainly and also we need to increase the awareness on HIV/AIDS and also need to make sure we maintain low Adult mortality rate.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}