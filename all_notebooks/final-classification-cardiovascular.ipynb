{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dfCardio=pd.read_csv('/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv')\n\ndfCardio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comma Separator:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio=pd.read_csv('/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv',  sep='[;]', engine='python')\ndfCardio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove Duplicate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age calculation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio['age']=(dfCardio['age']/365).apply(np.floor)\n#dfCardio.age.astype(int)\ndfCardio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio['age'] = dfCardio.age.astype(int)\ndfCardio['age']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detecting Outliers ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calcuating upper and lower range for ap_hi, ap_lo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ap_list = [\"ap_hi\", \"ap_lo\"]\nboundary = pd.DataFrame(index=[\"lower_bound\",\"upper_bound\"]) # We created an empty dataframe\nfor each in ap_list:\n    Q1 = dfCardio[each].quantile(0.25)\n    Q3 = dfCardio[each].quantile(0.75)\n    IQR = Q3 - Q1\n\n    lower_bound = Q1- 1.5*IQR\n    upper_bound = Q3 + 1.5*IQR\n    boundary[each] = [lower_bound, upper_bound ]\nboundary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can select the index of outlier data by using boundaries we calculated.\n#upper outliers.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ap_hi_filter = (dfCardio[\"ap_hi\"] > boundary[\"ap_hi\"][1])\nap_lo_filter = (dfCardio[\"ap_lo\"] > boundary[\"ap_lo\"][1])                                                           \noutlier_filter = (ap_hi_filter | ap_lo_filter)\nx_outliers = dfCardio[outlier_filter]\nx_outliers[\"cardio\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_filter = ((dfCardio[\"ap_hi\"]>250) | (dfCardio[\"ap_lo\"]>200) )\nprint(\"There is {} outlier\".format(dfCardio[out_filter][\"cardio\"].count()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCardio = dfCardio[~out_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr =dfCardio.corr()\nf, ax = plt.subplots(figsize = (15,15))\nsns.heatmap(corr, annot=True, fmt=\".3f\", linewidths=0.5, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Testing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dfCardio[\"cardio\"]\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=dfCardio.drop(['id','cardio'],axis=1)\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\ndec = DecisionTreeClassifier()\nran = RandomForestClassifier(n_estimators=100)\nknn = KNeighborsClassifier(n_neighbors=100)\nsvm = SVC(random_state=1)\nnaive = GaussianNB()\n\nmodels = {\"Decision tree\" : dec,\n          \"Random forest\" : ran,\n          \"KNN\" : knn,\n          \"SVM\" : svm,\n          \"Naive bayes\" : naive}\nscores= { }\n\nfor key, value in models.items():    \n    model = value\n    model.fit(x_train, y_train)\n    scores[key] = model.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_frame = pd.DataFrame(scores, index=[\"Accuracy Score\"]).T\nscores_frame.sort_values(by=[\"Accuracy Score\"], axis=0 ,ascending=False, inplace=True)\nscores_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.barplot(x=scores_frame.index,y=scores_frame[\"Accuracy Score\"])\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#It seems that KNN and SVM algorithms are far ahead of the others.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grid Search \n# grid search cross validation with 1 hyperparameter\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = {\"n_estimators\" : np.arange(10,150,10)}\n\nran_cv = GridSearchCV(ran, grid, cv=3) # GridSearchCV\nran_cv.fit(x_train,y_train)# Fit\n\n# Print hyperparameter\nprint(\"Tuned hyperparameter n_estimators: {}\".format(ran_cv.best_params_)) \nprint(\"Best score: {}\".format(ran_cv.best_score_))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(solver=\"liblinear\", max_iter=200)\ngrid = {\"penalty\" : [\"l1\", \"l2\"],\n         \"C\" : np.arange(60,80,2)} # (60,62,64 ... 78)\nlog_reg_cv = GridSearchCV(log_reg, grid, cv=3)\nlog_reg_cv.fit(x_train, y_train)\n\n# Print hyperparameter\nprint(\"Tuned hyperparameter n_estimators: {}\".format(log_reg_cv.best_params_)) \nprint(\"Best score: {}\".format(log_reg_cv.best_score_))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg_best = LogisticRegression(C=74, penalty=\"l1\", solver=\"liblinear\")\nlogreg_best.fit(x_train, y_train)\nprint(\"Test accuracy: \",logreg_best.score(x_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = y_test\ny_pred = logreg_best.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, y_pred)\nf, ax = plt.subplots(figsize=(5,5))\nsns.heatmap(cm,fmt=\".0f\", annot=True,linewidths=0.2, linecolor=\"purple\", ax=ax)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Grand Truth\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#F1 Score \nTN = cm[0,0]\nTP = cm[1,1]\nFN = cm[1,0]\nFP = cm[0,1]\nPrecision = TP/(TP+FP)\nRecall = TP/(TP+FN)\nF1_Score = 2*(Recall * Precision) / (Recall + Precision)\npd.DataFrame([[Precision, Recall, F1_Score]],columns=[\"Precision\", \"Recall\", \"F1 Score\"], index=[\"Results\"])\n#High precision relates to the low false positive rate\n#High recall relates to the low false negative rate\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}