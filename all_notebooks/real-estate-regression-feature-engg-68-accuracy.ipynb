{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Lets import the libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport scipy\nfrom sklearn.linear_model import LinearRegression\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"price=pd.read_csv('/kaggle/input/real-estate-price-prediction/Real estate.csv')\nprice.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ** clearly No column will not be at all useful, as it is just showing the index number, \n# so drop the No column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"price.drop('No',axis=1,inplace=True)\nprice.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Column names are not written in proper way.\n# There are spaces in between the column name.\n# So lets fill the spaces by underscore(_) for smooth operation*********"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names=price.columns\ncol_names=col_names.str.replace(\" \",\"_\")\nprice.columns=col_names\n\n\nprice.columns\n## column names got changed to the names we wanted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  lets see are there any null values in the dataset ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"price.isnull().sum()\n\n## no null values in the data\n## thats a good sign\n## will make the code writing somewhat easier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price.describe()\n\n## in column starting with names X3 and X4\n## the mean value of the column and its maximum value are having a huge difference between them\n## so it means some outliers are there \n## lets deal with those outliers are the last\n## hopefully it will boost our algorithms accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets see the data type of each column\nif any data-type is of object(categorical) type, we need to change it to numerical type.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"price.info()\n\n## all columns have data type of int or float type","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"## lets visualize all the numeric columns\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(6,10))\nsns.pairplot(price)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **> Lets see the co-relation between the columns and the target column -> Price of house**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncorr=price.corr()\nplt.figure(figsize=(10,6))\nsns.heatmap(corr,annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ther's so much relation between the columns starting their name with X4, X5, X6 and also with the target column -> price of house column.\n"},{"metadata":{},"cell_type":"markdown","source":"# **So lets use the traditional way to see which column will contribute towards the linear regression model and which are not contributing, we will discard that column**"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets say the boundary line for alpha will be 0.05\n\n## if p-value > alpha :  so that coumn is not contributing to the model\n\n\nfrom statsmodels.formula.api import ols\n\nmodel=ols(formula = 'Y_house_price_of_unit_area ~X1_transaction_date',data=price).fit()\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Since P>|t| for the first column X1 is greater than alpha=0.05.\nSo lets discard that column.\nSince it will not be contributing to the model***"},{"metadata":{},"cell_type":"markdown","source":"**Lets go on adding the other column to see their contribution in the model**"},{"metadata":{},"cell_type":"raw","source":"## column with name starting with X6 is not contributing the model\nmodel=ols(formula = 'Y_house_price_of_unit_area ~X2_house_age+X3_distance_to_the_nearest_MRT_station+X4_number_of_convenience_stores+X5_latitude',data=price).fit()\nmodel.summary()"},{"metadata":{},"cell_type":"markdown","source":"**Lets try some feature engineering ideas here.\nLets multiply longitude and latitude column\n\n****\nyou can try addition or any other operation which will boost the accuracy.\n\n**\nAs of now, lets go with multiplication idea.****"},{"metadata":{},"cell_type":"markdown","source":"**so lets do the following to the dataset :\n\nX1_transaction_date -> column\n\n**replace latitude column** as -> X5_latitude * X6_longitude\n\nX5_latitude and X6_longitude -> column*******"},{"metadata":{"trusted":true},"cell_type":"code","source":"price.drop('X1_transaction_date',axis=1,inplace=True)\n\nprice['X5_latitude']=price['X5_latitude'] * price['X6_longitude']\n\nprice.drop(['X6_longitude'],axis=1,inplace=True)\n\n\n\n## lets see now how the corelation heatmap looks like\n\n\ncorr=price.corr()\nplt.figure(figsize=(10,6))\nsns.heatmap(corr,annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Data splitting into training and testing model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = price.iloc[:,:-1]\ny = price.iloc[:,-1]\n\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data modelling and evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_reg=LinearRegression()\nmodel=linear_reg.fit(xtrain,ytrain)\ny_predict=model.predict(xtest)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## lets check the mean square error \n\nfrom sklearn.metrics import mean_squared_error\n\nmean_squared_error(ytest,y_predict)\n\n## low value of mean squared error\n## thats a good sign","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# since accuracy score doesnt go hand in hand with linear regression\n#  so we will use r2_score function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nr2_score(ytest,y_predict,)\n\n## 67 % accuracy ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ## lets see the actual plot between ytest and y_predicted values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Actual':ytest,'Predictions':y_predict})\ndf['Predictions']= round(df['Predictions'])\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot('Actual','Predictions',data=df)\n\n## relatively good graph\n## less deviation from main data line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}