{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Loading the dataset into notebook\n\ndata = pd.read_csv('/kaggle/input/bank-telemarketing-campaign-case/bank_marketing_updated_v1.csv')\n\ndata.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formating the rows as there are some discrepencies in the first two rows\n\ndata = pd.read_csv('/kaggle/input/bank-telemarketing-campaign-case/bank_marketing_updated_v1.csv', skiprows = 2)\n\ndata.head(4) # this dataset looks good","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. After inspecting the dataset we can say that 'customerid' is of no importance in the analysis process, so we can drop it.\n2. The 'jobedu' column should be separeted into two different columns\n3. We can create a separate column for year\n4. We can change the datatypes of column 'age', 'month'\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Dropping customer id column\ndata.drop('customerid', axis = 'columns', inplace = True)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regular function:\n\n> def square(x):\n>     return x * x\n    \nLambda function:\n\n> lambda x: x * x\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Splitting 'jobedu' in two columns by using lambda function\n\n# Job column\ndata['job'] = data['jobedu'].apply(lambda x: x.split(',')[0])\n\n# Education column\ndata['education'] = data['jobedu'].apply(lambda x: x.split(',')[1])\n\n# Drop the 'jobedu' column\ndata.drop('jobedu', axis = 1, inplace = True)\n\n# Result\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the missing values\n\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping missing values in 'age' & response column\n\ndata.dropna(subset=['age'], inplace = True) # for age column\n\ndata.dropna(subset=['response'], inplace = True) # for response column\n\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing values to the missing values for month column\n\nmonth_mode = data.month.mode()[0]\n\ndata.month.fillna(month_mode, inplace = True)\n\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3. Splitting the month column in two\n\n# Month column\ndata['month1'] = data['month'].apply(lambda x: x.split(',')[0])\n\n# Year column\ndata['year'] = data['month'].apply(lambda x: x.split(',')[1])\n\n# Drop the 'month' column\ndata.drop('month', axis = 1, inplace = True)\n\n# Result\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Changing the datatypes of columns where necessary\n\ndata.age.astype('int32')\n\ndata.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling Outliers:\n\nTwo types of outliers:\n1. Univariate Outlier\n2. Multivariate Outlier\n\nWe can handle outliers by either dropping them, imputing with values or leaving them as is.[](http://)"},{"metadata":{},"cell_type":"markdown","source":"### Analysis:\n\n#### 1. Univariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"**a. Categorical Unordered Univariate Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Job status category\n\ndata.job.value_counts()\n\ndata.job.value_counts().plot.barh()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage of each job using normalize\n\ndata.job.value_counts(normalize = True)\n\ndata.job.value_counts(normalize = True).plot.barh()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**b. Categorical Ordered Univariate Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Education variable\n\ndata.education.value_counts(normalize = True)\n\ndata.education.value_counts(normalize = True).plot.pie()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# month variable\n\ndata.month1.value_counts()\n\ndata.month1.value_counts().plot.barh()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**c . Numerical Univariate Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age column\n\ndata.age.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Bivariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"**a. Numeric-Numeric Analysis**\n\nThis analysis can be perfomed by using:\n1. Scatter Plot\n2. Pair Plot\n3. Correlation Matrix"},{"metadata":{},"cell_type":"markdown","source":"1. Scatter Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets take the salary, balance and age variables\n\n# 1. Age vs Salary\n\ndata.plot.scatter(x = \"age\", y = \"salary\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Age vs Balance\n\ndata.plot.scatter(x = \"age\", y = \"balance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Salary vs Balance\n\ndata.plot.scatter(x = \"salary\", y = \"balance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Pair Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using pair plots from seaborn library\n\nsns.pairplot(data = data, vars=['salary', 'balance', 'age'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Corr function\n\ndata[['age', 'salary', 'balance']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using seaborn heatmap\n\nsns.heatmap(data[['age', 'salary', 'balance']].corr(), annot= True, cmap = 'Blues')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**b. Numeric-Categorical Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loan and balance -mean\n\ndata.groupby('loan')['balance'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loan and balance - median\n\ndata.groupby('loan')['balance'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting\n\nsns.boxplot(data.loan, data.balance)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**c. Categorical-Categorical Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting categorical variables into factors\n# 1 = yes\n# 0 = no\n\ndata['response_rate'] = np.where(data.response=='yes', 1, 0)\ndata.response_rate.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Letâ€™s see how the response rate varies for different categories in marital status.\n\ndata.groupby('marital')['response_rate'].mean().plot.bar()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}