{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom plotly.figure_factory import create_gantt\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport os, re, gc \n\nfrom io import StringIO\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Given https://github.com/yutkin/Lenta.Ru-News-Dataset, perform EDA on it focusing on the following:\n  - Provide descriptive statistics\n  - Anomaly detection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = '/kaggle/input/corpus-of-russian-news-articles-from-lenta/lenta-ru-news.csv'\ndf = pd.read_csv(filename)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert object to datatime64 and round the date to the day.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'])\ndf['date'] = df['date'].dt.floor('D')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We plot the number of news for each year . ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"countNewsPerYear = df.groupby(df['date'].dt.year).size()\nplt.figure(figsize=(12, 8))\nfig = countNewsPerYear.plot(kind='bar')\nfig.set_title('TOTAL NUMBER OF NEWS ARTICLES')\nfig.set_xlabel('YEAR')\nfig.set_ylabel('NUMBER OF NEWS ARTICLES')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found something intresting in 1914 year. Let's check it by clicking on the link","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['date'].dt.year == 1914]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That news was written in 2014. We should change the date for them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'][:5] = df['date'][:5] + pd.offsets.DateOffset(year=2014)\n\ndf = df.sort_values(['date'], ascending=True)\ndf = df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentages of nans for topic and text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"amountOfNans = df.iloc[:, 2:4].isna().sum() \namountOfNans.sort_values(ascending = False ) / df.shape[0] * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We must drop Nans in topic and text beacuse in the future, we will create a model for extracting topic from text. Without text or topic we can't train the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['topic'].notna()]\ndf = df[df['text'].notna()]\n\n#refresh the indexes\ndf = df.set_index(np.arange(len(df.index)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have found that the word 'Культпросвет ' has an extra space.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove extra space from 'Культпросвет '\ndf_topic = []\n\nfor i in df['topic']:\n    if i == 'Культпросвет ':\n        df_topic.append('Культпросвет')\n    else:\n        df_topic.append(i)\n\ndf['topic'] = df_topic\n\ndel df_topic\ngc.collect() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We check the appearance of topics to understand how important the topic is. Then shorter the life span of the topic than less important it is.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique topic names\nnameOfTopics = df['topic'].unique()\n\ndf_dict = []\nfor i in nameOfTopics:      \n    serie = df[df['topic'] == i]   \n    # add first, last date appearance for each topic\n    df_dict.append(dict(Task=i, Start=serie.iloc[0, 5], Finish=serie.iloc[-1, 5]))\n    \nfig = create_gantt(df_dict, title='The date appearance of topics', height=600, bar_width=0.5, width=600)\nfig.show()\n\ndel df_dict\ngc.collect() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see Медновости, Сочи, ЧМ-2014 and Библиотека are less important then others","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now we plot the number of news for each topic. Then more number of topics than more important the topic is","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"countNewsPerTopic = df.groupby(df['topic']).size()\ncountNewsPerTopic = countNewsPerTopic.sort_values(ascending = False)\n\nplt.figure(figsize=(12, 8))\nfig = countNewsPerTopic.plot(kind='bar')\nfig.set_title('TOTAL NUMBER OF NEWS ARTICLES')\nfig.set_xlabel('TOPIC')\nfig.set_ylabel('NUMBER OF NEWS ARTICLES')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How we can see the dataset is unbalanced and some topics seems nearly zero. We need to check how many percent of rare topics is in the entire dataset. We need to know this, because in the future we will create a model for extracting the topic from the text.Then a larger number of topics, than greater the chance that the model may make mistakes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rareTopics = ['Крым','Культпросвет', 'Легпром', 'Библиотека', 'Оружие', 'ЧМ-2014', 'Сочи', 'МедНовости', '69-я параллель'] \npercOfRareTopic = sum((df['topic'].isin(rareTopics)))/ len(df['topic']) * 100\n\nprint(f'{percOfRareTopic:.3f}% for rare topics')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.logical_not(df['topic'].isin(rareTopics))\ndf = df[mask]\n\n\ndel mask\ngc.collect() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#refresh the indexes\ndf = df.set_index(np.arange(len(df.index)))\n#Remove url and date from the dataset\ndf = df.drop(['url', 'date'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('textFromEDA.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics\nWe should check two metrics: Logistic Loss, F1 Score. These two metrics are well suited to our task.\nLogistic Loss metric considers confidence in a particular class. In F1 Score, it is necessary that the precision and recall are equal to one and it is close to zero if one of the arguments is close to zero. Accuracy is not a good metric because we have an unbalanced dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocFile = '/kaggle/input/a-job-project/preprocess_text2.csv'\n\nnew_df = pd.read_csv(preprocFile)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}