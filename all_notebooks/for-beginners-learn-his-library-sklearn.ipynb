{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1  style =\"color:blue\"><center>Some of the important commands that you can use in making your project from the SKlearn library</center></h1>\nHere we are working on downloading some private data from the cactlearn library, which is stored inside it"},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Data:\n1. And it is done by removing the spaces, whether the value of nan or zero or others, and it is in this formula\n2. code here....EXample to make Cleaning for data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Libraries\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n#----------------------------------------------------\n#load breast cancer data\nBreastData = load_breast_cancer()\n#X Data\nX = BreastData.data\n#y Data\ny = BreastData.target\n#----------------------------------------------------\n# Cleaning data\n\n'''\nimpute.SimpleImputer(missing_values=nan, strategy='mean’, fill_value=None, verbose=0, copy=True)\n'''\nImputedModule = SimpleImputer(missing_values = np.nan, strategy ='mean')\nImputedX = ImputedModule.fit(X)\nX = ImputedX.transform(X)\n\n\n#X Data\nprint('X Data is \\n' , X[:5])\n\n#y Data\nprint('y Data is \\n' , y[:5])\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Metrics Module:\n And it is very important in making a calculation of the amount of errors during the test, and it is divided into two types, one for expectation, and one for classification:\n\n\nForecasting tools:\n1. metrics.mean_absolute_error\n2. metrics.mean_squared_error\n3. metrics.median_absolute_error\n\nClassification Tools:\n1. metrics.confusion_matrix\n2.\tmetrics.accuracy_score\n3.\tmetrics.f1_score\n4.  metrics.recall_score\n5.\tmetrics.precision_score\n6.  metrics.precision_recall_fscore_support\n7.  metrics.precision¬_recall_curve\n8. \tmetrics.classification_report\n9.\tmetrics.roc_curve\n10. metrics.auc\n12. metrics.roc_auc_score\n13.\tmetrics.zero_one_loss\n\n\n\n \n \n\n"},{"metadata":{},"cell_type":"markdown","source":"Example for Mean Absolute Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import mean_absolute_error\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\nmean_absolute_error(y_true, y_pred)\ny_true = [[0.5, 1], [-1, 1], [7, -6]]\ny_pred = [[0, 2], [-1, 2], [8, -5]]\n\nmean_absolute_error(y_true, y_pred) # 0.75\nmean_absolute_error(y_true, y_pred, multioutput='uniform_average') # 0.75و\nmean_absolute_error(y_true, y_pred, multioutput='raw_values') # array([0.5, 1. ])\n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example for Mean Squared Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import mean_squared_error\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nmean_squared_error(y_true, y_pred)\n\ny_true = [[0.5, 1],[-1, 1],[7, -6]]\ny_pred = [[0, 2],[-1, 2],[8, -5]]\n\nmean_squared_error(y_true, y_pred)\nmean_squared_error(y_true, y_pred, multioutput='uniform_average') \n\n\nmean_squared_error(y_true, y_pred, multioutput='raw_values')\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example for Media Absolute Error\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import median_absolute_error\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nmedian_absolute_error(y_true, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example for Confusion Matrix\n\nTP\tFP\nFN\tTN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny_pred = ['a','a','b','b','a','b','a','a','a','a']\ny_true  = ['a','b','b','a','b','a','a','b','a','b']\nconfusion_matrix(y_true, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example for culculation Accuracy Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_pred = [0, 2, 1, 3,5,3]\ny_true = [0, 1, 2, 3,5,3]\nprint(accuracy_score(y_true, y_pred)) # fraction of all Trues over everything\nprint(accuracy_score(y_true, y_pred, normalize=False)) #number of all Trues\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example for F1 Score:\n1. F1 = 2 * (precision * recall) / (precision + recall)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_pred = [0, 2, 1, 0, 0, 1]\ny_true = [0, 1, 2, 0, 1, 2]\nf1_score(y_true, y_pred, average='micro')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style =\"color:blue\">Feature Selection </h1> \nIt is for selecting the required and influencing features and excluding the rest, and it is chosen based on the extent of its association with the output y, and it is done through the feature_selection module:\n\n1.\tfeature_selection.SelectPercentile\n2.  feature_selection.GenericUnivariateSelect\n3.  feature_selection.SelectKBest\n4.\tfeature_selection.SelectFromModel\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"Select Percentile: \n\n1. The selectpercentile tool is used, which selects the most important features related to the outcome according to the percentage given, and the importance is determined in several ways, such as the f_classif tool or the chi2 tool."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.feature_selection import SelectPercentile, chi2\nX, y = load_digits(return_X_y=True)\nX.shape\n\n\nX_new = SelectPercentile(score_func =chi2, percentile=10).fit_transform(X, y)\n\nprint(X_new.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select From Model:\n\n1. The fitcher is selected based on a specific model, so that the model itself is shown to have finished the task, which is a matter of selectfrommodel."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\ndata = load_breast_cancer()\nX = data.data\ny = data.target\nsel = SelectFromModel(RandomForestClassifier(n_estimators = 20)) \nsel.fit(X,y)\nselected_features = sel.transform(X)\nsel.get_support()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style =\"color:blue\">Data Scaling </h1>:\n\nIt is specific to the process of scaling all kinds of data, and it comes from a preprocessing module:\n\n1. preprocessing.StandardScaler \n2. preprocessing.MinMaxScaler   \n3. preprocessing.Normalizer\n4. preprocessing.MaxAbsScaler\n5. preprocessing.FunctionTransformer\n6. preprocessing.Binarizer\n7.preprocessing.PolynomialFeatures\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Standard Scaler(Standardization)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndata = [[0, 0], [0, 0], [1, 1], [1, 1]]\nscaler = StandardScaler()\nscaler.fit(data)\nprint(scaler.mean_)\nnewdata = scaler.transform(data)\nprint(newdata)\n\nnewdata = scaler.fit_transform(data) \nprint(newdata)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import Normalizer\nX = [[4, 1, 2, 2], [1, 3, 9, 3], [5, 7, 5, 1]]\n\n#transformer = Normalizer(norm='l1' )\n\n#transformer = Normalizer(norm='l2' )\n\ntransformer = Normalizer(norm='max' )\n\ntransformer.fit(X)\ntransformer.transform(X)\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Data Split</h1> \nIt is for doing data segmentation before training it, and it is done using model_selection from the sklearn library\nIt has more than one tool:\n\n \n1. model_selection.train_test_split\n2. model_selection.Kfold\n3. model_selection.RepeatedKFold\n4. model_selection.StratifiedKFold\n5. model_selection.RepeatedStratifiedKFold\n6. model_selection.LeaveOneOut\n7. model_selection.LeavePOut\n8. model_selection.ShuffleSplit\n9. model_selection.StratifiedShuffleSplit\n10. model_selection.TimeSeriesSplit\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nX, y = np.arange(10).reshape((5, 2)), range(5)\n\nX\nlist(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nX_train\ny_train\nX_test\ny_test\n\ntrain_test_split(y, shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center>Now we will use algorithms in this library and there are many algorithms in which we can use the task.</center></h1>"},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\">Linear Regression</h1>\n\nMake predictions using the Linear Model:\n\n\n1.\tlinear_model.LinearRegression\t\n2.\tlinear_model.Ridge\n3.\tlinear_model.Lasso\t\t\t\t\n4.\tlinear_model.SGDRegressor\t\t\t\n \n"},{"metadata":{},"cell_type":"markdown","source":"#  Example to showing  what do mean this"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n#----------------------------------------------------\n\n#load boston data\n\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\n\n#y Data\ny = BostonData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#----------------------------------------------------\n#Applying Linear Regression Model \n\nLinearRegressionModel = LinearRegression(fit_intercept=True, normalize=True,copy_X=True,n_jobs=-1)\nLinearRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('Linear Regression Train Score is : ' , LinearRegressionModel.score(X_train, y_train))\nprint('Linear Regression Test Score is : ' , LinearRegressionModel.score(X_test, y_test))\nprint('Linear Regression Coef is : ' , LinearRegressionModel.coef_)\nprint('Linear Regression intercept is : ' , LinearRegressionModel.intercept_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = LinearRegressionModel.predict(X_test)\nprint('Predicted Value for Linear Regression is : ' , y_pred[:10])\n\n#----------------------------------------------------\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Absolute Error Value is : ', MAEValue)\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)\n\n#----------------------------------------------------\n#Calculating Median Squared Error\nMdSEValue = median_absolute_error(y_test, y_pred)\nprint('Median Squared Error Value is : ', MdSEValue )\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# By using Ridge Regression\n\nIt is for linear prediction, with regularization\n\n\n\n \n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Example to showing what do mean this "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n#----------------------------------------------------\n\n#load boston data\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\n\n#y Data\ny = BostonData.target\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n#----------------------------------------------------\n#Applying Ridge Regression Model \n\n'''\n#sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False,\n#                           copy_X=True, max_iter=None, tol=0.001, solver='auto',\n#                           random_state=None)\n'''\n\nRidgeRegressionModel = Ridge(alpha=1.0,random_state=33)\nRidgeRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('Ridge Regression Train Score is : ' , RidgeRegressionModel.score(X_train, y_train))\nprint('Ridge Regression Test Score is : ' , RidgeRegressionModel.score(X_test, y_test))\nprint('Ridge Regression Coef is : ' , RidgeRegressionModel.coef_)\nprint('Ridge Regression intercept is : ' , RidgeRegressionModel.intercept_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = RidgeRegressionModel.predict(X_test)\nprint('Predicted Value for Ridge Regression is : ' , y_pred[:10])\n\n#----------------------------------------------------\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Absolute Error Value is : ', MAEValue)\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)\n\n#----------------------------------------------------\n#Calculating Median Squared Error\nMdSEValue = median_absolute_error(y_test, y_pred)\nprint('Median Squared Error Value is : ', MdSEValue )\n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# By using Lasso Regression:\nIt is for linear prediction, with regularization (least absolute shrinkage and selection operator)."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n#----------------------------------------------------\n\n#load boston data\n\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\n\n#y Data\ny = BostonData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n #----------------------------------------------------\n#Applying Lasso Regression Model \n\n'''\n#sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=\n#                           False, copy_X=True, max_iter=1000, tol=0.0001,\n#                           warm_start=False, positive=False, random_state=None,selection='cyclic')\n'''\n\nLassoRegressionModel = Lasso(alpha=1.0,random_state=33,normalize=False)\nLassoRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('Lasso Regression Train Score is : ' , LassoRegressionModel.score(X_train, y_train))\nprint('Lasso Regression Test Score is : ' , LassoRegressionModel.score(X_test, y_test))\nprint('Lasso Regression Coef is : ' , LassoRegressionModel.coef_)\nprint('Lasso Regression intercept is : ' , LassoRegressionModel.intercept_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = LassoRegressionModel.predict(X_test)\nprint('Predicted Value for Lasso Regression is : ' , y_pred[:10])\n\n#----------------------------------------------------\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Absolute Error Value is : ', MAEValue)\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)\n\n#----------------------------------------------------\n#Calculating Median Squared Error\nMdSEValue = median_absolute_error(y_test, y_pred)\nprint('Median Squared Error Value is : ', MdSEValue )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# By using  SGD Regressor:\n\nIt is for linear prediction, but uses SGD smoothing\nIt is used by module."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n#----------------------------------------------------\n\n#load boston data\n\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\n#y Data\ny = BostonData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#----------------------------------------------------\n#Applying SGDRegressor Model \n\n'''\n#sklearn.linear_model.SGDRegressor(loss='squared_loss’, penalty=’l2’, alpha=0.0001,\n#                                  l1_ratio=0.15, fit_intercept=True, max_iter=None,\n#                                  tol=None, shuffle=True, verbose=0, epsilon=0.1,\n#                                  random_state=None, learning_rate='invscaling’,\n#                                  eta0=0.01, power_t=0.25, early_stopping=False,\n#                                  validation_fraction=0.1, n_iter_no_change=5,\n#                                  warm_start=False, average=False, n_iter=None)\n'''\n\nSGDRegressionModel = SGDRegressor(alpha=0.1,random_state=33,penalty='l2',loss = 'huber')\nSGDRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('SGD Regression Train Score is : ' , SGDRegressionModel.score(X_train, y_train))\nprint('SGD Regression Test Score is : ' , SGDRegressionModel.score(X_test, y_test))\nprint('SGD Regression Coef is : ' , SGDRegressionModel.coef_)\nprint('SGD Regression intercept is : ' , SGDRegressionModel.intercept_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = SGDRegressionModel.predict(X_test)\nprint('Predicted Value for SGD Regression is : ' , y_pred[:10])\n\n#----------------------------------------------------\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Absolute Error Value is : ', MAEValue)\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)\n\n#----------------------------------------------------\n#Calculating Median Squared Error\nMdSEValue = median_absolute_error(y_test, y_pred)\nprint('Median Squared Error Value is : ', MdSEValue )\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\"><center>Logistic Regression</center></h1>\n\n1. linear_model. LogisticRegression: Classification by linear model\n2. linear_model. SGDClassifier:      Classification using random regression"},{"metadata":{},"cell_type":"markdown","source":"# Example to showing what do this."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Import Libraries\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import zero_one_loss\n#----------------------------------------------------\n\n#load breast cancer data\n\nBreastData = load_breast_cancer()\n\n#X Data\nX = BreastData.data\n\n#y Data\ny = BreastData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n\n#----------------------------------------------------\n#Applying LogisticRegression Model \n\n'''\n#linear_model.LogisticRegression(penalty='l2’,dual=False,tol=0.0001,C=1.0,fit_intercept=True,intercept_scaling=1,\n#                                class_weight=None,random_state=None,solver='warn’,max_iter=100,\n#                                multi_class='warn’, verbose=0,warm_start=False, n_jobs=None)\n'''\n\nLogisticRegressionModel = LogisticRegression(penalty='l2',solver='sag',C=1.0,random_state=33)\nLogisticRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(X_train, y_train))\nprint('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(X_test, y_test))\nprint('LogisticRegressionModel Classes are : ' , LogisticRegressionModel.classes_)\nprint('LogisticRegressionModel No. of iteratios is : ' , LogisticRegressionModel.n_iter_)\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = LogisticRegressionModel.predict(X_test)\ny_pred_prob = LogisticRegressionModel.predict_proba(X_test)\nprint('Predicted Value for LogisticRegressionModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for LogisticRegressionModel is : ' , y_pred_prob[:10])\n\n#----------------------------------------------------\n#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()\n\n#----------------------------------------------------\n#Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))\nAccScore = accuracy_score(y_test, y_pred, normalize=False)\nprint('Accuracy Score is : ', AccScore)\n\n#----------------------------------------------------\n#Calculating F1 Score  : 2 * (precision * recall) / (precision + recall)\n# f1_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n\nF1Score = f1_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('F1 Score is : ', F1Score)\n\n#----------------------------------------------------\n#Calculating Recall Score : (Sensitivity) (TP / float(TP + FN))   1 / 1+2  \n# recall_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’, sample_weight=None)\n\nRecallScore = recall_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('Recall Score is : ', RecallScore)\n\n#----------------------------------------------------\n#Calculating Precision Score : (Specificity) #(TP / float(TP + FP))  \n# precision_score(y_true, y_pred, labels=None, pos_label=1, average=’binary’,sample_weight=None)\n\nPrecisionScore = precision_score(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('Precision Score is : ', PrecisionScore)\n\n#----------------------------------------------------\n#Calculating Precision recall Score :  \n#metrics.precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=\n#                                        None, warn_for = ('precision’,’recall’, ’f-score’), sample_weight=None)\n\nPrecisionRecallScore = precision_recall_fscore_support(y_test, y_pred, average='micro') #it can be : binary,macro,weighted,samples\nprint('Precision Recall Score is : ', PrecisionRecallScore)\n\n#----------------------------------------------------\n#Calculating Precision recall Curve :  \n# precision_recall_curve(y_true, probas_pred, pos_label=None, sample_weight=None)\n\nPrecisionValue, RecallValue, ThresholdsValue = precision_recall_curve(y_test,y_pred)\nprint('Precision Value is : ', PrecisionValue)\nprint('Recall Value is : ', RecallValue)\nprint('Thresholds Value is : ', ThresholdsValue)\n\n#----------------------------------------------------\n#Calculating classification Report :  \n#classification_report(y_true, y_pred, labels=None, target_names=None,sample_weight=None, digits=2, output_dict=False)\n\nClassificationReport = classification_report(y_test,y_pred)\nprint('Classification Report is : ', ClassificationReport )\n\n#----------------------------------------------------\n#Calculating Area Under the Curve :  \n\nfprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)\nAUCValue = auc(fprValue2, tprValue2)\nprint('AUC Value  : ', AUCValue)\n\n#----------------------------------------------------\n#Calculating Receiver Operating Characteristic :  \n#roc_curve(y_true, y_score, pos_label=None, sample_weight=None,drop_intermediate=True)\n\nfprValue, tprValue, thresholdsValue = roc_curve(y_test,y_pred)\nprint('fpr Value  : ', fprValue)\nprint('tpr Value  : ', tprValue)\nprint('thresholds Value  : ', thresholdsValue)\n\n#----------------------------------------------------\n#Calculating ROC AUC Score:  \n#roc_auc_score(y_true, y_score, average=’macro’, sample_weight=None,max_fpr=None)\n\nROCAUCScore = roc_auc_score(y_test,y_pred, average='micro') #it can be : macro,weighted,samples\nprint('ROCAUC Score : ', ROCAUCScore)\n\n#----------------------------------------------------\n#Calculating Zero One Loss:  \n#zero_one_loss(y_true, y_pred, normalize = True, sample_weight = None)\n\nZeroOneLossValue = zero_one_loss(y_test,y_pred,normalize=False) \nprint('Zero One Loss Value : ', ZeroOneLossValue )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"another Example"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndataset = pd.read_csv('../input/scikitconf/heart-disease.csv')\n\ndataset.head(20)\n\nX = dataset.iloc[:, :-1]\ny = dataset.iloc[:, -1]\n\nX\ny\n\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nprint(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Fitting Logistic Regression to the Training set\nfrom sklearn.linear_model import LogisticRegression\nclss = LogisticRegression(random_state = 0)\nclss.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = clss.predict(X_test)\nprint(y_pred) \n\nprint(clss.n_iter_)\nprint(clss.classes_)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#probability of all values\npr = clss.predict_proba(X_test)[0:10,:]\npr\n\n#probability of zeros\npr = clss.predict_proba(X_test)[0:10,0]\npr\n\n#probability of ones\npr = clss.predict_proba(X_test)[0:10,1]\npr\n\n\n#  Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test, y_pred)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_test, y_pred)\n\nfrom sklearn.metrics import median_absolute_error\nmedian_absolute_error(y_test, y_pred)\n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example: Filing with the Kfolds app"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score , confusion_matrix\n \niris = load_iris()\nX = iris.data\ny = iris.target\nX\ny\n\nskf = StratifiedKFold(n_splits = 5)\npredict = np.zeros(y.shape[0])\n\nfor train,test in skf.split(X,y):\n    x_train = X[train]\n    x_test = X[test]\n    y_train = y[train]\n    y_test = y[test]\n    logreg = LogisticRegression()\n    logreg.fit(x_train , y_train)\n    result= logreg.predict(x_test)\n    predict[test] = result\nconf = confusion_matrix(y , predict)\n\n\n \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  print('train data \\n' , train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('result \\n',result)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  print('test data \\n ', test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total accuracy \\n',accuracy_score(y , predict))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('this accuracy \\n' , accuracy_score(y_test , result))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('confusion matrix \\n',  conf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example: Classification with Standardization & Normalization work# "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score , confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler ,Normalizer\nfrom sklearn.model_selection import train_test_split\n\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n\n\nscale  = MinMaxScaler()\nscale.fit(X)\nnewx = scale.transform(X)\n\n#nor = Normalizer(norm = 'max')\n#nor.fit(X)\n#newx = nor.transform(X)\n\nx_train, x_test, y_train, y_test = train_test_split(newx, y, test_size = 0.2)\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train , y_train)\nresult= logreg.predict(x_test)\nprint(accuracy_score(y_test , result))\n\nconf = confusion_matrix(y_test , result)\nprint('confusion matrix \\n',  conf)\n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Example: Classify with the Transform function implemented"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score , confusion_matrix\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import train_test_split\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n\ndef function1(z):\n#    return np.log1p(z)\n#    return np.sqrt(z)\n    return np.power(z,4)\n\n\nf = FunctionTransformer(func = function1)\nf.fit(X)\nx_f = f.transform(X)\n\n\nx_train, x_test, y_train, y_test = train_test_split(x_f, y, test_size = 0.2)\n\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train , y_train)\nresult= logreg.predict(x_test)\nprint(accuracy_score(y_test , result))\n \nconf = confusion_matrix(y_test , result)\nprint('confusion matrix \\n',  conf)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example: Sort with the Polynomial Features app"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\n\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n\n\npoly = PolynomialFeatures( degree = 2 , include_bias = False)\npoly.fit(X)\nx_poly = poly.transform(X)\n\nx_train, x_test, y_train, y_test = train_test_split(x_poly, y, test_size = 0.2)\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train , y_train)\nresult= logreg.predict(x_test)\nprint('accuracy =',accuracy_score(y_test , result))\n \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf = confusion_matrix(y_test , result)\nprint('confusion matrix \\n',  conf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = poly.get_feature_names()\n\nprint('fatures names \\n' , names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example: Sort with the Selected Features app# "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectPercentile ,f_classif , chi2 \n\n\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n\n#sel = SelectPercentile(score_func = chi2 , percentile = 20)\n#sel = SelectPercentile(score_func = chi2 , percentile = 40)\n#sel = SelectPercentile(score_func = chi2 , percentile = 60)\n#sel = SelectPercentile(score_func = chi2, percentile = 80)\n\nsel = SelectPercentile(score_func = f_classif , percentile = 20)\n\nsel.fit(X,y)\nselected_features = sel.transform(X)\nsfeatures = sel.get_support()\nprint('Selected features = \\n' , sfeatures)\n\nx_train, x_test, y_train, y_test = train_test_split(selected_features, y, test_size = 0.2)\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train , y_train)\nresult= logreg.predict(x_test)\nprint('accuarcy = ',accuracy_score(y_test , result))\n\nconf = confusion_matrix(y_test , result)\nprint('confusion matrix \\n',  conf)\n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:red\"><center>Neural Network </center></h1>\n\nIt is the use of neural networks for either prediction or classification:\n\n1. neural_network.MLPRegressor: Predicting using neural networks\n2. neural_network.MLPClassifier: Classification using neural networks"},{"metadata":{},"cell_type":"markdown","source":"# Using MLPRegressor:\n\nIt is for constructing neural networks for prediction\n1. It is used by the neural_network\n2. MLPRegressor module\n* Parameters used in the model:\n\n\n1. activation selection of the activation function\n2. Solver: the modus operandi of optimization\n3. epsilon: value if Adam will be used in the silver\n4. alpha :smoothing factor\n5. batch_size: the size of the mini-batch\n6. learning_rate: is the learning parameter\n7. max_iter: The maximum number of attempts\n8. shuffle: whether or not to randomize the data\n9. early_stopping :if early stop will be implemented\n10. learning_rate: is the learning parameter\n11. Hidden_layer_sizes: design of hidden layers"},{"metadata":{},"cell_type":"markdown","source":"# an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#load boston data\n\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\n#y Data\ny = BostonData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#----------------------------------------------------\n#Applying MLPRegressor Model \n\n'''\n#sklearn.neural_network.MLPRegressor(hidden_layer_sizes=(100, ), activation='relu’, solver=’adam’,\n#                                    alpha=0.0001,batch_size='auto’, learning_rate=’constant’,\n#                                    learning_rate_init=0.001, power_t=0.5,max_iter=200, shuffle=True,\n#                                    random_state=None,tol=0.0001, verbose=False, warm_start=False,\n#                                    momentum=0.9, nesterovs_momentum=True,early_stopping=False,\n#                                    validation_fraction=0.1,beta_1=0.9, beta_2=0.999, epsilon=1E-08,\n#                                    n_iter_no_change=10)\n'''\n\nMLPRegressorModel = MLPRegressor(activation='tanh', # can be also identity , logistic , relu\n                                 solver='lbfgs',  # can be also sgd , adam\n                                 learning_rate='constant', # can be also invscaling , adaptive\n                                 early_stopping= False,\n                                 alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\nMLPRegressorModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('MLPRegressorModel Train Score is : ' , MLPRegressorModel.score(X_train, y_train))\nprint('MLPRegressorModel Test Score is : ' , MLPRegressorModel.score(X_test, y_test))\nprint('MLPRegressorModel loss is : ' , MLPRegressorModel.loss_)\nprint('MLPRegressorModel No. of iterations is : ' , MLPRegressorModel.n_iter_)\nprint('MLPRegressorModel No. of layers is : ' , MLPRegressorModel.n_layers_)\nprint('MLPRegressorModel last activation is : ' , MLPRegressorModel.out_activation_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Prediction\ny_pred = MLPRegressorModel.predict(X_test)\nprint('Predicted Value for MLPRegressorModel is : ' , y_pred[:10])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------------------------------------------\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Absolute Error Value is : ', MAEValue)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#----------------------------------------------------\n#Calculating Median Squared Error\nMdSEValue = median_absolute_error(y_test, y_pred)\nprint('Median Squared Error Value is : ', MdSEValue )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# another example:\nIts idea is based on creating a network that trains the thousand numbers for X and Y, whose value is sin, and draws them in blue, then performs a test on twenty numbers between them and draws the resulting value on the same shovel in red to see the extent of congruence."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neural_network import MLPRegressor\n\nx = np.arange(0.0, 1, 0.001).reshape(-1, 1)\ny = np.sin(2 * np.pi * x).ravel()\n\nprint('x  = \\n' ,x.shape)\nprint('y  = \\n' ,y.shape)\n\n\nnn = MLPRegressor(\n    hidden_layer_sizes=(100,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n    random_state=0, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\nn = nn.fit(x, y)\ntest_x = np.arange(0.0, 1, 0.05).reshape(-1, 1)\ntest_y = nn.predict(test_x)\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.scatter(x, y, s=1, c='b', marker=\"s\", label='real')\nax1.scatter(test_x,test_y, s=10, c='r', marker=\"o\", label='NN Prediction')\nplt.show()\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# using MLPClassifier:\n1. It is for building neural networks for classification\n2. It is used by the neural_network.MLPClassifier module"},{"metadata":{},"cell_type":"markdown","source":"# an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#----------------------------------------------------\n\n#load iris data\n\nIrisData = load_iris()\n\n#X Data\nX = IrisData.data\n\n#y Data\ny = IrisData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n#----------------------------------------------------\n#Applying MLPClassifier Model \n'''\nsklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100, ), activation='relu’, solver=’adam’,\n                                     alpha=0.0001,batch_size='auto’, learning_rate=’constant’,momentum=0.9,\n                                     learning_rate_init=0.001, power_t=0.5,max_iter=200, shuffle=True,\n                                     random_state=None, tol=0.0001, verbose=False, warm_start=False, \n                                     n_iter_no_change=10, nesterovs_momentum=True,early_stopping=False, \n                                     validation_fraction=0.1,beta_1=0.9, beta_2=0.999, epsilon=1E-08,)\n'''\n\nMLPClassifierModel = MLPClassifier(activation='tanh', # can be also identity , logistic , relu\n                                   solver='lbfgs',  # can be also sgd , adam\n                                   learning_rate='constant', # can be also invscaling , adaptive\n                                   early_stopping= False,\n                                   alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\nMLPClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('MLPClassifierModel Train Score is : ' , MLPClassifierModel.score(X_train, y_train))\nprint('MLPClassifierModel Test Score is : ' , MLPClassifierModel.score(X_test, y_test))\nprint('MLPClassifierModel loss is : ' , MLPClassifierModel.loss_)\nprint('MLPClassifierModel No. of iterations is : ' , MLPClassifierModel.n_iter_)\nprint('MLPClassifierModel No. of layers is : ' , MLPClassifierModel.n_layers_)\nprint('MLPClassifierModel last activation is : ' , MLPClassifierModel.out_activation_)\nprint('----------------------------------------------------')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Calculating Prediction\ny_pred = MLPClassifierModel.predict(X_test)\ny_pred_prob = MLPClassifierModel.predict_proba(X_test)\nprint('Predicted Value for MLPClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for MLPClassifierModel is : ' , y_pred_prob[:10])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# another example"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score ,confusion_matrix\n\ndf = pd.read_csv('../input/lower-back-pain-symptoms-dataset/Dataset_spine.csv')\ndf = df.drop(['Unnamed: 13'], axis=1)\ndf.head()\n\ndf.describe()\n\ndf = df.drop(['Col7','Col8','Col9','Col10','Col11','Col12'], axis=1)\ndf.head()\n\n\ny = df['Class_att']\nx = df.drop(['Class_att'], axis=1)\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.25,random_state=27)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MLPClassifier(hidden_layer_sizes=(100), max_iter=500, alpha=0.0001,solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n\nclf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)\n\naccuracy_score(y_test, y_pred)\n\ncm = confusion_matrix(y_test, y_pred)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(cm, center=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:red\"><center>SVR</center></h1>\n1. It is for the implementation of the model of the automatic support system SVM for expectation\n2. It is used by the .svm.SVR modules."},{"metadata":{},"cell_type":"markdown","source":"# an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n#----------------------------------------------------\n\n#load boston data\n\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\n\n#y Data\ny = BostonData.target\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#----------------------------------------------------\n#Applying SVR Model \n\n'''\nsklearn.svm.SVR(kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001,\n                C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False,max_iter=-1)\n'''\n\nSVRModel = SVR(C = 1.0 ,epsilon=0.1,kernel = 'rbf') # it also can be : linear, poly, rbf, sigmoid, precomputed\nSVRModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('SVRModel Train Score is : ' , SVRModel.score(X_train, y_train))\nprint('SVRModel Test Score is : ' , SVRModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Prediction\ny_pred = SVRModel.predict(X_test)\nprint('Predicted Value for SVRModel is : ' , y_pred[:10])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------------------------------------------\n#Calculating Mean Absolute Error\nMAEValue = mean_absolute_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Absolute Error Value is : ', MAEValue)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#----------------------------------------------------\n#Calculating Median Squared Error\nMdSEValue = median_absolute_error(y_test, y_pred)\nprint('Median Squared Error Value is : ', MdSEValue )\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# another example: \nwith dataset Earthquakes"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndataset = pd.read_csv('../input/for-test/Earthquakes.csv')\n\ndataset.head(20)\n\nfrom sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp = imp.fit(dataset)\ndataset = imp.transform(dataset)\n\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndataset = sc.fit_transform(dataset)\n\n\nX = dataset[:, :-1]\ny = dataset[:, -1]\n\nprint(X)\nprint(y)\n\nfrom sklearn.svm import SVR\nclf = SVR(kernel = 'linear')\nclf.fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict([[90,12,12,-5,54,0.3,0.9,3.5,16.2,10]]) \ny_pred\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\"><center>K Nearest Neighbors </center></h1>\n1.  It is an application of the idea of close neighbors and is used for prediction, classification, or evidence without supervision\n\nThere are three main types:\n\n1. neighbors.KNeighborsRegressor to expect\n\n2. neighbors.KNeighborsClassifier for classification\n\n3. neighbors.NearestNeighbors data without supervision"},{"metadata":{},"cell_type":"markdown","source":"# an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error \nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.metrics import median_absolute_error\n#----------------------------------------------------\n\n#load boston data\n\nBostonData = load_boston()\n\n#X Data\nX = BostonData.data\nprint('X Data is \\n' , X[:5])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X shape is ' , X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X Features are \\n' , BostonData.feature_names)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import neighbors\n\nnp.random.seed(0)\nX = np.sort(5 * np.random.rand(40, 1), axis=0)\nT = np.linspace(0, 5, 500)[:, np.newaxis]\ny = np.sin(X).ravel()\n\n# Add noise to targets\ny[::5] += 1 * (0.5 - np.random.rand(8))\n\n# #############################################################################\n# Fit regression model\nn_neighbors = 5\n\nfor i, weights in enumerate(['uniform', 'distance']):\n    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n    y_ = knn.fit(X, y).predict(T)\n\n    plt.subplot(2, 1, i + 1)\n    plt.scatter(X, y, c='b', label='data')\n    plt.plot(T, y_, c='r', label='prediction')\n    plt.axis('tight')\n    plt.legend()\n    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors,\n                                                                weights))\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K Neighbors Classifier"},{"metadata":{},"cell_type":"markdown","source":"# an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#----------------------------------------------------\n\n#load breast cancer data\n\nBreastData = load_breast_cancer()\n\n#X Data\nX = BreastData.data\n#print('X Data is \\n' , X[:10])\n#print('X shape is ' , X.shape)\n#print('X Features are \\n' , BreastData.feature_names)\n\n#y Data\ny = BreastData.target\n#print('y Data is \\n' , y[:10])\n#print('y shape is ' , y.shape)\n#print('y Columns are \\n' , BreastData.target_names)\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#Splitted Data\n#print('X_train shape is ' , X_train.shape)\n#print('X_test shape is ' , X_test.shape)\n#print('y_train shape is ' , y_train.shape)\n#print('y_test shape is ' , y_test.shape)\n\n#----------------------------------------------------\n#Applying KNeighborsClassifier Model \n\n'''\n#sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform’, algorithm=’auto’, leaf_size=30,\n#                                       p=2, metric='minkowski’, metric_params=None,n_jobs=None)\n'''\n\nKNNClassifierModel = KNeighborsClassifier(n_neighbors= 5,weights ='uniform', # it can be distance\n                                          algorithm='auto') # it can be ball_tree, kd_tree,brute\nKNNClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('KNNClassifierModel Train Score is : ' , KNNClassifierModel.score(X_train, y_train))\nprint('KNNClassifierModel Test Score is : ' , KNNClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = KNNClassifierModel.predict(X_test)\ny_pred_prob = KNNClassifierModel.predict_proba(X_test)\nprint('Predicted Value for KNNClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for KNNClassifierModel is : ' , y_pred_prob[:10])\n\n#----------------------------------------------------\n#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:blue\"><center>Naive Bayes</center></h1>\n\nIt is implementing the various types of Naif Base code.\n\nIt is only used in classification and very rarely in prediction.\n\nThere are three main types:\n\n1. naive_bayes.GaussianNB used when vectors are normally distributed (Gaussian) like IRIS data\n\n2. naive_bayes.MultinomialNB is used with separate data, for example if we have a movie rating that has numbers 1, 2, 3 or\n\n3. naive_bayes.BernoulliNB is used with the binary classification, zero or one, true or false, sick or not sick"},{"metadata":{},"cell_type":"markdown","source":"# GaussianNB:\n"},{"metadata":{},"cell_type":"markdown","source":"# Example:\nHere we dawnload for breast cancer data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#----------------------------------------------------\n\n#load breast cancer data\n\nBreastData = load_breast_cancer()\n\n#X Data\nX = BreastData.data\nprint('X Data is \\n' , X[:5])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X Features are \\n' , BreastData.feature_names)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X shape is ' , X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = BreastData.target\nprint('y Data is \\n' , y[:10])\n#Splitting data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('y shape is ' , y.shape)\nprint('y Columns are \\n' , BreastData.target_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here we using GaussianNBModel and make fit for (x and y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"GaussianNBModel = GaussianNB()\nGaussianNBModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('GaussianNBModel Train Score is : ' , GaussianNBModel.score(X_train, y_train))\nprint('GaussianNBModel Test Score is : ' , GaussianNBModel.score(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Calculating Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating Prediction\ny_pred = GaussianNBModel.predict(X_test)\ny_pred_prob = GaussianNBModel.predict_proba(X_test)\nprint('Predicted Value for GaussianNBModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for GaussianNBModel is : ' , y_pred_prob[:10])\n\n#----------------------------------------------------\n#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another example by using dataset heart"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\ndataset = pd.read_csv('../input/scikitconf/heart-disease.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nimport seaborn as sns\nsns.heatmap(cm, center=True)\nplt.show()\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# For MultinomialNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Import Libraries\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#----------------------------------------------------\n\n#load breast cancer data\n\nBreastData = load_breast_cancer()\n\n#X Data\nX = BreastData.data\nprint('X Data is \\n' , X[:5])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X shape is ' , X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X Features are \\n' , BreastData.feature_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = BreastData.target\nprint('y Data is \\n' , y[:10])\nprint('y shape is ' , y.shape)\nprint('y Columns are \\n' , BreastData.target_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#Splitted Data\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MultinomialNBModel = MultinomialNB(alpha=1.0)\nMultinomialNBModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('MultinomialNBModel Train Score is : ' , MultinomialNBModel.score(X_train, y_train))\nprint('MultinomialNBModel Test Score is : ' , MultinomialNBModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = MultinomialNBModel.predict(X_test)\ny_pred_prob = MultinomialNBModel.predict_proba(X_test)\nprint('Predicted Value for MultinomialNBModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for MultinomialNBModel is : ' , y_pred_prob[:10])\n#----------------------------------------------------\n#Calculating Confusion Matrix\nCM = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix is : \\n', CM)\n\n# drawing confusion matrix\nsns.heatmap(CM, center = True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}