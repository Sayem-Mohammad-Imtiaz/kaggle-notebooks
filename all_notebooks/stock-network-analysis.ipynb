{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport csv\nimport os\nimport re\n\n# %load_ext rpy2.ipython\n# import rpy2.rinterface\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing correlation dataframe\ndata = pd.read_excel(\"../input/stockmarketanalysis/data.xlsx\",index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks_cross_corr = data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stocks_cross_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the Graph with stocks as nodes and corr as edges\nimport networkx as nx\nimport networkx.algorithms.community as nxcom\nimport community\n\nedge_weights = []\ndef build_graph(stocks_cross_corr, threshold):\n    graph_edges = []\n    for x in stocks_cross_corr.keys():\n        for y in stocks_cross_corr[x].keys():\n            #print(x, y) \n            # Filter by absolute value of the corr\n            if abs(stocks_cross_corr[x][y]) > threshold:\n                #if same stock, continue\n                if  x == y:\n                    continue\n                if x < y: #Avoid duplicates, AxAAL vs AALxA\n                    graph_edges.append([x,y,dict(weight=abs(stocks_cross_corr[x][y]))])\n                    edge_weights.append(abs(stocks_cross_corr[x][y]))\n                else:\n                    None\n    \n#   print(len(graph_edges))\n    G = nx.Graph()\n    G.add_edges_from(graph_edges)\n    return G\n#     partition = community.best_partition(G)\n#     modularity = community.modularity(partition, G)\n#     values = [partition.get(node) for node in G.nodes()]\n#     nx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\n#     print(modularity)    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import networkx as nx\nimport networkx.algorithms.community as nxcom\nimport community\n\n\n#stocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\n#stocks_cross_corr = stocks_cross_corr[1]\n\ncorr_thresholds = np.linspace(0.5, 0.95, 20)\nmodularity_list = []\ncommunity_list = []\n#for cor in corr_thresholds:\n    #G = build_graph(stocks_cross_corr, cor)\n    #partition = community.best_partition(G)\n    #modularity = community.modularity(partition, G)\n    #modularity_list.append(modularity)\n    #community_list.append(len(G.nodes()))\n    \n\n#\n\n# partition = community.best_partition(G)\n# modularity = community.modularity(partition, G)\n# values = [partition.get(node) for node in G.nodes()]\n# nx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\n# print(modularity)\n# print(\"Total number of Communities=\", len(G.nodes()))\n\n# partition=community.best_partition(G)\n# # Calculating modularity and the total number of communities\n# mod=community.modularity(partition,G)\n# print(\"Modularity: \", mod)\n# print(\"Total number of Communities=\", len(G_comm.nodes()))\n\n# dict_degree_centrality = nx.degree_centrality(G)\n# dict_closeness_centrality = nx.closeness_centrality(G)\n# dict_eigenvector_centrality = nx.eigenvector_centrality(G)\n# print(\"dict_degree_centrality: \", dict_degree_centrality)\n# print(\"dict_closeness_centrality: \", dict_closeness_centrality)\n# print(\"dict_eigenvector_centrality: \", dict_eigenvector_centrality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Louvian\n%matplotlib inline\n#stocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\n#stocks_cross_corr = stocks_cross_corr[1]\n\ncor_thresold = 0.7\nG = build_graph(stocks_cross_corr, cor_thresold)\npartition = community.best_partition(G)\nmodularity = community.modularity(partition, G)\nvalues = [partition.get(node) for node in G.nodes()]\nplt.figure(figsize=(10,10))\nnx.draw_spring(G, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)\nprint(modularity)\nprint(\"Total number of Communities=\", len(G.nodes()))\n\ndict_betwenness_centrality = nx.betweenness_centrality(G)\ndict_degree_centrality = nx.degree_centrality(G)\ndict_closeness_centrality = nx.closeness_centrality(G)\ndict_eigenvector_centrality = nx.eigenvector_centrality(G)\nprint(\"dict_degree_centrality: \", dict_degree_centrality)\nprint(\"dict_closeness_centrality: \", dict_closeness_centrality)\nprint(\"dict_eigenvector_centrality: \", dict_eigenvector_centrality)\nprint(\"dict_betweenness_centrality: \", dict_betwenness_centrality)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Portfolio Formula: \nc_dict = dict([(k, [dict_betwenness_centrality[k], dict_eigenvector_centrality[k], dict_degree_centrality[k], dict_closeness_centrality[k] ]) for k in dict_betwenness_centrality])\n#print(c_dict)    \n    \nC_total = {}\nfor key in c_dict: \n    C_total[key] = sum(c_dict[key]) \n        \n\nprint(\"The Centrality total for stocks are:\", C_total)   \n\nnewDict = dict(filter(lambda elem: elem[1] > 0, C_total.items()))\nprint(\"Stocks greater than 0.3 centrality are\",newDict)\nprint(len(newDict))\n\ndf_centrality = pd.DataFrame(list(newDict.items()),columns = ['Symbol','Centrality']) \ndf_centrality.sort_values(by='Centrality', ascending=False)\n#df_centrality.head(20)\n#type(df_centrality['Centrality'])\ndf_centrality.to_csv('centrality_of_stocks_0.7cor.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_node_community(G, communities):\n    '''Add community to node attributes'''\n    for c, v_c in enumerate(communities):\n        for v in v_c:\n            # Add 1 to save 0 for external edges\n            G.nodes[v]['community'] = c + 1 \n            \ndef set_edge_community(G):\n    '''Find internal edges and add their community to their attributes'''\n    for v, w, in G.edges:\n        if G.nodes[v]['community'] == G.nodes[w]['community']:\n            # Internal edge, mark with community\n            G.edges[v, w]['community'] = G.nodes[v]['community']\n        else:\n            # External edge, mark as 0\n            G.edges[v, w]['community'] = 0\n            \ndef get_color(i, r_off=1, g_off=1, b_off=1):\n    r0, g0, b0 = 0, 0, 0\n    n = 16\n    low, high = 0.1, 0.9\n    span = high - low\n    r = low + span * (((i + r_off) * 3) % n) / (n - 1)\n    g = low + span * (((i + g_off) * 5) % n) / (n - 1)\n    b = low + span * (((i + b_off) * 7) % n) / (n - 1)\n    return (r, g, b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Community detection using Girvan Newman (GN)\n#stocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\n#stocks_cross_corr = stocks_cross_corr[1]\n\n\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\nresult = nxcom.girvan_newman(G)\ncommunities_gn = next(result)\n# Set node and edge communities\nset_node_community(G, communities_gn)\nset_edge_community(G)\nprint(\"GN Communities: \", len(communities_gn))\n\n# Set community color for nodes\nnode_color = [    \n    get_color(G.nodes[v]['community'])    \n    for v in G.nodes]\n\n# Set community color for internal edgese\nexternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] == 0]\ninternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] > 0]\ninternal_color = [    \n    get_color(G.edges[e]['community'])    \n    for e in internal]\n\nstock_pos = nx.spring_layout(G)\nplt.rcParams.update({'figure.figsize': (15, 15)})\n# Draw external edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_size=0,    \n    edgelist=external, edge_color=\"#333333\", with_labels=False)\n# Draw nodes and internal edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_color=node_color,    \n    edgelist=internal, edge_color=internal_color, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tuple(sorted(c) for c in next(communities_gn))\n#print(\"List of GN Community = \", list(communities_gn))\n# for communities in itertools.islice(comp, k):\n#     print(tuple(sorted(c) for c in communities)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Community detection using CNM\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\n\ncommunities_cnm = sorted(nxcom.greedy_modularity_communities(G), key=len, reverse=True) # contains information of community\n# Set node and edge communities\nset_node_community(G, communities_cnm)\nset_edge_community(G)\nprint(\"CNM Communities: \", len(communities_cnm))\n\n# Set community color for nodes\nnode_color = [    \n    get_color(G.nodes[v]['community'])    \n    for v in G.nodes]\n\n# Set community color for internal edgese\nexternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] == 0]\ninternal = [    \n    (v, w) for v, w in G.edges    \n    if G.edges[v, w]['community'] > 0]\ninternal_color = [    \n    get_color(G.edges[e]['community'])    \n    for e in internal]\n\nstock_pos = nx.spring_layout(G)\nplt.rcParams.update({'figure.figsize': (15, 15)})\n# Draw external edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_size=0,    \n    edgelist=external, edge_color=\"#333333\", with_labels=False)\n# Draw nodes and internal edges\nnx.draw_networkx(    \n    G, pos=stock_pos, node_color=node_color,    \n    edgelist=internal, edge_color=internal_color, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"communities_cnm # contains information of community","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Community detection using Fluid Communities\n# cor_thresold = 0.6\n# G = build_graph(stocks_cross_corr, cor_thresold)\n# number_of_communities = 10\n# result = nxcom.asyn_fluidc(G, number_of_communities)\n# communities_fluid = next(result)\n# # Set node and edge communities\n# set_node_community(G, communities_fluid)\n# set_edge_community(G)\n# print(\"Fluid Communities: \", len(communities_fluid))\n\n# # Set community color for nodes\n# node_color = [    \n#     get_color(G.nodes[v]['community'])    \n#     for v in G.nodes]\n\n# # Set community color for internal edgese\n# external = [    \n#     (v, w) for v, w in G.edges    \n#     if G.edges[v, w]['community'] == 0]\n# internal = [    \n#     (v, w) for v, w in G.edges    \n#     if G.edges[v, w]['community'] > 0]\n# internal_color = [    \n#     get_color(G.edges[e]['community'])    \n#     for e in internal]\n\n# stock_pos = nx.spring_layout(G)\n# plt.rcParams.update({'figure.figsize': (15, 15)})\n# # Draw external edges\n# nx.draw_networkx(    \n#     G, pos=stock_pos, node_size=0,    \n#     edgelist=external, edge_color=\"#333333\", with_labels=False)\n# # Draw nodes and internal edges\n# nx.draw_networkx(    \n#     G, pos=stock_pos, node_color=node_color,    \n#     edgelist=internal, edge_color=internal_color, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cliques = list(nx.find_cliques(G))\nmax_clique = max(cliques, key=len)\n# Visualize maximum clique\nnode_color = [(0.5, 0.5, 0.5) for v in G.nodes()]\nfor i, v in enumerate(G.nodes()):\n    if v in max_clique:\n        node_color[i] = (0.5, 0.5, 0.9)\nnx.draw_networkx(G, node_color=node_color, pos=stock_pos, with_labels=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create graph and write it as GraphML\n#stocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\n#stocks_cross_corr = stocks_cross_corr[1]\ncor_thresold = 0.6\nG = build_graph(stocks_cross_corr, cor_thresold)\n\n#sp_500_graph_06.graphml\n#sp_500_graph_08.graphml\n#stocks_2B_graph_06.graphml\n# stocks_2B_graph_08.graphml\nnx.write_graphml(G,'sp_500_graph_06.graphml')\n#stocks_cross_corr, _, _ = calculate_corr(df_stock_prices,1, len(df_stock_prices), 'pearson')\n#stocks_cross_corr = stocks_cross_corr[1]\ncor_thresold = 0.8\nG = build_graph(stocks_cross_corr, cor_thresold)\n\nnx.write_graphml(G,'sp_500_graph_08.graphml')\n# g = Graph(directed=False)\n# g.add_vertices(len(edges))\n# i = 0\n# for x in edges:\n#     g.vs[i][\"id\"] = x\n#     g.vs[i][\"label\"] = x\n#     i = i + 1\n\n# # g.es[\"weight\"] = weights\n# # g.es[\"label\"] = weights\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import igraph as ig\nfrom tabulate import tabulate\n\nGix08 = ig.read('sp_500_graph_08.graphml',format=\"graphml\")\nGix06 = ig.read('sp_500_graph_06.graphml',format=\"graphml\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gix06.es[\"weight\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Community detection with CNM \ndendrogram_cnm = Gix06.community_fastgreedy(weights=\"weight\")\noptimal_count_cnm = dendrogram_cnm.optimal_count\nprint(\"CNM Optimum community count: \", optimal_count_cnm)\n# convert it into a flat clustering\nclusters_cnm = dendrogram_cnm.as_clustering()\n# get the membership vector\nmembership_cnm = clusters_cnm.membership\nmodularity_cnm = clusters_cnm.q\nprint(\"Modularity: \", modularity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(1)\n\nig.plot(clusters_cnm, label=True, mark_groups = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"community_list_cnm = []\nfor name, membership in zip(Gix06.vs[\"id\"], membership_cnm):\n    community_list_cnm.append([name, membership])\n#     print(name, membership)\ndf_community_cnm = pd.DataFrame(community_list_cnm, columns = ['symbol', 'community'])\n# df_community_cnm.set_index('symbol',inplace=True)\n# df_community_cnm.sort_values(by=['community', 'symbol'], inplace=True)\n\ndf_community_cnm = df_community_cnm.groupby('community', as_index=True).agg(lambda x: ', '.join(set(x.astype(str))))\nprint(df_community_cnm.to_markdown())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}