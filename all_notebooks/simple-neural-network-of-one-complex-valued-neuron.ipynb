{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os #Sistem \nimport warnings #uyarÄ±lar\nprint(os.listdir(\"../input/\"))\nwarnings.filterwarnings(\"ignore\")\n# simple neural network of one complex valued neuron\n# extended to use a periodic activation function\nimport numpy\n# pandas for reading csv files\nimport pandas\n# sklearn for splitting data into test/train sets\n#import sklearn.cross_validation\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class neuralNetwork:\n    \n    def __init__(self, inputs, cats, periods):\n        # number of inputs\n        self.inputs = inputs\n        \n        # link weights matrix\n        self.w = numpy.random.normal(0.0, pow(1.0, -0.5), (self.inputs + 1))\n        self.w = numpy.array(self.w, ndmin=2, dtype='complex128')\n        self.w += 1j * numpy.random.normal(0.0, pow(1.0, -0.5), (self.inputs + 1))\n        \n        # testing overrride\n        #self.w = numpy.array([1.0 + 0.0j, 1.0 + 0.0j], ndmin=2, dtype='complex128')\n        \n        # number of output class categories\n        self.categories = cats\n        \n        # todo periodicity\n        self.periodicity = periods\n        \n        pass\n    \n    def z_to_class(self, z):\n        # first work out the angle, but shift angle from [-pi/2, +pi.2] to [0,2pi]\n        angle = numpy.mod(numpy.angle(z) + 2*numpy.pi, 2*numpy.pi)\n        # from angle to category\n        p = int(numpy.floor (self.categories * self.periodicity * angle / (2*numpy.pi)))\n        p = numpy.mod(p, self.categories)\n        return p\n\n    def class_to_angles(self, c):\n        # class to several angles due to periodicity, using bisector\n        angles = (c + 0.5 + (self.categories * numpy.arange(self.periodicity))) / (self.categories * self.periodicity) * 2 * numpy.pi\n        return angles\n    \n    def status(self):\n        print (\"w = \", self.w)\n        print (\"categories = \", self.categories)\n        print (\"periodicity = \", self.periodicity)\n        pass\n\n    def query(self, inputs_list):\n        # add bias input\n        inputs_list.append(1.0)\n        \n        # convert input to complex\n        inputs = numpy.array(inputs_list, ndmin=2, dtype='complex128').T\n        #print(\"inputs = \\n\", inputs)\n        \n        # combine inputs, weighted\n        z = numpy.dot(self.w, inputs)\n        #print(\"z = \", z)\n        \n        # map to output classes\n        o = self.z_to_class(z)\n        #print(\"output = \", o)\n        #print (\"\")\n        return o\n    \n    def train(self, inputs_list, target):\n        # add bias input\n        inputs_list.append(1.0)\n        \n        # convert inputs and outputs list to 2d array\n        inputs = numpy.array(inputs_list, ndmin=2, dtype='complex128').T\n\n        # combine inputs, weighted\n        z = numpy.dot(self.w, inputs)[0]\n        \n        # desired angle from trainging set\n        # first get all possible angles\n        desired_angles = self.class_to_angles(target)\n        \n        # potential errors errors\n        errors =  numpy.exp(1j*desired_angles) - z\n        # select smallest error\n        e = errors[numpy.argmin(numpy.abs(errors))]\n        \n        # dw = e * x.T / (x.x.T)\n        dw = (e * numpy.conj(inputs.T)) / (self.inputs + 1)\n        #print(\"dw = \", dw)\n        self.w += dw\n        #print(\"new self.w = \", self.w )\n        #print(\"test new self.w with query = \", self.query(inputs.T))\n        #print(\"--\")\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create instance of neural network\nnumber_of_inputs = 4\ncategories = 3\nperiods = 3\n\nn = neuralNetwork(number_of_inputs, categories, periods)\nn.status()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# load the iris training data CSV file into a list\ndf = pandas.read_csv('../input/irisdata/iris.csv')\n# scale the lengths\ndf[['PW', 'PL', 'SW', 'SL']] = df[['PW', 'PL', 'SW', 'SL']].astype(numpy.float64) * 0.01\n\nimport sklearn.model_selection\n# shuffle and split dataframe into train and test sets, split 3/4 and 1/4\niris_train, iris_test = sklearn.model_selection.train_test_split(df, train_size=0.75)\n#iris_train, iris_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=9)\niris_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train neural network\n\nepochs = 2\n\nfor e in range(epochs):\n    # go through all records in the training data set\n    for idx, data in iris_train.iterrows():\n        data_list = data.tolist()\n        species = data_list[0]\n        lengths = data_list[1:]\n        n.train(lengths, species)\n        pass\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n.status()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# query after training\n\nscorecard = []\n\nfor idx, data in iris_test.iterrows():\n    data_list = data.tolist()\n    correct_species = int(data_list[0])\n    lengths = data_list[1:]\n    answer = n.query(lengths)\n    print(correct_species, answer)\n    if (answer == correct_species):\n        # network's answer matches correct answer, add 1 to scorecard\n        scorecard.append(1)\n    else:\n        # network's answer doesn't match correct answer, add 0 to scorecard\n        scorecard.append(0)\n        pass\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate the performance score, the fraction of correct answers\nscorecard_array = numpy.asarray(scorecard)\nprint (\"performance = \", scorecard_array.sum() / scorecard_array.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performance over %90 is done selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"while True:\n    # train neural network\n\n    epochs = 2\n\n    for e in range(epochs):\n        # go through all records in the training data set\n        for idx, data in iris_train.iterrows():\n            data_list = data.tolist()\n            species = data_list[0]\n            lengths = data_list[1:]\n            n.train(lengths, species)\n            pass\n        pass\n\n    # query after training\n\n    scorecard = []\n\n    for idx, data in iris_test.iterrows():\n        data_list = data.tolist()\n        correct_species = int(data_list[0])\n        lengths = data_list[1:]\n        answer = n.query(lengths)\n        #print(correct_species, answer)\n        if (answer == correct_species):\n            # network's answer matches correct answer, add 1 to scorecard\n            scorecard.append(1)\n        else:\n            # network's answer doesn't match correct answer, add 0 to scorecard\n            scorecard.append(0)\n            pass\n        pass\n\n    # calculate the performance score, the fraction of correct answers\n    scorecard_array = numpy.asarray(scorecard)\n    sonuc =  scorecard_array.sum() / scorecard_array.size\n    print(sonuc)\n    if sonuc >0.9:\n        break\n        \nprint (\"performance = \", scorecard_array.sum() / scorecard_array.size)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}