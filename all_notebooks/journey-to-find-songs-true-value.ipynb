{"cells":[{"metadata":{"_uuid":"96bc49c01e4f7e6b137f6c115757da89b1513eb5","_cell_guid":"c0fbca38-68e0-49a5-ae4b-dd5a6e51563d"},"cell_type":"markdown","source":"Usually, people bring up the total streaming amount to show how much did public like the music. \n\nbut\n\nI believe,  the total streaming amount is just showing off how many people it can reach.\nThere can be many songs that you might like, but you don't listen to because you don't know its presence\n\nand like such, the streaming amount is not covering all the people that will like the music. \n\nThere are songs that obtained its accessibility to population and reached high position and streaming amount, but collapsed right after its surge. \n\nAlso there can be good songs that didn't reach out to people yet, but  possessing a potential to be popular.\n\n\nEven the Gangnam style which had the potential to be globally popular,  stayed very low streaming amount before accidently got the access to global consumers.  \n\nIt obtained the access to global population at the end of 2012 and made a massive explosion. even now people come up with the horse riding dance\n\nIts potential could not had been seen clearly through its total streaming before becoming popular.\n\nBringing up the total streaming value as a measurement may not be a correct way to see \n\n-----------------\n\n\nIn this kernel, Instead of the total streaming amount,  In order to witness and measure the true value of songs,  \n\nThe kernel is applying an idea that repeated consumption is a decent measurement to witness the consumer satisfaction.\n\nWe are going to sort music by how long it maintained its consumers, measuring the value only by people who have at least listened to it once, whether they move out or stay in, not the people who potentially like it, usually deemed as the total streaming amount. \n\nThis way, we might have been able to anticipate the Gangnam style's potential even before it got its accessibility.  \n\n"},{"metadata":{"_uuid":"8a3f6fc051243ac5266eddde870d705ce7db8564","_cell_guid":"813986ac-23fe-4408-86c1-e77fcd029221"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_kg_hide-input":true,"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"408886dac04b34569a9fba33123256ee86acecd2","_cell_guid":"bf5ca4db-ccb4-4c84-bec3-adee18185838","collapsed":true,"trusted":false},"cell_type":"code","source":"spo = pd.read_csv('../input/spotifys-worldwide-daily-song-ranking/data.csv')\nreleasedate = pd.read_csv('../input/spotifys-daily-song-ranking-music-released-date/spotify_music_released_date.csv', header = None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e121f3566c6bf38d176e42dd5b90e1e0e8f4635","_cell_guid":"2fb6aaaa-8156-4bf0-9a73-1b760daa1b72","collapsed":true,"trusted":false},"cell_type":"code","source":"releasedate = releasedate.dropna()\ndef fam(x):\n    return datetime.strptime(x[:10] , \"%Y-%m-%d\") \nmj = releasedate[1].map(fam)\nreleasedate.iloc[:,1] = mj","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c67283a8781ed546f7d1b7bfb62f37ac9129864c","_cell_guid":"95132c00-17c3-4f87-97e7-4ea1c1316350"},"cell_type":"markdown","source":"modify the list of songs' released date into a datetime format."},{"metadata":{"_uuid":"fb9cb54236f9dc797de525ebd69470fe3770ae21","_cell_guid":"86d52138-a309-4936-a33e-f3192238d4f9","collapsed":true,"trusted":false},"cell_type":"code","source":"releasedate.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"436a410d7552c8eb72bc07c25b523d768879c5c4","_cell_guid":"7be2e117-0591-4f5a-b3cd-7c3bf8e04eef"},"cell_type":"markdown","source":"Since, due to the inherent limitation in the dataset, that the full charts are only between 2017 and 2018, To watch the entire streaming life cycle of a music, we are going to limit the sample for the kernel to only songs that are released between 2017-1-1 and 2017-4-1\n\n*through this sampling process, 'New Rules' and 'Havana' are excluded. They were the true outliers and I really liked them which were released in the middle of 2017.  "},{"metadata":{"_uuid":"192198c7ac0ff0808768a0a89aa6ec20c09dd3ab","_cell_guid":"62d172fd-a90e-40be-9342-b461ed50c157","collapsed":true,"trusted":false},"cell_type":"code","source":"releasedate = releasedate[releasedate[1] >= datetime(2017,1,1)]\nreleasedate = releasedate[releasedate[1] <= datetime(2017,4,1)] \ntglist = list(releasedate[0])                                       \nfg = lambda x : True if x in tglist else False\nnewspo = spo['Track Name'].map(fg) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fec8bb8f66a6a39987bc7383a8c7a4954e4ce1a","_cell_guid":"1585dcfe-c3d0-4f70-9c7f-a6150cd56c21"},"cell_type":"markdown","source":"Here are the samples we are going to line them up"},{"metadata":{"_uuid":"d461a106b00061ddd630572ab0ce833db940f8e6","_cell_guid":"afa459e2-f41f-40f8-bb51-b0373dede9dd","collapsed":true,"trusted":false},"cell_type":"code","source":"spo[newspo].head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d49c0a4e929a95e19d6ce274659581b0d79194ef","_cell_guid":"739a87bb-744a-4ed5-98c2-e795f7d45076"},"cell_type":"markdown","source":"Not using the raw streaming data, we are going deploy a trend function and re-create the data.\nThis is because the raw streaming data fluctuate too much"},{"metadata":{"_uuid":"337995b3ccfa1f6199d76aa9cc89300249b69a0d","_cell_guid":"0b262329-4081-4805-889b-fd5a8a56f247","collapsed":true,"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"finaldf = pd.DataFrame(index = tglist, columns = ['value','streaminglevel', 'startdate', 'entlen' ,'morethan70len', 'maxlen'])\nfor iname in tglist:\n    testRickey = spo[spo['Track Name'] ==iname].groupby('Date').sum()\n    testRickey = testRickey.reset_index()\n    susul2 = testRickey.loc[:,['Date','Streams']]\n    susul2['Ra'] = range(len(susul2))\n    ym = np.array(susul2['Streams'])\n    xm = np.array(susul2['Ra'])\n    zm = np.polyfit(xm, ym, 30)                                                   \n    fm = np.poly1d(zm)                     \n    x_Me = np.linspace(xm[0], xm[-1], len(testRickey))\n    y_Me = fm(x_Me)                         \n    newdict = { 'x' : x_Me, 'y' : y_Me}                 \n    newdictdf = pd.DataFrame(newdict)  \n    paramss = 0.7\n    L = newdictdf['y'] >= (newdictdf['y'].max()*paramss)     \n    newdictdf['TF'] = L                                         \n    finaldf.loc[iname,'value'] = L.sum()/len(testRickey)\n    finaldf.loc[iname,'streaminglevel']= y_Me.max()/100000\n    finaldf.loc[iname,'startdate'] = susul2.iloc[0,0]\n    finaldf.loc[iname,'entlen'] =  len(testRickey)\n    finaldf.loc[iname,'morethan70len'] =  L.sum()\n    finaldf.loc[iname,'maxlen'] =  371   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5864e5cf0129e69f692a7b5da2536692cc7a15f9","_cell_guid":"c4c339c2-7d26-4bec-9f71-fd6e78953c34"},"cell_type":"markdown","source":"'maxlen' is 371, the full length of the dataset from 2017 to 2018. \n\n'entlen' is the length the music stayed on the chart\n\n'morethan70len' is the length  that streaming amount is more than 70 percent of each song's maximum.\n\n'streaming level' is the maximum streaming amount. divided it by 100,000 to see it easily. \n\n'startdate' is the first date that the music showed up on the chart.\n \n'value' is a morethan70len divided by the entlen\n"},{"metadata":{"_uuid":"4c63d24084f859ca74bd2b622182e79f9a7bd2ea","_cell_guid":"ff537446-5b1f-4841-8abf-973b35ab43ae","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"finaldf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef74d630a98906abfb4d1d68b9559686d1aafedb","_cell_guid":"b0006146-923f-4755-b237-b5353ad8e994"},"cell_type":"markdown","source":"Just to make it more clear, we are going to sample it again for those only featuring decent amount of streaming.   at least 200,000\n\nThis is to eliminate possible problems, that music with too low streaming amount maintain their max streaming  as a default everyday and It is unclear whether it is losing its consumers or not  \n\nMusic with more than 200,000 streamings everyday will be observed clearly. "},{"metadata":{"_uuid":"e292cb5e02241e48fa2e4f3b80073ba19005c86a","_cell_guid":"c8f357d4-b121-4b18-92c0-d9be8608a8b7","collapsed":true,"trusted":false},"cell_type":"code","source":"finaldfsort = finaldf[(finaldf['streaminglevel'] > 2)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7b9b43647801e06b4742e9c29aabfbcfc48b3ce","_cell_guid":"84a4deea-43de-4433-a11c-9c85212a58b4"},"cell_type":"markdown","source":"Here is what we got!"},{"metadata":{"_uuid":"ea21bda692e5b384788710339432db42c15ec056","_cell_guid":"1f718773-b93a-4b0c-89c1-eaa7c5a8443a","collapsed":true,"trusted":false},"cell_type":"code","source":"New_method_list = finaldfsort.sort_values(by = ['morethan70len','value'], ascending = False)\nNew_method_list.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c96d4ef6a74da581d42461538c1b9b682350a096","_cell_guid":"9972a84c-3a4b-4379-a61f-a2455b80bd2f"},"cell_type":"markdown","source":"Those songs are amazing!\nTop 10 music maintained their consumers for almost the entire year. "},{"metadata":{"_uuid":"cee39c58914c5cd6664ec90b70ba6f835229b325","_cell_guid":"0e9e3168-eaea-4281-b23d-49bb7726e571"},"cell_type":"markdown","source":"What if we sort music by its total streaming amount"},{"metadata":{"_uuid":"3fb253ffaaef8df40ab60ed4134700197cc21367","_cell_guid":"0eaa6113-6dda-4bbd-bd3d-f1e87f34e639","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"ordinary_method_list = spo[newspo].groupby('Track Name').sum().sort_values(by = 'Streams', ascending = False)\nordinary_method_list.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35ec8c25205009f4f3593568a795b08b07f7ff6c","_cell_guid":"ccbbb717-07f3-47d6-b4ee-552b1f259b20"},"cell_type":"markdown","source":"Let's compare both rankings with visualization"},{"metadata":{"_uuid":"41541d56ade73899ef58f29a586963c4413cbe21","_cell_guid":"81293c4a-23dd-4980-a552-80f949b9557f","collapsed":true,"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(10, 2, figsize=(13,70))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71153a4f257630d01dd6935535eade537fdedb2b","_cell_guid":"bddd2eee-1c20-4892-9941-8b76ddf06174","collapsed":true,"trusted":false},"cell_type":"code","source":"for num, iname in enumerate(list(New_method_list.head(10).index)):\n    testRickey = spo[spo['Track Name'] ==iname].groupby('Date').sum()\n    testRickey = testRickey.reset_index()\n    susul2 = testRickey.loc[:,['Date','Streams']]\n    susul2['Ra'] = range(len(susul2))\n    ym = np.array(susul2['Streams'])\n    xm = np.array(susul2['Ra'])\n    zm = np.polyfit(xm, ym, 30)  \n    fm = np.poly1d(zm)    \n    x_Me = np.linspace(xm[0], xm[-1], len(testRickey))\n    y_Me = fm(x_Me)\n    newdict = { 'x' : x_Me, 'y' : y_Me}                 \n    newdictdf = pd.DataFrame(newdict) \n    paramss = 0.7\n    L = newdictdf['y'] >= (newdictdf['y'].max()*paramss)\n    newdictdf['TF'] = L                                       \n    ax[num,1].plot(xm,ym,'o', x_Me, y_Me)\n    ax[num,1].set_title(\"lined up by how long it maintains {0} , Title = {1}\".format(num,iname))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0a9104311805b9abd269b2417c6875a29b70d31","_cell_guid":"f5774d3e-a21a-4e0a-a71f-273c97e4f908","collapsed":true,"trusted":false},"cell_type":"code","source":"for num, iname in enumerate(list(ordinary_method_list.head(10).reset_index()['Track Name'])):\n    testRickey = spo[spo['Track Name'] ==iname].groupby('Date').sum()\n    testRickey = testRickey.reset_index()\n    susul2 = testRickey.loc[:,['Date','Streams']]\n    susul2['Ra'] = range(len(susul2))\n    ym = np.array(susul2['Streams'])\n    xm = np.array(susul2['Ra'])\n    zm = np.polyfit(xm, ym, 30)                                                      \n    fm = np.poly1d(zm)                      \n    x_Me = np.linspace(xm[0], xm[-1], len(testRickey))\n    y_Me = fm(x_Me)                         \n    newdict = { 'x' : x_Me, 'y' : y_Me}                 \n    newdictdf = pd.DataFrame(newdict)  \n    paramss = 0.7\n    L = newdictdf['y'] >= (newdictdf['y'].max()*paramss)    \n    newdictdf['TF'] = L                                        \n    ax[num,0].plot(xm,ym,'o', x_Me, y_Me)\n    ax[num,0].set_title(\"lined up by total streaming amount {0} , Title = {1}\".format(num,iname))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d7df3c8b576fbd6cbaf0fb6c6465833e523e7ce","_cell_guid":"8f90939b-1632-4b56-a7e3-2a25a9f561f5","trusted":false,"collapsed":true},"cell_type":"code","source":"fig","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46a01b79748050398c3496ae6a0b1986b09969e9","_cell_guid":"e4c42005-7e80-4ed7-bdb2-15a11d49ec93"},"cell_type":"markdown","source":"What we see here is that most of the songs ranked high with total streaming value, didn't really maintained its consumers, they left out earlier than songs on the right side. \n\nThe song named 'Congratulations' reached very high position by the total streaming amount and also ranked high by maintaing its consumers which is the best music I present. "},{"metadata":{"_uuid":"80b4b6eb4d9f8732a8650c14cc9a18a644c640ca","_cell_guid":"6bb2eb66-df67-4f1f-9401-d62ccdec05f3"},"cell_type":"markdown","source":"In this kernel, we assume that music only reach their established consumers immediately after release, and there is low possibility that new listeners comming in as time goes by.\nIn addition, we had filtered music which streaming level is more than 200,000, once again eliminating such cases.\nSo the longer it maintained its streaming amount the more those fans repeatedly listened to it, indicating that music is more valuable.\nThose music could have made a global explosion if they had obtained an accessibility to more population.  \n\n\n\nSome might argue that those songs ranked high with total streaming amount is still featuring absolutely more number of streaming amount compare to the songs filtered by the new method, so they worths much more than those songs.\nBut still, the fact that they lost their consumers who once approached, that is the point of the kernel. "},{"metadata":{"_uuid":"f7753533c9c15fd601a6866b6a2c30744fdbee8e","_cell_guid":"55e4c63c-faef-4565-b723-12874291653c"},"cell_type":"markdown","source":"I admit that streaming amount is a combination of various  factors and this kernel is written on very strict limitations. The frame for the observation was limited to only one year from 2017 to 2018 \nwhich led us to only sample songs only released between 2017-1-1 and 2017-4-1 excluding so many awesome songs. \n\nIt could have been more awesome if we were able to observe all songs. \n\nBut the idea, to rank songs by how long they maintained their consumers was worth a try. \n\nThanks for reading. \n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b7162281d61ce0eebd14345dfb73b067a1c09f2c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}