{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/data-set/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df[\"CustomerAttrition\"]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df[['sex', 'Aged', 'Married', 'TotalDependents', 'ServiceSpan',\n       'MobileService', '4GService', 'CyberProtection', 'HardwareSupport',\n       'TechnicalAssistance', 'FilmSubscription', 'SettlementProcess',\n       'QuarterlyPayment', 'GrandPayment']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_count = df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_values_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_with_missing = [col for col in df.columns\n                     if df[col].isnull().any()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfor col in cols_with_missing:\n    df[col + '_was_missing'] = df[col].isnull()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df=df.fillna(0)\nmean_value=df['GrandPayment'].mean()\ndf['GrandPayment'].fillna(value=mean_value, inplace=True)\n#df['GrandPayment']=df['GrandPayment'].fillna(value=mean_value, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df.GrandPayment==mean_value).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df[['sex', 'Aged', 'Married', 'TotalDependents', 'ServiceSpan',\n       'MobileService', '4GService', 'CyberProtection', 'HardwareSupport',\n       'TechnicalAssistance', 'FilmSubscription', 'SettlementProcess',\n       'QuarterlyPayment', 'GrandPayment']]#,'GrandPayment_was_missing']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=df[ 'CustomerAttrition']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = (x.dtypes == 'object')  # || x.dtypes=='bool')\nobject_cols = list(s[s].index)\n\n#object_cols.append('GrandPayment_was_missing')\nprint(\"Categorical variables:\")\nprint(object_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y2=y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y= label_encoder.fit_transform(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier,XGBRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(x[object_cols]))\n#OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = x.index\n#OH_cols_valid.index = X_valid.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = x.drop(object_cols, axis=1)\n#num_X_valid = X_valid.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_X = pd.concat([num_X_train, OH_cols_train], axis=1)\n#OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores =   cross_val_score(tesla_model ,OH_X ,y,\n                             cv=5,\n                            scoring='accuracy')\n\nprint(\"MAE scores:\\n\", scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC, SVC\nlsvc = LinearSVC(C=0.05, penalty=\"l1\", dual=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = OH_X.mean(axis=0)\nOH_X -= mean\nstd = OH_X.std(axis=0)\nOH_X /= std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(OH_X, y, stratify=y, random_state=42, test_size = 0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\n\nY_train = to_categorical(y_train, num_classes=None)\nY_test = to_categorical(y_test, num_classes=None)\nprint (Y_train.shape)\nprint (Y_train[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.layers import Dropout\nfrom keras import regularizers\n\n# define a function to build the keras model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(32, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(28,)))\n    model.add(Dense(32, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(8, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n    model.add(Dense(8, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(16, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n    model.add(Dense(16, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(2, activation='softmax'))\n    \n    # compile model\n    adam = Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n    return model\n\nmodel = create_model()\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" Y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=100, batch_size=10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n# Model accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Losss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tesla_model = RandomForestClassifier(max_leaf_nodes=40,random_state = 5)\ntesla_model1=LinearSVC(C=0.05, penalty=\"l1\", dual=False)\nX_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=42)\ntesla_model1.fit(X_train, y_train)\nmae = mean_absolute_error(y_test,tesla_model1.predict(X_test))\nmae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"0.20425867507886436","metadata":{}},{"cell_type":"code","source":"tesla_model = RandomForestClassifier(max_leaf_nodes=40,random_state = 5)\ntesla_model2=LinearSVC(C=0.07, penalty=\"l1\", dual=False)\nX_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2, random_state=42)\ntesla_model2.fit(X_train, y_train)\nmae = mean_absolute_error(y_test,tesla_model2.predict(X_test))\nmae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tesla_model = DecisionTreeClassifier(max_leaf_nodes=50,random_state = 1)\nX_train, X_test, y_train, y_test = train_test_split(OH_X, y, test_size=0.2, random_state=42)\ntesla_model.fit(X_train, y_train)\nmae = mean_absolute_error(y_test,tesla_model.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model=XGBClassifier(learning_rate =0.008,n_estimators=1200,max_depth=6)\nmodel2=XGBClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVC()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nnormalized_X = preprocessing.scale(OH_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import datasets, linear_model\nlasso = linear_model.Lasso()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVR\nsvm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* MAE\nscores =   cross_val_score(clf , normalized_X  ,y,\n                             cv=5,\n                            scoring='accuracy')\n\nprint(\"MAE scores:\\n\", scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Average MAE score (across experiments):\")\nprint(scores.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Average MAE score (across experiments):\n0.21000375959505924","metadata":{}},{"cell_type":"markdown","source":"Average MAE score (across experiments) svm:\n0.2650678843439009","metadata":{}},{"cell_type":"markdown","source":"0.24282315711372648","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n  \n# Creating the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': [0.1, 1, 10, 100, 1000], \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']} \n  \n# Instantiating logistic regression classifier\nfrom sklearn import svm\nclf = svm.SVC()\n  \n# Instantiating the GridSearchCV object\nlogreg_cv = GridSearchCV(clf , param_grid, cv = 5)\n  \nlogreg_cv.fit(normalized_X, y)\n  \n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \nprint(\"Best score is {}\".format(logreg_cv.best_score_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf3=svm.SVC(C= 1000, gamma= 10, kernel= 'rbf')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores =   cross_val_score(svm_poly_reg , normalized_X  ,y,\n                             cv=5)\n\nprint(\"MAE scores:\\n\", scores)\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nOH_X_train, OH_X_valid, y_train, y_valid=train_test_split(OH_X,y,test_size=0.2,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom xgboost import XGBClassifier,XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import svm #Perforing grid search\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    #model = GridSearchCV(estimator = XGBClassifier( learning_rate=0.01, n_estimators=1000, max_depth=4,cv=5) ,param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n    #model =XGBRegressor( learning_rate =0.008,n_estimators=1200,max_depth=6)\n    clf = svm_poly_reg\n    clf.fit(X_train, y_train)\n    #model.fit(X_train, X_train)\n    preds = clf.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_poly_reg.fit(normalized_X  ,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"OH_X_train, OH_X_valid, y_train, y_valid","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeClassifier\n\ndef get_mae(max_leaf_nodes,OH_X_train, OH_X_valid, y_train, y_valid):\n    model = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n    model.fit(OH_X_train, y_train)\n    preds_val = model.predict(OH_X_valid)\n    mae = mean_absolute_error(y_valid, preds_val)\n    return(mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes,OH_X_train, OH_X_valid, y_train, y_valid)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OH_X_train.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=pd.read_csv(\"../input/data-set/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k=df2.iloc[0:,1:15]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = (k.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_test = pd.DataFrame(OH_encoder.fit_transform(k[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_test.index = k.index\n\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_test = k.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_y = pd.concat([num_test, OH_cols_test], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c=OH_y.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_value=OH_y['GrandPayment'].mean()\nOH_y['GrandPayment'].fillna(value=mean_value, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml=tesla_model1.predict(OH_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml2=np.round(ml)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=df2['ID']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml2 = pd.Series(ml2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = pd.DataFrame(df3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ml2 = ml2.rename('CustomerAttrition')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4 = df3.join(ml2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(df4)\n\n# ↓ ↓ ↓  Yay, download link! ↓ ↓ ↓ ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}