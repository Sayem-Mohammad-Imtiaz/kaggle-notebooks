{"cells":[{"metadata":{},"cell_type":"markdown","source":"Dataset Exploration and Utilisation\n========\n\nLet's have a look at our dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pathlib\nimport os\nimport io\nfrom collections import namedtuple, OrderedDict\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nimport IPython.display as display\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading dataset into train/test"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/playing-cards-dataset'\npath_train = os.path.join(path,'train_zipped')\npath_test = os.path.join(path,'test_zipped')\nprint(path_train)\n\ntrain = pd.read_csv(os.path.join(path,'train_cards_label.csv'))\ntest = pd.read_csv(os.path.join(path,'test_cards_label.csv'))\nprint(train.shape)\nprint(test.shape)\nprint('_' * 49)\nprint(train.head())\nprint('_' * 100)\nprint(test.head())\nprint(train['class'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, each card has several identified classes (up to 8)\n\nWe have a 5 000 dataset for training\n\nWe have a 1 000 dataset for testing\n\nNow, let's display an image"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def display_image(i):\n    row = train.filename.unique()\n    try:\n        img = cv2.imread(os.path.join(path_train, row[i]))[...,::-1]\n        print(img.shape)\n        plt.axis(\"off\")\n        plt.imshow(img)\n        plt.show()\n    except:\n        print('out of bound')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_image(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a dataset generator with tf.data\n\nWe will convert these images to 500x500 so as to lower the computational time, and scale them by 255.\n\nLet's build our own pipeline by using batch of 256 (big enough to mesure F1 score)\n\n- Parse xml do a dict\n- Create TF record \n- Create datasate with tf.data"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 500\nCHANNELS = 3\nBATCH_SIZE = 256\nSHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\nN_LABELS = 52","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nlist_ds = tf.data.Dataset.list_files(str(path_train+'/*.jpg'))\nfor f in list_ds.take(5):\n    print(f.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recursive_parse_xml_to_dict(xml):\n    \"\"\"Recursively parses XML contents to python dict.\"\"\"\n    if not xml:\n        return {xml.tag: xml.text}\n    result = {}\n    for child in xml:\n        child_result = recursive_parse_xml_to_dict(child)\n        if child.tag != 'object':\n            result[child.tag] = child_result[child.tag]\n        else:\n            if child.tag not in result:\n                result[child.tag] = []\n            result[child.tag].append(child_result[child.tag])\n    return {xml.tag: result}\n\ndef read_examples_list(path):\n    \"\"\"Read list of training or validation examples.\"\"\"\n    with tf.gfile.GFile(path) as fid:\n        lines = fid.readlines()\n    return [line.strip().split(' ')[0] for line in lines]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def class_text_to_int(row_label):\n    if row_label == '2s':\n        return 33\n    elif row_label == '2c':\n        return 34\n    elif row_label == '2d':\n        return 35\n    elif row_label == '2h':\n        return 36\n    elif row_label == '3s':\n        return 37\n    elif row_label == '3c':\n        return 38\n    elif row_label == '3d':\n        return 39\n    elif row_label == '3h':\n        return 40\n    elif row_label == '4s':\n        return 41\n    elif row_label == '4c':\n        return 42\n    elif row_label == '4d':\n        return 43\n    elif row_label == '4h':\n        return 44\n    elif row_label == '5s':\n        return 45\n    elif row_label == '5c':\n        return 46\n    elif row_label == '5d':\n        return 47\n    elif row_label == '5h':\n        return 48\n    elif row_label == '6s':\n        return 49\n    elif row_label == '6c':\n        return 50\n    elif row_label == '6d':\n        return 51\n    elif row_label == '6h':\n        return 52\n    elif row_label == '7s':\n        return 1\n    elif row_label == '8s':\n        return 2\n    elif row_label == '9s':\n        return 3\n    elif row_label == 'Qs':\n        return 4\n    elif row_label == 'Ks':\n        return 5\n    elif row_label == '10s':\n        return 6\n    elif row_label == 'As':\n        return 7\n    elif row_label == 'Js':\n        return 8\n    elif row_label == '7h':\n        return 9\n    elif row_label == '8h':\n        return 10\n    elif row_label == '9h':\n        return 11\n    elif row_label == 'Qh':\n        return 12\n    elif row_label == 'Kh':\n        return 13\n    elif row_label == '10h':\n        return 14\n    elif row_label == 'Ah':\n        return 15\n    elif row_label == 'Jh':\n        return 16\n    elif row_label == '7d':\n        return 17\n    elif row_label == '8d':\n        return 18\n    elif row_label == '9d':\n        return 19\n    elif row_label == 'Qd':\n        return 20\n    elif row_label == 'Kd':\n        return 21\n    elif row_label == '10d':\n        return 22\n    elif row_label == 'Ad':\n        return 23\n    elif row_label == 'Jd':\n        return 24\n    elif row_label == '7c':\n        return 25\n    elif row_label == '8c':\n        return 26\n    elif row_label == '9c':\n        return 27\n    elif row_label == 'Qc':\n        return 28\n    elif row_label == 'Kc':\n        return 29\n    elif row_label == '10c':\n        return 30\n    elif row_label == 'Ac':\n        return 31\n    elif row_label == 'Jc':\n        return 32\n    else:\n        return 0\n    \ndef split(df, group):\n    data = namedtuple('data', ['filename', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\ndef create_tf_example(group, path):\n    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n    filename = group.filename.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n    for index, row in group.object.iterrows():\n        xmins.append(row['xmin'] / width)\n        xmaxs.append(row['xmax'] / width)\n        ymins.append(row['ymin'] / height)\n        ymaxs.append(row['ymax'] / height)\n        classes_text.append(row['class'].encode('utf8'))\n        classes.append(class_text_to_int(row['class']))\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': int64_feature(height),\n        'image/width': int64_feature(width),\n        'image/filename': bytes_feature(filename),\n        'image/source_id': bytes_feature(filename),\n        'image/encoded': bytes_feature(encoded_jpg),\n        'image/format': bytes_feature(image_format),\n        'image/object/bbox/xmin': float_list_feature(xmins),\n        'image/object/bbox/xmax': float_list_feature(xmaxs),\n        'image/object/bbox/ymin': float_list_feature(ymins),\n        'image/object/bbox/ymax': float_list_feature(ymaxs),\n        'image/object/class/text': bytes_list_feature(classes_text),\n        'image/object/class/label': int64_list_feature(classes),\n    }))\n    return tf_example","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's read the TFRecord !"},{"metadata":{"trusted":true},"cell_type":"code","source":"filename_train = [os.path.join(path,'train.record')]\nfilename_test = [os.path.join(path,'test.record')]\n\ntrain_data = tf.data.TFRecordDataset(filename_train)\ntest_data = tf.data.TFRecordDataset(filename_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in train_data.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(data.numpy())\n    print(example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}