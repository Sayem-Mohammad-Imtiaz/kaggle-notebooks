{"cells":[{"metadata":{},"cell_type":"markdown","source":"Inspired by \"Traffic Sign Classification using ResNet\" Notebook ( https://www.kaggle.com/syamkakarla/traffic-sign-classification-using-resnet )"},{"metadata":{},"cell_type":"markdown","source":"# Import libraries. 必要なライブラリをインポート\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport cv2 as cv # (pip install opencv-python)\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.utils import to_categorical\nfrom keras.utils.io_utils import HDF5Matrix\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Activation, Input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.xception import Xception\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.layers.pooling import GlobalAveragePooling2D\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load train/test data from image directory. 学習・検証用データを画像ファイルディレクトリから取得\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train/test data path. 学習・検証用データが格納されているパス\npath = '../input/traffic-signs-classification/myData'\n# Get classes from sub directory's name. サブディレクトリの名前が交通標識のクラス名（分類名）になっているので、サブディレクトリのリストを取得\nclasses = os.listdir(path)\nprint(f'Total number of categories （クラス分類数）: {len(classes)}')\n\n# A dictionary which contains class and number of images in that class. クラス分類ごとのデータ数を取得して格納\ncounts = {}\nfor c in classes:\n    counts[c] = len(os.listdir(os.path.join(path, c)))\n\ntotal = sum(list(counts.values()))\nprint(f'Total number of images in dataset （全データ数）: {total}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot labels and item counts on chart. 学習・検証用各クラスのラベルと画像データ件数をグラフ表示する\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of images in each clsss plot. 学習・検証用画像データのラベルとその件数をグラフ表示\nfig = plt.figure(figsize = (25, 5))\nsns.barplot(x = list(counts.keys()), y = list(counts.values())).set_title('Number of train/test images in each class')\nplt.xticks(rotation = 90)\nplt.margins(x=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adjust image size, and add to list. 画像ディレクトリにある画像データファイルを読み込んでサイズを調整し、そのデータとラベルの情報をリストに格納する\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image size. 学習・検証用データの画像サイズ\n# ベースとするモデルの種類によっては、最小の画像サイズが異なるようなので注意する\n# たとえば Xception は 71x71 以上。ResNet50 は 197x197 以上ということだが、実は 32x32 でも大丈夫？（ https://keras.io/ja/applications/ ）\nimage_width = 32 # 32, 64, 96, 128\nimage_height = 32 # 32, 64, 96, 128\n\n# The images are RGB.\nimage_channels = 3\n\n# Get image and label data with ImageDataGenerator\ndatagen = ImageDataGenerator()\ndata = datagen.flow_from_directory(path,\n                                    target_size=(image_width, image_height),\n                                    batch_size=total,\n                                    class_mode='categorical',\n                                    shuffle=True )\n\nX , y = data.next()\n\n# Labels are one hot encoded\nprint(f\"Data Shape 画像データのリストの構造:{X.shape}\")\nprint(f\"Labels shape 正解ラベルのリストの構造:{y.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display image samples. 画像データのサンプルを表示\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(10,10, figsize=(18,18))\nfor i,ax in enumerate(axes.flat):\n    r = np.random.randint(X.shape[0])\n    ax.imshow(X[r].astype('uint8'))\n    ax.grid(False)\n    ax.axis('off')\n    ax.set_title('Label: '+str(np.argmax(y[r])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dividing data into train and test in the split percentage of 80:20. 学習用データと検証用データに分割\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)\nprint(\"Train Shape（学習用データ）: {}\\nTest Shape（検証用データ）: {}\".format(X_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Callback functions. モデルに適用するコールバック関数の定義\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Export model file name. 学習済みモデルの保存ファイル名\nbest_model_file_path = './best_model.hdf5'\n\n# ModelCheckpoint. 複数回学習を繰り返す中で、一番精度がよかったパターンのモデルを保存する\ncheckpoint = ModelCheckpoint(best_model_file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\n# EarlyStopping.　過学習を防止するための仕組み。学習の精度が上がらなくなった段階で実行を停止する\nearly_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='max', restore_best_weights=True)\n\n# ReduceLROnPlateau. 精度の改善が停滞した時に学習率を減らす\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the network. （参考）シンプルな CNN モデルを構築\n\nWe build a very basic neural network for classifying the images, based on a simple Keras demo script. The network is quick to train and well suited for small datasets like the one we are using. Dropout layers have been added to prevent overfitting\n\n後述の Fine Tuning の手法を利用しない場合は、以下のように、手動で独自の CNN モデルを構築する方法もあります"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = Sequential()\n#\n#model.add(Conv2D(64, (3, 3), padding='same',\n#                 input_shape=X_train.shape[1:]))\n#model.add(Activation('relu'))\n#model.add(Conv2D(64, (3, 3)))\n#model.add(Activation('relu'))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n#\n#model.add(Conv2D(128, (3, 3), padding='same'))\n#model.add(Activation('relu'))\n#model.add(Conv2D(128, (3, 3)))\n#model.add(Activation('relu'))\n#model.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n#\n#model.add(Flatten())\n#model.add(Dense(512))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.5))\n#model.add(Dense(y_test.shape[1]))\n#model.add(Activation('softmax'))\n## initiate RMSprop optimizer\n#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n#\n## Let's train the model using RMSprop\n#model.compile(loss='categorical_crossentropy',\n#              optimizer=opt,\n#              metrics=['accuracy'])\n#\n#loss_history = []\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for i in range(10):\n#    loss_history += [model.fit(X_train, y_train,\n#                               validation_data=(X_test, y_test), \n#                               batch_size = 256,\n#                               epochs = 1, shuffle=\"batch\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine Tuning. ファインチューニングの手法を用いてモデルを構築\n\nFine Tuning について： https://ymgsapo.com/2019/03/14/extend-model-and-fine-tuning/ など\n\nKeras で利用できるモデル： https://keras.io/ja/applications/\n\n以下のコードは、いくつか調整すべきポイントがあります。\n\n- ベースとするモデルの種類（ base_model。Xception、ResNet50、MobileNet など）\n- Optimizer の種類（ optimizer。adamax、adam、sgd など）\n- 学習対象とする層の数（ layer_index_freezed。どのレイヤー以降を trainable＝True とするか。あるいは、全ての層を再学習対象とするか）"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ベースとするモデルの中の一部のレイヤーのみを再学習対象にする場合（末尾の10層のみを再学習対象にする、など）は 'imagenet' を指定、\n# ベースとするモデルの全ての層で再学習させる場合は、None を指定\nweight = 'imagenet' # None\n\n#base_model = ResNet50(weights=weight, include_top=False, input_shape=(image_width,image_height,image_channels))\n#base_model = Xception(weights=weight, include_top=False, input_shape=(image_width,image_height,image_channels))\nbase_model = MobileNet(weights=weight, include_top=False, input_shape=(image_width,image_height,image_channels))\n\ntop_model = base_model.output\ntop_model = GlobalAveragePooling2D()(top_model)\ntop_model = Dropout(0.5)(top_model) # 入力にドロップアウトを適用する． 訓練時の更新においてランダムに入力ユニットを0とする割合であり，過学習の防止に役立ちます．\npredictions = Dense(len(classes), activation='softmax')(top_model)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Set layer to trainable / non-trainable. ベースとするモデルのどの層までを固定にして、どの層からを再学習対象にするかを決定\n# たとえば Xception モデルは全部で 135層のレイヤーから構成されているので、そのうちの130層目までを、固定、それ以降を再学習対象とする、という設定ができる\n# （ MobileNet は 90層、ResNet50 は 178層）\nif weight == 'imagenet':\n    trainable = False\n    layer_index_freezed = 85\n    index = 0\n    for layer in model.layers:\n        if index > layer_index_freezed:\n            trainable = True\n    \n        layer.trainable = trainable\n\n        # ただし、それ以前の層でも、Batch Normalization 層は再学習させる（参考： https://qiita.com/mokoenator/items/6d7b8f670d3d1250d516 ）\n        # Batch Normalization とは： http://tozensou32.blog76.fc2.com/blog-entry-40.html など\n        if layer.name.endswith('bn'):\n            layer.trainable = True\n        \n        index = index + 1\n\n# Model layers. モデルの層の数を表示\nprint(\"Model layers: {}層\".format(len(model.layers)))\n# Model summary. モデルの構造を表示\nprint(\"Model summary: モデルの構造：\")\nmodel.summary()\n\n# Optimizer. オプティマイザ（最適化アルゴリズム）\n# adam、adamax、sgd などが指定できる（ https://keras.io/ja/optimizers/ ）\noptimizer = 'adam' # 'adamax', 'sgd'\n\n# Compile the model. モデルを構築\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit the model. 構築したモデルを用いて学習を実行\n\n以下のコードは、いくつか調整すべきポイントがあります。\n\n- エポック数（ epochs ）\n- バッチサイズ（ batch_size ）"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Epochs. エポック数\n# 多いほど学習の回数が増えるが、多すぎると過学習となる可能性も高まる\nepochs = 5 # 5, 10, 20, 30, ...\n\n# Batch size. バッチサイズ\nbatch_size = 32 # 32, 64, 128, ...\n\n# Fit the model. 学習を実行\nhistory = model.fit(x=X_train, \n                    y=y_train, \n                    batch_size=batch_size, \n                    epochs=epochs, \n                    verbose=1, \n                    validation_data=(X_test, y_test), \n                    callbacks=[early_stopping, checkpoint, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examining Loss. 学習結果をグラフ表示\n\nThe following function shows the loss and accuracy over the course of training\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot learning curves\nfig = plt.figure(figsize = (17, 4))\n    \nplt.subplot(121)\nplt.plot(history.history['accuracy'], label = 'acc')\nplt.plot(history.history['val_accuracy'], label = 'val_acc')\n#plt.plot(history.history['acc'], label = 'acc')\n#plt.plot(history.history['val_acc'], label = 'val_acc')\nplt.legend()\nplt.grid()\nplt.title(f'accuracy')\n\nplt.subplot(122)\nplt.plot(history.history['loss'], label = 'loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.legend()\nplt.grid()\nplt.title(f'loss')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation Result. 性能評価\n\n以下の \"Test accuracy\" の値で、最終的な当モデルの性能を評価する\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading weights from best model. 一番精度の良かったパターンの結果を読み込む\nmodel.load_weights(best_model_file_path)\n\n# Evaluation result. 性能評価\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display prediction result samples. 予測結果のサンプルを表示\n\n以下のコードは変更せずに、そのままお使いください"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5,5, figsize=(18,18))\nfor i,ax in enumerate(axes.flat):\n    r = np.random.randint(X_test.shape[0])\n    ax.imshow(X_test[r].astype('uint8'))\n    ax.grid(False)\n    ax.axis('off')\n    ax.set_title('Original: {} Predicted: {}'.format(np.argmax(y_test[r]), np.argmax(model.predict(X_test[r].reshape(1, image_width, image_height, image_channels)))))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}