{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://www.kaggle.com/cabirerguven/weather-in-aus","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/cabirerguven/weather-in-aus\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T20:34:29.583949Z","iopub.execute_input":"2021-06-02T20:34:29.584295Z","iopub.status.idle":"2021-06-02T20:34:29.593777Z","shell.execute_reply.started":"2021-06-02T20:34:29.584266Z","shell.execute_reply":"2021-06-02T20:34:29.592793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1) Read the dataset as a dataframe. Create a copy of your dataframe\ndf = pd.read_csv(\"../input/weather-dataset-rattle-package/weatherAUS.csv\")\ndf_weather = df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:29.596515Z","iopub.execute_input":"2021-06-02T20:34:29.597038Z","iopub.status.idle":"2021-06-02T20:34:30.080973Z","shell.execute_reply.started":"2021-06-02T20:34:29.59699Z","shell.execute_reply":"2021-06-02T20:34:30.079895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2.Find out the describe and info attributes of the dataframe. \n# Analyze these information and create a short write-up according to your findings.\ndf_weather.describe()\n\n\n# Here we can see statistical values of given csv file such as min and max temperature, wind, sunshine, humidity pressure cloud \n# and many other information. Count, mean, std, quartiles etc tell us a lot about whole data.","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.082469Z","iopub.execute_input":"2021-06-02T20:34:30.082956Z","iopub.status.idle":"2021-06-02T20:34:30.264639Z","shell.execute_reply.started":"2021-06-02T20:34:30.082904Z","shell.execute_reply":"2021-06-02T20:34:30.263831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_weather.info()\n# here, we can see total entry numbers, all the column names, , their data types and non-null counts for given csv file.","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.266231Z","iopub.execute_input":"2021-06-02T20:34:30.266736Z","iopub.status.idle":"2021-06-02T20:34:30.374031Z","shell.execute_reply.started":"2021-06-02T20:34:30.26668Z","shell.execute_reply":"2021-06-02T20:34:30.373059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3.1 Find out the shape and \ndf_weather.shape\n# There are total 14560 entry and 23 columns","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.375501Z","iopub.execute_input":"2021-06-02T20:34:30.375821Z","iopub.status.idle":"2021-06-02T20:34:30.381099Z","shell.execute_reply.started":"2021-06-02T20:34:30.37579Z","shell.execute_reply":"2021-06-02T20:34:30.380203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3.2 size info of the dataset.\ndf_weather.size\n# There are total 3345580 elements in this object.","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.382391Z","iopub.execute_input":"2021-06-02T20:34:30.382671Z","iopub.status.idle":"2021-06-02T20:34:30.395063Z","shell.execute_reply.started":"2021-06-02T20:34:30.382643Z","shell.execute_reply":"2021-06-02T20:34:30.393974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4.Find out the types values of the columns and save the result as a dataframe.\nDATA_TYPES = pd.DataFrame(df.dtypes,columns=['DATA_TYPES'])\nDATA_TYPES","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.396498Z","iopub.execute_input":"2021-06-02T20:34:30.396804Z","iopub.status.idle":"2021-06-02T20:34:30.413719Z","shell.execute_reply.started":"2021-06-02T20:34:30.396775Z","shell.execute_reply":"2021-06-02T20:34:30.412613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5.Find out the non-null counts of the columns and save the result as a dataframe.\nNOT_NULL = pd.DataFrame(df.notnull().sum().to_frame('NOT_NULL'))\nNOT_NULL\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.415053Z","iopub.execute_input":"2021-06-02T20:34:30.415331Z","iopub.status.idle":"2021-06-02T20:34:30.52792Z","shell.execute_reply.started":"2021-06-02T20:34:30.415305Z","shell.execute_reply":"2021-06-02T20:34:30.526887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6.Find out the null counts of the columns and save the result as a dataframe.\nISNULL = pd.DataFrame(df.isnull().sum(), columns=['ISNULL'])\nISNULL","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.530589Z","iopub.execute_input":"2021-06-02T20:34:30.530905Z","iopub.status.idle":"2021-06-02T20:34:30.634866Z","shell.execute_reply.started":"2021-06-02T20:34:30.530876Z","shell.execute_reply":"2021-06-02T20:34:30.633858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7.Find out the unique counts of the columns and save the result as a dataframe.\nUNIQUE = pd.DataFrame(df.nunique(), columns=['UNIQUE'])\nUNIQUE","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.636455Z","iopub.execute_input":"2021-06-02T20:34:30.63676Z","iopub.status.idle":"2021-06-02T20:34:30.853106Z","shell.execute_reply.started":"2021-06-02T20:34:30.636719Z","shell.execute_reply":"2021-06-02T20:34:30.852023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. Merge the dataframes you created in questions 4-5-6-7.\nmerged = pd.concat([DATA_TYPES, NOT_NULL, ISNULL, UNIQUE], axis=1).reset_index()\nmerged","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.854334Z","iopub.execute_input":"2021-06-02T20:34:30.854622Z","iopub.status.idle":"2021-06-02T20:34:30.872878Z","shell.execute_reply.started":"2021-06-02T20:34:30.854593Z","shell.execute_reply":"2021-06-02T20:34:30.871865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 9.Lowercase all column names.\n\ndf_weather.columns = df_weather.columns.str.lower()\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.874206Z","iopub.execute_input":"2021-06-02T20:34:30.874483Z","iopub.status.idle":"2021-06-02T20:34:30.975407Z","shell.execute_reply.started":"2021-06-02T20:34:30.874455Z","shell.execute_reply":"2021-06-02T20:34:30.974386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10.Change all the No values to NoRain and all the Yes values to Rain in raintoday and \n# raintomorrow columns.\n\ndf_weather.raintoday.replace('No', 'noRain', inplace=True)\ndf_weather.raintomorrow.replace('No', 'noRain', inplace=True)\ndf_weather.raintoday.replace('Yes', 'Rain', inplace=True)\ndf_weather.raintomorrow.replace('Yes', 'Rain', inplace=True)\n\ndf_weather['raintoday'].sample(20)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:30.976635Z","iopub.execute_input":"2021-06-02T20:34:30.976931Z","iopub.status.idle":"2021-06-02T20:34:31.027835Z","shell.execute_reply.started":"2021-06-02T20:34:30.976904Z","shell.execute_reply":"2021-06-02T20:34:31.026767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# 11. Change the data type of \"date\" (object) column to datetime64 and reformat the date as DD/MM/YYYY\ndf_weather.date=pd.to_datetime(df_weather.date,format='%Y/%m/%d')\ndf_weather['date']","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.029084Z","iopub.execute_input":"2021-06-02T20:34:31.029368Z","iopub.status.idle":"2021-06-02T20:34:31.089117Z","shell.execute_reply.started":"2021-06-02T20:34:31.02934Z","shell.execute_reply":"2021-06-02T20:34:31.088162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 12. Remove Create a new column called \"difference\", calculate the difference \n# between maxtemp and mintemp columns for each row, and store the value in this new column.\n\ndf_weather['difference'] = df_weather['maxtemp'] - df_weather['mintemp'] \ndf_weather['difference']\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.090436Z","iopub.execute_input":"2021-06-02T20:34:31.09077Z","iopub.status.idle":"2021-06-02T20:34:31.103106Z","shell.execute_reply.started":"2021-06-02T20:34:31.090725Z","shell.execute_reply":"2021-06-02T20:34:31.101997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 13. Remove the evaporation and sunshine columns from the dataset permanently.\ndf_weather#.#drop#(['evaporation', 'sunshine'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.104483Z","iopub.execute_input":"2021-06-02T20:34:31.104858Z","iopub.status.idle":"2021-06-02T20:34:31.219441Z","shell.execute_reply.started":"2021-06-02T20:34:31.104825Z","shell.execute_reply":"2021-06-02T20:34:31.218536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 14. Find out the most rainy day for each city.\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.22296Z","iopub.execute_input":"2021-06-02T20:34:31.223284Z","iopub.status.idle":"2021-06-02T20:34:31.226992Z","shell.execute_reply.started":"2021-06-02T20:34:31.223255Z","shell.execute_reply":"2021-06-02T20:34:31.225718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 15. Filter out all the data for the city 'Albury' and then sort according to maxtemp column.\ndf2 =df_weather[df_weather.location == 'Albury']  \ndf2.sort_values(by=['maxtemp'])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.228125Z","iopub.execute_input":"2021-06-02T20:34:31.228407Z","iopub.status.idle":"2021-06-02T20:34:31.322828Z","shell.execute_reply.started":"2021-06-02T20:34:31.228379Z","shell.execute_reply":"2021-06-02T20:34:31.321728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 16. Find out the NaN counts for each column.\n\ndf_weather.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.324116Z","iopub.execute_input":"2021-06-02T20:34:31.324407Z","iopub.status.idle":"2021-06-02T20:34:31.413622Z","shell.execute_reply.started":"2021-06-02T20:34:31.324378Z","shell.execute_reply":"2021-06-02T20:34:31.412591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 19. Find out the hottest day of \"Perth\". Example output: Timestamp('2015-01-05 00:00:00')\ndf_weather.groupby('location')['maxtemp'].max()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.415036Z","iopub.execute_input":"2021-06-02T20:34:31.415363Z","iopub.status.idle":"2021-06-02T20:34:31.437447Z","shell.execute_reply.started":"2021-06-02T20:34:31.415333Z","shell.execute_reply":"2021-06-02T20:34:31.436396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 17. Remove the rows with NaN values in \"windgustdir\" column from the dataframe permanently.\n\ndf_weather.dropna(subset=['windgustdir'], axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.438902Z","iopub.execute_input":"2021-06-02T20:34:31.439197Z","iopub.status.idle":"2021-06-02T20:34:31.474723Z","shell.execute_reply.started":"2021-06-02T20:34:31.439168Z","shell.execute_reply":"2021-06-02T20:34:31.473872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 18. Create a new dataframe, use \"Location\" column as the index of the dataframe, display \n# the min, max, and median values of \"evaporation\" and \"sunshine\" columns in this dataframe.\nmin = df_weather.groupby('location')[['evaporation', 'sunshine']].min()\nmax = df_weather.groupby('location')[['evaporation', 'sunshine']].max()\nmedian = df_weather.groupby('location')[['evaporation', 'sunshine']].median()\n\n\ndf_merged = pd.concat([min,min,median], axis = 1)\ndf_merged","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:41:28.189326Z","iopub.execute_input":"2021-06-02T20:41:28.189733Z","iopub.status.idle":"2021-06-02T20:41:28.277606Z","shell.execute_reply.started":"2021-06-02T20:41:28.189695Z","shell.execute_reply":"2021-06-02T20:41:28.276557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 19. Find out the hottest day of \"Perth\". Example output: Timestamp('2015-01-05 00:00:00')\n\ndf_weather[df_weather.location=='Perth'][['location','date','maxtemp']].sort_values(by=['maxtemp'], ascending=False).iloc[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:41:56.123245Z","iopub.execute_input":"2021-06-02T20:41:56.123589Z","iopub.status.idle":"2021-06-02T20:41:56.151616Z","shell.execute_reply.started":"2021-06-02T20:41:56.12356Z","shell.execute_reply":"2021-06-02T20:41:56.150554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 20.Group your dataframe by location and find out the averages of all numeric values.\ndf_weather.groupby('location').mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T20:34:31.523162Z","iopub.execute_input":"2021-06-02T20:34:31.523925Z","iopub.status.idle":"2021-06-02T20:34:31.607025Z","shell.execute_reply.started":"2021-06-02T20:34:31.52388Z","shell.execute_reply":"2021-06-02T20:34:31.606103Z"},"trusted":true},"execution_count":null,"outputs":[]}]}