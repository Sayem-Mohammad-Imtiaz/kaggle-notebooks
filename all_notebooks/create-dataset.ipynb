{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Creating sentence-author dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nfrom nltk import tokenize, download\nimport numpy as np\nimport random\nimport pandas as pd\n\nfrom typing import List","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"download('punkt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To improve the operation of the offer tokenizer, some character combinations are replaced"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_text(filepath: str, min_char: int = 5) -> List[str]:\n    \n    text = str()\n    with open(filepath, \"r\", encoding=\"utf8\") as file:\n        text = file.read().replace('\\n', '. ')\n        text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n        text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n        # ...\n    \n    sentences = tokenize.sent_tokenize(text)    \n    sentences = [sentence for sentence in sentences if len(sentence) >= min_char]\n\n    return list(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chekhov = []\nfor path in glob.glob('../input/russian-literature/prose/Chekhov/*.txt'):\n    chekhov += split_text(path)\n    \ndostoevsky = []\nfor path in glob.glob('../input/russian-literature/prose/Dostoevsky/*.txt'):\n    dostoevsky += split_text(path)\n\ntolstoy = []\nfor path in glob.glob('../input/russian-literature/prose/Tolstoy/*.txt'):\n    tolstoy += split_text(path)\n\ngogol = []\nfor path in glob.glob('../input/russian-literature/prose/Gogol/*.txt'):\n    gogol += split_text(path)\n    \ngorky = []\nfor path in glob.glob('../input/russian-literature/prose/Gorky/*.txt'):\n    gorky += split_text(path)\n    \nturgenev = []\nfor path in glob.glob('../input/russian-literature/prose/Gorky/*.txt'):\n    turgenev += split_text(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chekhov[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_dict = { 'Chekhov': chekhov, 'Dostoevsky': dostoevsky, 'Tolstoy': tolstoy, 'Gogol': gogol, \n             'Gorky': gorky, 'Turgenev': turgenev }\n\nfor key in text_dict.keys():\n    print(key, ':', len(text_dict[key]), ' sentences')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All sentences from 11516 to 77817. Let's choose about 10_000 sents for dataset."},{"metadata":{},"cell_type":"markdown","source":"## Combine mixed sentences"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\n\nmax_len = 10_000\n\nnames = [chekhov, dostoevsky, tolstoy, gogol, gorky, turgenev]\n\ncombined = []\nfor name in names:\n    name = np.random.choice(name, max_len, replace=False)\n    combined += list(name)\n\nprint('Length of combo and internally shuffled list:', len(combined))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a labeled list"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Chekhov'] * max_len + ['Dostoevsky'] * max_len + ['Tolstoy'] * max_len + ['Gogol'] * max_len\\\n            + ['Gorky'] * max_len + ['Turgenev'] * max_len\n\nprint('Length of the labeled list:', len(labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Control length of data and labels:"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(combined) == len(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Randomly shuffle the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(3)\n\nzipped = list(zip(combined, labels))\nrandom.shuffle(zipped)\ncombined, labels = zip(*zipped)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exporting the resulting dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"out_data = pd.DataFrame()\nout_data['text'] = combined\nout_data['author'] = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(out_data.head())\nprint(out_data.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_data.to_csv('author_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}