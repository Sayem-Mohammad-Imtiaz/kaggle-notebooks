{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Dense, LSTM, Conv1D, Embedding\nfrom wordcloud import WordCloud","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# test Import self-crawled tweets about the COVID-19 vaccine\nI managed to scrape about 80.000 unique tweets. The twitter API is quite limited when running a free dev account. It may not be the largest dataset. However i feel like the main objective of the project is to show what I have learned in TDDE16, and perhaps it's ok that my dataset is not the most robust. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\npath = '../input/tweets-about-covid19-vaccine'         # use your path\nall_files = glob.iglob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\ndf_from_each_file = (pd.read_csv(f) for f in all_files)\ndf = pd.concat(df_from_each_file, ignore_index=True)\n\n# As the data has no column titles, we will add our own\n#df.columns = [\"username\", \"acc_desc\", \"location\", \"following\", \"followers\", \"totaltweets\", \"usercreatedts\", \"tweetcreatedts\", \"retweetcount\", \"text\", \"hashtags\"]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nr of tweets\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the first 10 rows of the dataframe.\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing tweets\nFirst let's define the preprocessing func"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading contractions.csv and storing it as a dict.\ncontractions = pd.read_csv('../input/contractions/contractions.csv', index_col='Contraction')\ncontractions.index = contractions.index.str.lower()\ncontractions.Meaning = contractions.Meaning.str.lower()\ncontractions_dict = contractions.to_dict()['Meaning']\n\n# Defining regex patterns.\nurlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)\"\nuserPattern       = '@[^\\s]+'\nhashtagPattern    = '#[^\\s]+'\nalphaPattern      = \"[^a-z0-9<>]\"\nsequencePattern   = r\"(.)\\1\\1+\"\nseqReplacePattern = r\"\\1\\1\"\n\n# Defining regex for emojis\nsmileemoji        = r\"[8:=;]['`\\-]?[)d]+\"\nsademoji          = r\"[8:=;]['`\\-]?\\(+\"\nneutralemoji      = r\"[8:=;]['`\\-]?[\\/|l*]\"\nlolemoji          = r\"[8:=;]['`\\-]?p+\"\n\ndef preprocess_apply(tweet):\n\n    tweet = str(tweet).lower()\n\n    # Replace all URls with '<url>'\n    tweet = re.sub(urlPattern,'<url>',tweet)\n    # Replace @USERNAME to '<user>'.\n    tweet = re.sub(userPattern,'<user>', tweet)\n    \n    # Replace 3 or more consecutive letters by 2 letter.\n    tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n\n    # Replace all emojis.\n    tweet = re.sub(r'<3', '<heart>', tweet)\n    tweet = re.sub(smileemoji, '<smile>', tweet)\n    tweet = re.sub(sademoji, '<sadface>', tweet)\n    tweet = re.sub(neutralemoji, '<neutralface>', tweet)\n    tweet = re.sub(lolemoji, '<lolface>', tweet)\n\n    for contraction, replacement in contractions_dict.items():\n        tweet = tweet.replace(contraction, replacement)\n\n    # Remove non-alphanumeric and symbols\n    tweet = re.sub(alphaPattern, ' ', tweet)\n\n    # Adding space on either side of '/' to seperate words (After replacing URLS).\n    tweet = re.sub(r'/', ' / ', tweet)\n    return tweet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apply preprocessing\nA new column with processed text will be added to the df"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['processed_tweet'] = df.text.apply(preprocess_apply)\nX_list = np.array(df['processed_tweet'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inspect tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display most frequently used words"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,20))\nwc = WordCloud(max_words = 1000 , width = 1600 , height = 800,  background_color ='white', min_font_size = 25,\n               collocations=False).generate(\" \".join(list(df['processed_tweet'])))      \nplt.axis(\"off\") \n\nplt.imshow(wc , interpolation = 'bilinear')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenizing preprocessed tweets\nThe LSTM model cannot process text direcetly. Tweets must first be tokenized and then padded so that all input has equal length (set to 60 during training)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n# import trained tokenizer \nfilename = \"../input/bilstm-15-model-epochs-trained-on-sentiment140/Tokenizer.pickle\"\nwith open(filename, 'rb') as f:\n    tokenizer = pickle.load(f)\n\nvocab_length = len(tokenizer.word_index) + 1\ninput_length = 60\nprint(\"Tokenizer vocab length:\", vocab_length)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\nX_tokenized = pad_sequences(tokenizer.texts_to_sequences(X_list), maxlen=input_length)\n\nprint(\"X.shape:\", X_tokenized.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define the same Bi-LSTM model architecture as used during training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getModel():\n    embedding_layer = Embedding(input_dim = vocab_length,\n                                output_dim = 100, # Dimensoin chosen for the Word2Vec model used in the embedding layer \n                                input_length=60,# Max word length of tweets manually set when padding input \n                                trainable=False)\n\n    model = Sequential([\n        embedding_layer,\n        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n        Conv1D(100, 5, activation='relu'),\n        GlobalMaxPool1D(),\n        Dense(16, activation='relu'),\n        Dense(1, activation='sigmoid'),\n    ],\n    name=\"Sentiment_Model\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create model"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_model = getModel()\ntraining_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\ntraining_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load weights from previous training\nLoading weights from the model that was trained for 15 epochs achieveing about 85% accuracy on the sentiment140 dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_path = '../input/bilstm-15-model-epochs-trained-on-sentiment140/Twitter-Sentiment-LSTM/variables/variables'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n!ls {checkpoint_dir}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store weights before loading pre-trained weights\npreloaded_layers = training_model.layers.copy()\npreloaded_weights = []\nfor pre in preloaded_layers:\n    preloaded_weights.append(pre.get_weights())\n\n# load pre-trained weights\ntry: \n    training_model.load_weights(checkpoint_path)\n\n    print(\"Loading weights from prev training\\n\")\n\n    # compare previews weights vs loaded weights\n    for layer, pre in zip(training_model.layers, preloaded_weights):\n        weights = layer.get_weights()\n\n        if weights:\n            if np.array_equal(weights, pre):\n                print('not loaded', layer.name)\n            else:\n                print('loaded', layer.name)\n                found_prev_weights = True\n\nexcept:\n    found_prev_weights = False\n    print(\"Error: no weights found\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now let's predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" \nWill use the LSTM model to predict the sentiment of a tweet. \n\"\"\"\ndef predict(X):\n    pred = training_model.predict(X)\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = predict(X_tokenized)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate percentage of negative and positive predictions\nLater we will filter out predictions that the model is quite uncertain about. These are intepreted as neutral. But before filtering out any neutral predictions, let's check the distribution when we consider all values < 0.5 to be negative and => 0.5 to be positive."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_unfiltered = np.where(predictions>=0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr_pos = np.sum(predictions_unfiltered == 1)\nnr_neg = np.sum(predictions_unfiltered == 0)\nnr_tot = len(predictions_unfiltered)\n\npercentage_pos = nr_pos / nr_tot\npercentage_neg = nr_neg / nr_tot\n\nprint(\"nr_pos:\", nr_pos)\nprint(\"nr_neg:\", nr_neg)\nprint(\"nr_tot:\", nr_tot)\n\nprint(\"percentage_pos:\", percentage_pos)\nprint(\"percentage_neg:\", percentage_neg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now let's filter out neutral predictions\nTo support the robustness of the classifier, classifications that are not assigned\na minimum probability of 75% being in the positive or negative class are interpreted\nas neutral. Therefore a value below 0.25 is considered negative (0), above 0.75 positive (1)\nand values inbetween 0.25 - 0.75 as neutral (8). "},{"metadata":{},"cell_type":"markdown","source":"## Calculate percentage of negative and positive predictions again"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_filtered = np.where(predictions >=0.75, 1, \n         (np.where(predictions <= 0.25, 0, 8)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr_neutral = np.sum(predictions_filtered == 8)\nnr_tot_filtered = len(predictions_filtered) - nr_neutral\nnr_pos_filtered = np.sum(predictions_filtered == 1)\nnr_neg_filtered = np.sum(predictions_filtered == 0)\n\npercentage_pos_filtered = nr_pos_filtered / nr_tot_filtered\npercentage_neg_filtered = nr_neg_filtered / nr_tot_filtered\n\nprint(\"Removed {} predictions considered neutral\\n\".format(nr_neutral))\nprint(\"nr_pos:\", nr_pos_filtered)\nprint(\"nr_neg:\", nr_neg_filtered)\nprint(\"nr_tot:\", nr_tot_filtered)\nprint(\"\\npercentage_pos_without_neutral:\", percentage_pos_filtered)\nprint(\"percentage_neg_without_neutral:\", percentage_neg_filtered)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"We got a majority of positive tweets about the vaccine. The results are 55% positive and 45% negative before filtering neutral predictions. After filtration the amount of positive predictions increased with 59% positive and 41% negative. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}