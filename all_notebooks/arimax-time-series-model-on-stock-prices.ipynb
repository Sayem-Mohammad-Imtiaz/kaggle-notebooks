{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 0.Setup the environment"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Read the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/av-hackathon-4/Train_awoL0xl.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print sample few rows\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We have the stock number and date, we have the open, high, low and close price for each date. An indicator to show if a particular day was holiday or not and an unpredictability score showing how volatile the stock is"},{"metadata":{},"cell_type":"markdown","source":"# 2. Install package pmdarima"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 6\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom pmdarima.arima import auto_arima\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Plot the closing price of Stock 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df[df.stock == 0]\nplt.figure(figsize=(10,6))\nplt.grid(True)\nplt.xlabel('Dates')\nplt.ylabel('Close Prices')\nplt.plot(df2['Close'])\nplt.title('Stock #1 closing price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Test for stationarity"},{"metadata":{},"cell_type":"markdown","source":"### Stationarity check is important in time series as we need to check what mathematical operations on the series make it predictable for future. For stationary time series the mean and variance is constant, so it is more predictable compared to non stationary time series. One of the test for stationarity is Augmented Dickey Fuller Test (ADF for short)\n\n### Wiki link: https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test\n\nCritical values for Dickey–Fuller t-distribution.\nWithout trend\tWith trend\nSample size\t1%\t5%\t1%\t5%\nT = 25\t−3.75\t−3.00\t−4.38\t−3.60\nT = 50\t−3.58\t−2.93\t−4.15\t−3.50\nT = 100\t−3.51\t−2.89\t−4.04\t−3.45\nT = 250\t−3.46\t−2.88\t−3.99\t−3.43\nT = 500\t−3.44\t−2.87\t−3.98\t−3.42\nT = ∞\t−3.43\t−2.86\t−3.96\t−3.41\nSource[2]:373"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test for stationarity\ndef test_stationarity(timeseries):\n    #Determing rolling statistics\n    rolmean = timeseries.rolling(12).mean()\n    rolstd = timeseries.rolling(12).std()\n    #Plot rolling statistics:\n    plt.plot(timeseries, color='blue',label='Original')\n    plt.plot(rolmean, color='red', label='Rolling Mean')\n    plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean and Standard Deviation')\n    plt.show(block=False)\n    \n    print(\"Results of Dickey Fuller test\")\n    adft = adfuller(timeseries,autolag='AIC')\n    # output for dft will give us without defining what the values are.\n    #hence we manually write what values does it explains using a for loop\n    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])\n    for key,values in adft[4].items():\n        output['critical value (%s)'%key] =  values\n    print(output)\n    \ntest_stationarity(df2.Close)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Based on the high p-value = 0.90 we observe that the time series is non stationary"},{"metadata":{},"cell_type":"markdown","source":"# 6. Check for seasonal decomposition"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = seasonal_decompose(df2.Close, model='multiplicative', freq = 30)\nfig = plt.figure()  \nfig = result.plot()  \nfig.set_size_inches(16, 9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Based on multiplicative model we see that the time series has a strong trend and seasonal component. Residual is mostly flat so most of the variance is explained by trend and seasonality"},{"metadata":{},"cell_type":"markdown","source":"# 7. Check 12 month moving average"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 10, 6\ndf_log = np.log(df2.Close)\nmoving_avg = df_log.rolling(12).mean()\nstd_dev = df_log.rolling(12).std()\nplt.legend(loc='best')\nplt.title('Moving Average')\nplt.plot(std_dev, color =\"black\", label = \"Standard Deviation\")\nplt.plot(moving_avg, color=\"red\", label = \"Mean\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Split the data in 90% test and 10% training"},{"metadata":{"trusted":true},"cell_type":"code","source":"#split data into train and training set\ntrain_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):]\nplt.figure(figsize=(10,6))\nplt.grid(True)\nplt.xlabel('Dates')\nplt.ylabel('Closing Prices')\nplt.plot(df_log, 'green', label='Train data')\nplt.plot(test_data, 'blue', label='Test data')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Run Autoarima with exogenous variables"},{"metadata":{},"cell_type":"markdown","source":"### Autoarima is useful as it selects the best values of p,d,q for time series stationarity through an iterative process. Below is brief explaination of p,d,q values\n\n### 1. p -> is the number of autoregressive terms\n### 2. d -> is the number of nonseasonal differences \n### 3. q -> is the number of lagged forecast errors"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df2[[\"holiday\",\"unpredictability_score\"]]\nmodel_autoARIMA = auto_arima(df2.Close, start_p=0, start_q=0,\n                      test='adf',       # use adftest to find             optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True,\n                      exogenous= df3)\nprint(model_autoARIMA.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The best model is ARIMA(1,0,3) which means we are describing stock closing price response variable (Y) by combining a 1st order Auto-Regressive model and a 3rd order Moving Average model."},{"metadata":{},"cell_type":"markdown","source":"# 10. Plot the diagnostic metrics for autoarima"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_autoARIMA.plot_diagnostics(figsize=(15,8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Based on the above diagnostic metrics we see the model is accurate\n\n### * Residual does not have specific trend\n### * Histogram is near normal"},{"metadata":{},"cell_type":"markdown","source":"# 11. Pick the best model for ARIMAX"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nmodel= SARIMAX(df2.Close, \n exog=df3,\n order=(1,0,3),\n enforce_invertibility=False, enforce_stationarity=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 12. Read in the test file"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/av-hackathon-4/Test_QQKW4dv.csv\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test2 = df_test[df_test.stock == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test3 = df_test2[[\"holiday\",\"unpredictability_score\"]]\nresults= model.fit()\nforecast_1= results.forecast(steps=len(df_test2.stock), exog=df_test3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(forecast_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 13. Append the forecast with the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = df2.Close\ntest_data = forecast_1\nplt.figure(figsize=(10,6))\nplt.grid(True)\nplt.xlabel('Dates')\nplt.ylabel('Closing Prices')\nplt.plot(train_data, 'green', label='Train data')\nplt.plot(test_data, 'blue', label='Test data')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The forecast is linear line and not as good as expected,more work is required to get better forecast, will explore more in next version, stay tuned."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}