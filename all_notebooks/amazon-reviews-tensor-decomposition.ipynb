{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorly\n","metadata":{"papermill":{"duration":7.63785,"end_time":"2021-05-20T16:41:53.320099","exception":false,"start_time":"2021-05-20T16:41:45.682249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:16.306782Z","iopub.execute_input":"2021-05-26T12:24:16.307475Z","iopub.status.idle":"2021-05-26T12:24:24.973265Z","shell.execute_reply.started":"2021-05-26T12:24:16.307372Z","shell.execute_reply":"2021-05-26T12:24:24.972067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom queue import PriorityQueue\nimport tensorly\nfrom tensorly.decomposition import parafac\nimport math\nfrom tensorly.metrics import regression\n\nimport random\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":6.751139,"end_time":"2021-05-20T16:42:00.089551","exception":false,"start_time":"2021-05-20T16:41:53.338412","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:24.974995Z","iopub.execute_input":"2021-05-26T12:24:24.975287Z","iopub.status.idle":"2021-05-26T12:24:31.201916Z","shell.execute_reply.started":"2021-05-26T12:24:24.975252Z","shell.execute_reply":"2021-05-26T12:24:31.201127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function that selecteds random samples from all three modes and returns them with their corresponding indices\ndef selectRandomSamples(A1slice,A2slice,A3slice,s1,s2,s3):\n\n    #moi along I:\n    pqI = PriorityQueue()\n    sum_weight = 0\n    for i in range(0,A1slice.shape[0]):\n        sum_weight = 0\n        for j in range(0,A1slice.shape[1]):\n            for k in range(0,A1slice.shape[2]):\n                #print(\"c:\",A1slice[i][j][k])\n                sum_weight += A1slice[i][j][k]\n        pqI.put((-sum_weight,i))\n\n\n\n    selectedI = np.zeros([s1,A1slice.shape[1],A1slice.shape[2]])\n    selectedindxI = np.zeros(s1)\n    i = 0\n    while not pqI.empty():\n        next_item = pqI.get()\n        if i < s1:\n            selectedI[i] = A1slice[next_item[1]]\n            selectedindxI[i] = next_item[1]\n        i += 1\n\n\n\n\n\n\n    #moi along J:\n    pqJ = PriorityQueue()\n    sum_weight = 0\n\n    for i in range(0,A2slice.shape[0]):\n        sum_weight = 0\n        for j in range(0,A2slice.shape[1]):\n            for k in range(0,A2slice.shape[2]):\n                #print(\"c:\",A1slice[i][j][k])\n                sum_weight += A2slice[i][j][k]\n        pqJ.put((-sum_weight,i))\n\n    selectedJ = np.zeros([s2,A2slice.shape[1],A2slice.shape[2]])\n    selectedindxJ = np.zeros(s2)\n    i = 0\n\n    while not pqJ.empty():\n        next_item = pqJ.get()\n        if i < s2:\n            selectedJ[i] = A2slice[next_item[1]]\n            selectedindxJ[i] = next_item[1]\n        i += 1\n\n\n\n    #moi along K:\n    pqK = PriorityQueue()\n    sum_weight = 0\n    for i in range(0,A3slice.shape[0]):\n        sum_weight = 0\n        for j in range(0,A3slice.shape[1]):\n            for k in range(0,A3slice.shape[2]):\n                #print(\"c:\",A1slice[i][j][k])\n                sum_weight += A3slice[i][j][k]\n        pqK.put((-sum_weight,i))\n\n    selectedK = np.zeros([s3,A3slice.shape[1],A3slice.shape[2]])\n    selectedindxK = np.zeros(s3)\n\n    i = 0\n\n    while not pqK.empty():\n        next_item = pqK.get()\n        if i < s3:\n            selectedK[i] = A3slice[next_item[1]]\n            selectedindxK[i] = next_item[1]\n        i += 1\n\n\n    return selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK","metadata":{"papermill":{"duration":0.037612,"end_time":"2021-05-20T16:42:00.182249","exception":false,"start_time":"2021-05-20T16:42:00.144637","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:31.209015Z","iopub.execute_input":"2021-05-26T12:24:31.209297Z","iopub.status.idle":"2021-05-26T12:24:31.226198Z","shell.execute_reply.started":"2021-05-26T12:24:31.209269Z","shell.execute_reply":"2021-05-26T12:24:31.225398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function that builds the Xs tensor\n#Xs tensor is made by combining all selected samples(from selectRandomSamples function) from all three slices\n#The F parameter is a tensor with new incoming data\n#F is set to None in the first iteration i.e for the initial tensor(before any new data has arrived)\n#If new data are sent as parameter during function call, it adds the new data slices to Xs along with the older randomly selected samples\ndef buildXs(selectedI,selectedJ,selectedK,F):\n    if F == None:\n        Xs = np.zeros([(selectedI.shape[0]+selectedJ.shape[0]+selectedK.shape[0]),max(selectedI.shape[1],selectedJ.shape[1],selectedK.shape[1]),max(selectedI.shape[2],selectedJ.shape[2],selectedK.shape[2])])\n    else:\n        fixed1 = F[0]\n        fixed2 = F[1]\n        fixed3 = F[2]\n        Xs = np.zeros([(selectedI.shape[0]+selectedJ.shape[0]+selectedK.shape[0]+fixed1.shape[0]+fixed2.shape[0]+fixed3.shape[0]),max(selectedI.shape[1],selectedJ.shape[1],selectedK.shape[1],fixed1.shape[1],fixed2.shape[1],fixed3.shape[1]),max(selectedI.shape[2],selectedJ.shape[2],selectedK.shape[2],fixed1.shape[2],fixed2.shape[2],fixed3.shape[2])])\n\n    l=0\n    m=0\n    n=0\n\n    for i in range(0,selectedI.shape[0]):\n        for j in range(0,selectedI.shape[1]):\n            for k in range(0,selectedI.shape[2]):\n                Xs[i][j][k] = selectedI[i][j][k]\n                l=i\n                m=j\n                n=k\n                \n    # Add new incoming slices\n    if F != None:\n        for i in range(0,fixed1.shape[0]):\n            l+=1\n            for j in range(0,fixed1.shape[1]):\n                for k in range(0,fixed1.shape[2]):\n                    Xs[l][j][k] = fixed1[i][j][k]\n\n    for i in range(0,selectedJ.shape[0]):\n        l+=1\n        for j in range(0,selectedJ.shape[1]):\n            for k in range(0,selectedJ.shape[2]):\n                Xs[l][j][k] = selectedJ[i][j][k]\n    \n    if F != None:\n        for i in range(0,fixed2.shape[0]):\n            l+=1\n            for j in range(0,fixed2.shape[1]):\n                for k in range(0,fixed2.shape[2]):\n                    Xs[l][j][k] = fixed2[i][j][k]\n\n    for i in range(0,selectedK.shape[0]):\n        l+=1\n        for j in range(0,selectedK.shape[1]):\n            for k in range(0,selectedK.shape[2]):\n                Xs[l][j][k] = selectedK[i][j][k]\n    if F != None:\n        for i in range(0,fixed3.shape[0]):\n            l+=1\n            for j in range(0,fixed3.shape[1]):\n                for k in range(0,fixed3.shape[2]):\n                    Xs[l][j][k] = fixed3[i][j][k]\n\n\n\n    return Xs\n","metadata":{"papermill":{"duration":0.038909,"end_time":"2021-05-20T16:42:00.239158","exception":false,"start_time":"2021-05-20T16:42:00.200249","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:31.227358Z","iopub.execute_input":"2021-05-26T12:24:31.227822Z","iopub.status.idle":"2021-05-26T12:24:31.247418Z","shell.execute_reply.started":"2021-05-26T12:24:31.227777Z","shell.execute_reply":"2021-05-26T12:24:31.246487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This function returns a summary of the tensor A\n#Summary of a tensor is a tensor Xs which has all the randomly selected samples from all trhee modes\n#The summary may or may not include the new incoming data slices depending on whether it is the initial iteration or not\n\ndef summary(A,s,fixed = None):\n    #determine sample sizes\n    I = A.shape[0]\n    J = A.shape[1]\n    K = A.shape[2]\n    s1 = math.ceil(I/s[0])\n    s2 = math.ceil(J/s[1])\n    s3 = math.ceil(K/s[2])\n\n    \n    #Slice input matrix A along all dimensions\n    A1slice = np.array(tf.slice(A, [0, 0, 0], [tf.shape(A)[0],tf.shape(A)[1] , tf.shape(A)[2]]))\n    print(\"i mode slicing done\")\n    \n\n    A2slice = np.zeros([A.shape[1],A.shape[0],A.shape[2]])\n    for i in range(0,tf.shape(A)[1]):\n        col = tf.slice(A, [0, i, 0], [tf.shape(A)[0],1 , tf.shape(A)[2]])\n        A2slice[i] = col[:,0]\n    print(\"j mode slicing done\")\n    \n    A3slice = np.zeros([A.shape[2],A.shape[0],A.shape[1]])\n    for i in range(0,tf.shape(A)[2]):\n        col = tf.slice(A, [0, 0, i], [tf.shape(A)[0],tf.shape(A)[1] , 1])\n        A3slice[i] = col[:,:,0]\n    print(\"k mode slicing done\")\n    \n    \n    #Choose random samples along modes 1,2,3\n    selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK = selectRandomSamples(A1slice,A2slice,A3slice,s1,s2,s3)\n  \n    #Combine samples\n    if(fixed == None):\n        Xs = buildXs(selectedI,selectedJ,selectedK,F = None)\n    else:\n        Xs = buildXs(selectedI,selectedJ,selectedK,F = fixed)\n\n    \n    return Xs,selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK\n    ","metadata":{"papermill":{"duration":0.034536,"end_time":"2021-05-20T16:42:00.292674","exception":false,"start_time":"2021-05-20T16:42:00.258138","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:31.248912Z","iopub.execute_input":"2021-05-26T12:24:31.249605Z","iopub.status.idle":"2021-05-26T12:24:31.264876Z","shell.execute_reply.started":"2021-05-26T12:24:31.249555Z","shell.execute_reply":"2021-05-26T12:24:31.263858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Xnew is used in place of the original tensor when new incoming slices have come\n# When no incoming slices have come yet, and tensor A is at it's initial state, a set of randomly selected samples are selected and saved\n# When new incoming data has arrived, the prevous samples selected when input tensor was at it's initial state are passed as parameters to this function\n# Xnew is built by adding 2 things:\n#     1. Adding the previously selected samples one after another using buildXs to create tensor Xslices\n#     2. Adding the new incoming data slices.(Let use assume that the new data slices are only added along mode three for this code)\n# Xnew is then returned\ndef buildXnew(Xold,F,mode1,mode2,mode3):\n    #Xslices tensor shape:\n    m = mode1.shape[0] \n    n = mode2.shape[0] \n    p = mode3.shape[0]\n    \n    #Build Xslices tensor with mode1,2 and 3 selected slices from previoud tensor\n\n    \"\"\"for i in range(0,m):\n        for j in range(0,n):\n            for k in range(0,p):\n                Xslices[i][j][k] = Xold[int(mode1[i])][int(mode2[j])][int(mode3[k])]\"\"\"\n    \n    Xslices = buildXs(mode1,mode1,mode3,F = None)\n                \n    \n    \n    \n    \n    #Merge Xslices and new incoming slices\n    m = max(Xslices.shape[0],F.shape[0])\n    n = max(Xslices.shape[1],F.shape[1])\n    p = Xslices.shape[2] + F.shape[2]\n    # Here, only p is the added value of shape(2) of Xslices and F because the slices are added along the third dimension\n    new = 0\n    Xnew = np.zeros([m,n,p])\n\n    \n    for i in range(0,m):\n        for j in range(0,n):\n            for k in range(0,p):\n                if k < Xslices.shape[2] and i < Xslices.shape[0] and j < Xslices.shape[1]:\n                    Xnew[i][j][k] = Xslices[i][j][k]\n                elif k >= Xslices.shape[2] and new < F.shape[2] and i < F.shape[0] and j < F.shape[1]:\n                    Xnew[i][j][k] = F[i][j][new]\n                    new+=1\n            new = 0\n                \n        \n   \n    \n                \n                \n    return Xnew\n    \n                ","metadata":{"papermill":{"duration":0.031786,"end_time":"2021-05-20T16:42:00.342561","exception":false,"start_time":"2021-05-20T16:42:00.310775","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:31.26823Z","iopub.execute_input":"2021-05-26T12:24:31.268718Z","iopub.status.idle":"2021-05-26T12:24:31.280652Z","shell.execute_reply.started":"2021-05-26T12:24:31.268659Z","shell.execute_reply":"2021-05-26T12:24:31.279669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge(As,Bs,Cs,r, rank,selectedI,selectedJ, selectedK ,Aold=None,Bold=None,Cold=None):\n    usedA =[]\n    if r ==0:\n        A = As\n        B = Bs\n        C = Cs\n    else:\n        vA=np.zeros([Aold.shape[0],1])\n        vB=np.zeros([Bold.shape[0],1])\n        vC=np.zeros([Cold.shape[0],1])\n        \n        for i in range(0,rank):\n            for j in range(0,rank):\n                vA[j] = np.dot(Aold[:,i] , As[:,j])\n                vB[j] = np.dot(Bold[:,i] , Bs[:,j])\n                vC[j] = np.dot(Cold[:,i] , Cs[:,j])\n                \n            idx = np.argsort(vA)\n            idx = idx[::-1]\n            \n            ii=0\n            while(idx[ii] in usedA):\n                ii= ii+1\n            \n            Id = idx[ii]\n            usedA.append(Id)\n            \n            for k in range(0,As.shape[0]):\n                if As[k][Id] == 0:\n                    As[k][Id] = As[k][Id] + Aold[k][i]\n                    \n            for k in range(0,Bs.shape[0]):\n                if Bs[k][Id] == 0:\n                    Bs[k][Id] = Bs[k][Id] + Bold[k][i]\n                    \n            for k in range(0,Cs.shape[0]):\n                if Cs[k][Id] == 0:\n                    Cs[k][Id] = Cs[k][Id] + Cold[k][i]\n        \n        A = As\n        B = Bs\n        C = Cs\n    \n    return A, B, C\n        \n    \n        \n    ","metadata":{"papermill":{"duration":0.034066,"end_time":"2021-05-20T16:42:00.395751","exception":false,"start_time":"2021-05-20T16:42:00.361685","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:31.282568Z","iopub.execute_input":"2021-05-26T12:24:31.282861Z","iopub.status.idle":"2021-05-26T12:24:31.298365Z","shell.execute_reply.started":"2021-05-26T12:24:31.282833Z","shell.execute_reply":"2021-05-26T12:24:31.297677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The data is loaded and processed in this cell by removing the null values\n# For attributes which have string values, each string value is assigned an integer\n# The previous step has to be done to build the tensor later in the code\ndf = pd.read_csv('../input/amazon-product-reviews/ratings_Electronics (1).csv', header = None, names = ['Cust_Id', 'Product_Id', 'Rating'], usecols = [0,1,2])\n#df=df.iloc[:5000, :]\n#df['Rating'] = df['Rating'].astype(float)\n\nprint('Dataset 1 shape: {}'.format(df.shape))\nprint('-Dataset examples-')\nprint(df.iloc[:5000, :])\n\n\n    \n    ","metadata":{"papermill":{"duration":299.231972,"end_time":"2021-05-20T16:46:59.645494","exception":false,"start_time":"2021-05-20T16:42:00.413522","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:31.299635Z","iopub.execute_input":"2021-05-26T12:24:31.300156Z","iopub.status.idle":"2021-05-26T12:24:42.200356Z","shell.execute_reply.started":"2021-05-26T12:24:31.300124Z","shell.execute_reply":"2021-05-26T12:24:42.198981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our dataframe has two dimensions\n# So another third dimnension is added since we are doing three dimensional tensor decomposition in this program \nsamples = 100\n\ncountry=[\"Australia\",\"USA\",\"Canada\",\"Bangladesh\",\"Mexico\",\"Russia\",\"China\",\"Japan\",\"Somalia\",\"Thailand\",\"South Korea\",\"Brazil\",\"England\"]\ncountry_list  = [\"\" for x in range(samples)]\n\ndf1=df.sample(n = samples)\nprint(df1.shape)\nfor i in range(0,samples):\n    r = random.randrange(0,len(country))\n    country_list[i] = country[r]\n\ndf1['country'] = country_list\n\n\ndf1.head()\n\n    ","metadata":{"papermill":{"duration":1.254598,"end_time":"2021-05-20T16:47:00.921075","exception":false,"start_time":"2021-05-20T16:46:59.666477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:42.201839Z","iopub.execute_input":"2021-05-26T12:24:42.202168Z","iopub.status.idle":"2021-05-26T12:24:42.866934Z","shell.execute_reply.started":"2021-05-26T12:24:42.202135Z","shell.execute_reply":"2021-05-26T12:24:42.865952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build The Tensor\ndf1['country']=df1['country'].astype('category').cat.codes\ndf1['Product_Id']=df1['Product_Id'].astype('category').cat.codes\ndf1['Cust_Id']=df1['Cust_Id'].astype('category').cat.codes\n\nl = list(df1['Product_Id'])\nm = list(df1['Cust_Id'])\nn = list(df1['country'])\n#print(n)\n\nproduct = dict([(y,x) for x,y in enumerate(set(l))])\nID = dict([(y,x) for x,y in enumerate(set(m))])\ncountry = dict([(y,x) for x,y in enumerate(set(n))])\n\nall_values = product.values()\nproductNo = max(all_values)\n\nall_values = ID.values()\nIDNo = max(all_values)\n\nall_values = country.values()\n#print(all_values)\ncountryNo = max(all_values)\n#print(countryNo)\n\n\nindexlist = []\nvaluelist = []\n  \n\nex = np.zeros([productNo+1,IDNo+1,countryNo+1])\n\n\nfor i,j in df1.iterrows():\n    #print(j.Movie_Id)\n    x = product[df1['Product_Id'][i]]\n    y = ID[df1['Cust_Id'][i]]\n    z = country[int(df1['country'][i])]\n\n    #print(str(x)+\" \"+str(y)+\" \"+str(z))\n    info = df1['Rating'][i]\n    \n    #print(info)\n    #print(x,y,z)\n    ex[x][y][z] = info\nm = min(product.values())  \n","metadata":{"papermill":{"duration":0.059632,"end_time":"2021-05-20T16:47:01.003969","exception":false,"start_time":"2021-05-20T16:47:00.944337","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:42.868299Z","iopub.execute_input":"2021-05-26T12:24:42.868569Z","iopub.status.idle":"2021-05-26T12:24:42.913675Z","shell.execute_reply.started":"2021-05-26T12:24:42.868543Z","shell.execute_reply":"2021-05-26T12:24:42.912776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#initial inputs\n\n# s specifies the number of samples to be selected in the tensor summary\n# Higher the value of s, higher the accuracy\n# But if s is too high, it may result in overfitting\ns = [10,10,10]\nrank = 3\n\n# Parafac is applied on the initial tensor. This is the only time parafac is applied on the entire tensor\nA = tensorly.tensor(ex)\nfactors = parafac(A,rank = rank, verbose = 0,normalize_factors=False)\n\n\n\n\n# Selected random indices from mode 1,2 and 3 of initial tensor as the FIXED INDICES\n# These samples will be used to estimate the factors later on when new slices are added instead of the full tensor\nXs,selectedI,selectedJ,selectedK,selectedindxI,selectedindxJ,selectedindxK = summary(A,s)\n\nprint(\"mode i selected:\",selectedI.shape)\nprint(\"mode j selected:\",selectedJ.shape)\nprint(\"mode k selected:\",selectedK.shape)\n\n\n\n\n","metadata":{"papermill":{"duration":0.508174,"end_time":"2021-05-20T16:47:01.532335","exception":false,"start_time":"2021-05-20T16:47:01.024161","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:42.91524Z","iopub.execute_input":"2021-05-26T12:24:42.915621Z","iopub.status.idle":"2021-05-26T12:24:43.72467Z","shell.execute_reply.started":"2021-05-26T12:24:42.915582Z","shell.execute_reply":"2021-05-26T12:24:43.723644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The primary sambaten function\n# First, a summary of the tensor is obtained with the previously selected samples and the new incomning slices\n# Then this summary is factoriezed and the corresponding factors are used to estimate the original tensor\ndef SamBATen(X, rank, s, r):\n    for i in range(0,r):\n        if i==0:\n            Xs,selectedI,selectedJ, selectedK, indI,indJ,indK =summary(X,s)\n            fixed = []\n            fixed.append(selectedI) \n            fixed.append(selectedJ) \n            fixed.append(selectedK)\n            \n        else:\n            Xs,selectedI,selectedJ, selectedK, indI,indJ,indK =summary(X,s,fixed)\n            \n        factors = parafac(Xs,rank = rank, verbose = 0,normalize_factors=False)\n        \n        weights = factors[0]\n        '''\n        scaling_matrix = np.array(np.diag(weights**(1/3)))\n        As= np.matmul(np.array(factors[1][0]),scaling_matrix)\n        Bs= np.matmul(np.array(factors[1][1]),scaling_matrix)\n        Cs= np.matmul(np.array(factors[1][2]),scaling_matrix)'''\n        As= factors[1][0]\n        Bs= factors[1][1]\n        Cs= factors[1][2]\n        \n        \n        \n        if i ==0:\n            A, B, C = merge(As,Bs,Cs,i,rank,selectedI,selectedJ, selectedK)\n        else :\n            A, B, C = merge(As,Bs,Cs,i,rank,selectedI,selectedJ, selectedK,Aold,Bold,Cold)\n            \n        Aold = A\n        Bold = B\n        Cold = C\n    return A,B,C,weights\n            ","metadata":{"papermill":{"duration":0.033696,"end_time":"2021-05-20T16:47:01.588466","exception":false,"start_time":"2021-05-20T16:47:01.55477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:43.726191Z","iopub.execute_input":"2021-05-26T12:24:43.726507Z","iopub.status.idle":"2021-05-26T12:24:43.736594Z","shell.execute_reply.started":"2021-05-26T12:24:43.726475Z","shell.execute_reply":"2021-05-26T12:24:43.735674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function creates a new tensor by merging the new slices with the intial tensor\ndef merge_oldnew(A,F):\n    m = A.shape[0]\n    n = A.shape[1]\n    p = A.shape[2]\n    \n    xx = F.shape[2]\n    \n    new = np.zeros(([m,n,p+xx]))\n    \n    fin = 0\n    \n    for i in range(0,m):\n        for j in range(0,n):\n            for k in range(0,new.shape[2]):\n                if k < p:\n                    new[i][j][k] = A[i][j][k]\n                else:\n                    new[i][j][k] = F[i][j][fin]\n                    fin += 1\n            fin = 0\n            \n    return new\n    ","metadata":{"papermill":{"duration":0.035099,"end_time":"2021-05-20T16:47:01.644825","exception":false,"start_time":"2021-05-20T16:47:01.609726","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:24:43.737868Z","iopub.execute_input":"2021-05-26T12:24:43.73834Z","iopub.status.idle":"2021-05-26T12:24:43.753719Z","shell.execute_reply.started":"2021-05-26T12:24:43.738294Z","shell.execute_reply":"2021-05-26T12:24:43.752618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAMBATEN(original)\n# Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 20\nno_of_new_cols = 1\nsambaten_error = 0\nsambaten_fit = 0\n\n\n\nAtotal = A\n\nimport tensorflow\n\nr = 1\nfor i in range(0,additions_no):\n    #Generate a random data sample as new data along the 3rd dimension\n    F = 4*np.random.rand(Atotal.shape[0],Atotal.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    #print(X.shape)\n    # The latest incoming slice is added to the total tensor(Atotal contains old and all new data)\n    Atotal = merge_oldnew(Atotal,F)\n    # Anew contains the selected initial sample slices and the last 10 new incoming slices\n    Anew = buildXnew(Atotal,F,selectedI,selectedJ,selectedK)\n    # Anew is used to estimate the new tensor instead of the entire tensor\n    factor1,factor2,factor3,weights = SamBATen(Anew, rank, s, r)\n    #print(\"Components on iteration \",i+1,\":\")\n    #print(factor1,factor2,factor3)\n    factor_array = []\n    factor_array.append(factor1)\n    factor_array.append(factor2)\n    factor_array.append(factor3)\n    \n    #regenerated_tensor = regenerate(factors)\n    regenerated_tensor = tensorly.cp_to_tensor((weights,factor_array))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Atotal) - np.linalg.norm(regenerated_tensor)\n    fit = 1- ((residual) /np.linalg.norm(Atotal))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Atotal))\n    print(\"error\",error)\n    sambaten_error += error\n    sambaten_fit += fit\n    print(\"------------------------------------------------------------------\")\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T12:24:43.755149Z","iopub.execute_input":"2021-05-26T12:24:43.755456Z","iopub.status.idle":"2021-05-26T12:26:51.011619Z","shell.execute_reply.started":"2021-05-26T12:24:43.75543Z","shell.execute_reply":"2021-05-26T12:26:51.010423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the average error across all iterations\n\nprint(\"Original Sambaten error: \",(sambaten_error/additions_no)*100)\nprint(\"Original Sambaten fitness: \",(sambaten_fit/additions_no)*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T12:26:51.013624Z","iopub.execute_input":"2021-05-26T12:26:51.014438Z","iopub.status.idle":"2021-05-26T12:26:51.026659Z","shell.execute_reply.started":"2021-05-26T12:26:51.014381Z","shell.execute_reply":"2021-05-26T12:26:51.025142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SAMBATEN(modified)\n# Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 20\nno_of_new_cols = 1\nsambaten_error = 0\nsambaten_fit = 0\n\n\n\nAtotal = A\n\nimport tensorflow\n\nr = 1\nfor i in range(0,additions_no):\n    #Generate a random data sample as new data along the 3rd dimension\n    F = 4*np.random.rand(Atotal.shape[0],Atotal.shape[1],no_of_new_cols)\n    F = np.around(F, decimals=0)\n    #Depending on condition, we take the last 10 new incoming slices and merge them to our tensor summary\n    if(i == 0):\n        X = F\n    else:\n        X = merge_oldnew(X,F)\n    if i >= 10:\n        X = merge_oldnew(X,F)\n        X = X[:,:,X.shape[2]-10:X.shape[2]]\n        Atotal = Atotal[:,:,Atotal.shape[2]-10:Atotal.shape[2]]\n    #print(X.shape)\n    # The latest incoming slice is added to the total tensor(Atotal contains old and all new data)\n    Atotal = merge_oldnew(Atotal,F)\n    # Anew contains the selected initial sample slices and the last 10 new incoming slices\n    Anew = buildXnew(Atotal,X,selectedI,selectedJ,selectedK)\n    # Anew is used to estimate the new tensor instead of the entire tensor\n    factor1,factor2,factor3,weights = SamBATen(Anew, rank, s, r)\n    #print(\"Components on iteration \",i+1,\":\")\n    #print(factor1,factor2,factor3)\n    factor_array = []\n    factor_array.append(factor1)\n    factor_array.append(factor2)\n    factor_array.append(factor3)\n    \n    #regenerated_tensor = regenerate(factors)\n    regenerated_tensor = tensorly.cp_to_tensor((weights,factor_array))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Atotal) - np.linalg.norm(regenerated_tensor)\n    fit = 1- ((residual) /np.linalg.norm(Atotal))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Atotal))\n    print(\"error\",error)\n    sambaten_error += error\n    sambaten_fit += fit\n    print(\"------------------------------------------------------------------\")\n\n\n\n","metadata":{"papermill":{"duration":4.301801,"end_time":"2021-05-20T16:47:05.968671","exception":false,"start_time":"2021-05-20T16:47:01.66687","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-26T12:26:51.030309Z","iopub.execute_input":"2021-05-26T12:26:51.032252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the average error across all iterations\n\nprint(\"Modified Sambaten error: \",(sambaten_error/additions_no)*100)\nprint(\"Modified Sambaten fitness: \",(sambaten_fit/additions_no)*100)","metadata":{"papermill":{"duration":0.057573,"end_time":"2021-05-20T16:47:06.069922","exception":false,"start_time":"2021-05-20T16:47:06.012349","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Online CP, Tucker decomposition and Matrix Product State method are applied in the following cells to demonstrate how our method SAMBATEN performs compared to the existing tensor decomposition methods","metadata":{"papermill":{"duration":0.021221,"end_time":"2021-05-20T16:47:06.155871","exception":false,"start_time":"2021-05-20T16:47:06.13465","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Online CP**","metadata":{"papermill":{"duration":0.021104,"end_time":"2021-05-20T16:47:06.198436","exception":false,"start_time":"2021-05-20T16:47:06.177332","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Online CP\n\nA = tensorly.tensor(ex)\n\nrank = 3\n\n\n\n#Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 1\nno_of_new_cols = 1\n\ncp_error = 0\ncp_fit = 0\n\nm = A.shape[0]\nn = A.shape[1]\np = A.shape[2]\nAnew = A\n\nr = 1\nfor i in range(0,additions_no):\n    F = 4*np.random.rand(Anew.shape[0],Anew.shape[1],no_of_new_cols)\n    Anew = merge_oldnew(Anew,F)\n    cp_weight,cp_factors = parafac(Anew,rank = rank, verbose = 0,normalize_factors=False)\n    cp_regenerated = tensorly.cp_to_tensor((cp_weight,cp_factors))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Anew) - np.linalg.norm(cp_regenerated)\n    fit = 1- ((residual) /np.linalg.norm(Anew))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Anew))\n    print(\"error\",error)\n    cp_error += error\n    cp_fit += fit\n    print(\"------------------------------------------------------------------\")","metadata":{"papermill":{"duration":0.392227,"end_time":"2021-05-20T16:47:06.612196","exception":false,"start_time":"2021-05-20T16:47:06.219969","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Online cp error: \",(cp_error/additions_no)*100)\nprint(\"Online cp fitness: \",(cp_fit/additions_no)*100)","metadata":{"papermill":{"duration":0.057746,"end_time":"2021-05-20T16:47:06.711852","exception":false,"start_time":"2021-05-20T16:47:06.654106","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Matrix Product State Method**","metadata":{"papermill":{"duration":0.022372,"end_time":"2021-05-20T16:47:06.760926","exception":false,"start_time":"2021-05-20T16:47:06.738554","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Matrix Product State Method\nA3 = tensorly.tensor(ex)\n\nrank = 3\n\nfrom tensorly.decomposition import matrix_product_state\nfrom tensorly import tt_to_tensor\n\n\n\n#Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 1\nno_of_new_cols = 1\n\nmat_product_error = 0\nmat_product_fit = 0\n\nm = A3.shape[0]\nn = A3.shape[1]\np = A3.shape[2]\nAnew3 = A3\n\nr = 1\nfor i in range(0,additions_no):\n    F = 4*np.random.rand(Anew3.shape[0],Anew3.shape[1],no_of_new_cols)\n    Anew3 = merge_oldnew(Anew3,F)\n    factors = matrix_product_state(Anew3, rank=rank)\n    cp_regenerated3 = np.round(tt_to_tensor(factors))\n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Anew3) - np.linalg.norm(cp_regenerated3)\n    fit = 1- ((residual) /np.linalg.norm(Anew3))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Anew3))\n    print(\"error\",error)\n    mat_product_error += error\n    mat_product_fit += fit","metadata":{"papermill":{"duration":0.183055,"end_time":"2021-05-20T16:47:06.966535","exception":false,"start_time":"2021-05-20T16:47:06.78348","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Matrix Product State method error: \",(mat_product_error/additions_no)*100)\nprint(\"Matrix Product State method fitness: \",(mat_product_fit/additions_no)*100)","metadata":{"papermill":{"duration":0.059711,"end_time":"2021-05-20T16:47:07.070698","exception":false,"start_time":"2021-05-20T16:47:07.010987","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tucker Decomposition**","metadata":{"papermill":{"duration":0.022194,"end_time":"2021-05-20T16:47:07.115372","exception":false,"start_time":"2021-05-20T16:47:07.093178","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Tucker decomposition\n\nA5 = tensorly.tensor(ex)\n\nrank = 3\n\nfrom tensorly.decomposition import matrix_product_state\nfrom tensorly import tt_to_tensor\nfrom tensorly.decomposition import tucker\nfrom tensorly import tucker_to_tensor\n\n\n#Add new data repeatedly and apply incremental tensor decompostion for subsequent iterations\nadditions_no = 1\nno_of_new_cols = 1\n\ntucker_error = 0\ntucker_fit = 0\n\nm = A5.shape[0]\nn = A5.shape[1]\np = A5.shape[2]\nAnew5 = A5\n\nr = 1\nfor i in range(0,additions_no):\n    F = 4*np.random.rand(Anew5.shape[0],Anew5.shape[1],no_of_new_cols)\n    Anew5 = merge_oldnew(Anew5,F)\n    \n    factors = tucker(Anew5, rank=3)\n    regenerated5 = tucker_to_tensor(factors)    \n    print(\"-------------------------------------------------------------------\")\n    print(\"Iteration no: \",i+1)\n    residual=np.linalg.norm(Anew5) - np.linalg.norm(regenerated5)\n    fit = 1- ((residual) /np.linalg.norm(Anew5))\n    print(\"fit\",fit)\n    error= abs(residual) /abs(np.linalg.norm(Anew5))\n    print(\"error\",error)\n    tucker_error += error\n    tucker_fit += fit","metadata":{"papermill":{"duration":0.205972,"end_time":"2021-05-20T16:47:07.343917","exception":false,"start_time":"2021-05-20T16:47:07.137945","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Tucker method error: \",(tucker_error/additions_no)*100)\nprint(\"Tucker method fitness: \",(tucker_fit/additions_no)*100)","metadata":{"papermill":{"duration":0.058364,"end_time":"2021-05-20T16:47:07.447022","exception":false,"start_time":"2021-05-20T16:47:07.388658","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This we can see that all the other decomposition methods had much higher percentage of error and lower fitness percentage compared to SAMBATEN.","metadata":{"papermill":{"duration":0.022916,"end_time":"2021-05-20T16:47:07.49554","exception":false,"start_time":"2021-05-20T16:47:07.472624","status":"completed"},"tags":[]}}]}