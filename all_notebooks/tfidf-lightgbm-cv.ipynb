{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T14:57:14.126405Z","iopub.execute_input":"2021-07-10T14:57:14.126855Z","iopub.status.idle":"2021-07-10T14:57:14.165696Z","shell.execute_reply.started":"2021-07-10T14:57:14.126772Z","shell.execute_reply":"2021-07-10T14:57:14.164877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! git clone --recursive https://github.com/Microsoft/LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-07-10T14:57:14.167217Z","iopub.execute_input":"2021-07-10T14:57:14.167592Z","iopub.status.idle":"2021-07-10T14:57:40.056158Z","shell.execute_reply.started":"2021-07-10T14:57:14.167554Z","shell.execute_reply":"2021-07-10T14:57:40.055251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install opencl-headers -y\n!apt install -y ocl-icd-opencl-dev","metadata":{"execution":{"iopub.status.busy":"2021-07-10T14:57:40.058396Z","iopub.execute_input":"2021-07-10T14:57:40.058816Z","iopub.status.idle":"2021-07-10T14:57:51.602882Z","shell.execute_reply.started":"2021-07-10T14:57:40.058776Z","shell.execute_reply":"2021-07-10T14:57:51.601989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;","metadata":{"execution":{"iopub.status.busy":"2021-07-10T14:57:51.604655Z","iopub.execute_input":"2021-07-10T14:57:51.605004Z","iopub.status.idle":"2021-07-10T15:02:42.149816Z","shell.execute_reply.started":"2021-07-10T14:57:51.604962Z","shell.execute_reply":"2021-07-10T15:02:42.148871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_set = '/kaggle/input/nlp-news-text/train_set.csv'\ntest_set_a = '/kaggle/input/nlp-news-text/test_a.csv'\ntest_set_b = '/kaggle/input/nlp-news-text/test_b.csv'","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:02:42.15286Z","iopub.execute_input":"2021-07-10T15:02:42.153166Z","iopub.status.idle":"2021-07-10T15:02:42.156902Z","shell.execute_reply.started":"2021-07-10T15:02:42.153133Z","shell.execute_reply":"2021-07-10T15:02:42.156106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#%matplotlib inline\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_df = pd.read_csv(data_set,sep='\\t')\ntest_df = pd.read_csv(test_set_a,sep='\\t')\n\ntrain_df['text_split'] = train_df['text'].apply(lambda x: str(x.split()))\ntest_df['text_split'] = test_df['text'].apply(lambda x: str(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:02:42.158232Z","iopub.execute_input":"2021-07-10T15:02:42.158732Z","iopub.status.idle":"2021-07-10T15:03:28.078258Z","shell.execute_reply.started":"2021-07-10T15:02:42.158694Z","shell.execute_reply":"2021-07-10T15:03:28.077336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text_split->tfidf\nword_vec = TfidfVectorizer(analyzer='word',\n            ngram_range=(1,2),#(1,3)\n            min_df=3,  # 4  5\n            max_df=0.9, # 0.95 1.0 \n            use_idf=True,\n            max_features = 3000,\n            smooth_idf=True, \n            sublinear_tf=True)\ntrain_term_doc = word_vec.fit_transform(train_df['text_split'])\ntest_term_doc = word_vec.transform(test_df['text_split'])","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:03:28.079693Z","iopub.execute_input":"2021-07-10T15:03:28.080031Z","iopub.status.idle":"2021-07-10T15:11:33.494902Z","shell.execute_reply.started":"2021-07-10T15:03:28.079995Z","shell.execute_reply":"2021-07-10T15:11:33.494002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# F1 score-线下\nfrom sklearn.metrics import f1_score\n#[1,2,3,2,1,3]\n#[1,2,3,1,1,3]\ndef cal_macro_f1(y_true,y_pred):\n    score = f1_score(y_true,y_pred,average='macro')\n    return score\n\nX_train, X_eval, y_train, y_eval  = train_test_split(train_term_doc,train_df['label'],test_size=0.2,shuffle=True,random_state=2019) # split the training data","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:11:33.497254Z","iopub.execute_input":"2021-07-10T15:11:33.497658Z","iopub.status.idle":"2021-07-10T15:11:33.84377Z","shell.execute_reply.started":"2021-07-10T15:11:33.497617Z","shell.execute_reply":"2021-07-10T15:11:33.842771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CV\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5, shuffle=True, random_state=666)\ntrain_matrix = np.zeros((train_df.shape[0],14)) #记录验证集的概率\n##!!!!!\ntest_pre_matrix = np.zeros((10,test_df.shape[0],14)) #将5轮的测试概率分别保存起来\ncv_scores=[] #每一轮线下的验证成绩","metadata":{"execution":{"iopub.status.busy":"2021-07-10T16:04:40.889977Z","iopub.execute_input":"2021-07-10T16:04:40.8903Z","iopub.status.idle":"2021-07-10T16:04:40.912048Z","shell.execute_reply.started":"2021-07-10T16:04:40.89027Z","shell.execute_reply":"2021-07-10T16:04:40.9112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir model\nimport pickle\ndef dump_obj(data,name):\n    with open(\"model/\"+name,'wb') as f:\n        pickle.dump(data,f)\ndef load(name):\n    with open(\"model/\"+name,'rb') as f:\n        return pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:11:33.853068Z","iopub.execute_input":"2021-07-10T15:11:33.853665Z","iopub.status.idle":"2021-07-10T15:11:34.558034Z","shell.execute_reply.started":"2021-07-10T15:11:33.853627Z","shell.execute_reply":"2021-07-10T15:11:34.55697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.linear_model import LogisticRegression\nlast_score = 100\nfor i,(train_index,eval_index) in enumerate(kf.split(train_term_doc)):\n    print(\"第%d轮训练\"%i)\n    print(len(train_index),len(eval_index))\n    \n    print(\"加载训练集和验证集\")\n    #训练集\n    X_train = train_term_doc[train_index]\n    y_train = train_df['label'][train_index]\n    \n    #验证集\n    X_eval = train_term_doc[eval_index]\n    y_eval = train_df['label'][eval_index]\n    print(\"训练lgbm分类器\")\n    # model = LogisticRegression(C=4, dual=False) \n    # model.fit(X_train,y_train)\n    model =lgb.LGBMClassifier(device_type='gpu',\n                   boosting_type='gbdt', \n                   num_leaves=2**5,\n                   max_depth=6, \n                   learning_rate= 0.1,\n                   n_estimators=500, #迭代次数\n                   objective='multiclass',\n                   subsample=0.7,#\n                   colsample_bytree=0.5,#\n                   reg_lambda=10,#l2\n                   n_jobs=16, #\n                   num_class=19,#\n                   silent=True, \n                   random_state=2019,\n#                    class_weight=20,\n                   colsample_bylevel=0.5,\n                   min_child_weight=1.5,\n                   metric='multi_logloss',\n                   num_threads = 4\n                  )\n    model.fit(X_train,y_train,eval_set=(X_eval,y_eval), early_stopping_rounds=50)\n    dump_obj(model,'lgbm'+str(i))\n    #model.booster_.savemodel(\"lgbm_model%d.txt\"%i)\n    ####对于验证集进行预测\n    eval_prob = model.predict_proba(X_eval)\n    train_matrix[eval_index] = eval_prob.reshape((X_eval.shape[0], 14))#array\n    \n    eval_pred = np.argmax(eval_prob,axis=1)\n    score = cal_macro_f1(y_eval,eval_pred)\n    cv_scores.append(score)\n    print(\"validation score is\",score)\n    \n    ###对于测试集进行预测\n    test_prob = model.predict_proba(test_term_doc)\n    test_pre_matrix[i,:,:] = test_prob.reshape((test_term_doc.shape[0], 14))\n    if score-last_score>=0.0005:\n        break\n    last_score = min(last_score,score)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T16:04:43.37319Z","iopub.execute_input":"2021-07-10T16:04:43.373539Z","iopub.status.idle":"2021-07-10T17:41:21.073556Z","shell.execute_reply.started":"2021-07-10T16:04:43.373488Z","shell.execute_reply":"2021-07-10T17:41:21.07067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_pred = np.argmax(train_matrix,axis=1)\nscore = cal_macro_f1(train_df['label'],all_pred)\nprint(\"all validation score is\",score)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T16:03:19.942206Z","iopub.status.idle":"2021-07-10T16:03:19.942949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = test_pre_matrix.mean(axis=0)\ntest_pred = np.argmax(test_pred,axis=1)\ntest_df['label'] = test_pred\ntest_df['label'].to_csv(\"submission_tfidf_lightGBM_10fold.csv\",index=False,header=True,encoding='utf-8')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T16:03:19.944102Z","iopub.status.idle":"2021-07-10T16:03:19.944817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf LightGBM","metadata":{"execution":{"iopub.status.busy":"2021-07-10T16:03:19.945845Z","iopub.status.idle":"2021-07-10T16:03:19.946547Z"},"trusted":true},"execution_count":null,"outputs":[]}]}