{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#sklearn\nfrom sklearn.metrics import confusion_matrix\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"churn_df = pd.read_csv(\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\nchurn_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape=\",churn_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df.dtypes # We see TotalCharges is a string need to be converted into float","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_df[\"TotalCharges\"] = churn_df[\"TotalCharges\"].apply(lambda x: float(x.strip()) if len(x.strip()) != 0 else 0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nPlan of Action : We will not use exploratory analysis approach in this study\n\n1. First Split the data using StraifiedKFold into 5 splits, repetition allowed.\n2. Build Initial Machine Learning Framework ( also include Customer ID ): Algorithms used KNN, SVM, RandomForest, ExtraTreeForest, XGB ( the results are not good enough )\n2. Extract Feaures ( Not Models ) Transform the raw data using PCA, NCA, SelectKBest, LDA, SelectKModel\n3. Build the second Machine Learning Framework: Algorithms used KNN, SVM, RandomForest, ExtraTreeForest, XGB ( the results are not good enough )\n4. Stack Features again but using Count Encoder, Percentile Encoder, Likelihood Encoder ( given by ) Far0n/kaggletils\n5. Build the second Machine Learning Framework: Algorithms used KNN, SVM, RandomForest,, XGB). RandomForest is giving promising results\n6. Grid Search to find best parameters for  RandomForest ( by running on one 1 fold data )\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = churn_df.values[:, :-1] # CustomerID is included\ny = churn_df.values[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RepeatStratifiedKFold\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\nrksf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\ntraining_test_split = []\nfor train_index, test_index in rksf.split(X, y):\n  training_test_split.append((train_index, test_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(training_test_split[0][0]), len(training_test_split[0][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_map = { v:k for k, v in enumerate(churn_df.columns)} # Indexing the columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Numeric features - Standardized\n# Categorical features - One Hot Encoded\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\n# Since we are using np.array not df\nnumeric_features = [column_map[i] for i in ('tenure','MonthlyCharges', 'TotalCharges' )]\ncategorical_feature = [column_map[i] for i in ('gender', 'SeniorCitizen', 'Partner', 'Dependents', \n                       'PhoneService', 'MultipleLines','InternetService',\n                       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n                       'PaperlessBilling', 'PaymentMethod') \n                      ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess = ColumnTransformer(\n    transformers = [\n        ('num', StandardScaler(), numeric_features), # Normalize Numeric Variables\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_feature) # Make OneHot encoding for Categorical var\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_transform = preprocess.fit_transform(X)\nprint(\"X_transform Shape\", X_transform.shape)\nX_transform[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply knn algorithm to predict\n\nfrom sklearn.neighbors import KNeighborsClassifier\ndisplay = True\nacc_knn=[]\nn_neighbors = 3 # Hyper parameter\nknn = KNeighborsClassifier(n_neighbors=n_neighbors)\nfor train_indices, test_indices in training_test_split:\n  knn.fit(X_transform[train_indices, :], y[train_indices])\n  \n  # Compute the nearest neighbor accuracy on the embedded test set\n  acc_knn.append(knn.score(X_transform[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \") \n    print(confusion_matrix(knn.predict(X_transform[test_indices,:]), y[test_indices]))\n    display = False\n  \nacc_knn = np.array(acc_knn)\nprint(\" Knn with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets try increasing k to see any effect\ndisplay = True\nacc_knn = []\nn_neighbors = 10 # Hyper parameter\nknn = KNeighborsClassifier(n_neighbors=n_neighbors)\n\nfor train_indices, test_indices in training_test_split:\n  knn.fit(X_transform[train_indices, :], y[train_indices])\n  \n  # Compute the nearest neighbor accuracy on the embedded test set\n  acc_knn.append(knn.score(X_transform[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(knn.predict(X_transform[test_indices,:]), y[test_indices]))\n    display = False\n  \n\"\"\"\nNot much change \n\"\"\"\nacc_knn = np.array(acc_knn)\nprint(\" Knn with neighbors={0}, accuracy={1},{2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))\n\n# Doesnt look promising :(","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply SVM algo\nfrom sklearn import svm\nacc_svm = []\ndisplay = True\nclf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_transform[train_indices, :], y[train_indices])\n  \n  acc_svm.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n    display = False\n    \n    \nacc_svm = np.array(acc_svm)\nprint(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nacc_rf = []\ndisplay = True\nclf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_transform[train_indices, :], y[train_indices])\n  \n  acc_rf.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n    display = False\n    \n    \nacc_rf = np.array(acc_rf)\nprint(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nacc_et = []\ndisplay = True\nclf = ExtraTreesClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_transform[train_indices, :], y[train_indices])\n  \n  acc_et.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n    display = False\n  \nacc_et = np.array(acc_et)\nprint(\" ERF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_et.mean(), acc_et.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\ndisplay = True\nacc_xgb = []\n\nfor train_indices, test_indices in training_test_split:\n  clf = xgb.XGBClassifier().fit(X_transform[train_indices, :], y[train_indices])\n  \n  acc_xgb.append(clf.score(X_transform[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_transform[test_indices,:]), y[test_indices]))\n    display = False\n    \nacc_xgb = np.array(acc_xgb)\nprint(\" XGB with accuracy={0},{1}\".format(acc_xgb.mean(), acc_xgb.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**If I have to stop here and chose a model it is unclear which one I shd pick**\n\n**On second thought we will drop ExtraTreesClassifier for further analysis its results are similar to RF**\n\n**Now lets transform our raw data and later on we will exclude the customer_id field and try again**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.feature_selection import SelectFromModel\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LassoCV\n\npca = PCA(n_components=5)\nskb = SelectKBest(mutual_info_classif, k=2)\nnca = NeighborhoodComponentsAnalysis(n_components=3, random_state=42)\nlda = LinearDiscriminantAnalysis(n_components=3)\nclf = LassoCV(cv=4)\nsfm = SelectFromModel(clf, threshold=0.25)\n\nunion = FeatureUnion(\n    [\n        (\"pca\", pca),\n        (\"skb\", skb),\n        (\"nca\", nca),\n        (\"lda\", lda),\n        (\"sfm\", sfm)\n        \n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"union.fit(X_transform, LabelEncoder().fit_transform(y)) # We also come to know that Variables are collinear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_feature = union.transform(X_transform)\nprint(\"X_feature shape\", X_feature.shape)\nX_feature[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply knn algorithm to predict\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\ndisplay = True\nacc_knn=[]\nn_neighbors = 3 # Hyper parameter\nknn = KNeighborsClassifier(n_neighbors=n_neighbors)\nfor train_indices, test_indices in training_test_split:\n  knn.fit(X_feature[train_indices, :], y[train_indices])\n  \n  # Compute the nearest neighbor accuracy on the embedded test set\n  acc_knn.append(knn.score(X_feature[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \") \n    print(confusion_matrix(knn.predict(X_feature[test_indices,:]), y[test_indices]))\n    display = False\n  \nacc_knn = np.array(acc_knn)\nprint(\" Knn with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply SVM algo\nfrom sklearn import svm\nacc_svm = []\ndisplay = True\nclf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_feature[train_indices, :], y[train_indices])\n  \n  acc_svm.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n    display = False\n        \n    \nacc_svm = np.array(acc_svm)\nprint(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nacc_rf = []\ndisplay = True\nclf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_feature[train_indices, :], y[train_indices])\n  \n  acc_rf.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n    display = False\n    \n    \nacc_rf = np.array(acc_rf)\nprint(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\ndisplay = True\nacc_xgb = []\n\nfor train_indices, test_indices in training_test_split:\n  clf = xgb.XGBClassifier().fit(X_feature[train_indices, :], y[train_indices])\n  \n  acc_xgb.append(clf.score(X_feature[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_feature[test_indices,:]), y[test_indices]))\n    display = False\n    \nacc_xgb = np.array(acc_xgb)\nprint(\" XGB with accuracy={0},{1}\".format(acc_xgb.mean(), acc_xgb.std()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It seems SVM did something weird was able to predict one class quiet good**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nLets merged the raw and transformed data to see if we get any benefits\n\"\"\"\nX_merged = np.hstack((X_transform, X_feature))\nprint(\"X_merged shape\", X_merged.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nWe will only try 2 Estimators SVM and RF to see if there is any difference in merging datasets\n\"\"\"\nfrom sklearn import svm\nacc_svm = []\ndisplay = True\nclf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_merged[train_indices, :], y[train_indices])\n  \n  acc_svm.append(clf.score(X_merged[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_merged[test_indices,:]), y[test_indices]))\n    display = False\n        \n    \nacc_svm = np.array(acc_svm)\nprint(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nacc_rf = []\ndisplay = True\nclf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_merged[train_indices, :], y[train_indices])\n  \n  acc_rf.append(clf.score(X_merged[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_merged[test_indices,:]), y[test_indices]))\n    display = False\n     \n  \nacc_rf = np.array(acc_rf)\nprint(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nhmm doesnt look like it makes any difference :(\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Second Level of Transformation**\nThe reason being our features are **collinear**. The above feature transformation are not great\n\nHere we use CounterEncoder, PercentileEncoder, LikelihoodEstimator to tranform the data and then reapply the algos.\nThese transformation can be viewed in https://github.com/Far0n/kaggletils"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = churn_df.values[:, :-1] # Not considering customer_id\ny = churn_df.values[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\n\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import LabelEncoder\nimport scipy\n#from statsmodels.distributions import ECDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CounterEncoder(BaseEstimator, TransformerMixin):\n  def __init__(self, min_count=0, nan_value=-1, copy=True):\n    self.min_cnt = min_count\n    self.nans = nan_value\n    self.cp = copy\n    self.counts = {}\n    \n  def is_numpy(self, x):\n    return isinstance(x, np.ndarray)\n    \n  def fit(self, x):\n    self.counts = {}\n    if len(x.shape) == 1:\n      x = x.reshape(-1, 1)\n    ncols = x.shape[1]\n    is_np = self.is_numpy(x)\n    \n    for i in range(ncols):\n      if is_np:\n        cnt = dict(Counter(x[:, i]))\n      else:\n        cnt = x.iloc[:, i].value_counts().to_dict()\n        \n      if self.min_cnt > 0:\n        cnt = dict((k, self.nans if v < self.min else v ) for k, v in cnt.items())\n    \n      self.counts.update({i:cnt})\n    return self\n  \n  def fit_transform(self, x):\n    self.fit(x)\n    return self.transform(x)\n  \n  def transform(self, x):\n    if self.cp:\n      xm = x.copy()\n      \n    if len(xm.shape) == 1:\n      xm = xm.reshape(-1, 1)\n      \n    ncols = xm.shape[1]\n    is_np = self.is_numpy(xm)\n    \n    for i in range(ncols):\n      cnt = self.counts[i]\n      \n      if is_np:\n        k, v = np.array( list ( zip ( *sorted(cnt.items()))))\n        ix = np.digitize(xm[:, i], k, right=True)\n        xm[:, i] = v[ix]\n      else:\n        xm.iloc[:, i].replace(cnt, inplace=True)\n    return xm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = [column_map[i] for i in ('tenure','MonthlyCharges', 'TotalCharges' )]\ncategorical_feature = [column_map[i] for i in ('gender', 'SeniorCitizen', 'Partner', 'Dependents', \n                       'PhoneService', 'MultipleLines','InternetService',\n                       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n                       'PaperlessBilling', 'PaymentMethod') \n                      ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_counter = counter.fit_transform(X[:, categorical_feature_index])\nX_label = X.copy()\nfor i in categorical_feature:\n  X_label[:, i] = LabelEncoder().fit(X[:, i]).transform(X[:, i])\n\ncounter = CounterEncoder()\nX_label_count = counter.fit_transform(X_label[:, categorical_feature])\n\nX_label_count[:3, :]# It captures the occurence of each categorical variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import check_X_y, check_array\n\ndef is_numpy(x):\n    return isinstance(x, np.ndarray)\n  \nclass LikelihoodEstimator(BaseEstimator):\n    def __init__(self, seed=0, alpha=0, noise=0, leave_one_out=False):\n        self.alpha = alpha\n        self.noise = noise\n        self.seed = seed\n        self.leave_one_out = leave_one_out\n        self.nclass = None\n        self.classes = None\n        self.class_priors = None\n        self.likelihoods = None\n        self.x_likelihoods = None\n\n    def fit(self, x, y):\n        np.random.seed(self.seed)\n        if len(x.shape) == 1:\n            x = x.reshape(-1, 1)\n\n        x, y = check_X_y(x, y)\n\n        self.classes = np.unique(y)\n        self.nclass = self.classes.shape[0]\n\n        ctab = pd.crosstab(y, list(x.T)).T.reset_index()\n\n        xdim = x.shape[1]\n        xcols = list(ctab.columns[:xdim])\n        ycols = list(ctab.columns[xdim:])\n\n        xtab = pd.DataFrame(x, columns=xcols)\n        xtab = xtab.merge(ctab, how='left', on=xcols)\n\n        self.class_priors = xtab[ycols].div(xtab[ycols].sum(axis=1), axis=0).mean().values\n\n        if self.leave_one_out:\n            xtab[ycols] -= pd.get_dummies(y)\n\n        xtab[ycols] = xtab[ycols].add(self.class_priors * self.alpha). \\\n            div(xtab[ycols].sum(axis=1) + self.alpha + 1E-15, axis=0)\n        if self.noise > 0:\n            xtab[ycols] = np.abs(xtab[ycols] + normal(0, scale=self.noise, size=xtab[ycols].shape))\n            xtab[ycols] = xtab[ycols].div(xtab[ycols].sum(axis=1), axis=0)\n        self.x_likelihoods = xtab[ycols].values\n\n        xtab_agg = xtab.groupby(xcols, as_index=False)[ycols].agg(['mean']).fillna(0)\n        xtab_agg.columns = xtab_agg.columns.get_level_values(1)\n\n        self.likelihoods = xtab_agg.T.ix['mean'].reset_index(drop=True).T.reset_index()\n        # self.likelihoods = xtab_agg.T.ix['mean'].reset_index(drop=True).to_dict('list')\n        # self.likelihoods_cov = xtab_agg.T.ix['std'].reset_index(drop=True).to_dict('list')\n        # self.likelihoods_cov = dict((k, np.diag(v)) for k, v in self.likelihoods_cov.items())\n\n        return self\n\n    def _calc_likelihood(self, x):\n        return (x + self.class_priors * self.alpha) / (x.sum() + self.alpha)\n\n    def _get_likelihood(self, x, noise):\n        mean = self.likelihoods.get(x[0], self.class_priors)\n        cov = self.likelihoods_cov.get(x[0], np.diag(np.zeros((self.nclass,))))\n        if noise:\n            if isinstance(noise, float):\n                cov = np.diag(np.ones((self.nclass,)) * noise)\n            lh = np.abs(multivariate_normal(mean, cov))\n            return lh / lh.sum()\n        else:\n            return mean\n\n    def predict(self, x, noise=False, normalize=False):\n        if normalize:\n            return np.average(self.predict_proba(x, noise), axis=1, weights=self.classes)\n        else:\n            return np.dot(self.predict_proba(x, noise), self.classes)\n\n    def predict_proba(self, x, noise=False):\n        if len(x.shape) == 1:\n            x = x.reshape(-1, 1)\n\n        x = check_array(x)\n\n        xx = pd.DataFrame(x, columns=self.likelihoods.columns[:-self.nclass])\n        xx = xx.merge(self.likelihoods, how='left')\n        xx.drop(xx.columns[:-self.nclass], axis=1, inplace=True)\n        xx.loc[xx.isnull().any(axis=1) | (xx == 0).all(axis=1), :] = self.class_priors\n\n        if noise:\n            np.random.seed(self.seed)\n            _noise = noise if isinstance(noise, float) else self.noise\n            if _noise > 1E-12:\n                xx = np.abs(xx + normal(0, scale=_noise, size=xx.shape))\n                xx = xx.div(xx.sum(axis=1), axis=0)\n\n        # return np.apply_along_axis(self._get_likelihood, 1, x, noise)\n        return xx.values\n\nclass LikelihoodEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, seed=0, alpha=0, leave_one_out=False, noise=0):\n        self.alpha = alpha\n        self.noise = noise\n        self.seed = seed\n        self.leave_one_out = leave_one_out\n        self.nclass = None\n        self.estimators = []\n\n    def fit(self, x, y):\n        if len(x.shape) == 1:\n            x = x.reshape(-1, 1)\n        ncols = x.shape[1]\n        if not is_numpy(x):\n            x = np.array(x)\n\n        self.nclass = np.unique(y).shape[0]\n\n        for i in range(ncols):\n            self.estimators.append(LikelihoodEstimator(**self.get_params()).fit(x[:, i], y))\n        return self\n      \n    def fit_transform(self, x, y):\n        self.fit(x, y)\n        return self.transform(x)\n\n    def transform(self, x):\n        if len(x.shape) == 1:\n            x = x.reshape(-1, 1)\n        ncols = x.shape[1]\n        if not is_numpy(x):\n            x = np.array(x)\n\n        likelihoods = None\n\n        for i in range(ncols):\n            lh = self.estimators[i].predict(x[:, i], noise=True).reshape(-1, 1)\n            # lh = self.estimators[i].predict_proba(x[:, i])\n            # if self.nclass <= 2:\n            #     lh = lh.T[1].reshape(-1, 1)\n            likelihoods = np.hstack((lh,)) if likelihoods is None else np.hstack((likelihoods, lh))\n        return likelihoods","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cat = X.copy()\nfor i in categorical_feature:\n  X_cat[:, i] = LabelEncoder().fit(X[:, i]).transform(X[:, i])\n  \nle = LikelihoodEncoder()\nX_likelihood = le.fit_transform(X_cat[:, 1:], LabelEncoder().fit_transform(y)) # # Not considering customer_id\nX_likelihood[:3, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Lets Stack features \"\"\"\nX_feature_stacking = np.hstack([X_label_count, X_feature, X_likelihood])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply knn algorithm to predict\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\ndisplay = True\nacc_knn=[]\nn_neighbors = 3 # Hyper parameter\nknn = KNeighborsClassifier(n_neighbors=n_neighbors)\nfor train_indices, test_indices in training_test_split:\n  knn.fit(X_feature_stacking[train_indices, :], y[train_indices])\n  \n  # Compute the nearest neighbor accuracy on the embedded test set\n  acc_knn.append(knn.score(X_feature_stacking[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \") \n    print(confusion_matrix(knn.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n    display = False\n  \nacc_knn = np.array(acc_knn)\nprint(\" Knn with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_knn.mean(), acc_knn.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply Naive algorithm to predict\n\nfrom sklearn.naive_bayes import GaussianNB\n\ndisplay = True\nacc_nb=[]\nn_neighbors = 3 # Hyper parameter\nnb = GaussianNB()\nfor train_indices, test_indices in training_test_split:\n  nb.fit(X_feature_stacking[train_indices, :], y[train_indices])\n  \n  # Compute the nearest neighbor accuracy on the embedded test set\n  acc_nb.append(nb.score(X_feature_stacking[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \") \n    print(confusion_matrix(knn.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n    display = False\n  \nacc_nb = np.array(acc_nb)\nprint(\" NB with neighbors={0}, accuracy={1}, {2}\".format(n_neighbors, acc_nb.mean(), acc_nb.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply SVM algo\nfrom sklearn import svm\nacc_svm = []\ndisplay = True\nclf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n\nfor train_indices, test_indices in training_test_split:\n  clf.fit(X_feature_stacking[train_indices, :], y[train_indices])\n  \n  acc_svm.append(clf.score(X_feature_stacking[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n    display = False\n        \n    \nacc_svm = np.array(acc_svm)\nprint(\" svm with kernel={0}, accuracy={1},{2}\".format('rbf', acc_svm.mean(), acc_svm.std()))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nacc_rf = []\ndisplay = True\nclf_rf = RandomForestClassifier(n_estimators=500, min_samples_split=5, random_state=42)\n\nfor train_indices, test_indices in training_test_split:\n  clf_rf.fit(X_feature_stacking[train_indices, :], y[train_indices])\n  \n  acc_rf.append(clf_rf.score(X_feature_stacking[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf_rf.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n    display = False\n     \n  \nacc_rf = np.array(acc_rf)\nprint(\" RF with n_estimators=500, accuracy={0},{1}\".format(n_neighbors, acc_rf.mean(), acc_rf.std()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\ndisplay = True\nacc_xgb = []\n\nfor train_indices, test_indices in training_test_split:\n  clf_xgb = xgb.XGBClassifier().fit(X_feature_stacking[train_indices, :], y[train_indices])\n  \n  acc_xgb.append(clf_xgb.score(X_feature_stacking[test_indices,:], y[test_indices]))\n  \n  if display:\n    print(\"confusion metrics = \")\n    print(confusion_matrix(clf_xgb.predict(X_feature_stacking[test_indices,:]), y[test_indices]))\n    display = False\n    \nacc_xgb = np.array(acc_xgb)\nprint(\" XGB with accuracy={0},{1}\".format(acc_xgb.mean(), acc_xgb.std()))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RF and XGB look very promising could it be that we may overfitted on the data Lets Check !!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_feature_train, X_feature_test, y_train, y_test = train_test_split(X_feature_stacking, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(clf_rf.predict(X_feature_test),y_test ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve\n\n\ny_pred_rf = clf_rf.predict_proba(X_feature_test)\nfpr_rf, tpr_rf, _ = roc_curve(LabelEncoder().fit_transform(y_test), y_pred_rf[:, 1])\n\nauc = roc_auc_score(LabelEncoder().fit_transform(y_test), y_pred_rf[:, 1])\n\nplt.figure(0)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rf, tpr_rf, label='RF AUC {}'.format(np.round(auc, 3)))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgb \nprint(confusion_matrix(clf_xgb.predict(X_feature_test),y_test ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve\n\n\ny_pred_rf = clf_xgb.predict_proba(X_feature_test)\nfpr_rf, tpr_rf, _ = roc_curve(LabelEncoder().fit_transform(y_test), y_pred_rf[:, 1])\n\nauc = roc_auc_score(LabelEncoder().fit_transform(y_test), y_pred_rf[:, 1])\n\nplt.figure(0)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rf, tpr_rf, label='XG AUC {}'.format(np.round(auc, 3)))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**My Hunch is it is overfitting now Need to put regularizer :)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}