{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Retail Analysis with Walmart Data\n\n\n#### DESCRIPTION :\n> One of the leading retail stores in the US, Walmart, would like to predict the sales and demand accurately. \nThere are certain events and holidays which impact sales on each day. There are sales data available for 45 \nstores of Walmart. The business is facing a challenge due to unforeseen demands and runs out of stock some times, \ndue to the inappropriate machine learning algorithm. An ideal ML algorithm will predict demand accurately and \ningest factors like economic conditions including CPI, Unemployment Index, etc.\n\n> Walmart runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, \nthe four largest of all, which are the Super Bowl, Labour Day, Thanksgiving, and Christmas. The weeks including \nthese holidays are weighted five times higher in the evaluation than non-holiday weeks. Part of the challenge \npresented by this competition is modeling the effects of markdowns on these holiday weeks in the absence of \ncomplete/ideal historical data. Historical sales data for 45 Walmart stores located in different regions are \navailable.\n\n\n#### Holiday Events :\n> 1. __Super Bowl :__ 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n> 2. __Labour Day :__ 10-Sep-10, 9-Sep-11, 7-Sep-12, 6-Sep-13\n> 3. __Thanksgiving :__ 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n> 4. __Christmas :__ 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13\n\n### Analysis Tasks.\n\n> #### Basic Statistics tasks :\n> * Which store has maximum sales\n> * Which store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation\n> * Which store/s has good quarterly growth rate in Q3â€™2012\n> * Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together\n> * Provide a monthly and semester view of sales in units and give insights\n\n\n> #### Statistical Model :\nFor Store 1 â€“ Build  prediction models to forecast demand\n> * Linear Regression â€“ Utilize variables like date and restructure dates as 1 for 5 Feb 2010 (starting from the earliest date in order). Hypothesize if CPI, unemployment, and fuel price have any impact on sales.\n> * Change dates into days by creating new variable.\n> * __Select the model which gives best accuracy.__","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport scipy.stats as stats\nimport sklearn as sk\nimport statsmodels as sm\n\nfrom datetime import datetime as dt\nfrom datetime import datetime as date\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:20.673034Z","iopub.execute_input":"2021-08-04T18:23:20.673586Z","iopub.status.idle":"2021-08-04T18:23:21.780297Z","shell.execute_reply.started":"2021-08-04T18:23:20.673467Z","shell.execute_reply":"2021-08-04T18:23:21.778953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/walmart-store-sales/Walmart_Store_sales.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:21.782199Z","iopub.execute_input":"2021-08-04T18:23:21.782566Z","iopub.status.idle":"2021-08-04T18:23:21.840342Z","shell.execute_reply.started":"2021-08-04T18:23:21.782517Z","shell.execute_reply":"2021-08-04T18:23:21.839315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA ðŸ”¨","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:21.842475Z","iopub.execute_input":"2021-08-04T18:23:21.84283Z","iopub.status.idle":"2021-08-04T18:23:21.86658Z","shell.execute_reply.started":"2021-08-04T18:23:21.842796Z","shell.execute_reply":"2021-08-04T18:23:21.865508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Change date to datetime format\n* __Weekly_Sales is target variable here__\n* No missing values.\n* Shape is (6435, 8)","metadata":{}},{"cell_type":"code","source":"# Date formatting : \ndata['Date'] = pd.to_datetime(data['Date'])\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:21.868392Z","iopub.execute_input":"2021-08-04T18:23:21.868746Z","iopub.status.idle":"2021-08-04T18:23:21.891232Z","shell.execute_reply.started":"2021-08-04T18:23:21.868711Z","shell.execute_reply":"2021-08-04T18:23:21.890462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Holiday_Flag'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:21.892548Z","iopub.execute_input":"2021-08-04T18:23:21.89313Z","iopub.status.idle":"2021-08-04T18:23:21.900598Z","shell.execute_reply.started":"2021-08-04T18:23:21.893091Z","shell.execute_reply":"2021-08-04T18:23:21.899795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['DateType'] = [dt.strptime(date, '%Y-%m-%d').date() for date in data['Date'].astype(str).values.tolist()]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:21.902005Z","iopub.execute_input":"2021-08-04T18:23:21.902343Z","iopub.status.idle":"2021-08-04T18:23:22.042786Z","shell.execute_reply.started":"2021-08-04T18:23:21.902299Z","shell.execute_reply":"2021-08-04T18:23:22.041752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Holidays :","metadata":{}},{"cell_type":"code","source":"data['Superbowl'] = np.where((data['DateType'] == dt(2010, 2, 12).date()) | (data['DateType'] == dt(2011, 2, 11).date())| \n                             (data['DateType'] == dt(2012, 2, 10).date()) | (data['DateType'] == dt(2013, 2, 8).date()),1, 0)\n\ndata['Labor_Day'] = np.where((data['DateType'] == dt(2010, 9, 10).date()) | (data['DateType'] == dt(2011, 9, 9).date()) | \n                             (data['DateType'] == dt(2012, 9,  7).date()) | (data['DateType'] == dt(2013, 9, 6).date()),1, 0)\n\ndata['Christmas'] = np.where((data['DateType'] == dt(2010, 12, 31).date()) | (data['DateType'] == dt(2011, 12, 30).date())| \n                             (data['DateType'] == dt(2012, 12, 28).date()) | (data['DateType'] == dt(2013, 12, 27).date()),1, 0)\n\ndata['Thanksgiving'] = np.where((data['DateType'] == dt(2010, 11, 26).date())| (data['DateType'] == dt(2011, 11, 25).date())|\n                                (data['DateType'] == dt(2012, 11, 23).date())|(data['DateType'] == dt(2013, 11, 29).date()),1,0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.044175Z","iopub.execute_input":"2021-08-04T18:23:22.044523Z","iopub.status.idle":"2021-08-04T18:23:22.084638Z","shell.execute_reply.started":"2021-08-04T18:23:22.044477Z","shell.execute_reply":"2021-08-04T18:23:22.083078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.Superbowl.value_counts())\nprint(data.Labor_Day.value_counts())\nprint(data.Thanksgiving.value_counts())\nprint(data.Christmas.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.086287Z","iopub.execute_input":"2021-08-04T18:23:22.086898Z","iopub.status.idle":"2021-08-04T18:23:22.103992Z","shell.execute_reply.started":"2021-08-04T18:23:22.086855Z","shell.execute_reply":"2021-08-04T18:23:22.102256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Which store has maximum sales","metadata":{}},{"cell_type":"code","source":"store_sales = data.groupby(['Store'])['Weekly_Sales'].sum().sort_values(ascending = False)\nround(store_sales, 1).head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.107035Z","iopub.execute_input":"2021-08-04T18:23:22.107381Z","iopub.status.idle":"2021-08-04T18:23:22.121957Z","shell.execute_reply.started":"2021-08-04T18:23:22.10735Z","shell.execute_reply":"2021-08-04T18:23:22.12109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### __So, the store 20 has maximum sales.__","metadata":{}},{"cell_type":"markdown","source":"## 2.  Which store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation","metadata":{}},{"cell_type":"code","source":"store_std = data.groupby(['Store'])['Weekly_Sales'].std().sort_values(ascending = False)\nround(store_std, 2).head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.123936Z","iopub.execute_input":"2021-08-04T18:23:22.124273Z","iopub.status.idle":"2021-08-04T18:23:22.138006Z","shell.execute_reply.started":"2021-08-04T18:23:22.124234Z","shell.execute_reply":"2021-08-04T18:23:22.136645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_mean = data.groupby(['Store'])['Weekly_Sales'].mean().sort_values(ascending = False)\n\ncoeff_variance = round(store_std / store_mean, 2)\n\ncoeff_variance.sort_values(ascending = False).head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.139796Z","iopub.execute_input":"2021-08-04T18:23:22.14022Z","iopub.status.idle":"2021-08-04T18:23:22.183786Z","shell.execute_reply.started":"2021-08-04T18:23:22.140182Z","shell.execute_reply":"2021-08-04T18:23:22.182272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights :\n>* __coeff_variance__ gives the coefficient of variance w.r.t particular stores of the dataset, as shown above.\n>* Store __14__ has the maximum standard deviation.","metadata":{}},{"cell_type":"markdown","source":"##  3.  Which store/s has good quarterly growth rate in Q3â€™2012","metadata":{}},{"cell_type":"code","source":"data['Year'] = data['Date'].dt.year\ndata['Month'] = data['Date'].dt.month\ndata['Quarter'] = data['Date'].dt.quarter\n\ndata.drop(columns = 'DateType', inplace = True)\n\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.185264Z","iopub.execute_input":"2021-08-04T18:23:22.185787Z","iopub.status.idle":"2021-08-04T18:23:22.220718Z","shell.execute_reply.started":"2021-08-04T18:23:22.185749Z","shell.execute_reply":"2021-08-04T18:23:22.219056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q3 = data[(data['Quarter'] == 3) & (data['Year'] == 2012)].groupby('Store')['Weekly_Sales'].sum().sort_values(ascending = False)\nq3.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.222228Z","iopub.execute_input":"2021-08-04T18:23:22.222561Z","iopub.status.idle":"2021-08-04T18:23:22.236366Z","shell.execute_reply.started":"2021-08-04T18:23:22.222529Z","shell.execute_reply":"2021-08-04T18:23:22.235168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insight :\n* Store __4__ has good quarterly growth rate in Q3â€™2012 with __maximum__ profit of $25652119.35$ compared with other stores.","metadata":{}},{"cell_type":"markdown","source":"#### Growth Rate :\n* Growth rate formula is defined as the ratio of difference in present value to past value by past value whole multiplied with 100 (since it is in percentage)\n* ((Present value â€” Past value )/Past value )*100","metadata":{}},{"cell_type":"code","source":"Q3_date_from = pd.Timestamp(date(2012, 7, 1))\nQ3_date_to = pd.Timestamp(date(2012, 9, 30))\nQ2_date_from = pd.Timestamp(date(2012, 4, 1))\nQ2_date_to = pd.Timestamp(date(2012, 6, 30))\n\n#Collecting the data of Q3 and Q2 from original dataset.\nQ2data = data[(data['Date'] > Q2_date_from) & (data['Date'] < Q2_date_to)]\nQ3data = data[(data['Date'] > Q3_date_from) & (data['Date'] < Q3_date_to)]\n\n#finding the sum weekly sales of each store in Q2\nQ2 = pd.DataFrame(Q2data.groupby('Store')['Weekly_Sales'].sum())\nQ2.reset_index(inplace=True)\nQ2.rename(columns={'Weekly_Sales': 'Q2_Weekly_Sales'},inplace = True)\n\n#finding the sum weekly sales of each store in Q2\nQ3 = pd.DataFrame(Q3data.groupby('Store')['Weekly_Sales'].sum())\nQ3.reset_index(inplace=True)\nQ3.rename(columns = {'Weekly_Sales': 'Q3_Weekly_Sales'},inplace = True)\n\n#mergeing Q2 and Q3 data on Store as a common column\nQ3_Growth= Q2.merge(Q3,how =  'inner',on = 'Store')\n\n#Calculating Growth rate of each Store and collecting it into a dataframe  \nQ3_Growth['Growth_Rate'] = (Q3_Growth['Q3_Weekly_Sales'] - Q3_Growth['Q2_Weekly_Sales']) / Q3_Growth['Q2_Weekly_Sales']\nQ3_Growth['Growth_Rate'] = round(Q3_Growth['Growth_Rate'],2)\nQ3_Growth.sort_values('Growth_Rate',ascending = False).head(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.23813Z","iopub.execute_input":"2021-08-04T18:23:22.238531Z","iopub.status.idle":"2021-08-04T18:23:22.277869Z","shell.execute_reply.started":"2021-08-04T18:23:22.238474Z","shell.execute_reply":"2021-08-04T18:23:22.276579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q3_Growth.sort_values('Growth_Rate',ascending = False).tail(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.279132Z","iopub.execute_input":"2021-08-04T18:23:22.27945Z","iopub.status.idle":"2021-08-04T18:23:22.29452Z","shell.execute_reply.started":"2021-08-04T18:23:22.279416Z","shell.execute_reply":"2021-08-04T18:23:22.293467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights :\n> * From above information we can say that Q3 growth rate is in __loss.__\n> * Store 16 has the __least loss__ of 3% compared with other stores.\n> * Store 14 has the __highest loss__ total of 18%","metadata":{}},{"cell_type":"markdown","source":"## 4.  Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together","metadata":{}},{"cell_type":"code","source":"round(data.groupby(['Holiday_Flag'])['Weekly_Sales'].sum(),1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.295897Z","iopub.execute_input":"2021-08-04T18:23:22.296229Z","iopub.status.idle":"2021-08-04T18:23:22.310019Z","shell.execute_reply.started":"2021-08-04T18:23:22.296185Z","shell.execute_reply":"2021-08-04T18:23:22.309221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('0 :', 6.231919e+09)\nprint('1 :', 5.052996e+08)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.311433Z","iopub.execute_input":"2021-08-04T18:23:22.311991Z","iopub.status.idle":"2021-08-04T18:23:22.323435Z","shell.execute_reply.started":"2021-08-04T18:23:22.311947Z","shell.execute_reply":"2021-08-04T18:23:22.32224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Spr_sales = data.groupby(['Superbowl'])['Weekly_Sales'].mean()\n\nLd_sales = data.groupby(['Labor_Day'])['Weekly_Sales'].mean()\n\nThanksg_sales = data.groupby(['Thanksgiving'])['Weekly_Sales'].mean()\n\nChristmas_sales = data.groupby(['Christmas'])['Weekly_Sales'].mean()\n\nNon_Holi_Sales = data[(data['Holiday_Flag'] == 0)].groupby('Holiday_Flag')['Weekly_Sales'].mean()\n\n\nprint(round(Spr_sales, 2))\nprint(round(Ld_sales, 2))\nprint(round(Thanksg_sales, 2))\nprint(round(Christmas_sales, 2))\nprint(round(Non_Holi_Sales, 2))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.324582Z","iopub.execute_input":"2021-08-04T18:23:22.324994Z","iopub.status.idle":"2021-08-04T18:23:22.355882Z","shell.execute_reply.started":"2021-08-04T18:23:22.324963Z","shell.execute_reply":"2021-08-04T18:23:22.355081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing :ðŸ“š\n\n### 1. Sales in Super Bowl holiday.","metadata":{}},{"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nplt.figure(figsize = (10, 6))\nSpr_sales.plot(kind = 'bar', legend = False, title = 'Sales in Super Bowl holiday', color = 'thistle')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.357163Z","iopub.execute_input":"2021-08-04T18:23:22.357457Z","iopub.status.idle":"2021-08-04T18:23:22.573643Z","shell.execute_reply.started":"2021-08-04T18:23:22.357428Z","shell.execute_reply":"2021-08-04T18:23:22.572675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Sales in Labor Day holiday.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nLd_sales.plot(kind = 'bar', legend = False, title = 'Sales in Labour Day holiday', color = ['plum','lavender'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.575037Z","iopub.execute_input":"2021-08-04T18:23:22.575356Z","iopub.status.idle":"2021-08-04T18:23:22.749906Z","shell.execute_reply.started":"2021-08-04T18:23:22.575324Z","shell.execute_reply":"2021-08-04T18:23:22.748899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Sales in Thanksgiving holiday.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nThanksg_sales.plot(kind = 'bar', legend = False, title = 'Sales in Thanksgiving holiday', color = ['powderblue','skyblue'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.753754Z","iopub.execute_input":"2021-08-04T18:23:22.754116Z","iopub.status.idle":"2021-08-04T18:23:22.912919Z","shell.execute_reply.started":"2021-08-04T18:23:22.754081Z","shell.execute_reply":"2021-08-04T18:23:22.911867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Sales in Christmas holiday.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nChristmas_sales.plot(kind = 'bar', legend = False, title = 'Sales in Christmas holiday', color = ['plum','lavender'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:22.914377Z","iopub.execute_input":"2021-08-04T18:23:22.914771Z","iopub.status.idle":"2021-08-04T18:23:23.070473Z","shell.execute_reply.started":"2021-08-04T18:23:22.914737Z","shell.execute_reply":"2021-08-04T18:23:23.069133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Non Holiday Sales.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nNon_Holi_Sales.plot(kind = 'bar', legend = False, title = 'Sales in Non-holiday', color = 'lavender')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:23.072136Z","iopub.execute_input":"2021-08-04T18:23:23.072606Z","iopub.status.idle":"2021-08-04T18:23:23.227287Z","shell.execute_reply.started":"2021-08-04T18:23:23.072556Z","shell.execute_reply":"2021-08-04T18:23:23.226178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Provide a monthly and semester view of sales in units and give insights.\n\n\n### I. Monthly sales view","metadata":{}},{"cell_type":"code","source":"monthly = data.groupby(pd.Grouper(key = 'Date', freq = '1M')).sum()\nmonthly = monthly.reset_index()\nfig, ax = plt.subplots(figsize=(13,6), dpi = 80)\nX = monthly['Date']\nY = monthly['Weekly_Sales']\nplt.plot(X,Y, color = 'plum')\nplt.title('Month Wise Sales')\nplt.xlabel('Monthly')\nplt.ylabel('Weekly Sales')\nplt.legend(['Sales'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:23.22863Z","iopub.execute_input":"2021-08-04T18:23:23.228946Z","iopub.status.idle":"2021-08-04T18:23:23.512882Z","shell.execute_reply.started":"2021-08-04T18:23:23.228911Z","shell.execute_reply":"2021-08-04T18:23:23.511727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### II. Semester wise sales view","metadata":{}},{"cell_type":"code","source":"Semester = data.groupby(pd.Grouper(key='Date', freq='6M')).sum()\nSemester = Semester.reset_index()\nfig, ax = plt.subplots(figsize=(13,6), dpi = 80)\nX = Semester['Date']\nY = Semester['Weekly_Sales']\nplt.plot(X,Y)\nplt.title('Semester Wise Sales')\nplt.xlabel('Semester')\nplt.ylabel('Weekly Sales')\nplt.legend('Sales')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:23.514081Z","iopub.execute_input":"2021-08-04T18:23:23.514378Z","iopub.status.idle":"2021-08-04T18:23:23.79311Z","shell.execute_reply.started":"2021-08-04T18:23:23.514349Z","shell.execute_reply":"2021-08-04T18:23:23.791899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights :\n> * We can infer that there's a big spike in sales from __February-2010__ to __February-2011__. Exactly for one year we can say.\n> * Then spike goes __bit down__ in February-2011 after that again there are few __ups-downs__ in further.\n> * From __August-2012__ sales goes __down__. **-** We can acknowledge that there is __loss__ in sales.","metadata":{}},{"cell_type":"markdown","source":"# For Store 1 â€“ Build  prediction models to forecast demand","metadata":{}},{"cell_type":"code","source":"data.drop(columns = ['Superbowl', 'Labor_Day', 'Christmas', 'Thanksgiving'], inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:23.795023Z","iopub.execute_input":"2021-08-04T18:23:23.795455Z","iopub.status.idle":"2021-08-04T18:23:23.801909Z","shell.execute_reply.started":"2021-08-04T18:23:23.795398Z","shell.execute_reply":"2021-08-04T18:23:23.800946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:23.805796Z","iopub.execute_input":"2021-08-04T18:23:23.806144Z","iopub.status.idle":"2021-08-04T18:23:24.242925Z","shell.execute_reply.started":"2021-08-04T18:23:23.806111Z","shell.execute_reply":"2021-08-04T18:23:24.242071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Store']","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.244872Z","iopub.execute_input":"2021-08-04T18:23:24.245551Z","iopub.status.idle":"2021-08-04T18:23:24.255339Z","shell.execute_reply.started":"2021-08-04T18:23:24.245507Z","shell.execute_reply":"2021-08-04T18:23:24.254371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Store'] = data['Store'].astype(str)\ndata['Store'] = 'Store ' + data['Store'].astype(str)\n\ndata.Store","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.256955Z","iopub.execute_input":"2021-08-04T18:23:24.257738Z","iopub.status.idle":"2021-08-04T18:23:24.280565Z","shell.execute_reply.started":"2021-08-04T18:23:24.257665Z","shell.execute_reply":"2021-08-04T18:23:24.279566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelEncod = LabelEncoder()\nstore_1 = data[data['Store'] == 'Store 1']\nstore_1 = store_1.copy()\n\nstore_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.281808Z","iopub.execute_input":"2021-08-04T18:23:24.282394Z","iopub.status.idle":"2021-08-04T18:23:24.30734Z","shell.execute_reply.started":"2021-08-04T18:23:24.282347Z","shell.execute_reply":"2021-08-04T18:23:24.30624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"store_1['Days'] = labelEncod.fit_transform(store_1['Date'])\nstore_1.drop(['Store','Date','Holiday_Flag','Year','Month','Quarter'], axis=1 , inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.308645Z","iopub.execute_input":"2021-08-04T18:23:24.308948Z","iopub.status.idle":"2021-08-04T18:23:24.316625Z","shell.execute_reply.started":"2021-08-04T18:23:24.308912Z","shell.execute_reply":"2021-08-04T18:23:24.315387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ncorr = store_1.corr()\nplt.figure(figsize = (13,8), dpi = 80)\ncorrmap = sns.heatmap(store_1.corr(), cmap = 'PuBuGn_r', annot = True)\ncorrmap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.318149Z","iopub.execute_input":"2021-08-04T18:23:24.318586Z","iopub.status.idle":"2021-08-04T18:23:24.846104Z","shell.execute_reply.started":"2021-08-04T18:23:24.318555Z","shell.execute_reply":"2021-08-04T18:23:24.845089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hypothesize if CPI, unemployment, and fuel price have any impact on sales.\n\n### Insights :\n> 1. As we can see __unemployment__ is highly correlated with __days__ and is ___insignificant___ as it correlation with Weekly Sales is __quite low.__ \n> 2. Also __temperature__ and __Unemployment__ are __negatively__ impacting the sales . \n> 3. however __Fuel Price__ and __CPI__ are __positively__ impacting the Sales.\n","metadata":{}},{"cell_type":"markdown","source":"## Model Building : Linear RegressionðŸ“ˆ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = store_1[['Days', 'Fuel_Price', 'CPI', 'Unemployment']]\ny = store_1['Weekly_Sales']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 123)\n\n\nprint('Shape of X_train :', X_train.shape)\nprint('Shape of y_train :', y_train.shape)\nprint('-'*40)\nprint('Shape of X_test :', X_test.shape)\nprint('Shape of y_test :', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.847414Z","iopub.execute_input":"2021-08-04T18:23:24.847749Z","iopub.status.idle":"2021-08-04T18:23:24.860096Z","shell.execute_reply.started":"2021-08-04T18:23:24.847718Z","shell.execute_reply":"2021-08-04T18:23:24.858375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinear_reg = LinearRegression()\nlinear_reg.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:24.862043Z","iopub.execute_input":"2021-08-04T18:23:24.862583Z","iopub.status.idle":"2021-08-04T18:23:25.069768Z","shell.execute_reply.started":"2021-08-04T18:23:24.862535Z","shell.execute_reply":"2021-08-04T18:23:25.0687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = linear_reg.predict(X_test)\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.07108Z","iopub.execute_input":"2021-08-04T18:23:25.071386Z","iopub.status.idle":"2021-08-04T18:23:25.082307Z","shell.execute_reply.started":"2021-08-04T18:23:25.071357Z","shell.execute_reply":"2021-08-04T18:23:25.081592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Coefficients: \\n',linear_reg.coef_)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.083605Z","iopub.execute_input":"2021-08-04T18:23:25.084127Z","iopub.status.idle":"2021-08-04T18:23:25.10061Z","shell.execute_reply.started":"2021-08-04T18:23:25.08409Z","shell.execute_reply":"2021-08-04T18:23:25.099411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Variance score: %.2f' % linear_reg.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.101857Z","iopub.execute_input":"2021-08-04T18:23:25.102143Z","iopub.status.idle":"2021-08-04T18:23:25.118378Z","shell.execute_reply.started":"2021-08-04T18:23:25.102115Z","shell.execute_reply":"2021-08-04T18:23:25.117272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Note :\n> * From above I can infer that Linear Regression model performs very poorly on our dataset.\n> * As we can see the variance is in negative numbers. Which indicates that our model is __Poor__.\n> * __Minimum__ variance helps our model to be __ideal / accurate__, Therefore further down I'll implement __RandomForest__ algorithms and check for accuray.\n> * If accuracy increses, then I will pick the model.\n> * Another way we can check accuracy by showing comparison between actual values and predicted values.\n\n# RandomForestRegressorðŸŽ„","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.119762Z","iopub.execute_input":"2021-08-04T18:23:25.12017Z","iopub.status.idle":"2021-08-04T18:23:25.128336Z","shell.execute_reply.started":"2021-08-04T18:23:25.12012Z","shell.execute_reply":"2021-08-04T18:23:25.127086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfr = RandomForestRegressor(n_estimators = 400, max_depth = 15)\nrfr.fit(X_train, y_train)\nY_pred = rfr.predict(X_test)\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint('-'*40)\nprint('Variance score: %.2f' % rfr.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.129606Z","iopub.execute_input":"2021-08-04T18:23:25.12989Z","iopub.status.idle":"2021-08-04T18:23:25.945133Z","shell.execute_reply.started":"2021-08-04T18:23:25.129862Z","shell.execute_reply":"2021-08-04T18:23:25.944218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Actual_vs_Pred = pd.DataFrame({\"Actual Sales\" : y_test, \"Predicted Sales\": y_pred})\nActual_vs_Pred.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.946325Z","iopub.execute_input":"2021-08-04T18:23:25.946652Z","iopub.status.idle":"2021-08-04T18:23:25.959709Z","shell.execute_reply.started":"2021-08-04T18:23:25.946621Z","shell.execute_reply":"2021-08-04T18:23:25.95861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Predicted Demand for Store 1***","metadata":{}},{"cell_type":"code","source":"# Errors in % w.r.t the particular store sales : predicted sales and actual sales.\nErrors = pd.DataFrame({'errors':round(((abs(y_pred - y_test))/y_test)*100,2)})\nErrors.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T18:23:25.993806Z","iopub.execute_input":"2021-08-04T18:23:25.994259Z","iopub.status.idle":"2021-08-04T18:23:26.012896Z","shell.execute_reply.started":"2021-08-04T18:23:25.994215Z","shell.execute_reply":"2021-08-04T18:23:26.012099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Insights : \n> * So here we can see, we have predicted __demand__ for store $1$\n> * Further down I've shown a table that shows __errors__ in %, w.r.t the store sales demand.\n> * Errors are not huge to decline our model also the __variance__ is good.\n> * Therefore we accept this Model - __RandomForest Regressor__.\n\n$Swapnil$  $Narwade$\n> *swapnil.narwade3@gmail.com* ðŸ¦„","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}