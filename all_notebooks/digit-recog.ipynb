{"cells":[{"metadata":{},"cell_type":"markdown","source":"Check [TensorBoard](https://tensorboard.dev/experiment/ozWPbkolTMCp6ABYydbwVg/#scalars)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read and reshape the data from dataframe to 3d tensors."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ndf_test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n\ny_train = np.array(df_train['label'])\ndf_train.drop('label', axis=1, inplace=True)\n\nx_train = np.expand_dims(df_train, axis=-1)\nx_train = np.reshape(x_train, (x_train.shape[0], 28, 28))\nx_train = np.expand_dims(x_train, axis=-1)\n\nx_test = np.expand_dims(df_test, axis=-1)\nx_test = np.reshape(x_test, (x_test.shape[0], 28, 28))\nx_test = np.expand_dims(x_test, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting the data to train and validation groups. Test tensor does not have labels as it is scored by Kaggle server."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_train,y_train,stratify=y_train,test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train: {x_train.shape}, Labels: {y_train.shape}, Val: {x_val.shape} Test: {x_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Change labels from scalars to one hot encoded 10 dim vectors."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = tensorflow.keras.utils.to_categorical(y_train,10)\ny_val = tensorflow.keras.utils.to_categorical(y_val,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I've recently came across an article which describes why testing on test samples does not always go as planned. Apparently the Kaggle test data contains many pictures which are wrongly labeled or are very hard to recognize even by a human.\n\nHere are some samples:"},{"metadata":{"trusted":true},"cell_type":"code","source":"hard_list = [2617, 4748, 5276, 9545, 10950, 11272, 14512, 16490, 17244, 19083,\n             20043, 20241, 20509, 22009, 22565, 24984, 27336, 27716, 3277, 3279,\n             6979, 7461, 8458, 8465, 10434, 14459, 14798, 14992, 15656, 16452,\n             17946, 18107, 22823, 24015, 25715, 27352, 27937, 6117, 18649, 11539,\n             15047, 15158, 8119, 19542, 20153, 21657, 22766, 24767, 27799, 645]\nhard_list_answ = [6, 7, 1, 1, 2, 1, 1, 1, 1, 7,\n                 7, 1, 5, 1, 6, 4, 0, 8, 9, 4,\n                 9, 4, 9, 6, 9, 4, 9, 9, 4, 9,\n                 9, 4, 9, 4, 4, 9, 9, 6, 6, 0,\n                 5, 3, 9, 8, 9, 5, 8, 5, 7, 2]\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# preview the images first\nplt.figure(figsize=(12,10))\nx, y = 10, 5\ncounter = 0\nfor index, answer in zip(hard_list, hard_list_answ):  \n    plt.subplot(y, x, counter+1)\n    plt.imshow(x_test[index].reshape((28,28)), cmap='gray')\n    plt.title(answer)\n    counter += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"37000 images of 10 different categories may be not enough so I've decided to use data augmentation. It's main job is to rotate a little an shift images. I can't do much because these are digits so 1 rotated can look as 7 and so on. But still I think it helps a little."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = tensorflow.keras.utils.normalize(x_train, axis=-1)\nx_test = tensorflow.keras.utils.normalize(x_test, axis=-1)\nx_val = tensorflow.keras.utils.normalize(x_val, axis=-1)\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1,\n                                 rotation_range=15,\n                                 width_shift_range=0.2,\n                                 height_shift_range=0.2,\n                                 zoom_range=0.1,\n                                 horizontal_flip=False,\n                                 vertical_flip=False)\ntest_datagen = ImageDataGenerator(rescale=1)\n\ntrain_generator = train_datagen.flow(x_train, y_train,\n                                    batch_size=64)\n\nvalidation_generator = test_datagen.flow(x_val, y_val,\n                                        batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the model I've used 3 blocks built from 2 Conv2D layers (after every one BatchNormalization to smooth out training) followed by MaxPooling - only last block lacks it because the data is too small to do next one in my opinion. I go 32-64-128 with the filters. It's followed by the Dropout to reduce overfitting and one Dense layer built from 512 neurons. Input to this layer is only (4608,) so 512 neurons should do the work. Before the output layer I've added 0.25 Dropout just in case.\n\nFirst block doesn't use padding because most of the time the edge pixels are black (value = 0) so I don't mind losing the data.\n\nOptimizer - adam (I've tested also rmsprop with no difference), Loss - categorical_crossentropy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.python.keras.layers.normalization import BatchNormalization\nfrom tensorflow.python.keras.regularizers import l2\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\n# model.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu', kernel_regularizer=l2(0.001)))\nmodel.add(Dropout(0.25))\n\n# model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n# model.add(Dropout(0.4))\n# model.add(Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n# model.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I use 4 callbacks. ModelCheckpoint to save lowest loss, EarlyStopping to leave training, ReduceLROnPlateau to gradualy reduce LR when aproaching minimum and Tensorboard."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n\nmcp = ModelCheckpoint(\"/kaggle/working/best_model.hdf5\", monitor='val_loss', verbose=1,\n    save_best_only=True)\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\nimport time\n\n# !rm -R ./logs/ # rf\nlog_dir=\"logs/fit/{}-{}\".format('CNN-Digit-recog-aug', time.strftime(\"%Y%m%d-%H%M%S\", time.gmtime()))\ntensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"history_aug = model.fit_generator(train_generator,\n                                  steps_per_epoch= (64 // x_train.shape[0]),\n                                  epochs=50,\n                                  validation_data=validation_generator,\n                                  validation_steps=(64 // x_val.shape[0]),\n                                  callbacks=[mcp, es, learning_rate_reduction, tensorboard])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simple plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history_aug.history['accuracy']\nval_acc = history_aug.history['val_accuracy']\nval_loss = history_aug.history['val_loss']\nepochs = range(1, len(acc) + 1)\nloss = history_aug.history['loss']\n\nplt.plot(epochs, loss, 'b', label='Training loss', color='red')\nplt.plot(epochs, val_loss, 'b', label='Validation loss', color='blue')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.clf()\n\nplt.plot(epochs, acc, 'b', label='Training accuracy', color='red')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy', color='blue')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Or see the same in [TensorBoard for 3 runs](https://tensorboard.dev/experiment/ozWPbkolTMCp6ABYydbwVg/#scalars)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\nbest_model = load_model('/kaggle/working/best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict the labels for test images and save to csv file to upload to kaggle."},{"metadata":{"trusted":true},"cell_type":"code","source":"results=best_model.predict_classes(x_test)\nprint(results)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n#submission.to_csv(\"F:\\\\PYTHON PROGRAM\\\\JaiShreeRammnist11.csv\",index=False)\nsubmission.to_csv(\"submission.csv\",index=False,header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_check = pd.read_csv('/kaggle/working/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_check","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model scored over 99.4% in the best run and 99.3% avg over 3 runs so I'm very happy with the result >99%\n\n![Score](https://i.imgur.com/4Ntb12D.png)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}