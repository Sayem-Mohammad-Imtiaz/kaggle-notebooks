{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Welcome to this Carleton AI Society workshop!\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%capture\nfrom IPython.display import Image\n\nimport os\nimport re\nimport numpy as np\nimport pandas as pd\nimport random\nimport warnings\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import collections as matcoll\nimport seaborn as sns\nimport lightgbm\n\nimport sklearn\nfrom sklearn import ensemble\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import *\nfrom sklearn.metrics import *\n\nfrom sklearn.metrics import roc_auc_score\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings('ignore')\nmatplotlib.rcParams['figure.figsize'] = [15, 7.5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L6_100nt = pd.read_csv('../input/L6_100nt.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Finding columns that contain data about the participant's microbiota\")\nL6_pattern = re.compile(\"k__(\\w*);p__(\\w*);c__(\\w*);o__(\\w*);f__(\\w*);g__(\\w*)$\")\nL3_pattern = re.compile(\"k__(\\w*);p__(\\w*);c__(\\w*);o__(\\w*)$\")\nL2_pattern = re.compile(\"k__(\\w*);p__(\\w*)$\")\nL6_columns = [col for col in L6_100nt.columns if L6_pattern.match(col)]\nL3_columns = [col for col in L6_100nt.columns if L3_pattern.match(col)]\nL2_columns = [col for col in L6_100nt.columns if L2_pattern.match(col)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_data(data, column, title, xAxis):\n    \"\"\" Just a quick function to plot data easily \"\"\"\n    data[column] = pd.to_numeric(data[column], errors='coerce')\n    fig, axes = plt.subplots(1, 2)\n    female = data[data['SEX'] == 'female']\n    male = data[data['SEX'] == 'male']\n    fig.suptitle(title, fontsize=16)\n    sns.distplot(male[column], bins=40, kde=False, ax=axes[0]);\n    axes[0].set_ylabel('Number of Individuals (male)', fontsize=14)\n    axes[0].set_xlabel(xAxis, fontsize=14)\n    sns.distplot(female[column], bins=40, kde=False, ax=axes[1], color='r');\n    axes[1].set_ylabel('Number of Individuals (female)', fontsize=14)\n    axes[1].set_xlabel(xAxis, fontsize=14)\n    return fig\n\ndef filter_data(study):\n    \"\"\" Removes unwanted rows or modify them to limit the space of the task \"\"\"\n    study = L6_100nt[L6_100nt['STUDY'] == study]\n\n    study['BMI_CORRECTED'] = study['BMI_CORRECTED'].replace(\"no_data\",np.nan).replace(\"Unspecified\",np.nan).replace(\"Unknown\",np.nan).astype(float)\n    study['AGE_CORRECTED'] = study['AGE_CORRECTED'].replace(\"Unspecified\",np.nan).replace(\"Unknown\",np.nan).astype(float)    \n    study = study[(study['AGE_CORRECTED'].isnull()) | (study['AGE_CORRECTED'] >= 18)]\n    \n    subset_underweight = study[(study['BMI_CORRECTED'] < 18.5)]\n    subset_healthyweight = study[(study['BMI_CORRECTED'] >= 18.5) & (study['BMI_CORRECTED'] < 25)]\n    subset_overweight = study[(study['BMI_CORRECTED'] >= 25) & (study['BMI_CORRECTED'] < 30)]\n    subset_obese = study[(study['BMI_CORRECTED'] >= 30) & (study['BMI_CORRECTED'])]\n    \n    study = pd.concat([subset_underweight, subset_healthyweight, subset_overweight, subset_obese])\n    \n    #Label Smoothing\n    study['SUBSET_UNDERWEIGHT'] = (study['BMI_CORRECTED'] < 18.5).astype(float) * 0.8\n    study['SUBSET_HEALTHYWEIGHT'] = ((study['BMI_CORRECTED'] >= 18.5) & (study['BMI_CORRECTED'] < 25)).astype(float) * 0.8\n    study['SUBSET_OVERWEIGHT'] = ((study['BMI_CORRECTED'] >= 25) & (study['BMI_CORRECTED'] < 30)).astype(float) * 0.8\n    study['SUBSET_OBESE'] = (study['BMI_CORRECTED'] >= 30).astype(float) * 0.8\n    return study","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Filtering based on the study, as many scientific studies were involved\")\nmeta_study = pd.concat([filter_data(study) for study in L6_100nt['STUDY'].unique()])\nmeta_study = meta_study[~meta_study['#SampleID'].duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Just a quick overview of the height of the participants. This can be used as a simple sanity check.\")\nsns.set()\nplt.show(visualize_data(meta_study, 'HEIGHT_CM', 'Height Distribution', 'Height (cm)'))\n#plt.show(visualize_data(meta_study, 'WEIGHT_KG', 'Weight Distribution', 'Weight (kg)'))\n#plt.show(visualize_data(meta_study, 'BMI_CORRECTED', 'BMI Distribution', 'BMI'))\n#plt.show(visualize_data(meta_study, 'AGE_CORRECTED', 'Age Distribution', 'Age (years)'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Grab every participant ignoring BMI class sizes \nsubset_underweight = meta_study[meta_study['SUBSET_UNDERWEIGHT'].astype(bool)]\nsubset_healthyweight = meta_study[meta_study['SUBSET_HEALTHYWEIGHT'].astype(bool)]#.sample(n=1000, random_state=SEED)\nsubset_overweight = meta_study[meta_study['SUBSET_OVERWEIGHT'].astype(bool)]#.sample(n=391, random_state=SEED)\nsubset_obese = meta_study[meta_study['SUBSET_OBESE'].astype(bool)]#.sample(n=391, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta = pd.concat([subset_underweight, subset_healthyweight, subset_overweight, subset_obese])\nmeta = meta.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering data to only consider one source of microbiota in the participant's body \n# Filtering further to ignore participants who recently used antibiotic\ndata = meta[meta['BODY_SITE'] == 'UBERON:feces']\ndata = data[data['SUBSET_ANTIBIOTIC_HISTORY'] | (data['ANTIBIOTIC_HISTORY'] == 'Year') | (data['ANTIBIOTIC_HISTORY'] == '6 months')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = meta[L6_columns].var().sort_values(ascending=False).index[:600].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.groupby([\"HOST_SUBJECT_ID\"]).first()\n\nunder = data[data[\"SUBSET_UNDERWEIGHT\"] == 0.8]\nover = data[data[\"SUBSET_OBESE\"] == 0.8]\n\nsample_size = min(under.shape[0], over.shape[0])\n\nunder = under.sample(sample_size)\nover = over.sample(sample_size)\n\nobesity = pd.concat([under, over])\n\nobesity[\"obesity_target\"] = (obesity[\"SUBSET_OBESE\"] == 0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(obesity[features], obesity[\"obesity_target\"], test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\nmodel = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\ntrained_model = model.fit(x_train, y_train)\npredictions = model.predict(x_test)\ncm = confusion_matrix(y_test, predictions)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nprint(roc_auc_score(y_test, predictions))\npd.DataFrame(data=cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dimensions = 300\nn_points = 1000\n\ncursed_data = np.random.normal(0, 1, size=(n_points, dimensions))\ncursed_label = cursed_data[:,0] > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cursed_data[:,0], y=[0]*(n_points), c=cursed_label, cmap=\"Accent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(cursed_data[:,0], cursed_data[:,1], c=cursed_label, cmap=\"Accent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\nax.scatter(cursed_data[:,0], cursed_data[:,2], cursed_data[:,1], c=cursed_label, cmap=\"Accent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cursed_features = range(0,100)\ncursed_df = pd.DataFrame(cursed_data)\ncursed_df[\"target\"] = cursed_label\nx_train, x_test, y_train, y_test = train_test_split(cursed_df[cursed_features], cursed_df[\"target\"], test_size=0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sklearn.neighbors.KNeighborsClassifier()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sklearn.tree.DecisionTreeClassifier()\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(obesity[features], obesity[\"obesity_target\"], test_size=0.30)\nmodel = sklearn.tree.DecisionTreeClassifier()\ntrained_model = model.fit(x_train, y_train)\npredictions = model.predict(x_test)\ncm = confusion_matrix(y_test, predictions)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nprint(roc_auc_score(y_test, predictions))\npd.DataFrame(data=cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trials = []\nrf_trials = []\nfor trial in range(100):\n    x_train, x_test, y_train, y_test = train_test_split(obesity[features], obesity[\"obesity_target\"], test_size=0.30)\n    model = sklearn.tree.DecisionTreeClassifier()\n    trained_model = model.fit(x_train, y_train)\n    predictions = model.predict(x_test)\n    score = (roc_auc_score(y_test, predictions))\n    trials.append(score)\n    \n    model = sklearn.ensemble.RandomForestClassifier(n_estimators=20)\n    trained_model = model.fit(x_train, y_train)\n    predictions = model.predict(x_test)\n    score = (roc_auc_score(y_test, predictions))\n    rf_trials.append(score)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = plt.hist(trials,bins=10, alpha=0.5, label=f\"Single Decision Tree: {np.mean(trials)}\")\nh = plt.hist(rf_trials,bins=10, alpha=0.5, label=f\"Random Forest: {np.mean(rf_trials)}\")\nplt.legend(loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plant_group = data.groupby([\"HOST_SUBJECT_ID\"]).first()\n\nplanty = plant_group[plant_group[\"TYPES_OF_PLANTS\"] == \"More than 30\"]\nnot_planty = pd.concat([plant_group[plant_group[\"TYPES_OF_PLANTS\"] == \"6 to 10\"], plant_group[plant_group[\"TYPES_OF_PLANTS\"] == \"Less than 5\"]])\n\nsample_size = min(planty.shape[0],not_planty.shape[0])\n\nplanty = planty.sample(sample_size)\nnot_planty = not_planty.sample(sample_size)\n\nplant_set = pd.concat([planty,not_planty])\ntargets = [1]*len(planty)+[0]*len(not_planty)\nplant_set[\"target\"] = targets\nplant_set = plant_set.sample(frac=1.0)\n\nx_train, x_test, y_train, y_test = train_test_split(plant_set[features], plant_set[\"target\"], test_size=0.20)\n\nmodel = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\ntrained_model = model.fit(x_train, y_train)\npredictions = model.predict(x_test)\ncm = confusion_matrix(y_test, predictions)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nprint(\"AUC score:\", roc_auc_score(y_test, predictions))\npd.DataFrame(data=cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=\"TYPES_OF_PLANTS\", hue=\"obesity_target\", data=obesity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(obesity.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import umap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reducer = umap.UMAP()\nembedding = reducer.fit_transform(obesity[features])\ncolors = sklearn.preprocessing.LabelEncoder().fit_transform(obesity[\"ALCOHOL_FREQUENCY\"])\nplt.scatter(embedding[:, 0], embedding[:, 1], c=[sns.color_palette()[x] for x in colors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reducer = sklearn.decomposition.PCA()\nembedding = reducer.fit_transform(obesity[features])\ncolors = sklearn.preprocessing.LabelEncoder().fit_transform(obesity[\"obesity_target\"])\nplt.scatter(embedding[:, 0], embedding[:, 1], c=[sns.color_palette()[x] for x in colors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reducer = umap.UMAP(n_components=2)\nembedding = reducer.fit_transform(obesity[features], y=obesity[\"obesity_target\"])\ncolors = sklearn.preprocessing.LabelEncoder().fit_transform(obesity[\"obesity_target\"])\nplt.scatter(embedding[:, 0], embedding[:, 1], c=[sns.color_palette()[x] for x in colors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding = reducer.transform(obesity[features])\ncolors = sklearn.preprocessing.LabelEncoder().fit_transform(obesity[\"obesity_target\"])\nplt.scatter(embedding[:, 0], embedding[:, 1], c=[sns.color_palette()[x] for x in colors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://msystems.asm.org/content/3/3/e00031-18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reducer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}