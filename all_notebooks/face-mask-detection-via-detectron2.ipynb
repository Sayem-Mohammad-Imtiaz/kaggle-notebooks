{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Face-Mask Detection via Detectron2\n---\n> I'm using Facebook AI Research's Detectron 2 for this task","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Installing Dependencies\n---","execution_count":null},{"metadata":{"id":"9_FzH13EjseR","outputId":"bd19b19f-18d2-4435-930e-d22c582417a9","trusted":true},"cell_type":"code","source":"# install dependencies: (use cu101 because colab has CUDA 10.1)\n!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n!pip install cython pyyaml==5.1\n!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version","execution_count":null,"outputs":[]},{"metadata":{"id":"b-i4hmGYk1dL","outputId":"17e724da-f986-417a-d445-8825206bbc0a","trusted":true},"cell_type":"code","source":"# install detectron2:\n!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing required libraries\n---","execution_count":null},{"metadata":{"id":"gOEMqgbdJt7m","outputId":"9457b1cd-daf5-46f2-de86-ad6f293889e1","trusted":true},"cell_type":"code","source":"import torch\ntorch.cuda.get_device_name()","execution_count":null,"outputs":[]},{"metadata":{"id":"a7qTg-YByo8r","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch.nn as nn\nfrom PIL import Image\nimport numpy as np\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom tqdm.autonotebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport random\nimport cv2\nimport random\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"id":"KufN3Rhcd72q","trusted":true},"cell_type":"code","source":"# Some basic setup\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom detectron2.structures import BoxMode\nfrom detectron2.data import DatasetCatalog\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setting up directories and reading the *train.csv* file and doing some EDA\n---","execution_count":null},{"metadata":{"id":"VV0VnDG0YTWK","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/face-mask-detection-dataset/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"H6cm6hn0mLsZ","outputId":"d00970cf-b54c-4058-cc5e-c84d286435e0","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.classname.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('classname').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df.name.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('name').count()","execution_count":null,"outputs":[]},{"metadata":{"id":"vhKVoqB9nxzP","trusted":true},"cell_type":"code","source":"img_folder_dir = '../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'","execution_count":null,"outputs":[]},{"metadata":{"id":"A7nK5WKwsBma","trusted":true},"cell_type":"code","source":"categories = {j:i for i, j in enumerate(df.classname.unique())}","execution_count":null,"outputs":[]},{"metadata":{"id":"M3ooaYKGtWPo","outputId":"0eb17042-f42c-4836-8b82-dad80a442865","trusted":true},"cell_type":"code","source":"categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating DataLoader functions for Detectron2\n---\n> The y1, x2 columns in the dataset are interchanged in the csv file so I have accounted for that in my functions","execution_count":null},{"metadata":{"id":"aF0iVID8tmXZ","trusted":true},"cell_type":"code","source":"def get_train_dataset():\n  train_data = []\n  for img in df.name.unique():\n    record = {}\n    image_id = img[:-4] if '.jpeg' not in img else img[:-5]\n    height, width, _ = np.array(Image.open(f'{img_folder_dir}/{img}')).shape\n    record['file_name'] = f'{img_folder_dir}/{img}'\n    record[\"image_id\"] = image_id\n    record[\"height\"] = height\n    record[\"width\"] = width\n\n    objs = []\n    d = df[df['name'] == img]\n    for _, row in d.iterrows():\n\n      xmin = min(row.x1, row.y1)\n      ymin = min(row.x2, row.y2)\n      xmax = max(row.x1, row.y1)\n      ymax = max(row.x2, row.y2)\n\n      poly = [\n          (xmin, ymin), (xmax, ymin), \n          (xmax, ymax), (xmin, ymax)\n      ]\n      poly = [p for x in poly for p in x]\n\n      obj = {\n        \"bbox\": [xmin, ymin, xmax, ymax],\n        \"bbox_mode\": BoxMode.XYXY_ABS,\n        \"segmentation\": [poly],\n        \"category_id\": categories[row.classname],\n        \"iscrowd\": 0\n      }\n      objs.append(obj)\n    record[\"annotations\"] = objs\n    train_data.append(record)\n  return train_data","execution_count":null,"outputs":[]},{"metadata":{"id":"XK8taM3rTzJw","trusted":true},"cell_type":"code","source":"def get_test_dataset():\n  d = pd.read_csv('../input/face-mask-detection-dataset/submission.csv')\n  test_data = []\n  for img in d.name.unique():\n    record = {}\n    image_id = img[:-4] if '.jpeg' not in img else img[:-5]\n    if ('jpe' in img and 'jpeg' not in img):\n      img = (img + 'g') \n    height, width, _ = np.array(Image.open(f'{img_folder_dir}/{img}')).shape\n    record['file_name'] = f'{img_folder_dir}/{img}'\n    record[\"image_id\"] = image_id\n    record[\"height\"] = height\n    record[\"width\"] = width\n    record[\"annotations\"] = None\n    test_data.append(record)\n  return test_data","execution_count":null,"outputs":[]},{"metadata":{"id":"sfVlXl8RyMlR","trusted":true},"cell_type":"code","source":"#dataset_dicts = get_train_dataset()","execution_count":null,"outputs":[]},{"metadata":{"id":"7izHI_Ux80KP","trusted":true},"cell_type":"code","source":"d=\"train\"\nDatasetCatalog.register(\"Face_Mask_Detection_TrainingSet\", lambda d=d: get_train_dataset())\nMetadataCatalog.get(\"Face_Mask_Detection_TrainingSet\").set(thing_classes=[class_ for class_ in df.classname.unique()])\nface_metadata = MetadataCatalog.get(\"Face_Mask_Detection_TrainingSet\")","execution_count":null,"outputs":[]},{"metadata":{"id":"R6MU5DJtUXvW","trusted":true},"cell_type":"code","source":"d=\"test\"\nDatasetCatalog.register(\"Face_Mask_Detection_TestSet\", lambda d=d: get_test_dataset())\nMetadataCatalog.get(\"Face_Mask_Detection_TestSet\").set(thing_classes=[class_ for class_ in df.classname.unique()])\nface_metadata = MetadataCatalog.get(\"Face_Mask_Detection_TestSet\")","execution_count":null,"outputs":[]},{"metadata":{"id":"MbosDjWhTGEn","outputId":"a46097bf-9524-408e-bf99-3ba4b0c67427","trusted":true,"collapsed":true},"cell_type":"code","source":"# To check if the dataloder function works properly\n#for d in random.sample(dataset_dicts, 1):\n#    img = cv2.imread(d[\"file_name\"])\n#    visualizer = Visualizer(img[:, :, ::-1], metadata=face_metadata, scale = .5)\n#    vis = visualizer.draw_dataset_dict(d)\n#    img = list(v.get_image()[:, :, ::-1])\n#    plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuration for training and training step\n---\n> Since there are lots of sparse classes in the datasetI have decided not to split into train and val data.\n\n> Instead all the training data was used for training.","execution_count":null},{"metadata":{"id":"XVRMzYQxgTNp","outputId":"9c397647-9ae7-42d5-a3f0-3e0fa9c6e6e4","trusted":true},"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"Face_Mask_Detection_TrainingSet\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.0002  # pick a good LR\ncfg.SOLVER.MAX_ITER = 4800\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 20\ncfg.OUTPUT_DIR = f'../output/kaggle/working'\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performing Inference on the Test set\n---","execution_count":null},{"metadata":{"id":"gc3ngBqDSQYd","trusted":true,"collapsed":true},"cell_type":"code","source":"cfg.MODEL.WEIGHTS = f'../output/kaggle/working/model_final.pth'\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\ncfg.DATASETS.TEST = (\"Face_Mask_Detection_TestSet\", )\npredictor = DefaultPredictor(cfg)","execution_count":null,"outputs":[]},{"metadata":{"id":"HCZ-Qc59VIyv","trusted":true},"cell_type":"code","source":"test_dataset_dicts = get_test_dataset()","execution_count":null,"outputs":[]},{"metadata":{"id":"gURglkiVUtHd","outputId":"d1dcace7-5da5-42c9-93e3-c09c28d73517","trusted":true},"cell_type":"code","source":"# Randomly selecting an image from the test set and drawing the predicted bounding boxes and labels on it\nfrom detectron2.utils.visualizer import ColorMode\nfor d in random.sample(test_dataset_dicts, 1):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=face_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    img = list(v.get_image()[:, :, ::-1])\n    plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"id":"YX9E2-yASWg8","trusted":true},"cell_type":"code","source":"categories = {j:i for i,j in categories.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans = {'name':[], 'x1':[], 'x2':[], 'y1':[],'y2':[],'classname':[]}\nfor record in tqdm(test_dataset_dicts, total=len(test_dataset_dicts)):\n  im = cv2.imread(record[\"file_name\"])\n  #cv2_imshow(im)\n  outputs = predictor(im)\n  outputs = outputs['instances'].to('cpu')\n  pred_boxes = outputs.pred_boxes\n  pred_labels = outputs.pred_classes\n  for box, label in zip(pred_boxes, pred_labels):\n    bbox = np.array(box)\n    a = record['file_name'][-3:] if 'jpeg' not in record['file_name'] else 'jpeg'\n    ans['name'].append(f'{record[\"image_id\"]}.{a}')\n    ans['x1'].append(bbox[0])\n    ans['x2'].append(bbox[2])\n    ans['y1'].append(bbox[1])\n    ans['y2'].append(bbox[3])\n    #print(label)\n    ans['classname'].append(categories[int(label)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans = pd.DataFrame(ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans.to_csv(f'../output/kaggle/working/submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}