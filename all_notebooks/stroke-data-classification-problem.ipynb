{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom matplotlib import pyplot as plt\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler \nfrom imblearn.pipeline import Pipeline\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stroke_data = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"stroke_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Minimum age as 0.08. Should be further checked during preprocessing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"stroke_data.set_index('id', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bi-variate analysis\nplt.style.use('seaborn-dark')\nsns.pairplot(stroke_data,hue='stroke',palette='Dark2');\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evidence of interrelationship among age, avg_glucose level and bmi. At a given bmi, higher the age, more cases of strokes. At higher age, there are more cases of strokes in people with higher avg glucose level. "},{"metadata":{"trusted":true},"cell_type":"code","source":"Stroke_plot = stroke_data['stroke'].value_counts().reset_index()\nStroke_plot.columns = ['stroke','count']\n\npx.pie(Stroke_plot,values='count',names='stroke',template='plotly',title='Stroke')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.set_context(context='notebook',font_scale=1.2)\nsns.heatmap(stroke_data[['age','avg_glucose_level','bmi']].corr(method='pearson'),cmap='Blues',annot=True);\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the null values\nstroke_data[stroke_data.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping null values\nstroke_data.dropna(inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking minimum values of age\nstroke_data[stroke_data.age < 1]\n#All ages less than 1 belong to children, which seems correct.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#separating the target column\ny = stroke_data.iloc[:,-1]\nx = stroke_data.iloc[:,:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#applying one hot encoding to convert categorical data into numerical data\ncat_data = x.select_dtypes(include=['object']).copy()\ncolumns = cat_data.columns\nx = pd.get_dummies(x, columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Balancing the classes of the data by first applying oversampling and then undersampling method \nover = SMOTE(sampling_strategy=0.1)\nunder = RandomUnderSampler(sampling_strategy=0.5)\n\nsteps = [('o', over), ('u', under)]\npipeline = Pipeline(steps=steps)\n\nx_ros, y_ros = pipeline.fit_resample(x, y)\n#The resultant classes are now in 2:1 ratio, from earlier 95:5 ratio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_ros.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data split and normalization"},{"metadata":{},"cell_type":"markdown","source":"We will be training 3 models on the data set obtained after balancing the classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting the dataset \nx_ros_train, x_ros_test, y_ros_train, y_ros_test = train_test_split(x_ros, y_ros, test_size = 0.6, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizing the data\nscaler = StandardScaler()\nx_ros_train_scaled = scaler.fit_transform(x_ros_train) #dataset 2\nx_ros_test_scaled = scaler.fit_transform(x_ros_test)   #dataset 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fiting the models and comparing the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nLR = LogisticRegression().fit(x_ros_train_scaled, y_ros_train)\n\npredict_train_LR = LR.predict(x_ros_train_scaled)\npredict_test_LR = LR.predict(x_ros_test_scaled)\n\n# accuracy score\nLR_train_score = LR.score(x_ros_train_scaled,y_ros_train)\nLR_test_score = LR.score(x_ros_test_scaled,y_ros_test)\n\n# f1-score\nLR_f1_score = metrics.f1_score(y_ros_test, predict_test_LR)\nLR_recall = metrics.recall_score(y_ros_test, predict_test_LR)\n\n\nprint('Accuracy on Train set',LR_train_score)\nprint('Accuracy on Test set',LR_test_score)\nprint('F1-score on Test set:',LR_f1_score)\nprint('\\n')\nprint(metrics.classification_report(y_ros_test, predict_test_LR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVM = svm.SVC().fit(x_ros_train_scaled, y_ros_train)\n\npredict_train_SVM = SVM.predict(x_ros_train_scaled)\npredict_test_SVM = SVM.predict(x_ros_test_scaled)\n\n# accuracy score\nSVM_train_score = SVM.score(x_ros_train_scaled,y_ros_train)\nSVM_test_score = SVM.score(x_ros_test_scaled,y_ros_test)\n\n# f1-score\nSVM_f1_score = metrics.f1_score(y_ros_test, predict_test_SVM)\nSVM_recall = metrics.recall_score(y_ros_test, predict_test_SVM)\n\n\nprint('Accuracy on Train set',SVM_train_score)\nprint('Accuracy on Test set',SVM_test_score)\nprint('F1-score on Test set:',SVM_f1_score)\nprint('\\n')\nprint(metrics.classification_report(y_ros_test, predict_test_SVM))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF = RandomForestClassifier().fit(x_ros_train_scaled, y_ros_train)\n\npredict_train_RF = RF.predict(x_ros_train_scaled)\npredict_test_RF = RF.predict(x_ros_test_scaled)\n\n# accuracy score\nRF_train_score = RF.score(x_ros_train_scaled,y_ros_train)\nRF_test_score = RF.score(x_ros_test_scaled,y_ros_test)\n\n# f1-score\nRF_f1_score = metrics.f1_score(y_ros_test, predict_test_RF)\nRF_recall = metrics.recall_score(y_ros_test, predict_test_RF)\n\n\nprint(RF.get_params())\nprint('Accuracy on Train set',RF_train_score)\nprint('Accuracy on Test set',RF_test_score)\nprint('F1-score on Test set:',RF_f1_score)\nprint('\\n')\nprint(metrics.classification_report(y_ros_test, predict_test_RF))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model tuning"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\n# to get best parameters\n\n# fine Tune the model using RandomizedSearchCV\n\n#\"\"\"\nparameters= {'n_estimators':[8, 32, 64, 100, 200],\n            'max_depth':[10, 12],\n            'max_features':[5, 8, 10],\n            'min_samples_split' : [2,4],\n            'min_samples_leaf' : [1,2]}\n\n\nrf = RandomForestClassifier()\n\nrf_model_tune = RandomizedSearchCV(rf, param_distributions = parameters, cv=3,n_iter = 20, verbose=2, random_state=42)\n\nrf_model_tune.fit(x_ros_train,y_ros_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nRF_model = RandomForestClassifier(n_estimators= 200,min_samples_split= 2,min_samples_leaf=1,max_features= 5,max_depth=10,bootstrap= False)\n\n# fit the model\nRF_model.fit(x_ros_train,y_ros_train)\n\n# model score\npredict_train_RF = RF_model.predict(x_ros_train)\npredict_test_RF = RF_model.predict(x_ros_test)\n\n# accuracy score\nRF_train_score = RF_model.score(x_ros_train,y_ros_train)\nRF_test_score = RF_model.score(x_ros_test,y_ros_test)\n\n# f1-score\nRF_f1_score = metrics.f1_score(y_ros_test,predict_test_RF)\nRF_recall = metrics.recall_score(y_ros_test,predict_test_RF)\nprint('Accuracy on Train set',RF_train_score)\nprint('Accuracy on Test set',RF_test_score)\nprint('F1-score on Test set:',RF_f1_score)\nprint(metrics.classification_report(y_ros_test,predict_test_RF))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF = RandomForestRegressor()\nRF.fit(x_ros_train_scaled, y_ros_train)\nimportance = RF.feature_importances_\nplt.barh(x_ros.columns, importance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_compare = pd.DataFrame({\n\n\n'Models':['LogisticRegression','Support Vector Machine','RandomForestClassifier'],\n'f1_score':[LR_f1_score, SVM_f1_score, RF_f1_score],\n'recall':[LR_recall, SVM_recall, RF_recall],\n'Accuracy on train set':[LR_train_score,SVM_train_score,RF_train_score],\n'Accuracy on test set':[LR_test_score, SVM_test_score,RF_test_score]\n\n})\n\nmodel_compare = model_compare.sort_values('recall',ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_compare.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}