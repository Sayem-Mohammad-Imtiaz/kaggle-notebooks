{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tf-pose","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T13:33:11.488872Z","iopub.execute_input":"2021-05-29T13:33:11.489312Z","iopub.status.idle":"2021-05-29T13:34:22.131978Z","shell.execute_reply.started":"2021-05-29T13:33:11.489275Z","shell.execute_reply":"2021-05-29T13:34:22.131036Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport re\nimport time\nimport logging\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport cv2\n\nfrom tf_pose import common\nfrom tf_pose.estimator import TfPoseEstimator\nfrom tf_pose.networks import get_graph_path, model_wh\n\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.animation as animation\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:47:03.074665Z","iopub.execute_input":"2021-05-29T13:47:03.075106Z","iopub.status.idle":"2021-05-29T13:47:03.083591Z","shell.execute_reply.started":"2021-05-29T13:47:03.075071Z","shell.execute_reply":"2021-05-29T13:47:03.080947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optional \nlogger = logging.getLogger('TfPoseEstimator-Video')\nlogger.setLevel(logging.DEBUG)\nch = logging.StreamHandler()\nch.setLevel(logging.DEBUG)\nformatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\nch.setFormatter(formatter)\nlogger.addHandler(ch)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:36:16.62297Z","iopub.execute_input":"2021-05-29T13:36:16.623431Z","iopub.status.idle":"2021-05-29T13:36:16.636026Z","shell.execute_reply.started":"2021-05-29T13:36:16.62339Z","shell.execute_reply":"2021-05-29T13:36:16.635128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model='mobilenet_thin'\n#show_process = True # for debug purpose, if enabled, speed for inference is dropped.\n#logger.debug('initialization %s : %s' % (model, get_graph_path(model)))\n\nresolution='864x736'\nw, h = model_wh(resolution)\ne = TfPoseEstimator(get_graph_path(model), target_size=(w, h))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-29T14:18:30.408475Z","iopub.execute_input":"2021-05-29T14:18:30.408919Z","iopub.status.idle":"2021-05-29T14:18:42.285945Z","shell.execute_reply.started":"2021-05-29T14:18:30.408875Z","shell.execute_reply":"2021-05-29T14:18:42.284294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_x_features_array_and_df(keypoints):\n        \n    feat_dict = {}\n    \n    for i in range (0, 18):\n        feat_dict[\"bp_\" + str(i) + '_x'] = None\n        feat_dict[\"bp_\" + str(i) + '_y'] = None\n\n    for i in range (0, len(keypoints)-1):\n        bps = int(re.findall(r'\\d+', keypoints[i].split(\"(\")[0])[-1])\n        coordinates = keypoints[i].split(\"(\")[1].split(\")\")[0].split(\",\")\n        \n        #print(i, bps)\n        feat_dict[\"bp_\" + str(bps) + '_x'] = float(coordinates[0])\n        feat_dict[\"bp_\" + str(bps) + '_y'] = float(coordinates[1])\n    \n#     for k, v in feat_dict.items():\n#         print(k, v)\n\n    df = pd.DataFrame(feat_dict.items()).set_index(0).T      \n    return list(feat_dict.values()), df","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:18:42.290108Z","iopub.execute_input":"2021-05-29T14:18:42.290523Z","iopub.status.idle":"2021-05-29T14:18:42.300804Z","shell.execute_reply.started":"2021-05-29T14:18:42.290488Z","shell.execute_reply":"2021-05-29T14:18:42.299774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_path = \"../input/human-keypoints-tracking-dataset/squat_test1.avi\"\nshowBG = True\nfps_time = 0\n\ncap = cv2.VideoCapture(video_path)\nif cap.isOpened() is False:\n    print(\"Error opening video stream or file\")","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:18:42.302605Z","iopub.execute_input":"2021-05-29T14:18:42.30331Z","iopub.status.idle":"2021-05-29T14:18:42.323886Z","shell.execute_reply.started":"2021-05-29T14:18:42.303271Z","shell.execute_reply":"2021-05-29T14:18:42.322803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fcount = 0    \nframes = []\nwhile True:\n    ret_val, image = cap.read()\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    fcount += 1\n    \n    #print(\"frame no : \", fcount)\n    \n    if not ret_val:\n        break\n\n    humans = e.inference(image,\n                         resize_to_default=(w > 0 and h > 0),\n                         upsample_size=4.0)\n \n    if len(humans) > 0:    \n        keypoints = str(str(str(humans[0]).split('BodyPart:')[1:]).split('-')).split(' score=')\n\n        arr, fdf = get_x_features_array_and_df(keypoints)\n        #print(arr)\n\n    if not showBG:\n        image = np.zeros(image.shape)\n    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n\n    cv2.putText(image, \"FPS: %f\" % (1.0 / (time.time() - fps_time)), (10, 10),\n                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n    frames.append(image)\n    #frames.append([plt.imshow(image, animated=True)])\n    #plt.imshow(image)\n    fps_time = time.time()\n#     if cv2.waitKey(1) & 0xFF == ord('q'):\n#         break\n    if len(frames) > 65:\n        break\n\nprint(\"{} frames processed\".format(len(frames)))\ncap.release()\n#cv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:21:39.388991Z","iopub.execute_input":"2021-05-29T14:21:39.389699Z","iopub.status.idle":"2021-05-29T14:24:26.753924Z","shell.execute_reply.started":"2021-05-29T14:21:39.389641Z","shell.execute_reply":"2021-05-29T14:24:26.752978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (20,50)\nrows = 16\nfor num, img in enumerate(frames[:-2]):\n    #img = PIL.Image.open(x)\n    plt.subplot(rows,4,num+1)\n    #plt.title(x.split('.')[0])\n    plt.axis('off')\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T14:27:33.573164Z","iopub.execute_input":"2021-05-29T14:27:33.573623Z","iopub.status.idle":"2021-05-29T14:27:43.635308Z","shell.execute_reply.started":"2021-05-29T14:27:33.573577Z","shell.execute_reply":"2021-05-29T14:27:43.633426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}