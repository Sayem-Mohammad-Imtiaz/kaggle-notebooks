{"cells":[{"metadata":{},"cell_type":"markdown","source":"### This notebook contains only the model building, comaprision of models using sklearn and pycaret modules.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Link for HR attrition analysis part one EDA: https://www.kaggle.com/winterbreeze/ibm-hr-attrition-analysis-part-1-eda","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\nimport warnings \nwarnings.filterwarnings('ignore')\npd.set_option('display.max_rows',None)\npd.set_option('display.max_column',None)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hrattritioneda/Attrition-EDA.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract the independent variable X and dependent variable Y","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Attrition',axis=1)\ny=df['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### PCA is a method used to reduce number of variables in the data by extracting important one from a large pool. It reduces the dimension of data with the aim of retaining as much information as possible.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cov_matirx=np.cov(X.T)\neig_vals,eig_vectors=np.linalg.eig(cov_matirx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eig_vals  # The values are not in order , we need to sort the values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tot=sum(eig_vals)\nvar_exp=[(i/tot)*100 for i in sorted(eig_vals,reverse=True)]\ncum_var_exp=np.cumsum(var_exp)\nprint('Cumulative variance Explained:',cum_var_exp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,4))\nplt.bar(range(X.shape[1]),var_exp,alpha=0.5,align='center',label='Individual explained variance')\nplt.step(range(X.shape[1]),cum_var_exp,where='mid',label='cummulative explained variance')\nplt.ylabel(\"explained variance ratio\")\nplt.xlabel(\"principal components\")\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eigen_pairs=[(np.abs(eig_vals[i]),eig_vectors[:,i]) for i in range(len(eig_vals))]\n\neig_val_sort=[eigen_pairs[index][0] for index in range(len(eig_vals))]\neig_vec_sort=[eigen_pairs[index][1] for index in range(len(eig_vals))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eig_val_sort.sort(reverse=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"P_reduce=np.array(eig_vec_sort[0:37]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"projected_data=np.dot(X,P_reduce)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"projected_data_df=pd.DataFrame(projected_data)\nprojected_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data set to train and test ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying PCA function on training \n# and testing set of X component \nfrom sklearn.decomposition import PCA\n\n\npca = PCA(n_components = 37)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)                          # LOGISITC REGRESSION WITH PCA\n\nfrom sklearn.linear_model import LogisticRegression\nalgo= LogisticRegression(random_state = 3)\n\nalgo.fit(X_train_pca , y_train)\ny_train_pred = algo.predict(X_train_pca)\ny_train_prob = algo.predict_proba(X_train_pca)\n\n#overall acc of train model\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score,roc_curve\nfrom sklearn.model_selection import cross_val_score\n\nprint('Confusion matrix - Train :', '\\n',confusion_matrix(y_train , y_train_pred))\nprint('Overall Accuracy - Train :',accuracy_score(y_train , y_train_pred))\nprint('AUC - Train:', roc_auc_score(y_train , y_train_prob[:,1]))\n\ny_test_pred = algo.predict(X_test_pca)\ny_test_prob = algo.predict_proba(X_test_pca)[:,1]\nprint('*'*50)\nprint('Confusion matrix - Test :', '\\n',confusion_matrix(y_test , y_test_pred))\nprint('Overall Accuracy - Test :',accuracy_score(y_test , y_test_pred))\nprint('AUC - Test:', roc_auc_score(y_test , y_test_prob))\n\nprint('*'*50)\nscores=cross_val_score(algo,X,y,cv=3,scoring='roc_auc')\nprint('Cross Val Scores')\nprint(scores)\nprint('Bias Error    :',100-scores.mean()*100)\nprint('Variance Error:',scores.std()*100)\n\n\n\nfpr , tpr , threshold = roc_curve(y_test , y_test_prob)\nplt.plot(fpr , tpr)\nplt.plot(fpr , fpr , 'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Building Machine Learning Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , accuracy_score , roc_auc_score , roc_curve\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score,KFold\n\n# Importing all the predictive models.\n\n\nlr = LogisticRegression(fit_intercept=True)\nbagged_lr = BaggingClassifier(base_estimator = lr, n_estimators = 25, random_state = 3)\ngnb= GaussianNB()\nbnb= BernoulliNB()\nmnb= MultinomialNB()\nknn = KNeighborsClassifier()\ndtc = DecisionTreeClassifier(ccp_alpha=0.01) # to increase pruning and avoid overfitting\nrfc= RandomForestClassifier()\nsvm= SVC(probability=True)\n\n# Declaring various classification models for the predictive model building.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a dummy classifier to know the base models predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=DummyClassifier(strategy='stratified')\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Base Score on Train Data Set: ',clf.score(X_train,y_train)) \nprint('Base Score on Test Data Set : ',clf.score(X_test,y_test)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* now we know that our Supervised Learning Models have to perform better than the above mentioned score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_eval(algo , X_train , y_train , X_test , y_test):\n\n    algo.fit(X_train , y_train)\n    y_pred = algo.predict(X_train)\n\n    y_train_pred = algo.predict(X_train)               # Finding the positives and negatives \n    y_train_prob = algo.predict_proba(X_train)[:,1]    #we are intersted only in the second column\n\n\n    #overall acc of train model\n    print('Confusion matrix - Train :', '\\n',confusion_matrix(y_train , y_train_pred))\n    print('Overall Accuracy - Train :',accuracy_score(y_train , y_train_pred))\n    print('AUC - Train:', roc_auc_score(y_train , y_train_prob))\n\n    y_test_pred = algo.predict(X_test)\n    y_test_prob = algo.predict_proba(X_test)[:,1]\n    print('*'*50)\n    print('Confusion matrix - Test :', '\\n',confusion_matrix(y_test , y_test_pred))\n    print('Overall Accuracy - Test :',accuracy_score(y_test , y_test_pred))\n    print('AUC - Test:', roc_auc_score(y_test , y_test_prob))\n    \n    print('*'*50)\n    scores=cross_val_score(algo,X,y,cv=3,scoring='roc_auc')\n    print('Cross Val Scores')\n    print(scores)\n    print('Bias Error    :',100-scores.mean()*100)\n    print('Variance Error:',scores.std()*100)\n    \n    print('\\n')\n    print('Classification Report:\\n', classification_report(y_test, y_test_pred))\n    \n    \n\n    fpr , tpr , threshold = roc_curve(y_test , y_test_prob)\n    plt.plot(fpr , tpr)\n    plt.plot(fpr , fpr , 'r-')\n    plt.xlabel('FPR')\n    plt.ylabel('TPR')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Logistic Regression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(bagged_lr , X_train , y_train , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score, cross_val_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bagged_lr=BaggingClassifier(base_estimator=lr,n_estimators=15,random_state=3)\nadaboost_lr=AdaBoostClassifier(base_estimator=lr,n_estimators=50,random_state=3)   #default decision tree\ngb=GradientBoostingClassifier(n_estimators=55,random_state=3)                   # Cannot have base_estimator\n\nmodels=[]\nmodels.append(('Bagged_Logisitc_Regression',bagged_lr))\nmodels.append(('Ada_Boost_Logistic_Regression',adaboost_lr))\nmodels.append(('Gradient_Boost',gb))\n\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X_train,y_train,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(knn , X_train , y_train , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bagged_knn=BaggingClassifier(base_estimator=knn,n_estimators=15,random_state=3) # default DT, cannot use RandomForest\nadaboost=AdaBoostClassifier(n_estimators=50,random_state=3)                    # default decision tree, cannot use KNN\n\n\nmodels=[]\nmodels.append(('Bagged_KNN',bagged_knn))\nmodels.append(('Ada_Boost',adaboost))\n\n\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X_train,y_train,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(gnb , X_train , y_train , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb= GaussianNB()\nbnb= BernoulliNB()\n\ngaussian_bag=BaggingClassifier(base_estimator=gnb,n_estimators=10,random_state=3)\ngaussian_adaboost=AdaBoostClassifier(base_estimator=gnb,n_estimators=30,random_state=3)\nbernoulli_bag=BaggingClassifier(base_estimator=bnb,n_estimators=10,random_state=3)\nbernoulli_adaboost=AdaBoostClassifier(base_estimator=bnb,n_estimators=30,random_state=3)\n\n\n\nmodels=[]\nmodels.append(('Naive_Bayes_Gaussian',gnb))\nmodels.append(('Naive_Bayes_Bernoulli',bnb))\nmodels.append(('Gaussian_bagged',gaussian_bag))\nmodels.append(('Bernoulli_bagged',bernoulli_bag))\nmodels.append(('Adaboost_Gaussian',gaussian_adaboost))\nmodels.append(('Adaboost_Bernoulli',bernoulli_adaboost))\n\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X_train,y_train,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(dtc , X_train , y_train , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bagged_dtc=BaggingClassifier(n_estimators=15,random_state=3)       # default decision tree, cannot use RandomF \nadaboost_dtc=AdaBoostClassifier(n_estimators=50,random_state=3)       # default decision tree, cannot use KNN\n\n\nmodels=[]\nmodels.append(('Bagged_DTC',bagged_dtc))\nmodels.append(('Adaboost_DTC',adaboost_dtc))\n\n\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X_train,y_train,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(rfc , X_train , y_train , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bagged_rfc=BaggingClassifier(base_estimator=rfc,n_estimators=15,random_state=3)       # default decision tree, cannot use RandomF \nadaboost_rfc=AdaBoostClassifier(base_estimator=rfc,n_estimators=50,random_state=3)   # default decision tree, cannot use KNN\n             \n\nmodels=[]\nmodels.append(('Bagged_RFC',bagged_rfc))\nmodels.append(('Adaboost_RFC',adaboost_rfc))\n\n\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X_train,y_train,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Randomised Search Cross Validation to Search for the best parameters ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrfc = RandomForestClassifier(random_state=3)\nparams = { 'n_estimators' : sp_randint(50 , 200) , \n           'max_features' : sp_randint(1,26) ,\n           'max_depth' : sp_randint(2,10) , \n           'min_samples_split' : sp_randint(2,10) ,\n           'min_samples_leaf' : sp_randint(1,10) ,\n           'criterion' : ['gini' , 'entropy']\n    \n}\n\nrsearch_rfc = RandomizedSearchCV(rfc , param_distributions= params , n_iter= 200 , cv = 3 , scoring='roc_auc' , random_state= 3 , return_train_score=True , n_jobs=-1)\n\nrsearch_rfc.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsearch_rfc.best_params_    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc= RandomForestClassifier(**rsearch_rfc.best_params_,random_state=3)\n\nrfc.fit(X_train,y_train)\n\ny_train_pred=rfc.predict(X_train)                 # Finding the Positives and Negatives \ny_train_prob=rfc.predict_proba(X_train)[:,1]      # We are interested only in the 2nd column\n\n\n\nprint('Confusion Matrix - Train:','\\n' ,confusion_matrix(y_train,y_train_pred))\nprint('Overall Accuracy - Train:', accuracy_score(y_train,y_train_pred))             #Train\nprint('AUC- Train',roc_auc_score(y_train,y_train_prob))\n\ny_test_pred=rfc.predict(X_test)\ny_test_prob=rfc.predict_proba(X_test)[:,1]\n\n\nprint('\\n')\nprint('Confusion Matrix - Test:','\\n' ,confusion_matrix(y_test,y_test_pred))\nprint('Overall Accuracy - Test:', accuracy_score(y_test,y_test_pred))               #Test\nprint('AUC- Test',roc_auc_score(y_test,y_test_prob))\n\nprint('\\n')\nfpr,tpr,thresholds= roc_curve(y_test,y_test_prob)\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr,'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_sorted_by_importance=rfc.feature_importances_.argsort()\nfeat_imp=pd.DataFrame({\n    'cols':X.columns[col_sorted_by_importance],\n    'imps':rfc.feature_importances_[col_sorted_by_importance]\n})\n\nfeat_imp.sort_values(by='imps',ascending=False)[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Support Vector Machines ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(svm, X_train , y_train , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC(probability=True)\n\nkernel=['linear','poly','rbf','sigmoid']\n\nfor i in kernel:\n    svm=SVC(kernel=i,C=1.0)\n    svm.fit(X_train,y_train)\n    print('For kernel i,',i)\n    print('accuracy is' ,svm.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV \nsvm=SVC(probability=True,class_weight='balanced',random_state=3)\nparam_grid = {'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'coef0':[0.001,10,0.5],\n              'kernel': ['rbf','poly', 'sigmoid']}  \n  \ngrid_search_svm = GridSearchCV(svm, param_grid, refit = True, verbose = 3) \n  \n# fitting the model for grid search \ngrid_search_svm.fit(X_train,y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print best parameter after tuning \nprint(grid_search_svm.best_params_) \n  \n# print how our model looks after hyper-parameter tuning \nprint(grid_search_svm.best_estimator_) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm= SVC(probability=True,**grid_search_svm.best_params_,random_state=3)\n\nsvm.fit(X_train,y_train)\n\ny_train_pred=svm.predict(X_train)                 # Finding the Positives and Negatives \ny_train_prob=svm.predict_proba(X_train)[:,1]      # We are interested only in the 2nd column\n\n\n\nprint('Confusion Matrix - Train:','\\n' ,confusion_matrix(y_train,y_train_pred))\nprint('Overall Accuracy - Train:', accuracy_score(y_train,y_train_pred))             #Train\nprint('AUC- Train',roc_auc_score(y_train,y_train_prob))\n\ny_test_pred=svm.predict(X_test)\ny_test_prob=svm.predict_proba(X_test)[:,1]\n\n\nprint('\\n')\nprint('Confusion Matrix - Test:','\\n' ,confusion_matrix(y_test,y_test_pred))\nprint('Overall Accuracy - Test:', accuracy_score(y_test,y_test_pred))               #Test\nprint('AUC- Test',roc_auc_score(y_test,y_test_prob))\n\nprint('\\n')\nfpr,tpr,thresholds= roc_curve(y_test,y_test_prob)\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr,'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bagged_svm=BaggingClassifier(base_estimator=svm,n_estimators=15,random_state=3)       # default decision tree, cannot use RandomF \nadaboost_svm=AdaBoostClassifier(base_estimator=svm,n_estimators=15,random_state=3)   # default decision tree, cannot use KNN\ngb_lr=GradientBoostingClassifier(n_estimators=55,random_state=3)                # Does not have base_estimator, uses DT as stump\n\nmodels=[]\nmodels.append(('Bagged_SVM',bagged_svm))\nmodels.append(('Adaboost_SVM',adaboost_svm))\nmodels.append(('Gradient_Boost',gb_lr))\n\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X_train,y_train,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,fontsize=8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Over Sampling Minority Class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xytrain=pd.concat([X_train,y_train],axis=1)\n\nprint('Before Oversampling:','\\n',Xytrain['Attrition'].value_counts())\n\nXytrain0=Xytrain[Xytrain['Attrition']==0]\nXytrain1=Xytrain[Xytrain['Attrition']==1]\n\nlen0=len(Xytrain0)\nlen1=len(Xytrain1)\n\nXytrain1_os=Xytrain1.sample(len0,replace=True,random_state=3) # To duplicate the values when over sampling [replace=True]\nXytrain_os=pd.concat([Xytrain0,Xytrain1_os],axis=0)           # Axis 0 because it is appending and not merging \n\nprint('\\n')\nprint('After Oversampling:','\\n',Xytrain_os['Attrition'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_os=Xytrain_os.drop('Attrition',axis=1)\ny_os=Xytrain_os['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_os, X_test_os, y_train_os, y_test_os = train_test_split(X_os, y_os, test_size=0.3, random_state=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\nX_train_os_scaled = ss.fit_transform(X_train_os)\nX_test_os_scaled = ss.transform(X_test_os)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"svm_os= SVC(probability=True)\nmodel_eval(svm_os, X_train_os_scaled , y_train_os , X_test_os_scaled , y_test_os)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SMOTE (Synthetic Minority Oversampling TEchnique)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE,SVMSMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30,random_state = 7)\n\nsmote=SVMSMOTE(sampling_strategy='minority',random_state=3)\nX_train_sm,y_train_sm=smote.fit_sample(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#smote = SMOTE(sampling_strategy = 'minority', random_state = 3)\n#X_train_sm, y_train_sm = smote.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm= SVC(probability=True)\n\nsvm.fit(X_train_sm,y_train_sm)\n\ny_train_pred=svm.predict(X_train_sm)                 # Finding the Positives and Negatives \ny_train_prob=svm.predict_proba(X_train_sm)[:,1]      # We are interested only in the 2nd column\n\n\n\nprint('Confusion Matrix - Train:','\\n' ,confusion_matrix(y_train_sm,y_train_pred))\nprint('Overall Accuracy - Train:', accuracy_score(y_train_sm,y_train_pred))             #Train\nprint('AUC- Train',roc_auc_score(y_train_sm,y_train_prob))\n\ny_test_pred=svm.predict(X_test)\ny_test_prob=svm.predict_proba(X_test)[:,1]\n\n\nprint('\\n')\nprint('Confusion Matrix - Test:','\\n' ,confusion_matrix(y_test,y_test_pred))\nprint('Overall Accuracy - Test:', accuracy_score(y_test,y_test_pred))               #Test\nprint('AUC- Test',roc_auc_score(y_test,y_test_prob))\n\nprint('\\n')\nfpr,tpr,thresholds= roc_curve(y_test,y_test_prob)\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr,'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *ADASUN (Adaptive Synthetic Sampling)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import ADASYN \nadasyn = ADASYN(sampling_strategy='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_adasyn,y_train_adasyn=adasyn.fit_sample(X_train,y_train)\ny_train_adasyn.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval(svm, X_train_adasyn , y_train_adasyn , X_test , y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nlgbm = lgb.LGBMClassifier()\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\nparams = {\n    'n_estimators' : sp_randint(50,200) , \n    'max_depth' : sp_randint(2,15) ,\n    'learning_rate' : sp_uniform(0.001 , 0.5 ) ,\n    'num_leaves' : sp_randint(20 , 50) \n} \n\n\nrsearch = RandomizedSearchCV(lgbm , param_distributions= params , cv = 3 , n_iter= 200 , n_jobs=-1 ,random_state= 3)\n\nrsearch.fit(X , y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rsearch.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm= lgb.LGBMClassifier(**rsearch.best_params_)\n\nlgbm.fit(X_train,y_train)\n\ny_train_pred=lgbm.predict(X_train)                 # Finding the Positives and Negatives \ny_train_prob=lgbm.predict_proba(X_train)[:,1]      # We are interested only in the 2nd column\n\nprint('Confusion Matrix - Train:','\\n' ,confusion_matrix(y_train,y_train_pred))\nprint('Overall Accuracy - Train:', accuracy_score(y_train,y_train_pred))             #Train\nprint('AUC- Train',roc_auc_score(y_train,y_train_prob))\n\ny_test_pred=lgbm.predict(X_test)\ny_test_prob=lgbm.predict_proba(X_test)[:,1]\n\n\nprint('\\n')\nprint('Confusion Matrix - Test:','\\n' ,confusion_matrix(y_test,y_test_pred))\nprint('Overall Accuracy - Test:', accuracy_score(y_test,y_test_pred))               #Test\nprint('AUC- Test',roc_auc_score(y_test,y_test_prob))\n\nprint('\\n')\nfpr,tpr,thresholds= roc_curve(y_test,y_test_prob)\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr,'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## * XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom xgboost import XGBClassifier\n\nparams = {\n        'min_child_weight': [1,2,3,4,5,6,7,8,9,10],\n        'gamma': [0.5, 1,1,1.25,1.35,1.45, 1.5,1.75, 2, 5],\n        'subsample': [0.6,0.7 ,0.8,0.9, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0,1.1,1.2],\n        'max_depth': [3, 4, 5,6,7]\n        }\n\nxgb = XGBClassifier(learning_rate=0.02, n_estimators=1000, objective='binary:logistic',\n                    silent=True, nthread=1)\n\nfolds = 3\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 3)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=skf.split(X,y), verbose=3, random_state=3 )\n\nrandom_search.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb= XGBClassifier(**random_search.best_params_,random_state=3)\n\nxgb.fit(X_train,y_train)\n\ny_train_pred=xgb.predict(X_train)                 # Finding the Positives and Negatives \ny_train_prob=xgb.predict_proba(X_train)[:,1]      # We are interested only in the 2nd column\n\n\n\nprint('Confusion Matrix - Train:','\\n' ,confusion_matrix(y_train,y_train_pred))\nprint('Overall Accuracy - Train:', accuracy_score(y_train,y_train_pred))             #Train\nprint('AUC- Train',roc_auc_score(y_train,y_train_prob))\n\ny_test_pred=xgb.predict(X_test)\ny_test_prob=xgb.predict_proba(X_test)[:,1]\n\n\nprint('\\n')\nprint('Confusion Matrix - Test:','\\n' ,confusion_matrix(y_test,y_test_pred))\nprint('Overall Accuracy - Test:', accuracy_score(y_test,y_test_pred))               #Test\nprint('AUC- Test',roc_auc_score(y_test,y_test_prob))\n\nprint('\\n')\nfpr,tpr,thresholds= roc_curve(y_test,y_test_prob)\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr,'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.svm import SVC\nsvm=SVC(probability=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked=VotingClassifier(estimators=[('Bagged_Logistic_Regression',bagged_lr),('Adaboost_Bernoulli_Naive_Bayes',bernoulli_adaboost),('GBOOst',gb),('Bagged_RandomForest',bagged_rfc),('Support_Vector_Machines',svm)],voting='soft')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[]\nmodels.append(('Bagged_Logistic_Regression',bagged_lr))\nmodels.append(('Adaboost_Bernoulli_Naive_Bayes',bernoulli_adaboost))\nmodels.append(('GBOOst',gb))\nmodels.append(('Bagged_RandomForest',bagged_rfc))\nmodels.append(('Support_Vector_Machines',svm))\nmodels.append(('Stacked',stacked))\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X,y,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked11=VotingClassifier(estimators=[('Bagged_Logistic_Regression',bagged_lr),('GBOOst',gb),('Support_Vector_Machines',svm)],voting='soft')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models=[]\nmodels.append(('Bagged_Logistic_Regression',bagged_lr))\nmodels.append(('GBOOst',gb))\nmodels.append(('Support_Vector_Machines',svm))\nmodels.append(('Stacked',stacked))\n\n\nresults=[]\nnames=[]\nfor name,model in models:\n    kfold=KFold(n_splits=5,shuffle=True,random_state=0)\n    cv_result=cross_val_score(model,X,y,cv=kfold,scoring='roc_auc')\n    results.append(cv_result)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name,np.mean(cv_result),np.var(cv_result,ddof=1)))\nfig=plt.figure(figsize=(15,8))\nfig.suptitle(\"Algorithm comparision\")\nax=fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ** Using Pycaret to assess which model is best  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/hrattritioneda/Attrition-EDA.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import *\nclf=setup(data,target='Attrition')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pycaret.classification import *\nclf=setup(data,target='Attrition',normalize=True,\n    normalize_method='zscore',\n    transformation=True,\n    transformation_method='yeo-johnson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare_models(sort='AUC')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.classes_ = np.array([-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_lr= tune_model(lr,optimize='AUC')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(tuned_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_lr_model=finalize_model(tuned_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_lr_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=predict_model(final_lr_model,data=data)\npredictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=[column for column in predictions.columns if (column!='Attrition') & (column!='Label') &(column!='Score')]\ncolumns= columns + ['Attrition','Label','Score']\npredictions=predictions[columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions['Attrition'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions['Label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"##### So we conclude that the best model we are getting is Logistic Regression model and now we can fit this model with the required predictor variables and predict the attrition of an employee. This is a versatile model and can be implemented in any organization to analyse their previous employee base and check the attrition.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Some of the proven employee retention statergies.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nImage.open('/kaggle/input/employee-retention/employee-retention-strategy-slide13.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is a link to article in site questionpro explaining some of the retention statergies.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[https://www.questionpro.com/blog/employee-retention-strategies/](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The END ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}