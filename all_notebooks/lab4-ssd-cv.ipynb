{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport json\nimport os\nimport matplotlib.pyplot as plt\nimport random\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras import backend as K\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\ndirectory = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\"\nimage_directory = \"../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\"\ndf = pd.read_csv(\"../input/face-mask-detection-dataset/train.csv\")\ndf_test = pd.read_csv(\"../input/face-mask-detection-dataset/submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvNet = cv2.dnn.readNetFromCaffe('../input/caffe-face-detector-opencv-pretrained-model/architecture.txt','../input/caffe-face-detector-opencv-pretrained-model/weights.caffemodel')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getJSON(filePathandName):\n    with open(filePathandName,'r') as f:\n        return json.load(f)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_gamma(image, gamma=1.0):\n    invGamma = 1.0 / gamma\n    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)])\n    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jsonfiles= []\nfor i in tqdm(os.listdir(directory)):\n    jsonfiles.append(getJSON(os.path.join(directory,i)))\njsonfiles[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/face-mask-detection-dataset/train.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nimg_size = 124\nmask = ['face_with_mask']\nnon_mask = [\"face_no_mask\"]\nlabels={'mask':0,'without mask':1}\nfor i in tqdm(df[\"name\"].unique()):\n    f = i+\".json\"\n    for j in getJSON(os.path.join(directory,f)).get(\"Annotations\"):\n        if j[\"classname\"] in mask:\n            x,y,w,h = j[\"BoundingBox\"]\n            img = cv2.imread(os.path.join(image_directory,i),1)\n            img = img[y:h,x:w]\n            img = cv2.resize(img,(img_size,img_size))\n            data.append([img,labels[\"mask\"]])\n        if j[\"classname\"] in non_mask:\n            x,y,w,h = j[\"BoundingBox\"]\n            img = cv2.imread(os.path.join(image_directory,i),1)\n            img = img[y:h,x:w]\n            img = cv2.resize(img,(img_size,img_size))    \n            data.append([img,labels[\"without mask\"]])\nrandom.shuffle(data)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = []\nfor face in data:\n    if(face[1] == 0):\n        p.append(\"Mask\")\n    else:\n        p.append(\"No Mask\")\nsns.countplot(p)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\nY = []\nfor features,label in data:\n    X.append(features)\n    Y.append(label)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)/255.0\nX = X.reshape(-1,124,124,3)\nY = np.array(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(124,124,3)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n \nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam' ,metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain,xval,ytrain,yval=train_test_split(X, Y,train_size=0.8,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,    \n        rotation_range=15,    \n        width_shift_range=0.1,\n        height_shift_range=0.1,  \n        horizontal_flip=True,  \n        vertical_flip=False)\ndatagen.fit(xtrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=32),\n                    steps_per_epoch=xtrain.shape[0]//32,\n                    epochs=5,\n                    verbose=1,\n                    validation_data=(xval, yval))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'],'g')\nplt.plot(history.history['val_accuracy'],'b')\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'],'g')\nplt.plot(history.history['val_loss'],'b')\nplt.title('Training Loss vs Validation Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_test[\"name\"]),len(df_test[\"name\"].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = ['1114.png','1504.jpg', '0072.jpg','0353.jpg','1374.jpg']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gamma = 2.0\nfig = plt.figure(figsize = (14,14))\nrows = 3\ncols = 2\naxes = []\nassign = {'0':'Mask','1':\"No Mask\"}\nfor j,im in tqdm(enumerate(test_images)):\n    image =  cv2.imread(os.path.join(image_directory,im),1)\n    image =  adjust_gamma(image, gamma=gamma)\n    (h, w) = image.shape[:2]\n    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n    cvNet.setInput(blob)\n    detections = cvNet.forward()\n    for i in range(0, detections.shape[2]):\n        try:\n            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n            frame = image[startY:endY, startX:endX]\n            confidence = detections[0, 0, i, 2]\n            if confidence > 0.2:\n                im = cv2.resize(frame,(img_size,img_size))\n                im = np.array(im)/255.0\n                im = im.reshape(1,124,124,3)\n                result = model.predict(im)\n                if result>0.5:\n                    label_Y = 1\n                else:\n                    label_Y = 0\n                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n                cv2.putText(image,assign[str(label_Y)] , (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (36,255,12), 2)\n        \n        except:pass\n    axes.append(fig.add_subplot(rows, cols, j+1))\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}