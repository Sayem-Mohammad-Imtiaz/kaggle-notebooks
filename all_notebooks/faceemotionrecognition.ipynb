{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* link to Dataset\n[https://www.kaggle.com/deadskull7/fer2013](http://)"},{"metadata":{},"cell_type":"markdown","source":"* Importing the Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/fer2013/fer2013.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Count of the images in train, validation and test datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Usage.value_counts() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Splitting the dataset into Train, Validation, Test Datsets"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngroups = [i for _, i in df.groupby('Usage')]\ntraining_data = groups[2]\nvalidation_data = groups[1]\ntesting_data = groups[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here we have huge number of images in class 3 and followed by class 6 and so on.. "},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.emotion.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data.emotion.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data.emotion.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_classes = 7\nwidth = 48\nheight = 48\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nclasses=np.array((\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction \n* Converting dataframes into respective arrays... \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(list(map(str.split, training_data.pixels)), np.float32) \nX_val = np.array(list(map(str.split, validation_data.pixels)), np.float32) \nX_test = np.array(list(map(str.split, testing_data.pixels)), np.float32) \nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1) \nX_val = X_val.reshape(X_val.shape[0], 48, 48, 1)\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.utils import np_utils\ny_train = training_data.emotion \ny_train = np_utils.to_categorical(y_train, num_classes) \ny_val = validation_data.emotion \ny_val = np_utils.to_categorical(y_val, num_classes) \ny_test = testing_data.emotion \ny_test = np_utils.to_categorical(y_test, num_classes) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fer2013_show_instance(index):\n    \"\"\"Shows the image and the emotion label of the index's instance.\"\"\"\n    image = np.reshape(training_data.at[index, \"pixels\"].split(\" \"), (width, height)).astype(\"float\")\n    image -= np.mean(image)\n    image /= np.std(image)\n    print(emotion_labels[training_data.at[index, \"emotion\"]])\n    plt.imshow(image, cmap=\"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fer2013_show_instance(np.random.randint(90,len(training_data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Normalizing the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fer2013_to_X():\n   \n    \n    X = []\n    pixels_list = training_data[\"pixels\"].values\n    \n    for pixels in pixels_list:\n        single_image = np.reshape(pixels.split(\" \"), (width, height)).astype(\"float\")\n        X.append(single_image)\n        \n    # Convert list to 4D array:\n    X = np.expand_dims(np.array(X), -1)\n    \n    # Normalize image data:\n    X -= np.mean(X, axis=0)\n    X /= np.std(X, axis=0)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = fer2013_to_X()\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.get_dummies(training_data['emotion']).values\ny.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Data Description"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.hist(bins=20, figsize=(15,15), color='b')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}