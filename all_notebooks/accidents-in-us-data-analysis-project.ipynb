{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Analysis Project\nThis is a small data analyis project, where I have tried to look at the accidents that occured in USA and the correlation between the cities and time.\n\n## Data explanation\n\nThe data is taken from Kaggle.com by Sobhan Moosavi. The title of the data is \"US Accidents (3 million records -- updated)\". This data contains huge set of information on the vehicle related accidents that are occured in USA. ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"## Downloading the data\nDownloading and re-uploading the data in jupyter consumes alot of time and resource, so I have used an easier method to do so by using a github project by JovianML, called opendatasets. This tool will goto the website and directly download the data. Further information can be found in his [github page](https://github.com/JovianML/opendatasets).\n\nInstall command:\npip install opendatasets --upgrade -quiet\n\nDownload data command:\n```\nimport opendatsets as od\n\ndownloadURL = 'https://www.kaggle.com/sobhanmoosavi/us-accidents'\n\nod.download(downloadURL)\n```","metadata":{"execution":{"iopub.status.busy":"2021-05-24T15:52:26.005242Z","iopub.execute_input":"2021-05-24T15:52:26.005821Z","iopub.status.idle":"2021-05-24T15:52:26.013376Z","shell.execute_reply.started":"2021-05-24T15:52:26.005732Z","shell.execute_reply":"2021-05-24T15:52:26.012013Z"}}},{"cell_type":"code","source":"# Installing the package\n#pip install opendatasets --upgrade -quiet","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:23:50.561722Z","iopub.execute_input":"2021-05-24T16:23:50.562434Z","iopub.status.idle":"2021-05-24T16:23:50.566835Z","shell.execute_reply.started":"2021-05-24T16:23:50.562327Z","shell.execute_reply":"2021-05-24T16:23:50.565746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Downloading the data using opendatasets","metadata":{}},{"cell_type":"code","source":"#import opendatasets as od\n#downloadURL = 'https://www.kaggle.com/sobhanmoosavi/us-accidents'\n#od.download(downloadURL)\n\n# OR\n# Download from the website itself or from here. I have attached file in the project.","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:23:50.568608Z","iopub.execute_input":"2021-05-24T16:23:50.568941Z","iopub.status.idle":"2021-05-24T16:23:50.578795Z","shell.execute_reply.started":"2021-05-24T16:23:50.568907Z","shell.execute_reply":"2021-05-24T16:23:50.577887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nsns.set(style = 'darkgrid')\nsns.color_palette(\"Paired\")\nimport matplotlib.pyplot as plt\n# To map the latitude and longitude\nimport folium\nfrom folium.plugins import HeatMap","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:23:50.580349Z","iopub.execute_input":"2021-05-24T16:23:50.580831Z","iopub.status.idle":"2021-05-24T16:23:51.776364Z","shell.execute_reply.started":"2021-05-24T16:23:50.580794Z","shell.execute_reply":"2021-05-24T16:23:51.775375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Parameters","metadata":{"execution":{"iopub.status.busy":"2021-05-24T15:55:05.653426Z","iopub.execute_input":"2021-05-24T15:55:05.65399Z","iopub.status.idle":"2021-05-24T15:55:05.658642Z","shell.execute_reply.started":"2021-05-24T15:55:05.653941Z","shell.execute_reply":"2021-05-24T15:55:05.657684Z"}}},{"cell_type":"code","source":"dataFileName = '../input/us-accidents/US_Accidents_Dec20_Updated.csv'","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:23:51.777946Z","iopub.execute_input":"2021-05-24T16:23:51.778268Z","iopub.status.idle":"2021-05-24T16:23:51.782783Z","shell.execute_reply.started":"2021-05-24T16:23:51.778236Z","shell.execute_reply":"2021-05-24T16:23:51.781399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing and Cleaning","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(dataFileName)\ndata","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:23:51.784295Z","iopub.execute_input":"2021-05-24T16:23:51.784589Z","iopub.status.idle":"2021-05-24T16:24:36.203438Z","shell.execute_reply.started":"2021-05-24T16:23:51.78456Z","shell.execute_reply":"2021-05-24T16:24:36.202415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Going through the data","metadata":{}},{"cell_type":"code","source":"# Overall review of the data\ndata.info()\n\n# Looking at columns only\nprint(data.columns)\n\n# Priting the number of rows and columns\nprint(f'rows = {len(data)}')\nprint(f'columns = {len(data.columns)}')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:36.204651Z","iopub.execute_input":"2021-05-24T16:24:36.204922Z","iopub.status.idle":"2021-05-24T16:24:36.228411Z","shell.execute_reply.started":"2021-05-24T16:24:36.204894Z","shell.execute_reply":"2021-05-24T16:24:36.227279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing Values\n# .isna() is function to check the missing value\n# if the data set has empty or missing value or null value, isna() will give \"True\" else \"False\" aS output\nprint(data.isna())","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:36.229757Z","iopub.execute_input":"2021-05-24T16:24:36.230031Z","iopub.status.idle":"2021-05-24T16:24:41.448593Z","shell.execute_reply.started":"2021-05-24T16:24:36.230004Z","shell.execute_reply":"2021-05-24T16:24:41.447539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summing the missing data dn ordering them\nmissingData = data.isna().sum().sort_values(ascending = False)\n\n# Missing data into percentage\nmissingPercent = data.isna().sum().sort_values(ascending =  False) / len(data)\nmissingPercent","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:41.451995Z","iopub.execute_input":"2021-05-24T16:24:41.452445Z","iopub.status.idle":"2021-05-24T16:24:51.923036Z","shell.execute_reply.started":"2021-05-24T16:24:41.452401Z","shell.execute_reply":"2021-05-24T16:24:51.922088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data with missing data only\nmissingData = missingPercent[missingPercent != 0]\nmissingData","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:51.924761Z","iopub.execute_input":"2021-05-24T16:24:51.925064Z","iopub.status.idle":"2021-05-24T16:24:51.932762Z","shell.execute_reply.started":"2021-05-24T16:24:51.925036Z","shell.execute_reply":"2021-05-24T16:24:51.931819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the missing data\ngraphMissing = missingData.plot(kind = 'barh',  figsize=(8, 6), title = 'Missing Data Percentage of different columns ')\ngraphMissing.set_xlabel('Percentage')\ngraphMissing.set_ylabel('Data Columns')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:51.933882Z","iopub.execute_input":"2021-05-24T16:24:51.934149Z","iopub.status.idle":"2021-05-24T16:24:52.323223Z","shell.execute_reply.started":"2021-05-24T16:24:51.934124Z","shell.execute_reply":"2021-05-24T16:24:52.322263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing the data\nI want to look at few columns for this project, namely\n* City\n* Start Time\n* Start Lat, Start Lng","metadata":{}},{"cell_type":"markdown","source":"## Accidents and City\nLet's see which city has the most accident in a horizontal graph","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:00:48.653213Z","iopub.execute_input":"2021-05-24T16:00:48.653577Z","iopub.status.idle":"2021-05-24T16:00:48.66004Z","shell.execute_reply.started":"2021-05-24T16:00:48.653547Z","shell.execute_reply":"2021-05-24T16:00:48.65819Z"}}},{"cell_type":"code","source":"# Going through cities\n\ncities =  data.City.unique()\nprint(f'Number of cities with accident: {len(cities)}')\n\ncitiesByAccident = data.City.value_counts()\ncitiesByAccident","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:52.324911Z","iopub.execute_input":"2021-05-24T16:24:52.325344Z","iopub.status.idle":"2021-05-24T16:24:53.389577Z","shell.execute_reply.started":"2021-05-24T16:24:52.3253Z","shell.execute_reply":"2021-05-24T16:24:53.38875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting top 50 cities\ngraphCities = citiesByAccident[:50].plot(kind = 'bar', figsize=(13, 7), title= 'Number of Accidents of top 50 cities ')\ngraphCities.title.set_size(20)\ngraphCities.set_xlabel('Cities', fontsize = 15)\ngraphCities.set_ylabel('Number of Accidents', fontsize = 15)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:53.392613Z","iopub.execute_input":"2021-05-24T16:24:53.392882Z","iopub.status.idle":"2021-05-24T16:24:54.664079Z","shell.execute_reply.started":"2021-05-24T16:24:53.392855Z","shell.execute_reply":"2021-05-24T16:24:54.662987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time of accidents\nThe column \"Start_Time\" gives the time, when did the accident occured and from this column, one can find the answers of following questions\n- What time of the day, does the accidents occur frequently?\n- Which days of the week have the most accidents?\n- Which months ahve the most accidents?\n- Trend of the accidents over the years\n","metadata":{}},{"cell_type":"code","source":"data.Start_Time\n# This column is a string, so the best way to begin would be converting them to real date-time format","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:54.665761Z","iopub.execute_input":"2021-05-24T16:24:54.666197Z","iopub.status.idle":"2021-05-24T16:24:54.67505Z","shell.execute_reply.started":"2021-05-24T16:24:54.666128Z","shell.execute_reply":"2021-05-24T16:24:54.674141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Start_Time = pd.to_datetime(data.Start_Time)\ndata.Start_Time","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:54.676551Z","iopub.execute_input":"2021-05-24T16:24:54.677251Z","iopub.status.idle":"2021-05-24T16:24:56.404155Z","shell.execute_reply.started":"2021-05-24T16:24:54.677205Z","shell.execute_reply":"2021-05-24T16:24:56.403177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After converting the column as datetime format, now one can easily work with the time and date separatly. \n# To the hour from the datetime format\ndata.Start_Time.dt.hour","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:56.405679Z","iopub.execute_input":"2021-05-24T16:24:56.406083Z","iopub.status.idle":"2021-05-24T16:24:56.74893Z","shell.execute_reply.started":"2021-05-24T16:24:56.40604Z","shell.execute_reply":"2021-05-24T16:24:56.74779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(data.Start_Time.dt.hour, bins=24, stat='probability').set_title('Time of the day of the Accidents')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:56.750416Z","iopub.execute_input":"2021-05-24T16:24:56.750716Z","iopub.status.idle":"2021-05-24T16:24:59.261351Z","shell.execute_reply.started":"2021-05-24T16:24:56.750686Z","shell.execute_reply":"2021-05-24T16:24:59.260248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's look at the day of the week chart\nsns.histplot(data.Start_Time.dt.dayofweek, bins=7, stat ='probability').set_title('Day of the week of the Accidents')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:24:59.26269Z","iopub.execute_input":"2021-05-24T16:24:59.26301Z","iopub.status.idle":"2021-05-24T16:25:01.733339Z","shell.execute_reply.started":"2021-05-24T16:24:59.262978Z","shell.execute_reply":"2021-05-24T16:25:01.732226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving one step further and check out, how is the trend for each day of the week.\ndays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nfig, axs =  plt.subplots(1, len(days), figsize=(20, 4))\n\nfor i in range(7):\n    dayTime = data.Start_Time[data.Start_Time.dt.dayofweek == i]\n    sns.histplot(dayTime.dt.hour, bins = 24, ax=axs[i], stat ='probability').set_title(f'{days[i]}')\n    \nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:25:01.734932Z","iopub.execute_input":"2021-05-24T16:25:01.735367Z","iopub.status.idle":"2021-05-24T16:25:08.298201Z","shell.execute_reply.started":"2021-05-24T16:25:01.735322Z","shell.execute_reply":"2021-05-24T16:25:08.296984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accidents over the year\nsns.histplot(data.Start_Time.dt.month, bins=12, stat ='probability').set_title('Accidents over the years')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:25:08.299515Z","iopub.execute_input":"2021-05-24T16:25:08.299795Z","iopub.status.idle":"2021-05-24T16:25:10.843825Z","shell.execute_reply.started":"2021-05-24T16:25:08.299765Z","shell.execute_reply":"2021-05-24T16:25:10.843105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"years = [2016, 2017, 2018, 2019]\n\nfig, axs =  plt.subplots(1, len(years), figsize=(20, 4))\n\nfor i in range(len(years)):\n    year = data.Start_Time[data.Start_Time.dt.year == years[i]]\n    sns.histplot(year.dt.month, bins = 12, stat ='probability', ax=axs[i]).set_title(f'{years[i]}')\n    \nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:25:10.845462Z","iopub.execute_input":"2021-05-24T16:25:10.846191Z","iopub.status.idle":"2021-05-24T16:25:14.682371Z","shell.execute_reply.started":"2021-05-24T16:25:10.846125Z","shell.execute_reply":"2021-05-24T16:25:14.680465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(x=data.Start_Lng, y=data.Start_Lat, size = 0.001)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:25:14.683467Z","iopub.execute_input":"2021-05-24T16:25:14.683729Z","iopub.status.idle":"2021-05-24T16:26:39.997317Z","shell.execute_reply.started":"2021-05-24T16:25:14.683703Z","shell.execute_reply":"2021-05-24T16:26:39.996316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a heatmap\nmap =  folium.Map()\nHeatMap(zip(list(data.Start_Lat), list(data.Start_Lng))).add_to(map)\nmap","metadata":{"execution":{"iopub.status.busy":"2021-05-24T16:26:39.998669Z","iopub.execute_input":"2021-05-24T16:26:39.998964Z","iopub.status.idle":"2021-05-24T16:27:31.368185Z","shell.execute_reply.started":"2021-05-24T16:26:39.998934Z","shell.execute_reply":"2021-05-24T16:27:31.36708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary and Conclusion\n### Accidents and cities\n- In the data set, 3 columns has more than 40% of the data missing, namely *Wind Chill, Precipitation and Number*. It is always recommended that the data which has more than 30-40% missing data is not really suitable for the data analysis. Hence, it is best to either remove the column or not use at all.\n- The number of accidents per city decreases expotentially\n- Less than 5% of cities have more than 1000 accidents\n\n### Time of accidents\n- Most the accidents occurs during the morning between *07:00 to 08:00* and later during the afternoon between *15:00 to 17:00*\n    - -> Probably, people are going to work and getting home after work\n- On weekdays, the number of accidents seems to be in the range and the number of accidents decreases over the weekend.\n    - -> One can assume that people over the weekend don't travel much as in weekdays\n- From the statments above, it can be concluded that accidents occurs mostly when people are mostly going to work. This theory can be pushed forward, by looking the graphs of time of accidents on different days of week. There is a clear trend that on the weekdays the accidents happens during the rush hour and on the weekends, it is during afternoons\n- It seems like there are more accidents around the months from *October* to *December*. One can speculate that, December being the holiday season, people slowly start to travel from one place to another and hence accidents rate increases. \n- But there is also a steap increase in the number of accidents staring from July already, but concreate reason must be investigated.\n- It seems like the data is incomplete for year 2016, therefore the weird trend at the beginning.\n\n### Place of Accidents\n- From the heatmap, it is pausible to conclude, there are more accidents in the coastal area and those are the places where the population is high also.\n\n\nWith this data set, much more information can be extracted, like state-wise accidents, sources of the accidents, weather conditions and many more. I have showed just a small sample data analysis, that one can perform with the help of pandas dataframe and visualisation. Such data analysis can be extended not only to this data set but any other data.\n\nIf there is any questions (9)","metadata":{}}]}