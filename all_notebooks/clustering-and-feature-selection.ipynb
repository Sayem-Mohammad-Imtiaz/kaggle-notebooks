{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # data visualization library  \nimport os\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LassoCV\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/ccdata/CC GENERAL.csv')\ndata.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DATA PREPROCESSING - FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"data.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Count missing variable\ndata.isnull().sum().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[data.isnull().any(axis=1)].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill  missing variable\ndata['MINIMUM_PAYMENTS'].fillna(data[\"PAYMENTS\"], inplace=True)\ndata['CREDIT_LIMIT'].fillna(data['CREDIT_LIMIT'].median(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Engineering\ndata[\"new_BALANCE_BALANCE_FREQUENCY\"] = data[\"BALANCE\"] * data[\"BALANCE_FREQUENCY\"]\ndata[\"new_ONEOFF_PURCHASES_PURCHASES\"] = data[\"ONEOFF_PURCHASES\"] / data[\"PURCHASES\"]\ndata[\"new_INSTALLMENTS_PURCHASES_PURCHASES\"] = data[\"INSTALLMENTS_PURCHASES\"] / data[\"PURCHASES\"]\ndata[\"new_CASH_ADVANCE_PURCHASES_PURCHASES\"] = data[\"CASH_ADVANCE\"] * data[\"CASH_ADVANCE_FREQUENCY\"]\ndata[\"new_PURCHASES_PURCHASES_FREQUENCY\"] = data[\"PURCHASES\"] * data[\"PURCHASES_FREQUENCY\"]\ndata[\"new_PURCHASES_ONEOFF_PURCHASES_FREQUENCY\"] = data[\"PURCHASES\"] * data[\"ONEOFF_PURCHASES_FREQUENCY\"]\ndata[\"new_PURCHASES_PURCHASES_TRX\"] = data[\"PURCHASES\"] / data[\"PURCHASES_TRX\"]\ndata[\"new_CASH_ADVANCE_CASH_ADVANCE_TRX\"] = data[\"CASH_ADVANCE\"] / data[\"CASH_ADVANCE_TRX\"]\ndata[\"new_BALANCE_CREDIT_LIMIT\"] = data[\"BALANCE\"] / data[\"CREDIT_LIMIT\"]\ndata[\"new_PAYMENTS_CREDIT_LIMIT\"] = data[\"PAYMENTS\"] / data[\"MINIMUM_PAYMENTS\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking missing variable\ndata.isnull().sum().sort_values(ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.fillna(0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Indexing CUST_ID feature\ndata.set_index('CUST_ID', inplace=True)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n    \nfor col in data.columns:\n    replace_with_thresholds(data, col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(data=data)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Min Max Scaler\nnames = data.columns\nindexes = data.index\nsc = MinMaxScaler((0, 1))\ndf = sc.fit_transform(data)\ndata_scaled = pd.DataFrame(df, columns=names, index=indexes)\ndata_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KMEANS CLUSTERING","metadata":{}},{"cell_type":"code","source":"# KMeans Clustering\nkmeans = KMeans()\nssd = []\nK = range(1, 30)\n\nfor k in K:\n    kmeans = KMeans(n_clusters=k).fit(data_scaled)\n    ssd.append(kmeans.inertia_)\n\nssd\n\nplt.plot(K, ssd, \"bx-\")\nplt.xlabel(\"Distance Residual Sums for K Values (WCSS)\")\nplt.title(\"Elbow Method for Optimum Number of Clusters\")\nplt.show()\n\nkmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k=(2, 20))\nvisu.fit(df)\nvisu.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans = KMeans(n_clusters=7).fit(data_scaled)\nclusters = kmeans.labels_\n\npd.DataFrame({\"Customers\": data.index, \"Clusters\": clusters})\ndata[\"cluster_no\"] = clusters\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"cluster_no\"] = data[\"cluster_no\"] + 1\ndata.groupby(\"cluster_no\").agg({\"cluster_no\": \"count\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"cluster_no\").agg(np.mean)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the histogram of various clusters\nfor i in data.columns:\n  plt.figure(figsize = (35, 5))\n  for j in range(1,8):\n    plt.subplot(1,8,j+1)\n    cluster = data[data['cluster_no'] == j]\n    cluster[i].hist(bins = 20)\n    plt.title('{}    \\nCluster {} '.format(i,j))\n  \n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HIERARCHICAL CLUSTERING","metadata":{}},{"cell_type":"code","source":"# Average Linkage Method\nhc_average = linkage(data_scaled, \"average\")\n\nplt.figure(figsize=(20, 10))\nplt.title(\"Hierarchical Clustering\")\nplt.xlabel(\"Observations\")\nplt.ylabel(\"Distance\")\ndendrogram(hc_average,\n           leaf_font_size=10, \n           p=10,\n           show_contracted=True,\n          truncate_mode='level')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Complete Linkage Method\nhc_complete = linkage(data_scaled, \"complete\")\n\nplt.figure(figsize=(15, 10))\nplt.title(\"Hierarchical Clustering\")\nplt.xlabel(\"Observations\")\nplt.ylabel(\"Distance\")\ndendrogram(hc_complete,\n           truncate_mode=\"lastp\",\n           p=10,\n           show_contracted=True,\n           leaf_font_size=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PRINCIPAL COMPONENT ANALYSIS","metadata":{}},{"cell_type":"code","source":"pca = PCA().fit(data_scaled)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel(\"# of components\")\nplt.ylabel(\"Cumulative Variance Ratio\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=6)\npca_fit = pca.fit_transform(data_scaled)\npca.explained_variance_ratio_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.cumsum(pca.explained_variance_ratio_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FEATURE SELECTION","metadata":{}},{"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(25,10))\ncor = data_scaled.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation with BALANCE variable\ncor_target = abs(cor[\"BALANCE\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.5]\nrelevant_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Random Forest Regression\nX = data_scaled.drop([\"BALANCE\",\"new_BALANCE_BALANCE_FREQUENCY\", \"new_BALANCE_CREDIT_LIMIT\", \"BALANCE_FREQUENCY\"],1)   #Feature Matrix\ny = data_scaled[\"BALANCE\"]          #Target Variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=46)\n\nrf_model = RandomForestRegressor(random_state=42).fit(X_train, y_train)\ny_pred = rf_model.predict(X_train)\nnp.sqrt(mean_squared_error(y_train, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Tuning\nrf_params = {\"max_depth\": [5, 8, None],\n             \"max_features\": [3, 5, 15],\n             \"n_estimators\": [200, 500],\n             \"min_samples_split\": [2, 5, 8]}\n\nrf_model = RandomForestRegressor(random_state=42)\nrf_cv_model = GridSearchCV(rf_model, rf_params, cv=5, n_jobs=-1, verbose=1).fit(X_train, y_train)\nrf_cv_model.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_tuned = RandomForestRegressor(**rf_cv_model.best_params_).fit(X_train, y_train)\n\ny_pred = rf_tuned.predict(X_train)\nnp.sqrt(mean_squared_error(y_train, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Feature Importances","metadata":{}},{"cell_type":"code","source":"def plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                     ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n\n\nplot_importance(rf_tuned, X, 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lasso CV Feature Importances","metadata":{}},{"cell_type":"code","source":"X = data_scaled.drop([\"BALANCE\",\"new_BALANCE_BALANCE_FREQUENCY\", \"new_BALANCE_CREDIT_LIMIT\", \"BALANCE_FREQUENCY\"],1)   #Feature Matrix\ny = data_scaled[\"BALANCE\"]          #Target Variable\n\nreg = LassoCV()\nreg.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\ncoef = pd.Series(reg.coef_, index = X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  \n      str(sum(coef == 0)) + \" variables\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}