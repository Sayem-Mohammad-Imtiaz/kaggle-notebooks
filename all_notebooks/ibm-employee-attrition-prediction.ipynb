{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40adf1f7-ef9e-9e14-0afa-afe3de23a0d8"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"464743fa-bbe0-3799-615e-af05c9acee06"},"outputs":[],"source":"df = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndf.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b79ad18f-e3fa-0f35-5079-079db2c4bc52"},"source":"## Data Analysis\nAlthough the main task is to explore **Attrition**, it's also interesting to explore other features like **MonthlyIncome** , **JobSatisfaction** and **WorkLifeBalance**. I will target these four features through this notebook. "},{"cell_type":"markdown","metadata":{"_cell_guid":"476af94e-e702-0451-a3e0-9fe365c0d474"},"source":"Let's first quickly check the quality of the dataset. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adf5920a-d4f7-bbe4-9a38-49ddb1aca0ae"},"outputs":[],"source":"df.isnull().any()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e28237e5-ae8a-ddda-e988-dadb9b610a8e"},"source":"Great! There are no missing values, now we can move to the next step: understanding the distributions of our targeted features. Here we should notice that **Attrition**, **JobSatisfaction**  and **WorkLifeBalance** are categorical variables, **MonthlyIncome** is a numerical variable. Categorical variables and numerical variables should be treated differently. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db57625f-f58f-3163-5a51-0b335a5428a3"},"outputs":[],"source":"f,((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(12,9))\nsns.countplot(x='Attrition',data=df,ax=ax1)\nsns.distplot(df['MonthlyIncome'],ax=ax2)\nsns.countplot(x=\"JobSatisfaction\",data=df,ax=ax3)\nsns.countplot(x=\"WorkLifeBalance\",data=df,ax=ax4)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d6ade79c-aaf9-bd19-6e80-ea62817600b8"},"source":"**Take away**\n\nFrom the distribution of three categorical variables, we can have a straightforward impression that employees in IBM seem to have a not bad life. The population of \"happy\" people is in general larger than \"sad\" people. "},{"cell_type":"markdown","metadata":{"_cell_guid":"9645795b-06fe-289d-2190-6a667f7405bb"},"source":"### Correlation of features\nThen we want to explore the correlation between features, a lot of cool visualisation will show up. This step can also help us to choose right features for each model. "},{"cell_type":"markdown","metadata":{"_cell_guid":"46563cd9-1345-8ed3-7e08-f06bbfc8520b"},"source":"#### ***MonthlyIncome***"},{"cell_type":"markdown","metadata":{"_cell_guid":"a1d2ad41-af1e-9851-6553-c4d04b749218"},"source":" - **Relationship with numerical features**\n\nBefore we do anything, we can first make an assumption of which features matter most. Maybe **Age**, **TotalWorkingYears** or **YearsAtCompany**? There are other interesting features as well like **EmployeeNumber** and **YearsSinceLastPromotion**. For numerical features, we can use scatter plot plusâ€‹ regression model to see the trend. Seanborn is a so powerful package that it can do most of the things for us very easily. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d662be60-ba8e-1e03-7864-175f5b00cd17"},"outputs":[],"source":"plt.figure()\ncols = [\"MonthlyIncome\",\"Age\",\"TotalWorkingYears\",\"EmployeeNumber\",\"YearsSinceLastPromotion\"]\nsns.pairplot(df[cols],diag_kind=\"kde\",kind=\"reg\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"3036bd3a-7986-7962-c223-794f800e4300"},"source":"**Take away**\n\nLuckily, our assumption seems make sense. **MonthlyIncome** has strong positive correlations with **Age** and **TotalWorkingYears** and a slight positive correlation with **YearsLastPromotion**.  It looks like **EmployNumber** cannot say a lot. Of course, it's not enough. Let's explore more!"},{"cell_type":"markdown","metadata":{"_cell_guid":"8cd1ac51-d652-cdaa-c084-c3f4b9a2572f"},"source":"- **Relationship with categorical features**\n\nSimilarly, we can make an assumption again. Don't worry, we are not experts in HR, we can never exactly make correct assumptions. But, that's the reason for data analysis, right? In this case, there are more categorical variables. We don't need to show all of them right now but some that I think maybe matter a lot, such as **Education**, **JobLevel**, **JobSatisfaction**. I also would like to check other interesting features like **Gender** and **MaritalStatus**. To make it more fun, I will use boxplot to show the trend. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26381d0f-b756-ca7f-c079-b383e9ceb43b"},"outputs":[],"source":"f,((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3,figsize=(12,8))\nsns.boxplot(x=df['Education'],y=df['MonthlyIncome'],ax=ax1)\nsns.boxplot(x=df['JobLevel'],y=df['MonthlyIncome'],ax=ax2)\nsns.boxplot(x=df['JobSatisfaction'],y=df['MonthlyIncome'],ax=ax3)\nsns.boxplot(x=df['Gender'],y=df['MonthlyIncome'],ax=ax4)\nsns.boxplot(x=df['MaritalStatus'],y=df['MonthlyIncome'],ax=ax5)\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b489be5-22de-0562-e01f-601e4df42759"},"source":"**Take away**\n\nWow, this time I find something really suprising. First of all, JobLevel has an extremely effect on the income, apparently higher job level means higher income. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f16e4f7-4760-9629-734b-d11de857e1ae"},"outputs":[],"source":"sns.jointplot(x=\"YearsAtCompany\",y=\"MonthlyIncome\",data=df,kind=\"hex\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e89ea4f-46f5-3d63-ba5a-1d9ac6b463fc"},"outputs":[],"source":"corrmat = df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);"},{"cell_type":"markdown","metadata":{"_cell_guid":"a713bec9-c93e-9a91-6a05-6e0579985341"},"source":"**Take away**\n\nGenerally, for the training model, we don't select features that have a strong correlation because it will have multicollinearity problem. Heatmap is a good way to detect this kind of situation. In this case, **YearsAtCompany**, **YearsInCurrentRole**, **YearsSinceLastPromotion** and **YearWithCurrManager** have strong correlations with each other. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dffcc65e-c00a-cd6b-1d97-afb4a9bf06e3"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74c1a1b6-0891-c54d-e936-f4145d4f62b5"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}