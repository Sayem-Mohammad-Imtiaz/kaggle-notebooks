{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/real-time-advertisers-auction/Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating and analysis of CPM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def weird_division(n, d):\n    return n / d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division((x['total_revenue'] * 100), x['measurable_impressions']) * 1000 , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CPM'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndf.plot(x='date', y='CPM')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"will remove the column 'total_revenue' as it directly affects the results. also we don't need a column 'date'"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_remove = ['date', 'total_revenue']\n\nX_train = df.loc[df['date'] <= '2019-06-21'].drop(columns=columns_to_remove)\nX_train = X_train[(X_train['CPM'] >= 0) & (X_train['CPM'] <= X_train['CPM'].quantile(.95))]\ny_train = X_train['CPM']\nX_train.drop(columns=['CPM'], inplace=True)\n\nX_test = df.loc[df['date'] > '2019-06-21'].drop(columns=columns_to_remove)\nX_test = X_test[(X_test['CPM'] >= 0) & (X_test['CPM'] <= X_test['CPM'].quantile(.95))]\ny_test = X_test['CPM']\nX_test.drop(columns=['CPM'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\nxgb_start = XGBRegressor(random_state=0)\nxgb_start.fit(X_train, y_train, eval_metric='rmse')\npred = xgb_start.predict(X_test)\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_feature_importance(clsf, ftrs):\n    imp = clsf.feature_importances_.tolist()\n    feat = ftrs\n    result = pd.DataFrame({'feat':feat,'score':imp})\n    result = result.sort_values(by=['score'],ascending=False)\n    return result\n\nget_feature_importance(xgb_start, X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently, the columns 'measurable_impressions', 'order_id' , 'line_item_type_id' are some leaks of the data, so the author of the initial solution removed them. Will remove it too. \n\nthe columns 'integration_type_id' , 'revenue_share_percent have no effect but the author of the initial solution removed them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_remove = ['date', 'total_revenue', 'measurable_impressions', 'order_id' , 'line_item_type_id', 'integration_type_id' , 'revenue_share_percent']\n\nX_train = df.loc[df['date'] <= '2019-06-21'].drop(columns=columns_to_remove)\nX_train = X_train[(X_train['CPM'] >= 0) & (X_train['CPM'] <= X_train['CPM'].quantile(.95))]\ny_train = X_train['CPM']\nX_train.drop(columns=['CPM'], inplace=True)\n\nX_test = df.loc[df['date'] > '2019-06-21'].drop(columns=columns_to_remove)\nX_test = X_test[(X_test['CPM'] >= 0) & (X_test['CPM'] <= X_test['CPM'].quantile(.95))]\ny_test = X_test['CPM']\nX_test.drop(columns=['CPM'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor(random_state=0)\nxgb.fit(X_train, y_train, eval_metric='rmse')\npred = xgb.predict(X_test)\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_feature_importance(xgb, X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find best models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet \nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \nfrom lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\n          GradientBoostingRegressor(random_state=0), \n          XGBRegressor(random_state=0), \n          RandomForestRegressor(random_state=0), \n          LGBMRegressor(random_state=0), \n          Ridge(random_state=0)\n          ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    try:\n        model.fit(X_train, y_train, eval_metric='rmse')\n    except:\n        model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    model_name = type(model).__name__\n    print(f'{model_name} - MAE {mean_squared_error(y_test, pred)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Ensemble of best models"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = None\nmodels = [\n          XGBRegressor(random_state=0), \n          RandomForestRegressor(random_state=0), \n          LGBMRegressor(random_state=0), \n          ]\nfor model in models:\n    try:\n        model.fit(X_train, y_train, eval_metric='rmse')\n    except:\n        model.fit(X_train, y_train)\n\nfor i in range(len(models)):\n    if pred is None: \n        pred = models[i].predict(X_test)\n    else:\n        pred += models[i].predict(X_test)\n\nprint(mean_squared_error(y_test, pred / 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Search best params for models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg = XGBRegressor(random_state=0)\nparams = {\n        'max_depth': [5, 10, 15],\n        'n_estimators': [50, 75, 100]\n        }\n\ngrid_search = GridSearchCV(xg_reg, params, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor(random_state=0, max_depth=10, n_estimators=75)\nxgb.fit(X_train, y_train, eval_metric='rmse')\npred = xgb.predict(X_test)\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_reg = RandomForestRegressor(random_state=0)\nparams = {\n        'max_depth': [15, 30, 25],\n        'n_estimators': [150, 200]\n        }\n\ngrid_search_rf = GridSearchCV(rf_reg, params, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n\ngrid_search_rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(random_state=0, max_depth = 25, n_estimators = 200)\nrf.fit(X_train, y_train)\npred = rf.predict(X_test)\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_reg = LGBMRegressor(random_state=0)\nparams = {\n        'max_depth': [15, 50, 100],\n        'n_estimators': [200, 500, 1000]\n        }\n\ngrid_search_lgbm = GridSearchCV(lgbm_reg, params, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n\ngrid_search_lgbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMRegressor(random_state=0, max_depth = 50, n_estimators = 1000)\nlgbm.fit(X_train, y_train, eval_metric='rmse')\npred = lgbm.predict(X_test)\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Voiting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\nVotReg = VotingRegressor(estimators=[('rf', rf), ('xgb', xgb), ('lgbm', lgbm),])\nVotReg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = VotReg.predict(X_test)\nmean_squared_error(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"of course, more detailed investigation will improve the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}