{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"*Disclaimer : I am here just trying to present the data. There is no offensive purpose at all. Maybe later on, you will find some of the data from the graph, that are considered offensive, I want to apologize. Enjoy!* \n\n# Data Preprocessing\n\nFirst thing that we need to do, like always, import the important library that give us abilities to import the data, *pandas* and *numpy*. *Pandas* is used for manipulating a table and *numpy* is used for matrix calculation and analysis. ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:45.955928Z","iopub.execute_input":"2021-06-07T14:28:45.956452Z","iopub.status.idle":"2021-06-07T14:28:45.971782Z","shell.execute_reply.started":"2021-06-07T14:28:45.956328Z","shell.execute_reply":"2021-06-07T14:28:45.970546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/income-adult/adult_data.csv')\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:45.973781Z","iopub.execute_input":"2021-06-07T14:28:45.974624Z","iopub.status.idle":"2021-06-07T14:28:46.092209Z","shell.execute_reply.started":"2021-06-07T14:28:45.974499Z","shell.execute_reply":"2021-06-07T14:28:46.091146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the top of the table above, there are data such as :\n1.  **Age**\n2.  **Workclass**\n3.  **Fnlwgt** (We don't really know what this is about, so we are just going to ignore this)\n4.  **Education**\n5.  **Education-num** (It is actually the same as education, but in the form of numbers)\n6.  **Marital-status**\n7.  **Occupation**\n8.  **Relationship**\n9.  **Race**\n10. **Sex**\n11. **Capital-gain**\n12. **Capital-loss**\n13. **Hours-per-week**\n14. **Native-country**\n\nAll of these 14 features contribute to what the salary, and that is what we will try to find out.","metadata":{}},{"cell_type":"markdown","source":"But first, when we see the data, especially at the name of the columns, there is something wrong there. At the beginning of each column's name, there is a space, something that is not supposed to be there. This little detail will make the analysis and the process of writing the code difficult. That is why we have to get rid of this first.  ","metadata":{}},{"cell_type":"code","source":"column_new_names = {}\nfor c in train.columns[1:]:\n    column_new_names[c] = c.split(' ')[1].replace('-', '_')\n    \ntrain = train.rename(columns=column_new_names)\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:46.094778Z","iopub.execute_input":"2021-06-07T14:28:46.095223Z","iopub.status.idle":"2021-06-07T14:28:46.118853Z","shell.execute_reply.started":"2021-06-07T14:28:46.095177Z","shell.execute_reply":"2021-06-07T14:28:46.117985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And then after that, we also want to see how many NaN values exist in the data. After we know how many, we will determine what treatment that we will give to these data. Obviously, if the data were ***categorical-data*** we have to treat them differently than if the data were ***numerical-data***. And also how big the population of this NaN data will affect our treatment decision to the data.  ","metadata":{}},{"cell_type":"code","source":"object_cols = [c for c in train.columns if train[c].dtype == 'O']\n\nfor c in object_cols:\n    new_values = []\n    for i, j in enumerate(train[c]):\n        k = j.split(' ')\n        if len(j) > 1: new_values.append(k[1]) \n        else: new_values.append(k[0])\n    train[c] = new_values\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:46.120338Z","iopub.execute_input":"2021-06-07T14:28:46.120606Z","iopub.status.idle":"2021-06-07T14:28:46.473556Z","shell.execute_reply.started":"2021-06-07T14:28:46.120579Z","shell.execute_reply":"2021-06-07T14:28:46.472667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see from the description above, there is no NaN or null value at all. With this, we can say that we don't need to use any treatment like **imputer** or any other function to fill the NaN. We just had to go straight analyze the data.   ","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis\n## Salaries of Workers","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsalary_1 = train.salary[0]\nfig, axes = plt.subplots(2, 1, figsize=(15, 15))\n\nplot_data = train.occupation[train.salary == salary_1].value_counts().reset_index()\nsns.barplot(data=plot_data, x='index', y='occupation', ax=axes[0])\naxes[0].set_xticks(np.arange(len(plot_data)))\naxes[0].set_xticklabels(plot_data['index'], rotation=45)\naxes[0].set_ylabel('Number of Workers')\naxes[0].set_title('Workers with Salary <= 50k')\n\nplot_data = train.occupation[train.salary != salary_1].value_counts().reset_index()\nsns.barplot(data=plot_data, x='index', y='occupation', ax=axes[1])\naxes[1].set_xticks(np.arange(len(plot_data)))\naxes[1].set_xticklabels(plot_data['index'], rotation=45)\naxes[1].set_ylabel('Number of Workers')\naxes[1].set_xlabel('Workers with Salary > 50k')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:46.475004Z","iopub.execute_input":"2021-06-07T14:28:46.475323Z","iopub.status.idle":"2021-06-07T14:28:47.369956Z","shell.execute_reply.started":"2021-06-07T14:28:46.475278Z","shell.execute_reply":"2021-06-07T14:28:47.369256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above we can see the graph that showed jobs that earned less than 50 thousands and more than 50 thousands. Most of the jobs that are paid less than 50 thousands are jobs that are technical, more specifically a repairing jobs etc. There are some technicians that earned more than 50 thousands, like what the second graph showed. But They are not as many as the technicians that are paid less than that. \n\nThe number one job with salary more than 50 thousands are **Executive Manager**. Obviously this job is the 'top of the food chain' job. If you are really good and spend long enough time on a job, at the end you will fill that position. The second one is the **Professional Speciality**. These are the people that have some specific skills simply, They are the best at what they are doing.   ","metadata":{}},{"cell_type":"markdown","source":"## Jobs Based on Gender","metadata":{}},{"cell_type":"code","source":"sex_1 = train.sex[0]\nfig, axes = plt.subplots(2, 1, figsize=(15, 15))\n\nplot_data = train.occupation[train.sex == sex_1].value_counts().reset_index()\nsns.barplot(data=plot_data, x='index', y='occupation', ax=axes[0])\naxes[0].set_xticks(np.arange(len(plot_data)))\naxes[0].set_xticklabels(plot_data['index'], rotation=45)\naxes[0].set_ylabel('Number of Workers')\naxes[0].set_title(\"Male's Occupation\")\n\nplot_data = train.occupation[train.sex != sex_1].value_counts().reset_index()\nsns.barplot(data=plot_data, x='index', y='occupation', ax=axes[1])\naxes[1].set_xticks(np.arange(len(plot_data)))\naxes[1].set_xticklabels(plot_data['index'], rotation=45)\naxes[1].set_ylabel('Number of Workers')\naxes[1].set_xlabel(\"Female's Occupation\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:47.370907Z","iopub.execute_input":"2021-06-07T14:28:47.371271Z","iopub.status.idle":"2021-06-07T14:28:47.909274Z","shell.execute_reply.started":"2021-06-07T14:28:47.371243Z","shell.execute_reply":"2021-06-07T14:28:47.908553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the graph above, something that I can conclude is Men tended to go to more technical jobs like being a technician, Engineer or a professional and Women tended to go for Administrative jobs.**  \n\nBut the statement above doesn't really explain the whole landscape becuase jobs in the 21st centruy is more broad and unpredictible than ever before. ","metadata":{}},{"cell_type":"markdown","source":"## Population Based on Race","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.countplot(data=train, x='race')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:47.910223Z","iopub.execute_input":"2021-06-07T14:28:47.910619Z","iopub.status.idle":"2021-06-07T14:28:48.18616Z","shell.execute_reply.started":"2021-06-07T14:28:47.910591Z","shell.execute_reply":"2021-06-07T14:28:48.185476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It will be better to present the data on percentage rather than the actual numbers. Because we can see that the white is so dominant. If we presented the data late on using barplot like what we did above, the data that we get from other races are going to be unseen. ","metadata":{}},{"cell_type":"code","source":"train['>50k'] = [0 if i == '<=50K' else 1 for i in train.salary]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:48.187113Z","iopub.execute_input":"2021-06-07T14:28:48.187496Z","iopub.status.idle":"2021-06-07T14:28:48.211603Z","shell.execute_reply.started":"2021-06-07T14:28:48.187468Z","shell.execute_reply":"2021-06-07T14:28:48.210814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Salaries Based on Races","metadata":{}},{"cell_type":"code","source":"data_used = train[['race', '>50k']].groupby('race').mean().reset_index()\ndata_used['<=50k'] = 1 - data_used['>50k']\ndata_used = pd.melt(data_used, id_vars=['race'], value_vars=['<=50k', '>50k'])\ndata_used.columns = ['race', 'salary', 'percentage']\ndata_used = data_used.replace({'Amer-Indian-Eskimo':'Indian-Eskimo', 'Asian-Pac-Islander':'Asian',\n                               '>50k':'more_than_50k', '<=50k':'less_than_50k'})\n\nplt.figure(figsize=(15, 10))\nsns.catplot(data=data_used, x='race', y='percentage', col='salary', kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:48.213786Z","iopub.execute_input":"2021-06-07T14:28:48.214184Z","iopub.status.idle":"2021-06-07T14:28:48.625688Z","shell.execute_reply.started":"2021-06-07T14:28:48.214153Z","shell.execute_reply":"2021-06-07T14:28:48.624719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Jobs Based on Race","metadata":{}},{"cell_type":"code","source":"occupations = train.occupation.value_counts().index[:8]\nrace = train.race.value_counts().index\nor_array = np.zeros([len(race), len(occupations)])\n\nfor i, r in enumerate(race):\n    for j, o in enumerate(occupations):\n        total = len(train[train.race == r])\n        or_array[i, j] = len(train[(train.race == r) & (train.occupation == o)]) / total\n        \nor_df = pd.DataFrame(or_array, columns=occupations, index=race)\nor_df = or_df.reset_index().melt(id_vars=['index']).rename(columns={'index':'race',\n                                                                    'variable':'occupation',\n                                                                    'value':'workers'})\nplt.figure(figsize=(50, 20))\nfig = sns.catplot(data=or_df, x='occupation', y='workers', row='race', kind='bar')\nfig.set_xticklabels(rotation=45)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:48.627246Z","iopub.execute_input":"2021-06-07T14:28:48.627594Z","iopub.status.idle":"2021-06-07T14:28:50.376959Z","shell.execute_reply.started":"2021-06-07T14:28:48.627563Z","shell.execute_reply":"2021-06-07T14:28:50.376172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most popular jobs for white people are : \n1. Craft repair\n2. Professional\n3. Executive Manager\n\nThe most popular jobs for black people are : \n1. Adm-clerical\n2. Service\n\nThe most popular jobs for asian are :\n1. Professional\n\nThe most popular jobs for Amer-Indian_eskimo are :\n1. Craft repair\n\nThe most popular jobs for people who aren't grouped above are : \n1. Service\n2. Machine Inspector","metadata":{}},{"cell_type":"markdown","source":"## Education Relations to Salaries","metadata":{}},{"cell_type":"code","source":"education = train.education.value_counts().index[:9]\nsalary = train.salary.value_counts().index\nse_array = np.zeros([len(salary), len(education)])\n\nfor i, s in enumerate(salary):\n    for j, e in enumerate(education):\n        se_array[i, j] = len(train[(train.salary == s) & (train.education == e)]) \n        \nse_df = pd.DataFrame(se_array, index=salary, columns=education)\nse_df = se_df.reset_index().melt(id_vars='index').rename(columns={'index':'salary',\n                                                                  'variable':'education',\n                                                                  'value':'workers'})\n\nplt.figure(figsize=(50, 20))\nfig = sns.catplot(data=se_df, x='education', y='workers', col='salary', kind='bar')\nfig.set_xticklabels(rotation=45)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:50.378193Z","iopub.execute_input":"2021-06-07T14:28:50.378807Z","iopub.status.idle":"2021-06-07T14:28:51.073063Z","shell.execute_reply.started":"2021-06-07T14:28:50.378754Z","shell.execute_reply":"2021-06-07T14:28:51.07202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the graph above, most people in this data are only a high school graduates. Most of them are getting salary less than 50 thousands dollar. After high school graduates, we have some-college graduates which most of them also had less than 50 thousands dollar as a yearly salary. \n\nBachelors degree are the one who has highest numbers on the salary more than 50 thousands. But it doesn't prove that with a bachelor's degree you will get that amount of salary. Because in fact, there are more bachelor's degree workers that have salaries less than 50 thousands than more.  ","metadata":{}},{"cell_type":"markdown","source":"## Age Relations to Salary","metadata":{}},{"cell_type":"code","source":"age = np.arange(train.age.min(), train.age.max())\nsalary = train.salary.value_counts().index\nas_array = np.zeros([len(age), len(salary)])\n\nfor i, a in enumerate(age):\n    for j, s in enumerate(salary):\n        as_array[i, j] = len(train[(train.salary == s) & (train.age == a)]) \n        \nas_df = pd.DataFrame(as_array, index=age, columns=salary)\nas_df = as_df.reset_index().melt(id_vars='index').rename(columns={'index':'age',\n                                                                  'variable':'salary',\n                                                                  'value':'workers'})\n\nplt.figure(figsize=(50, 20))\nsns.relplot(data=as_df, x='age', y='workers', col='salary', kind='line')\nplt.ylim(0, 1000)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:51.076229Z","iopub.execute_input":"2021-06-07T14:28:51.076554Z","iopub.status.idle":"2021-06-07T14:28:52.394009Z","shell.execute_reply.started":"2021-06-07T14:28:51.076524Z","shell.execute_reply":"2021-06-07T14:28:52.392805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see from the graph above, there are people who are already old but still working. They are over 60 years old and they still have jobs. These jobs have many variants, because there are elders that got paid more than 50 thousands but there are also elders that got paid less. \n\nBut, the obvious pattern is something that you can see at the left graph. **The more you get older, the more you tend to have higher wage.** \n\nThis makes sense because we can assume that a worker doing the same job over the years, or moved to a different new job if it offered higher wage, and the more a worker do it the higher the paid that they would receive, because people hire experinced and professional workers more.   ","metadata":{}},{"cell_type":"markdown","source":"## Week-Hour Work Relations to Salary","metadata":{}},{"cell_type":"code","source":"hours = np.arange(train.hours_per_week.min(), train.hours_per_week.max())\nsalary = train.salary.value_counts().index\nas_array = np.zeros([len(hours), len(salary)])\n\nfor i, a in enumerate(hours):\n    for j, s in enumerate(salary):\n        as_array[i, j] = len(train[(train.salary == s) & (train.hours_per_week == a)]) \n        \nas_df = pd.DataFrame(as_array, index=hours, columns=salary)\nas_df = as_df.reset_index().melt(id_vars='index').rename(columns={'index':'hours',\n                                                                  'variable':'salary',\n                                                                  'value':'workers'})\n\nplt.figure(figsize=(50, 20))\nsns.relplot(data=as_df, x='hours', y='workers', col='salary', kind='line')\nplt.ylim(0, 1000)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:52.395546Z","iopub.execute_input":"2021-06-07T14:28:52.39597Z","iopub.status.idle":"2021-06-07T14:28:53.991413Z","shell.execute_reply.started":"2021-06-07T14:28:52.395925Z","shell.execute_reply":"2021-06-07T14:28:53.99032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see at the graph above, that the left graph which showed you the distributions of workers with less than 50 thousands wage based on their work hours, it doesn't really have a pattern. Maybe there are some rules in their offices that they need to work a certain hours, but it is fair to say that workers can work more and still get paid less. \n\nAt the other hand, the right graph which showed the workers with higher wage, it can be seen that most of these workers work between 40 to 60 hours a week. ","metadata":{}},{"cell_type":"code","source":"overworked_job = pd.DataFrame(train[train.hours_per_week > 60]['occupation'].value_counts()[:6])\noj = overworked_job.reset_index().rename(columns={'index':'job', 'occupation':'workers'})\nplt.figure(figsize=(15, 4))\nsns.barplot(data=oj, x='job', y='workers')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:53.992872Z","iopub.execute_input":"2021-06-07T14:28:53.993271Z","iopub.status.idle":"2021-06-07T14:28:54.181908Z","shell.execute_reply.started":"2021-06-07T14:28:53.993239Z","shell.execute_reply":"2021-06-07T14:28:54.181081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above is the graph showing what are the jobs that spend more work-hours. We can see in the first place there is **executive managerial**, then a **professional** etc.","metadata":{}},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"markdown","source":"In this modeling, we will try to find the best method. There are some emthods or model that we would build and tested which are :\n1. **Linear Regression** \n2. **Logistic Regression**\n3. **Gaussian Naive-Bayes**\n4. **K-Neighbors Classifier**\n5. **Support Vector Classifier**\n6. **Decision Tree Classifier**\n7. **Ada Boost Classifier**\n8. **Random Forest Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\ny_values = train['>50k']\nx_values = train.drop(['>50k', 'salary'], axis=1)\n\ncat_cols = [c for c in x_values.columns if x_values[c].dtype == 'O'] \nnum_cols = [c for c in x_values.columns if c not in cat_cols]\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_values, y_values, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:54.183328Z","iopub.execute_input":"2021-06-07T14:28:54.183772Z","iopub.status.idle":"2021-06-07T14:28:54.401056Z","shell.execute_reply.started":"2021-06-07T14:28:54.18373Z","shell.execute_reply":"2021-06-07T14:28:54.399829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"workclass_le = LabelEncoder()\neducation_le = LabelEncoder()\nmarital_status_le = LabelEncoder()\noccupation_le = LabelEncoder()\nrelationship_le = LabelEncoder()\nrace_le = LabelEncoder()\nsex_le = LabelEncoder()\nnative_country_le = LabelEncoder()\n\ncat_cols_var = [workclass_le, education_le, marital_status_le, \n                occupation_le, relationship_le, race_le, \n                sex_le, native_country_le]\n\ncat_train_transformed = pd.DataFrame()\nfor i, c in zip(cat_cols, cat_cols_var):\n    add = c.fit_transform(x_train[i]).reshape(-1, 1)\n    add = pd.DataFrame(add, columns=[i])\n    cat_train_transformed = pd.concat([cat_train_transformed, add], axis=1)\n    \ncat_valid_transformed = pd.DataFrame()\nfor i, c in zip(cat_cols, cat_cols_var):\n    add = c.transform(x_valid[i]).reshape(-1, 1)\n    add = pd.DataFrame(add, columns=[i])\n    cat_valid_transformed = pd.concat([cat_valid_transformed, add], axis=1)\n    \nnum_train = x_train[num_cols]\nnum_valid = x_valid[num_cols]\nnum_transformer = MinMaxScaler()\n\nnum_train_transformed = pd.DataFrame(num_transformer.fit_transform(num_train), columns=num_cols)\nnum_valid_transformed = pd.DataFrame(num_transformer.transform(num_valid), columns=num_cols)\n\nx_train_transformed = pd.concat([cat_train_transformed, num_train_transformed], axis=1)\nx_valid_transformed = pd.concat([cat_valid_transformed, num_valid_transformed], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:54.40255Z","iopub.execute_input":"2021-06-07T14:28:54.402852Z","iopub.status.idle":"2021-06-07T14:28:54.593606Z","shell.execute_reply.started":"2021-06-07T14:28:54.402822Z","shell.execute_reply":"2021-06-07T14:28:54.592692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n\nmodel = [LinearRegression(), LogisticRegression(), GaussianNB(), \n         KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), \n         AdaBoostClassifier(), RandomForestClassifier()]\nmodel_names = ['Linear Regression', 'Logistic Regression', 'Gaussian Naive-Bayes', \n               'K-Neighbors Classifier', 'Support Vector Classifier', 'Decision Tree Classifier', \n               'Ada Boost Classifier', 'Random Forest Classifier']\nscores = np.zeros(len(model)).reshape(-1, 1)\n\nfor i, m in enumerate(model):\n    clf = m.fit(x_train_transformed, y_train)\n    scores[i] = clf.score(x_valid_transformed, y_valid)\n    \nthe_scores = pd.DataFrame(scores, index=model_names, columns=['score'])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:28:54.594926Z","iopub.execute_input":"2021-06-07T14:28:54.595362Z","iopub.status.idle":"2021-06-07T14:29:26.653143Z","shell.execute_reply.started":"2021-06-07T14:28:54.595318Z","shell.execute_reply":"2021-06-07T14:29:26.652075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"the_scores","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:29:26.654743Z","iopub.execute_input":"2021-06-07T14:29:26.655165Z","iopub.status.idle":"2021-06-07T14:29:26.666364Z","shell.execute_reply.started":"2021-06-07T14:29:26.655118Z","shell.execute_reply":"2021-06-07T14:29:26.665136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nab = AdaBoostClassifier()\nparameters = {'n_estimators':[50, 80, 100, 130, 150, 200], 'learning_rate':[0.1, 0.5, 1, 1.2, 1.5, 2]}\nclf = GridSearchCV(ab, parameters)\nclf.fit(x_train_transformed, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:29:26.667728Z","iopub.execute_input":"2021-06-07T14:29:26.66803Z","iopub.status.idle":"2021-06-07T14:34:20.083577Z","shell.execute_reply.started":"2021-06-07T14:29:26.668002Z","shell.execute_reply":"2021-06-07T14:34:20.082778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AdaBoostClassifier().get_params().keys()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:34:20.084624Z","iopub.execute_input":"2021-06-07T14:34:20.084924Z","iopub.status.idle":"2021-06-07T14:34:20.091092Z","shell.execute_reply.started":"2021-06-07T14:34:20.084894Z","shell.execute_reply":"2021-06-07T14:34:20.090148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.cv_results_","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:34:20.092553Z","iopub.execute_input":"2021-06-07T14:34:20.092952Z","iopub.status.idle":"2021-06-07T14:34:20.117049Z","shell.execute_reply.started":"2021-06-07T14:34:20.092911Z","shell.execute_reply":"2021-06-07T14:34:20.116083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.get_params","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:34:20.118245Z","iopub.execute_input":"2021-06-07T14:34:20.118552Z","iopub.status.idle":"2021-06-07T14:34:20.123676Z","shell.execute_reply.started":"2021-06-07T14:34:20.118525Z","shell.execute_reply":"2021-06-07T14:34:20.123018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = AdaBoostClassifier(n_estimators=120, learning_rate=1).fit(x_train_transformed, y_train)\ns = clf.score(x_valid_transformed, y_valid)\ns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:34:20.124558Z","iopub.execute_input":"2021-06-07T14:34:20.124914Z","iopub.status.idle":"2021-06-07T14:34:22.182014Z","shell.execute_reply.started":"2021-06-07T14:34:20.124887Z","shell.execute_reply":"2021-06-07T14:34:22.18134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best model that we can get here is **Ada Boost Classifier** with the parameter :\n1. n_estimator = 120\n2. learning_rate = 1\n\nFrom this model we can get the accuracy of 86.28%.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\n1. There are many factors contributing to how much wage a worker will get, from education to expererience\n2. Jobs with the most workers to be paid more than 50 thousands dollars are **Executive Managerial** and **Professional**.\n3. The best prediction model we can find is Ada Boost Classifier with the parameters: (*n_estimator* = 120, *learning_rate* = 1).","metadata":{}}]}