{"cells":[{"metadata":{},"cell_type":"markdown","source":"# In this notebook, you will find:\n* How to train a perceptron using sigmoid as activation function.\n* Using the perceptron for binary classification.\n* Digit classification using the famous MNIST dataset.\n* How to select the optimal number of hidden layers in a multi-layer perceptron\n* Evaluating the perceptrons trained on different classification metrics(Accuracy,Precision,ROC-AUC etc..)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Do upvote if you find this notebook useful. So let's get started.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Imports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler,LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix, roc_curve, auc, f1_score, precision_score,recall_score, roc_auc_score\nfrom keras.datasets import mnist\nimport warnings \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binary classification using Single Layer Perceptron","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/breast-cancer-dataset/breast_cancer.csv')\ndel df['Unnamed: 32']\nx = df.iloc[:,2:]\n\ny = df['diagnosis']\ny = y.map({'M': 0, 'B': 1})\ny = y.values\n\n\nsc = MinMaxScaler()\nX = sc.fit_transform(x)\nX = np.c_[np.ones(len(X)),X]\nx_train, x_test, y_train, y_test = train_test_split(X, y, train_size = 0.7)\nx.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the perceptron\n\n### I have used sigmoid as the activation function(you can also use the step function). The function *train_perceptron* returns the weight vector after iterating.\n\n### Some links providing good insights about perceptron and training rule:\n\n1. [https://appliedgo.net/perceptron/](http://)\n1. [https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef train_perceptron(X,Y,alpha = 0.1,iter = 2500):\n    theta = np.random.uniform(size=(X.shape[1], 1))\n    Y = Y.reshape(Y.shape[0], 1)\n    for i in range(iter):\n        z = X @ theta\n        Y_pred = sigmoid(z)\n        error = Y - Y_pred\n        temp = alpha * error\n        theta += X.T @ temp\n    return theta","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function to evaluate classifier ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateClassifier(x,y,y_pred,y_score):\n    cm = pd.DataFrame(\n        confusion_matrix(y, y_pred),\n        columns=['Predicted Benign', 'Predicted Malignant'],\n        index=['True Benign', 'True Malignant']\n    )\n    print('\\nConfusion Matrix: \\n')\n    sns.set(font_scale=1.4) # for label size\n    sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}) # font size\n    plt.show()\n\n    w1 = cm['Predicted Benign']['True Benign'] / (cm['Predicted Benign']['True Benign'] + cm['Predicted Malignant']['True Benign'])\n    w2 = cm['Predicted Malignant']['True Malignant'] / (cm['Predicted Benign']['True Malignant'] + cm['Predicted Malignant']['True Malignant'])\n    print('\\nClasswise accuracy: ')\n    print('\\nBenign: ',w1 * 100)\n    print('\\nMalignant: ',w2 * 100)\n    \n    indices = ['Accuracy','Precision','F1 score','Recall  score']\n    eval = pd.DataFrame([accuracy_score(y,y_pred) * 100,precision_score(y,y_pred,average = 'macro') * 100,f1_score(y,y_pred,average = 'macro') * 100,recall_score(y,y_pred,average = 'macro') * 100],columns=['Value'],index=indices)\n    eval.index.name = 'Metrics'\n    print('\\n',eval)\n  \n    fpr,tpr,_ = roc_curve(y, y_score)\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)        \n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.05])\n    plt.ylim([0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    plt.title('ROC curve')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculating the predicted values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = train_perceptron(x_train,y_train)\ny_pred = sigmoid(x_test @ weights)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Set the threshold value here(I have used 0.5)*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probs = y_pred\ny_pred[y_pred >=  0.5] = 1\ny_pred[y_pred <  0.5] = 0\nevaluateClassifier(x_test,y_test,y_pred,y_probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multi-class classification on MNIST dataset using Multi-layer Perceptron","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train / 255\nx_test = x_test / 255\n\nnsamples, nx, ny = x_train.shape\nx_train = x_train.reshape((nsamples,nx*ny))\n\nnsamples, nx, ny = x_test.shape\nx_test = x_test.reshape((nsamples,nx*ny))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Varying the number of hidden layer and calculating the training and testing accuracies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"training_acc = np.zeros(11)\ntesting_acc = np.zeros(11)\niter = 0\nfor i in range(30,41): \n    mlp = MLPClassifier(hidden_layer_sizes = (i), max_iter = 10, alpha=0.001, solver='sgd', verbose=False, learning_rate_init=0.01)\n    \n    mlp.fit(x_train, y_train)\n    training_acc[iter] = mlp.score(x_train, y_train)\n    \n    mlp.fit(x_test, y_test)\n    testing_acc[iter] = mlp.score(x_test, y_test)\n    iter += 1\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting training accuracy vs no. of hidden layers ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(30,41),training_acc * 100,'b-')\nplt.xlabel('No. of hidden layer nodes')\nplt.ylabel('Accuracy')\nplt.title('Training accuracy v/s no. of hidden nodes')\nplt.show()\ns = pd.Series(training_acc * 100,range(30,41))\ndf = pd.DataFrame({'No. of hidden nodes':s.index, 'Training Accuracy':s.values})\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting testing accuracy vs no. of hidden layers ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(30,41),testing_acc * 100,'b-')\nplt.xlabel('No. of hidden layer nodes')\nplt.ylabel('Accuracy')\nplt.title('Testing accuracy v/s no. of hidden nodes')\nplt.show()\ntesting_acc * 100\n\ns = pd.Series(testing_acc * 100,range(30,41))\ndf = pd.DataFrame({'No. of hidden nodes':s.index, 'Testing Accuracy':s.values})\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Since the maximum testing accuracy is with 40 hidden nodes, we will use 40 nodes in the hidden layer for classification.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(hidden_layer_sizes = (40), max_iter = 10, alpha=0.001, solver='sgd', verbose=False, learning_rate_init=0.01)\nmlp.fit(x_train,y_train)\ny_pred = mlp.predict(x_test)\ny_probs = mlp.predict_proba(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = ['Accuracy','Precision','F1 score','Recall  score']\neval = pd.DataFrame([accuracy_score(y_test,y_pred) * 100,precision_score(y_test,y_pred,average = 'macro') * 100,f1_score(y_test,y_pred,average = 'macro') * 100,recall_score(y_test,y_pred,average = 'macro') * 100],columns=['Value'],index=indices)\neval.index.name = 'Metrics'\nprint('\\n',eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclasses = range(10)\nprobabs = y_probs\ny_test2 = label_binarize(y_test, classes)\nfor i in range(10):\n    preds = probabs[:,i]    \n    fpr, tpr, threshold = roc_curve(y_test2[:, i], preds)\n    roc_auc = auc(fpr, tpr)\n    plt.title('Receiver Operating Characteristic')\n    plt.plot(fpr, tpr, 'b', label = 'Class ' + str(i + 1))\n    plt.legend(loc = 'lower right')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}