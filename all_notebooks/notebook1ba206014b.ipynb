{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cd /kaggle/input/bill_authentication\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n#Loading the dataset, path from my gdrive\ndataset = pd.read_csv('bill_authentication.csv')\n\nprint(dataset.head())\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_entropy(y):\n    if len(y) < 2: \n        return 0\n    freq = np.array( y.value_counts(normalize=True) )\n    return -(freq * np.log2(freq + 1e-6)).sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_info_gain(samples, attr, target):\n    values = samples[attr].value_counts(normalize=True)\n    split_ent = 0\n    for v, fr in values.iteritems():\n        index = samples[attr]==v\n        sub_ent = compute_entropy(target[index])\n        split_ent += fr * sub_ent\n    \n    ent = compute_entropy(target)\n    return ent - split_ent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass TreeNode:\n\n    def __init__(self):\n        self.children = {} \n        self.decision = None \n        self.split_feat_name = None \n\n    def pretty_print(self, prefix=''):\n        if self.split_feat_name is not None:\n            for k, v in self.children.items():\n                v.pretty_print(f\"{prefix}:When {self.split_feat_name} is {k}\")\n                #v.pretty_print(f\"{prefix}:{k}:\")\n        else:\n            print(f\"{prefix}:{self.decision}\")\n\n    def predict(self, sample):\n        if self.decision is not None:\n            \n            print(\"Decision:\", self.decision)\n            return self.decision\n        else: \n            attr_val = sample[self.split_feat_name]\n            child = self.children[attr_val]\n            \n            print(\"Testing \", self.split_feat_name, \"->\", attr_val)\n            return child.predict(sample)\n\n    def fit(self, X, y):\n        if len(X) == 0:\n            self.decision = \"Yes\"\n            return\n        else: \n            unique_values = y.unique()\n            if len(unique_values) == 1:\n                self.decision = unique_values[0]\n                return\n            else:\n                info_gain_max = 0\n                for a in X.keys(): \n                    aig = compute_info_gain(X, a, y)\n                    if aig > info_gain_max:\n                        info_gain_max = aig\n                        self.split_feat_name = a\n                print(f\"Split by {self.split_feat_name}, IG: {info_gain_max:.2f}\")\n                self.children = {}\n                for v in X[self.split_feat_name].unique():\n                    index = X[self.split_feat_name] == v\n                    self.children[v] = TreeNode()\n                    self.children[v].fit(X[index], y[index])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating to X and Y \nX = dataset.drop('Class', axis=1)\ny= dataset['Class']\n\n# splitting training and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, shuffle=True, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating tree and fitting the tree.\nt = TreeNode()\nt.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}