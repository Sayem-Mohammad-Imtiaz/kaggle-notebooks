{"cells":[{"metadata":{},"cell_type":"markdown","source":"__________________________\n# <center>Count the number of faces in an Image</center>\n__________________________","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://i.pinimg.com/originals/b2/13/7c/b2137cd75449417bdcb2eb05305d1a1e.png\" height=500 width=600/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nThe method of face detection in pictures is complicated because of variability present across human faces such as pose, expression, position and orientation, skin colour, the presence of glasses or facial hair, differences in camera gain, lighting conditions, and image resolution.\n\n- YOLOv5 is one of the object detection technique and using this technique we gonna classify the number of object in an image. And for this particular dataset we are treating human faces as an object.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### <font color='red'>Note:</font> \n\n- If you are a beginner or using YOLOv5 for the first time i suggest you check this [Beginners Notebook On YOLOv5](https://www.kaggle.com/vin1234/gettingstarted-with-yolov5-global-wheat-detection).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## How gonna we prceed further with this problem using YOLOv5?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"YOLO “You Only Look Once” is one of the most popular and most favorite algorithms for AI engineers. It always has been the first preference for real-time object detection.\n\nYOLO model are trained on [COCO dataset](https://cocodataset.org/), which has around 80 classes.\n\n> So here we gonna use the concept of transfer leanring for object(face) detection. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Reading the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np \n\n\n# import useful tools\nfrom glob import glob\nfrom PIL import Image\nimport cv2\n\n# import data visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\n\nfrom bokeh.plotting import figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs\n\nfrom tqdm.auto import tqdm\nimport shutil as sh\n\n# import data augmentation\nimport albumentations as albu","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Face Count EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### About the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/count-the-number-of-faces-present-in-an-image/train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup the paths to train and test images\ntrain=pd.read_csv('../input/count-the-number-of-faces-present-in-an-image/train/train.csv')\ntest=pd.read_csv('../input/count-the-number-of-faces-present-in-an-image/test.csv')\n\nImages='../input/count-the-number-of-faces-present-in-an-image/train/image_data/'\n# Glob the directories and get the lists of train and test images\nimg = glob(Images + '*')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute at the number of images:\nprint('Total Number of images is {}'.format(len(img)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of image in train data are {}'.format(train.shape[0]))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of image in test data are {}'.format(test.shape[0]))\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What's in the bbox_train.csv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bbox=pd.read_csv('../input/count-the-number-of-faces-present-in-an-image/train/bbox_train.csv')\nbbox.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- These are the box dimensions around the faces.\n- Let's merge the data set and then see a sample of image with bounding boxes. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge all train images with the bounding boxes dataframe\n\ntrain_images = train.merge(bbox, on='Name', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_images.isnull().sum())\nprint(train_images.shape)\ntrain_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Let's plot some image examples:\n\ntrain_images.iloc[2].Name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First we store all the box dimensions.\ndef get_all_bboxes(df, image_id):\n    image_bboxes = df[df.Name == image_id]\n    \n    bboxes = []\n    for _,row in image_bboxes.iterrows():\n        bboxes.append((row.xmin, row.ymin, row.xmax, row.ymax))\n        \n    return bboxes\n\n# function for box representation on the image.\n\ndef plot_image_with_box(df, rows=3, cols=4, title='Face count images'):\n    fig, axs = plt.subplots(rows, cols, figsize=(20,15))\n    for row in range(rows):\n        for col in range(cols):\n            idx = np.random.randint(len(df), size=1)[0]\n            img_id = df.iloc[idx].Name\n            \n            img = Image.open(Images + img_id)\n            axs[row, col].imshow(img)\n            \n            bboxes = get_all_bboxes(df, img_id)\n            \n            for bbox in bboxes:\n                rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=2,edgecolor='g',facecolor='none')\n                axs[row, col].add_patch(rect)\n            \n            axs[row, col].axis('off')\n            \n    plt.suptitle(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_image_with_box(train_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Important points\n\n- Here we can see that the ```bounding boxes``` data is not only around the face but it also covers other body portion. But the __number of bounding boxes is equivalent__ to the number of __faces__ in the image. \n\n- Here we can see images are take into different lighting condition, and persons have different facial expression in the images. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Count the number of faces or bounding boxes \n\n        - That's what we need to predict for the test images.\n        ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- This data is already given but here we are creating a function for bounding box and counting the bounding box we will predict the number of faces in an Image.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute the number of bounding boxes per train image\n# train_images['count'] = train_images.loc[:,train_images.columns !='HeadCount'].apply(lambda row: 1 if np.isfinite(row.width) else 0, axis=1)\n\n\n# train_images_count = train_images.loc[:,train_images.columns !='HeadCount'].groupby('Name').sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_images_count['HeadCount']=train['HeadCount']\n# train_images_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(train_images_count.Name.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we see the count is equivalent to the HeadCount or we can call it as ```FACECOUNT```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# See this article on how to plot bar charts with Bokeh:\n# https://towardsdatascience.com/interactive-histograms-with-bokeh-202b522265f3\n\ndef hist_hover(dataframe, column, colors=[\"#94c8d8\", \"#ea5e51\"], bins=30, title=''):\n    hist, edges = np.histogram(dataframe[column], bins = bins)\n    \n    hist_df = pd.DataFrame({column: hist,\n                             \"left\": edges[:-1],\n                             \"right\": edges[1:]})\n    hist_df[\"interval\"] = [\"%d to %d\" % (left, right) for left, \n                           right in zip(hist_df[\"left\"], hist_df[\"right\"])]\n\n    src = ColumnDataSource(hist_df)\n    plot = figure(plot_height = 400, plot_width = 600,\n          title = title,\n          x_axis_label = 'Faces in image',\n          y_axis_label = \"Count\")    \n    plot.quad(bottom = 0, top = column,left = \"left\", \n        right = \"right\", source = src, fill_color = colors[0], \n        line_color = \"#35838d\", fill_alpha = 0.7,\n        hover_fill_alpha = 0.7, hover_fill_color = colors[1])\n        \n    hover = HoverTool(tooltips = [('Interval', '@interval'),\n                              ('Count', str(\"@\" + column))])\n    plot.add_tools(hover)\n    \n    output_notebook()\n    show(plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_hover(train_images, 'HeadCount', title='Number of faces per image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train_images\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['x_center'] = df['xmin'] + df['width']/2\ndf['y_center'] = df['ymin'] + df['height']/2\ndf['classes'] = 0\n\n\ndf['image_id']=df['Name'].str.replace('.jpg','')\n\ndf = df[['image_id','xmin', 'ymin', 'width', 'height','x_center','y_center','classes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recreation of YOLOv5 model for Face Detection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## First and Farmost \n\n### Data ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> (Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, clear_output  # to display images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import required dependencies\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom tqdm.auto import tqdm\nimport shutil as sh\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Clone the github repo\n\n1.👌 Settings > Internet (set on)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/AIVenture0/yolov5.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for the cloned repo\n!ls -R","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# move all the files of YOLOv5 to current working directory\n!mv yolov5/* ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for all the files in the current working directory\n!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Install Dependencies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -r requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # read the training data.\n\n\n# df = pd.read_csv('../input/global-wheat-detection/train.csv')\n# bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n# for i, column in enumerate(['x', 'y', 'w', 'h']):\n#     df[column] = bboxs[:,i]\n# df.drop(columns=['bbox'], inplace=True)\n# df['x_center'] = df['x'] + df['w']/2\n# df['y_center'] = df['y'] + df['h']/2\n# df['classes'] = 0\n# from tqdm.auto import tqdm\n# import shutil as sh\n# df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count\nindex = list(set(df.image_id))\nlen(index)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Creation\n\n\n- To work with the yolo you need to frame your data in to a particular formate.Because that's how yolo is designed.\n\n> Formate\n\n- converter(main directory)\n    - val2017\n        - labels (contains all the box dimensions)\n        - images (contains images)\n    - train2017\n        - labels\n        - images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# code to transform the dataset.\n\nsource = 'train'\nif True:\n    for fold in [0]:\n        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n        for name,mini in tqdm(df.groupby('image_id')):\n            if name in val_index:\n                path2save = 'val2017/'\n            else:\n                path2save = 'train2017/'\n            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n                row = mini[['classes','x_center','y_center','width','height']].astype(float).values\n                row = row/1024\n                row = row.astype(str)\n                for j in range(len(row)):\n                    text = ' '.join(row[j])\n                    f.write(text)\n                    f.write(\"\\n\")\n            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n            sh.copy(\"../input/count-the-number-of-faces-present-in-an-image/{}/image_data/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/count-the-number-of-faces-present-in-an-image/train\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !ls ./convertor\n\n!ls ./convertor/fold0/labels/train2017/12433.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Training Custom YOLOv5 Detector for Wheat Head\n\nAgain i am saying if you actually want to understand all the concepts of YOLOv5 with deeper intution check [Beginners Notebook On YOLOv5](https://www.kaggle.com/vin1234/gettingstarted-with-yolov5-global-wheat-detection).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# As i am running it for just trial(To save training time and GPU ) \n# So i am considering all the training factors to a limited extent.\n\n# Play with all featuers and see their performance.\n\n\n# !python train.py --img 1024 --batch 20 --epochs 10 --data ../input/yaml-file-for-face-count-data-model/face_count.yaml --cfg ../input/yaml-file-for-face-count-data-model/yolov5x.yaml --name yolov5x_fold0_new\n\n\n!python ./train.py --img 640 --batch 3 --epochs 20 --data ../input/yaml-file-for-face-count-data-model/face_count.yaml --cfg ../input/yaml-file-for-face-count-data-model/yolov5x.yaml --name yolov5x_fold0_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Run Inference With Trained Weights","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# trained weights are saved by default in the weights folder\n%ls weights/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!python ./detect.py --weights ./weights/last_yolov5x_fold0_new.pt --img 640 --conf 0.4 --source ./convertor/fold0/images/val2017","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Output will look something like this.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will work from your end when you edit this notebook and run it.\nImage(filename='/kaggle/working/inference/output/16800.jpg', width=400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(filename='/kaggle/working/inference/output/10185.jpg', width=400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(filename='/kaggle/working/inference/output/10118.jpg', width=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model prediction is not much appriciable.\n\n- Till now i totally consumed my weekly gpu quota. \n- I leave all up to you guys to practice and and try out different parameters to achieve better result.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"-------------------Let me know in the comment section about your results-----------------------------------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}