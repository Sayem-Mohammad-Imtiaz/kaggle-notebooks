{"cells":[{"metadata":{},"cell_type":"markdown","source":"## FIFA Decision Tree from scratch\nI'm going to use the FIFA player dataset in order to build a decision tree.<br>\nI will first analyse the data and than chose the features and targets.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# List of content\n\n1. [Exploratory Analysis](#exploratory)\n1. [Implementation](#implementation)\n2. [Analyze Results](#results)\n3. [Random Players Test](#test)\n4. [Resources](#resources)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img align=left width='500px' src='https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Flag_of_FIFA.svg/1024px-Flag_of_FIFA.svg.png' />","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"exploratory\"></a>\n# Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nfrom collections import Counter\nfrom random import seed\nfrom math import sqrt\nfrom random import randrange\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 7 csv files in the current version of the dataset:\n","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Distribution graphs (histogram/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you're ready to read in the data and use the plotting functions to visualize the data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Let's check 1st file: /kaggle/input/players_15.csv","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df15 = pd.read_csv('/kaggle/input/players_15.csv', delimiter=',', encoding='utf8')\ndf15.dataframeName = 'players_15.csv'\n\ndf16 = pd.read_csv('/kaggle/input/players_16.csv', delimiter=',', encoding='utf8')\ndf16.dataframeName = 'players_16.csv'\n\ndf17 = pd.read_csv('/kaggle/input/players_17.csv', delimiter=',', encoding='utf8')\ndf17.dataframeName = 'players_17.csv'\n\ndf18 = pd.read_csv('/kaggle/input/players_18.csv', delimiter=',', encoding='utf8')\ndf18.dataframeName = 'players_18.csv'\n\ndf19 = pd.read_csv('/kaggle/input/players_19.csv', delimiter=',', encoding='utf8')\ndf19.dataframeName = 'players_19.csv'\n\ndf20 = pd.read_csv('/kaggle/input/players_20.csv', delimiter=',', encoding='utf8')\ndf20.dataframeName = 'players_20.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df15, df16, df17, df18, df19, df20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove duplicates and take the mean\ndf = df.groupby('short_name').mean().reset_index()\ndf.dataframeName = 'fifa_players'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a quick look at what the data looks like:","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skills_df = df[['pace', 'shooting', 'passing', 'dribbling', 'overall']]\nskills_df.dataframeName = 'fifa_players'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skills_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotCorrelationMatrix(skills_df, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the correlation table,<br>\nFeatures(X_train): shooting, passing, dribbling.\nTarget(y_train): overall","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df = df[['shooting', 'passing', 'dribbling', 'overall']]\nx_df = x_df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_iloc = x_df[(x_df['overall'] >= 80) & (x_df['overall'] < 100)].index.values\nmedium_iloc = x_df[(x_df['overall'] >= 50) & (x_df['overall'] < 80)].index.values\nlow_iloc = x_df[x_df['overall'] < 50].index.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df.loc[high_iloc, 'overall'] = 2.0\nx_df.loc[medium_iloc, 'overall'] = 1.0\nx_df.loc[low_iloc, 'overall'] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shooting_mean = x_df['shooting'].mean()\nshooting_std = x_df['shooting'].std()\n\npassing_mean = x_df['passing'].mean()\npassing_std = x_df['passing'].std()\n\ndribbling_mean = x_df['dribbling'].mean()\ndribbling_std = x_df['dribbling'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df['shooting'] = (x_df['shooting'] - shooting_mean) / shooting_std\nx_df['passing'] = (x_df['passing'] - passing_mean) / passing_std\nx_df['dribbling'] = (x_df['dribbling'] - dribbling_mean) / dribbling_std","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"implementation\"></a>\n# Implementation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def entropy(y):\n    hist = np.bincount(y)\n    ps = hist / len(y)\n    return -np.sum([p * np.log2(p) for p in ps if p > 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Node:\n\n    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n        self.feature = feature\n        self.threshold = threshold\n        self.left = left\n        self.right = right\n        self.value = value\n\n    def is_leaf_node(self):\n        return self.value is not None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecisionTree:\n\n    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n        self.min_samples_split = min_samples_split\n        self.max_depth = max_depth\n        self.n_feats = n_feats\n        self.root = None\n\n    def fit(self, X, y):\n        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n        self.root = self._grow_tree(X, y)\n\n    def predict(self, X):\n        return np.array([self._traverse_tree(x, self.root) for x in X])\n\n    def _grow_tree(self, X, y, depth=0):\n        n_samples, n_features = X.shape\n        n_labels = len(np.unique(y))\n\n        # stopping criteria\n        if (depth >= self.max_depth\n                or n_labels == 1\n                or n_samples < self.min_samples_split):\n            leaf_value = self._most_common_label(y)\n            return Node(value=leaf_value)\n\n        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n\n        # greedily select the best split according to information gain\n        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n        \n        # grow the children that result from the split\n        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n        return Node(best_feat, best_thresh, left, right)\n\n    def _best_criteria(self, X, y, feat_idxs):\n        best_gain = -1\n        split_idx, split_thresh = None, None\n        for feat_idx in feat_idxs:\n            X_column = X[:, feat_idx]\n            thresholds = np.unique(X_column)\n            for threshold in thresholds:\n                gain = self._information_gain(y, X_column, threshold)\n\n                if gain > best_gain:\n                    best_gain = gain\n                    split_idx = feat_idx\n                    split_thresh = threshold\n\n        return split_idx, split_thresh\n\n    def _information_gain(self, y, X_column, split_thresh):\n        # parent loss\n        parent_entropy = entropy(y)\n\n        # generate split\n        left_idxs, right_idxs = self._split(X_column, split_thresh)\n\n        if len(left_idxs) == 0 or len(right_idxs) == 0:\n            return 0\n\n        # compute the weighted avg. of the loss for the children\n        n = len(y)\n        n_l, n_r = len(left_idxs), len(right_idxs)\n        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])\n        child_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n\n        # information gain is difference in loss before vs. after split\n        ig = parent_entropy - child_entropy\n        return ig\n\n    def _split(self, X_column, split_thresh):\n        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n        return left_idxs, right_idxs\n\n    def _traverse_tree(self, x, node):\n        if node.is_leaf_node():\n            return node.value\n\n        if x[node.feature] <= node.threshold:\n            return self._traverse_tree(x, node.left)\n        return self._traverse_tree(x, node.right)\n\n    def _most_common_label(self, y):\n        counter = Counter(y)\n        most_common = counter.most_common(1)\n        if(len(most_common) > 0):\n            most_common = most_common[0][0]\n        else:\n            most_common = 0.0\n        return most_common   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(y_true, y_pred):\n    accuracy = np.sum(y_true == y_pred) / len(y_true)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = x_df.to_numpy()\n\nX = np.array(dataset[:,:-1], dtype=np.float64)\ny = np.array(dataset[:,-1], dtype=np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTree(max_depth=10)\nclf.fit(X_train, y_train)\n    \ny_pred = clf.predict(X_test)\nacc = accuracy(y_test, y_pred)\n\nprint (\"Accuracy:\", acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"results\"></a>\n# Analyze results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def player_stats_normalized(row):\n    pace = (row[0] - pace_mean) / pace_std\n    shooting = (row[1] - shooting_mean) / shooting_std\n    passing = (row[2] - passing_mean) / passing_std\n    dribbling = (row[3] - dribbling_mean) / dribbling_std\n    \n    return [pace, shooting, passing, dribbling]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def expected_group(overall):\n    if(overall >= 80):\n        return 2.0\n    if(overall >=50):\n        return 1.0\n    else:\n        return 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def player_stats_by_name(name):\n    player_stats = df[['shooting', 'passing', 'dribbling', 'overall']].iloc[df[df['short_name'] == name].index[0]].to_numpy()\n    player_stats_norm = player_stats_normalized(player_stats)\n    player_overall = np.array([expected_group(player_stats[-1])])\n    return np.hstack((player_stats_norm, player_overall))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_by_stats(stats):\n    predicted = clf.predict(stats[:-1].reshape(1,4))[0]\n    expected = stats[-1]\n    return float(predicted), expected","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the decision tree to predict Messi group\nmessi_stats = player_stats_by_name('L. Messi')\npredicted, expected = predict_by_stats(messi_stats)\nprint(\"Predicted \", predicted, \" Expected \", expected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"test\"></a>\n# Random Players Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"players = np.array(df['short_name'].unique())\nnp.random.shuffle(players)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players_overall = [player_stats_by_name(p) for p in players[:25]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_nan(players_name_overall):\n    indexes = []\n    result = None\n    for i, (name, stats) in enumerate(players_name_overall):\n        if(np.isnan(stats).any()):\n            indexes.append(i)\n    result = np.delete(players_name_overall, indexes, axis=0)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players_name_overall = list(map(list, zip(players, players_overall)))\nplayers_name_overall = remove_nan(players_name_overall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players = players_name_overall[:,0]\nplayers_stats = players_name_overall[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = []\nexpected = []\nfor stats in players_stats:\n    pred, expec = predict_by_stats(stats)\n    predicted.append(pred)\n    expected.append(expec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"players_df_stats = df[df['short_name'].isin(players)][['short_name', 'shooting', 'passing', 'dribbling', 'overall']]\nplayers_df_predicted = pd.DataFrame(list(map(list, zip(players, predicted, expected))), columns=[\"short_name\", \"predicted\", \"expected\"])\ndf_final = pd.merge(players_df_stats, players_df_predicted, how='right', on='short_name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', df_final.shape[0]+1)\ndf_final","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resources\"></a>\n# Resources\n\nhttps://www.youtube.com/watch?v=Oq1cKjR8hNo","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Please don't forget to up-vote if you enjoy the reading of this notebook.<br>\nUp-votes are pure motivation into creative notebook creation.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}