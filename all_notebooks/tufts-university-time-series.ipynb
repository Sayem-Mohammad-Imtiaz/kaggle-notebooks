{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering for Time Series Data\n\n### Time Series\n\nA time series is a sequential set of data points, measured typically over successive times. It is mathematically defined as a set of vectors *f(t),t = 0,1,2,*... where *t* represents the time elapsed . The variable *f(t)* is treated as a random variable. The measurements taken during an event in a time series are arranged in a proper chronological order. \n\n   * A time series containing records of a single variable is is termed as **univarite**.\n   * A time series containing records of more than one variable is reffered as **multivarite**\n\n\nA time series can be discrete or continuous. \n\n### Creating Feature from Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pylab as plt\n\nimport matplotlib.dates as mdates\nplt.rcParams['figure.figsize'] = (15.0, 8.0)\nimport pandas as pd\nimport seaborn as sns\n\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n\nimport bokeh as bk","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"energy_data = pd.read_csv(\"../input/house-hold-energy-data/D202.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"energy_data[\"DATE_TIME\"] = pd.to_datetime(energy_data.DATE + \" \" + energy_data[\"END TIME\"])\nenergy_data = energy_data[[\"DATE_TIME\",\"USAGE\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"energy_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Determine Type of Day"},{"metadata":{"trusted":true},"cell_type":"code","source":"energy_data[\"DAY_TYPE\"] = energy_data.DATE_TIME.apply(lambda x: 1 if x.dayofweek > 5 else 0  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"energy_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Impact of Holidays"},{"metadata":{"trusted":true},"cell_type":"code","source":"cal = calendar()\nholidays = cal.holidays(start = energy_data.DATE_TIME.min(),\n                        end = energy_data.DATE_TIME.max())\nenergy_data[\"IS_HOLIDAY\"] = energy_data.DATE_TIME.isin(holidays)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"energy_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Excercise \n\nCreate a feature to represent part of the day such as Morning (M), Noon (N), Evening (E) and Night (N).\n"},{"metadata":{},"cell_type":"markdown","source":"### Target from Time\n\nSometimes we may have to create taget variables from time itself. Such an excercise is required in usecases such as **Survival Models/Predictive Maintainance** ."},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_raw = pd.read_csv(\"../input/phm-2018/05_M02_DC_train.csv\")\nphm_raw.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_raw.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_tgt = pd.read_csv(\"../input/phm-2018/05_M02_train_fault_data.csv\")\nphm_tgt.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_tgt.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_joined = pd.merge(phm_raw,\n                     phm_tgt,\n                     how='left',\n                    on=['time','Tool'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_joined.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phm_joined['time_stamp'] = pd.to_datetime(phm_joined.time,unit='s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(Image(\"../input/pic-nb/1_EXwJYgnAok6XLu1x1l3V_g.png\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)"},{"metadata":{},"cell_type":"markdown","source":"## Excercise \n\nCreate Time to failure bases on the filure time.\n\nTip!\n\nFor each observation in the uptime duration sustract the failure time !\n\n\n# Let's Nuke the Plan!!!\n\nData Source - https://www.kaggle.com/imeintanis/collision-detection-ai-using-vibration-data "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/collision-detection-ai-using-vibration-data/train_features.csv\")\ntrain_target = pd.read_csv(\"/kaggle/input/collision-detection-ai-using-vibration-data/train_target.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport sklearn as sl\nimport scipy as sp\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_data(accelaration_df : pd.DataFrame,features : list, title : str) -> None:\n    \"\"\" Plot the accelaration data\n        :params accelaration_df: accelaration data for one id\n        :params title: string\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,6))\n    fig.tight_layout(pad=10.0)\n    fig.suptitle(title)\n    \n    for idx,feature in enumerate(features):\n        ax = fig.add_subplot(2,2,idx+1)\n        accelaration_df[feature].plot(kind='line',\n                                     title = title + \" \" + feature,\n                                     ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats_to_plot = [\"S1\",\"S2\",\"S3\", \"S4\"]\nplot_data(train_data[train_data.id == 0],feats_to_plot,\"Accelaration Params\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What is the Challenge Here!\n\nOne record != one sample "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data.id == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## How to approach Feature Engineering\n\n### Fourier Transform\n\nOne of the prominent methods to approach signal data is to apply forurier transformation in the data. The Fourier transformed data can be used for training a model."},{"metadata":{"trusted":true},"cell_type":"code","source":"fs = 5 #sampling frequency\nfmax = 25 #sampling period\ndt = 1/fs #length of signal\nn = 75\n\ndef fft_features(data_set : pd.DataFrame) -> np.ndarray:\n    \"\"\" Convert the dataset to fourier transfomed\n        :params data_set: original collider params data\n        :returns ft_data: Fourier transformed data\n        #Reference - https://dacon.io/competitions/official/235614/codeshare/1174\n    \"\"\"\n    ft_data = list()\n    \n    features = [\"S1\",\"S2\",\"S3\", \"S4\"]\n    \n    id_set = list(data_set.id.unique())\n    \n    for ids in tqdm(id_set):\n        s1_fft = np.fft.fft(data_set[data_set.id==ids]['S1'].values)*dt\n        s2_fft = np.fft.fft(data_set[data_set.id==ids]['S2'].values)*dt\n        s3_fft = np.fft.fft(data_set[data_set.id==ids]['S3'].values)*dt\n        s4_fft = np.fft.fft(data_set[data_set.id==ids]['S4'].values)*dt\n        \n        ft_data.append(np.concatenate([np.abs(s1_fft[0:int(n/2+1)]),\n                                       np.abs(s2_fft[0:int(n/2+1)]),\n                                       np.abs(s3_fft[0:int(n/2+1)]),\n                                       np.abs(s4_fft[0:int(n/2+1)])]))\n    \n    return np.array(ft_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fft = fft_features(train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Alternative Fature Engineering\n\nAn alternative approach in feature engineering is to aggregate the features and compute key statistics such as mean, median, standard deviation, minimum value, and skew."},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_agg_feats(data_set : pd.DataFrame) -> pd.DataFrame:\n    \"\"\" Create aggrage features from the data\n        :param data_set: Base data as DataFrame\n        :returns agg_data: Aggragated DataFrame\n    \"\"\"\n    \n    max_feats = data_set.groupby(['id']).max().add_suffix('_max').iloc[:,1:]\n    min_feats = data_set.groupby(['id']).min().add_suffix('_min').iloc[:,1:]\n    mean_feats = data_set.groupby(['id']).mean().add_suffix('_mean').iloc[:,1:]\n    std_feats = data_set.groupby(['id']).std().add_suffix('_std').iloc[:,1:]\n    median_feats = data_set.groupby(['id']).median().add_suffix('_median').iloc[:,1:]\n    skew_feats = data_set.groupby(['id']).skew().add_suffix('_skew').iloc[:,1:]\n    \n    agg_data = pd.concat([max_feats,min_feats,\n                          mean_feats,std_feats,median_feats,skew_feats],\n                        axis=1)\n    \n    return agg_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_train = generate_agg_feats(train_data)\nagg_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Challenge\n\nBuild regression model for the collider parameter detection!!"},{"metadata":{},"cell_type":"markdown","source":"## Reference\n\nPHM 2018 Data - https://www.phmsociety.org/events/conference/phm/18/data-challenge\n\nHydrogen Collider Data - https://www.kaggle.com/jaganadhg/atomicai-starter \n\nElectricity Usage Data - https://www.kaggle.com/jaganadhg/house-hold-energy-data "},{"metadata":{"trusted":true},"cell_type":"code","source":"Reference","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}