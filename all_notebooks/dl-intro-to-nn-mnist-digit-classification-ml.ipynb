{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference Blogs\n\n**Interactive CNN**\n\n* **Interactice Convolution Neural Network on MNIST -** https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html\n\n* **Interactive CNN with CIFAR-10 dataset -** https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\n\n* **Toy 2D data set classification using CNN -** https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html\n\n**Blogs to follow for Computer Vision**\n\n* **Computer Vision for Dummies -** https://www.visiondummy.com/\n\n* **Learn OpenCV -** https://www.learnopencv.com/\n\n* **Tombone's CV blog -** https://www.computervisionblog.com/\n\n* **Andrez Karpathy Blog -** http://karpathy.github.io/\n\n* **AI Shack Blog -** https://aishack.in/\n\n* **Computer Vision Talks -** https://computer-vision-talks.com/","metadata":{}},{"cell_type":"markdown","source":"# <center> Case Study on Image Classification:","metadata":{}},{"cell_type":"markdown","source":"\n# Context:\n- We are given a **dataset** which contains image data. \n- The data contains **pixel values** of the images in csv format. \n- Each image represents one of the number from 0, 1, 2, ..., 8, 9. So there are 10 possible outcomes for each row of data. As the data contains the pixel values of the image in each row. \n- Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. \n- Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning lighter shade. \n- This pixel-value is an integer between 0 and 255, inclusive.\n- The data set has 785 columns. \n- The first column, called \"label\", is the digit which is in the image. \n- *The* rest of the columns contain the pixel-values of the associated image.","metadata":{"id":"ZibhRtQ2DzPP"}},{"cell_type":"code","source":"28 * 28","metadata":{"id":"860yaTYrqS4U","outputId":"765a5711-ce06-42ff-f855-bf6106cdd5f3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Problem:\n- Classify the image based on the pixel value.\n- The result of the model should be the number which is represented by the pixel values.\n- Use Supervised Learning method for it.","metadata":{"id":"hQp3fAsEHRt_"}},{"cell_type":"markdown","source":"# Data:\n- **label:** A value between 0 and 9. Both inclusive. Total 10 unique values.\n- **pixel0, pixel1, pixel2, ..., pixel782, pixel783:** Each value in these columns is between 0 and 255. Which represents the pixel intensity. ","metadata":{"id":"H37yWAWZHqT0"}},{"cell_type":"code","source":"# ! pip install opencv-python","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"ovA48OkpDrLc","outputId":"4a838340-6dd3-4631-9edc-d42d996a3f0d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Loading the data\n- We use panda's read_csv to read train.csv into a dataframe.\n- Then we separate our images and labels for supervised learning.\n- We also do a train_test_split to break our data into two sets, one for training and one for testing. This let's us measure how well our model was trained by later inputting some known test data.","metadata":{"id":"gVbd_vGsDrLh"}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/d/aggarwalrahul/dl-intro-to-nn/dataset.csv')    # Load the dataset by providing the path to the file.","metadata":{"id":"watsLCCsDrLi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"0dOe_Ps--jQb","outputId":"15e4780e-a660-45b4-a2e6-66969f32a8f3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"id":"6vjl-ggHQE0B","outputId":"27f51120-17ab-4eda-c808-0afc1f3d6468","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The labels for images.\ny = data[\"label\"]","metadata":{"id":"TwpHt4vIDrLl","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see some of the labels.","metadata":{"id":"5OnmCx6iemTR"}},{"cell_type":"code","source":"print(y[0])               # Label for 1st image.\nprint(y[2000])            # Label for 2001st image.","metadata":{"id":"q7ecDtEseqPL","outputId":"5c1ddd16-51c1-471f-b7c2-7ccb732c77f5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Data Preparation\n\n**Add on:**\n\nWhat should we do to prepare the data according to the model input?\n\nLet's see in the next steps.","metadata":{"id":"iBOj8RpafAD8"}},{"cell_type":"code","source":"# Drop 'label' column.\nX = data.drop(labels = [\"label\"], axis = 1)","metadata":{"id":"3qHkPllCDrLn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y[0])               # Label for 1st image.\nprint(y[2000])            # Label for 2001st image.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=2000\nimg = X.iloc[i].values\nimg = img.reshape((28,28))\nplt.imshow(img, cmap='gray')\nplt.title(y[i]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Think about it:\n\nWhy did we drop the labels from the data and saved it into new variable \"X\"?","metadata":{"id":"qoKrchkGfZDZ"}},{"cell_type":"markdown","source":"## Think about it:\n\nDo we know, how the data distribution looks like across all the numbers?\n\ni.e. We need to know the images corresponding to each number.","metadata":{"id":"iENhNh4kfjm8"}},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.countplot(x=y);","metadata":{"id":"Vz3bmnIWDrLq","outputId":"52df683f-959d-4fd1-f731-6df030541cea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight -** We can see from the above plot that the data is evenly distributed among all the classes (from 0, 1, 2, ..., 8, 9). So, the dataset is perfectly balanced.","metadata":{"id":"YghaEzSV0_MN"}},{"cell_type":"markdown","source":"### 3. Check for Null and Missing Values","metadata":{"id":"B5wTnQZ2DrLt"}},{"cell_type":"code","source":"# Check the data\nX.isnull().sum()","metadata":{"id":"7MSX5S1DDrLu","outputId":"5053d188-5019-4fe1-ce67-d90d30fc615f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights** We checked for corrupted images (missing values inside) - There are no missing values in the dataset. So we can safely go ahead.","metadata":{"id":"xCdXjZaTDrLx"}},{"cell_type":"markdown","source":"### 4. Normalization [Depends upon the Algorithm]\n* We perform a grayscale normalization to reduce the effect of illumination's differences.\n\n* https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/","metadata":{"id":"Kbp9tbJ5DrLy"}},{"cell_type":"code","source":"# Normalize the data\nX = X.astype('float32') / 255.0","metadata":{"id":"dCiHsJ5eDrLy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Train and Test Split","metadata":{}},{"cell_type":"code","source":"X = X.values # Convert the features (pixel values) to numpy array to feed into the supervised learning model.\ny = y.values # Convert the labels to numpy array to feed into the supervised learning model.","metadata":{"id":"fzXfwxBbLe-I","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into test and train to build the model.\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)","metadata":{"id":"croSzfCaDrL1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(X_train) # As we can see that the data to be fed into model is of the type numpy array.","metadata":{"id":"BSpJiuyeKl2B","outputId":"fba769ff-f88e-4533-ab18-3f1933e396c9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can get a better sense for one of these examples by visualising the image and looking at the label.","metadata":{"id":"XSiKBnaoDrL3"}},{"cell_type":"markdown","source":"### 6. Viewing an Image\n- Since the image is currently one-dimension, we load it into a numpy array and reshape it so that it is two-dimensional (28x28 pixels)\n- Then, we plot the image and label with matplotlib\n\n* You can change the value of variable i to check out other images and labels.","metadata":{"id":"mBjg8ZrpDrL3"}},{"cell_type":"code","source":"i=10\nimg = X[i]\nimg = img.reshape((28,28))\nplt.imshow(img, cmap='gray')\nplt.title(y[i]);","metadata":{"id":"ogQfrOQJDrL4","outputId":"f24f2432-da8e-4e36-b576-e90e9d9c0d84","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add-on:\n- What is `X[i]`'s shape?\n- How to reshape the whole array instead of just one row?\n- What's the shape of the reshaped array?","metadata":{"id":"RylRXwz1SF6I"}},{"cell_type":"markdown","source":"* In the original data, the pixel values were in a 1-Dimensional array.\n* We converted that 1-D array of 784 pixel values into an 2-D array of shape (28 X 28).\n* Note that 28 multiplied by 28 is equal to 784.\n* As each pixel value represents dark or white spot, when we plot the 28x28 pixel's array, we get the above image.\n* So, it validates the fact that image can be represented by an numpy array.\n* Each value of the above numpy array represents a pixel, which has value between 0 and 255.","metadata":{"id":"9z-Rvd7r2Iax"}},{"cell_type":"markdown","source":"### 7. Examining the Pixel Values:\n- Note that these images aren't actually black and white (0,1). They are gray-scale (0-255).\n- A histogram of this image's pixel values shows the range.","metadata":{"id":"C924HqB4DrL6"}},{"cell_type":"code","source":"plt.figure(figsize=(10,7), edgecolor='blue')\n\nn, bins, patches = plt.hist(X[9], bins=10, range=(0.0, 1.0))\nplt.xlabel('Pixel value')\nplt.ylabel('Number of Pixels')\nplt.title('Histogram of Pixel values')\nplt.show();","metadata":{"id":"tR-VjkaNDrL6","outputId":"797df553-3dcc-437f-c351-a6efd2a0d49f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Think about it:\n\n- What does the height = 641 mean?\nSimilarly other height values in the result.\n- The width is same for all = 0.1","metadata":{"id":"NhxIuw6KqojM"}},{"cell_type":"markdown","source":"* From above histogram, we can see that the there are more number of pixels which have value equal to zero. \n* Zero value represents black pixel.\n* From the image we saw before, we observed that the black portion of image was more than the white portion.\n* It confirms that white pixel is represented by value equal to 1.","metadata":{"id":"vW9K3euq3Mu-"}},{"cell_type":"markdown","source":"----------------------------------------------------","metadata":{"id":"E9bilMJ-r4T6"}},{"cell_type":"markdown","source":"## Think about it:\n\n- What should be our next step while understanding about the images?","metadata":{"id":"rG2-SgSoromK"}},{"cell_type":"markdown","source":"### 8. Training our model\n- First, we use the sklearn.ensemble module to create a **random forest classifier**.\n- Next, we pass our training images and labels to the classifier's fit method, which trains our model.\n- Finally, the test images and labels are passed to the score method to see how well we trained our model. Score will return a float between 0-1 indicating our accuracy on the test data set\n\n* Try playing with the parameters of RandomForestClassifier() to see how the results change.","metadata":{"id":"UhuCU0WZDrL9"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"?RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random forest model creation\nclf = RandomForestClassifier(random_state=190,verbose=False,n_estimators=201,n_jobs=8,max_depth=8)","metadata":{"id":"sTlKVDJXSPS5","outputId":"fc51f0ee-61ce-4790-fd3a-4f0d9fad426e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred_cl=clf.predict(X_test)\ntrain_pred_cl","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.score(X_test, y_test)","metadata":{"id":"z8wJbZO4DrL9","outputId":"79cd67cc-f586-4eef-f2a3-42b8c8a3633e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(X_test)\ny_pred","metadata":{"id":"-2VlLptZOz-l","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" How did our model do?\n- You should have gotten around 0.9376, or **93.76% accuracy**. This is good.","metadata":{"id":"mNzzpIh0DrL_"}},{"cell_type":"code","source":"i=0\nimg = X_test[i]\nimg = img.reshape((28,28))\nplt.imshow(img, cmap='gray')\nplt.title(y_pred[i]);","metadata":{"id":"-KiepNei7Y5X","outputId":"b7bfc539-9993-4cdb-da1e-6d816d210a5a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix","metadata":{"id":"F31G4fDUDrMF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"=== Confusion Matrix ===\")\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","metadata":{"id":"GFssUSxGOtEp","outputId":"8c848c2d-c53a-4a25-d882-8e2f15b75382","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cm = pd.DataFrame(cm, index = [i for i in \"0123456789\"],\n                     columns = [i for i in \"0123456789\"])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, fmt='d');","metadata":{"id":"4akqR7KmRsC1","outputId":"0927b124-cd27-479c-ec3c-09b9ce36f9a6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"=== Classification Report ===\")\nprint(classification_report(y_test, y_pred))","metadata":{"id":"Am6wEwLARqnv","outputId":"08cc3bbe-0465-409a-f5fa-b036258b8fc4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insights** So, we got a pretty good accuracy on classification of the images of digits, as the classification report shows.","metadata":{"id":"b0qtAzjCTCpa"}},{"cell_type":"markdown","source":"## Please Note:\nNEVER loop through a numpy array or pandas df! Use vectorized operations instead!\nhttps://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html","metadata":{"id":"P8S4oJhiXj6i"}},{"cell_type":"markdown","source":"### So, we got a pretty good accuracy on classification of the images of digits, as the classification report shows.\n\n# Session Summary\n- The images can be represented using numpy array.\n- If the array is 1-D, then we can visualize the image after reshaping the array to suitable shape. In this case we converted it to 2-D array.\n- We visualized the image by plotting the numpy array using matplotlib.\n- After that we saw that the pixel values' distribution in histogram, the black pixel's value is zero, and the white pixel's value is 1. These values are after normalization of pixel values, i.e. after dividing each value by 255.\n- We used RandomForestClassifier as supervised classification method.","metadata":{"id":"84I_Zi2g6n6_"}}]}