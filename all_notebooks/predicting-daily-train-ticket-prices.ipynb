{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RepeatedKFold \nfrom sklearn.tree import DecisionTreeRegressor  \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/spanish-high-speed-rail-system-ticket-pricing/renfe.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA UNDERSTANDING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Travel ticket breakdowns for PONFERRADA - MADRID route \ndata.groupby(['origin',\"destination\",\"start_date\",\"end_date\",\"train_type\",\"train_class\",\"fare\"]).count().loc[\"PONFERRADA\"].groupby([\"train_type\",\"train_class\",\"fare\"]).count().head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA CLEANING AND MANIPULATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the columns that have null values in their rows\ndata.columns[data.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding percentage of null values comparing to entire dataframe\ntotal_row_count = data['insert_date'].count()\nprint(\"Total rows:\",total_row_count)\nNull_values=data[['price','train_class','fare']].isnull().sum() / total_row_count *100\nNull_values.to_frame().rename(index={\"price\":\"Price\",\"train_class\":\"Train Class\",\"fare\":\"Fare\"},columns={0:\"Percentage of null values\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing null values from dataframe\ndata = data.dropna()\ndata.columns[data.isnull().any()]\nprint(\"Total rows without null values:\",data[\"insert_date\"].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting string date values into datetime values\ndata['start_date'] = pd.to_datetime(data['start_date'])\ndata['end_date'] = pd.to_datetime(data['end_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting distance values in hours into seconds\ndata['Duration'] = data['end_date'] - data['start_date']\ndata['Duration'] = data['Duration'].dt.total_seconds()\ndata['Date'] = data['start_date'].dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating mean of price and duration based on the grouped indexes\ndata_one_train_per_day = data.groupby([\"Date\",\"train_class\",\"train_type\",\"fare\",\"origin\",\"destination\"])['price','Duration'].mean().reset_index()\nnumber_of_days_per_each_class = data_one_train_per_day.groupby([\"train_class\",\"train_type\",\"fare\",\"origin\",\"destination\"]).count().reset_index();number_of_days_per_each_class.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eliminating the rows whose Date values is smaller than 90 (below 90 sample is not sufficient) and removing 3 columns\nrow_deduction_data = number_of_days_per_each_class[number_of_days_per_each_class[\"Date\"]>=90]\nrow_deduction_data = row_deduction_data.drop(columns=['Date','price','Duration'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging our deducted data  \ndata_one_train_per_day = pd.merge(data_one_train_per_day, row_deduction_data, on=[\"train_class\",\"train_type\",\"fare\",\"origin\",\"destination\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_categories = data_one_train_per_day.groupby([\"train_class\",\"train_type\",\"fare\",\"origin\",\"destination\"]).count().reset_index() \ndata_one_train_per_day['Ori_Des'] = data_one_train_per_day['origin'] + '_' + data_one_train_per_day['destination']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VISUALIZATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing that the price is not stationary but it is moving - Just for one unique combination\nvisualiz_data = data[(data['origin']==\"BARCELONA\") & (data['destination']==\"MADRID\") & (data['train_type']==\"AVE\")\n& (data['train_class']==\"Turista\")\n& (data['fare']==\"Flexible\")]\nsns.lineplot(x=\"Date\", y=\"price\", data=visualiz_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of trains each day between cities\nx_values = np.arange(len(data_one_train_per_day.Ori_Des.value_counts().values))\ny_values = data_one_train_per_day.Ori_Des.value_counts().values\ncity_names = data_one_train_per_day.Ori_Des.value_counts().index\ndf = pd.DataFrame({'Number of train journeys per route': y_values},index=city_names)\ndf.plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OUTLIER ELIMINATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data_without_outlier = pd.DataFrame()\nfor i in range(len(train_categories)):\n    train_class=train_categories.iloc[i].train_class\n    train_type=train_categories.iloc[i].train_type\n    fare=train_categories.iloc[i].fare\n    origin=train_categories.iloc[i].origin\n    destination=train_categories.iloc[i].destination\n    \n    outlier_detection_data = data_one_train_per_day[(data_one_train_per_day['train_class']==train_class) &\n                          (data_one_train_per_day['train_type']==train_type) &\n                          (data_one_train_per_day['fare']==fare) &\n                          (data_one_train_per_day['origin']==origin) &\n                          (data_one_train_per_day['destination']==destination)].copy()\n    \n    mean = outlier_detection_data['price'].mean()\n    std = outlier_detection_data['price'].std()\n    outlier_detection_data['IsOutlier'] = np.where((outlier_detection_data['price'] < (mean + 2*std)) \n                                                   & (outlier_detection_data['price'] > (mean - 2*std))\n                                                   , 0, 1)\n    \n    outlier_detection_data['price'] = np.where(outlier_detection_data['IsOutlier']==1 , mean , outlier_detection_data['price'])\n    main_data_without_outlier = main_data_without_outlier.append(outlier_detection_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELS"},{"metadata":{},"cell_type":"markdown","source":"# 1 - MOVING AVERAGE (BASELINE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"moving_average_parameter = 5\nmain_data_moving_ave = pd.DataFrame()\n\nfor i in range(len(train_categories)):\n    train_class=train_categories.iloc[i].train_class\n    train_type=train_categories.iloc[i].train_type\n    fare=train_categories.iloc[i].fare\n    origin=train_categories.iloc[i].origin\n    destination=train_categories.iloc[i].destination\n\n    ma_data = main_data_without_outlier[(main_data_without_outlier['train_class']==train_class) &\n                          (main_data_without_outlier['train_type']==train_type) &\n                          (main_data_without_outlier['fare']==fare) &\n                          (main_data_without_outlier['origin']==origin) &\n                          (main_data_without_outlier['destination']==destination)].copy()\n    \n    ma_data = ma_data.sort_values('Date')\n    ma_data['MovingAverage'] = ma_data.price.rolling(window=moving_average_parameter).sum()\n    ma_data['MovingAverage'] = ma_data['MovingAverage'] - ma_data['price']\n    ma_data['MovingAverage'] = ma_data['MovingAverage'] / (moving_average_parameter-1)\n    main_data_moving_ave = main_data_moving_ave.append(ma_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Moving average vs actual price over time\nma_data_graph = main_data_moving_ave[main_data_moving_ave['MovingAverage'].notnull()]\nma_data_graph = ma_data_graph[(ma_data_graph['origin']==\"BARCELONA\") & (ma_data_graph['destination']==\"MADRID\") & (ma_data_graph['train_type']==\"AVE\")\n& (ma_data_graph['train_class']==\"Turista\")\n& (ma_data_graph['fare']==\"Flexible\")]\n\nplt.plot( 'Date', 'price', data=ma_data_graph, markerfacecolor='blue', color='skyblue', linewidth=1)\nplt.plot( 'Date', 'MovingAverage', data=ma_data_graph, color='olive', linewidth=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding mean absolute percentage error for predicted output with moving average model\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\nma_actual_values = main_data_moving_ave[main_data_moving_ave['MovingAverage'].notnull()].price\nma_actual_pred = main_data_moving_ave[main_data_moving_ave['MovingAverage'].notnull()].MovingAverage\nmean_absolute_percentage_error(ma_actual_values,ma_actual_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 - LINEAR REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make the categorical values binary/numerical for linear regression\nmain_data_lm = main_data_moving_ave.copy()\ndummy_columns = pd.get_dummies(main_data_moving_ave[['fare','train_type','train_class','origin','destination']])\nmain_data_lm = pd.concat([main_data_lm, dummy_columns], axis=1, ignore_index=False)\nmain_data_lm['Duration_for_model'] = main_data_lm['Duration']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = main_data_lm.iloc[:,11:].values\nY = main_data_lm.iloc[:,6].values\n# TRAIN/TEST SPLIT\nX_train,X_test,Y_train,Y_test,duration_train,duration_test = train_test_split(X,Y,main_data_moving_ave[\"Duration\"],test_size=0.2,random_state=5)\n# MODEL FITTING\nmodel = LinearRegression()\nmodel = model.fit(X_train, Y_train)\ny_pred = model.predict(X_test)\n#R-squared\ntest_score = model.score(X_test, Y_test);test_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding mean absolute percentage error for predicted output with linear regression model\nerrors = abs(y_pred - Y_test)\nnp.mean(errors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3 - SUPPORT VECTOR REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data_lm = main_data_moving_ave.copy()\ndummy_columns = pd.get_dummies(main_data_moving_ave[['fare','train_type','train_class','origin','destination']])\nmain_data_lm = pd.concat([main_data_lm, dummy_columns], axis=1, ignore_index=False)\nmain_data_lm['Duration_for_model'] = main_data_lm['Duration']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = main_data_lm.iloc[:,11:].values\nY = main_data_lm.iloc[:,6].values\n# TRAIN/TEST SPLIT\nX_train,X_test,Y_train,Y_test,duration_train,duration_test = train_test_split(X,Y,main_data_moving_ave[\"Duration\"],test_size=0.2,random_state=5)\n# MODEL FITTING\nregressor = SVR()\nregressor.fit(X_train, Y_train)\ny_pred = regressor.predict(X_test)\n\nerrors = abs(y_pred - Y_test)\nnp.mean(errors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4 - DECISION TREE"},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data_rf = main_data_moving_ave.copy()\ndummy_columns = pd.get_dummies(main_data_moving_ave[['fare','train_type','train_class','origin','destination']])\nmain_data_rf = pd.concat([main_data_rf, dummy_columns], axis=1, ignore_index=False)\n\nX = main_data_rf.iloc[:,11:].values\nY = main_data_rf.iloc[:,6].values\n\n# BASIC TRAIN/TEST SPLIT\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=5)\ndt=DecisionTreeRegressor()\ndt.fit(X_train, Y_train) \npredictions= dt.predict(X_test)\n\nerrors = abs(predictions - Y_test)\nnp.mean(errors)\n#test_score = dt.score(X_test, Y_test);test_score ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5 - RANDOM FOREST "},{"metadata":{"trusted":true},"cell_type":"code","source":"main_data_rf = main_data_moving_ave.copy()\ndummy_columns = pd.get_dummies(main_data_moving_ave[['fare','train_type','train_class','origin','destination']])\nmain_data_rf = pd.concat([main_data_rf, dummy_columns], axis=1, ignore_index=False)\n\nX = main_data_rf.iloc[:,11:].values\nY = main_data_rf.iloc[:,6].values\n\n# BASIC TRAIN/TEST SPLIT\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=5)\n\n# MODEL FITTING\nrf= RandomForestRegressor(n_estimators = 1000, random_state = 42)\nrf.fit(X_train, Y_train)\npredictions = rf.predict(X_test)\n\n# Finding mean absolute percentage erro\nerrors = abs(predictions - Y_test)\nnp.mean(errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}