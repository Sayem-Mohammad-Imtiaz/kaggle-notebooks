{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom plotly.subplots import make_subplots #Visualizations\nimport plotly.graph_objects as go #visualizations\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n#read CSV and check\ndf=pd.read_csv('../input/retail-store-sales-transactions/scanner_data.csv')\ndf.head()\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clean it up, check it out for clarity","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum() #finds duplicayet rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum() #Finds any null values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Nice, no dupes or missing values\n\n### Lets drop 'Unnamed: 0' columns and go into checking data types","metadata":{}},{"cell_type":"code","source":"df.drop('Unnamed: 0', axis=1, inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets turn Date column into DateTime","metadata":{}},{"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])\ndf.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Nice\n\n## The data we recieved states this is 1 year of data, lets check that","metadata":{}},{"cell_type":"code","source":"df.sort_values(by=['Date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Indeed there is 1 year of data, beginning on 2017-01-02 and ending 2018-01-01 <br> A full Calendar year","metadata":{}},{"cell_type":"code","source":"print(df['Date'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we see that there are only 363 dates recorded <br>\nWe are missing 2 days, what are they?","metadata":{}},{"cell_type":"code","source":"pd.date_range(start = '2017-01-02', end = '2018-01-01' ).difference(df['Date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Those missing dates are 2017-03-28 & 2017-12-26","metadata":{}},{"cell_type":"markdown","source":"# Let us begin to gather Sales Data\n## We will then order subplots over different periods to view Sales Amounts\n## Sales by Quarter, Month, Week, and day\n- Both Sales Amount and Individual Transactions","metadata":{}},{"cell_type":"code","source":"#Create new Dataframes containing individual breakdowns of time period and sales amount\nsales_time = df.sort_values('Date').copy()\nsales_time['Quarter']= df.Date.dt.quarter\nsales_time['Month']= df.Date.dt.month\nsales_time['Week']= df.Date.dt.isocalendar().week\nsales_time['Day of Week']= df.Date.dt.dayofweek #Monday = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales_time.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Data for Sales Amount Tables","metadata":{}},{"cell_type":"code","source":"sales_by_quarter= sales_time.groupby(['Quarter']).agg({'Sales_Amount':'sum'}).reset_index()\nsales_by_Month= sales_time.groupby(['Month']).agg({'Sales_Amount':'sum'}).reset_index()\nsales_by_week= sales_time.groupby(['Week']).agg({'Sales_Amount':'sum'}).reset_index()\nsales_by_weekday= sales_time.groupby(['Day of Week']).agg({'Sales_Amount':'sum'}).reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Plotly, we will create a subplot view of sales amount over these time frames","metadata":{}},{"cell_type":"code","source":"fig=make_subplots(rows=2,cols=2, subplot_titles=('Sales by Quarter', 'Sales by Month', 'Sales By Week', 'Sales By Day of Week (0=Monday)'))\nfig.add_trace(go.Bar(x=sales_by_quarter['Quarter'], y=sales_by_quarter['Sales_Amount']), row=1, col=1)\nfig.add_trace(go.Bar(x=sales_by_Month['Month'], y=sales_by_Month['Sales_Amount']), row=1, col=2)\nfig.add_trace(go.Bar(x=sales_by_week['Week'], y=sales_by_week['Sales_Amount']), row=2, col=1)\nfig.add_trace(go.Bar(x=sales_by_weekday['Day of Week'], y=sales_by_week['Sales_Amount']), row=2, col=2)\nfig.update_layout(showlegend=False, title_text=\"Sales Amounts in Currency Over different Periods\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# With the above data we can visualize a quick idea of the spread of sales\n## Some insights\n1. Mondays are typically low earning days\n2. Sales amount rose in the 4th quarter, as supported by rising Sales Amount through weeks","metadata":{}},{"cell_type":"markdown","source":"# Lets look into SKU'S \n1. How many Sku's are there?\n2. What are the most popular items, by quantity?\n3. What item gave the most revenue?","metadata":{}},{"cell_type":"code","source":"#Groups SKU's amd gives us total sales and quanitity sold for each\nsku= df.groupby(['SKU']).agg({'Sales_Amount':'sum', 'Quantity':'sum'}).reset_index()\nsku.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(sku)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Total Sku's = 5242, as we expected from data source","metadata":{}},{"cell_type":"markdown","source":"### Top 10 Best selling items this year by quantity","metadata":{}},{"cell_type":"code","source":"sku.sort_values(['Quantity'], ascending=False).head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Worst 10 selling items this year by quantity","metadata":{}},{"cell_type":"code","source":"sku.sort_values(['Sales_Amount']).head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets explore the data with respect to Transactions","metadata":{}},{"cell_type":"code","source":"transactions=sales_time.sort_values('Transaction_ID')\ndf.Transaction_ID.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Total transactions for the year is 64,682, as expected","metadata":{}},{"cell_type":"markdown","source":"### We will create new dataframes similarly to Sales Amount data","metadata":{}},{"cell_type":"code","source":"transactions_by_quarter= sales_time.groupby(['Quarter']).agg({'Transaction_ID':'nunique'}).reset_index()\ntransactions_by_Month= sales_time.groupby(['Month']).agg({'Transaction_ID':'nunique'}).reset_index()\ntransactions_by_week= sales_time.groupby(['Week']).agg({'Transaction_ID':'nunique'}).reset_index()\ntransactions_by_weekday= sales_time.groupby(['Day of Week']).agg({'Transaction_ID':'nunique'}).reset_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets see this information graphed to see when the store is busiest with customers","metadata":{}},{"cell_type":"code","source":"fig2=make_subplots(rows=2,cols=2, subplot_titles=('Transactions by Quarter', 'Transactions by Month', 'Transactions By Week', 'Transactions By Day of Week (0=Monday)'))\nfig2.add_trace(go.Bar(x=transactions_by_quarter['Quarter'], y=transactions_by_quarter['Transaction_ID']), row=1, col=1)\nfig2.add_trace(go.Bar(x=transactions_by_Month['Month'], y=transactions_by_Month['Transaction_ID']), row=1, col=2)\nfig2.add_trace(go.Bar(x=transactions_by_week['Week'], y=transactions_by_week['Transaction_ID']), row=2, col=1)\nfig2.add_trace(go.Bar(x=transactions_by_weekday['Day of Week'], y=transactions_by_week['Transaction_ID']), row=2, col=2)\nfig2.update_layout(showlegend=False, title_text=\"Total Transactions Over different Periods\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transactions over time appear very similar to Sales Amount over time. \n### We can add these 2 sets of charts together to better understand the relationship, with transactions as line charts","metadata":{}},{"cell_type":"code","source":"fig=make_subplots(rows=2,cols=2, subplot_titles=('Quarterly', 'Monthly', 'Weekly','Day of Week 0=Monday'),\n                                specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}],\n                                       [{\"secondary_y\": True}, {\"secondary_y\": True}]])\n\n#Quarterly\nfig.add_trace(go.Bar(x=sales_by_quarter['Quarter'], y=sales_by_quarter['Sales_Amount'],name='Sale Amount'), row=1, col=1, secondary_y=False)\nfig.add_trace(go.Line(x=transactions_by_quarter['Quarter'], y=transactions_by_quarter['Transaction_ID'],name='Transaction Total'), row=1, col=1, secondary_y=True,)\n#Monthly\nfig.add_trace(go.Bar(x=sales_by_Month['Month'], y=sales_by_Month['Sales_Amount'],name='Sale Amount'), row=1, col=2,secondary_y=False)\nfig.add_trace(go.Line(x=transactions_by_Month['Month'], y=transactions_by_Month['Transaction_ID'],name='Transaction Total'), row=1, col=2,secondary_y=True,)\n#Weekly\nfig.add_trace(go.Bar(x=sales_by_week['Week'], y=sales_by_week['Sales_Amount'],name='Sale Amount'), row=2, col=1,secondary_y=False)\nfig.add_trace(go.Line(x=transactions_by_week['Week'], y=transactions_by_week['Transaction_ID'],name='Transaction Total'), row=2, col=1,secondary_y=True,)\n#By Day of Week\nfig.add_trace(go.Bar(x=sales_by_weekday['Day of Week'], y=sales_by_week['Sales_Amount'],name='Sale Amount'), row=2, col=2,secondary_y=False)\nfig.add_trace(go.Line(x=transactions_by_weekday['Day of Week'], y=transactions_by_week['Transaction_ID'],name='Transaction Total'), row=2, col=2,secondary_y=True,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We can the relationship between Sales Amount and total transactions in that same period","metadata":{}},{"cell_type":"markdown","source":"# Lets breakdown some informative data on the actual SKU products\n### First we will isolate SKUs and Quantity and turn it into a pivot table, broken down by week","metadata":{}},{"cell_type":"code","source":"grouped=sales_time.groupby(['Week', 'SKU']).agg({'Quantity':['sum']})\nprint(grouped.head())\nprint(grouped.tail())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### That looks good\n\n### Lets turn this into a pivot table to grab some statistics","metadata":{}},{"cell_type":"code","source":"pivot=grouped.pivot_table(values='Quantity', index='SKU', columns='Week')\npivot.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check datatypes have been preserved\npivot.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets replace those NAN values with zeros","metadata":{}},{"cell_type":"code","source":"pivot=pivot.replace(np.nan, 0)\npivot.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Must set index to SKU\npivot.reset_index(inplace=True)\n#Creates new Dataframe using Index from Pivot\nstats=pd.DataFrame(index=pivot.index)\nstats['SKU']=pivot['SKU'] #Copies SKUs into column\nstats['total_sold']=pivot.sum(axis=1) #Finds total sold of SKU for the year\nstats['average']=pivot.mean(axis=1) #Gives average of units sold of SKU for weekly period\nstats['std_dev']=pivot.std(axis=1) #Gives the standard deviation of quantity sold in a week\nstats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets add in the SKU category back into the","metadata":{}},{"cell_type":"code","source":"#Check your data matches\nstats2=stats.copy()\nprint(df['Quantity'].sum())\nprint(stats2['total_sold'].sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create separate dataframe for SKUs\nskuCat=pd.DataFrame()\nskuCat['SKU']=df['SKU']\nskuCat['SKU_Category']=df['SKU_Category']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop duplicates and sort values to match out stats dataframe\nskuCat.drop_duplicates(inplace=True)\nskuCat.sort_values('SKU', inplace=True)\nstats2.sort_values('SKU', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make sure everything matches\n\n","metadata":{}},{"cell_type":"code","source":"print(skuCat)\nprint(stats2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge this info using Full outer join back to stats dataframe\n","metadata":{}},{"cell_type":"code","source":"stats=pd.merge(stats2, skuCat, how='outer', on='SKU')\nstats.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we can see what categories these products belong to!","metadata":{}},{"cell_type":"markdown","source":"### With this data:\n1. We have an over view of trends in sales amount, as well as quantity of products sold\n2. We also have an statistics table where we can further investigate which items are popular and how often they sell!\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}