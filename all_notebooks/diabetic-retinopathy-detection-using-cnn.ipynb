{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Diabetic retinopathy detection using Convolutional Neural Networks\n\nIn this notebook I'll show how to use CNNs and transfer learning to train a diabetic retinopathy detection model using fundus images.\n\n---\n\n## *Detecção de retinopatia diabética utilizando redes neurais convolucionais*\n\n*Neste notebook irei demonstrar como utilizar redes neurais convolucionais e transferência de aprendizado para treinar um modelo de detecção de retinopatia diabética a partir de imagens de retina.*","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom os import listdir\nfrom os.path import isfile, join\nimport os\n\nimport tensorflow as tf # google's library for deep learning\nfrom tensorflow.keras.utils import Sequence, to_categorical\nimport cv2 # opencv - for computer vision\nfrom tensorflow.keras.preprocessing.image import (ImageDataGenerator, load_img,\n                                                  save_img)\n\nfrom tensorflow.keras.layers import (AveragePooling2D, Conv2D, Dense, Dropout,\n                                     Flatten, Input, Lambda, LeakyReLU,\n                                     MaxPooling2D, UpSampling2D)\nfrom tensorflow.keras import optimizers\nimport tensorflow.keras.backend as K\nfrom sklearn.utils import shuffle\nimport math\nfrom typing import AnyStr, Callable\n","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:14:46.844149Z","iopub.execute_input":"2021-07-29T10:14:46.84489Z","iopub.status.idle":"2021-07-29T10:14:53.990083Z","shell.execute_reply.started":"2021-07-29T10:14:46.84484Z","shell.execute_reply":"2021-07-29T10:14:53.988948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## List all image files and its DR levels on a DataFrame\n\nThe used dataset can be found [here](https://www.kaggle.com/sovitrath/diabetic-retinopathy-2015-data-colored-resized).\n\n---\n\n### *Lista todos arquivos de imagem e seus níveis de RD e os coloca num DataFrame*\n\nO banco de dados utilizado pode ser encontrado [aqui](https://www.kaggle.com/sovitrath/diabetic-retinopathy-2015-data-colored-resized).","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns=['image','file','level'])\nmypath = '/kaggle/input/diabetic-retinopathy-2015-data-colored-resized/colored_images/colored_images/No_DR/'\ndf['image'] = [f for f in listdir(mypath) if isfile(join(mypath, f))]\ndf['level'] = 0\ndf['file'] = mypath + df['image']\n\ndf2 = pd.DataFrame(columns=['image','file','level'])\nmypath = '/kaggle/input/diabetic-retinopathy-2015-data-colored-resized/colored_images/colored_images/Mild/'\ndf2['image'] = [f for f in listdir(mypath) if isfile(join(mypath, f))]\ndf2['level'] = 1\ndf2['file'] = mypath + df2['image']\ndf = df.append(df2,ignore_index=True)\n\ndf2 = pd.DataFrame(columns=['image','file','level'])\nmypath = '/kaggle/input/diabetic-retinopathy-2015-data-colored-resized/colored_images/colored_images/Moderate/'\ndf2['image'] = [f for f in listdir(mypath) if isfile(join(mypath, f))]\ndf2['level'] = 2\ndf2['file'] = mypath + df2['image']\ndf = df.append(df2,ignore_index=True)\n\ndf2 = pd.DataFrame(columns=['image','file','level'])\nmypath = '/kaggle/input/diabetic-retinopathy-2015-data-colored-resized/colored_images/colored_images/Severe/'\ndf2['image'] = [f for f in listdir(mypath) if isfile(join(mypath, f))]\ndf2['level'] = 3\ndf2['file'] = mypath + df2['image']\ndf = df.append(df2,ignore_index=True)\n\ndf2 = pd.DataFrame(columns=['image','file','level'])\nmypath = '/kaggle/input/diabetic-retinopathy-2015-data-colored-resized/colored_images/colored_images/Proliferate_DR/'\ndf2['image'] = [f for f in listdir(mypath) if isfile(join(mypath, f))]\ndf2['level'] = 4\ndf2['file'] = mypath + df2['image']\ndf = df.append(df2,ignore_index=True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:14:53.991852Z","iopub.execute_input":"2021-07-29T10:14:53.992222Z","iopub.status.idle":"2021-07-29T10:15:24.887923Z","shell.execute_reply.started":"2021-07-29T10:14:53.99218Z","shell.execute_reply":"2021-07-29T10:15:24.886904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The DataFrame df contains 3 columns:\n- image: the name of the each image.\n- file: the complete path of each image file.\n- level: the DR level.\n---\n\n*O DataFrame df contém 3 colunas:*\n- *image: o nome de cada imagem.*\n- *file: o caminho completo de cada arquivo de imagem.*\n- *level: o nível de RD de cada imagem.*","metadata":{}},{"cell_type":"markdown","source":"### Define the Sequence, structure responsible for providing the model with preprocessed data\n\n---\n\n### *Define a estrutura Sequence, responsável por prover as amostras ao model durante o treinamento*","metadata":{}},{"cell_type":"code","source":"class RetinaSequence(Sequence):\n\n    def __init__(self, x_set: list, y_set: list, batch_size: int = 32, augmentate: bool = True, \n                 shuffle: bool = True, input_shape: tuple = (512, 512), preprocessing_fcn: callable = None):\n        \"\"\" \n        This is called when the object is initialized.\n        \n        Parameters\n        ----------\n        x_set : list\n            The array with image files paths.\n        y_set : list\n            The array with DR levels.  \n        batch_size : int\n            The batch size, which is how many samples are delivered at each update of the training algorithm.\n        augmentate : bool\n            If True, will use data augmentation.\n        shuffle: bool\n            If True, will shuffle the data at the end of each epoch.\n        input_shape: tuple\n            The size of the input images. Larger input images needs GPUs with more memory.\n        preprocessing_fcn: callable\n            Method for the preprocessing function that will be applied to the input images.\n            \n        print_cols : bool, optional\n            A flag used to print the columns to the console (default is False)\n\n        \n        \"\"\"\n        \n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.augmentate = augmentate\n        self.shuffle = shuffle\n        self.preprocessing_fcn = preprocessing_fcn\n        self.input_shape = input_shape\n\n        self.datagen = ImageDataGenerator(featurewise_center=False,\n                                          samplewise_center=False,\n                                          featurewise_std_normalization=False,\n                                          samplewise_std_normalization=False,\n                                          rotation_range=360.,\n                                          width_shift_range=0.0,\n                                          height_shift_range=0.0,\n                                          shear_range=0.,\n                                          zoom_range=0.0,\n                                          channel_shift_range=0.,\n                                          fill_mode='constant',\n                                          cval=0.,\n                                          horizontal_flip=True,\n                                          vertical_flip=True,\n                                          rescale=None,\n                                          preprocessing_function=None,\n                                          data_format=K.image_data_format())\n\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n\n    def __getitem__(self, idx):\n        \"\"\"This is the method called to actually give data to the model.\n\n        Args:\n            idx (int): index.\n\n        Returns:\n            [ndarray]: array with a batch of data and its labels.\n        \"\"\"        \n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        return np.array([self.preprocess(file_name)\n                         for file_name in batch_x]), np.array(batch_y)\n\n    def preprocess(self, file_name):\n        \"\"\"The preprocessing method. It does the contrast enhancement. Data augmentation if asked and transform to float32.\n\n        Args:\n            file_name (str): the file path.\n\n        Returns:\n            ndarray: the preprocessed image.\n        \"\"\"        \n        img = load_img(file_name, target_size=self.input_shape)\n        x = np.array(img, dtype=np.uint8)\n        alfa = 4.0\n        tal = -4.0\n        xf = cv2.GaussianBlur(\n            x, ksize=(0, 0), sigmaX=img.size[0] // 30, sigmaY=0)\n        xf = xf.astype(np.float32)\n        x = x.astype(np.float32)\n        x = alfa * x + tal * xf + 128.0\n        x[x < 0] = 0\n        x[x > 255] = 255\n\n        if self.augmentate:\n            x = self.datagen.random_transform(x)\n            factor = np.random.uniform(low=0.6, high=1.67)\n            x = np.array(x, dtype=K.floatx())\n            x = 128 + factor * (x - 128)\n            x[x > 255] = 255\n            x[x < 0] = 0\n        else:\n            x = x.astype(np.float32)\n        if self.preprocessing_fcn is None:\n            x -= 127.0\n            x /= 127.0\n        else:\n            x = x.astype(np.uint8)\n            x = self.preprocessing_fcn(x)\n        return x\n\n    def on_epoch_end(self):\n        \"\"\"This is called on each epoch end and shuffles the data if self.shuffe is True.\n        \"\"\"\n        if self.shuffle:\n            self.x, self.y = shuffle(self.x, self.y)    ","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:15:24.890455Z","iopub.execute_input":"2021-07-29T10:15:24.890915Z","iopub.status.idle":"2021-07-29T10:15:24.912734Z","shell.execute_reply.started":"2021-07-29T10:15:24.890855Z","shell.execute_reply":"2021-07-29T10:15:24.909554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ratio = 0.5 # this is the percentage of data that will be used as test set, where we'll verify the model's performance.\nvalidation_ratio = 0.2 # this is the percentage of data that will be used as validation set, used for early stopping.\n\ndf['class'] = df.level > 1\nn = df.shape[0]\nweights = {False: n / df.loc[df['class'] == False].shape[0],\n           True: n / df.loc[df['class'] == True].shape[0]}\ndf['weights'] = df['class'].map(weights) # higher weights for class with less examples.\n\nimages = df.image.unique()\n\nmsk = np.random.rand(len(df)) < (1.0 - test_ratio)\ntrain = df.loc[df.image.isin(images[msk])]\ntest = df.loc[df.image.isin(images[~msk])]\n\nimages = train.image.unique()\nmsk = np.random.rand(len(train)) < (1.0 - validation_ratio)\nval = train.loc[train.image.isin(images[~msk])]\ntrain = train.loc[train.image.isin(images[msk])]\n\ntrain = train.sample(n=4 * len(train.index),\n                     replace=True, weights='weights') # balancing the classes in the set used for training.\n\nval = val.sample(n=4 * len(val.index),\n                     replace=True, weights='weights') # balancing the classes in the set used for validation.\n\nnb_train = len(train.index)\nnb_val = len(val.index)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:15:24.915192Z","iopub.execute_input":"2021-07-29T10:15:24.915691Z","iopub.status.idle":"2021-07-29T10:15:24.993418Z","shell.execute_reply.started":"2021-07-29T10:15:24.915647Z","shell.execute_reply":"2021-07-29T10:15:24.992448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing_fcn = tf.keras.applications.nasnet.preprocess_input # the preprocessing function is the default for the used model.\n\n# we are going to use NASNetMobile because it is small and fast to train.\nbase_model = tf.keras.applications.nasnet.NASNetMobile(include_top=False, weights='imagenet',\n                                                    input_tensor=None,\n                                                    pooling='avg')\ninput_shape = base_model.input_shape[1:3]\n\n# Freeze the pretrained weights\nbase_model.trainable = False\n\n# adding the final part of the model.\nx = base_model.output\nx = Dense(units=512, activation='relu', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.005),\n          bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = Dense(units=256, activation='relu', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.005),\n          bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = Dense(units=2, activation='softmax', use_bias=True, kernel_regularizer=tf.keras.regularizers.l2(0.005),\n          bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(x)\nmodel = tf.keras.Model(inputs=base_model.input,\n                    outputs=x, name='NASNetMobile')","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:15:24.99496Z","iopub.execute_input":"2021-07-29T10:15:24.995365Z","iopub.status.idle":"2021-07-29T10:15:35.816453Z","shell.execute_reply.started":"2021-07-29T10:15:24.995309Z","shell.execute_reply":"2021-07-29T10:15:35.815353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate the sequences.\ntrain_seq = RetinaSequence(x_set=train['file'],\n                           y_set=to_categorical(\n                               train['class'], num_classes=2),\n                           batch_size=16, augmentate=True, shuffle=True,\n                           input_shape=input_shape,\n                           preprocessing_fcn=preprocessing_fcn)\nval_seq = RetinaSequence(x_set=val['file'], y_set=to_categorical(val['class'], num_classes=2),\n                         batch_size=16, augmentate=False, shuffle=False,\n                         input_shape=input_shape,\n                         preprocessing_fcn=preprocessing_fcn)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:15:35.818033Z","iopub.execute_input":"2021-07-29T10:15:35.818566Z","iopub.status.idle":"2021-07-29T10:15:35.827635Z","shell.execute_reply.started":"2021-07-29T10:15:35.818521Z","shell.execute_reply":"2021-07-29T10:15:35.82652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First we will train the recently added layers for a couple of epochs.","metadata":{}},{"cell_type":"code","source":"# those are the metrics we are going to check.\nMETRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=METRICS)\n\nepochs = 5\nmodel.fit(\n    x=train_seq,\n    steps_per_epoch=nb_train // (4 * 16),\n    epochs=epochs,\n    verbose=1,\n    validation_data=val_seq,\n    validation_steps=nb_val // (4*16),\n    max_queue_size=10,\n    workers=20,\n    use_multiprocessing=False,\n    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:15:35.829114Z","iopub.execute_input":"2021-07-29T10:15:35.829837Z","iopub.status.idle":"2021-07-29T10:43:13.496042Z","shell.execute_reply.started":"2021-07-29T10:15:35.829792Z","shell.execute_reply":"2021-07-29T10:43:13.492169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we unfreeze the layers of the pre-trained model and train it all.","metadata":{}},{"cell_type":"code","source":"patience_early_stop = 5\nfor layer in model.layers:\n    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = True\n\n# compile the model using Stochastic Gradient Descent optimization algorithm.\nmodel.compile(optimizer=optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True),\n              loss='binary_crossentropy', metrics=METRICS)\n\n# The callbacks are the methods called during the training process.\n# EarlyStopping will stop the training process if the loss stops getting better.\n\n# ModelCheckpoint will save the model at the best epoch.\ncallbacks = [tf.keras.callbacks.EarlyStopping(\n                 monitor='val_loss',\n                 patience=patience_early_stop),\n                 tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/model_DR.h5', monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=False, mode=\"auto\", save_freq=\"epoch\")\n                     ]\n\nmodel.fit(\n    x=train_seq,\n    steps_per_epoch=nb_train // (4 * 16),\n    epochs=50,\n    verbose=1,\n    callbacks=callbacks,\n    validation_data=val_seq,\n    validation_steps= nb_val // 16,\n    max_queue_size=10,\n    workers=20,\n    use_multiprocessing=False,\n    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T10:43:13.506126Z","iopub.execute_input":"2021-07-29T10:43:13.510373Z","iopub.status.idle":"2021-07-29T12:14:35.551847Z","shell.execute_reply.started":"2021-07-29T10:43:13.510321Z","shell.execute_reply":"2021-07-29T12:14:35.550745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now let's evaluate our model.\n---\n## Agora vamos avaliar nosso modelo.","metadata":{}},{"cell_type":"code","source":"test_seq = RetinaSequence(x_set=test['file'], y_set=to_categorical(test['class'], num_classes=2),\n                         batch_size=16, augmentate=False, shuffle=False,\n                         input_shape=input_shape,\n                         preprocessing_fcn=preprocessing_fcn)\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_seq)\nprint(\"test loss, test acc:\", results)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T12:14:35.553967Z","iopub.execute_input":"2021-07-29T12:14:35.554443Z","iopub.status.idle":"2021-07-29T12:19:21.534012Z","shell.execute_reply.started":"2021-07-29T12:14:35.554396Z","shell.execute_reply":"2021-07-29T12:19:21.532846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}