{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nThe given dataset has data about patients if they have heart disease or not with respect to some given features. Our goal is to predict whether a person has heart disease or not based on given feature values. We will follow the following process to achieve this:\n* Import Data\n* Exploratory data analysis\n* Data Preprocessing\n* Model our Data\n* Compare different Models\n* Tune our Model(Hyperparameter tuning)\n* Evaluate our Data\n\nIf you find this helpful kindly do **Upvote**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Columns (Features)\n\n *   age - age in years\n *   sex - (1 = male; 0 = female)\n *   cp - chest pain type\n      *  0: Typical angina: chest pain related decrease blood supply to the heart\n      *  1: Atypical angina: chest pain not related to heart\n      *  2: Non-anginal pain: typically esophageal spasms (non heart related)\n      *  3: Asymptomatic: chest pain not showing signs of disease\n *   trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n        anything above 130-140 is typically cause for concern\n *   chol - serum cholestoral in mg/dl\n        serum = LDL + HDL + .2 * triglycerides\n        above 200 is cause for concern\n *   fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n        '>126' mg/dL signals diabetes\n *  restecg - resting electrocardiographic results\n       * 0: Nothing to note\n       * 1: ST-T Wave abnormality\n            can range from mild symptoms to severe problems\n            signals non-normal heart beat\n       * 2: Possible or definite left ventricular hypertrophy\n            Enlarged heart's main pumping chamber\n *   thalach - maximum heart rate achieved\n *   exang - exercise induced angina (1 = yes; 0 = no)\n *   oldpeak - ST depression induced by exercise relative to rest\n        looks at stress of heart during excercise\n        unhealthy heart will stress more\n *   slope - the slope of the peak exercise ST segment\n      *  0: Upsloping: better heart rate with excercise (uncommon)\n      *  1: Flatsloping: minimal change (typical healthy heart)\n      *  2: Downslopins: signs of unhealthy heart\n *   ca - number of major vessels (0-3) colored by flourosopy\n        colored vessel means the doctor can see the blood passing through\n        the more blood movement the better (no clots)\n *   thal - thalium stress result\n      *  1,3: normal\n      *  6: fixed defect: used to be defect but ok now\n      *  7: reversable defect: no proper blood movement when excercising\n *   target - have disease or not (1=yes, 0=no) (= the predicted attribute)\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets Do Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.target.value_counts().plot(kind='bar',color=['orange','green'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heart Disease with respect to Sex\npd.crosstab(df.sex,df.target).plot(kind=\"bar\",figsize=(10,6))\nplt.title(\"Heart Disease vs Sex\")\nplt.xlabel(\"0=No Disease & 1=Disease\")\nplt.ylabel(\"Count\")\nplt.legend([\"female\",\"Male\"]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age vs Max Heart rate(thalach)\nplt.figure(figsize=(10,6))\n\nplt.scatter(df.age[df.target==1],\n           df.thalach[df.target==1])\n\nplt.scatter(df.age[df.target==0],\n           df.thalach[df.target==0])\n\nplt.legend([\"Disease\",\"No Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Heart Rate\")\nplt.title(\"Age vs Heart Rate\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(df.cp,df.target).plot(kind=\"bar\",figsize=(10,6))\nplt.xlabel(\"Chest Pain Type\")\nplt.title(\"Chest Pain vs Target\")\nplt.ylabel(\"Count\")\nplt.legend([\" No Disease\",\"Disease\"])\nplt.xticks(rotation = 0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Correlation matrix using seaborn \ncorr_mat=df.corr()\nplt.figure(figsize=(15,10))\nsns.heatmap(corr_mat,\n           annot=True,\n           linewidth=0.5,\n           fmt= \".2f\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing\nData consist of categorical features. We need to convert them to dummy variables ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cp=pd.get_dummies(df['cp'],prefix='cp',drop_first=True)\nthal=pd.get_dummies(df['thal'],prefix='thal',drop_first=True)\nslope=pd.get_dummies(df['slope'],prefix='slope',drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df=pd.concat([df,cp,thal,slope],axis=1)\nnew_df=new_df.drop(['cp','thal','slope'],axis=1)\nnew_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_df.drop(\"target\", axis=1)\n\n# Target variable\ny = new_df['target']\n\n#Normalize X\nX = (X - X.min())/(X.max()-X.min())\n\n#Split data into training and test data\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets Model our Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score,RandomizedSearchCV,GridSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Store all models in a Dictionary\nnp.random.seed(42)\nmodels={'Logistic Regression':LogisticRegression(max_iter=1000),\n       'RandomForestClassifier':RandomForestClassifier(),\n        \"GradientBoostingClassifier\":GradientBoostingClassifier(),\n       \"Knn\":KNeighborsClassifier(),\n        \"GaussianNB\":GaussianNB(),\n       \"SVC\":SVC(kernel='linear')}\n#Store result in an empty dictionary\nscores={}\n\n#Write a function to fit,train and test a model and store in result dictionary\ndef fit_and_score(models,X_train,X_test,y_train,y_test):\n    for model_name,model in models.items():\n        model.fit(X_train,y_train)\n        scores[model_name]=model.score(X_test,y_test)\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_and_score(models,X_train,X_test,y_train,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores['Knn']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compare Different Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(scores,index=['accuracy']).T.plot(kind='bar',figsize=(10,6))\nplt.yticks(np.arange(0,1.1,0.05))\nplt.grid();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let us try to tune our Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Let us tune our KNN model wuth different values of n_neighbors\ntrain_scores = []\n\n# Create a list of test scores\ntest_scores = []\n\n# Create a list of different values for n_neighbors\nneighbors = range(1, 21) # 1 to 20\n\n# Setup algorithm\nknn = KNeighborsClassifier()\n\n# Loop through different neighbors values\nfor i in neighbors:\n    knn.set_params(n_neighbors = i) # set neighbors value\n    \n    # Fit the algorithm\n    knn.fit(X_train, y_train)\n    \n    # Update the training scores\n    train_scores.append(knn.score(X_train, y_train))\n    \n    # Update the test scores\n    test_scores.append(knn.score(X_test, y_test))\n    \nplt.plot(neighbors, train_scores, label=\"Train score\")\nplt.plot(neighbors, test_scores, label=\"Test score\")\nplt.xticks(np.arange(1, 21, 1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model score\")\nplt.legend()\n \nknn_score=max(test_scores)\nprint(f\"Maximum KNN score on the test data: {knn_score*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Let us tune our Logistic Regression and Random Forest model using RandomizedSearchCV\n#Logistic Regression hyperparameter grid\nlog_reg_grid={\"C\":np.logspace(-4,4,20),\n             \"solver\":['newton-cg','liblinear','sag','saga']}\n#RandomForest hyerparameter grid\nrf_grid={\"n_estimators\":np.arange(10,1000,50),\n        \"max_depth\":[None,1,2,3,5,10,15,22,25],\n        \"min_samples_split\":np.arange(2,40,2),\n        \"min_samples_leaf\":np.arange(1,40,2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set up random hyperparameter search for Logistic Regression\nnp.random.seed(42)\nrs_log_reg=RandomizedSearchCV(LogisticRegression(),param_distributions=log_reg_grid,n_iter=100,cv=5,verbose=True)\n\nrs_log_reg.fit(X_train,y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best parameters for LogisticRegression Model\nrs_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy score for LogisticRegression Model\nrs_log_reg_score=rs_log_reg.score(X_test,y_test)\nrs_log_reg_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nrs_rf=RandomizedSearchCV(RandomForestClassifier(),param_distributions=rf_grid,n_iter=20,cv=5,verbose=True)\n\nrs_rf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_rf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_rf_score=rs_rf.score(X_test,y_test)\nrs_rf_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_model=['Logistic Regression','RandomForestClassifier','GradientBoostingClassifier','Knn','GaussianNB','SVC']\naccuracy=[rs_log_reg_score,rs_rf_score,scores['GradientBoostingClassifier'],knn_score,scores['GaussianNB'],scores['SVC']]\nplt.bar(x=clf_model,height=accuracy)\nplt.title('Model Accuracy')\nplt.grid()\nplt.xticks(rotation=90)\nplt.yticks(np.arange(0,1.1,0.1));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above graph we can see that **GaussianNB** performs best with **93.44%** accuracy","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Evaluating our Model\nWe will evaluate our model using \n * ROC Curve\n * Confusion Matrix\n * Classification Matrix\n * Precisin \n * Recall \n * F1-Score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicted values for y_test\ngnb=GaussianNB()\ngnb.fit(X_train,y_train)\ny_preds = gnb.predict(X_test)\ny_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot ROC Curve\nfrom sklearn.metrics import plot_roc_curve,confusion_matrix,plot_confusion_matrix,classification_report\nplot_roc_curve(gnb,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot confusion matrix\nconfusion_matrix(y_test,y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(gnb,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print Calssification Report\nprint(classification_report(y_test,y_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncv_acc= cross_val_score(gnb,\n                        X,\n                        y,\n                        cv=5,  #5-fold cross validation\n                       scoring='accuracy') # scoring parameter as accuracy\n\ncv_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Take mean of these values\ncv_acc=np.mean(cv_acc)\ncv_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate rest of paramters\ncv_precision=np.mean(cross_val_score(gnb,\n                        X,\n                        y,\n                        cv=5,  \n                       scoring='precision'))\n\ncv_precision ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_recall=np.mean(cross_val_score(gnb,\n                        X,\n                        y,\n                        cv=5,  \n                       scoring='recall'))\n\ncv_recall ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_f1=np.mean(cross_val_score(gnb,\n                        X,\n                        y,\n                        cv=5,  \n                       scoring='f1'))\n\ncv_f1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us visualize them\ncv_metrics=pd.DataFrame({'Accuracy':cv_acc,\n                        'Precision':cv_precision,\n                        'Recall':cv_recall,\n                        'F1-score':cv_f1},index=[0])\ncv_metrics.T.plot(kind='bar',legend=False)\nplt.title(\"Classification Metrics for GaussianNB\")\nplt.yticks(np.arange(0,1.1,0.1))\nplt.grid();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}