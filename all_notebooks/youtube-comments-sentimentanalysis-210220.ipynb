{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Youtube Comments Sentiment Analysis**\n\nFirst of all thank you @gsc ankith for upload this dataset. Here I have tried to perform a very simple sentiment analysis using AFINN library"},{"metadata":{"id":"n4DoiU3-2V6i","colab_type":"code","colab":{},"trusted":true,"collapsed":true},"cell_type":"code","source":"#installing contractions library\n!pip install contractions","execution_count":null,"outputs":[]},{"metadata":{"id":"0Px1s4ypx5b1","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Generic Data Processing & Visualization Libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re,string,unicodedata\nimport contractions #import contractions_dict\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"3c9WPiHLCJTX","colab_type":"code","colab":{},"trusted":true,"collapsed":true},"cell_type":"code","source":"#Importing text processing libraries\nimport spacy\nimport spacy.cli\nimport nltk\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\n#downloading wordnet/punkt dictionary\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"id":"KEPcX8TGL--i","colab_type":"code","colab":{},"trusted":true,"collapsed":true},"cell_type":"code","source":"#Installing & Importing Sentiment Analysis Library  - AFINN\n!pip install afinn\nfrom afinn import Afinn","execution_count":null,"outputs":[]},{"metadata":{"id":"3UxC52hzyWCV","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/nlp-dataset-collected-from-youtube-comments/iran.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"hS4AyA1Pyccq","colab_type":"text"},"cell_type":"markdown","source":"**Data Exploration**"},{"metadata":{"id":"2DMPQeXCyfcm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"51cc25a9-4000-4e7d-f1dd-2d4ac0b847ec","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"fVm8drm6yqV4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#checking for null/missing values\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"TLpbgO4VyyVC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"127c24bd-3b4c-4546-feb4-cb43e3a96bdf","trusted":true},"cell_type":"code","source":"#dropping the index with missing comments\ndata = data.dropna()\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"7UmFVUkQzNY5","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#creating a new column in the dataset for word count\ndata ['word_count'] = data['Comments'].apply(lambda x:len(str(x).split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"id":"VyJzKQVMy7Zy","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"NL7oOD_00aCs","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#taking a copy of the clean dataset\ndata_clean = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"CQcKkCBPzuU0","colab_type":"text"},"cell_type":"markdown","source":"**Data Preperation**"},{"metadata":{"id":"_jBUtFUMzyrF","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#lowering cases\ndata_clean['Comments'] = data_clean['Comments'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"id":"QGkfjXtn0p5z","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#stripping leading spaces (if any)\ndata_clean['Comments'] = data_clean['Comments'].str.strip()","execution_count":null,"outputs":[]},{"metadata":{"id":"iJSNrfbm0ya2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#removing punctuations\nfrom string import punctuation\n\ndef remove_punct(text):\n  for punctuations in punctuation:\n    text = text.replace(punctuations, '')\n  return text\n\n#apply to the dataset\ndata_clean['Comments'] = data_clean['Comments'].apply(remove_punct)","execution_count":null,"outputs":[]},{"metadata":{"id":"x5oTjwFR1Pbm","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#function to remove special characters\ndef remove_special_chars(text, remove_digits=True):\n  pattern = r'[^a-zA-z0-9\\s]'\n  text = re.sub(pattern, '', text)\n  return text\n\n#applying the function on the clean dataset\ndata_clean['Comments'] = data_clean['Comments'].apply(remove_special_chars)","execution_count":null,"outputs":[]},{"metadata":{"id":"KiJbzkNC1xwc","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#function to remove macrons & accented characters\ndef remove_accented_chars(text):\n    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return text\n\n#applying the function on the clean dataset\ndata_clean['Comments'] = data_clean['Comments'].apply(remove_accented_chars)  ","execution_count":null,"outputs":[]},{"metadata":{"id":"74vJ_uMI2DOQ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Function to expand contractions\ndef expand_contractions(con_text):\n  con_text = contractions.fix(con_text)\n  return con_text\n\n#applying the function on the clean dataset\ndata_clean['Comments'] = data_clean['Comments'].apply(expand_contractions)  ","execution_count":null,"outputs":[]},{"metadata":{"id":"VMqBdvnw1Ar0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":194},"outputId":"ba5c3240-871a-492a-bab9-43146c4123c9","trusted":true},"cell_type":"code","source":"data_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"SrI7qU-yBJS0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#dropping 'label' column as it is does not serve any purpose\ndata_clean = data_clean.drop(columns='label',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"4a5-mvJmBzOs","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#back up of the prepared data\ndata_clean_bckup = data_clean.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"uf-UsZusCExx","colab_type":"text"},"cell_type":"markdown","source":"**Text Processing/Normalization - Removing Stop Words**"},{"metadata":{"id":"Xjpp0_sbC0Q8","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"stopword_list = set(stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"id":"0MkP1KZDEXRg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"tokenizer = ToktokTokenizer()","execution_count":null,"outputs":[]},{"metadata":{"id":"0WFiisrWDzIS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#function to remove stopwords\ndef remove_stopwords(text, is_lower_case=False):\n    tokens = tokenizer.tokenize(text)\n    tokens = [token.strip() for token in tokens]\n    if is_lower_case:\n        filtered_tokens = [token for token in tokens if token not in stopword_list]\n    else:\n        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n    filtered_text = ' '.join(filtered_tokens)    \n    return filtered_text\n\n#applying the function\ndata_clean['Comments_Clean'] = data_clean['Comments'].apply(remove_stopwords)      ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"XSOVmCJ0FOmv"},"cell_type":"markdown","source":"**Text Processing/Normalization - Stemming**\n\napplying the most simplest stemmer i.e. PorterStemmer"},{"metadata":{"id":"S5aDVfblFUgf","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Function for stemming\ndef simple_stemmer(text):\n  ps = nltk.porter.PorterStemmer()\n  text = ' '.join([ps.stem(word) for word in text.split()])\n  return text\n\n#applying the function\ndata_clean['Normalized_Comments'] = data_clean['Comments_Clean'].apply(simple_stemmer)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"pT40rR-fHZIX","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#dropping unwanted columns\ndata_clean = data_clean.drop(columns=data_clean[['Comments_Clean']],axis=1)\ndata_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Rv01XB90Km9s","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#rearranging columns\ndata_clean = data_clean[['Comments','Normalized_Comments','word_count']]\n\n#taking backup \ndata_clean_bckup_norm = data_clean.copy()\n\ndata_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"NgPjWzwgLoMy","colab_type":"text"},"cell_type":"markdown","source":"**Sentiment Analysis - Using Afinn Library**"},{"metadata":{"id":"DLY9r7d8LrAS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Instantiating Afinn Library\naf = Afinn()","execution_count":null,"outputs":[]},{"metadata":{"id":"rBtAdd94Nnj_","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#function to perform Afinn Sentiment Analyis\ndef afinn_sent_analysis(text):\n  score = af.score(text)\n  return score\n\n#applying the function to Normalized Comments\ndata_clean['afinn_score'] = [afinn_sent_analysis(comm) for comm in data_clean['Normalized_Comments']]","execution_count":null,"outputs":[]},{"metadata":{"id":"P964DFWyO81N","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#function to categorize the afinn sentiment score\ndef afinn_sent_category(score):\n  categories = ['positive','negative','neutral']\n  if score > 0:\n    return categories[0]\n  elif score < 0:\n    return categories[1]\n  else:\n    return categories[2]  \n\ndata_clean['afinn_sent_category'] = [afinn_sent_category(scr) for scr in data_clean['afinn_score']]","execution_count":null,"outputs":[]},{"metadata":{"id":"6Ii0zvoAQy36","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#taking backup \ndata_clean_bckup_afinn = data_clean.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"vI0WMtu3Sed1","colab_type":"text"},"cell_type":"markdown","source":"**Visualisation**"},{"metadata":{"id":"gygLKKe2Ryfz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":194},"outputId":"1cc4a8f0-256c-468a-f43c-44ba33734f5a","trusted":true},"cell_type":"code","source":"data_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"WO6FFyI0S4Bv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":536},"outputId":"8f4c7181-069a-47a0-8df6-7c9c6ca835ff","trusted":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nfig, ax = plt.subplots(figsize=(8,8))\nax = sns.countplot(x=\"afinn_sent_category\", data=data_clean)\nplt.title('Sentiment Category Count Plot')\nplt.ylabel('Count')\nplt.xlabel('Sentiment Category')\n\n#ax.set_xticklabels(ax.get_xticklabels(),rotation=0)\n#i=0\n#for p in ax.patches:\n#    height = p.get_height()\n#    ax.text(p.get_x()+p.get_width()/2., height + 1,\n#        data_clean['afinn_sent_category'].value_counts()[i],ha=\"center\")\n#    i += 1","execution_count":null,"outputs":[]},{"metadata":{"id":"hQUcya63VfD5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":628},"outputId":"6851f5f9-ae27-45d6-f08e-0446b6c77dc4","trusted":true},"cell_type":"code","source":"sns.set(style=\"whitegrid\")\nf, ax = plt.subplots(figsize=(15, 10))\nsns.despine(f, left=True, bottom=True)\nsns.scatterplot(x=\"afinn_score\", y=\"word_count\", \n                hue=\"afinn_sent_category\", \n                palette=\"ch:r=-.2,d=.3_r\", \n                sizes=(1,8), \n                data=data_clean, ax=ax)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Youtube_Comments_SentimentAnalysis_210220.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}