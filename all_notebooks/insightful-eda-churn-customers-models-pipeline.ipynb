{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Welcome to Telco Churn Customers analysis and Prediction\n_______________________________________\n![](http://dataskunkworks.com/wp-content/uploads/2018/05/churn-1024x482.png)\n"},{"metadata":{},"cell_type":"markdown","source":"## Description of dataset\n## Context\n\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n\n## Content\nEach row represents a customer, each column contains customer’s attributes described on the column Metadata.\n\n## The data set includes information about:\n\n<b>Customers who left within the last month</b> – the column is called Churn<br>\n<b>Services that each customer has signed up for</b> – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies<br>\n<b>Customer account information</b> – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges<br>\n<b>Demographic info about customers</b> – gender, age range, and if they have partners and dependents<br><br>\n## Inspiration\nTo explore this type of models and learn more about the subject.\n__________________________________"},{"metadata":{},"cell_type":"markdown","source":"## Objectives:\nI will explore the data and try to answer some questions like:\n- What's the % of Churn Customers and customers that keep in with the active services.\n- We can see different patterns in Churn Customers based on the type of service provided?\n- We have difference pattern of churn between genders ?\n- What's the difference between customers that pay monthly and by year?\n- what's the most profitable service types?\n- What's the amount lose in revenue?\n- What's the mean age of papeless customers? they are more propense to churn? \n- A lot of other questions that will raise trought the exploration\n\n## After EDA \nI will build a pipeline to find a model that better fits our data.\nWith the best models I will predict the result and verify the scores of the models. \n<br>\nI hope you enjoy the Kernel. <br>\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nfrom scipy import stats # statistic library\nimport pandas as pd # To table manipulations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Standard plotly imports\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\n\n# Using plotly + cufflinks in offline mode\ninit_notebook_mode(connected=True)\ncufflinks.go_offline(connected=True)\n\nimport os\n\n#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.ensemble import BaggingClassifier, VotingClassifier, RandomTreesEmbedding","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def binary_ploting_distributions(df, cat_col):\n    from plotly import tools\n\n    fig = tools.make_subplots(rows=1,\n                              cols=2,\n                              print_grid=True,\n                              horizontal_spacing=0.15, \n                              subplot_titles=(\"Distribution of and % Churn\", \n                                              f'Mean Monthly Charges of {cat_col}') \n                             )\n\n    tmp_churn = df[df['Churn'] == 1]\n    tmp_no_churn = df[df['Churn'] == 0]\n    tmp_attr = round(tmp_churn[cat_col].value_counts().sort_index() / df_train[cat_col].value_counts().sort_index(),2)*100\n\n    trace1 = go.Bar(\n        x=tmp_churn[cat_col].value_counts().sort_index().index,\n        y=tmp_churn[cat_col].value_counts().sort_index().values,\n        name='Yes_Churn',opacity = 0.8, marker=dict(\n            color='seagreen',\n            line=dict(color='#000000',width=1)))\n\n    trace2 = go.Bar(\n        x=tmp_no_churn[cat_col].value_counts().sort_index().index,\n        y=tmp_no_churn[cat_col].value_counts().sort_index().values,\n        name='No_Churn', opacity = 0.8, \n        marker=dict(\n            color='indianred',\n            line=dict(color='#000000',\n                      width=1)\n        )\n    )\n\n    trace3 =  go.Scatter(   \n        x=tmp_attr.sort_index().index,\n        y=tmp_attr.sort_index().values,\n        yaxis = 'y2',\n        name='% Churn', opacity = 0.6, \n        marker=dict(\n            color='black',\n            line=dict(color='#000000',\n                      width=2 )\n        )\n    )\n\n    df_tmp = (df_train.groupby(['Churn', cat_col])['MonthlyCharges'].mean().reset_index())\n\n    tmp_churn = df_tmp[df_tmp['Churn'] == 1]\n    tmp_no_churn = df_tmp[df_tmp['Churn'] == 0]\n\n    df_tmp = (df_train.groupby(['Churn', cat_col])['MonthlyCharges'].mean()).unstack('Churn').reset_index()\n    df_tmp['diff_rate'] = round((df_tmp[1] / df_tmp[0]) - 1,2) * 100\n\n    trace4 = go.Bar(\n        x=tmp_churn[cat_col],\n        y=tmp_churn['MonthlyCharges'], showlegend=False,\n        name='Mean Charge Churn',opacity = 0.8, marker=dict(\n            color='seagreen',\n            line=dict(color='#000000',width=1)))\n\n    trace5 = go.Bar(\n        x=tmp_no_churn[cat_col],\n        y=tmp_no_churn['MonthlyCharges'],showlegend=False,\n        name='Mean Charge NoChurn', opacity = 0.8, \n        marker=dict(\n            color='indianred',\n            line=dict(color='#000000',\n                      width=1)\n        )\n    )\n\n    trace6 =  go.Scatter(   \n        x=df_tmp[cat_col],\n        y=df_tmp['diff_rate'],\n        yaxis = 'y2',\n        name='% Diff Churn', opacity = 0.6, \n        marker=dict(\n            color='black',\n            line=dict(color='#000000',\n                      width=5 )\n        )\n    )\n\n    fig.append_trace(trace1, 1, 1)\n    fig.append_trace(trace2, 1, 1) \n    fig.append_trace(trace3, 1, 1)\n    fig.append_trace(trace4, 1, 2)\n    fig.append_trace(trace5, 1, 2)\n    fig.append_trace(trace6, 1, 2) \n\n    fig['data'][2].update(yaxis='y3')\n    fig['data'][5].update(yaxis='y4')\n\n    fig['layout']['xaxis'].update(autorange=True,\n                                   tickfont=dict(size= 10), \n                                   title= f'{cat_col}', \n                                   type= 'category',\n                                  )\n    fig['layout']['yaxis'].update(title= 'Count')\n\n    fig['layout']['xaxis2'].update(autorange=True,\n                                   tickfont=dict(size= 10), \n                                   title= f'{cat_col}', \n                                   type= 'category',\n                                  )\n    fig['layout']['yaxis2'].update( title= 'Mean Monthly Charges' )\n\n    fig['layout']['yaxis3']=dict(range= [0, 100], #right y-axis in subplot (1,1)\n                              overlaying= 'y', \n                              anchor= 'x', \n                              side= 'right', \n                              showgrid= False, \n                              title= '%Churn Ratio'\n                             )\n\n    #Insert a new key, yaxis4, and the associated value:\n    fig['layout']['yaxis4']=dict(range= [-20, 100], #right y-axis in the subplot (1,2)\n                              overlaying= 'y2', \n                              anchor= 'x2', \n                              side= 'right', \n                              showgrid= False, \n                              title= 'Monhtly % Difference'\n                             )\n    fig['layout']['title'] = f\"{cat_col} Distributions\"\n    fig['layout']['height'] = 500\n    fig['layout']['width'] = 1000\n\n    iplot(fig)\n    \ndef plot_dist_churn(df, col, binary=None):\n    tmp_churn = df[df[binary] == 1]\n    tmp_no_churn = df[df[binary] == 0]\n    tmp_attr = round(tmp_churn[col].value_counts().sort_index() / df[col].value_counts().sort_index(),2)*100\n    print(f'Distribution of {col}: ')\n    trace1 = go.Bar(\n        x=tmp_churn[col].value_counts().sort_index().index,\n        y=tmp_churn[col].value_counts().sort_index().values,\n        name='Yes_Churn',opacity = 0.8, marker=dict(\n            color='seagreen',\n            line=dict(color='#000000',width=1)))\n\n    trace2 = go.Bar(\n        x=tmp_no_churn[col].value_counts().sort_index().index,\n        y=tmp_no_churn[col].value_counts().sort_index().values,\n        name='No_Churn', opacity = 0.8, \n        marker=dict(\n            color='indianred',\n            line=dict(color='#000000',\n                      width=1)\n        )\n    )\n\n    trace3 =  go.Scatter(   \n        x=tmp_attr.sort_index().index,\n        y=tmp_attr.sort_index().values,\n        yaxis = 'y2',\n        name='% Churn', opacity = 0.6, \n        marker=dict(\n            color='black',\n            line=dict(color='#000000',\n                      width=2 )\n        )\n    )\n    \n    layout = dict(title =  f'Distribution of {str(col)} feature by Target - With Churn Rates',\n              xaxis=dict(), \n              yaxis=dict(title= 'Count'), \n              yaxis2=dict(range= [0, 100], \n                          overlaying= 'y', \n                          anchor= 'x', \n                          side= 'right',\n                          zeroline=False,\n                          showgrid= False, \n                          title= 'Percentual Churn Ratio'\n                         ))\n\n    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n    iplot(fig)\n    \n    \ndef plot_distribution(df, var_select=None, bins=1.0): \n    # Calculate the correlation coefficient between the new variable and the target\n    tmp_churn = df[df['Churn'] == 1]\n    tmp_no_churn = df[df['Churn'] == 0]    \n    corr = df_train['Churn'].corr(df_train[var_select])\n    corr = np.round(corr,3)\n    tmp1 = tmp_churn[var_select].dropna()\n    tmp2 = tmp_no_churn[var_select].dropna()\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['Yes_churn', 'No_churn']\n    colors = ['seagreen','indianred', ]\n\n    fig = ff.create_distplot(hist_data,\n                             group_labels,\n                             colors = colors, \n                             show_hist = True,\n                             curve_type='kde', \n                             bin_size = bins\n                            )\n    \n    fig['layout'].update(title = var_select+' '+'(corr target ='+ str(corr)+')')\n\n    iplot(fig, filename = 'Density plot')\n    \ndef monthly_charges(df, col, binary=None):\n    #(df_train.groupby(['Churn', 'tenure'])['MonthlyCharges'].mean()).unstack('Churn').reset_index()\n    df_tmp = (df_train.groupby([binary, col])['MonthlyCharges'].mean().reset_index())\n    \n    tmp_churn = df_tmp[df_tmp['Churn'] == 1]\n    tmp_no_churn = df_tmp[df_tmp['Churn'] == 0]\n\n    df_tmp = (df_train.groupby([binary, col])['MonthlyCharges'].mean()).unstack('Churn').reset_index()\n    df_tmp['diff_rate'] = round((df_tmp[1] / df_tmp[0]) - 1,2) * 100\n    \n    trace1 = go.Bar(\n        x=tmp_churn[col],\n        y=tmp_churn['MonthlyCharges'],\n        name='Mean Charge\\nChurn',opacity = 0.8, marker=dict(\n            color='seagreen',\n            line=dict(color='#000000',width=1)))\n\n    trace2 = go.Bar(\n        x=tmp_no_churn[col],\n        y=tmp_no_churn['MonthlyCharges'],\n        name='Mean Charge No Churn', opacity = 0.8, \n        marker=dict(\n            color='indianred',\n            line=dict(color='#000000',\n                      width=1)\n        )\n    )\n    \n    trace3 =  go.Scatter(   \n        x=df_tmp[col],\n        y=df_tmp['diff_rate'],\n        yaxis = 'y2',\n        name='% Diff Churn', opacity = 0.6, \n        marker=dict(\n            color='black',\n            line=dict(color='#000000',\n                      width=5 )\n        )\n    )\n        \n    layout = dict(title =  f'Mean Monthly Charges of {str(col)} feature by Churn or Not Churn Customers - With Churn Ratio',\n              xaxis=dict(), \n              yaxis=dict(title= 'Mean Monthly Charges'), \n              yaxis2=dict(range= [0, 100], \n                          overlaying= 'y', \n                          anchor= 'x', \n                          side= 'right',\n                          zeroline=False,\n                          showgrid= False, \n                          title= '% diff Monthly Charges Mean'\n                         ))\n\n    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n    iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=10),2) \n\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resumetable(df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very interesting."},{"metadata":{},"cell_type":"markdown","source":"- We can see that we have one entry for each CustomerId\n- The dataset don't have missing values\n- Some features are categorical\n- The target the we will use to guide the exploration is Churn\n\n## Let's investigate the data further. \n- I will get all categorical features and see their distribution by the target \n- I will calculate the Churn Rate for each value in categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n                'PaperlessBilling', 'PhoneService', 'Contract', 'StreamingMovies',\n                'StreamingTV', 'TechSupport', 'OnlineBackup', 'OnlineSecurity',\n                'InternetService', 'MultipleLines', 'DeviceProtection', 'PaymentMethod']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Understanding the Churn Distribution\n- Let's known our target feature"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"CUSTOMERS %CHURN:\")\nprint(round(df_train['Churn'].value_counts(normalize=True) * 100,2))\n# df_train.groupby('Churn')['customerID'].count().iplot(kind='bar', title='Churn (Target) Distribution', \n#                                                      xTitle='Customer Churn?', yTitle='Count')\n\ntrace0 = go.Bar(\n    x=df_train.groupby('Churn')['customerID'].count().index,\n    y=df_train.groupby('Churn')['customerID'].count().values,\n    marker=dict(\n        color=['indianred', 'seagreen']),\n)\n\ndata = [trace0]\nlayout = go.Layout(\n    title='Churn (Target) Distribution', \n    xaxis=dict(\n        title='Customer Churn?'),\n    yaxis=dict(\n        title='Count')\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 26.5% of our data that is about the Churned customers, and I will try to understand the pattern of these groups<br>\nI will filter the dataset and set an dataset for Churn and Non Churn Customers.\n- Also, I will see if monthly Charges has some difference to Churn and Non-Churn Customers. <br>\n- I have the hipotesis that maybe Churn customers has a highest mean value of no churn customers"},{"metadata":{},"cell_type":"markdown","source":"## Monthly Charges Distribution\nLet's see the distribution of Monthly Charges by Churn and No Churn Customers. \n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_train['TotalCharges'].fillna(df_train['MonthlyCharges'], inplace=True)\ndf_train['Churn'] = df_train.Churn.replace({'Yes': 1, 'No': 0})\nprint(f\"The mininum value in Monthly Charges is {df_train['MonthlyCharges'].min()} and the maximum is {df_train['MonthlyCharges'].max()}\")\nprint(f\"The mean Monthly Charges of Churn Customers is {round(df_train[df_train['Churn'] != 0]['MonthlyCharges'].mean(),2)}\\\n      \\nThe mean Monthly Charges of Non-churn Customers is {round(df_train[df_train['Churn'] == 0]['MonthlyCharges'].mean(),2)}\")\n\nplot_distribution(df_train, 'MonthlyCharges', bins=4.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can see that monthly Charges have a medium correlation with Churn feature.\n- The distribution of Yes and No has clearly different pattern. "},{"metadata":{},"cell_type":"markdown","source":"## Ploting all categorical features "},{"metadata":{},"cell_type":"markdown","source":"I will plot all categorical features distributions with the % of Churn by each category and the mean and difference of Monhtly charges for each group "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"## The inspiration of this view is a Kernel that I saw in Vincent Lugat Kernel \n## I did some modifications but you can see the original on IBM \n\nfor col in cat_features:\n    binary_ploting_distributions(df_train, col) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Analyzing the outputs we can note that:\n- Gender,  PhoneService, MultipleLines don't have a clear difference Churn Rates between the values in categories\n- The other features seems that could be possible to help algorithmn predict Churn Customers\n- The features with the churn ratio values higher or equal to 40%: <br>\n-- Internet service<br>\n-- online Security<br>\n-- online Backup<br>\n-- tech support<br>\n-- contract<br>\n-- seniorcitzen<br>\n\nWe can see that in some categories, the churn customers have highest mean of monthly charges."},{"metadata":{},"cell_type":"markdown","source":"## Understanding the distribution of Total services provided for each Customer and the Churn % Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['internet']= np.where(df_train.InternetService != 'No', 'Yes', 'No')\n\ndf_train['num_services'] = (df_train[['PhoneService', 'OnlineSecurity',\n                                      'OnlineBackup', 'DeviceProtection', \n                                      'TechSupport', 'StreamingTV', \n                                      'StreamingMovies', 'internet']] == 'Yes').sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_ploting_distributions(df_train, 'num_services') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 22% of customers with only one service contracted... Of people with 1 service contract, 95% are Phone Service and 5% of total are DSL; \n\nAltought we have some part of our sample with one service, we can see that people with two services are more propense to left. \n\n100% of Customers with total of services 2+ has internet (DSL or Fiber)"},{"metadata":{},"cell_type":"markdown","source":"## Based on Num Services\n- I thought in see what's the Contract Type and the Churn distribution by each group"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def countplot(x, hue, **kwargs):\n    sns.countplot(x=x, hue=hue, **kwargs, order=['Month-to-month', 'One year', 'Two year'])\n\nprint(\"TOTAL NUMBER OF SERVICES BY CONTRACT AND CHURN\")\ngrid = sns.FacetGrid(data=df_train,col='num_services', col_wrap=2,\n                     aspect=1.9, height=3, sharey=False, sharex=False)\nfig = grid.map(countplot,'Contract','Churn', palette=['indianred', 'seagreen'] )\nfig.set_titles('Customer Total Services: {col_name}', fontsize=18)\nfig.add_legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very cool and meaningful visualization.\n\nWe can see difference in Contract feature in different total services that a customer has. "},{"metadata":{},"cell_type":"markdown","source":"## Knowning the Numerical Features\n- The total features is object because it contains blank space. <br>\n- When exploring the dataset, I noted that these values occurs in customers with tenure 0, that don't have generated the first bill.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_train.loc[df_train['TotalCharges'] == ' ', 'TotalCharges'] = np.nan\ndf_train['TotalCharges'] = df_train['TotalCharges'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- I will fill this Na's values with zero"},{"metadata":{},"cell_type":"markdown","source":"## Total of the Monthly Revenue Lose "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Total Amount of Monthly Charges by each group: \")\nprint(round(df_train.groupby('Churn')['MonthlyCharges'].sum() ))\n\ntrace0 = go.Bar(\n    x=round(df_train.groupby('Churn')['MonthlyCharges'].sum() \\\n      / df_train.groupby('Churn')['MonthlyCharges'].sum().sum() * 100).index, \n    y=round(df_train.groupby('Churn')['MonthlyCharges'].sum() \\\n      / df_train.groupby('Churn')['MonthlyCharges'].sum().sum() * 100).values,\n    marker=dict(\n        color=['indianred', 'seagreen']),\n)\n\ndata = [trace0]\nlayout = go.Layout(\n    title='Monthly Revenue % Lost by Churn Customer or not', \n    xaxis=dict(\n        title='Customer Churn?', type='category'), \n    yaxis=dict(\n        title='% of Total Monthly Revenue')\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that when we consider the amount of customers, the churn represents 26.5% of total customers, but when we consider Monthly Charges we can see that the ratio is 31% of total revenue was \"lost\" by people who left."},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Total Charges\n- To better view the Total Charges I will use the log of Total Charges"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_train['TotalCharges_log'] = np.log(df_train['TotalCharges']+1)\nprint(f\"The mininum value in Total Charges is {df_train['TotalCharges'].min()} and the maximum is {df_train['TotalCharges'].max()}\")\nprint(f\"The mean Total Charges of Churn Customers is {round(df_train[df_train['Churn'] != 0]['TotalCharges'].mean(),2)}\\\n      \\nThe mean Total Charges of Non-churn Customers is {round(df_train[df_train['Churn'] == 0]['TotalCharges'].mean(),2)}\")\n\nplot_distribution(df_train, 'TotalCharges_log', bins=.25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can note that churn customers has lower values in Total Charges.... I think that it's a signal of a different tenure values; <br>\nLet's check what tenure feature says."},{"metadata":{},"cell_type":"markdown","source":"## Tenure feature\n- Let's understand the distribution and churn probabilities by Tenure"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f\"The mininum value in Tenure is {df_train['tenure'].min()} and the maximum is {df_train['tenure'].max()}\")\nprint(f\"The mean Tenure of Churn Customers is {round(df_train[df_train['Churn'] != 0]['tenure'].mean())}\\\n      \\nThe mean Tenure of Non-churn Customers is {round(df_train[df_train['Churn'] == 0]['tenure'].mean())}\")\n\nplot_dist_churn(df_train, 'tenure', 'Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the mean of two groups has different... To afirm it, we need to do a statistc test, but it's a very insightful visualization."},{"metadata":{},"cell_type":"markdown","source":"## Mean Monthly Charges by tenure with Churn Rate of tenure values"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"MEAN MONTHLY CHARGES OF TENURE FOR CHURN OR NO CHURN CUSTOMERS\")\n    \nmonthly_charges(df_train, 'tenure', 'Churn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very insightful. The mean of Monthly Charges and the difference Churn Customer is highest in Churn Customers. \nwe can see that in tenure 45 months, is the unique \n"},{"metadata":{},"cell_type":"markdown","source":"## The Average Monthly Charges by Total Number of Services Contracted\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"monthly_charges(df_train, 'num_services', 'Churn') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nNice! We can see that to customers that has only Phone Services we cannot see difference in average monthly charges. <br>\nIn customers with two or more services we can see difference in Average Monthly Charges of Churn Customers to Customers who keep the services"},{"metadata":{},"cell_type":"markdown","source":"## Knowing Tenure by Total Charges for each Target value"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tmp_churn = df_train[df_train['Churn'] == 1]\ntmp_no_churn = df_train[df_train['Churn'] == 0]\n\ntmp_churn_fiber = tmp_churn[tmp_churn['InternetService'] == 'Fiber optic']\ntmp_churn_dsl = tmp_churn[tmp_churn['InternetService'] == 'DSL']\ntmp_churn_no = tmp_churn[tmp_churn['InternetService'] == 'No']\n\ntmp_no_churn_fiber = tmp_no_churn[tmp_no_churn['InternetService'] == 'Fiber optic']\ntmp_no_churn_dsl = tmp_no_churn[tmp_no_churn['InternetService'] == 'DSL']\ntmp_no_churn_no = tmp_no_churn[tmp_no_churn['InternetService'] == 'No']\n\n# Create traces\ntrace0 = go.Scatter(\n    x = tmp_churn_fiber['tenure'],\n    y = tmp_churn_fiber['MonthlyCharges'],\n    mode = 'markers', opacity=.6,\n    name = 'Churn - Fiber', marker=dict(\n        color='indianred', symbol='star'\n))\ntrace1 = go.Scatter(\n    x = tmp_churn_dsl['tenure'],\n    y = tmp_churn_dsl['MonthlyCharges'],\n    mode = 'markers', opacity=.6,\n    name = 'Churn - DSL', marker=dict(\n        color='indianred', symbol='square'\n))\ntrace2 = go.Scatter(\n    x = tmp_churn_no['tenure'],\n    y = tmp_churn_no['MonthlyCharges'],\n    mode = 'markers', opacity=.6,\n    name = 'Churn - No', marker=dict(\n        color='indianred', symbol='circle'\n))\n\n# Create traces\ntrace3 = go.Scatter(\n    x = tmp_no_churn_fiber['tenure'],\n    y = tmp_no_churn_fiber['MonthlyCharges'],\n    mode = 'markers', opacity=.6,\n    name = 'No-Churn-Fiber', marker=dict(\n        color='seagreen', symbol='star'\n))\ntrace4 = go.Scatter(\n    x = tmp_no_churn_dsl['tenure'],\n    y = tmp_no_churn_dsl['MonthlyCharges'],\n    mode = 'markers', opacity=.6,\n    name = 'No-Churn-DSL', marker=dict(\n        color='seagreen', symbol='square'\n))\ntrace5 = go.Scatter(\n    x = tmp_no_churn_no['tenure'],\n    y = tmp_no_churn_no['MonthlyCharges'],\n    mode = 'markers', opacity=.6,\n    name = 'No-Churn-No', marker=dict(\n        color='seagreen', symbol='circle'\n))\n\nlayout = dict(title ='Dispersion of Total Charges explained by Monthly Charges by Target',\n              xaxis=dict(title='Internet Service Types'), \n              yaxis=dict(title= 'Monthly Charges'))\n\nfig = go.Figure(data = [trace0, trace3, trace1, trace4, trace2, trace5], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see a \"linear function\" where the two features are very correlated and it that make a lot of sense. <br>\nI tought that could be interesting if we divide the Total charges by the Monthly Charges and we will get the months till the Churn... It would be very close value of tenure"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['assign_months'] = round(df_train['TotalCharges'] / df_train['MonthlyCharges'],0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Comparing Tenure and Assign Months\")\npd.concat([df_train['assign_months'].describe().reset_index(),\n           df_train['tenure'].describe().reset_index()['tenure']], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cool.\nAs we can see, the both features shows the same information, so I will drop the new features that I created"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop('assign_months', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Mean Monthly Charges by Categorical Features and the Diff Ratio of Charges"},{"metadata":{},"cell_type":"markdown","source":"## Let's see the Ratio of Revenue lost by some interesting Features\n- This charts shows the "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"color_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\ndef PieChart(df_cat, df_value, title, limit=15):\n    \"\"\"\n    This function helps to investigate the proportion of metrics of toxicity and other values\n    \"\"\"\n\n    # count_trace = df_train[df_cat].value_counts()[:limit].to_frame().reset_index()\n    tmp_churn = df_train[df_train['Churn'] == 1].groupby(df_cat)[df_value].sum().nlargest(limit).to_frame().reset_index()\n    tmp_no_churn = df_train[df_train['Churn'] == 0].groupby(df_cat)[df_value].sum().nlargest(limit).to_frame().reset_index()\n\n    trace1 = go.Pie(labels=tmp_no_churn[df_cat], \n                    values=tmp_no_churn[df_value], name= \"No-Churn\", hole= .5, \n                    hoverinfo=\"label+percent+name+value\", showlegend=True,\n                    domain= {'x': [0, .48]})\n\n    trace2 = go.Pie(labels=tmp_churn[df_cat], \n                    values=tmp_churn[df_value], name=\"Churn\", hole= .5, \n                    hoverinfo=\"label+percent+name+value\", showlegend=False, \n                    domain= {'x': [.52, 1]})\n\n    layout = dict(title= title, height=450, font=dict(size=15),\n                  annotations = [\n                      dict(\n                          x=.20, y=.5,\n                          text='No Churn', \n                          showarrow=False,\n                          font=dict(size=20)\n                      ),\n                      dict(\n                          x=.80, y=.5,\n                          text='Churn', \n                          showarrow=False,\n                          font=dict(size=20)\n                      )\n        ])\n\n    fig = dict(data=[trace1, trace2], layout=layout)\n    iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Internet Service\nFor instance:<br>\nOptical fiber is responsible for 53% (168,99k) of the monthly revenue, DSL 37% (118,14k) and 9% of customers don't have "},{"metadata":{"trusted":true},"cell_type":"code","source":"no_churn_monthly_renenue = tmp_no_churn['MonthlyCharges'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"InternetService\", 'MonthlyCharges', \"Internet Services Total Charges by Churn\", limit=10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Contract types "},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"Contract\", 'MonthlyCharges', \"Type of Contract by Churn or not with Ratio of Monthly Charges\", limit=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice. 87% of all monthly revenue lost are caused by customers with Month-to-Month Contracts\n- As we can see in some graphs, Contract has a lot of informations about the Churn and it could help us to predict. "},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Multiple Lines"},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"MultipleLines\", 'MonthlyCharges', \"Type of Contract by Churn or not with Ratio of Monthly Charges\", limit=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Device Protection"},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"DeviceProtection\", 'MonthlyCharges', \"Type of Contract by Churn or not with Ratio of Monthly Charges\", limit=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Tech Support"},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"TechSupport\", 'MonthlyCharges', \"Type of Contract by Churn or not with Ratio of Monthly Charges\", limit=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Online Backup\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"OnlineBackup\", 'MonthlyCharges', \"Type of Contract by Churn or not with Ratio of Monthly Charges\", limit=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## %Ratio of Monthly Charges by Online Security"},{"metadata":{"trusted":true},"cell_type":"code","source":"PieChart(\"OnlineSecurity\", 'MonthlyCharges', \"Type of Contract by Churn or not with Ratio of Monthly Charges\", limit=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Based on the plots, let's create some binary features and see the distributions again"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Feature engineering and preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"Id_col     = ['customerID']\n\ntarget_col = [\"Churn\"]\n\ncat_cols   = df_train.nunique()[df_train.nunique() < 10].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nbinary_cols   = df_train.nunique()[df_train.nunique() == 2].keys().tolist()\n\nmulti_cols = [i for i in cat_cols if i not in binary_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.loc[:,'Engaged'] = np.where(df_train['Contract'] != 'Month-to-month', 1,0)\ndf_train.loc[:,'YandNotE'] = np.where((df_train['SeniorCitizen']==0) & (df_train['Engaged']==0), 1,0)\ndf_train.loc[:,'ElectCheck'] = np.where((df_train['PaymentMethod'] == 'Electronic check') & (df_train['Engaged']==0), 1,0)\ndf_train.loc[:,'fiberopt'] = np.where((df_train['InternetService'] != 'Fiber optic'), 1,0)\ndf_train.loc[:,'StreamNoInt'] = np.where((df_train['StreamingTV'] != 'No internet service'), 1,0)\ndf_train.loc[:,'NoProt'] = np.where((df_train['OnlineBackup'] != 'No') |\\\n                                    (df_train['DeviceProtection'] != 'No') |\\\n                                    (df_train['TechSupport'] != 'No'), 1,0)\n\ndf_train['TotalServices'] = (df_train[['PhoneService', 'InternetService', 'OnlineSecurity',\n                                       'OnlineBackup', 'DeviceProtection', 'TechSupport',\n                                       'StreamingTV', 'StreamingMovies']]== 'Yes').sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n#Label encoding Binary columns\nle = LabelEncoder()\n\ntmp_churn = df_train[df_train['Churn'] == 1]\ntmp_no_churn = df_train[df_train['Churn'] == 0]\n\nbi_cs = df_train.nunique()[df_train.nunique() == 2].keys()\ndat_rad = df_train[bi_cs]\n\nfor cols in bi_cs :\n    tmp_churn[cols] = le.fit_transform(tmp_churn[cols])\n    \n\ndata_frame_x = tmp_churn[bi_cs].sum().reset_index()\ndata_frame_x.columns  = [\"feature\",\"yes\"]\ndata_frame_x[\"no\"]    = tmp_churn.shape[0]  - data_frame_x[\"yes\"]\ndata_frame_x  = data_frame_x[data_frame_x[\"feature\"] != \"Churn\"]\n\n#count of 1's(yes)\ntrace1 = go.Scatterpolar(r = data_frame_x[\"yes\"].values.tolist(), \n                         theta = data_frame_x[\"feature\"].tolist(),\n                         fill  = \"toself\",name = \"Churn 1's\",\n                         mode = \"markers+lines\", visible=True,\n                         marker = dict(size = 5)\n                        )\n\n#count of 0's(No)\ntrace2 = go.Scatterpolar(r = data_frame_x[\"no\"].values.tolist(),\n                         theta = data_frame_x[\"feature\"].tolist(),\n                         fill  = \"toself\",name = \"Churn 0's\",\n                         mode = \"markers+lines\", visible=True,\n                         marker = dict(size = 5)\n                        ) \nfor cols in bi_cs :\n    tmp_no_churn[cols] = le.fit_transform(tmp_no_churn[cols])\n    \ndata_frame_x = tmp_no_churn[bi_cs].sum().reset_index()\ndata_frame_x.columns  = [\"feature\",\"yes\"]\ndata_frame_x[\"no\"]    = tmp_no_churn.shape[0]  - data_frame_x[\"yes\"]\ndata_frame_x  = data_frame_x[data_frame_x[\"feature\"] != \"Churn\"]\n\n#count of 1's(yes)\ntrace3 = go.Scatterpolar(r = data_frame_x[\"yes\"].values.tolist(),\n                         theta = data_frame_x[\"feature\"].tolist(),\n                         fill  = \"toself\",name = \"NoChurn 1's\",\n                         mode = \"markers+lines\", visible=False,\n                         marker = dict(size = 5)\n                        )\n\n#count of 0's(No)\ntrace4 = go.Scatterpolar(r = data_frame_x[\"no\"].values.tolist(),\n                         theta = data_frame_x[\"feature\"].tolist(),\n                         fill  = \"toself\",name = \"NoChurn 0's\",\n                         mode = \"markers+lines\", visible=False,\n                         marker = dict(size = 5)\n                        ) \n\ndata = [trace1, trace2, trace3, trace4]\n\nupdatemenus = list([\n    dict(active=0,\n         x=-0.15,\n         buttons=list([  \n            dict(\n                label = 'Churn Dist',\n                 method = 'update',\n                 args = [{'visible': [True, True, False, False]}, \n                     {'title': 'Customer Churn Binary Counting Distribution'}]),\n             \n             dict(\n                  label = 'No-Churn Dist',\n                 method = 'update',\n                 args = [{'visible': [False, False, True, True]},\n                     {'title': 'No Customer Churn Binary Counting Distribution'}]),\n\n        ]),\n    )\n])\n\nlayout = dict(title='ScatterPolar Distribution of Churn and Non-Churn Customers (Select from Dropdown)', \n              showlegend=False,\n              updatemenus=updatemenus)\n\nfig = dict(data=data, layout=layout)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice, we can easily access a lot of information about our customers.\n"},{"metadata":{},"cell_type":"markdown","source":"# Creating new numerical columns"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"multi_cols.remove('Contract')\ndf_train['monthly_diff_mean'] = df_train['MonthlyCharges'] / df_train['MonthlyCharges'].mean() \nfor cat in cat_cols:\n    df_train[str(cat)+'_diff_mean'] = df_train['MonthlyCharges'] / df_train.groupby(['Contract',cat])['MonthlyCharges'].transform('mean')\n    df_train[str(cat)+'_diff_std'] = df_train['MonthlyCharges'] / df_train.groupby(['Contract',cat])['MonthlyCharges'].transform('std')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding and binarizing features"},{"metadata":{"trusted":true},"cell_type":"code","source":"for cols in binary_cols :\n    df_train[cols] = le.fit_transform(df_train[cols])\n    \n#Duplicating columns for multi value columns\ndf_train = pd.get_dummies(data = df_train,columns = multi_cols )\n\ndf_train.drop(\"Contract\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols   = [x for x in df_train.columns if x not in cat_cols + target_col + Id_col]\n\nfrom sklearn.preprocessing import StandardScaler\ndf_train.fillna(-99, inplace=True)\n#Scaling Numerical columns\nss = StandardScaler()\nscl = ss.fit_transform(df_train[num_cols])\nscl = pd.DataFrame(scl, columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\n# df_data_og = df_train.copy()\n\ndf_train = df_train.drop(columns = num_cols,axis = 1)\ndf_train = df_train.merge(scl, left_index=True, right_index=True, how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection\n- Let's use the correlation to drop features high correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Threshold for removing correlated variables\nthreshold = 0.90\n\n# Absolute value correlation matrix\ncorr_matrix = df_train.corr().abs()\n\n# Getting the upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))\nprint(list(to_drop))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.drop(columns = to_drop)\nprint('Training shape: ', df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing - Seting X and y\n- spliting into X_train and X_val"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train = df_train.drop(['Churn', 'customerID'], axis=1)\ny_train = df_train['Churn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classifier models pipeline"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, \n                                                                       n_estimators=1000))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, \n                                 cv=kfold, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(),  \n                               cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#MODEL FUNCTION\n\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n\ndef model(algorithm, X_train, y_train, \n          X_val, y_val, of_type):\n    \n    print (\"*****************************************************************************************\")\n    print (\"MODEL - OUTPUT\")\n    print (\"*****************************************************************************************\")\n    algorithm.fit(X_train.values,y_train.values)\n    predictions = algorithm.predict(X_val.values)\n    \n    print (\"\\naccuracy_score :\",accuracy_score(y_val, predictions))\n    \n    print (\"\\nclassification report :\\n\",(classification_report(y_val, predictions)))\n        \n    plt.figure(figsize=(14,12))\n    plt.subplot(221)\n    sns.heatmap(confusion_matrix(y_val, predictions),\n                annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n    \n    plt.title(\"CONFUSION MATRIX\",fontsize=20)\n    \n    predicting_probabilites = algorithm.predict_proba(X_val)[:,1]\n    fpr,tpr,thresholds = roc_curve(y_val,predicting_probabilites)\n    plt.subplot(222)\n    plt.plot(fpr,tpr,label = (\"Area_under the curve :\",auc(fpr,tpr)),color = \"r\")\n    plt.plot([1,0],[1,0],linestyle = \"dashed\",color =\"k\")\n    plt.legend(loc = \"best\")\n    plt.title(\"ROC - CURVE & AREA UNDER CURVE\",fontsize=20)\n    \n    if  of_type == \"feat\":\n        \n        dataframe = pd.DataFrame(algorithm.feature_importances_, X_train.columns).reset_index()\n        dataframe = dataframe.rename(columns={\"index\":\"features\",0:\"coefficients\"})\n        dataframe = dataframe.sort_values(by=\"coefficients\",ascending = False)\n        plt.subplot(224)\n        ax = sns.barplot(x = \"coefficients\" ,y =\"features\",data=dataframe,palette=\"husl\")\n        plt.title(\"FEATURE IMPORTANCES\",fontsize =20)\n        for i,j in enumerate(dataframe[\"coefficients\"]):\n            ax.text(.011,i,j,weight = \"bold\")\n    \n    elif of_type == \"coef\" :\n        \n        dataframe = pd.DataFrame(algorithm.coef_.ravel(),X_train.columns).reset_index()\n        dataframe = dataframe.rename(columns={\"index\":\"features\",0:\"coefficients\"})\n        dataframe = dataframe.sort_values(by=\"coefficients\",ascending = False)\n        plt.subplot(224)\n        ax = sns.barplot(x = \"coefficients\" ,y =\"features\",data=dataframe,palette=\"husl\")\n        plt.title(\"FEATURE IMPORTANCES\",fontsize =20)\n        for i,j in enumerate(dataframe[\"coefficients\"]):\n            ax.text(.011,i,j,weight = \"bold\")\n            \n    elif of_type == \"none\" :\n        return (algorithm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Prediction and Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf =LogisticRegression(solver = \"lbfgs\", multi_class = \"auto\")\n\nmodel(rf,X_train, y_train,\n      X_val, y_val, \"coef\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBClassifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(n_estimators=800, n_jobs=-1)\n\nxgb.fit(X_train.values,y_train.values)\npredictions = xgb.predict(X_val.values)\n\nprint (\"\\naccuracy_score :\",accuracy_score(y_val, predictions))\n\nprint (\"\\nclassification report :\\n\",(classification_report(y_val, predictions)))\n\nplt.figure(figsize=(14,12))\nplt.subplot(221)\nsns.heatmap(confusion_matrix(y_val, predictions),\n            annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n\nplt.title(\"CONFUSION MATRIX\",fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Model and Feature Importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf =RandomForestClassifier(n_estimators=500)\n\nmodel(rf,X_train, y_train,\n      X_val, y_val, \"feat\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NOTE: This kernel is not finished. If you think that it's useful, votes up the kernel "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}