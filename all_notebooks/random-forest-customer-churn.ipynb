{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Hi, welcome to my project!, today we will build random forest and extra trees classifiers to predict customer churn. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's read our csv file, take into account the file we will use today was generated from a previous project in which we worked with KNN.","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/churndata/churndata_processed.csv')\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see how many unique values we have in each column of our dataframe:","metadata":{}},{"cell_type":"code","source":"for x in data.columns:\n    print(x, len(data[x].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,10)) \nsns.heatmap(data.corr())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see how in the proportion of the classes in our label:","metadata":{}},{"cell_type":"code","source":"target='churn_value'\ndata[target].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[target].value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splitting our dataset:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\n\nfeature_cols = [x for x in data.columns if x != target]\n\n\n# Split the data into two parts with 1500 points in the test data\n# This creates a generator\nstrat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=1500, random_state=42)\n\n# Get the index values from the generator\ntrain_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], data[target]))\n\n# Create the data sets\nX_train = data.loc[train_idx, feature_cols]\ny_train = data.loc[train_idx, target]\n\nX_test = data.loc[test_idx, feature_cols]\ny_test = data.loc[test_idx, target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest:","metadata":{}},{"cell_type":"markdown","source":"### Let's fit random forest models with a range of tree numbers, then evaluate the out-of-bag error for each of these.","metadata":{}},{"cell_type":"code","source":"# Suppress warnings about too few trees from the early models\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: Since the only thing changing in our model is the number of trees, the **warm_start** flag can be used so that the model just adds more trees to the existing model each time. Thus we should have to use the **set_params** method to update the number of trees.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\nRF = RandomForestClassifier(oob_score=True, \n                            random_state=42, \n                            warm_start=True,\n                            n_jobs=-1)\n\noob_list = list()\n\nfor n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]:\n    \n    # Use this to set the number of trees\n    RF.set_params(n_estimators=n_trees)\n\n    # Fit the model\n    RF.fit(X_train, y_train)\n\n    # Get the oob error\n    oob_error = 1 - RF.oob_score_\n    \n    # Store it\n    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n\nrf_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n\nrf_oob_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's plot the resulting oob errors as a function of the number of trees.","metadata":{}},{"cell_type":"code","source":"sns.set_context('talk')\nsns.set_style('white')\n\nax = rf_oob_df.plot(legend=False, marker='o', figsize=(14, 7), linewidth=5)\nax.set(ylabel='out-of-bag error');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  ExtraTreesClassifier\n### After building this model, we are going to compare out-of-bag errors for the two different types of models.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nEF = ExtraTreesClassifier(oob_score=True, \n                          random_state=42, \n                          warm_start=True,\n                          bootstrap=True,\n                          n_jobs=-1)\n\noob_list = list()\n\nfor n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]:\n    \n    # Use this to set the number of trees\n    EF.set_params(n_estimators=n_trees)\n    EF.fit(X_train, y_train)\n\n    # oob error\n    oob_error = 1 - EF.oob_score_\n    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n\net_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n\net_oob_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It would be better if we create a dataframe with both oob-errors as columns in order to be easier to plot both lines.","metadata":{}},{"cell_type":"code","source":"oob_df = pd.concat([rf_oob_df.rename(columns={'oob':'RandomForest'}),\n                    et_oob_df.rename(columns={'oob':'ExtraTrees'})], axis=1)\n\noob_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context('talk')\nsns.set_style('white')\n\nax = oob_df.plot(marker='o', figsize=(14, 7), linewidth=5)\nax.set(ylabel='out-of-bag error');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see in the figure above **RandomForest error is lower**, therefore is the best model for our case of study. We could select number of trees = 200 as the model which gave us the lowest oob-error and compute its corresponding error metrics. ","metadata":{}},{"cell_type":"markdown","source":"### Now let's select the RandomForest model for 200 trees and calculate error metrics and confusion matrix on the test data set:","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRF_200 = RandomForestClassifier(n_estimators=200\n          ,oob_score=True \n          ,random_state=42\n          ,n_jobs=-1)\n\nRF_200.fit(X_train,y_train)\noob_error200 = 1 - RF_200.oob_score_\noob_error200","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=RF_200.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Computing error metrics for n=200:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report, roc_auc_score\n\ncr = classification_report(y_test, y_pred)\nprint(cr)\n\nscore_df = [['accuracy', accuracy_score(y_test, y_pred)],\n            ['precision', precision_score(y_test, y_pred)],\n            ['recall', recall_score(y_test, y_pred)],\n            ['f1', f1_score(y_test, y_pred)],\n            ['auc', roc_auc_score(y_test, y_pred)]] \n\nscore_df=pd.DataFrame(score_df,columns=['Error metric','Measurement']).set_index('Error metric')\nscore_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_RF200=confusion_matrix(y_test,y_pred)\ncm_RF200","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disp = ConfusionMatrixDisplay(confusion_matrix=cm_RF200, display_labels=RF_200.classes_)\ndisp.plot(cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The ROC-AUC and precision-recall curves.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, precision_recall_curve\nsns.set_context('talk')\n\nfig, axList = plt.subplots(ncols=2)\nfig.set_size_inches(16, 8)\n\n# Get the probabilities for each of the two categories\ny_prob = RF_200.predict_proba(X_test)\n\n# Plot the ROC-AUC curve\nax = axList[0]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])\nax.plot(fpr, tpr, linewidth=5)\n# It is customary to draw a diagonal dotted line in ROC plots.\n# This is to indicate completely random prediction. Deviation from this\n# dotted line towards the upper left corner signifies the power of the model.\nax.plot([0, 1], [0, 1], ls='--', color='black', lw=.3)\nax.set(xlabel='False Positive Rate',\n       ylabel='True Positive Rate',\n       xlim=[-.01, 1.01], ylim=[-.01, 1.01],\n       title='ROC curve')\nax.grid(True)\n\n# Plot the precision-recall curve\nax = axList[1]\n\nprecision, recall, _ = precision_recall_curve(y_test, y_prob[:,1])\nax.plot(recall, precision, linewidth=5)\nax.set(xlabel='Recall', ylabel='Precision',\n       xlim=[-.01, 1.01], ylim=[-.01, 1.01],\n       title='Precision-Recall curve')\nax.grid(True)\n\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The feature importances plot. Satisfaction is the biggest predictor of customer churn.","metadata":{}},{"cell_type":"code","source":"feat=pd.DataFrame(RF_200.feature_importances_,index=feature_cols, columns=['Importance']).sort_values(by='Importance',ascending=False)\nax=feat.plot(kind='bar', figsize=(16,6))\nax.set(ylabel='Feature Importance')\nax.set(xlabel='Features')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}