{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic - Machine Learning from Disaster\n\n<a href=\"#general_inspection\">1. General inspection</a>\n\n<a href=\"#visualizations\">2. Visualizations</a>\n\n<a href=\"#missing_data\">3. Missing data</a>\n\n<a href=\"#categorical_features\">4. Categorical features</a>\n\n<a href=\"#creating_features\">5. Creating/modifying features</a>\n\n<a href=\"#models\">6. Models and predictions (Logistic Regression, Random Forest, Support Vector, XGBoost, Neural Network, Voting Classifier)</a>\n\n<a href=\"#results\">7. Submit results</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom xgboost import XGBClassifier\nimport tensorflow as tf\nfrom keras.models import Sequential \nfrom keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nsns.set_style('darkgrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '../input/titanic'\n\nprint(os.listdir(data_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n- Train and Test sets.\n- gender_submission.csv is an example of a submission file for the competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(os.path.join(data_path, 'train.csv'), index_col='PassengerId')\ntest  = pd.read_csv(os.path.join(data_path, 'test.csv'), index_col='PassengerId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a copy of the original datasets\ntrain_original = train.copy()\ntest_original  = test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"general_inspection\">1. General inspection</a>"},{"metadata":{},"cell_type":"markdown","source":"### Target\n\n- **Survived** (*int*): wheter the passenger survived or not --> 0 = No, 1 = Yes.\n\n### Features\n\n- **Pclass** (*int*): ticket class --> 1 = first class, 2 = second class, 3 = third class.\n\n- **Name** (*str*).\n\n- **Sex** (*str*): male or female.\n\n- **Age** (*float*): age in years (fractional if less than 1; if the age is estimated, it is in the form of xx.5).\n\n- **SibSp** (*int*): number of siblings and spouse that travelled with the passenger.\n\n- **Parch** (*int*): number of childs and parents that travelled with the passenger.\n\n- **Ticket** (*str*): ticket number (**NOT USED**).\n\n- **Fare** (*float*): passenger fare.\n\n- **Cabin** (*str*): cabin number (**NOT USED**).\n\n- **Embarked** (*str*): port of embarkation --> C = Cherbourg, Q = Queenstown, S = Southampton."},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'Survived'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the Ticket, Cabin and Name columns\ntrain = train.drop(['Ticket', 'Cabin'], axis=1)\ntest  = test.drop(['Ticket', 'Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(test.columns)\n\nprint(f'- Number of rows (train) = {len(train)}')\nprint(f'- Number of rows (test) = {len(test)}')\nprint(f'- Number of used features = {len(features)} --> {features}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"visualizations\">2. Visualizations</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def annotate_barplot_with_percentages(ax, fontsize=12):\n    \"\"\"Function to annotate barplots with percentages.\"\"\"\n\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height() / len(train))\n        x = p.get_x() + p.get_width() / 2\n        y = p.get_height() / 2\n        ax.annotate(percentage, (x, y), ha='center', fontsize=fontsize, fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Simple plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2, 3, figsize=(16, 10))\n# Survivors plot\nax_1 = sns.countplot(x=target, data=train, palette='Blues', ax=axes[0, 0])\nax_1.set_title('Survival', fontsize=14, fontweight='bold')\nax_1.set_xticklabels(['No', 'Yes'])\nannotate_barplot_with_percentages(ax_1)\n# Pclass plot\nax_2 = sns.countplot(x='Pclass', data=train, palette='Blues', ax=axes[0, 1])\nax_2.set_title('Pclass', fontsize=14, fontweight='bold')\nannotate_barplot_with_percentages(ax_2)\n# Sex plot\nax_3 = sns.countplot(x='Sex', data=train, palette='Blues', ax=axes[0, 2])\nax_3.set_title('Sex', fontsize=14, fontweight='bold')\nannotate_barplot_with_percentages(ax_3)\n# Age distribution plot\nbin_size = 10\nax_4 = sns.distplot(train['Age'], bins=int(train['Age'].max() / bin_size), ax=axes[1, 0])\nax_4.set_title('Age distribution', fontsize=14, fontweight='bold')\n# Fare distribution plot\nbin_size = 10\nax_5 = sns.distplot(train['Fare'], bins=int(train['Fare'].max() / bin_size), ax=axes[1, 1])\nax_5.set_title('Fare distribution', fontsize=14, fontweight='bold')\n# Embarked plot\nax_6 = sns.countplot(x='Embarked', data=train, palette='Blues', ax=axes[1, 2])\nax_6.set_title('Embarked', fontsize=14, fontweight='bold')\nannotate_barplot_with_percentages(ax_6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Survival plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1, 3, figsize=(16, 5))\n# Sex hue plot\nax_1 = sns.countplot(x=target, data=train, hue='Sex', palette='Blues', ax=axes[0])\nax_1.set_title('Survival by Sex', fontsize=14, fontweight='bold')\nax_1.set_xticklabels(['No', 'Yes'])\nannotate_barplot_with_percentages(ax_1, fontsize=10)\n# Pclass hue plot\nax_2 = sns.countplot(x=target, data=train, hue='Pclass', palette='Blues', ax=axes[1])\nax_2.set_title('Survival by Pclass', fontsize=14, fontweight='bold')\nax_2.set_xticklabels(['No', 'Yes'])\nannotate_barplot_with_percentages(ax_2, fontsize=10)\n# Embarked hue plot\nax_3 = sns.countplot(x=target, data=train, hue='Embarked', palette='Blues', ax=axes[2])\nax_3.set_title('Survival by Embarked', fontsize=14, fontweight='bold')\nax_3.set_xticklabels(['No', 'Yes'])\nannotate_barplot_with_percentages(ax_3, fontsize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"missing_data\">3. Missing data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify features with missing values (NaN)\n\nprint('===== TRAIN =====')\nfor feature_with_nans in train.loc[:, train.isna().sum() > 0]:\n    number_of_nans = train[feature_with_nans].isna().sum()\n    print(f'- {feature_with_nans} --> {number_of_nans} ({round(100 * number_of_nans / len(train), 2)} %)')\n\nprint('\\n===== TEST =====')\nfor feature_with_nans in test.loc[:, test.isna().sum() > 0]:\n    number_of_nans = test[feature_with_nans].isna().sum()\n    print(f'- {feature_with_nans} --> {number_of_nans} ({round(100 * number_of_nans / len(test), 2)} %)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute Age feature with their median value\nsimple_imputer = SimpleImputer(strategy='median')\ntrain['Age']   = simple_imputer.fit_transform(train[['Age']])\ntest['Age']    = simple_imputer.fit_transform(test[['Age']])\n\n# Impute Fare feature with their mean value\nsimple_imputer = SimpleImputer(strategy='mean')\ntest['Fare']   = simple_imputer.fit_transform(test[['Fare']])\n\n# Impute Embarked feature with the most frequent value\nsimple_imputer    = SimpleImputer(strategy='most_frequent')\ntrain['Embarked'] = simple_imputer.fit_transform(train[['Embarked']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check that there are no more missing values\nif (train.isna().sum().sum() == 0) and (test.isna().sum().sum() == 0):\n    print('Great! Now there are no missing values.')\nelse:\n    print('Ooops! There are still some missing values.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## <a id=\"categorical_features\">4. Categorical features</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode Sex and Embarked features with one hot encoder\none_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n\ntrain_encoded_df = pd.DataFrame(one_hot_encoder.fit_transform(train[['Sex']]).toarray(), columns=['Female', 'Male'], index=train.index)\ntest_encoded_df  = pd.DataFrame(one_hot_encoder.fit_transform(test[['Sex']]).toarray(), columns=['Female', 'Male'], index=test.index)\n\ntrain = train.join(train_encoded_df)\ntest  = test.join(test_encoded_df)\n\ntrain_encoded_df = pd.DataFrame(one_hot_encoder.fit_transform(train[['Embarked']]).toarray(), columns=['C', 'Q', 'S'], index=train.index)\ntest_encoded_df  = pd.DataFrame(one_hot_encoder.fit_transform(test[['Embarked']]).toarray(), columns=['C', 'Q', 'S'], index=test.index)\n\ntrain = train.join(train_encoded_df)\ntest  = test.join(test_encoded_df)\n\ntrain = train.drop(['Sex', 'Male', 'Embarked'], axis=1)\ntest  = test.drop(['Sex', 'Male', 'Embarked'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"creating_features\">5. Creating/modifying features</a>"},{"metadata":{},"cell_type":"markdown","source":"### Name feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the Title feature based on the Name column\ntrain['Title'] = train['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())\ntest['Title']  = test['Name'].apply(lambda name: name.split(',')[1].split('.')[0].strip())\n\n# Normalized titles\nnormalized_titles = {\n                     \"Capt\":         \"Officer\",\n                     \"Col\":          \"Officer\",\n                     \"Major\":        \"Officer\",\n                     \"Jonkheer\":     \"Royalty\",\n                     \"Don\":          \"Royalty\",\n                     \"Sir\" :         \"Royalty\",\n                     \"Dr\":           \"Officer\",\n                     \"Rev\":          \"Officer\",\n                     \"the Countess\": \"Royalty\",\n                     \"Dona\":         \"Royalty\",\n                     \"Mme\":          \"Mrs\",\n                     \"Mlle\":         \"Mrs\",\n                     \"Ms\":           \"Mrs\",\n                     \"Mr\" :          \"Mr\",\n                     \"Mrs\" :         \"Mrs\",\n                     \"Miss\" :        \"Mrs\",\n                     \"Master\" :      \"Master\",\n                     \"Lady\" :        \"Royalty\"\n                    }\n\n# Map the normalized titles to the current titles\ntrain['Title'] = train['Title'].map(normalized_titles)\ntest['Title']  = test['Title'].map(normalized_titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode Ttile feature with one hot encoder\none_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n\ncolumns = ['Title_1', 'Title_2', 'Title_3', 'Title_4', 'Title_5']\n\ntrain_encoded_df = pd.DataFrame(one_hot_encoder.fit_transform(train[['Title']]).toarray(), columns=columns, index=train.index)\ntest_encoded_df  = pd.DataFrame(one_hot_encoder.fit_transform(test[['Title']]).toarray(), columns=columns, index=test.index)\n\ntrain = train.join(train_encoded_df)\ntest  = test.join(test_encoded_df)\n\ntrain = train.drop(['Name', 'Title'], axis=1)\ntest  = test.drop(['Name', 'Title'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SibSp and Parch features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a feature using SibSp and Parch that indicates if the person was travelling with any relative\ntrain['WithFamily'] = (train['SibSp'] + train['Parch'] > 0).astype(int)\ntest['WithFamily']  = (test['SibSp'] + test['Parch'] > 0).astype(int)\n\ntrain = train.drop(['SibSp', 'Parch'], axis=1)\ntest  = test.drop(['SibSp', 'Parch'], axis=1)\n\n# Encode WithFamily feature with one hot encoder\none_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n\ntrain_encoded_df = pd.DataFrame(one_hot_encoder.fit_transform(train[['WithFamily']]).toarray(), columns=['Alone', 'Family'], index=train.index)\ntest_encoded_df  = pd.DataFrame(one_hot_encoder.fit_transform(test[['WithFamily']]).toarray(), columns=['Alone', 'Family'], index=test.index)\n\ntrain = train.join(train_encoded_df)\ntest  = test.join(test_encoded_df)\n\ntrain = train.drop(['WithFamily', 'Family'], axis=1)\ntest  = test.drop(['WithFamily', 'Family'], axis=1)\n\n# Set target column as the last column\ntrain = pd.concat([train.loc[:, train.columns != target], train[target]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorize_age(age):\n    \"\"\"Function to categorize the Age feature.\"\"\"\n\n    if age < 16:\n        category = 1\n    elif age < 30:\n        category = 2\n    elif age < 50:\n        category = 3\n    elif age < 80:\n        category = 4\n    else:\n        category = 5\n\n    return category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorize the Age feature in intervals (0-16 -> 1, 16-30 -> 2, ...)\ntrain['Age'] = train['Age'].apply(categorize_age)\ntest['Age']  = test['Age'].apply(categorize_age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fare feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorize_fare(fare):\n    \"\"\"Function to categorize the Fare feature.\"\"\"\n\n    if fare < 10:\n        category = 1\n    elif fare < 40:\n        category = 2\n    elif fare < 100:\n        category = 3\n    else:\n        category = 4\n\n    return category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorize the Fare feature\ntrain['Fare'] = train['Fare'].apply(categorize_fare)\ntest['Fare']  = test['Fare'].apply(categorize_fare)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=\"models\">6. Models and predictions</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_complete_train = train.loc[:, train.columns != target]\ny_complete_train = train[target]\n\n# Divide train dataset into train and validation\nX_train, X_valid, y_train, y_valid = train_test_split(train.loc[:, train.columns != target], \n                                                      train[target], \n                                                      test_size=0.33)\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a base model\nlr_classifier = LogisticRegression()\n\n# Train the model\nlr_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = lr_classifier.predict(X_train)\nvalid_pred = lr_classifier.predict(X_valid)\n\ntrain_accuracy = accuracy_score(y_train, train_pred)\nvalid_accuracy = accuracy_score(y_valid, valid_pred)\n\nprint(f'Accuracy with Logistic Regression Classifier (train) = {train_accuracy}')\nprint(f'Accuracy with Logistic Regression Classifier (valid) = {valid_accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_classifier = RandomForestClassifier()\n\nrf_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = rf_classifier.predict(X_train)\nvalid_pred = rf_classifier.predict(X_valid)\n\ntrain_accuracy = accuracy_score(y_train, train_pred)\nvalid_accuracy = accuracy_score(y_valid, valid_pred)\n\nprint(f'Accuracy with Random Forest Classifier (train) = {train_accuracy}')\nprint(f'Accuracy with Random Forest Classifier (valid) = {valid_accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SV Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"sv_classifier = SVC(probability=True)\n\nsv_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = sv_classifier.predict(X_train)\nvalid_pred = sv_classifier.predict(X_valid)\n\ntrain_accuracy = accuracy_score(y_train, train_pred)\nvalid_accuracy = accuracy_score(y_valid, valid_pred)\n\nprint(f'Accuracy with Supported Vector Classifier (train) = {train_accuracy}')\nprint(f'Accuracy with Supported Vector Classifier (valid) = {valid_accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_classifier = XGBClassifier()\n\nxgb_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = xgb_classifier.predict(X_train)\nvalid_pred = xgb_classifier.predict(X_valid)\n\ntrain_accuracy = accuracy_score(y_train, train_pred)\nvalid_accuracy = accuracy_score(y_valid, valid_pred)\n\nprint(f'Accuracy with XGBoost Classifier (train) = {train_accuracy}')\nprint(f'Accuracy with XGBoost Classifier (valid) = {valid_accuracy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Neural Network Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_nn():\n    \"\"\"Function that generates the neural network classifier.\"\"\"\n\n    nn_classifier = Sequential([\n        layers.Dense(units=9, activation='relu', kernel_initializer='uniform', input_shape=[13]), \n        layers.Dense(units=9, activation='relu', kernel_initializer='uniform'), \n        layers.Dense(units=9, activation='relu', kernel_initializer='uniform'), \n        layers.Dense(units=1, activation='sigmoid', kernel_initializer='uniform')    \n    ])\n\n    nn_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n    return nn_classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_classifier = build_nn()\nnn_classifier.fit(X_train, y_train, batch_size=32, epochs=200, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = nn_classifier.predict(X_train)\nvalid_scores = nn_classifier.predict(X_valid)\n\ntrain_pred = (train_scores > 0.5).astype(int).reshape(X_train.shape[0])\nvalid_pred = (valid_scores > 0.5).astype(int).reshape(X_valid.shape[0])\n\ntrain_accuracy = accuracy_score(y_train, train_pred)\nvalid_accuracy = accuracy_score(y_valid, valid_pred)\n\nprint(f'Accuracy with Neural Network (train) = {train_accuracy}')\nprint(f'Accuracy with Neural Network (valid) = {valid_accuracy}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras_nn_classifier = tf.keras.wrappers.scikit_learn.KerasClassifier(build_nn, epochs=200, verbose=False)\nkeras_nn_classifier._estimator_type = \"classifier\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate a voting model with the previous classifiers (lr, rf, svc, xgb, nn)\n\nWe create a voting model with all of the previous classifiers.\nIn the voting process, the probabilities of each model prediction is taken into account (voting='soft')."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create our voting classifier with soft method (takes into account the probabilities of each prediction in the voting process)\nvoting_classifier = VotingClassifier(estimators=[('lr',  lr_classifier), \n                                                 ('rf',  rf_classifier), \n                                                 ('svc', sv_classifier), \n                                                 ('xgb', xgb_classifier), \n                                                 ('nn',  keras_nn_classifier)], \n                                     voting='soft')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voting_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = voting_classifier.predict(X_train)\nvalid_pred = voting_classifier.predict(X_valid)\n\ntrain_accuracy = accuracy_score(y_train, train_pred)\nvalid_accuracy = accuracy_score(y_valid, valid_pred)\n\nprint(f'Accuracy with Voting Classifier (train) = {train_accuracy}')\nprint(f'Accuracy with Voting Classifier (valid) = {valid_accuracy}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train with all the available data\nvoting_classifier.fit(X_complete_train, y_complete_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the predictions for the test dataset\ntest_pred = voting_classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## <a id=\"results\">7. Submit results</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df = pd.DataFrame({'PassengerId': X_test.index, 'Survived': test_pred})\noutput_df.to_csv('rfc_50.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}