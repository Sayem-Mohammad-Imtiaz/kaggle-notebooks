{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## My aim was do dos some exploratory data analysis on this dataset and we could try to predict if a pokemon was legendary or not so i've done that as well..","metadata":{}},{"cell_type":"markdown","source":"### imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom itertools import combinations\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download the dataset from here\n# https://www.kaggle.com/ahmettezcantekin/beginner-datasetss\n\ndf = pd.read_csv(\"pokemon.csv\")\ndf.head(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"df.info()\n\n# null values in type 2 column...\n\n# i think fillna can handle this!","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Type 2'].fillna(df['Type 1'], inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random idea can you predict the type of a pokemon given its stats...?","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = sns.barplot(df['Type 1'].value_counts().values, df['Type 1'].value_counts().index, orient='h');\nax.set(xlabel=\"Number of pokemon as per type 1\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nax = sns.barplot(df['Type 2'].value_counts().values, df['Type 2'].value_counts().index, orient='h');\nax.set(xlabel=\"Number of pokemon as per type 2\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# im not getting any clear ideas..\n# lets see correlation to get some if possible\n\nplt.figure(figsize=(10,8))\ncor = df.corr()\nsns.heatmap(cor,annot=True,cmap='Greens');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ledendary shows some correlation... and some ppl have tried to predict legendary.\n\n### I will use a model on it but for now i'm gonna try and extract some data for exploration purpose","metadata":{}},{"cell_type":"code","source":"\nplt.figure(figsize=(10,8))\nax = sns.barplot(df.groupby(['Type 1'])['Attack'].mean().values, df.groupby(['Type 1'])['Attack'].mean().index, orient='h');\nax.set(xlabel=\"Attack as per Type 1\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we might want to combine type 1 and 2 to create a new type\n\nall_types = pd.concat([df['Type 1'], df['Type 2']], ignore_index=True, axis=0).unique()\ncomb = combinations(all_types, 2)\n\ntype_combo = []\nfor i in list(comb):\n    type_combo.append(' '.join(i))\n\n\ndef type_clf(row):\n#     print(row)\n    if (row['Type 1'] + ' ' + row['Type 2']) in type_combo: \n        return (row['Type 1'] + ' ' + row['Type 2'])\n    elif (row['Type 2'] + ' ' + row['Type 1']) in type_combo:\n        return (row['Type 2'] + ' ' + row['Type 1'])\n    elif row['Type 1'] == row['Type 2']:\n        return row['Type 1']\n    \n    \n        \n        \n    \ndf['Type'] = df.apply(type_clf, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(10,25))\nax = sns.barplot(df.groupby(['Type'])['Attack'].mean().values, df.groupby(['Type'])['Attack'].mean().index, orient='h');\nax.set(xlabel=\"Attack as per Type 1\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['Type']).agg({'Attack': ['mean', 'min', 'max']})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,25))\nax = sns.barplot(df.groupby(['Type'])['HP'].mean().values, df.groupby(['Type'])['HP'].mean().index, orient='h');\nax.set(xlabel=\"HP as per Type 1\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,25))\nax = sns.barplot(df.groupby(['Type'])['Defense'].mean().values, df.groupby(['Type'])['Defense'].mean().index, orient='h');\nax.set(xlabel=\"Defence as per Type 1\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,25))\nax = sns.barplot(df.groupby(['Type'])['Speed'].mean().values, df.groupby(['Type'])['Speed'].mean().index, orient='h');\nax.set(xlabel=\"Speed as per Type 1\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### if you'd want to become a pokemon master, you clearly need to use this dataset","metadata":{}},{"cell_type":"code","source":"# The total column represents the total of all the stats... lets see who's at the top and bottom","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['Total'] == max(df['Total'])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['Total'] == min\n   (df['Total'])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# but i dont want legendardy for max\n\ndf[df['Total'] == max(df[df['Legendary'] == False]['Total'])][df['Legendary'] == False]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets see the weakest legendary\n\ndf[df['Total'] == min(df[df['Legendary'] == True]['Total'])][df['Legendary'] == True]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# does belonging to a higher generation make you stronger?\n\ndf.groupby(['Generation'])['Total'].mean()\n\n# ok. ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['Generation'])['Total'].max()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['Generation'])['Total'].min()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting all data. and i realized i can't see all of it...\n\ndf.groupby(['Type'])['Total','HP' ,'Attack','Defense','Sp. Atk','Sp. Def','Speed'].describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now, lets make the classificaition model","metadata":{}},{"cell_type":"code","source":"for col in df.iloc[:,4:12].columns:\n    sns.distplot(df[col])\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### most of our data if normalish distributed","metadata":{}},{"cell_type":"code","source":"\nfor col in df.iloc[:,4:12].columns:\n    sns.distplot(np.sqrt(df[col]))    # sqrt usually doesn't have a big effect but log caused left skeweness\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df.iloc[:,4:12].columns:\n    sns.distplot(np.log1p(df[col]))    # sqrt usually doesn't have a big effect but log caused left skeweness\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets fix our data\n\nfor col in df.iloc[:,5:11].columns:\n    df[col] = np.sqrt(df[col])   \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### except type, generation and '#' column\n\nfeatures = ['Total', 'HP', 'Attack', 'Defense',\n       'Sp. Atk', 'Sp. Def', 'Speed']\n\nX = df[features]\ny = df['Legendary'].replace({True:1,False:0})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standardize it","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### train test split... i really need to start using other stuff like stratified k fold, cv, etc,. instead","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models","metadata":{}},{"cell_type":"code","source":"log_clf = LogisticRegression()\n\nlog_clf.fit(X_train,y_train)\n\nlog_clf.score(X_test,y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_clf_cv = LogisticRegressionCV(cv=5, random_state=0)\n\nlog_clf_cv.fit(X_train,y_train)\n\nlog_clf.score(X_test,y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_clf = RandomForestClassifier()\nrf_clf.fit(X_train,y_train)\nrf_clf.score(X_test,y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance metrics","metadata":{}},{"cell_type":"code","source":"df['Legendary'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = log_clf.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test,y_pred)\n\n# 6 false negative top right\n# 6 false positive bottom left","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thank you\n## Don't forget to leave a like or upvote if it was worth your time.","metadata":{}}]}