{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":" import os, sys\nimport re\nimport string\nimport pathlib\nimport random\nfrom collections import Counter, OrderedDict\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nfrom tqdm import tqdm, tqdm_notebook, tnrange\ntqdm.pandas(desc='Progress')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n\nimport torchtext\nfrom torchtext import data\nfrom torchtext import vocab\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity='all'\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words(\"english\")) \nlemmatizer = WordNetLemmatizer()\n\ndef clean_text(text):\n    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n    text = re.sub(r'https?:/\\/\\S+', ' ', text)\n    text = [lemmatizer.lemmatize(token) for token in text.split(' ')]\n    text = [word for word in text if not word in stop_words]\n    text = \" \".join(text)\n    return text.strip()\n#for text in df.review:\n#    print(clean_text(text))\n#df.review = df.review.progress_apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnlp = spacy.load('en')\ndef tokenizer(s): return [w.text.lower() for w in nlp(clean_text(s))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt_field = data.Field(sequential=True, tokenize=tokenizer, include_lengths=True, use_vocab=True)\nlabel_field = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_val_fields = [\n    ('review', txt_field),\n    ('sentiment', label_field),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrainds, valds, testds = data.TabularDataset.splits(path='../input/', format='csv',\n                                            train='traindf.csv', validation='valdf.csv', test='testdf.csv',\n                                            fields=train_val_fields, skip_header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntxt_field.build_vocab(trainds, valds, testds, max_size=100000, vectors=\"glove.6B.100d\")\nlabel_field.build_vocab(trainds,testds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt_field.vocab.vectors[txt_field.vocab.stoi[\"the\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BatchGenerator:\n    def __init__(self, dl, x_field, y_field):\n        self.dl, self.x_field, self.y_field = dl, x_field, y_field\n        \n    def __len__(self):\n        return len(self.dl)\n    \n    def __iter__(self):\n        for batch in self.dl:\n            X = getattr(batch, self.x_field)\n            y = getattr(batch, self.y_field)\n            yield (X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(txt_field.vocab)\nembedding_dim = 100\nn_hidden = 64\nn_out = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out, pretrained_vec, bidirectional=True):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.n_hidden = n_hidden\n        self.n_out = n_out\n        self.bidirectional = bidirectional\n        \n        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n        self.emb.weight.data.copy_(pretrained_vec)\n        self.emb.weight.requires_grad = False\n        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, bidirectional=bidirectional)\n        if bidirectional:\n            self.out = nn.Linear(self.n_hidden*2*2, self.n_out)\n        else:\n            self.out = nn.Linear(self.n_hidden*2, self.n_out)\n        \n    def forward(self, seq, lengths):\n        bs = seq.size(1)\n        self.h = self.init_hidden(bs)\n        seq = seq.transpose(0,1)\n        embs = self.emb(seq)\n        embs = embs.transpose(0,1)\n        embs = pack_padded_sequence(embs, lengths)\n        gru_out, self.h = self.gru(embs, self.h)\n        gru_out, lengths = pad_packed_sequence(gru_out)        \n        \n        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)\n        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(bs,-1)        \n        outp = self.out(torch.cat([avg_pool,max_pool],dim=1))\n        return F.log_softmax(outp)\n    \n    def init_hidden(self, batch_size): \n        if self.bidirectional:\n            return torch.zeros((2,batch_size,self.n_hidden)).to(device)\n        else:\n            return torch.zeros((1,batch_size,self.n_hidden)).cuda().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(model, train_dl, val_dl, loss_fn, opt, epochs=3, tollerance=5):\n    num_batch = len(train_dl)\n    from_valacc = 0\n    path_to_best_model = \"../network.py\"\n    for epoch in tnrange(epochs):      \n        y_true_train = list()\n        y_pred_train = list()\n        total_loss_train = 0          \n        \n        t = tqdm_notebook(iter(train_dl), leave=False, total=num_batch)\n        for (X,lengths),y in t:\n            t.set_description(f'Epoch {epoch}')\n            lengths = lengths.cpu().numpy()\n            \n            opt.zero_grad()\n            pred = model(X, lengths)\n            loss = loss_fn(pred, y)\n            loss.backward()\n            opt.step()\n            \n            t.set_postfix(loss=loss.item())\n            pred_idx = torch.max(pred, dim=1)[1]\n            \n            y_true_train += list(y.cpu().data.numpy())\n            y_pred_train += list(pred_idx.cpu().data.numpy())\n            total_loss_train += loss.item()\n            \n        train_acc = accuracy_score(y_true_train, y_pred_train)\n        train_loss = total_loss_train/len(train_dl)\n        \n        y_true_val = list()\n        y_pred_val = list()\n        total_loss_val = 0\n        for (X,lengths),y in tqdm_notebook(val_dl, leave=False):\n            pred = model(X, lengths.cpu().numpy())\n            loss = loss_fn(pred, y)\n            pred_idx = torch.max(pred, 1)[1]\n            y_true_val += list(y.cpu().data.numpy())\n            y_pred_val += list(pred_idx.cpu().data.numpy())\n            total_loss_val += loss.item()\n        valacc = accuracy_score(y_true_val, y_pred_val)\n        valloss = total_loss_val/len(valdl)\n        if from_valacc>valacc:\n            tollerance -=1\n        if from_valacc<valacc:\n            from_valacc=valacc\n            tollerance = 5\n            torch.save(model.state_dict(),path_to_best_model)\n        print(f'Epoch {epoch}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {valloss:.4f} val_acc: {valacc:.4f} | tollerance: {tollerance:}')\n        if tollerance<=0:\n            break\n    model.load_state_dict(torch.load(path_to_best_model))\n    print(\"Training stopped\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindl, valdl = data.BucketIterator.splits(datasets=(trainds, valds), batch_sizes=(512,512), sort_key=lambda x: len(x.review), device=device, sort_within_batch=True, repeat=False)\ntrain_batch_it = BatchGenerator(traindl, 'review', 'sentiment')\nval_batch_it = BatchGenerator(valdl, 'review', 'sentiment')\ntestdl = data.BucketIterator(dataset=testds, batch_size=512, sort_key=lambda x: len(x.review), device=device, sort_within_batch=True, repeat=False)\ntest_batch_it = BatchGenerator(testdl, 'review', 'sentiment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = Network(vocab_size, embedding_dim, n_hidden, n_out, trainds.fields['review'].vocab.vectors).to(device)\nopt = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), 1e-3)\n\nfit(model=m, train_dl=train_batch_it, val_dl=val_batch_it, loss_fn=F.nll_loss, opt=opt, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\ny_true_test = list()\ny_pred_test = list()\nfor (X,lengths),y in tqdm_notebook(test_batch_it, leave=False):\n    pred = m(X, lengths.cpu().numpy())\n    loss = F.nll_loss(pred, y)\n    pred_idx = torch.max(pred, 1)[1]\n    y_true_test += list(y.cpu().data.numpy())\n    y_pred_test += list(pred_idx.cpu().data.numpy())\n#testacc = accuracy_score(y_true_val, y_pred_val)\nprint(metrics.classification_report(y_pred_test,y_true_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}