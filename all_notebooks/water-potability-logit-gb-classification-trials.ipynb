{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##Data Analysis Packages##\nimport pandas as pd\nimport numpy as np\nimport sklearn as sk\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score\nfrom sklearn.feature_selection import RFE, RFECV\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\n\n\n##Data Visualization Packages ##\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:36.002474Z","iopub.execute_input":"2021-07-24T02:08:36.002947Z","iopub.status.idle":"2021-07-24T02:08:36.747456Z","shell.execute_reply.started":"2021-07-24T02:08:36.002853Z","shell.execute_reply":"2021-07-24T02:08:36.746611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Importing Water Potability Dataset##\nwater_potability_data = pd.read_csv(r'../input/water-potability/water_potability.csv')\nwater_potability_data.info() #High Level Overview of Water Potability Dataset before Splitting and Performining Exploratory Data Analysis.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:36.749364Z","iopub.execute_input":"2021-07-24T02:08:36.749727Z","iopub.status.idle":"2021-07-24T02:08:36.911611Z","shell.execute_reply.started":"2021-07-24T02:08:36.749692Z","shell.execute_reply":"2021-07-24T02:08:36.910351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Separating predictor (X) variables from response variable (y)##\ny = water_potability_data.loc[:,'Potability'] #Response Variable (y): Potability (Water that is safe to drink)\nX = water_potability_data.drop('Potability', axis=1) #Removing response variable in order to segregate from predictor set.\n\n##Splitting data into train (80%) and test (20%) portions##\nX_train,X_test,y_train, y_test = train_test_split(X,y, train_size=0.80, test_size=0.20, random_state=2021)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:36.913224Z","iopub.execute_input":"2021-07-24T02:08:36.913555Z","iopub.status.idle":"2021-07-24T02:08:36.92215Z","shell.execute_reply.started":"2021-07-24T02:08:36.913522Z","shell.execute_reply":"2021-07-24T02:08:36.921273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--Step 1. Performing Data Pre-Processing--","metadata":{}},{"cell_type":"code","source":"##Overview of Training Dataset Columns before Pre-Processing ##\nX_train.info() #Columns with highest number of non-null observations (2620): Hardness, Solids, Chloramines, Conductivity, Organic_carbon, Turbidity.\nX_train.head() ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:36.923364Z","iopub.execute_input":"2021-07-24T02:08:36.923874Z","iopub.status.idle":"2021-07-24T02:08:36.960742Z","shell.execute_reply.started":"2021-07-24T02:08:36.923827Z","shell.execute_reply":"2021-07-24T02:08:36.959705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Descriptive statistics for predictor variables before removing null values##\nX_train.describe().round(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:36.962163Z","iopub.execute_input":"2021-07-24T02:08:36.96247Z","iopub.status.idle":"2021-07-24T02:08:37.016079Z","shell.execute_reply.started":"2021-07-24T02:08:36.962438Z","shell.execute_reply":"2021-07-24T02:08:37.015001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Descriptive statistics for response variable before removing null values##\ny_train_cat_1 = y_train.astype('category')\ny_train_cat_1.describe() #Highest frequency is 0 (non-potable) ~ 1606/2620 = 61% of observations correspond to non-potable water. Therefore, 39% of observations corresponse to potable water.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.017611Z","iopub.execute_input":"2021-07-24T02:08:37.017958Z","iopub.status.idle":"2021-07-24T02:08:37.037007Z","shell.execute_reply.started":"2021-07-24T02:08:37.017925Z","shell.execute_reply":"2021-07-24T02:08:37.03592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Re-joining training dataset before removing observations with null values to ensure that responses are removed simultaneously when removing observations with nulls##\ncombined_train_data = X_train.join(y_train)\n\ncombined_train_data.dropna(inplace=True) #Dropping all null values.\ncombined_train_data.info() #1613 observations remaining.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.038478Z","iopub.execute_input":"2021-07-24T02:08:37.038964Z","iopub.status.idle":"2021-07-24T02:08:37.061906Z","shell.execute_reply.started":"2021-07-24T02:08:37.038927Z","shell.execute_reply":"2021-07-24T02:08:37.060673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Separating cleaned training dataset into predictors and a response once again##\nX_train_cleaned = combined_train_data.drop('Potability', axis=1)\n\ny_train_cleaned = combined_train_data.loc[:, 'Potability']","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.064786Z","iopub.execute_input":"2021-07-24T02:08:37.065131Z","iopub.status.idle":"2021-07-24T02:08:37.071273Z","shell.execute_reply.started":"2021-07-24T02:08:37.065099Z","shell.execute_reply":"2021-07-24T02:08:37.070141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Displaying descriptive statistics of 'X_train_cleaned' dataframe##\nX_train_cleaned.describe().round(1) #Rounding to 1 decimal place.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.073343Z","iopub.execute_input":"2021-07-24T02:08:37.073701Z","iopub.status.idle":"2021-07-24T02:08:37.129717Z","shell.execute_reply.started":"2021-07-24T02:08:37.07367Z","shell.execute_reply":"2021-07-24T02:08:37.128784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Displaying descriptive statistics of 'y_train_cleaned' dataframe##\ny_train_cat_2 = y_train_cleaned.astype('category')\ny_train_cat_2.describe() #Highest frequency is 0 (non-potable) ~ 964/1613 = 60% of observations correspond to non-potable water. Therefore, 40% of observations corresponse to potable water.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.131334Z","iopub.execute_input":"2021-07-24T02:08:37.131785Z","iopub.status.idle":"2021-07-24T02:08:37.143532Z","shell.execute_reply.started":"2021-07-24T02:08:37.131737Z","shell.execute_reply":"2021-07-24T02:08:37.142271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating correlation matrix for all variables from 'combined_train_data' dataframe for context##\ncombined_train_data_corr = combined_train_data.corr()\nmatrix = np.tril(combined_train_data_corr)\nf, ax = plt.subplots(figsize=(15,12))\nsns.heatmap(combined_train_data_corr, vmax=0.8, annot=True, mask=matrix) #No visibly strong correlations seen for predictors amongst themselves or with response variablee (all weak, pearson/point biserial correlation coefficients 0.20 or less)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.145185Z","iopub.execute_input":"2021-07-24T02:08:37.145635Z","iopub.status.idle":"2021-07-24T02:08:37.777736Z","shell.execute_reply.started":"2021-07-24T02:08:37.145588Z","shell.execute_reply":"2021-07-24T02:08:37.776965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Histograms of all predictor variables in 'X_train_cleaned' dataframe##\nX_train_cleaned.hist(bins=10, figsize=(20,15), layout=(3,3), color='green'); #All histograms appear relatively symmetrical (no drastic relative skew upon first glance)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:37.778903Z","iopub.execute_input":"2021-07-24T02:08:37.779322Z","iopub.status.idle":"2021-07-24T02:08:39.330215Z","shell.execute_reply.started":"2021-07-24T02:08:37.779279Z","shell.execute_reply":"2021-07-24T02:08:39.329365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step 3. Performing Data Modelling\n\nThe following models will be attempted: Logistic Regression & Gradient Boost Classification.","metadata":{}},{"cell_type":"markdown","source":"Step 3a. Logistic Regression Modelling ","metadata":{}},{"cell_type":"code","source":"##Importing Logistic Regression Package##\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.331333Z","iopub.execute_input":"2021-07-24T02:08:39.331782Z","iopub.status.idle":"2021-07-24T02:08:39.335741Z","shell.execute_reply.started":"2021-07-24T02:08:39.331751Z","shell.execute_reply":"2021-07-24T02:08:39.33463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Standardizing input variables for logistic regression model due to magnitude of differences between predictor variables##\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler() #Re-scaling so that mean =0 and standard deviation = 1.\n\nX_train_clean_scale = scaler.fit_transform(X_train_cleaned) #Standardizing training data.\n\n##Converting scaled data to dataframe and re-adding column names\nX_train_clean_scale_df = pd.DataFrame(X_train_clean_scale, columns = X_train_cleaned.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.337134Z","iopub.execute_input":"2021-07-24T02:08:39.337428Z","iopub.status.idle":"2021-07-24T02:08:39.357009Z","shell.execute_reply.started":"2021-07-24T02:08:39.3374Z","shell.execute_reply":"2021-07-24T02:08:39.3558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Applying Recursive Elimination with Cross-Validation (RFECV) for Logistic Regression in support of Feature Selection##\nlogit_estimator = LogisticRegression(solver='liblinear', random_state=2021)\n\n##Identification of optimal number of features to select with RFECV. Applying 10 folds.\nlogit_opt_feat_num_rfecv = RFECV(estimator = logit_estimator, step=1, cv=StratifiedKFold(10), scoring='balanced_accuracy', min_features_to_select=1)\n\nlogit_opt_feat_num_rfecv.fit(X_train_clean_scale_df, np.ravel(y_train_cleaned))\n\n##Extracting optimal number of features\nprint(logit_opt_feat_num_rfecv.n_features_) #3 out of the 9 features were selected as important.\n\n##Plotting chart in support of optimum number of features\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross Validation Score\")\nplt.plot(range(1,\n               len(logit_opt_feat_num_rfecv.grid_scores_) + 1),\n         logit_opt_feat_num_rfecv.grid_scores_)\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.358251Z","iopub.execute_input":"2021-07-24T02:08:39.358685Z","iopub.status.idle":"2021-07-24T02:08:39.890038Z","shell.execute_reply.started":"2021-07-24T02:08:39.358632Z","shell.execute_reply":"2021-07-24T02:08:39.888868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Training the logit classifier with optimal number of features already identified.\nlogit_classifier = RFE(estimator=logit_estimator, n_features_to_select=3, step=1)\nlogit_classifier.fit(X_train_clean_scale_df, np.ravel(y_train_cleaned))\n\n##Extracting the 6 factors with highest importance for the logistic regression model.##\nlogit_feat = pd.DataFrame()\nlogit_feat['feature_name'] = X_train_clean_scale_df.columns\nlogit_feat['importance'] = logit_classifier.support_\nprint(logit_classifier.ranking_)\nlogit_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.891435Z","iopub.execute_input":"2021-07-24T02:08:39.891761Z","iopub.status.idle":"2021-07-24T02:08:39.932125Z","shell.execute_reply.started":"2021-07-24T02:08:39.891729Z","shell.execute_reply":"2021-07-24T02:08:39.931077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating filtered training and testing datasets having the highest importance to the logistic regression model##\nX_train_cleanreduce_scale = X_train_clean_scale_df.filter(['ph', 'Solids', 'Turbidity'])\n\nX_test_reduce = X_test.filter(['ph', 'Solids', 'Turbidity'])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.93342Z","iopub.execute_input":"2021-07-24T02:08:39.933779Z","iopub.status.idle":"2021-07-24T02:08:39.941045Z","shell.execute_reply.started":"2021-07-24T02:08:39.933747Z","shell.execute_reply":"2021-07-24T02:08:39.939944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Checking for Multicollinearity before building model##\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX_train_cleanreduce_vif = sm.add_constant(X_train_cleanreduce_scale) #For evaluating VIF only.\n\nvif = [variance_inflation_factor(X_train_cleanreduce_vif.values,i) for i in range(X_train_cleanreduce_vif.shape[1])]\n\npd.DataFrame({'vif': vif[1:]}, index=X_train_cleanreduce_scale.columns).T #Multicollinearity interpretted as high when VIF > 5. All appear acceptable (<5).","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.9424Z","iopub.execute_input":"2021-07-24T02:08:39.942755Z","iopub.status.idle":"2021-07-24T02:08:39.979276Z","shell.execute_reply.started":"2021-07-24T02:08:39.942722Z","shell.execute_reply":"2021-07-24T02:08:39.978484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Evaluating sample size before building model##\n\n##Rule of Thumb: (10*k)/p, where k = number of predictor variables. P = fraction of positive/'1' observations. \n\n##Minimum Sample size should be: (10*6)/0.40 = 150 observations; Fulfilled.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.980484Z","iopub.execute_input":"2021-07-24T02:08:39.981003Z","iopub.status.idle":"2021-07-24T02:08:39.984803Z","shell.execute_reply.started":"2021-07-24T02:08:39.980962Z","shell.execute_reply":"2021-07-24T02:08:39.983886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building Logistic Regression Model with statsmodel for visibility to coefficients##\nlogit_sm = sm.Logit(np.ravel(y_train_cleaned), X_train_cleanreduce_scale)\nresult_logit_sm = logit_sm.fit()\nresult_logit_sm.summary() #No p-values appear to be identified as statistically signficant (p-value all >0.05)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:39.986167Z","iopub.execute_input":"2021-07-24T02:08:39.986571Z","iopub.status.idle":"2021-07-24T02:08:40.032464Z","shell.execute_reply.started":"2021-07-24T02:08:39.986436Z","shell.execute_reply":"2021-07-24T02:08:40.031468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building Logistic Regression Model for Sklearn Prediction##\nlogit_skmodel = LogisticRegression(solver='liblinear',random_state=2021).fit(X_train_cleanreduce_scale, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.034139Z","iopub.execute_input":"2021-07-24T02:08:40.034816Z","iopub.status.idle":"2021-07-24T02:08:40.045094Z","shell.execute_reply.started":"2021-07-24T02:08:40.034768Z","shell.execute_reply":"2021-07-24T02:08:40.044124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score##\nlogit_skmodel_cvs = cross_val_score(logit_skmodel, X_train_cleanreduce_scale, np.ravel(y_train_cleaned), cv=StratifiedKFold(10))\nlogit_skmodel_cvs.mean() #0.5976458860516832","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.046741Z","iopub.execute_input":"2021-07-24T02:08:40.047467Z","iopub.status.idle":"2021-07-24T02:08:40.125764Z","shell.execute_reply.started":"2021-07-24T02:08:40.047419Z","shell.execute_reply":"2021-07-24T02:08:40.12484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##When originally attempting to run model prediction with scaled test dataset, a notification indicated that there were null values present. Therefore, null values were filled with a constant placeholder and data was re-scaled.##\nX_test_reduce = X_test_reduce.fillna(0)\n\nX_test_scaled = scaler.fit_transform(X_test_reduce) #Standardizing test data separate from training data to avoid information leakage.\n\n##Converting scaled data to dataframe and re-adding column names\nX_test_scalereduce_df = pd.DataFrame(X_test_scaled, columns = X_test_reduce.columns)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.127283Z","iopub.execute_input":"2021-07-24T02:08:40.127978Z","iopub.status.idle":"2021-07-24T02:08:40.139297Z","shell.execute_reply.started":"2021-07-24T02:08:40.127932Z","shell.execute_reply":"2021-07-24T02:08:40.138107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction##\nlogit_ypred = logit_skmodel.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.141108Z","iopub.execute_input":"2021-07-24T02:08:40.141844Z","iopub.status.idle":"2021-07-24T02:08:40.161136Z","shell.execute_reply.started":"2021-07-24T02:08:40.141796Z","shell.execute_reply":"2021-07-24T02:08:40.159942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining accuracy scores##\naccuracy_score(y_test,logit_ypred) #0.6051829268292683","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.165624Z","iopub.execute_input":"2021-07-24T02:08:40.16602Z","iopub.status.idle":"2021-07-24T02:08:40.177478Z","shell.execute_reply.started":"2021-07-24T02:08:40.165984Z","shell.execute_reply":"2021-07-24T02:08:40.175553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for logistic regression model.##\nprint(classification_report(y_test, logit_ypred))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.183028Z","iopub.execute_input":"2021-07-24T02:08:40.183391Z","iopub.status.idle":"2021-07-24T02:08:40.19617Z","shell.execute_reply.started":"2021-07-24T02:08:40.18336Z","shell.execute_reply":"2021-07-24T02:08:40.194921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for logistic regression model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.##\nconfusion_matrix(y_test, logit_ypred)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.199361Z","iopub.execute_input":"2021-07-24T02:08:40.199755Z","iopub.status.idle":"2021-07-24T02:08:40.207651Z","shell.execute_reply.started":"2021-07-24T02:08:40.199707Z","shell.execute_reply":"2021-07-24T02:08:40.206578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for logistic regression model.##\nroc_auc_score(y_test, logit_ypred) #0.5100881261595548","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.209018Z","iopub.execute_input":"2021-07-24T02:08:40.209383Z","iopub.status.idle":"2021-07-24T02:08:40.224041Z","shell.execute_reply.started":"2021-07-24T02:08:40.209346Z","shell.execute_reply":"2021-07-24T02:08:40.222977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining F1 score for the logistic regresion model##\nf1_score(y_test, logit_ypred,average='binary') #0.04428044280442805; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.225699Z","iopub.execute_input":"2021-07-24T02:08:40.226043Z","iopub.status.idle":"2021-07-24T02:08:40.235585Z","shell.execute_reply.started":"2021-07-24T02:08:40.226012Z","shell.execute_reply":"2021-07-24T02:08:40.234431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The final metrics obtained for this Logistic Regression Model were:\n\n1. Final Test Score: 0.60; \n2. Sensitivity: TP/(TP+FN) = (6/(6+258)) = 0.02;\n3. Specificity: TN/(TN+FP) = (391/(391+1)) = 1.00;\n4. AUC Score: 0.5;\n5. F1 Score: 0;**","metadata":{}},{"cell_type":"markdown","source":"Step 3b:Gradient Boost Classification Modelling","metadata":{}},{"cell_type":"code","source":"##Importing Gradient Boosting Classifier##\nfrom sklearn.ensemble import GradientBoostingClassifier","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.237045Z","iopub.execute_input":"2021-07-24T02:08:40.237348Z","iopub.status.idle":"2021-07-24T02:08:40.260762Z","shell.execute_reply.started":"2021-07-24T02:08:40.23732Z","shell.execute_reply":"2021-07-24T02:08:40.259486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building GB Classification Model for Sklearn Prediction##\ngb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=2021)\n\n##Identification of optimal number of features to select with RFECV approach. Selecting 10 folds \nopt_gb_rfecv = RFECV(estimator = gb_classifier, step=1, cv=StratifiedKFold(10), scoring='balanced_accuracy', min_features_to_select=1)\nopt_gb_rfecv.fit(X_train_cleaned, np.ravel(y_train_cleaned))\nprint(opt_gb_rfecv.n_features_) #5 out of 8 selected as important.\n\n##Plotting Cross Validation performance\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score\")\nplt.plot(range(1,\n               len(opt_gb_rfecv.grid_scores_) + 1),\n         opt_gb_rfecv.grid_scores_)\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:08:40.262167Z","iopub.execute_input":"2021-07-24T02:08:40.262487Z","iopub.status.idle":"2021-07-24T02:09:11.609634Z","shell.execute_reply.started":"2021-07-24T02:08:40.262456Z","shell.execute_reply":"2021-07-24T02:09:11.60884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Training the gradient boost classifier with optimal number of features already identified.\ngb_rfe_classifier = RFE(estimator=gb_classifier, n_features_to_select=5, step=1)\ngb_rfe_classifier.fit(X_train_cleaned, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:11.610989Z","iopub.execute_input":"2021-07-24T02:09:11.611505Z","iopub.status.idle":"2021-07-24T02:09:13.860606Z","shell.execute_reply.started":"2021-07-24T02:09:11.611471Z","shell.execute_reply":"2021-07-24T02:09:13.859424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining features of highest importance for the gradient boost model.##\ngb_feat = pd.DataFrame()\ngb_feat['feature_name'] = X_train_cleaned.columns\ngb_feat['importance'] = gb_rfe_classifier.support_\nprint(gb_rfe_classifier.ranking_)\ngb_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:13.861874Z","iopub.execute_input":"2021-07-24T02:09:13.86221Z","iopub.status.idle":"2021-07-24T02:09:13.877821Z","shell.execute_reply.started":"2021-07-24T02:09:13.862177Z","shell.execute_reply":"2021-07-24T02:09:13.876533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Only columns found to have  importance to the gradient boost model via RFECV.##\nX_train_reduced_gb = X_train_cleaned.filter(['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate'])\nX_test_reduced_gb = X_test.filter(['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate'])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:13.879366Z","iopub.execute_input":"2021-07-24T02:09:13.87971Z","iopub.status.idle":"2021-07-24T02:09:13.889984Z","shell.execute_reply.started":"2021-07-24T02:09:13.87968Z","shell.execute_reply":"2021-07-24T02:09:13.88858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Building Gradient Boost Classification Model with Selected Variables##\nmodel_varimp = GradientBoostingClassifier(n_estimators=100, random_state=2021).fit(X_train_reduced_gb, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:13.891398Z","iopub.execute_input":"2021-07-24T02:09:13.891721Z","iopub.status.idle":"2021-07-24T02:09:14.24969Z","shell.execute_reply.started":"2021-07-24T02:09:13.891681Z","shell.execute_reply":"2021-07-24T02:09:14.248634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score##\ngb_model_cvs = cross_val_score(model_varimp, X_train_reduced_gb, np.ravel(y_train_cleaned), cv=StratifiedKFold(10))\ngb_model_cvs.mean() #0.6602676175139944","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:14.251041Z","iopub.execute_input":"2021-07-24T02:09:14.251337Z","iopub.status.idle":"2021-07-24T02:09:17.454062Z","shell.execute_reply.started":"2021-07-24T02:09:14.251309Z","shell.execute_reply":"2021-07-24T02:09:17.453078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Filling null values with 0 for purpose of prediction##\nX_test_reduced_gb = X_test_reduced_gb.fillna(0) \n\n##Response Prediction\ny_pred_gb = model_varimp.predict(X_test_reduced_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.455556Z","iopub.execute_input":"2021-07-24T02:09:17.455983Z","iopub.status.idle":"2021-07-24T02:09:17.464977Z","shell.execute_reply.started":"2021-07-24T02:09:17.455925Z","shell.execute_reply":"2021-07-24T02:09:17.464016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining test accuracy score##\naccuracy_score(y_test, y_pred_gb) #0.6036585365853658","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.46617Z","iopub.execute_input":"2021-07-24T02:09:17.466476Z","iopub.status.idle":"2021-07-24T02:09:17.486741Z","shell.execute_reply.started":"2021-07-24T02:09:17.466445Z","shell.execute_reply":"2021-07-24T02:09:17.485703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for GB Classification Model##\nprint(classification_report(y_test, y_pred_gb))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.488237Z","iopub.execute_input":"2021-07-24T02:09:17.488555Z","iopub.status.idle":"2021-07-24T02:09:17.504306Z","shell.execute_reply.started":"2021-07-24T02:09:17.488524Z","shell.execute_reply":"2021-07-24T02:09:17.503235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for GB Classification Model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.##\nconfusion_matrix(y_test, y_pred_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.507658Z","iopub.execute_input":"2021-07-24T02:09:17.508393Z","iopub.status.idle":"2021-07-24T02:09:17.518495Z","shell.execute_reply.started":"2021-07-24T02:09:17.508343Z","shell.execute_reply":"2021-07-24T02:09:17.517296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for the GB Classification Model.##\nroc_auc_score(y_test, y_pred_gb) #0.5725108225108225","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.520251Z","iopub.execute_input":"2021-07-24T02:09:17.520737Z","iopub.status.idle":"2021-07-24T02:09:17.530688Z","shell.execute_reply.started":"2021-07-24T02:09:17.520688Z","shell.execute_reply":"2021-07-24T02:09:17.529573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining F1 score for the GB Classification Model.##\nf1_score(y_test, y_pred_gb,average='binary') #0.45606694560669453; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.531781Z","iopub.execute_input":"2021-07-24T02:09:17.532066Z","iopub.status.idle":"2021-07-24T02:09:17.542526Z","shell.execute_reply.started":"2021-07-24T02:09:17.532038Z","shell.execute_reply":"2021-07-24T02:09:17.541493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Generating values for feature importance plot.##\nreduced_list_gb = list(['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate'])\n\n##Numerical Importance of Predictors\nimportance_gb = list(model_varimp.feature_importances_)\n\n##Merged and Sorted with Predictors of importance\nvar_importance_merge_gb = [(predictor,round(importance,2)) for predictor, importance in zip(reduced_list_gb,importance_gb)]\n\nvar_importance_merge_gb = sorted(var_importance_merge_gb, key = lambda x: x[1], reverse = True)\n\nprint(var_importance_merge_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.543936Z","iopub.execute_input":"2021-07-24T02:09:17.544223Z","iopub.status.idle":"2021-07-24T02:09:17.556502Z","shell.execute_reply.started":"2021-07-24T02:09:17.544196Z","shell.execute_reply":"2021-07-24T02:09:17.555502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting feature importance.\ndf_importance_gb = pd.DataFrame(var_importance_merge_gb, columns = ['PREDICTOR','IMPORTANCE_LEVEL'])\n\n#Predictor Rank Plot\nsns.catplot(x=\"IMPORTANCE_LEVEL\", y='PREDICTOR', data = df_importance_gb, kind = \"bar\", height =14)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.558205Z","iopub.execute_input":"2021-07-24T02:09:17.558654Z","iopub.status.idle":"2021-07-24T02:09:17.865747Z","shell.execute_reply.started":"2021-07-24T02:09:17.558605Z","shell.execute_reply":"2021-07-24T02:09:17.864433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning with GridSearchCV Part 1 - max_depth and min_samples_split##\nparam_grid1 = {\n    'max_depth':[4,8,12],\n    'min_samples_split':[1,40,2],\n}\n\ngb_gscv1 = GridSearchCV(estimator = gb_classifier, param_grid = param_grid1, cv=StratifiedKFold(10), n_jobs=-1, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.86754Z","iopub.execute_input":"2021-07-24T02:09:17.868048Z","iopub.status.idle":"2021-07-24T02:09:17.873753Z","shell.execute_reply.started":"2021-07-24T02:09:17.867999Z","shell.execute_reply":"2021-07-24T02:09:17.872997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting GSCV with training data##\ngb_gscv1.fit(X_train_reduced_gb, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:17.875215Z","iopub.execute_input":"2021-07-24T02:09:17.875786Z","iopub.status.idle":"2021-07-24T02:09:43.109566Z","shell.execute_reply.started":"2021-07-24T02:09:17.875749Z","shell.execute_reply":"2021-07-24T02:09:43.108734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Extracting best params from GSCV 1##\ngb_gscv1.best_params_ #{'max_depth': 4, 'min_samples_split': 2}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:43.111175Z","iopub.execute_input":"2021-07-24T02:09:43.111777Z","iopub.status.idle":"2021-07-24T02:09:43.118541Z","shell.execute_reply.started":"2021-07-24T02:09:43.11173Z","shell.execute_reply":"2021-07-24T02:09:43.117568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning with GridSearchCV Part 2 - min_samples_leaf##\nparam_grid2 = {\n    'min_samples_leaf':[1,20,2],\n    'max_depth':[4],\n    'min_samples_split': [2]\n}\n\ngb_gscv2 = GridSearchCV(estimator = gb_classifier, param_grid = param_grid2, cv=StratifiedKFold(10), n_jobs=-1, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:43.120016Z","iopub.execute_input":"2021-07-24T02:09:43.120579Z","iopub.status.idle":"2021-07-24T02:09:43.133693Z","shell.execute_reply.started":"2021-07-24T02:09:43.120535Z","shell.execute_reply":"2021-07-24T02:09:43.132786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting GSCV with training data##\ngb_gscv2.fit(X_train_reduced_gb, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:43.13497Z","iopub.execute_input":"2021-07-24T02:09:43.13543Z","iopub.status.idle":"2021-07-24T02:09:48.421634Z","shell.execute_reply.started":"2021-07-24T02:09:43.135397Z","shell.execute_reply":"2021-07-24T02:09:48.420685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Extracting best params from GSCV 2##\ngb_gscv2.best_params_ #{'max_depth': 4, 'min_samples_leaf': 20, 'min_samples_split': 2}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:48.423062Z","iopub.execute_input":"2021-07-24T02:09:48.423461Z","iopub.status.idle":"2021-07-24T02:09:48.42956Z","shell.execute_reply.started":"2021-07-24T02:09:48.42342Z","shell.execute_reply":"2021-07-24T02:09:48.42853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning with GridSearchCV Part 3 - max_features##\nparam_grid3 = {\n    'min_samples_leaf':[20],\n    'max_depth':[4],\n    'min_samples_split': [2],\n    'max_features':['sqrt','log2']\n}\n\ngb_gscv3 = GridSearchCV(estimator = gb_classifier, param_grid = param_grid3, cv=StratifiedKFold(10), n_jobs=-1, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:48.431035Z","iopub.execute_input":"2021-07-24T02:09:48.431406Z","iopub.status.idle":"2021-07-24T02:09:48.45268Z","shell.execute_reply.started":"2021-07-24T02:09:48.431373Z","shell.execute_reply":"2021-07-24T02:09:48.451402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting GSCV with training data##\ngb_gscv3.fit(X_train_reduced_gb, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:48.454282Z","iopub.execute_input":"2021-07-24T02:09:48.454687Z","iopub.status.idle":"2021-07-24T02:09:50.515729Z","shell.execute_reply.started":"2021-07-24T02:09:48.4546Z","shell.execute_reply":"2021-07-24T02:09:50.514501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Extracting best params from GSCV 3##\ngb_gscv3.best_params_ #{'max_depth': 4, 'min_samples_leaf': 20, 'min_samples_split': 2, 'max_features': 'sqrt'}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:50.517007Z","iopub.execute_input":"2021-07-24T02:09:50.517428Z","iopub.status.idle":"2021-07-24T02:09:50.523116Z","shell.execute_reply.started":"2021-07-24T02:09:50.517387Z","shell.execute_reply":"2021-07-24T02:09:50.522224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Hypertuning with GridSearchCV Part 4 - learning rate and n_estimators##\nparam_grid4 = {\n    'min_samples_leaf':[20],\n    'max_depth':[4],\n    'min_samples_split': [2],\n    'max_features':['sqrt'],\n    'learning_rate':[0.01,0.1,0.02],\n    'n_estimators':[80,120,5]\n}\n\ngb_gscv4 = GridSearchCV(estimator = gb_classifier, param_grid = param_grid4, cv=StratifiedKFold(10), n_jobs=-1, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:50.524392Z","iopub.execute_input":"2021-07-24T02:09:50.52485Z","iopub.status.idle":"2021-07-24T02:09:50.541871Z","shell.execute_reply.started":"2021-07-24T02:09:50.524819Z","shell.execute_reply":"2021-07-24T02:09:50.540653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Fitting GSCV with training data##\ngb_gscv4.fit(X_train_reduced_gb, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:50.543472Z","iopub.execute_input":"2021-07-24T02:09:50.543848Z","iopub.status.idle":"2021-07-24T02:09:56.444076Z","shell.execute_reply.started":"2021-07-24T02:09:50.543813Z","shell.execute_reply":"2021-07-24T02:09:56.443097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Extracting best params from GSCV 3##\ngb_gscv4.best_params_ #{'learning_rate': 0.1,'max_depth': 4, 'max_features': 'sqrt','min_samples_leaf': 20,'min_samples_split': 2,'n_estimators': 120}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:56.445789Z","iopub.execute_input":"2021-07-24T02:09:56.446221Z","iopub.status.idle":"2021-07-24T02:09:56.4526Z","shell.execute_reply.started":"2021-07-24T02:09:56.446174Z","shell.execute_reply":"2021-07-24T02:09:56.451933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Re-fitting a second gradient boosting classification model with hypertuned parameters##\nmodel_gb_final= GradientBoostingClassifier(learning_rate=0.1, n_estimators=120, min_samples_split=2, min_samples_leaf=20, max_depth=4, random_state=2021).fit(X_train_reduced_gb, np.ravel(y_train_cleaned))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:56.453726Z","iopub.execute_input":"2021-07-24T02:09:56.454152Z","iopub.status.idle":"2021-07-24T02:09:56.983916Z","shell.execute_reply.started":"2021-07-24T02:09:56.454121Z","shell.execute_reply":"2021-07-24T02:09:56.983071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Cross-Validation Accuracy Score##\nmodel_gb_final_cvs = cross_val_score(model_gb_final, X_train_reduced_gb, np.ravel(y_train_cleaned), cv=StratifiedKFold(10))\nmodel_gb_final_cvs.mean() #0.6807415075531017","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:09:56.985209Z","iopub.execute_input":"2021-07-24T02:09:56.985835Z","iopub.status.idle":"2021-07-24T02:10:01.798406Z","shell.execute_reply.started":"2021-07-24T02:09:56.985791Z","shell.execute_reply":"2021-07-24T02:10:01.797701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Response Prediction##\ny_pred_gb_final = model_gb_final.predict(X_test_reduced_gb)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.799431Z","iopub.execute_input":"2021-07-24T02:10:01.799847Z","iopub.status.idle":"2021-07-24T02:10:01.807862Z","shell.execute_reply.started":"2021-07-24T02:10:01.799817Z","shell.execute_reply":"2021-07-24T02:10:01.806935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining Test Score##\naccuracy_score(y_test, y_pred_gb_final)#0.6067073170731707","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.809148Z","iopub.execute_input":"2021-07-24T02:10:01.809434Z","iopub.status.idle":"2021-07-24T02:10:01.825127Z","shell.execute_reply.started":"2021-07-24T02:10:01.809406Z","shell.execute_reply":"2021-07-24T02:10:01.823963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating classification report for gradient boosting classification.##\nprint(classification_report(y_test, y_pred_gb_final))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.827442Z","iopub.execute_input":"2021-07-24T02:10:01.827821Z","iopub.status.idle":"2021-07-24T02:10:01.844126Z","shell.execute_reply.started":"2021-07-24T02:10:01.827784Z","shell.execute_reply":"2021-07-24T02:10:01.84292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Creating confusion matrix for gradient boosting model. True negatives (TN) are in the upper-left position, False Negatives (FN) are in the lower-left position, False Positives (FP) are in the upper-right position, True Positives (TP) are in the lower-right position.##\nconfusion_matrix(y_test, y_pred_gb_final)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.845378Z","iopub.execute_input":"2021-07-24T02:10:01.8457Z","iopub.status.idle":"2021-07-24T02:10:01.855779Z","shell.execute_reply.started":"2021-07-24T02:10:01.845642Z","shell.execute_reply":"2021-07-24T02:10:01.85474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining AUC score for gradient boosting classification model.##\nroc_auc_score(y_test, y_pred_gb_final) #0.5762987012987013","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.857415Z","iopub.execute_input":"2021-07-24T02:10:01.858056Z","iopub.status.idle":"2021-07-24T02:10:01.86888Z","shell.execute_reply.started":"2021-07-24T02:10:01.858004Z","shell.execute_reply":"2021-07-24T02:10:01.867736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Determining F1 score for the for classification model.##\nf1_score(y_test, y_pred_gb_final,average='binary') #0.4625; a poor F1 score, is close to 0.0. Best F1 score is close to 1.","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.8701Z","iopub.execute_input":"2021-07-24T02:10:01.870455Z","iopub.status.idle":"2021-07-24T02:10:01.884153Z","shell.execute_reply.started":"2021-07-24T02:10:01.870402Z","shell.execute_reply":"2021-07-24T02:10:01.883065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Generating values for feature importance plot.\nreduced_list_gb_final = list(['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate'])\n\n##Numerical Importance of Predictors\nimportance_gb_final = list(model_gb_final.feature_importances_)\n\n##Merged and Sorted with Predictors of importance\nvar_importance_merge_gb_final = [(predictor,round(importance,2)) for predictor, importance in zip(reduced_list_gb_final,importance_gb_final)]\n\nvar_importance_merge_gb_final = sorted(var_importance_merge_gb_final, key = lambda x: x[1], reverse = True)\n\nprint(var_importance_merge_gb_final)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.885533Z","iopub.execute_input":"2021-07-24T02:10:01.885899Z","iopub.status.idle":"2021-07-24T02:10:01.897056Z","shell.execute_reply.started":"2021-07-24T02:10:01.885871Z","shell.execute_reply":"2021-07-24T02:10:01.896109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plotting feature importance.##\ndf_importance_gb_final= pd.DataFrame(var_importance_merge_gb_final, columns = ['PREDICTOR','IMPORTANCE_LEVEL'])\n\n##Predictor Rank Plot\nsns.catplot(x=\"IMPORTANCE_LEVEL\", y='PREDICTOR', data = df_importance_gb_final, kind = \"bar\", height =14)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T02:10:01.898547Z","iopub.execute_input":"2021-07-24T02:10:01.898943Z","iopub.status.idle":"2021-07-24T02:10:02.443077Z","shell.execute_reply.started":"2021-07-24T02:10:01.898906Z","shell.execute_reply":"2021-07-24T02:10:02.441797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The final metrics obtained for this Gradient Boosting Classification Model were:                                        1. Final Test Score: 0.68;                                      2. Sensitivity: TP/(TP+FN) = (111/(111+153)) = 0.42;              3. Specificity: TN/(TN+FP) = (287/(287+153)) = 0.65; \n4. AUC Score: 0.6; \n5. F1 Score: 0.5**\n","metadata":{}}]}