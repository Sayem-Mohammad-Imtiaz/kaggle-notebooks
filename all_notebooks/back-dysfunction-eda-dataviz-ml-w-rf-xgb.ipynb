{"cells":[{"metadata":{"_uuid":"6dab0b2780cee04b23b2399a2b8f35783a098a1f"},"cell_type":"markdown","source":"# Predicting Back Dysfunction From Biomechanics\n![](https://media.giphy.com/media/l2JebyxjfgZuhPXl6/giphy.gif)\n\nThis kernal will go through some basic EDA and data visualization using python tools like Pandas Dataframes and Seaborn.\n\nI will also develop some simple models to attempt to classify back dysfunction based on biomechanical variables.\n\n\n"},{"metadata":{"_uuid":"bfa9722596d17f42f04eeb5ed52015e528e15319"},"cell_type":"markdown","source":"# First, We need to understand what we are classifying:\n\n**Heriated disk:**\n![](https://www.mayoclinic.org/-/media/kcms/gbs/patient-consumer/images/2016/11/22/17/38/mcdc7_herniated_disk-8col.jpg)\n\n**spondylolisthesis**:\n\n![](https://www.cartersvillechiro.com/images/New-art/Sponylo-Grades01.jpg)"},{"metadata":{"_uuid":"04d0d85ac2c3631339d8bf68dbdcd7129f127694"},"cell_type":"markdown","source":"# Imports:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Visualiztion:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Machine Learning/Modleing:\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\n# ignore warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Load Data:"},{"metadata":{"trusted":true,"_uuid":"ac6b9ba53c68e3cd1aa7ac8b323353af1c8b0eaf"},"cell_type":"code","source":"DF_data_2c = pd.read_csv(\"../input/column_2C_weka.csv\")\nDF_data_3c = pd.read_csv(\"../input/column_3C_weka.csv\")\n\nprint('Preview of 2 Category data:')\nprint(DF_data_2c.shape)\nprint(DF_data_2c.keys())\nprint(DF_data_2c.dtypes)\n\nprint('\\n Preview of 3 Category data:')\nprint(DF_data_3c.shape)\nprint(DF_data_3c.keys())\nprint(DF_data_3c.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c43fceb99d6e152dfa6bba9f8b18d9e0ce21652a"},"cell_type":"markdown","source":"# Let's start by examining the dataset w/ 3 Categories:\nClassifying people into 3 categories should be moredifficult than 2, so let's start with that..."},{"metadata":{"_uuid":"f58a1c689495a336ee8b47c5c04355290e61d125"},"cell_type":"markdown","source":"**Preview DataFrame:**"},{"metadata":{"trusted":true,"_uuid":"c7c5b9f20dce81bf02c53faf002d85a543ee727e"},"cell_type":"code","source":"DF_data_3c.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceda098154875bed2081d2f43e7b1ad4294c9f75"},"cell_type":"code","source":"DF_data_3c.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d6d5e5f00873b035c54dab20c2c9d4f62aa37d4"},"cell_type":"markdown","source":"# Let's Examine the Data a Bit Deeper:\n\nHere we can see that there are more Spondylolidthesis than Normal than Hernia..."},{"metadata":{"trusted":true,"_uuid":"a4bc2cf69a78b05bdbee30da52bc159573d4e603"},"cell_type":"code","source":"print(DF_data_3c['class'].value_counts())\nsns.countplot(DF_data_3c['class']);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb9dbaf21f54355625b0c64c6e392651442e6587"},"cell_type":"markdown","source":"**Let's See how each variable varies by classification:**"},{"metadata":{"trusted":true,"_uuid":"cf2e65e1232a014e093c98c3e3a5f4165dd8be71"},"cell_type":"code","source":"vars = DF_data_3c.keys().drop('class')\n\n# Here we use a simple for loop to quickly create subplot boxplots of each variable.\nplt.figure(figsize=(20,10))\nfor idx, var in enumerate(vars):\n    plt.subplot(2,3,idx+1)\n    sns.boxplot(x='class', y=var, data=DF_data_3c)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b3f1d067ffecb6156c14a3597ccf7e78d16c384"},"cell_type":"code","source":"# Alternatively, we can visualize the data using violin plots...\nplt.figure(figsize=(20,10))\nfor idx, var in enumerate(vars):\n    plt.subplot(2,3,idx+1)\n    sns.violinplot(x='class', y=var, data=DF_data_3c)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6edf88690e1c7c2e0281453b406bf47c2fd4933"},"cell_type":"markdown","source":"Here we can see that these biomechanical variables can definitely differ by class. For instance, the Spondy. class has greater pelvic incidence, lumbar lordosis, sacral slope, and degree spondylolisthesis than the other gorups. \n\n**Next we can see how these variable relate to eachother, as well:**\n\n(notice how you can customize the upper/lower/diagonal plot by modifying the commented portions)"},{"metadata":{"trusted":true,"_uuid":"89934e7390e943516e5dba5822f450369628c218"},"cell_type":"code","source":"# seaborn has an awesome tool (pairplot) to do this very easily:\ng = sns.pairplot(DF_data_3c, hue='class', height=4)\n# g.map_upper(sns.regplot) # some plot options: 'regplot', 'residplot', 'scatterplot'\n# g.map_lower(sns.kdeplot)\n#g.map_diag(plt.hist)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaac618a0eb0e1d0bd412b1383449bbf78591fc4"},"cell_type":"markdown","source":"# Simple Machine Learning Models:"},{"metadata":{"_uuid":"82a77d2ec14c36e7a0c9bac6b2805e72610b51b5"},"cell_type":"markdown","source":"**Split data into Training and Test Data:**"},{"metadata":{"trusted":true,"_uuid":"8f1705edbd52ce689b4a2de44a84b62e2d86866f"},"cell_type":"code","source":"# Create X (independant vars) and y (dependant var) \nX = DF_data_3c.copy().drop(['class'], axis=1)\ny = DF_data_3c[\"class\"].copy()\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1, test_size = 0.20)\n\nprint(train_X.shape)\nprint(val_X.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcc083e3a6e4f0a62f93db3d8727b47f6a7d502c"},"cell_type":"markdown","source":"**Decision Tree Model:**"},{"metadata":{"trusted":true,"_uuid":"362190ab4735bf35e06bd68b0954d7ee86b44c70"},"cell_type":"code","source":"DTC_model = DecisionTreeClassifier()\nDTC_model.fit(train_X,train_y)\n\n# Make PredicitonsL:\nDTC_predictions = DTC_model.predict(val_X)\n\n#Print accuracy Results for DTR model\nDTC_accuracy =  DTC_model.score(val_X, val_y)\nprint(\"Accuracy score for Decision Tree Classifier Model : \" + str(DTC_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(DTC_model.feature_importances_[idx]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a17470f41496724266125db13714ea30a540900f"},"cell_type":"markdown","source":"**Random Forest Model:**"},{"metadata":{"trusted":true,"_uuid":"b53427d9ae1cb4dbdce8f47bdba9e44e1071f166"},"cell_type":"code","source":"RF_model = RandomForestClassifier(random_state=1)\nRF_model.fit(train_X, train_y)\n\n# make predictions\nRF_predictions = RF_model.predict(val_X)\n\n# Print Accuracy for initial RF model\nRF_accuracy = RF_model.score(val_X, val_y)\nprint(\"Accuracy score for Random Forest Model : \" + str(RF_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(RF_model.feature_importances_[idx]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66893e8a14a8f3df006b7014d63cc084c26ecd9b"},"cell_type":"markdown","source":"From a very simple Random Forest model, we were able to predict the class ~ 80% of the time. Not bad, but not great... Next we will try a boosted tree classifier...****"},{"metadata":{"_uuid":"256884be2fba6583278fd1cd80abd04d15ed86c0"},"cell_type":"markdown","source":"**XGBoost Model:**"},{"metadata":{"trusted":true,"_uuid":"fd1632867fd276a83ea75e249b23d3d29c1bed9b"},"cell_type":"code","source":"XGBC_model = XGBClassifier(random_state=1)\nXGBC_model.fit(train_X, train_y)\n\n# make predictions\nXGBC_predictions = XGBC_model.predict(val_X)\n\n# Print Accuracy for initial RF model\nXGBC_accuracy = accuracy_score(val_y, XGBC_predictions)\nprint(\"Accuracy score for XGBoost Classifier model : \" + str(XGBC_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(XGBC_model.feature_importances_[idx]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a96188bafe3daa4b6e287f8c55399a7118ef28f"},"cell_type":"markdown","source":"Here we can see that, surprisingly, accuracy was not improved by using a XGBoost Classifier model. Luckily, these models are easy to tune. Let's Try that next..."},{"metadata":{"_uuid":"fd9b94d38cf35768d59c497a5390843516f082f4"},"cell_type":"markdown","source":"**Tuned XGBoost Classifier Model:**"},{"metadata":{"trusted":true,"_uuid":"3330a97cc2b898d4a12d604ba36458aa513b4c79"},"cell_type":"code","source":"%%time\n# Slightly Tuned XGB Model:\nXGBC_model = XGBClassifier(random_state=1, objective = 'multi:softprob', num_class=3) # \n\nparameters = {'learning_rate': [0.01, 0.015, 0.02, 0.025], # also called `eta` value\n              'max_depth': [2, 3, 4, 5],\n              'min_child_weight': [0.75, 1.0, 1.25, 2, 5],\n              'n_estimators': [100, 150, 200, 250, 300, 500]}\n\nXGBC_grid = GridSearchCV(XGBC_model,\n                        parameters,\n                        cv = 3,\n                        n_jobs = 5,\n                        verbose=True)\n\nXGBC_grid.fit(train_X, train_y)\n\n#print(XGBC_grid.best_score_)\nprint(XGBC_grid.best_params_)\n\n# make predictions\nXGBC_grid_predictions = XGBC_grid.predict(val_X)\n# Print MAE for initial XGB model\nXGBC_grid_accuracy = accuracy_score(XGBC_grid_predictions, val_y)\nprint(\"Accuracy Score for Tuned XGBoost Classifier Model : \" + str(XGBC_grid_accuracy))\n\nprint('\\nVariable Importance:')\nfor idx, var in enumerate(vars):\n    print(var, ':', str(XGBC_grid.best_estimator_.feature_importances_[idx]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8046f0ce9cb0eb175d1a7a2e840c2f3ce510565a"},"cell_type":"markdown","source":"here we improved our classification accuracy to almost 84% with some minor XGBoost model tuning."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}