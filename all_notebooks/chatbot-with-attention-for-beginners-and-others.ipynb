{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport codecs\nimport tensorflow as tf\nimport pandas as pd\nimport ast\nimport tqdm\nprint(tf.__version__)","metadata":{"id":"mb2hvcbWgv-B","outputId":"b04a3257-6689-4e54-ba67-07b78ece8532","execution":{"iopub.status.busy":"2021-06-19T06:20:47.880837Z","iopub.execute_input":"2021-06-19T06:20:47.881238Z","iopub.status.idle":"2021-06-19T06:20:54.397826Z","shell.execute_reply.started":"2021-06-19T06:20:47.881204Z","shell.execute_reply":"2021-06-19T06:20:54.396613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We are faced with the task of writing a simple chat bot using a neural network. We'll be using the Cornell Movie-Dialogs Corpus dataset. It contains more than 130 thousand refined replicas from 617 films.\n#### What does cleared mean - we can remove all dialogues with long lines. Important: we do not remove the long lines themselves, but the entire dialogues with such lines, so that we have coherent dialogues. Thus, more than 130 thousand replicas turned out and not 220.\n#### Our model will implement the attention mechanism.","metadata":{}},{"cell_type":"markdown","source":"## Prepare to learning\n","metadata":{"id":"Abe9Z7HT3EkM"}},{"cell_type":"markdown","source":"### Loading the data.","metadata":{}},{"cell_type":"code","source":"dialogs = pd.read_csv('../input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv')","metadata":{"id":"ihhSiCvxadEs","execution":{"iopub.status.busy":"2021-06-19T06:20:56.906087Z","iopub.execute_input":"2021-06-19T06:20:56.906454Z","iopub.status.idle":"2021-06-19T06:20:58.492998Z","shell.execute_reply.started":"2021-06-19T06:20:56.906421Z","shell.execute_reply":"2021-06-19T06:20:58.491817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dialogs.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:21:22.874148Z","iopub.execute_input":"2021-06-19T06:21:22.874554Z","iopub.status.idle":"2021-06-19T06:21:22.906597Z","shell.execute_reply.started":"2021-06-19T06:21:22.874522Z","shell.execute_reply":"2021-06-19T06:21:22.90552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dialogs.shape","metadata":{"id":"ZLnwXbtl3fyb","outputId":"2cc4e6c0-af80-4950-9851-235b0dcb9b59","execution":{"iopub.status.busy":"2021-06-19T06:21:25.991653Z","iopub.execute_input":"2021-06-19T06:21:25.992257Z","iopub.status.idle":"2021-06-19T06:21:25.998362Z","shell.execute_reply.started":"2021-06-19T06:21:25.992219Z","shell.execute_reply":"2021-06-19T06:21:25.997385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text encoding.\nWe are now ready to encode our sequences numerically. Let's use the functions from the practical assignment.\nFirst, let's code the dictionaries for both sequences.","metadata":{}},{"cell_type":"code","source":"input_texts = pd.read_csv('../input/cleaned-data-for-the-chatbot-collected-from-movies/input3.csv')\ntarget_texts = pd.read_csv('../input/cleaned-data-for-the-chatbot-collected-from-movies/target3.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:56:20.572204Z","iopub.execute_input":"2021-06-19T06:56:20.572752Z","iopub.status.idle":"2021-06-19T06:56:21.551561Z","shell.execute_reply.started":"2021-06-19T06:56:20.572717Z","shell.execute_reply":"2021-06-19T06:56:21.550094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in input_texts.index:\n    typ = type(input_texts.text[i])\n    if typ == float:\n        input_texts.text[i] = ' '\n\nfor i in target_texts.index:\n    typ = type(target_texts.text[i])\n    if typ == float:\n        target_texts.text[i] = ' '","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:56:21.957214Z","iopub.execute_input":"2021-06-19T06:56:21.957608Z","iopub.status.idle":"2021-06-19T06:56:28.748332Z","shell.execute_reply.started":"2021-06-19T06:56:21.957576Z","shell.execute_reply":"2021-06-19T06:56:28.747232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_vocab(texts):\n    vocab = sorted(set(''.join(texts)))\n    vocab.append('<START>')\n    vocab.append('<END>')\n    vocab_size = len(vocab)\n    char2idx = {u:i for i, u in enumerate(vocab)}\n    idx2char = np.array(vocab)\n    return vocab_size, char2idx, idx2char\n\ninput_texts_for_vocabs = input_texts.text.values.tolist()\ntarget_texts_for_vocabs = target_texts.text.values.tolist()\nINPUT_VOCAB_SIZE, input_char2idx, input_idx2char = prepare_vocab(input_texts_for_vocabs)\nTARGET_VOCAB_SIZE, target_char2idx, target_idx2char = prepare_vocab(target_texts_for_vocabs)","metadata":{"id":"cuFYohX5UDZC","execution":{"iopub.status.busy":"2021-06-19T06:56:38.357734Z","iopub.execute_input":"2021-06-19T06:56:38.358166Z","iopub.status.idle":"2021-06-19T06:56:38.634864Z","shell.execute_reply.started":"2021-06-19T06:56:38.35813Z","shell.execute_reply":"2021-06-19T06:56:38.633785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_texts_as_int = [[input_char2idx[c] for c in text] for text in dialogs['question']]\ntarget_texts_as_int = [[target_char2idx[c] for c in text] for text in dialogs['answer']]","metadata":{"id":"W_vdKlh2Cwqu","execution":{"iopub.status.busy":"2021-06-19T06:56:40.18515Z","iopub.execute_input":"2021-06-19T06:56:40.185567Z","iopub.status.idle":"2021-06-19T06:56:41.782743Z","shell.execute_reply.started":"2021-06-19T06:56:40.185532Z","shell.execute_reply":"2021-06-19T06:56:41.78173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's encode the sequences themselves using dictionaries.\nSince for our model we need to enter the Encoder and enter and exit the Decoder, we will prepare three sequences of numbers.","metadata":{}},{"cell_type":"code","source":"encoder_input_seqs = [np.array(text) for text in input_texts_as_int]\ndecoder_input_seqs = []\ndecoder_target_seqs = []\nfor target_text in target_texts_as_int:\n    decoder_input_seqs.append(np.array([target_char2idx['<START>']] + target_text))\n    decoder_target_seqs.append(np.array(target_text + [target_char2idx['<END>']]))","metadata":{"id":"ZJ0xpTKa3jmp","execution":{"iopub.status.busy":"2021-06-19T06:56:41.976715Z","iopub.execute_input":"2021-06-19T06:56:41.977104Z","iopub.status.idle":"2021-06-19T06:56:46.125557Z","shell.execute_reply.started":"2021-06-19T06:56:41.977069Z","shell.execute_reply":"2021-06-19T06:56:46.124711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's add padding.","metadata":{}},{"cell_type":"code","source":"max_enc_seq_length = 100\nmax_dec_seq_length = 100\n\nencoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n    encoder_input_seqs,\n    value=input_char2idx[' '],\n    padding='post',\n    maxlen=max_enc_seq_length)\n\ndecoder_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n    decoder_input_seqs,\n    value=target_char2idx[' '],\n    padding='post',\n    maxlen=max_dec_seq_length)\n\ndecoder_target_seqs = tf.keras.preprocessing.sequence.pad_sequences(\n    decoder_target_seqs,\n    value=target_char2idx[' '],\n    padding='post',\n    maxlen=max_dec_seq_length)","metadata":{"id":"QHVcwSJf_3JT","execution":{"iopub.status.busy":"2021-06-19T06:56:46.127158Z","iopub.execute_input":"2021-06-19T06:56:46.127557Z","iopub.status.idle":"2021-06-19T06:56:48.737934Z","shell.execute_reply.started":"2021-06-19T06:56:46.127528Z","shell.execute_reply":"2021-06-19T06:56:48.737139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_enc_seq_length, max_dec_seq_length","metadata":{"id":"O0JmNca8-Hl2","outputId":"5cfeca70-0ae5-4d05-8301-f29af7779ac7","execution":{"iopub.status.busy":"2021-06-19T06:56:48.739028Z","iopub.execute_input":"2021-06-19T06:56:48.739418Z","iopub.status.idle":"2021-06-19T06:56:48.743825Z","shell.execute_reply.started":"2021-06-19T06:56:48.739389Z","shell.execute_reply":"2021-06-19T06:56:48.743143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_input_seqs.shape, decoder_input_seqs.shape, decoder_target_seqs.shape","metadata":{"id":"TqHjW9Sq8rkg","outputId":"e613f3d7-2ac1-4450-d8ab-98d8aceb3a98","execution":{"iopub.status.busy":"2021-06-19T06:56:48.744772Z","iopub.execute_input":"2021-06-19T06:56:48.745122Z","iopub.status.idle":"2021-06-19T06:56:48.761336Z","shell.execute_reply.started":"2021-06-19T06:56:48.745092Z","shell.execute_reply":"2021-06-19T06:56:48.760237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''.join(input_idx2char[encoder_input_seqs[0]])","metadata":{"id":"TBvUEu8zG5wV","outputId":"146fdb69-c0c0-4c72-cc02-baa6a3d36ecc","execution":{"iopub.status.busy":"2021-06-19T06:56:48.763879Z","iopub.execute_input":"2021-06-19T06:56:48.764365Z","iopub.status.idle":"2021-06-19T06:56:48.776356Z","shell.execute_reply.started":"2021-06-19T06:56:48.764328Z","shell.execute_reply":"2021-06-19T06:56:48.775199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create and train the model.\nLet's create a model. Our model will have three bidirectional LSTM layers and an attention mechanism. On our data, the model should train long enough to give a good result.","metadata":{"id":"u1MJ07UuADaq"}},{"cell_type":"code","source":"H_SIZE = 512 \nEMB_SIZE = 512 \n\nclass Encoder_att(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.embed = tf.keras.layers.Embedding(INPUT_VOCAB_SIZE, EMB_SIZE)\n        self.lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True))\n        self.lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True))\n        self.lstm_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(H_SIZE, return_sequences=True, return_state=True))\n        \n    def call(self, x):\n        out = self.embed(x)\n        out, f_h_1, f_c_1, b_h_1, b_c_1 = self.lstm_1(out)\n        out, f_h_2, f_c_2, b_h_2, b_c_2 = self.lstm_2(out)\n        out, f_h_3, f_c_3, b_h_3, b_c_3 = self.lstm_3(out)\n        h_1 = tf.keras.layers.Concatenate()([f_h_1, b_h_1])\n        c_1 = tf.keras.layers.Concatenate()([f_c_1, b_c_1])\n        h_2 = tf.keras.layers.Concatenate()([f_h_2, b_h_2])\n        c_2 = tf.keras.layers.Concatenate()([f_c_2, b_c_2])\n        h_3 = tf.keras.layers.Concatenate()([f_h_3, b_h_3])\n        c_3 = tf.keras.layers.Concatenate()([f_c_3, b_c_3])\n        state_1 = (h_1, c_1)\n        state_2 = (h_2, c_2)\n        state_3 = (h_3, c_3)\n        return out, (state_1, state_2, state_3)\n\nclass Decoder_att(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.embed = tf.keras.layers.Embedding(TARGET_VOCAB_SIZE, EMB_SIZE)\n        self.lstm_1 = tf.keras.layers.LSTM(H_SIZE*2, return_sequences=True, return_state=True)\n        self.lstm_2 = tf.keras.layers.LSTM(H_SIZE*2, return_sequences=True, return_state=True)\n        self.lstm_3 = tf.keras.layers.LSTM(H_SIZE*2, return_sequences=True, return_state=True)\n        self.attention = tf.keras.layers.Attention()\n        self.fc = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation='softmax')\n        \n    def call(self, x, init_state, encoder_outputs, training=True):\n        out = self.embed(x)\n        out, h_1, c_1 = self.lstm_1(out, initial_state=init_state[0])\n        out, h_2, c_2 = self.lstm_2(out, initial_state=init_state[1])\n        out, h_3, c_3 = self.lstm_3(out, initial_state=init_state[2])\n        out = self.attention([out, encoder_outputs], training=training)\n        out = self.fc(out)\n        state_1 = (h_1, c_1)\n        state_2 = (h_2, c_2)\n        state_3 = (h_3, c_3)\n        return out, (state_1, state_2, state_3)\n\nencoder_model_att = Encoder_att()\ndecoder_model_att = Decoder_att()\n\nencoder_inputs_att = tf.keras.layers.Input(shape=(None,))\ndecoder_inputs_att = tf.keras.layers.Input(shape=(None,))\n\nencoder_outputs_att, enc_state_att = encoder_model_att(encoder_inputs_att)\ndecoder_outputs_att, _ = decoder_model_att(decoder_inputs_att, enc_state_att, encoder_outputs_att)\n\nseq2seq = tf.keras.Model([encoder_inputs_att, decoder_inputs_att], decoder_outputs_att)","metadata":{"id":"s90qT0F2_9SG","execution":{"iopub.status.busy":"2021-06-19T06:56:48.778424Z","iopub.execute_input":"2021-06-19T06:56:48.77885Z","iopub.status.idle":"2021-06-19T06:56:58.276055Z","shell.execute_reply.started":"2021-06-19T06:56:48.778805Z","shell.execute_reply":"2021-06-19T06:56:58.27506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq2seq.summary()","metadata":{"id":"e3JyngNS4GuM","outputId":"0e9a1f6c-5790-4dea-fd8b-8c2d092d4970","execution":{"iopub.status.busy":"2021-06-19T06:56:58.277406Z","iopub.execute_input":"2021-06-19T06:56:58.277794Z","iopub.status.idle":"2021-06-19T06:56:58.28921Z","shell.execute_reply.started":"2021-06-19T06:56:58.277754Z","shell.execute_reply":"2021-06-19T06:56:58.288076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCHS = 50\n\nloss = tf.losses.SparseCategoricalCrossentropy()\nseq2seq.compile(optimizer='rmsprop', loss=loss, metrics=['accuracy'])\n\nfor iterate in range(0, 40):\n    seq2seq.fit([encoder_input_seqs, decoder_input_seqs], decoder_target_seqs,\\\n          batch_size=BATCH_SIZE, steps_per_epoch=50, epochs=EPOCHS)\n    print(next_line('Tell me about itTell me about it'))\n    print(next_line('What are you thinking about?'))\n    print(next_line('Close the door!'))\n    print(next_line('What is your name?'))\n    print(next_line('How about we have lunch together?'))\n    print(next_line('What time is it?'))\n    seq2seq.save_weights(f'model_att{iterate}iter_expanded')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> It takes a very long time to train again, so we load the weights with the model I have already trained","metadata":{}},{"cell_type":"code","source":"seq2seq.load_weights('../input/cleaned-data-for-the-chatbot-collected-from-movies/model_att29iter_expanded')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:56:58.292392Z","iopub.execute_input":"2021-06-19T06:56:58.292907Z","iopub.status.idle":"2021-06-19T06:57:01.54545Z","shell.execute_reply.started":"2021-06-19T06:56:58.292857Z","shell.execute_reply":"2021-06-19T06:57:01.54462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{"id":"Lx0xhbFC_UC8"}},{"cell_type":"code","source":"def seq2seq_att_inference(input_seq):\n    output, state = encoder_model_att(input_seq)\n\n    target_seq = np.array([[target_char2idx['<START>']]])\n\n    decoded_sentence = ''\n    while True:\n        output_tokens, state = decoder_model_att(x=target_seq, init_state=state, encoder_outputs=output, training=False)\n\n        sampled_token_index = np.argmax(np.array(output_tokens[0, -1, :]))\n        sampled_char = target_idx2char[sampled_token_index]\n        decoded_sentence += sampled_char\n\n        if (sampled_char == '<END>' or\n           len(decoded_sentence) > max_dec_seq_length):\n            break\n\n        target_seq = np.array([[sampled_token_index]])\n\n    return decoded_sentence","metadata":{"id":"8gyuBfn1_WXF","execution":{"iopub.status.busy":"2021-06-19T06:28:05.792959Z","iopub.execute_input":"2021-06-19T06:28:05.793375Z","iopub.status.idle":"2021-06-19T06:28:05.802522Z","shell.execute_reply.started":"2021-06-19T06:28:05.793334Z","shell.execute_reply":"2021-06-19T06:28:05.800645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def next_line(line):\n    int_seq = np.array([input_char2idx[c] for c in line])\n    int_seq_pad = np.zeros(100)\n    int_seq_pad[:len(int_seq)] = int_seq\n    int_seq_pad = int_seq_pad.reshape(1, -1)\n    decoded = seq2seq_att_inference(int_seq_pad)\n    if decoded[-5:] == '<END>':\n        decoded = decoded[:-5]\n    decoded = decoded.rstrip()\n    return decoded","metadata":{"id":"OZ5z-RRJ4CE4","execution":{"iopub.status.busy":"2021-06-19T06:58:04.640275Z","iopub.execute_input":"2021-06-19T06:58:04.64074Z","iopub.status.idle":"2021-06-19T06:58:04.648747Z","shell.execute_reply.started":"2021-06-19T06:58:04.640703Z","shell.execute_reply":"2021-06-19T06:58:04.647056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"line = 'Hi, how are you?'\nprint(line)\nfor _ in range(10):\n    line = next_line(line)\n    print(line)","metadata":{"id":"P2QXc-4nntjk","outputId":"52ce482c-c8ea-480e-ff20-07f159facd7e","execution":{"iopub.status.busy":"2021-06-19T06:58:07.008561Z","iopub.execute_input":"2021-06-19T06:58:07.008984Z","iopub.status.idle":"2021-06-19T06:58:29.780795Z","shell.execute_reply.started":"2021-06-19T06:58:07.008933Z","shell.execute_reply":"2021-06-19T06:58:29.779651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def own_dialog(len_of_conversation):\n    for i in range(len_of_conversation):\n        line_input = str(input())\n        line_output = next_line(line_input)\n        print(line_output)\nown_dialog(10)","metadata":{"id":"2abnNm8O4bvH","outputId":"edd860fe-9887-4046-f11f-393a6d368fc9","execution":{"iopub.status.busy":"2021-06-19T06:58:32.537278Z","iopub.execute_input":"2021-06-19T06:58:32.537651Z","iopub.status.idle":"2021-06-19T07:01:26.118404Z","shell.execute_reply.started":"2021-06-19T06:58:32.537621Z","shell.execute_reply":"2021-06-19T07:01:26.117272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the answers to be meaningful, you need to connect BERT or something like this","metadata":{}},{"cell_type":"markdown","source":"Most of the answers are at least grammatically correct","metadata":{}}]}