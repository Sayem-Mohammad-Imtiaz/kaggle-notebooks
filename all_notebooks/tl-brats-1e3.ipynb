{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install medpy","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:06:19.592479Z","iopub.execute_input":"2021-06-05T07:06:19.592941Z","iopub.status.idle":"2021-06-05T07:06:35.924368Z","shell.execute_reply.started":"2021-06-05T07:06:19.59286Z","shell.execute_reply":"2021-06-05T07:06:35.923481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom medpy.io import load, save\nimport numpy as np\nimport gc\nimport cv2\nimport glob\ntarget_dict={'HGG':1,'LGG':0}\ntargets_h=[]\nimages_h=[]\nfor path in tqdm(glob.glob('../input/brain-tumor-segmentation-brats-2019/MICCAI_BraTS_2019_Data_Training/HGG/*/*_flair.nii')):\n    trg=path.split('/')\n    img=load(path)[0]\n    seg=load(path.replace('_flair','_seg'))[0]\n    mn=np.mean(img)\n    std=np.std(img)\n    try:\n        pos=round((min(np.where(seg==1)[-1])+max(np.where(seg==1)[-1]))/2)\n        img=cv2.resize(img[:,:,pos], (224,224), interpolation = cv2.INTER_AREA )\n        img=(img-mn)/std\n        img=np.repeat(np.expand_dims(img,-1),3,-1)\n        images_h.append(img)\n        targets_h.append(target_dict[path.split('/')[4]])\n        del([img,seg])\n        gc.collect()\n    except:\n        continue","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:06:35.926127Z","iopub.execute_input":"2021-06-05T07:06:35.926473Z","iopub.status.idle":"2021-06-05T07:07:54.127858Z","shell.execute_reply.started":"2021-06-05T07:06:35.926427Z","shell.execute_reply":"2021-06-05T07:07:54.125829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom medpy.io import load, save\nimport numpy as np\nimport gc\nimport cv2\nimport glob\ntarget_dict={'HGG':1,'LGG':0}\ntargets_l=[]\nimages_l=[]\nfor path in tqdm(glob.glob('../input/brain-tumor-segmentation-brats-2019/MICCAI_BraTS_2019_Data_Training/LGG/*/*_flair.nii')):\n    trg=path.split('/')\n    original=load(path)[0]\n    seg=load(path.replace('_flair','_seg'))[0]\n    mn=np.mean(original)\n    std=np.std(original)\n    try:\n        pos=round((min(np.where(seg==1)[-1])+max(np.where(seg==1)[-1]))/2)\n        dev=np.std(list(range(original.shape[-1])))*0.08\n        \n        img=cv2.resize(original[:,:,pos+int(dev)], (224,224), interpolation = cv2.INTER_AREA )\n        img=(img-mn)/std\n        img=np.repeat(np.expand_dims(img,-1),3,-1)\n        images_l.append(img)\n        targets_l.append(target_dict[path.split('/')[4]])\n        \n        img=cv2.resize(original[:,:,pos-int(dev)], (224,224), interpolation = cv2.INTER_AREA )\n        img=(img-mn)/std\n        img=np.repeat(np.expand_dims(img,-1),3,-1)\n        images_l.append(img)\n        targets_l.append(target_dict[path.split('/')[4]])\n        \n        \n        img=cv2.resize(original[:,:,pos], (224,224), interpolation = cv2.INTER_AREA )\n        img=(img-mn)/std\n        img=np.repeat(np.expand_dims(img,-1),3,-1)\n        images_l.append(img)\n        targets_l.append(target_dict[path.split('/')[4]])\n        \n        del([img,seg])\n        gc.collect()\n    except:\n        continue","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:07:54.12875Z","iopub.status.idle":"2021-06-05T07:07:54.129126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=images_h+images_l\ntargets=targets_h+targets_l\nimport random\nls=list(range(len(images)))\nrandom.shuffle(ls)\nimages=np.stack(images)\ntargets=np.array(targets)\nimages=images[ls]\ntargets=targets[ls]","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:08:01.291279Z","iopub.execute_input":"2021-06-05T07:08:01.291624Z","iopub.status.idle":"2021-06-05T07:08:01.311292Z","shell.execute_reply.started":"2021-06-05T07:08:01.291595Z","shell.execute_reply":"2021-06-05T07:08:01.309528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:07:54.131868Z","iopub.status.idle":"2021-06-05T07:07:54.132515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import *\nimport tensorflow as tf\nimport random, os, sys\nimport numpy as np\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.initializers import *\nimport tensorflow as tf\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nclass LayerNormalization(Layer):\n    def __init__(self, eps=1e-6, **kwargs):\n        self.eps = eps\n        super(LayerNormalization, self).__init__(**kwargs)\n    def build(self, input_shape):\n        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n                                     initializer=Ones(), trainable=True)\n        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n                                    initializer=Zeros(), trainable=True)\n        super(LayerNormalization, self).build(input_shape)\n    def call(self, x):\n        mean = K.mean(x, axis=-1, keepdims=True)\n        std = K.std(x, axis=-1, keepdims=True)\n        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n    def compute_output_shape(self, input_shape):\n        return input_shape\nclass abc(keras.layers.Layer):\n    def __init__(self,\n                 hidden_dim,\n                 **kwargs):\n        self.hidden_dim = hidden_dim\n        \n        self.conv1=Conv1D(self.hidden_dim,1)\n        self.conv2=Conv1D(self.hidden_dim,1)\n        self.conv3=Conv1D(self.hidden_dim,1)\n        \n        self.Wq = self.Wk = self.Wv = self.Wo = None\n        self.bq = self.bk = self.bv = self.bo = None\n\n        self.intensity = self.attention = None\n        super(abc, self).__init__(**kwargs)\n\n    def call(self, inputs, mask=None):\n        \n        q, k, v = inputs\n        \n        q=self.conv1(q)\n        k=self.conv2(k)\n        v=self.conv3(v)\n        \n        \n        def scaled_dot_product_attention(inputs):\n          query, key, value = inputs\n          feature_dim = K.shape(query)[-1]\n          e = K.batch_dot(query, key, axes=2) \n          intensity = e\n          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n          attention = e / K.sum(e, axis=-1, keepdims=True)\n          v = K.batch_dot(attention, value)\n          return v\n       \n       \n        y = scaled_dot_product_attention(inputs=[q,k,v])\n        \n        \n        return y\n\nfrom tensorflow import keras \nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.applications import *\ndef load_model():   \n  \n  K.clear_session() \n  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n  d = mod.get_layer('conv5_block16_concat').output\n\n  inp = mod.get_layer('conv3_block12_concat').output\n  a = Reshape((28*28,512))(inp)\n  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n  d_a = Reshape((28*28,1024))(d_a)\n  a = abc(hidden_dim=512)([a,d_a,a])\n  a = LayerNormalization()(a)\n  a = Reshape((28,28,512,))(a)\n  a = keras.layers.GlobalAveragePooling2D()(a)\n\n  inp = mod.get_layer('conv4_block24_concat').output\n  b = Reshape((14*14,1024))(inp)\n  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n  d_b = Reshape((14*14,1024))(d_b)\n  b = abc(hidden_dim=1024)([b,d_b,b])\n  b = LayerNormalization()(b)\n  b = Reshape((14,14,1024,))(b)\n  b = keras.layers.GlobalAveragePooling2D()(b)\n\n  d = keras.layers.GlobalAveragePooling2D()(d)\n  \n\n  b = Dense(3, activation=\"softmax\")(b) \n  b = Reshape((-1,3))(b) \n  a = Dense(3, activation=\"softmax\")(a) \n  a = Reshape((-1,3))(a) \n  d = Dense(3, activation=\"softmax\")(d) \n  d = Reshape((-1,3))(d) \n  \n  conc=Concatenate(axis=1)([a,b,d])\n  conc=keras.layers.GlobalAveragePooling1D()(conc)\n  mod=Model(inputs=mod.input,outputs=conc)\n  mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n  for layer in mod.layers:\n    layer.trainable=False\n  a=mod.layers[-9].output\n  b=mod.layers[-10].output\n  d=mod.layers[-11].output\n  b = Dense(1, activation=\"sigmoid\")(b) \n  b = Reshape((-1,1))(b) \n  a = Dense(1, activation=\"sigmoid\")(a) \n  a = Reshape((-1,1))(a) \n  d = Dense(1, activation=\"sigmoid\")(d) \n  d = Reshape((-1,1))(d) \n  conc=Concatenate(axis=1)([a,b,d])\n  conc=keras.layers.GlobalAveragePooling1D()(conc)\n  mod=Model(inputs=mod.input,outputs=conc)\n  for en,layer in enumerate(mod.layers):\n    if layer.trainable==True:\n        print(en)\n  return mod\n\nmod=load_model()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:08:05.155689Z","iopub.execute_input":"2021-06-05T07:08:05.156029Z","iopub.status.idle":"2021-06-05T07:08:20.082004Z","shell.execute_reply.started":"2021-06-05T07:08:05.15599Z","shell.execute_reply":"2021-06-05T07:08:20.08116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom imgaug import augmenters as iaa\ndef rotate_image(image, angle):\n  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n  return result\ndef Hflip( images):\n\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n\t\treturn seq.augment_images(images)\ndef Vflip( images):\n\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n\t\treturn seq.augment_images(images)\ndef noise(images):\n    ls=[]\n    for i in images:\n        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n        ls.append(i+x)\n    return ls\ndef rotate(images):\n    ls=[]\n    for angle in range(-15,20,5):\n        for image in images:\n            ls.append(rotate_image(image,angle))\n    return ls\n\nclass DataGenerator(keras.utils.Sequence):\n  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n    self.labels       = labels              # array of labels\n    self.images = images        # array of image paths\n    self.batch_size   = batch_size          # batch size\n    self.on_epoch_end()\n\n  def __len__(self):\n    return int(np.floor(self.labels.shape[0] / self.batch_size))\n\n  def on_epoch_end(self):\n    self.indexes = np.arange(self.labels.shape[0])\n\n  def __getitem__(self, index):\n\t\t# selects indices of data for next batch\n    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n    # select data and load images\n    labels = self.labels[indexes]\n    img = [self.images[k].astype(np.float32) for k in indexes]\n    imgH=Hflip(img)\n    imgV=Vflip(img)\n    imgR=rotate(img)\n    images=[]\n    images.extend(imgH)\n    images.extend(imgV)\n    images.extend(imgR)\n    lbl=labels.copy()\n    labels=np.repeat(labels,9)\n    del([imgV,imgR,imgH,lbl])\n    gc.collect()\n    #images = np.array([preprocess_input(img) for img in images])\n    return np.asarray(images).astype('float16'), labels.astype('uint8')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:08:20.083661Z","iopub.execute_input":"2021-06-05T07:08:20.083994Z","iopub.status.idle":"2021-06-05T07:08:21.588817Z","shell.execute_reply.started":"2021-06-05T07:08:20.083955Z","shell.execute_reply":"2021-06-05T07:08:21.587947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nfrom tensorflow.keras.optimizers import *\ntrain_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\nmod.compile(optimizer=Adam(1e-3), loss='binary_crossentropy', metrics=['accuracy'])\nhist=mod.fit_generator(train_data,epochs=100)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:08:21.59063Z","iopub.execute_input":"2021-06-05T07:08:21.590994Z","iopub.status.idle":"2021-06-05T07:08:21.878446Z","shell.execute_reply.started":"2021-06-05T07:08:21.590958Z","shell.execute_reply":"2021-06-05T07:08:21.876948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre=mod.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(np.round(pre),y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:07:54.139062Z","iopub.status.idle":"2021-06-05T07:07:54.139642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#1e4 decay=1e5\nfrom matplotlib import pyplot as plt\nplt.plot(hist.history['loss'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:07:54.140762Z","iopub.status.idle":"2021-06-05T07:07:54.141389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist.history['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T07:07:54.142408Z","iopub.status.idle":"2021-06-05T07:07:54.143018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}