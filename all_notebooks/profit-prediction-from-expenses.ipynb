{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Profit Prediction from Expenses</h1>\n\nby <b>Santanu Sikder</b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the necessary modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Data Loading and Cleaning</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dataset containing the various expenses of 50 startups and their profits\ndf = pd.read_csv(\"../input/various-expenses-and-the-profits-of-50-startups/50_Startups.csv\")\n# Preview\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing values\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neither there is any missing value, nor any unstandardised one.\nThe only thing left is to convert the categorical variable State into a numerical one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# LabelEncoder from sklearn.preprocessing can be used to convert multiple categories in a categorical variable into numerical values\ncatToNum = LabelEncoder()\ndf[\"State\"] = catToNum.fit_transform(df[\"State\"])\n# Preview\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the name of the R&D Spend column to RD and Marketing Spend to Marketing\ndf.rename(columns = {\"R&D Spend\" : \"RD\", \"Marketing Spend\" : \"Marketing\"}, inplace = True)\n# Preview\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Data Analysis and Visualisation</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's study the dataframe a bit more using describe and info.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To understand the above data better, I'm going to plot a boxplot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14, 8))\nsns.boxplot(x = df.columns, y = [df[col] for col in df.columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above analysis, we see that Marketing costs have the widest range and Administration costs have the narrowest one. The expenses are almost equally distributed among the two sides of the medians and no type of expenses has any outlier.\nHowever the range of the profits is quite small and has a lower outlier.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Also, the Research & Development expenses (RD) and the Administration costs have a similar range as that of the Profits, but that of the Marketing costs is very different (large and varied).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's look at the correlation table to check how good are the expenses at predicting the profit, in terms of linear relationship.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This informs us that Administration costs and State are poorly related to Profit linearly and that RD is very strongly related (quite obvious).\nBut the State categorical variable MIGHT be a good factor in determining Profit, if combined with other factors. Let's check how different are the profits in case of different States.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the differences in the means\n# California: 0, Florida: 1, New York: 2\ndf.groupby(\"State\", as_index = True).mean()[\"Profit\"].to_frame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the differences in minimums and maximums\nmaximums = df.groupby(\"State\").max()[\"Profit\"].to_frame()\nminimums = df.groupby(\"State\").min()[\"Profit\"].to_frame()\nminimums.merge(maximums, on = \"State\").rename(columns = {\"Profit_x\" : \"min\", \"Profit_y\" : \"max\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The maximum Profits yielded by the States are almost equal while the minimum values have visible differences.\nTime for the boxplots!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data = df, x = \"State\", y = \"Profit\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For deeper understanding, I'll do a F-test and examine the F-values for the various pairs of groups","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stateGroups = df.groupby(\"State\", as_index = True)\ngCal, gFlor, gNY = stateGroups.get_group(0)[\"Profit\"], stateGroups.get_group(1)[\"Profit\"], stateGroups.get_group(2)[\"Profit\"]\n# So I got the groups above and now I'll create a list for making the pairing easy during the F-tests\nprofitGroups = [gCal, gFlor, gNY, gCal]\nfor i in range(3):\n    f_score, p_value = stats.f_oneway(profitGroups[i], profitGroups[i + 1])\n    print('''\\\n    Category pair: (%d, %d)\n    F-Score = %f\n    P-Value (Confidence Score) = %f\n    '''%(i, (i + 1) % 3, f_score, p_value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above data confirms our correlation table that State is not a good linear predictor for Profit alone.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's plot the regression plots between Profit and each of the expenses, and also the State!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize = (14, 12))\nfig.suptitle(\"Regression plots: Profit vs expenses and State\", fontsize = 20)\naxesList = list(axes[0])\naxesList.extend(list(axes[1]))\n\nfor i, axis in enumerate(axesList):\n    col = df.columns[i]\n    sns.regplot(data = df, x = col, y = \"Profit\", ax = axis)\n    axis.set_title(\"Profit vs %s %s\"%(col, \"costs\" if col != \"State\" else \"categories\"), fontsize = 15)\n\n# plt.savefig(\"Profit_vs_Expenses.jpg\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Processing Data for Model Training</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fortunately, there's no need of standard scaling. So I'll directly perform the Train-Test split.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, testX, trainy, testy = train_test_split(df[df.columns[:-1]], df[[\"Profit\"]], test_size = 1/5, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Model Training</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate the linear regression object\nregr = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train using the training set\nregr.fit(trainX, trainy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print out the coefficients matrix (m * n) and the intercept vector (m,)\nprint('''\\\nCoefficients: %s\nIntercepts: %s\n'''%(regr.coef_, regr.intercept_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Model Evaluation and Testing our Model</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I'll use MSE, RMSE and R2-Score to evaluate this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly, let's create the trainyCap and testyCap arrays by predicting values based on trainX and testX, respectively\ntrainyCap = regr.predict(trainX)\ntestyCap = regr.predict(testX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I'll check the statistical scores in both the cases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training set's evaluation\nmse = mean_squared_error(trainy, trainyCap)\nrmse = np.sqrt(mse) # or mean_squared_error(trainy, trainyCap, squared = False)\nr2 = r2_score(trainy, trainyCap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set's evaluation\nmse2 = mean_squared_error(testy, testyCap)\nrmse2 = np.sqrt(mse2) # or mean_squared_error(trainy, trainyCap, squared = False)\nr22 = r2_score(testy, testyCap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the above results into a dataframe\ndfEvaluation = pd.DataFrame({\"Train\" : [mse, rmse, r2], \"Test\" : [mse2, rmse2, r22]}, index = [\"MSE\", \"RMSE\", \"R2 Score\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View\ndfEvaluation","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}