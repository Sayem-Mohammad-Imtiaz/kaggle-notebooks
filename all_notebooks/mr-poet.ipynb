{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport random\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/all.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bd0d7f144da8ffb3a0faa719dba8baedcbf6c3c","collapsed":true},"cell_type":"code","source":"content = df['content'].tolist()[:3]","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"0203c7bd2249ea208f71f45c026cb7c8f09d5cf2"},"cell_type":"markdown","source":"## Convert sentence into list of words"},{"metadata":{"trusted":true,"_uuid":"710080392a3057d615791ea2e8e34d88b891e8a8","collapsed":true},"cell_type":"code","source":"def sent_to_words(content):\n    return [np.array([x.split() for x in poem.split()]) for poem in content]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1f6ceea141550199101fec5894f4177677924be"},"cell_type":"code","source":"poems = sent_to_words(content)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"d6e34f6a590a8aef3987f7d1bfc26c852d1db4d5"},"cell_type":"markdown","source":"## Convert char to number mapping"},{"metadata":{"trusted":true,"_uuid":"e466080dfddeabd74331ff0edd11e720e2680f10","collapsed":true},"cell_type":"code","source":"def build_dict(poems):\n    dictionary = {}\n    rev_dict = {}\n    count = 0\n    for content in poems:\n        for i in content:\n            if i[0] in dictionary:\n                pass\n            else:\n                dictionary[i[0]] = count\n                count += 1\n    rev_dict = dict(zip(dictionary.values(), dictionary.keys()))\n    return dictionary, rev_dict","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7692ec1cff720b0b44aee87de694c596ffb7c63","collapsed":true},"cell_type":"code","source":"dictionary, rev_dict = build_dict(poems)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"d1542471fd0ed66e9ef3480f8f7bea356a8130e6"},"cell_type":"markdown","source":"## LSTM time"},{"metadata":{"trusted":true,"_uuid":"e09452f7540d65de4fd653be6995fee893ac33aa","collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.contrib import rnn","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"334f0b27493b3f96a3817c13c1087d430b37c456"},"cell_type":"code","source":"vocab_size = len(dictionary)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7691eae5bd66e13acd50bdf58f089d38d5e89108"},"cell_type":"code","source":"# Parameters\nlearning_rate = 0.0001\ntraining_iters = 1600\ndisplay_step = 200\nn_input = 9","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ff485abf057745e85bce0df2554a2347530a610e"},"cell_type":"code","source":"# number of units in RNN cell\nn_hidden = 512","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32a292c643b66b8e514a6f26a7713484f087d5e6","collapsed":true},"cell_type":"code","source":"# tf Graph input\ntf.device(\"/device:GPU:0\")\nx = tf.placeholder(\"float\", [None, n_input, 1])\ny = tf.placeholder(\"float\", [None, vocab_size])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c78d6b1e10400d17f842f81b8b16ab43b3329f64"},"cell_type":"code","source":"# RNN output node weights and biases\nweights = {\n    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n}\nbiases = {\n    'out': tf.Variable(tf.random_normal([vocab_size]))\n}","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6de51e8da35c0c74ef51590ab96fba0c3677a470"},"cell_type":"code","source":"def RNN(x, weights, biases):\n\n    # reshape to [1, n_input]\n    x = tf.reshape(x, [-1, n_input])\n\n    # Generate a n_input-element sequence of inputs\n    # (eg. [had] [a] [general] -> [20] [6] [33])\n    x = tf.split(x,n_input,1)\n\n    # 2-layer LSTM, each layer has n_hidden units.\n    # Average Accuracy= 95.20% at 50k iter\n    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n    # generate prediction\n    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n    # there are n_input outputs but\n    # we only want the last output\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0a2d3f502014d5c4a7e8a779c6b8c9419d4af9","collapsed":true},"cell_type":"code","source":"pred = RNN(x, weights, biases)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faf88f9687b8daec6dc0ef0f6d016eb53053d740","collapsed":true},"cell_type":"code","source":"# Loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1652c4d8eb6d7007837d9074538bf60a85d8635b"},"cell_type":"code","source":"# Model evaluation\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3be694b6eb5f57b37bd42ff52e24f23aee2db9ac"},"cell_type":"code","source":"saver = tf.train.Saver()\ninit = tf.global_variables_initializer()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3abba475c27ad24cd8c0801326cb3d736f1942c6","collapsed":true},"cell_type":"code","source":"df_train = sent_to_words(content)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afdfb0a74c0ace0fb11ecfa81a148f2ebe6946d1","collapsed":true},"cell_type":"code","source":"j = 0\nfor i in df_train:\n    if i.shape[0] <= n_input:\n        df_train = np.delete(df_train, (j), axis = 0)\n        j -= 1\n    j += 1","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddd282b7eecef03865f989d2ae93179c46628f70","collapsed":true},"cell_type":"code","source":"with tf.Session() as session:\n    session.run(init)\n    step = 0\n    end_offset = n_input + 1\n    acc_total = 0\n    loss_total = 0\n    while step < training_iters:\n        acc_total = 0\n        loss_total = 0\n        j = 0\n        for training_data in df_train:\n            m = training_data.shape[0]\n            windows = m - n_input\n            acc_win = 0\n            for window in range(windows):\n                batch_x = training_data[window : window + n_input]\n                batch_y = training_data[window + n_input]\n                symbols_in_keys = [dictionary[i[0]] for i in batch_x]\n                symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n        \n                symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n                symbols_out_onehot[dictionary[batch_y[0]]] = 1.0\n                symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n\n                _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n                loss_total += loss\n                acc_win += acc\n            acc_total += float(acc_win) / m\n        acc_total /= len(df_train)\n        if (step+1) % display_step == 0:\n            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n                  \"{:.2f}%\".format(100*acc_total))\n        step += 1\n    print(\"Optimization Finished!\")\n    save_path = saver.save(session, \"../working/model.ckpt\")\n    print(\"Model saved in path: %s\" % save_path)\n    while True:\n        prompt = \"%s words: \" % n_input\n        sentence = 'When I Queen Mab within my fancy viewed, My'\n        sentence = sentence.strip()\n        words = sentence.split(' ')\n        if len(words) != n_input:\n            continue\n        try:\n            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n            for i in range(64):\n                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n                onehot_pred = session.run(pred, feed_dict={x: keys})\n                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n                sentence = \"%s %s\" % (sentence,rev_dict[onehot_pred_index])\n                symbols_in_keys = symbols_in_keys[1:]\n                symbols_in_keys.append(onehot_pred_index)\n            print(sentence)\n            break\n        except:\n            print(\"Word not in dictionary\")","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b0c801a36cf5022cf8cdf474dfbc8b269f0eb5c","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4231f469b949106681d5ded927bec04f17d7382f","collapsed":true},"cell_type":"markdown","source":"Sir Charles into my chamber coming in, When I was writing of my Fairy Queen; I praysaid hewhen Queen Mab you do see Present my service to her Majesty: And tell her I have heard Fame's loud report Both of her beauty and her stately court. When I Queen Mab within my fancy viewed, My thoughts bowed low, fearing I should be rude; Kissing her garment thin which fancy made, I knelt upon a thought, like one that prayed; And then, in whispers soft, I did present His humble service which in mirth was sent; Thus by imagination I have been In Fairy court and seen the Fairy Queen."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"05f324c3b507b085aea53603f3074db969529410"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0e4cc7aa6d4e771880b9ff7a93fa1f7830c6876c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}