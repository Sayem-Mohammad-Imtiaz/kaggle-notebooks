{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Importing necessary libraries\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom wordcloud import WordCloud\n#from autocorrect import spell\nimport matplotlib.pyplot as plt\nfrom math import log, sqrt\nfrom sklearn.model_selection import train_test_split, cross_validate, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.classify.scikitlearn import SklearnClassifier\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, export_text\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, classification_report\nimport numpy as np\nimport pandas as pd\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2. Loading the Dataset\nmessages = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', encoding = 'latin-1')\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3.a. Dataset Pre-Processing\n# removing unwanted columns\nmessages = messages.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming columns and converting to numerical form\nmessages = messages.rename(columns={'v1':'label', 'v2':'message'})\nprint(messages.label.value_counts())\nmessages['label'] = messages.label.map({'ham':0, 'spam':1})\nmessages.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4. Visualizing the Dataset\n\n# basic description of the dataset\nprint('Dataset Description : ', messages.groupby('label').describe(),'\\n')\n# length of the messages \nmessages['start_length'] = messages['message'].map(lambda msg: len(msg))\nprint(messages.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spam messages word cloud\nspamWords = ''.join(list(messages[messages['label']==1]['message']))\nspamWordCloud = WordCloud(width=512, height=512).generate(spamWords)\nplt.figure(figsize=(10,10), facecolor='k')\nplt.imshow(spamWordCloud)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ham messages word cloud\nhamWords = ''.join(list(messages[messages['label']==0]['message']))\nhamWordCloud = WordCloud(width=512, height=512).generate(hamWords)\nplt.figure(figsize=(10,10), facecolor='k')\nplt.imshow(hamWordCloud)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3.b. Dataset Preprocessing prep for training\ndef preprocessing(dataset):\n    lbls = dataset['label']\n    msgs = dataset['message']\n\n    processedMessages = msgs.str.replace(r'[^A-Za-z\\s\\w\\d\\s+]', '')\n\n    processedMessages = processedMessages.str.lower()\n\n    stop_words = stopwords.words('english')\n    processedMessages = processedMessages.apply(lambda words: ' '.join(word for word in words.split() if word not in set(stop_words)))\n\n    stemmer = PorterStemmer()\n    processedMessages = processedMessages.apply(lambda words: ' '.join(stemmer.stem(word) for word in words.split()))\n    \n    return pd.concat([lbls, processedMessages], axis=1)\n\nprocessedMessages = preprocessing(messages)\n\nprocessedMessages['after_length'] = processedMessages['message'].map(lambda msg: len(msg))\nprint(processedMessages.head())\n\n#example = pd.DataFrame({'label':[0], 'message': [\"\"\"  ***** CONGRATlations **** You won 2 tIckETs to Hamilton in NYC http://www.hamiltonbroadway.com/J?NaIOl/event   wORtH over $500.00...CALL 555-477-8914 or send message to: hamilton@freetix.com to get ticket !! !  \"\"\"]})\nexample = pd.DataFrame({'label':[1], 'message': [\"Free entry in 2 a wkly comp to win FA Cup final\"]})\nprocessedExample = preprocessing(example)\nprint(processedExample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Message Lengths comparison before and after dataset prepeocessing\nfigure, ax = plt.subplots(1,2)\nax[0].hist(messages['start_length'], bins=50)\nax[0].set_title('Messages before Preprocessing')\nax[0].set_xlabel('message length')\nax[0].set_ylabel('frequency')\n\nax[1].hist(processedMessages['after_length'], bins=50)\nax[1].set_title('Messages after Preprocessing')\nax[1].set_xlabel('message length')\nax[1].set_ylabel('frequency')\nplt.show()\n\n# based on message length and label\nmessages['start_length'].hist(by = messages['label'])\nprocessedMessages['after_length'].hist(by = processedMessages['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5. Splitting dataset into Training and Testing 75:25 \nprint(processedMessages.head())\ntrainMessages, testMessages, trainLabels, testLabels = train_test_split(\n    processedMessages[\"message\"], processedMessages[\"label\"], test_size = 0.25, random_state = 10\n)\nprint(trainMessages.shape)\nprint(testMessages.shape)\nprint(trainLabels.shape)\nprint(testLabels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 6. Classifier\nvectorize = CountVectorizer(stop_words='english')\nvectorize.fit(trainMessages)\n\ntrainMessagesDF = vectorize.transform(trainMessages)\ntestMessagesDF = vectorize.transform(testMessages)\nexampleMessageDF = vectorize.transform(processedExample['message'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# multinomial naive bayes classifier\nmnbModel = MultinomialNB()\n%time mnbModel.fit(trainMessagesDF,trainLabels)\n\nmnbPrediction = mnbModel.predict(testMessagesDF)\n\nprint('Multinomial Naive Bayes F1 Score :', metrics.f1_score(testLabels, mnbPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, mnbPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Multinomial Naive Bayes - Classification Report \\n', classification_report(testLabels, mnbPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bernoulli naive bayes classifier\nbnbModel = BernoulliNB()\nbnbModel.fit(trainMessagesDF,trainLabels)\n\nbnbPrediction = bnbModel.predict(testMessagesDF)\n\nprint('Bernoulli Naive Bayes F1 Score :', metrics.f1_score(testLabels, bnbPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, bnbPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Bernoulli Naive Bayes - Classification Report \\n', classification_report(testLabels, bnbPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear svc classifier\nlinsvcModel = LinearSVC()\nlinsvcModel.fit(trainMessagesDF,trainLabels)\n\nlinsvcPrediction = linsvcModel.predict(testMessagesDF)\n\nprint('Linear SVC F1 Score :', metrics.f1_score(testLabels, linsvcPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, linsvcPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Linear SVC - Classification Report \\n', classification_report(testLabels, linsvcPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# svc classifier\nsvcModel = SVC(kernel='rbf')\nsvcModel.fit(trainMessagesDF,trainLabels)\n\nsvcPrediction = svcModel.predict(testMessagesDF)\n\nprint('SVC (rbf Kernel) F1 Score :', metrics.f1_score(testLabels, svcPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, svcPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('SVC (rbf Kernel) - Classification Report \\n', classification_report(testLabels, svcPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# logistic regression classifier\nlogRegModel = LogisticRegression()\nlogRegModel.fit(trainMessagesDF, trainLabels)\n\nlogRegPrediction = logRegModel.predict(testMessagesDF)\n\nprint('Logistic Regression F1 Score :', metrics.f1_score(testLabels, logRegPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, logRegPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Logistic Regression - Classification Report \\n', classification_report(testLabels, logRegPrediction))","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"# decision tree classifier\ndtcModel = DecisionTreeClassifier()\ndtcModel.fit(trainMessagesDF, trainLabels)\n\ndtcPrediction = dtcModel.predict(testMessagesDF)\n\nprint('Decision Tree F1 Score :', metrics.f1_score(testLabels, dtcPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, dtcPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Decision Tree - Classification Report \\n', classification_report(testLabels, dtcPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K Nearest Neighbors classifier\nkncModel = KNeighborsClassifier(1)\nkncModel.fit(trainMessagesDF, trainLabels)\n\nkncPrediction = kncModel.predict(testMessagesDF)\n\nprint('K Nearest Neighbors F1 Score :', metrics.f1_score(testLabels, kncPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, kncPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('K Nearest Neighbors - Classification Report \\n', classification_report(testLabels, kncPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random forest classifier\nrfModel = RandomForestClassifier(n_estimators=1, min_samples_split=30)\nrfModel.fit(trainMessagesDF,trainLabels)\n\nrfPrediction = rfModel.predict(testMessagesDF)\n\nprint('Random Forest Classifier F1 Score :', metrics.f1_score(testLabels, rfPrediction))\n# cross-validation using confusion matrix\npd.DataFrame(metrics.confusion_matrix(testLabels, rfPrediction),index=[['actual', 'actual'], ['spam', 'ham']], columns=[['predicted', 'predicted'], ['spam', 'ham']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Random Forests - Classification Report \\n', classification_report(testLabels, rfPrediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7. Model Performance Evaluation\nscoring = {'accuracy':metrics.make_scorer(metrics.accuracy_score), \n           'precision':metrics.make_scorer(metrics.precision_score),\n           'recall':metrics.make_scorer(metrics.recall_score), \n           'f1_score':metrics.make_scorer(metrics.f1_score)}\n\ndef modelPerformanceEvaluation(X, Y, cvFolds):\n    MNB = cross_validate(mnbModel, X, Y, cv=cvFolds, scoring=scoring)\n    BNB = cross_validate(bnbModel, X, Y, cv=cvFolds, scoring=scoring)\n    linearSVC = cross_validate(linsvcModel, X, Y, cv=cvFolds, scoring=scoring)\n    SVC = cross_validate(svcModel, X, Y, cv=cvFolds, scoring=scoring)\n    logReg = cross_validate(logRegModel, X, Y, cv=cvFolds, scoring=scoring)\n    DTC = cross_validate(dtcModel, X, Y, cv=cvFolds, scoring=scoring)\n    KNC = cross_validate(kncModel, X, Y, cv=cvFolds, scoring=scoring)\n    RF = cross_validate(rfModel, X, Y, cv=cvFolds, scoring=scoring)\n\n    modelsScoreTable = pd.DataFrame(\n        {'Multinomial Naive Bayes': [\n            MNB['test_accuracy'].mean(),\n            MNB['test_precision'].mean(),\n            MNB['test_recall'].mean(),\n            MNB['test_f1_score'].mean()\n        ],\n        'Bernoulli Naive Bayes': [\n            BNB['test_accuracy'].mean(),\n            BNB['test_precision'].mean(),\n            BNB['test_recall'].mean(),\n            BNB['test_f1_score'].mean()\n        ],\n        'Linear Support Vector Classifier': [\n            linearSVC['test_accuracy'].mean(),\n            linearSVC['test_precision'].mean(),\n            linearSVC['test_recall'].mean(),\n            linearSVC['test_f1_score'].mean()\n        ],\n        'Support Vector Classifier': [\n            SVC['test_accuracy'].mean(),\n            SVC['test_precision'].mean(),\n            SVC['test_recall'].mean(),\n            SVC['test_f1_score'].mean()\n        ],\n        'Logistic Regression': [\n            logReg['test_accuracy'].mean(),\n            logReg['test_precision'].mean(),\n            logReg['test_recall'].mean(),\n            logReg['test_f1_score'].mean()\n        ],\n        'Decision Tree Classifier': [\n            DTC['test_accuracy'].mean(),\n            DTC['test_precision'].mean(),\n            DTC['test_recall'].mean(),\n            DTC['test_f1_score'].mean()\n        ],\n        'K Nearest Neighbor Classifier': [\n            KNC['test_accuracy'].mean(),\n            KNC['test_precision'].mean(),\n            KNC['test_recall'].mean(),\n            KNC['test_f1_score'].mean()\n        ],\n        'Random Forest Classifier': [\n            RF['test_accuracy'].mean(),\n            RF['test_precision'].mean(),\n            RF['test_recall'].mean(),\n            RF['test_f1_score'].mean()\n        ]},\n        index = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n    )\n\n    modelsScoreTable['Best Score'] = modelsScoreTable.idxmax(axis=1)\n\n    return modelsScoreTable\n\nmodelPerformanceEvaluation(trainMessagesDF, trainLabels, 8)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc_aucCurve(X, Y, testPrediction, classifier):\n    spam_auc = roc_auc_score(testLabels, testPrediction)\n\n    print(classifier, ' - Spam Messages: ROC AUC = %.3f' % (spam_auc))\n\n    spamFalsePos, spamTruePos, _ = roc_curve(testLabels, testPrediction)\n    return [spamFalsePos, spamTruePos]\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, mnbPrediction, 'Multinomial NB')\nplt.plot(res[0], res[1], linestyle='--', color='orange', label='Multinomial NB')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, bnbPrediction, 'Bernoulli NB')\nplt.plot(res[0], res[1], linestyle='-', color='pink', label='Bernoulli NB')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, linsvcPrediction, 'Linear SVC')\nplt.plot(res[0], res[1], linestyle=':', color='green', label='Linear SVC')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, svcPrediction, 'SVC (rbf Kernel)')\nplt.plot(res[0], res[1], linestyle='-', color='purple', label='SVC')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, logRegPrediction, 'Logistic Regression')\nplt.plot(res[0], res[1], linestyle='dashdot', color='blue', label='Logistic Regression')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, dtcPrediction, 'Decision Tree')\nplt.plot(res[0], res[1], linestyle='--', color='black', label='Decision Tree')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, kncPrediction, 'K Nearest Neighbor')\nplt.plot(res[0], res[1], linestyle=':', color='red', label='K Nearest Neighbor')\n\nres = roc_aucCurve(trainMessagesDF, trainLabels, rfPrediction, 'Random Forest')\nplt.plot(res[0], res[1], linestyle='dashdot', color='yellow', label='Random Forest')\n\nplt.title('ROC Curve')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend(loc='best')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ensemble Classifier (Voting Classifier)\nvotingCLF = VotingClassifier(estimators=[\n    ('MNB', mnbModel), ('BNB', bnbModel), ('linearSVC', linsvcModel), ('SVC', svcModel), ('logReg', logRegModel), ('DTC', dtcModel), ('KNC', kncModel), ('RF', rfModel)\n], voting='hard')\n\nfor clf, label in zip([mnbModel, bnbModel, linsvcModel, svcModel, logRegModel, dtcModel, kncModel, rfModel, votingCLF], ['Multinomial NB', 'Bernoulli NB', 'Linear SVC', 'SVC (rfb Kernel', 'Logistic Regression', 'Decision Tree', 'K Nearest Neighbor', 'Random Forest', 'Ensemble']):\n    scores = cross_val_score(clf, trainMessagesDF, trainLabels, scoring='accuracy', cv=9)\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}