{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bayesian Model Averaging Regression\n\nIn this notebook we will use Bayes Factors and then Bayesian Model Averaging (BMA) to understand a linear regression problem.  The data is SAT scores for all states in the US, with information on school expenditures, student participation, student to teacher ratio, and teacher salary."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom statsmodels.regression.linear_model import OLS\nfrom statsmodels.tools import add_constant\nfrom itertools import combinations","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the data, and check the head.  Our data is a the SAT scores by U.S. state along with variables for each state that might impact the average SAT score."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sat-score-data-by-state/Guber1999data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We start our analysis with a linear regression model has Total SAT score as a function of spending."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[[\"Spend\"]]\ny = df[\"SATT\"]\nregr = OLS(y, add_constant(X)).fit()\nregr.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that we get something very suprising here.  The coefficient for spending is -20.8922, with a p-score of 0.006.  This means that the variable is significant, and that higher spending corresponds to lower SAT scores, on average.  While we certainly won't make the improper conclusion that spending *causes* a decrease in SAT scores, this is still counter-intuitive.\n\nLet's use the seaborn library and a pairplot to look at the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seaborn visualization library\nimport seaborn as sns\n# Create the default pairplot\nsns.pairplot(df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bayesian Information Criterion and Bayes Factors\n\nWe want to use the Bayesian Information Criterion to analyze models.  There are different information criterion that can be computed and used to estiamte liklihoods.  The different ICs use different approximations (using different simplifying assumptions and Taylor Series approximations). Assuming that the errors are normaly distributed, the formula for **Bayesian Information Criterion (BIC)** is:\n\\begin{equation}\n    \\text{BIC} = n\\ln(\\hat{\\sigma^2_e}) + k \\ln(n)\n\\end{equation}\nwhere $n$ is the number of observations (data values), $k$ is the number of predictor variables in the regression model, and $\\hat{\\sigma^2_e}$ is the error variance, or Mean Squared Error (MSE),\n\\begin{equation}\n    \\hat{\\sigma^2_e} = \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n {(y_i-\\hat{y_i})}^2.\n\\end{equation}\nNote that the BIC formula has two terms.  The frist term, $n\\ln(\\hat{\\sigma^2_e})$, measures the goodness-of-fit, since lower MSE gives a lower valuer for the first term.  The second term, $k \\ln(n)$, is a penalty on the number of input varialbes in the model, and increases as the number of input valirables increases.\n\nWe also want to consider the likelihood of this model, and the likelihood is given by\n\\begin{equation}\n    p(x|M)=e^{-\\text{BIC}/2}.\n\\end{equation}\nwhich, sometimes for ease of computation is combined with the above formulas to get a formula for likelihood in terms of MSE,\n\\begin{equation}\n    p(x|M)=\\text{MSE}^{-n/2}n^{-k/2}.\n\\end{equation}\nSometimes it is more intuitive to write the formula as\n\\begin{equation}\n    p(x|M)=\\frac{1}{\\text{MSE}^{n/2}}\\frac{1}{n^{k/2}}.\n\\end{equation}\n\nIf we have two models $M_1$ and $M_2$ with prior probabilities $p(M_1)$ and $p(M_2)$, the **Bayes Factor** is the ratio\n\\begin{equation}\n   {BF}_{12} =\\frac{p(x|M_1)p(M_1)}{p(x|M_2)p(M_2)},\n\\end{equation}\nwhich is just the likelihood ratio if we have equal (uninformative) priors."},{"metadata":{"trusted":true},"cell_type":"code","source":"likelihood1 = np.exp(-regr.bic/2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just as a verification, we can check that the this likelihood gives us a value that is close to the likelihood provided by the OLS software.  Because these computaitons are approximations to integrals, we expect the values to be close but not exactly equal."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.log(likelihood1))\nprint(regr.llf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create a model that considerd both the Spending and PrcntTake (percentage of students who take the exam) variables, and record the likelihood."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[[\"Spend\", \"PrcntTake\"]]\ny = df[\"SATT\"]\nregr = OLS(y, add_constant(X)).fit()\nlikelihood2 = np.exp(-regr.bic/2)\nregr.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Examining the summary, we see that this model has a higher F-statistic (106.7 in comparison to the 8.128 for the previous model) and a lower BIC (498.5 in comparison to 572.4 for the previous model).  Both of these suggest that this 2-element model is better than the previous 1-element model. (Recall that the F-statistic is useful for comparing two models onlt when the models are nested - one model is a subset of the other - which is the case here.)\n\nThis second model has a coefficient of 12.2865 for the spend variable, and still a p-score of 0.006, now suggesting that, for the same percent of students taking the exam, higher spending corresponds to higher SAT scores.  \n\nThe PrcntTake variable has a coefficient of -2.8509, so it appears that the PrcntTake variable is explaining the drop in SAT scores.  Schools in states that have higher spending also have higher percentages of students taking the exam, and thus are less 'selective' about which students take the exam.\n\nWe can use the Bayes' Factor to compare the likelihoods of these two models."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(likelihood2/likelihood1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This Bayes factor is extremely large, suggesting that the 2-element model is much more likely than the 1-element model, so we should trust its conclusions more strongly.  But while giving one answer, this raises new questions:  \n* Do we just take the value of 12.2865 for the coefficent of the spend variable, or should it be something else?\n* How does the coefficient for Spend change as we add or remove other variables?  \n* Among all the other possible models, what else might they tell us?\n\nWe will use Bayesian Model Averaging (BMA) to address these questions, but first we check the full model for comparison."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[[\"Spend\", \"StuTeaRat\", \"Salary\", \"PrcntTake\"]]\ny = df[\"SATT\"]\nregr = OLS(y, add_constant(X)).fit()\nbic4 = regr.bic\nlikelihood4 = np.exp(-bic4/2)\nregr.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observe that the coefficient for Spend is now around 4.5, significantly less than the 12.3 we saw in the 2-element model.  Which value is correct?  (And really what does 'correct' mean....?)\n\nThe F-statistic and BIC score are between the values for the first two models we looked at, suggesting this model is somewhere between the previous two in terms of being 'correct'.  Again, this raises more questions:\n* How do we interpret this new model in light of the previous two?\n* Is this new model good enough that we should somehow consider the values of the coefficients as well?\n* and what about the $2^4=16$ total number of models that could be made?  Should we look at each individualy?\n\nFortunately, this is exactly what Baeysian Model Averaging is designed to handle!"},{"metadata":{},"cell_type":"markdown","source":"# Bayesian Model Averaging\nHere we define the class that will perform our BMA analysis.\n\nFor any model $M_i$ (each model is defined by the set of predictor varialbes being used in the model), Bayes theorem tells us that the probability for $M_i$ is\n\\begin{equation}\np(M_i|X,y)=\\frac{p(X,y|M_i)p(M_i)}{p(X,y)}.\n\\end{equation}\n\nUsing our previous formulas, this becomes,\n\\begin{equation}\np(M_i|X,y)=\\frac{e^{−\\text{BIC}_i/2}p(M_i)}{\\sum_k e^{−\\text{BIC}_k/2}p(M_k)}.\n\\end{equation}\n\nSo far, we have just done Bayesian analysis to compute a posterior probability distribution on the parameters.  But now we can do more with the 'averaging' part of BMA.\n\nThe probability for any predictor variable is the sum of the probabilities for all models contiaining that predictor variable, and the expected value for the coefficient of the predictor variable is the average value of the coefficient over all models containing the variable, weighted by the probability of each model.  That is,\n\\begin{equation}\np(X_k) = \\sum_{M_i \\text{such that } X_k\\in M_i} p(M_i|X,y),\n\\end{equation}\nand\n\\begin{equation}\nE[\\beta_k] = \\sum_{M_i \\text{such that } X_k\\in M_i} p(M_i|X,y)\\times \\beta_k^{(i)},\n\\end{equation}\nwhere $\\beta_k^{(i)}$ is the coefficient of $X_k$ in model $M_i$."},{"metadata":{},"cell_type":"markdown","source":"Here is code for a BMA class that will do the Bayeisan Model Averaging.  An excessively commented version of this code is provided at the end of the notebook, which includes commenting for the model averaging steps and code functionality."},{"metadata":{"trusted":true},"cell_type":"code","source":"class BMA:\n    \n    def __init__(self, y, X, **kwargs):\n        # Setup the basic variables.\n        self.y = y\n        self.X = X\n        self.names = list(X.columns)\n        self.nRows, self.nCols = np.shape(X)\n        self.likelihoods = np.zeros(self.nCols)\n        self.coefficients = np.zeros(self.nCols)\n        self.probabilities = np.zeros(self.nCols)\n        self.names = list(X.columns)\n        # Check the max model size. (Max number of predictor variables to use in a model.)\n        # This can be used to reduce the runtime but not doing an exhaustive sampling.\n        if 'MaxVars' in kwargs.keys():\n            self.MaxVars = kwargs['MaxVars']\n        else:\n            self.MaxVars = self.nCols  \n        # Prepare the priors if they are provided.\n        # The priors are provided for the individual regressor variables.\n        # The prior for a model is the product of the priors on the variables in the model.\n        if 'Priors' in kwargs.keys():\n            if np.size(kwargs['Priors']) == self.nCols:\n                self.Priors = kwargs['Priors']\n            else:\n                print(\"WARNING: Provided priors error.  Using equal priors instead.\")\n                print(\"The priors should be a numpy array of length equal tot he number of regressor variables.\")\n                self.Priors = np.ones(self.nCols)  \n        else:\n            self.Priors = np.ones(self.nCols)  \n        \n    def fit(self):\n        # Perform the Bayesian Model Averaging\n        \n        # Initialize the sum of the likelihoods for all the models to zero.  \n        # This will be the 'normalization' denominator in Bayes Theorem.\n        likelighood_sum = 0\n        \n        # To facilitate iterating through all possible models, we start by iterating thorugh\n        # the number of elements in the model.  \n        for num_elements in range(1,self.MaxVars+1): \n            \n            # Make a list of all index sets of models of this size.\n            model_index_sets = list(combinations(list(range(self.nCols)), num_elements)) \n            \n            # Iterate through all possible models of the given size.\n            for model_index_set in model_index_sets:\n                \n                # Compute the linear regression for this given model. \n                model_X = self.X.iloc[:,list(model_index_set)]\n                model_regr = OLS(self.y, model_X).fit()\n                \n                # Compute the likelihood (times the prior) for the model. \n                model_likelihood = np.exp(-model_regr.bic/2)*np.prod(self.Priors[list(model_index_set)])\n                print(\"Model Variables:\",model_index_set,\"likelihood=\",model_likelihood)\n                # Add this likelihood to the running tally of likelihoods.\n                likelighood_sum = likelighood_sum + model_likelihood\n                \n                # Add this likelihood (times the priors) to the runny tally\n                # of likelihoods for each variable in the model.\n                for idx, i in zip(model_index_set, range(num_elements)):\n                    self.likelihoods[idx] = self.likelihoods[idx] + model_likelihood\n                    self.coefficients[idx] = self.coefficients[idx] + model_regr.params[i]*model_likelihood\n\n        # Divide by the denominator in Bayes theorem to normalize the probabilities \n        # sum to one.\n        self.probabilities = self.likelihoods/likelighood_sum\n        self.coefficients = self.coefficients/likelighood_sum\n        \n        # Return the new BMA object as an output.\n        return self\n        \n    def summary(self):\n        # Return the BMA results as a data frame for easy viewing.\n        df = pd.DataFrame([self.names, list(self.probabilities), list(self.coefficients)], \n             [\"Variable Name\", \"Probability\", \"Avg. Coefficient\"]).T\n        return df  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we split our data into input X dataframe and an output y dataframe, and run our BMA analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[[\"Spend\", \"StuTeaRat\", \"Salary\", \"PrcntTake\"]]\ny = df[\"SATT\"]\nresult = BMA(y,add_constant(X)).fit()\nresult.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can consider the full BMA analysis from the regression model.\n\nFirst, we observe that the probability for the PrcntTake variable is 1.  This means that the models that did not include this where so unlikely that we probably shouldn't even consider them.\n\nSecond, pertaining to the origonal question of the relationship between spending and SAT scores, we see that, all other things being equal, increase in spending corresponds to an increase in SAT scores, and the expected value for the coefficient, after considering all possible models, is 8.47046.  This is not as high as what we saw in the model that considered just spending and percent of students taking the exam (about 12), buch much higher (and more reasonable) than the model that considered just spending alone (which had a coefficient of -2.85).  \n\nOf course, there may be some direct or indirect relationships between spending and student-to-teacher ratio and teacher salary that should also be considered.  Taken as a whole, this single BMA output gives a much more complete picture than any individual models, or even consideration of two models.\n\nLast, we should always consider that there are some other underlying variables that are not included in the analysis.  That is, what other data could have been collected about each state that might also be affecting the outcome SAT scores, and how would these variables affect the analysis.  From a model averaging perspective, we are considering whether our set of predictor varailbes is 'complete'.  The analysis only considers variables we put into it, and the results are only valid for these variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is an excessively commented version of the code for Bayeisan Model Averaging.\n\nclass BMA:\n    # After the class definition, we have a sequence of 'methods' associated with the class, \n    # which are just functions that are connected to the class and get internal access \n    # to the internal variables of the class.  The 'self' variable within the class always \n    # refers to class itself.  Varialbes with names of the form self.varname will be \n    # accesible in the methods within the class, and accesible outside the class as \n    # classname.varname.\n    \n    def __init__(self, y, X, **kwargs):\n        # This __init__ function is the initilization method and runs when the class \n        # is created. Here we just use it to attached the X and y variables to the class, \n        # compute basic shape variables and attach them, and build some placeholder \n        # variables for our BMA analysis.  The variable names are self-explanatory.\n        self.y = y\n        self.X = X\n        self.names = list(X.columns)\n        self.nRows, self.nCols = np.shape(X)\n        self.likelihoods = np.zeros(self.nCols)\n        self.coefficients = np.zeros(self.nCols)\n        self.probabilities = np.zeros(self.nCols)\n        self.names = list(X.columns)\n        # Check the max model size. (Max number of predictor variables to use in a model.)\n        # This can be used to reduce the runtime but not doing an exhaustive sampling.\n        if 'MaxVars' in kwargs.keys():\n            self.MaxVars = kwargs['MaxVars']\n        else:\n            self.MaxVars = self.nCols  \n        # Prepare the priors if they are provided.\n        # The priors are provided for the individual regressor variables.\n        # The prior for a model is the product of the priors on the variables in the model.\n        if 'Priors' in kwargs.keys():\n            if np.size(kwargs['Priors']) == self.nCols:\n                self.Priors = kwargs['Priors']\n            else:\n                print(\"WARNING: Provided priors error.  Using equal priors instead.\")\n                print(\"The priors should be a numpy array of length equal tot he number of regressor variables.\")\n                self.Priors = np.ones(self.nCols)  \n        else:\n            self.Priors = np.ones(self.nCols)  \n        \n    def fit(self):\n        # In this fit method, we are doing our model averaging.  This is a Baeysian \n        # process, where in general we consider different values of the parameters and \n        # use Bayes Theorem to compute a probability for each set of parameter values, \n        # resulting in a probability distribution for the parameters.\n        \n        # The parameters we want to estimate is whether or not to include each available \n        # predictor variable.  This means we want to assign a probability to the options \n        # {include, do not include} for each variable. This gives the probability of \n        # including the variable in the model.\n        \n        # From a Bayesian Statistics sampleing perspective, we are going to compute all \n        # possible parameter combinations as the default.  This is only feasible for \n        # problems with only a few predictor variables.  The keyward MaxVars can be used \n        # to reduce the number of models.\n        \n        # We initialize the sum of the likelihoods for all the models to zero.  \n        # This will be the denominatory in Bayes Theorem, and we will apply it to \n        # normalize in the end.\n        likelighood_sum = 0\n        \n        # To facilitate iterating through all possible models, we start by iterating thorugh\n        # the number of elements in the model.  The number of elements is the number of \n        # predictor variables.\n        for num_elements in range(1,self.MaxVars+1): \n            \n            # Make a list of all index sets of models of this size.\n            # For example, if there are 4 predictor variables, this will output the list\n            # [(0,1), (0,2), (0,3), (1,2), (1,2), (2,3)].\n            model_index_sets = list(combinations(list(range(self.nCols)), num_elements)) \n            # We now iterate through all possible models of the given size.\n            for model_index_set in model_index_sets:\n                \n                # This is where the model averaging happens.\n                # First, we compute the linear regression for this given model.  \n                # (In other words, we select the set of input variables in model_index_set, \n                # and compute the linear regression model using just these variables.)  \n                # We do this using OLS from the statsmodels package.  In our notation, \n                # henceforth any variable beginning with model_ is a variable that is \n                # just for this specific model.\n                model_X = self.X.iloc[:,list(model_index_set)]\n                model_regr = OLS(self.y, model_X).fit()\n                \n                # We compute the likelihood for the model from the BIC provided by OLS. \n                # This could alternatively be computed using AIC, the likelihood provided \n                # by OLS, or from RSS using the formula described previously.\n                # NOTE:  This is actually the likelihood times the prior.\n                model_likelihood = np.exp(-model_regr.bic/2)*np.prod(self.Priors[list(model_index_set)])\n                print(\"Model Variables:\",model_index_set,\"likelihood=\",model_likelihood)\n                # Add this likelihood to the running tally of likelihoods for the denominator\n                # in Bayes theorem.\n                likelighood_sum = likelighood_sum + model_likelihood\n                \n                # The key step in model averaging for regression is that for each \n                # predictor variable, the probability that the variable should be included \n                # is the sum of all probabilities for all models that include the given \n                # variable.  This is equal to the sum of likelihoodsfor all models \n                # that include the given variable divided by the total likelihood.  \n                \n                # The other component of model average is that we can compute the \n                # average value of any any varaible over all the models, where this \n                # average is weighted by the probability of each model.  This gives the \n                # expected value for the variable given all the models being considered. \n                # In the following loop we compute the average value for the coefficients\n                # for each variable.\n                \n                # following loop we iterate through all variables in the model \n                # (using their indexes), add the likelihood for the model to the vaiable \n                # tracking the likelihoods for each variable present in the model.  \n                # We also add the coefficent for each variable (weighted by \n                # its likelihood) to the variable for the averaged coefficients.\n                # [NOTE: idx is the index for the predictor variable within the set of \n                # all predictor variables and i is the index for this same \n                # predictor variable in the current regression model.]\n                for idx, i in zip(model_index_set, range(num_elements)):\n                    self.likelihoods[idx] = self.likelihoods[idx] + model_likelihood\n                    self.coefficients[idx] = self.coefficients[idx] + model_regr.params[i]*model_likelihood\n\n        # Now we divide by the denominator in Bayes theorem to normalize the probabilities to one.\n        self.probabilities = self.likelihoods/likelighood_sum\n        self.coefficients = self.coefficients/likelighood_sum\n        \n        # Having updated all the internal varaibles with our Bayeisan Model Averaing, \n        # we return the new BMA object as an output.\n        return self\n        \n    def summary(self):\n        # This function just takes the Bayesian Model Averaging analysis and returns\n        # it as a data frame which makes it easier to veiw.\n        df = pd.DataFrame([self.names, list(self.probabilities), list(self.coefficients)], \n             [\"Variable Name\", \"Probability\", \"Avg. Coefficient\"]).T\n        return df        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}