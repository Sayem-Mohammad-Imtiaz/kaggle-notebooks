{"cells":[{"metadata":{},"cell_type":"markdown","source":"**1 Gather the Data**\n\nAdd the dataset of Titanic into the programe"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2 Data Preparation**\n\n* Split our data into test training data and test data.\n* Split both training data and test data into features data and label data\n* Handle with the missing data(Handle with the problems caused by NaN)"},{"metadata":{},"cell_type":"markdown","source":"**2.1 Prepare the traing data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/titanic/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In my opinion, 'Name' and 'Cabin' and 'Embarked' have nothing to do with the possibility of survival of the passengers. So I set up 'df1' with the rest of the features of the passengers."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = train[['PassengerId','Survived','Pclass','Sex','Age','SibSp','Parch','Fare']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count the number of 'NaN'"},{"metadata":{"trusted":true},"cell_type":"code","source":"p = df1.isnull().sum().sum()\nprint(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In my opinion, filling the 'NaN' with other data which are fake or calculated artificially will decrease the accuracy of our prediction model in this case. So I choose to delete the rows which contain the missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_dl=df1.dropna(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make sure there is no missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"q = df1_dl.isnull().sum().sum()\nprint(q)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try to use '1' or '0' to describe 'Sex' instead of strings.\n* 1 -> male\n* 0 -> female"},{"metadata":{},"cell_type":"markdown","source":"* Set up a new column named 'Sex_value' \n* Set the 'Sex_value' of every passenger according to 'Sex'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_dl['Sex_value'] = df1_dl['Sex']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_dl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_dl.loc[df1_dl['Sex'] == 'male','Sex_value'] = 1\ndf1_dl.loc[df1_dl['Sex'] == 'female','Sex_value'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_dl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set up 'df1_train' without column 'Sex'"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_train = df1_dl[['Survived','Pclass','Age','SibSp','Parch','Fare','Sex_value']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split features and labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = df1_train.iloc[:,1:]\ny_train = df1_train.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2.2 Prepare the test data**\n* Almost the same as preparing the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = test[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare']]\nG_S = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G_S","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add the column 'Survived' of dataframe 'Survived' into dataframe 'df2' in order to delete the rows which contain missing data conveniently."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['Survived'] = G_S['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = df2.isnull().sum().sum()\nprint(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_dl=df2.dropna(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = df2_dl.isnull().sum().sum()\nprint(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_dl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_dl['Sex_value'] = df2_dl['Sex']\ndf2_dl.loc[df2_dl['Sex'] == 'male','Sex_value'] = 1\ndf2_dl.loc[df2_dl['Sex'] == 'female','Sex_value'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_dl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_test = df2_dl[['Pclass','Age','SibSp','Parch','Fare','Sex_value','Survived']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = df2_test.iloc[:,0:6]\ny_test = df2_test.iloc[:,6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the shape of dataframe "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make sure there is no NaN in our data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = x_train.isnull().sum().sum()\ny1 = y_train.isnull().sum().sum()\nx2 = x_test.isnull().sum().sum()\ny2 = y_test.isnull().sum().sum()\nprint(x1,y1,x2,y2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3 Train and Evaluate the Model**\n\nLet's see how LogisticRegression perform in this case "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression()\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4 Predict the Particular Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict(x_test[301:306])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[301:306]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5 Other Models**\n\n* 5.1 SVM\n* 5.2 RandomForestClassifier"},{"metadata":{},"cell_type":"markdown","source":">>5.1 SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC()\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">>5.2 RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Dense(256, activation='relu', input_shape = [x_train.shape[1]]),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(128, activation='relu'),  \n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(64, activation='relu'),  \n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(1)                     \n])\n\noptimizer = tf.keras.optimizers.RMSprop(0.001)\n\nmodel.compile(optimizer=optimizer,\n              loss='mse',\n              metrics=['mae','mse'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(\n    model,\n    to_file='model.png',\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir='TB',\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PrintDot(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs):\n        if epoch % 100 == 0: print('')\n        print('.', end='')\n\nEPOCHS = 2000\n\nhistory = model.fit(\n    x_train, y_train,\n    epochs=EPOCHS, \n    validation_data=(x_test, y_test), \n    verbose=0,\n    callbacks=[PrintDot()],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}