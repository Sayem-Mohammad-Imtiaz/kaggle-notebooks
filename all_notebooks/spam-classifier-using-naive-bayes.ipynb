{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Spam Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport string\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 1: Read dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ndf = pd.read_csv(\n    '/kaggle/input/sms-spam-collection-dataset/spam.csv',\n    encoding='latin-1',\n    usecols=['v1', 'v2']).rename(\n        columns={'v1':'target', 'v2':'content'})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check null values\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part 2: EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check total spam and ham\ndf.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check content length\ndf['len_content'] = df['content'].apply(lambda x:len(x))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('target')['len_content'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\ndf[df.target=='spam']['len_content'].plot(kind='hist', color='r', label='Spam', alpha=0.6)\ndf[df.target=='ham']['len_content'].plot(kind='hist', bins=35, color='b', label='Ham', alpha=0.5)\nplt.legend(loc='upper right')\nplt.xlabel('Content length')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spam messages have longer content length than ham.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Part 3: Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"steps = [\n    ('tfidf', TfidfVectorizer(min_df=4)),\n    ('model', MultinomialNB())]\npipeline = Pipeline(steps)\n\n# Clean content\nstopword = stopwords.words('english') + [\n    'u', 'Ã¼', 'ur', '4', '2', 'im', 'dont',\n    'doin', 'ure', 'n', 'e', 'c', 'r', 'v',\n    'k', 'y', 'x']\n\ndef before_text_clean(dataframe):\n    # Train test split\n    y = dataframe['target']\n    X = dataframe['content']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    \n    # Model fit\n    pipeline.fit(X_train, y_train)\n    y_pred = pipeline.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    print('Accuracy: {}\\nConfusion matrix:\\n{}'.format(accuracy, cf_matrix))\n\n    \ndef cleaning_text(text):\n    # Remove punctuations\n    text  = \"\".join([char for char in text if char not in string.punctuation])\n        \n    # Tokenize\n    text = word_tokenize(text.lower())\n    \n    # Remove stopwords\n    return \" \".join([char for char in text if char not in stopword])                  \n    \n\ndef after_text_clean(dataframe):\n    # Text clean\n    dataframe['clean_text'] = dataframe['content'].apply(lambda x:cleaning_text(x))\n    \n    # Train test split\n    y = dataframe['target']\n    X = dataframe['clean_text']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    \n    # Model fit\n    pipeline.fit(X_train, y_train)\n    y_pred = pipeline.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    cf_matrix = confusion_matrix(y_test, y_pred)\n    print('Accuracy: {}\\nConfusion matrix:\\n{}'.format(accuracy, cf_matrix))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"before_text_clean(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"after_text_clean(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Text cleaning helped to increase the accuracy slightly. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}