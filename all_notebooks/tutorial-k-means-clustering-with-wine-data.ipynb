{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Custom Functions\n'''\nNull_value_imputations\n1. show_percentage_values_missing(dataFrame:pd.DataFrame) Show all percentage values missing\n2. missing_val_regression(df , feature_name)              Replace continuous variables\n3. replace_all_empty_in_df(df :pd.DataFrame)              Replace all empty data in dataframe\n\nOutlier handling\n1. boxplot_plot(data:pd.DataFrame, bins:int, vert:bool, print_stats:bool)   Bin number allows us to automatically segment the boxplots\n2. outlier_removal_by_std(data:pd.DataFrame,std_multi:int=3, inplace:bool=False)            Don't use if more than 20% dataloss\n3. outlier_using_range(data:pd.DataFrame, inplace:bool=False)               If too much data loss, use this function instead\n\nDensity and correlation\n1. get_density_plots(data:pd.DataFrame, suptitle:str)\n2. correlation_fig(df:pd.DataFrame)\n\nKmeans\n1. norm(a:list)\n2. elbow_method(data:pd.DataFrame, max_range:int, title:str)\n'''\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stat\nimport math\nimport matplotlib.pyplot as plt\nfrom cycler import cycler\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\ndef show_percentage_values_missing(dataFrame:pd.DataFrame):\n    missing_values = pd.concat([\n        dataFrame.isnull().sum().sort_values(ascending = False) ,                                                  #Column 1\n        dataFrame.isnull().sum().sort_values(ascending = False).apply(lambda x: (x / dataFrame.shape[0]) * 100) ,  #Column 2\n        dataFrame.dtypes                                                                                           #Column 3\n    ],\n        axis = 1, #Increasing by column\n        keys = ['Values missing', 'Percent of missing', 'Data type'])\n    if dataFrame.isnull().sum().sum() == 0:\n        print('\\n==================================================\\nThere are no null values present in this dataframe\\n==================================================')\n    return (missing_values[missing_values['Percent of missing']>0]) \n\ndef missing_val_regression(df,feature):\n    df_copy = df.copy()\n    df_true = df_copy.dropna() #DF with non_nans\n    \n    #Define Null Colls and Categorical/Obj Colls\n    null_columns = df.columns[df.isna().any()]\n    obj_columns = df.select_dtypes(include='object').columns\n    parameters = list(set(df.columns) - set(null_columns)- set(obj_columns))\n\n\n    model = LinearRegression()\n    model.fit(X = df_true[parameters],y = df_true[feature])\n\n    df_copy.loc[df_copy[feature].isnull(), feature] = model.predict(df_copy[parameters])[df_copy[feature].isnull()]\n    return df_copy\n\ndef replace_all_empty_in_df(df :pd.DataFrame):\n    for missing_feature in reversed(df.columns[df.isna().any()]):\n        df = missing_val_regression(df, missing_feature)\n        print(show_percentage_values_missing(data))\n    return df\n\n#Outlier\ndef boxplot_plot(data:pd.DataFrame, bins:int, vert:bool, print_stats:bool=False):\n    stds = data.std().to_list()\n    if print_stats:\n        print(stds)\n        print(some_df)\n    some_df = pd.DataFrame()\n    some_df['range'] = pd.cut(data.describe().std(),bins = bins, labels=list(range(0,bins)))\n    for i in set(some_df['range']):\n        desired_column = some_df[some_df['range']==i].index\n        df_new = pd.DataFrame(data[desired_column])\n        df_new.plot.box(grid='True', vert=vert)\n        \ndef outlier_removal_by_std(data:pd.DataFrame,std_multi:int=3, inplace:bool=False):\n    df_copy = data if inplace else data.copy()\n    data_shape_before = data.shape\n    print('Before outlier removal   : ', data_shape_before)\n    for name in df_copy.select_dtypes(exclude=\"object\").columns:\n        upper_limit = df_copy[name].mean() + std_multi*df_copy[name].std()\n        lower_limit = df_copy[name].mean() - std_multi*df_copy[name].std()\n        df_copy.drop(df_copy[(lower_limit>df_copy[name]) | (df_copy[name]>upper_limit)].index, inplace = True)\n    print('After removal of outliers: ' ,df_copy.shape)\n    print('Total percentage of data removed due to outliers', ((data_shape_before[0]-df_copy.shape[0])/data_shape_before[0])*100)\n    print('With upperlimit = (mean+',std_multi,'x std)')\n\ndef outlier_using_range(data:pd.DataFrame, inplace:bool=False):\n    df2_copy = data if inplace else data.copy\n    for col in df2_copy.columns:\n        if((df2_copy[col].max() - df2_copy[col].min()) > 12 ):\n            df_test = pd.cut(df2_copy[col], bins = 8, labels=[1,2,3,4,5,6,7,8])\n            new_name = col+'_RANGE'\n            df2_copy[new_name] = df_test\n            df2_copy.drop(columns=col, axis=1,inplace=True)\n    \n    df2_copy.head()\n\n\ndef get_density_plots(data:pd.DataFrame, suptitle:str):\n    df_len = len(data.select_dtypes(exclude = \"object\").columns)\n    rows = df_len//5 if df_len%5 == 0 else (df_len//5)+1\n    \n    #Axes\n    fig, axes = plt.subplots(rows,5, figsize=(20,20))\n    axes = axes.flatten()\n    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n    fig.suptitle(suptitle, fontsize=20)\n\n    count = 0\n    for i,name in enumerate(data.select_dtypes(exclude = \"object\").columns):\n        #Math of density function\n        mean = data[name].mean()\n        std = data[name].std()\n        x_axis = sorted(data[name])\n        y_axis = stat.norm.pdf(x_axis, data[name].mean(), data[name].std())\n        \n        if (i+3) > len(colors):\n            colors=colors+colors\n        #Plot histogram and lineplot in similar ax\n        axes[i].plot(x_axis,y_axis,color=colors[i+2], linewidth=3)\n        axes[i].hist(data[name], bins=20, rwidth=0.6, density=True,color=colors[i])\n        axes[i].legend(['density','frequency'], \n                       bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left', ncol=2, mode=\"expand\", borderaxespad=0.)\n        #Set x and y labels\n        axes[i].set_xlabel(name)\n        axes[i].set_ylabel(\"count\")\n        \n        count=i\n    #Delete unnecessary rows\n    for x in range(count,len(axes)):\n        axes.flat[x].remove()\n\n    plt.show()\n\ndef correlation_fig(df:pd.DataFrame):\n    #Compute the correlation matrix\n    corr = df.corr()\n    \n    #Generate a mask for the upper triangle\n    mask = np.triu(np.ones_like(corr,dtype=bool))\n    \n    #Set up the matplotlib figure\n    fig, axes =  plt.subplots(figsize=(11,9))\n    \n    #Generate a custom diverging colormap\n    cmap = sns.diverging_palette(230,20,as_cmap=True)\n    \n    #Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(corr,mask=mask,cmap=cmap,vmax=1, center=0,\n               square=True, linewidths=.5, cbar_kws={\"shrink\":.5})\n    \n#Elbow methods\nfrom sklearn.metrics import silhouette_score\nfrom sklearn import preprocessing as pp\n\ndef norm(a:list):\n    rtn = [(float(i)-min(a))/(max(a)-min(a)) for i in a]\n    #print(rtn)\n    return rtn\n\ndef elbow_method(data:pd.DataFrame, max_range:int, title:str):\n    mean_square_error = []\n    sil = []\n    range_of_plot = range(1,max_range+1)\n    for i in range_of_plot:\n        km= KMeans(n_clusters=i, init='random', n_init=10, max_iter=300,random_state=0)\n        label = km.fit(data)\n        labels = km.labels_\n        mean_square_error.append(km.inertia_)\n        if i>1:\n            sil.append(silhouette_score(data, labels, metric = 'euclidean')) \n    df = pd.DataFrame()\n    df['range_of_k'] = range_of_plot\n    df['mean_square'] = norm(mean_square_error)\n    df['silhouette'] = [0]+norm(sil)\n\n    #2 plots in 1 plot, or same axes\n    ax = sns.lineplot(data=df,x=\"range_of_k\",y=\"silhouette\", label='Silhouette',marker='o')\n    ax = sns.lineplot(data=df,x=\"range_of_k\",y=\"mean_square\",label = 'Elbow aka MeanSquare', marker='o')\n    ax.set(xlabel=\"k\", ylabel = \"Score\", title=title)\n    index_of_max_silhouette = df['silhouette'].idxmax() \n    k_ideal = df['range_of_k'][index_of_max_silhouette]\n    print('ideal number of k_cluster for ',title,'is: [',k_ideal,']')\n    return k_ideal","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nwine_data = pd.read_csv('../input/wine-pca/Wine.csv')\nwine_data.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Summary of data\nwine_data.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dealing with null\nThere is no null values apparently","metadata":{}},{"cell_type":"code","source":"show_percentage_values_missing(wine_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Outliers\n","metadata":{}},{"cell_type":"code","source":"wine_data.plot.box(grid='True', vert=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxplot_plot(wine_data,bins=90,vert=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#outlier_removal_by_std(wine_data,,inplace=True)\noutlier_removal_by_std(data= wine_data,std_multi=2.5, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxplot_plot(wine_data,bins=90,vert=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_density_plots(wine_data,suptitle=\"Density and frequency plot\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_fig(wine_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Illustrating Flavanoids and Total_Phenols\nsns.regplot(x=wine_data.Flavanoids, y=wine_data.Total_Phenols).set(title='Relationship between Phenols and Flavanoids')\nplt.show()\n\n#Dropping One of the features due to high correlation\nwine_data.drop(['Total_Phenols'], axis=1, inplace=True)\n'''\n#Standard matplotlib\nx = wine_data.Flavanoids\ny = wine_data.Total_Phenols\nm , c = np.polyfit(x,y,1)\nplt.scatter(x=x,y=y,marker='o')\nplt.title('Matplotlib')\nplt.plot(x, m*x+c)\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize data\nfrom sklearn.preprocessing import StandardScaler \nnormalized_wine_data = StandardScaler().fit_transform(wine_data)\n\n\n#Demonstration of normalized data\nfig, axes = plt.subplots(1,2, figsize=(10,10))\naxes = axes.flatten()\n\naxes[0].scatter(x=wine_data.Alcohol, y=wine_data.Flavanoids, color='black')\naxes[1].scatter(x= norm(wine_data.Alcohol) ,y=norm(wine_data.Flavanoids),color='black')\n\n#Set Labels and titles\naxes[0].set_title('Original data')\naxes[0].set_xlabel('Alcohol')\naxes[0].set_ylabel('Flavanoids')\naxes[1].set_title('Normalized data')\naxes[1].set_xlabel('Alcohol')\naxes[1].set_ylabel('Flavanoids')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elbow_method(data=normalized_wine_data, max_range=10, title='Normalized k_means')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elbow_method(data=wine_data, max_range=10, title='Original/Non_normalized k_means')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = normalized_wine_data\n\nkm = KMeans(n_clusters=3, init='random', n_init=10, max_iter=400,random_state=0)\nlabel = km.fit_predict(X)\ncentroids= km.cluster_centers_\n\nfor i in list(set(label)):\n    name='cluster'+str(i)\n    sns.scatterplot(x=X[label==i,0], y=X[label==i,1], marker=\"o\", label=name )\n\ndf_copy = wine_data.copy()\ndf_copy['label'] = pd.cut(label ,bins = 3, labels=['cluster0','cluster1','cluster2'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iterate = len(df_copy.columns)\n#print\nsns.pairplot(df_copy, hue=\"label\", markers=[\"o\",\"s\",\"D\"], \n             x_vars= df_copy.columns[0:6],\n             y_vars= df_copy.columns[0:6],\n             corner= True)\nsns.pairplot(df_copy, hue=\"label\", markers=[\"o\",\"s\",\"D\"],\n             x_vars= df_copy.columns[6:12],\n             y_vars= df_copy.columns[6:12],\n             corner= True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}