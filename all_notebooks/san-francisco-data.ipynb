{"cells":[{"metadata":{},"cell_type":"markdown","source":"# San Francisco Data Analysis "},{"metadata":{},"cell_type":"markdown","source":"### Based on Location Data. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport folium\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sf-parks/SF_Park_Scores.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns={'Facility Type':'FacilityType','Square Feet':'SquareFeet','Perimeter Length':'PerimeterLength'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"park_data = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data_na = (park_data.isnull().sum() / len(park_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Cleaning Process\n# I will drop the Floor Count    \npark_data = park_data.drop([\"Floor Count\"], axis = 1)\npark_data = park_data.dropna()\n#I will put 0 for numeric data\npark_data[\"Latitude\"] = park_data[\"Latitude\"].fillna(0)\npark_data[\"Longitude\"] = park_data[\"Longitude\"].fillna(0)\npark_data[\"Acres\"] = park_data[\"Acres\"].fillna(0)\npark_data[\"Perimeter Length\"] = park_data[\"PerimeterLength\"].fillna(0)\npark_data[\"Square Feet\"] = park_data[\"SquareFeet\"].fillna(0)\npark_data[\"Zipcode\"] = park_data[\"Zipcode\"].fillna(0)\n#I will put None for strings\npark_data[\"State\"] = park_data[\"State\"].fillna(\"None\")\npark_data[\"Address\"] = park_data[\"Address\"].fillna(\"None\")\npark_data[\"Facility Name\"] = park_data[\"Facility Name\"].fillna(\"None\")\npark_data[\"FacilityType\"] = park_data[\"FacilityType\"].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#info about the dataset\npark_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"park_data.Zipcode.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#the distrubution of parks in san francisco in terms of longtitude and latitude\nlongitude = list(park_data.Longitude) \nlatitude = list(park_data.Latitude)\nplt.figure(figsize = (10,10))\nplt.plot(longitude,latitude,'.', alpha = 0.4, markersize = 30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"address = 'san francisco'\n\ngeolocator = Nominatim(user_agent=\"san francisco\")\nlocation = geolocator.geocode(address)\nlatitude_toronto = location.latitude\nlongitude_toronto = location.longitude\nprint('The geograpical coordinate of san francisco are {}, {}.'.format(latitude_toronto, longitude_toronto))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_toronto = folium.Map(location=[latitude_toronto, longitude_toronto], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, Neighbourhood in zip(park_data['Latitude'], park_data['Longitude'], park_data['Park'], park_data['Score']):\n    label = '{}, {}'.format(Neighbourhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(22,12))\nsns.countplot(y=park_data['Zipcode'],order=park_data['Zipcode'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nfrom wordcloud import WordCloud, STOPWORDS\n\nmpl.rcParams['font.size']=12                \nmpl.rcParams['savefig.dpi']=100             \nmpl.rcParams['figure.subplot.bottom']=.1 \nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(park_data['Park']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\nfig.savefig(\"word1.png\", dpi=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SF Parks Facility Score points\npark_data['Score'].value_counts().sort_index().plot.line(figsize=(12, 6),color='mediumvioletred',fontsize=16,title='SF Parks Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Which Public Administation has the highest parks \nimport plotly.graph_objs as go\nimport plotly.offline as py\npy.init_notebook_mode(connected=True) # this is important\n\nz = {'PSA1': 'PSA1', 'PSA2': 'PSA2', 'PSA3': 'PSA3','PSA4': 'PSA4','PSA5': 'PSA5','PSA6': 'PSA6','GGP': 'GGP'}\ndata = [go.Bar(\n            x = park_data.PSA.map(z).unique(),\n            y = park_data.PSA.value_counts().values,\n            marker= dict(colorscale='Jet',\n                         color = park_data.PSA.value_counts().values\n                        ),\n           \n    )]\n\nlayout = go.Layout(\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='basic-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLIENT_ID = 'MIF2SPKPEZP0YIUKZMPBLCA3R4ESWCFJDYPFTPHV4PTFVXIO' # your Foursquare ID\nCLIENT_SECRET = '5UOPEX5O43CRW0TZWYYOXST2VJBTPKIXAJWJ2TJVH3S23ZEK' # your Foursquare Secret\nVERSION = '20180604'\nLIMIT = 30\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_venues = getNearbyVenues(names=park_data['Park'].head(20),\n                                   latitudes=park_data['Latitude'],\n                                   longitudes=park_data['Longitude']\n                                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(manhattan_venues.shape)\nmanhattan_venues.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_venues.groupby('Neighborhood').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} uniques categories.'.format(len(manhattan_venues['Venue Category'].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding\nmanhattan_onehot = pd.get_dummies(manhattan_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nmanhattan_onehot['Neighborhood'] = manhattan_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [manhattan_onehot.columns[-1]] + list(manhattan_onehot.columns[:-1])\nmanhattan_onehot = manhattan_onehot[fixed_columns]\n\nmanhattan_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_onehot.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_grouped = manhattan_onehot.groupby('Neighborhood').mean().reset_index()\nmanhattan_grouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_grouped.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_top_venues = 5\n\nfor hood in manhattan_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = manhattan_grouped[manhattan_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = manhattan_grouped['Neighborhood']\n\nfor ind in np.arange(manhattan_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(manhattan_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster Neighborhoods"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set number of clusters\nkclusters = 5\n\nmanhattan_grouped_clustering = manhattan_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(manhattan_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n#park_data.drop(['Cluster Labels'], axis=1)\nmanhattan_merged = park_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nmanhattan_merged = manhattan_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Park')\n\nmanhattan_merged.head() # check the last columns!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"address = 'san francisco'\n\ngeolocator = Nominatim(user_agent=\"san francisco\")\nlocation = geolocator.geocode(address)\nlatitude_toronto = location.latitude\nlongitude_toronto = location.longitude\nprint('The geograpical coordinate of san francisco are {}, {}.'.format(latitude_toronto, longitude_toronto))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_clusters = folium.Map(location=[latitude_toronto, longitude_toronto], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(manhattan_merged['Latitude'], manhattan_merged['Longitude'], manhattan_merged['Park'], manhattan_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        #color=rainbow[kcluster-1],\n        fill=True,\n        #fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Examine Clusters"},{"metadata":{},"cell_type":"markdown","source":"#### Cluster 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 0, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cluster 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 1, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cluster 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 2, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cluster 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 3, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cluster 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"manhattan_merged.loc[manhattan_merged['Cluster Labels'] == 4, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## By the Observations and Analysis of Data. Following are the findings\n* Public Administation PSA4 has most parks\n* Park Play ground are the most used workds in it\n* Clusters are formed so that easily group can be classified"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}