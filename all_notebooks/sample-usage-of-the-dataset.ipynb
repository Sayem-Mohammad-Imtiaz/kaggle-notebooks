{"cells":[{"metadata":{"_uuid":"bf3845dde951f2d7626d53cb8e8bbe94461be958","_cell_guid":"60b63b60-db11-40d0-8e96-670010c0042e"},"cell_type":"markdown","source":"This notebook demonstrate Sentiment Analysis on Roman Urdu"},{"metadata":{"_uuid":"89d88752813076a620f71b48218d083736d62f4f","_cell_guid":"e0113241-a2d2-451a-a10e-9939ce88b505"},"cell_type":"markdown","source":"## Imports\nHere we are simply importing the things we will be using in our Script\n"},{"metadata":{"_uuid":"216f65e3f9a5f5bc4128c1045e1455686133d010","_cell_guid":"f2be002c-c3b6-48a8-9e91-40282471a2ed","collapsed":true,"trusted":true},"cell_type":"code","source":"\nfrom __future__ import print_function\n\nimport logging\nimport numpy as np\nfrom optparse import OptionParser\nimport sys\nfrom time import time\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.extmath import density\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport eli5\n\nimport re\nfrom tqdm import *\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1122598a0abca12d9ba6c303a47d44aaa7dca370","_cell_guid":"608af430-8416-4f70-863d-ecff612d17b7"},"cell_type":"markdown","source":"## Preprocessing\nHere are two utility functions to clean data, and optionally use the phonetic algorithm to hash the data."},{"metadata":{"_uuid":"5d72438e102e4363e322c1d392d21c2c75206dcf","_cell_guid":"30ff3145-21b8-4dd4-8772-28d938bff5b8","collapsed":true,"trusted":true},"cell_type":"code","source":"\ndef cleaner(word):\n  word = re.sub(r'\\#\\.', '', word)\n  word = re.sub(r'\\n', '', word)\n  word = re.sub(r',', '', word)\n  word = re.sub(r'\\-', ' ', word)\n  word = re.sub(r'\\.', '', word)\n  word = re.sub(r'\\\\', ' ', word)\n  word = re.sub(r'\\\\x\\.+', '', word)\n  word = re.sub(r'\\d', '', word)\n  word = re.sub(r'^_.', '', word)\n  word = re.sub(r'_', ' ', word)\n  word = re.sub(r'^ ', '', word)\n  word = re.sub(r' $', '', word)\n  word = re.sub(r'\\?', '', word)\n\n  return word.lower()\n\n\ndef hashing(word):\n  word = re.sub(r'ain$', r'ein', word)\n  word = re.sub(r'ai', r'ae', word)\n  word = re.sub(r'ay$', r'e', word)\n  word = re.sub(r'ey$', r'e', word)\n  word = re.sub(r'ie$', r'y', word)\n  word = re.sub(r'^es', r'is', word)\n  word = re.sub(r'a+', r'a', word)\n  word = re.sub(r'j+', r'j', word)\n  word = re.sub(r'd+', r'd', word)\n  word = re.sub(r'u', r'o', word)\n  word = re.sub(r'o+', r'o', word)\n  word = re.sub(r'ee+', r'i', word)\n  if not re.match(r'ar', word):\n    word = re.sub(r'ar', r'r', word)\n  word = re.sub(r'iy+', r'i', word)\n  word = re.sub(r'ih+', r'eh', word)\n  word = re.sub(r's+', r's', word)\n  if re.search(r'[rst]y', 'word') and word[-1] != 'y':\n    word = re.sub(r'y', r'i', word)\n  if re.search(r'[bcdefghijklmnopqrtuvwxyz]i', word):\n    word = re.sub(r'i$', r'y', word)\n  if re.search(r'[acefghijlmnoqrstuvwxyz]h', word):\n    word = re.sub(r'h', '', word)\n  word = re.sub(r'k', r'q', word)\n  return word\n\ndef array_cleaner(array):\n  # X = array\n  X = []\n  for sentence in array:\n    clean_sentence = ''\n    words = str(sentence).split(' ')\n    for word in words:\n      clean_sentence = clean_sentence +' '+ cleaner(word)\n    X.append(clean_sentence)\n  return X\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58a4ec2353df76cec523ac1f9a1c109b508bc829","_cell_guid":"7d200c76-23d9-4ef8-8474-1e600bca7c97"},"cell_type":"markdown","source":"## Data\n\nHere we are reading the file containing data"},{"metadata":{"_uuid":"226cd27c85cecac134073efeb7dfece51989fc3f","_cell_guid":"8aab9899-1dfe-434b-8960-eb0c7772dd8b","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/roman-urdu-dataset/Dataset/Roman Urdu DataSet.csv', encoding=\"ISO-8859-1\", header=None)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70769a6e79eea8730cd8d890842c3bfd34f8bbab","_cell_guid":"672f51d2-0c4d-44f9-abcd-d194ac6f1434"},"cell_type":"markdown","source":"We are training the data on all of the dataset."},{"metadata":{"_uuid":"3eb556b1a5fd33514bcc5d2fe024c4110566279f","_cell_guid":"088a7cb5-45d9-4d66-89e6-5b01beed2f45","trusted":true},"cell_type":"code","source":"numpy_array = data.as_matrix()\nX = numpy_array[:, 0]\n# Clean X here\nX_train = array_cleaner(X)\ny_train = numpy_array[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04ae758e9280d85ae07c23acb0110caee59ca95d","_cell_guid":"d71d7b0e-3849-4fa4-80f9-808af11054cd"},"cell_type":"markdown","source":"## Vectorizing\nAnd using TF-IDF as our vectorizing method.\nWe are specifying the N-gram to be 3.\n"},{"metadata":{"_uuid":"d3d6f7801a6bc05a0a4954cb57f8f81b07e6ef54","_cell_guid":"7157fceb-48f8-4151-9f0a-a47c88fd97ac","trusted":true,"collapsed":true},"cell_type":"code","source":"ngram = 3\nvectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1, ngram), max_df=0.5)\nX_train = vectorizer.fit_transform(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c28bbcd459d6efb948100dac675f423637aacd24","_cell_guid":"9aa2ded0-370d-476a-8858-772d23a82a58"},"cell_type":"markdown","source":"## Classification\n\nA utility function to help us train different classifier:\n"},{"metadata":{"_uuid":"dea02feae0c4eeded39aeedc91faae91fb168e06","_cell_guid":"04fea009-051b-4bbe-89c4-7b3e57f2078f","collapsed":true,"trusted":true},"cell_type":"code","source":"def benchmark(clf, name):\n  print('_' * 80)\n  print(\"Training: \")\n  print(clf)\n  clf.fit(X_train, y_train)\n  return clf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3fb4db4f0db4069dc026698dffe7a26fa6ce075","_cell_guid":"54d011d2-ec89-48fe-8344-11a038197f28"},"cell_type":"markdown","source":"Uncomment single classifier to train the model to it.\n\nThe top features (both positive and negative) for each class would be listed.\n"},{"metadata":{"_uuid":"7f581f744fcace5223d556913bcaa34ea5909915","_cell_guid":"2257b019-0472-4442-a0cd-a9119323298a","trusted":true,"collapsed":true},"cell_type":"code","source":"# clf = benchmark(RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\")\nclf = benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty=\"elasticnet\"), 'SGD-elasticnet')\n# clf = benchmark(SGDClassifier(alpha=.0001, n_iter=50,penalty='l1'), 'SGD-L1')\n# clf = benchmark(LinearSVC(penalty='l1', dual=False,tol=1e-3), 'liblinear L1')\n# clf = benchmark(LinearSVC(penalty='l2', dual=False,tol=1e-3), 'liblinear L2')\n# clf = benchmark(MultinomialNB(alpha=.01), 'MultiNB')\n# clf = benchmark(BernoulliNB(alpha=.01), 'BernoulliNB')\n# clf = benchmark(NearestCentroid(), 'Rocchio')\n# clf = benchmark(KNeighborsClassifier(n_neighbors=10), \"kNN\")\n# clf = benchmark(PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\")\n\neli5.show_weights(clf, vec=vectorizer)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5230d2d13baafc417a2002c9c7256b2e37fc3b4","_cell_guid":"c3f93848-a4c4-481f-9c0e-6740bc10c38b"},"cell_type":"markdown","source":"## Testing\n\nWe can check our model against a test sentence to see how well it performed."},{"metadata":{"_uuid":"187b38202d8cd059b54a02651ea5ae1149dcc05c","_cell_guid":"a9568c1c-b89e-4c6a-884d-37a772e31803","trusted":true,"collapsed":true},"cell_type":"code","source":"test_sentence = \"Movie achi thi magar hero bura tha\"\neli5.show_prediction(clf, doc=test_sentence, vec=vectorizer)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":1}